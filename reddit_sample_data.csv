id,author,author_flair_text,created,clicked,distinguished,edited,is_original_content,is_self,locked,permalink,title,content,subreddit,url,num_comments,score,upvote_ratio,comments
17ovaau,AutoModerator,,2023-11-06 05:01:25+00:00,False,,False,False,True,False,/r/datascience/comments/17ovaau/weekly_entering_transitioning_thread_06_nov_2023/,"Weekly Entering & Transitioning - Thread 06 Nov, 2023 - 13 Nov, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/17ovaau/weekly_entering_transitioning_thread_06_nov_2023/,3,1,1.0,"[Comment(id='k821anq'), Comment(id='k82i6cv'), Comment(id='k82l8wv')]"
17igak2,Omega037,PhD | Sr Data Scientist Lead | Biotech,2023-10-28 15:35:43+00:00,False,moderator,False,False,True,False,/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,[Meta] New Automod Rule - Minimum Comment Karma before Submissions,"After feedback from many members and discussions within the mod team, we have decided to implement a new Automod rule:

**Rule:** Effective immediately, **users must have at least 10 comment karma** **within** r/datascience **before they can make a top-level submission.**

The desired outcomes are:

1. Reduce pure self-promotion botspam
2. Reduce the number of top-level submissions that belong to the Weekly Sticky thread.

**Please let us know if it appears to be working incorrectly or causing unwanted side effects.**",datascience,https://www.reddit.com/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,23,49,0.96,"[Comment(id='k6tzxfr'), Comment(id='k6uhhep'), Comment(id='k6ul7pa'), Comment(id='k6upm79'), Comment(id='k6vtoi6'), Comment(id='k6vzca0'), Comment(id='k6xc30u'), Comment(id='k6vfoue'), Comment(id='k6yb67z'), Comment(id='k72f04h'), Comment(id='k74vzwv'), Comment(id='k76p2zt'), Comment(id='k7as0sz'), Comment(id='k7c7ofx'), Comment(id='k7d7lam'), Comment(id='k7etzi7'), Comment(id='k7fm52l'), Comment(id='k7ncv6j'), Comment(id='k7yn8nw'), Comment(id='k6uk8nc'), Comment(id='k7exn8b'), Comment(id='k7ndc1v'), Comment(id='k7ogl4p')]"
17oulta,Difficult-Big-3890,,2023-11-06 04:19:53+00:00,False,,False,False,False,False,/r/datascience/comments/17oulta/how_much_do_you_agree_with_this_post_screenshot/,How much do you agree with this post (screenshot attached) based on your DS experience?,"TlDr: A DS needs to have functional knowledge about Docker, OOP, FastAPI, Postgres to create relational DB.",datascience,https://i.redd.it/sfozkw40mnyb1.jpg,90,184,0.9,"[Comment(id='k813t0x'), Comment(id='k814ls5'), Comment(id='k814h6u'), Comment(id='k81dto7'), Comment(id='k816fpu'), Comment(id='k81ajvd'), Comment(id='k818ghr'), Comment(id='k81bahk'), Comment(id='k81b6fc'), Comment(id='k8190g1'), Comment(id='k817m5y'), Comment(id='k81bxhy'), Comment(id='k81eagt'), Comment(id='k81flo0'), Comment(id='k81cv3s'), Comment(id='k81logg'), Comment(id='k816tni'), Comment(id='k81iesl'), Comment(id='k81mw0z'), Comment(id='k81r4cb'), Comment(id='k8289g7'), Comment(id='k8164h9'), Comment(id='k81fohq'), Comment(id='k81kpq9'), Comment(id='k81d0c8'), Comment(id='k81jvr9'), Comment(id='k81jvwa'), Comment(id='k81ipp4'), Comment(id='k81pfv0'), Comment(id='k81u773'), Comment(id='k81ghc7'), Comment(id='k81jlkk'), Comment(id='k81rima'), Comment(id='k81s2ez'), Comment(id='k81ufn6'), Comment(id='k81x90g'), Comment(id='k820c1m'), Comment(id='k8231hw'), Comment(id='k82am9n'), Comment(id='k82bulg'), Comment(id='k82c9tl'), Comment(id='k82cxk5'), Comment(id='k82ep3c'), Comment(id='k82f6ew'), Comment(id='k82fpje'), Comment(id='k82gu1i'), Comment(id='k82i40f'), Comment(id='k82j8z8'), Comment(id='k82jb92'), Comment(id='k82jlz1'), Comment(id='k822m57'), Comment(id='k82motr'), Comment(id='k81kuu9'), Comment(id='k81jzw4'), Comment(id='k82lhj6'), Comment(id='k81830c'), Comment(id='k81cfv1'), Comment(id='k81d3zj'), Comment(id='k829od6'), Comment(id='k821lxm'), Comment(id='k82blgy'), Comment(id='k82duxk'), Comment(id='k81kixn'), Comment(id='k81antz'), Comment(id='k82e4et'), Comment(id='k8288kz'), Comment(id='k82emfz'), Comment(id='k82lyk8'), Comment(id='k81oehr'), Comment(id='k81v95q'), Comment(id='k81o6cu'), Comment(id='k82cji0'), Comment(id='k81hh10'), Comment(id='k8250i2'), Comment(id='k81y409'), Comment(id='k81xdlf'), Comment(id='k81p8zf'), Comment(id='k81wzj4'), Comment(id='k82el5j'), Comment(id='k822tbq'), Comment(id='k82g9oh'), Comment(id='k8245gt'), Comment(id='k826fnh'), Comment(id='k829jgb'), Comment(id='k82epue'), Comment(id='k82bted'), Comment(id='k82c59h'), Comment(id='k82d9j4'), <MoreComments count=0, children=[]>]"
17p2qtc,fulowa,,2023-11-06 13:29:18+00:00,False,,False,False,True,False,/r/datascience/comments/17p2qtc/data_scientist_action_figure_dalle3/,Data Scientist action figure (dalle3),"dalle3 prompt: data scientist as a sealed action figure

[dalle3 prompt: data scientist as a sealed action figure](https://preview.redd.it/3s37ff2qbqyb1.png?width=1024&format=png&auto=webp&s=e39787d53aa1b3e947e9f0e5ade9c9ca71df3b01)",datascience,https://www.reddit.com/r/datascience/comments/17p2qtc/data_scientist_action_figure_dalle3/,4,4,0.83,"[Comment(id='k82fxo3'), Comment(id='k82hgsg'), Comment(id='k82hnnm'), Comment(id='k82lvol')]"
17ox3wi,swordyfish,,2023-11-06 07:04:17+00:00,False,,1699254672.0,False,True,False,/r/datascience/comments/17ox3wi/where_do_you_get_help_for_personal_projects/,Where do you get help for personal projects?,"As a student, I'm used to going to office hours to get help on projects. However, once I graduate and start working on my own personal projects, who can I turn to for help?

I understand that finding the answer yourself is the most rewarding and that there's ChatGPT and such now, but I still find it extremely useful to have a zoom call with someone to go over stuff.

Resources I can think of are friends, discord servers, mentors, and maybe even paid freelancers (on Upwork or something?). Does anyone have experience with any of those? What resources do you guys use for your own personal projects?",datascience,https://www.reddit.com/r/datascience/comments/17ox3wi/where_do_you_get_help_for_personal_projects/,5,6,1.0,"[Comment(id='k81p58b'), Comment(id='k82bz5s'), Comment(id='k82c147'), Comment(id='k81rqsz'), Comment(id='k81v4wi')]"
17o4er9,WeOnlyCryAlone,,2023-11-05 04:36:18+00:00,False,,False,False,True,False,/r/datascience/comments/17o4er9/expecting_to_be_laidoff_in_q1_how_do_i_prepare_to/,"Expecting to be laid-off in Q1, how do I prepare to re-enter the job market?","Currently employed with a title of Data Scientist but really I'm a product analyst building out to Excel on ad hoc projects, mostly around why we aren't making money in that product line. My company is in the third round of layoffs this year and without a plan to improve, I'm expecting to exit, one way or the other, early in 2024.   


I'm feeling woefully under-skilled because I've been underutilized. I haven't put a model into production in three years because we haven't been asked. I have built dashboards that don't get used because managers want to look at the data themselves in Excel. My company has done \_nothing\_ with GenAI, NLP, Deep Learning, Image Processing, all of the significant advances in the last few years. I let myself get comfortable in a job where I could talk about data with people who were scared of it, but as I look at job openings for data scientists I truly don't feel qualified to even apply. I feel like my skills were relevant as of \~2019.  


What should I do in order to become relevant again?",datascience,https://www.reddit.com/r/datascience/comments/17o4er9/expecting_to_be_laidoff_in_q1_how_do_i_prepare_to/,54,104,0.93,"[Comment(id='k7w0stt'), Comment(id='k7w1v5l'), Comment(id='k7wxrru'), Comment(id='k7xl4d2'), Comment(id='k7xzum5'), Comment(id='k7wqkoy'), Comment(id='k7x7jkc'), Comment(id='k7x5mob'), Comment(id='k7xb89f'), Comment(id='k7yiaku'), Comment(id='k7yk9s2'), Comment(id='k80e71p'), Comment(id='k7wqj89'), Comment(id='k7xwzmb'), Comment(id='k7yepok'), Comment(id='k7yusbn'), Comment(id='k7zb28n'), Comment(id='k80lu92'), Comment(id='k81efqg'), Comment(id='k7w4dki'), Comment(id='k7zliam'), Comment(id='k7w4c8a'), Comment(id='k7w8pzj'), Comment(id='k80p8wa'), Comment(id='k80pbll'), Comment(id='k7yzums'), Comment(id='k7yqynz'), Comment(id='k80pj53'), Comment(id='k80q0h6'), Comment(id='k80q8pw'), Comment(id='k7xh67j'), Comment(id='k80qchi'), Comment(id='k80r8kb'), Comment(id='k80rif7'), Comment(id='k7zpv5a'), Comment(id='k7zl1dw'), Comment(id='k7zdmqd'), Comment(id='k7yun6n'), Comment(id='k80xdof'), Comment(id='k815vvg'), Comment(id='k80tczb'), Comment(id='k817npl'), Comment(id='k7xrofk'), Comment(id='k801rs4'), Comment(id='k80p4sw'), Comment(id='k80pnt4'), Comment(id='k7zh2wu'), Comment(id='k7xtg9s'), Comment(id='k80olv8'), Comment(id='k817cfm'), Comment(id='k80xo3m'), Comment(id='k7y0l2e'), Comment(id='k82k7t1')]"
17nwp4y,norfkens2,,2023-11-04 21:58:33+00:00,False,,1699139411.0,False,True,False,/r/datascience/comments/17nwp4y/when_applying_for_a_startup_what_questions_should/,When applying for a start-up - what questions should I ask?,"For an interview with a US startup - what should I be aware of? What kind of question should I be asking to form a solid opinion on the [edit] company?

e.g. I don't know much about funding at the different funding stages. What would I want to look at?",datascience,https://www.reddit.com/r/datascience/comments/17nwp4y/when_applying_for_a_startup_what_questions_should/,34,29,0.9,"[Comment(id='k7v371l'), Comment(id='k7v3jks'), Comment(id='k7ulael'), Comment(id='k7vg3os'), Comment(id='k7v3ire'), Comment(id='k7uj75z'), Comment(id='k7x0phi'), Comment(id='k7uygj8'), Comment(id='k7v3qh6'), Comment(id='k7vn538'), Comment(id='k7xuyl3'), Comment(id='k7xz2jp'), Comment(id='k7y0e4a'), Comment(id='k7ze5lf'), Comment(id='k7w4sxl'), Comment(id='k7w9dn6'), Comment(id='k7w9gy3'), Comment(id='k7uq3sn'), Comment(id='k7w3rzq'), Comment(id='k7w9htw'), Comment(id='k7um5sk'), Comment(id='k7w0myt'), Comment(id='k7w0vg9'), Comment(id='k7w3v51'), Comment(id='k7wbg2r'), Comment(id='k7y7cez'), Comment(id='k7uydwr'), Comment(id='k7w2jxl'), Comment(id='k7yaedj'), Comment(id='k7w0h2r'), Comment(id='k7wbheu'), Comment(id='k7yndnz'), Comment(id='k7wsnqx'), Comment(id='k7yyri4')]"
17o2n7u,andrew2018022,,2023-11-05 02:50:50+00:00,False,,1699153075.0,False,True,False,/r/datascience/comments/17o2n7u/going_through_a_somewhat_unfamiliar_interview/,Going through a somewhat unfamiliar interview process. The company is having me fill out a questionnaire in lieu of a first round interview?,"I get reached out to by a recruiter with a biotech research company for a remote statistician role, so I send my resume in. They say I pass the initial screening and am shortlisted for the position, and respond with a list of questions for me to fill out (some behavioral, some technical, etc) and say that it is a pressing need to be filled so if they like what I say, they’ll expedite the process and give an offer letter relatively quickly without other rounds of interviewing. I did some LinkedIn searching, it is a legitimate company with legit people, and the talent acquisition coordinator is a legit person and I’m fairly confident it’s a real thing here. Has anyone seen this before?

Some potential red flags:
1.) I have no clue where they got my email from to reach out

2.) I’ve never seen a situation where they’d send an offer without ever meeting me over the phone or face to face

Some potential green flags:

1.) The people and the job all exist in LinkedIn and other job boards

2.) they are willing to meet over the phone as well 
",datascience,https://www.reddit.com/r/datascience/comments/17o2n7u/going_through_a_somewhat_unfamiliar_interview/,16,12,0.83,"[Comment(id='k7vphp3'), Comment(id='k7vv2ty'), Comment(id='k7wdlmr'), Comment(id='k7x6sid'), Comment(id='k7ywqcx'), Comment(id='k7xoer9'), Comment(id='k7xvgxz'), Comment(id='k7vpqjy'), Comment(id='k7vvimr'), Comment(id='k7wq5oz'), Comment(id='k7wt0zc'), Comment(id='k7yz38o'), Comment(id='k7xl4j3'), Comment(id='k7xkz9n'), Comment(id='k7xpxoo'), Comment(id='k7y4siv')]"
17nlj1t,jeffrey_56,,2023-11-04 13:20:13+00:00,False,,False,False,True,False,/r/datascience/comments/17nlj1t/how_would_you_explain_complex_data/,How would you explain complex data transformations to others?,"This is my first data job and I’m the only data science person there, sorry if the question is kinda obvious.

How would you approach explaining complex transformations if you don’t have anyone in your company who can review your code?

Would it be smart to use graphical tools to illustrate each step and briefly explain methods used, such as right/inner joins? 

I’ve been working on this rather complex analysis in python with many steps and different queries. My project manager told me that he doesn’t feel confident with the results yet, due to the numerous (and sadly unavoidable) data transformation steps.",datascience,https://www.reddit.com/r/datascience/comments/17nlj1t/how_would_you_explain_complex_data/,37,25,0.86,"[Comment(id='k7saxol'), Comment(id='k7t0pff'), Comment(id='k7tjzy8'), Comment(id='k7sazo3'), Comment(id='k7sihh4'), Comment(id='k7sveg1'), Comment(id='k7txbk9'), Comment(id='k7sq7fu'), Comment(id='k7t18l0'), Comment(id='k7t1ppw'), Comment(id='k7tgm04'), Comment(id='k7ticlu'), Comment(id='k7u5ngf'), Comment(id='k7up5nv'), Comment(id='k7v6y1h'), Comment(id='k8106km'), Comment(id='k823f8f'), Comment(id='k7skexz'), Comment(id='k7t3sj4'), Comment(id='k7tkczq'), Comment(id='k7tn093'), Comment(id='k7tnni4'), Comment(id='k7zfpvs'), Comment(id='k7skkgn'), Comment(id='k7sd7zh'), Comment(id='k7teni6'), Comment(id='k7tdb1q'), Comment(id='k7tekit'), Comment(id='k825btk'), Comment(id='k7sjjv5'), Comment(id='k7vhb8s'), Comment(id='k8289ih'), Comment(id='k7t13iy'), Comment(id='k7td3xd'), Comment(id='k7w5chg'), Comment(id='k7tdqzu'), Comment(id='k7xbybe')]"
17ndvwn,OverratedDataScience,,2023-11-04 04:28:59+00:00,False,,False,False,True,False,/r/datascience/comments/17ndvwn/if_you_had_a_chance_to_rebuild_your_dsde_team_how/,"If you had a chance to rebuild your DS/DE team, how would you do it?","I've been asked to consolidate and rebuild a data team after a spree of layoffs and reorgs. People have to be realigned to newer projects and priorities. Some of the projects they were working on were scrapped entirely due to lack of funding. As the layoffs would still continue, I want this new  team to be ""not on the list"" as much as possible.

If you had the chance to build a team from scratch, what would you do?",datascience,https://www.reddit.com/r/datascience/comments/17ndvwn/if_you_had_a_chance_to_rebuild_your_dsde_team_how/,56,69,0.87,"[Comment(id='k7r9bhf'), Comment(id='k7rr67q'), Comment(id='k7r7897'), Comment(id='k7r4ukg'), Comment(id='k7rm8uk'), Comment(id='k7rlr0e'), Comment(id='k7r1zir'), Comment(id='k7s1up7'), Comment(id='k7s5s0l'), Comment(id='k7snuxl'), Comment(id='k7zdeuc'), Comment(id='k7r7lvp'), Comment(id='k7sm7o8'), Comment(id='k7s8s67'), Comment(id='k7ra5jv'), Comment(id='k81szgr'), Comment(id='k7ulxys'), Comment(id='k7ryfuy'), Comment(id='k7sejrj'), Comment(id='k7rzy9t'), Comment(id='k7st99h'), Comment(id='k7vet96'), Comment(id='k7rwjwe'), Comment(id='k7rnpon'), Comment(id='k7reyaj'), Comment(id='k7rb8u8'), Comment(id='k7st2wu'), Comment(id='k7st4sp'), Comment(id='k7u18vz'), Comment(id='k7vq3ky'), Comment(id='k7sqcd1'), Comment(id='k7stg3l'), Comment(id='k7rgb4w'), Comment(id='k7t3ynw'), Comment(id='k7t4eoq'), Comment(id='k7rbrc5'), Comment(id='k7tnmy6'), Comment(id='k7ul6il'), Comment(id='k7t3nqw'), Comment(id='k7tdgwd'), Comment(id='k7tdlqu'), Comment(id='k7vlxjd'), Comment(id='k7tlxhj'), Comment(id='k7tnmal'), Comment(id='k7tolz4'), Comment(id='k7top3e'), Comment(id='k7tm4io'), Comment(id='k7tnack'), Comment(id='k7zwoem'), Comment(id='k7trd9o'), Comment(id='k7to0g7'), Comment(id='k7tt0p5'), Comment(id='k7tsn7z'), Comment(id='k7ts00h'), Comment(id='k7ttutm'), Comment(id='k7tt3lq')]"
17ngwrb,WadeEffingWilson,,2023-11-04 08:06:43+00:00,False,,False,False,True,False,/r/datascience/comments/17ngwrb/how_can_someone_determine_the_geometry_of_their/,"How can someone determine the geometry of their clusters (ie, flat or convex) if the data has high dimensionality?","I'm doing a deep dive on cluster analysis for the given problem I'm working on. Right now, I'm using hierarchical clustering and the data that I have contains 24 features. Naturally, I used t-SNE to visualize the cluster formation and it looks solid but I can't shake the feeling that the actual geometry of the clusters is lost in the translation. 

The reason for wanting to do this is to assist in selecting additional clustering algorithms for evaluation. 

I haven't used PCA yet as I'm worried about the effects of data lost during the dimensionality redux and how it  might skew further analysis.

Does there exist a way to better understand the geometry of clusters? Was my intuition correct about t-SNE possibly altering (or obscuring) the cluster shapes?",datascience,https://www.reddit.com/r/datascience/comments/17ngwrb/how_can_someone_determine_the_geometry_of_their/,38,23,0.79,"[Comment(id='k7rkzx9'), Comment(id='k7s07yk'), Comment(id='k7rmi10'), Comment(id='k7roc0n'), Comment(id='k7rnkin'), Comment(id='k7s9wd0'), Comment(id='k7s31c8'), Comment(id='k7s9907'), Comment(id='k7sof9n'), Comment(id='k7sq23g'), Comment(id='k7ukour'), Comment(id='k7vpvks'), Comment(id='k7w6a9w'), Comment(id='k82ib1y'), Comment(id='k7rpky9'), Comment(id='k7ulyrv'), Comment(id='k81u38s'), Comment(id='k7rq121'), Comment(id='k7rqzo7'), Comment(id='k7rsaly'), Comment(id='k7rpp3n'), Comment(id='k81dk3z'), Comment(id='k7yo61r'), Comment(id='k7umj1h'), Comment(id='k7rw988'), Comment(id='k7rwb8t'), Comment(id='k7um7jg'), Comment(id='k7rq9re'), Comment(id='k7ulfqo'), Comment(id='k7uqtxb'), Comment(id='k7rrxju'), Comment(id='k80j3wk'), Comment(id='k7us8of'), Comment(id='k7tbsvy'), Comment(id='k7uygr8'), Comment(id='k7umnca'), Comment(id='k7v4phr'), Comment(id='k7vk08p')]"
17mzv7z,Mundane-Astronomer-7,,2023-11-03 17:08:13+00:00,False,,False,False,True,False,/r/datascience/comments/17mzv7z/should_i_use_poaching_attempts_to_ask_for_higher/,Should I use poaching attempts to ask for higher salary?,"I am a data scientist and I report directly to the CEO whom I have a candid rapport with. I have generated a lot of use case and working models in my short tenure. I have no intention to leave my company yet. Recently I received a couple of job offers without interviewing or seeking for jobs. I was thinking of mentioning these attempts during my performance review with the CEO and ask for a higher salary to ""make future attempts harder to accept"". Should I do it? Would it place my neck on the chopping board during hard times?",datascience,https://www.reddit.com/r/datascience/comments/17mzv7z/should_i_use_poaching_attempts_to_ask_for_higher/,59,94,0.88,"[Comment(id='k7oc5tf'), Comment(id='k7ocrb1'), Comment(id='k7ohqwk'), Comment(id='k7of9ah'), Comment(id='k7p9p7b'), Comment(id='k7prws5'), Comment(id='k7p361y'), Comment(id='k7oky92'), Comment(id='k7of5ow'), Comment(id='k7prro1'), Comment(id='k7ondac'), Comment(id='k7pvucm'), Comment(id='k7qhcz4'), Comment(id='k7pkkcv'), Comment(id='k7ocml2'), Comment(id='k7p2ydc'), Comment(id='k7qbzlj'), Comment(id='k7qepxj'), Comment(id='k7ox88y'), Comment(id='k7p5btb'), Comment(id='k7pfakh'), Comment(id='k7pjo3d'), Comment(id='k7pnjun'), Comment(id='k7prhoi'), Comment(id='k7pwjb2'), Comment(id='k7pzb1i'), Comment(id='k7q2j70'), Comment(id='k7q3wqd'), Comment(id='k7qodim'), Comment(id='k7qta2c'), Comment(id='k7rfqw2'), Comment(id='k7rlfn6'), Comment(id='k7rz9lq'), Comment(id='k7s59ef'), Comment(id='k7s5bze'), Comment(id='k7s5m1x'), Comment(id='k7sbjpn'), Comment(id='k7ui4qx'), Comment(id='k7z89p0'), Comment(id='k7zlgmk'), Comment(id='k7odeyi'), Comment(id='k7pf18k'), Comment(id='k7rcf5t'), Comment(id='k7pjwpz'), Comment(id='k7s2cjb'), Comment(id='k7pq65o'), Comment(id='k7r5ylx'), Comment(id='k7p8xy4'), Comment(id='k7pnpdr'), Comment(id='k7p4gww'), Comment(id='k7oem9f'), Comment(id='k7q7aol'), Comment(id='k7q8v8w'), Comment(id='k7pnozg'), Comment(id='k7pwaye'), Comment(id='k7ogf2o'), Comment(id='k7p6ph0'), Comment(id='k7p8fk5'), Comment(id='k7p8mcm'), Comment(id='k7rdh7n')]"
17mv3y3,LeaguePrototype,,2023-11-03 13:28:30+00:00,False,,False,False,False,False,/r/datascience/comments/17mv3y3/good_blog_post_that_clears_up_why_most_tech/,Good Blog Post That Clears Up Why Most Tech Workers Don't Have Any Work To Do,,datascience,https://emaggiori.com/employed-in-tech-for-years-but-almost-never-worked/,21,19,0.65,"[Comment(id='k7nppp9'), Comment(id='k7ocz6i'), Comment(id='k7ppdxc'), Comment(id='k7q1bc6'), Comment(id='k7p35e3'), Comment(id='k7qx4jc'), Comment(id='k7s987e'), Comment(id='k7pyyms'), Comment(id='k7uc3jb'), Comment(id='k7ppjb6'), Comment(id='k7p8gf6'), Comment(id='k7pyqix'), Comment(id='k7rkskq'), Comment(id='k7qpkcy'), Comment(id='k7uarl5'), Comment(id='k7ycugi'), Comment(id='k7prf6n'), Comment(id='k7rqx3b'), Comment(id='k7ucijr'), Comment(id='k7tgls9'), Comment(id='k7vl1o0')]"
17m8la5,ibsurvivors,,2023-11-02 17:18:55+00:00,False,,1698965355.0,True,True,False,/r/datascience/comments/17m8la5/i_applied_to_250_jobs_and_timed_how_long_each_one/,I applied to 250 jobs and timed how long each one took,"Applying to jobs online is like navigating a maze.

Amidst the special torture that is resume parsing software, the inability to reuse information across different application tracking systems (ATS), and the existence of a certain company that rhymes with every day of the week, it can get pretty frustrating.

I wanted to explore what factors make a job application more or less frustrating.

For example, what industries have the worst application processes? Do big companies ask for more information than small companies? What is it about websites like Workday that make them really hard to use?

To answer these questions, I applied to 250 jobs. One by one. Click by click. No Linkedin Easy Apply, no shortcuts – just straight from the careers page.

I timed how long it took me to go from “apply to job” to “submit application”.

https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&format=png&auto=webp&s=2123533d9d04aabcdd5988471274ee2ed3b98704

Make no mistake: I sacrificed my soul for this post. I created over 83 accounts and spent a total of 11 hours scrolling. I was originally going to do this for 500 companies, but wanted to chop my head off halfway.

I did this for a mix of companies – Fortune 500 to early stage startups, spread out across different industries from software to manufacturing. The *type* of role I applied to was kept constant: engineering / product focused.

https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&format=png&auto=webp&s=f27a52217e85bfade6eb30f0b696914eac7fc270

The outcome? An average of over two and a half minutes per application—162 seconds of your life you'll never get back. But as we dig deeper, you'll discover that these 162 seconds only scratch the surface of an often maddening process.

*Key Takeaways*

* **Average Application Time:** On average, it took a bit over two and a half minutes to apply to a job.
* **Company Size Impact:** If company size doubles, the application time increases by 5%. If company size increases by a factor of 10, then the app time increases by 20%.
* **Industry Influence:** Being a government company is the single largest determinant of a long application, followed closely by aerospace and consulting firms.
* **Longest Application:** The longest application time went to the United States Postal Service (10 minutes and 12 seconds).
* **Shortest Application:** On the other hand, It took me just 17 seconds to apply to Renaissance Technologies.
* **ATS Impact:** Older ATS like Workday and Taleo make job applications as much as 128% longer.

**You can view the spreadsheet with the full raw data** [here](https://mailchi.mp/1a15a90c4aeb/company_raw_data_leadmagnet)

Let's dive in.

# The Setup

There’s no real method to the 250 companies I pick. I’m just typing names into Google and trying to vary it up. Where does Trisha work? What was that billboard I saw? It's all up for grabs.

Here’s the distribution of the 250 companies by size:

https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&format=png&auto=webp&s=6feb536781f5f892ff57aaed0033e716be4c25c4

Some examples of companies in each range:

* 1-500 → Glean, Quizlet, Gumroad
* 500-5,000 → Notion, Dolby, Moloco
* 5,000-50,000 → Airbnb, Genentech, Logitech
* 50,000-100,000 → HP, American Express, Pfizer
* 100,000+ → Wells Fargo, Lockheed Martin, General Motors

And here’s a look at the different types of industries represented:

https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&format=png&auto=webp&s=2234a153954270bd3724029dac51cd270bfaf6ba

I used a mix of Linkedin and Crunchbase for categorization.

Before we get started, if you’d like you can read up on my [methodology](https://docs.google.com/document/d/1A0I9_WBN9zIqwezM6OXqmOl3LPqaq5704EPmGDTDiYI/edit) for applying to each job (aka assumptions I made, what data I chose to submit, and how much effort I put into each application).

***Note***: For more content like this, [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. In a couple of weeks, I'll be releasing my guide to writing a killer resume.*

# What makes a job application so frustrating

Generally speaking, the more frustrating a job application, the longer it takes to complete.

The three main factors that might influence how long a job application is (as measured in my data):

1. **Company size** → I would expect bigger companies to ask more questions.
2. **The ATS that is being used** → I would expect clunkier, older ATS to make job applications longer.
3. **Company industry** → I would expect more “traditional” industries to ask more questions.

We’re going to model the relationship between the above three factors and the amount of time it takes to complete a job application. To do this, we’re going to use a technique called linear regression.

Regression is about the way two measurements change together. It can help us make predictions.

For example, if I add 10 employees to a company, how many seconds will that add to the company’s job application process?

Since we have other factors like ATS and Industry, we will also account for those. For now, though, let’s just focus on each factor one by one.

# Company Size

Let’s first plot the data as is:

https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&format=png&auto=webp&s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199

Yes, I know, this isn’t the most useful graph. I’m going to spruce it up real quick, I promise.

The United States Postal Service has a job application that took over 10 minutes to complete. Navigating their portal felt like using Internet Explorer in 2003:

https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&format=png&auto=webp&s=b7b65699a39f2e4e3c3abadf38875280a673a0d7

Netflix’s application was just 20 seconds - their only mandatory requirements are your resume and basic info.

https://preview.redd.it/sl4fums4wyxb1.png?width=2310&format=png&auto=webp&s=4c0c87299460bd22163f34db1040a56ea3893059

Apple took me 71 seconds, still pretty fast for a company that has over 270,000 employees (PWC, which has a similar number of employees, took me almost six times as long).

Okay, back to the chart. There are a couple of problems with it.

First, the data is not linear. This is a problem if we want to use linear regression.

Second, the company size scale is hard to interpret because of the many data points clumped together near zero (representing all the smaller companies).

We can resolve both these issues with the following insight:

There is a big difference between going from 10 to 100 employees and, say, 10,000 to 10,100 employees. The first represents major changes in company structure: you might actually hire a proper HR team, a bunch of recruiters, and build out your candidate experience. The second, though, is pretty much just business as usual - think of a multinational opening up a satellite office or a regular month of hiring.

Since we want to account for this, our data is better suited to a log scale than a linear scale. I will also transform our Y-axis, the application time, to a log scale because it helps normalize the data.

If we plot both our variables on a log-log scale, we get the below chart:

https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&format=png&auto=webp&s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e

Better right? This is the same data as the last chart, but with different axes that fits the data better, we observe a linear relationship.

We have the usual suspects in the top right: Government organizations, professional services firms, and some of the tech industry dinosaurs.

The variance in application times across smaller companies, like startups, is interesting. For example, many of the startups with longer application times (e.g OpenAI, Posthog, Comma.AI) reference that they are looking for “exceptional” candidates on their careers page. (Note that OpenAI has changed its application since I last analyzed it - it’s now much faster, but when I went through they asked for a mini essay on why you’re exceptional).

One thing that I was expecting to see was competitors mirroring each other’s application times. This is most closely represented with the consulting firms like Deloitte, E&Y, KPMG, etc all clumped together. McKinsey and Bain, the two most prestigious consulting firms, have applications that take longer to complete.

This doesn’t necessarily seem to be the case with the FAANG companies.

We can also calculate the correlation coefficient for this graph. This is a statistical measure of the strength of a linear relationship between two variables. The closer to 1 the value, the stronger the relationship.

For the above data, we get a correlation coefficient of 0.58, which is a moderate to strong association.

Note that on its own, this doesn't tell us anything about causation. But it does start to point us in some type of direction.

It's not rocket science: big companies ask for more stuff. Sometimes they ask for the last 4 digits of your SSN.

https://preview.redd.it/c7g5717bwyxb1.png?width=1512&format=png&auto=webp&s=38c776e46d45d179a6627ba3470fd4f89ca04204

Sometimes they even ask if you’d be okay going through a polygraph:

https://preview.redd.it/1q52rzldwyxb1.png?width=400&format=png&auto=webp&s=b3b8921e055d38e04ee7395e9b982fa50c38f9df

An argument here is that if big companies didn’t have some sort of barriers in their application process, they’d get swarmed with applications.

Consider the fact that Google gets 3 million applications every year. Deloitte gets 2 million. Without some sort of initial friction in the application process, those numbers would be even higher. That friction almost serves as a reliable filter for interest.

If you’re an employer, you don’t really care about the people using a shotgun approach to apply. You want the candidates that have a real interest in the position. On the other hand, if you’re a candidate, the reality is such that the shotgun approach to apply is arguably the most efficient.

So we have this inherent tension between companies and candidates. Candidates want the most bang for their buck, companies don’t want thousands of irrelevant resumes.

And in the middle, we have the plethora of application tracking software that can often be quite old and clunky.

# ATS

Everytime I came face to face with a company that used Workday as their ATS, I died a bit inside. This is because Workday makes you:

1. create a new account every single time
2. redirects you away from the careers page

I defined a redirect as one when the job description is not listed on the same page as the first input box part of the application.

This isn’t a perfectly accurate measure, but it does allow us to differentiate between the modern ATS like Greenhouse and older ones like Workday.

With every ATS, I implicitly had some type of “how easy is this going to be” metric in my head.

We can try to represent this “how easy is this going to be” metric a bit more concretely using the matrix below.

https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&format=png&auto=webp&s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa

Ideally, you want the ATS to be in the bottom left corner. This creates an experience that is low friction and fast.

If we plot application time versus ATS, this is what we get:

https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&format=png&auto=webp&s=8df5c1118f9f0044e2154c8ae63816332ca42d67

The ATS that don’t make you create an account and don’t redirect you are tied to lower application times than the ones that do.

One possibility is that certain companies are more likely to use certain ATS. Big companies might use Workday for better compliance reporting. Same with the industry - maybe B2C software companies use the newer ATS on the market. These would be confounding variables, meaning that we may misinterpret a relationship between the ATS and the application time when in fact there isn’t one (and the real relationship is tied to the industry or size).

So to properly understand whether the ATS actually has an effect on application time, we need to control for our other variables. We’ll do this in the final section when we run a regression including all our variables.

One of the big frustrations surrounding different ATS is that when you upload your resume, you then need to retype out your experience in the boxes because the ATS resume parser did it incorrectly. For example, I went to UC Berkeley but sometimes got this:

https://preview.redd.it/ay21vccnwyxb1.png?width=928&format=png&auto=webp&s=9862b0860c49c87a76b02218f8e4118134acfb89

The only resume parser that didn't seem abysmal was the one from Smart Recruiters. TikTok's resume parser also isn't bad.

Another frustrating experience is tied to inconsistency between the company I'm applying to and the ATS.

https://preview.redd.it/9xzq21vpwyxb1.png?width=350&format=png&auto=webp&s=8432b293be4db0f58770760097df0117b53e667e

A company’s application process is often the first touchpoint you have with their brand. Startups competing for the best talent can't afford extra steps in their process. Apple and Facebook can.

Whilst the average time to complete a job application may only be 162 seconds, the fact that many ATS require steps like account creation and authentication can lead to application fatigue.

It’s not necessarily the explicit amount of time it takes, it’s the steps involved that drain you of energy and make you want to avoid applying to new jobs.

# Industry

Okay, so far we’ve looked at company size and the ATS as a loose indicator of what might make a job application frustrating. What about the company industry?

You would expect industries like banking or professional services to have longer application times, because getting those jobs revolves around having a bunch of credentials which they likely screen for (and ask you to submit) early on in the process.

On the other hand, internet startups I’d expect to be quick and fast. Let’s find out if this is true.

https://preview.redd.it/i7825ssvwyxb1.png?width=4012&format=png&auto=webp&s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b

Hyped up industries like AI and Crypto have shorter application times. As expected, banks and consulting firms care about your GPA and ask you to submit it.

A government company has to basically verify your identity before they can even receive your application, so the process is entirely different and reflected in the submission time.

For many technology companies, the application process is almost like an extension of the company’s brand itself. For example, Plaid (an API first Fintech company), has a neat option where you can actually apply to the job via API:

https://preview.redd.it/px5k5wwxwyxb1.png?width=720&format=png&auto=webp&s=d669e7e47e77e51d48a4867a2d06d27125617ed8

Roblox, a gaming company, allows people to submit job applications from within their [games](https://gamerant.com/roblox-company-interview-job-applicants-in-game/).

We also notice differences between legacy companies and their newer competitors. If we compare legacy banks versus neobanks (like Monzo, Mercury, etc), the legacy players averaged around 250 seconds per job application whereas the neobanks averaged less than 60 seconds.

If you can’t compete on prestige, you need to find other ways. One of those ways can be through asking for less information upfront.

# Putting it together

Now that we've analyzed each variable - the company size, ATS, and the industry - to understand the separate relationship of each to application time, we can use linear regression to understand the *combined* relationships.

This will allow us to determine what factors actually have an impact on the job application time versus which ones might just have had one when we looked at them in isolation.

After some number crunching in R, I get the following results (I’ve only added the statistically significant factors – the ones with the “strongest evidence”):

https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&format=png&auto=webp&s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9

Here’s how you can interpret some of the information above:

* When a job app is for a company that is within the Government industry, the submission time goes up by 366% (assuming the size and ATS are constant). For the aerospace industry, this is 249% (and so on).
* When a job app is for a company using the Workday ATS, the submission times goes up by 128% (assuming the size and industry are constant). For the Phenom ATS, this is 110% (and so on).
* Our only (statistically significant) metric which seems to make job applications faster is the Lever ATS (42% shorter).

Okay, now what about company size?

Well, first up: company size is indeed statistically significant. So there is an effect.

However, its effect is not as strong as most of our other variables. To be precise, here are some ways to interpret our company size coefficient:

* If company size doubles, the app size increases by 5%
* If company size increases by a factor of 10, then the app time increases by 20%

This is a smaller effect size compared to ATS or industry (a 20% increases in app time for a 10x large company is a qualitatively smaller effect size than e.g. a 100% increase in app time for Taleo ATS). So although company size is statistically significant, it is not as strong of a driver as ATS and industry of app time.

# Wrapping it up

Two and a half minutes might not be too long, but it can feel like an eternity when you’re forced to answer the same questions and upload the same documents. Over and over again.

Think about catching a flight. All you want is to get on the jet. Hawaii awaits.

But first: the security line. You have to take your shoes off. You get patted down and your bag gets searched. The gate numbers don’t make sense. And then at the end of it, your flight’s delayed. Congrats.

Applying to a job can feel similar. All you want to do is say aloha to the hiring manager, a real human being.

To even have the remote possibility of making that happen, you need to create an account and password, check your email, retype your entire resume, tell them the color of your skin, and explain why this company you’ve never heard of before is the greatest thing on Earth.

And for what? Most likely for the privilege of receiving an automated email about two weeks later rejecting you.

If we make it tiring and unappealing to look for new opportunities, then we prevent people from doing their best work.

But what would a world where applying took just a few seconds actually look like? Recruiters would get bombarded with resumes. It's possible to argue that job applications taking so long is a feature, not a bug. You get to filter for intent and narrow down your application pool.

Is it fair to shift the burden of screening unqualified candidates onto good candidates that now need to provide so much information? Shouldn’t that burden fall on the recruiter?

The truth is that applying to a job via the careers page is a bit of a rigged game. The odds are not in your favor.

Sometimes, though, all you need is to only be right once.

\*\*\*

If you made it all the way to the bottom, you're a star. This took a while to write. I hope you enjoyed it.

For more content like this, [subscribe](https://www.careerfair.io/subscribe) to my newsletter. It's my best content delivered to your inbox \~once a month.

Any questions and I'll be in the comments :)

\- Shikhar",datascience,https://www.reddit.com/r/datascience/comments/17m8la5/i_applied_to_250_jobs_and_timed_how_long_each_one/,115,771,0.97,"[Comment(id='k7j8ouw'), Comment(id='k7ja1g1'), Comment(id='k7jf0zd'), Comment(id='k7jey48'), Comment(id='k7jdepf'), Comment(id='k7jvtyl'), Comment(id='k7jbiol'), Comment(id='k7js2wc'), Comment(id='k7l7is9'), Comment(id='k7ji6ox'), Comment(id='k7kkj8i'), Comment(id='k7jmc01'), Comment(id='k7jyfuc'), Comment(id='k7le8u6'), Comment(id='k7jgr1c'), Comment(id='k7jju2a'), Comment(id='k7jvvkw'), Comment(id='k7jzxka'), Comment(id='k7khecf'), Comment(id='k7kpr8m'), Comment(id='k7lja1s'), Comment(id='k7lvsnz'), Comment(id='k7m465f'), Comment(id='k7mvuh3'), Comment(id='k7mwgp4'), Comment(id='k7ntlgu'), Comment(id='k7o5fei'), Comment(id='k7qnp0v'), Comment(id='k7vwfxs'), Comment(id='k7jelfz'), Comment(id='k7jxr4q'), Comment(id='k7k8tnd'), Comment(id='k7nk5rn'), Comment(id='k7kh51c'), Comment(id='k7kixqh'), Comment(id='k7ko9jq'), Comment(id='k7kqkj9'), Comment(id='k7kwppc'), Comment(id='k7l1lt1'), Comment(id='k7llhi7'), Comment(id='k7ln49d'), Comment(id='k7mv6un'), Comment(id='k7o3azu'), Comment(id='k7ob13l'), Comment(id='k7pdj7e'), Comment(id='k7pi4x4'), Comment(id='k7psbrq'), Comment(id='k7ptw2z'), Comment(id='k7pwj8z'), Comment(id='k7qiq48'), Comment(id='k7swe77'), Comment(id='k7t8su1'), Comment(id='k7vce3z'), Comment(id='k7yllyj'), Comment(id='k80ijpb'), Comment(id='k80l4kr'), Comment(id='k80rg5l'), Comment(id='k81t7t9'), Comment(id='k7jch2n'), Comment(id='k7l3ucw'), Comment(id='k7k19ny'), Comment(id='k7l4yxd'), Comment(id='k7jkbug'), Comment(id='k7mbqjm'), Comment(id='k7l12hc'), Comment(id='k7l9fig'), Comment(id='k7jgpma'), Comment(id='k7jgj6g'), Comment(id='k7l7z9x'), Comment(id='k7jkjla'), Comment(id='k7nyj8z'), Comment(id='k7mwssl'), Comment(id='k7kjdim'), Comment(id='k7nxiw2'), Comment(id='k7jgvtd'), Comment(id='k7jtfeb'), Comment(id='k7pxwok'), Comment(id='k7pwcvo'), Comment(id='k7jrzgq'), Comment(id='k7jgowz'), Comment(id='k7jyj6c'), Comment(id='k7kjcrq'), Comment(id='k7pwery'), Comment(id='k7kpwph'), Comment(id='k7l81c3'), Comment(id='k7l80pq'), Comment(id='k7l7zt4'), Comment(id='k7n640g'), Comment(id='k7pwdjr'), Comment(id='k7pwif3'), Comment(id='k7pw93t'), Comment(id='k7tb8an'), Comment(id='k80nu79'), Comment(id='k7kynf7'), Comment(id='k7jo30o'), Comment(id='k7knlsw'), Comment(id='k7jsrah'), Comment(id='k7jkoes'), Comment(id='k7kkf52'), Comment(id='k7jk85i'), Comment(id='k7l8aj0'), Comment(id='k80ohop'), Comment(id='k7joeye'), Comment(id='k7ju70d'), Comment(id='k7jncj0'), Comment(id='k7jrx8a'), Comment(id='k7k4e8x'), Comment(id='k7jv59a'), Comment(id='k7joy94')]"
17mps8p,LatterConcentrate6,,2023-11-03 07:43:59+00:00,False,,False,False,True,False,/r/datascience/comments/17mps8p/what_makes_an_average_data_science_manager_an/,What makes an average Data Science Manager an Excellent DSM?,... and what makes a bad DSM,datascience,https://www.reddit.com/r/datascience/comments/17mps8p/what_makes_an_average_data_science_manager_an/,17,27,0.81,"[Comment(id='k7ngd6c'), Comment(id='k7mw7po'), Comment(id='k7nhyjd'), Comment(id='k7nwewt'), Comment(id='k7mmz3b'), Comment(id='k7orsnl'), Comment(id='k7nrws1'), Comment(id='k7mtjo6'), Comment(id='k7mrv4e'), Comment(id='k7o5ob2'), Comment(id='k7mwe6z'), Comment(id='k7o7dfn'), Comment(id='k7oto8i'), Comment(id='k7za7rj'), Comment(id='k7zlku2'), Comment(id='k7oxrzt'), Comment(id='k7pociq')]"
17m7q3j,AdFew4357,,2023-11-02 16:41:19+00:00,False,,False,False,True,False,/r/datascience/comments/17m7q3j/statisticians_in_ds_how_did_you_connect_the_dots/,"Statisticians in DS, how did you “connect the dots” between business skills and theory?","I’m an MS statistician whose gonna be starting a data scientist position soon. I think one of the things I’m the most confident about is my statistical analysis and overarching background I have on methods. I am fairly comfortable I can handle up to 95% of weird data sets, and know how to properly assess assumptions, critically look at data, and choose the right model or tool for the job. I’m even more confident in my ability to present and explain interpretations of results, because that’s what is also emphasized in our applied coursework. With a good background in stats, I’m fairly confident in the actual “doing” of data analysis and wrangling and what not.

But I think the part I’m not really sure about or worried I’ll be bad at is “connecting the dots” between my stats stuff and the business problem. A lot of what I’m worried about is that I can do all of this stuff to understand the data, but if I don’t even understand the context well enough, then my analysis has no path to follow. This ambiguity is something I know I’m going to struggle with, and I’m not sure how I’m going to improve in this area besides talking to more of the stakeholders.

But for any statisticians here who turned to DS, what kind of things did you do to improve this aspect? How did you “connect” the business side to the hard core stats side?",datascience,https://www.reddit.com/r/datascience/comments/17m7q3j/statisticians_in_ds_how_did_you_connect_the_dots/,121,72,0.94,"[Comment(id='k7j4ipc'), Comment(id='k7j2f0o'), Comment(id='k7jc1um'), Comment(id='k7j5xl1'), Comment(id='k7jdwwm'), Comment(id='k7jan5i'), Comment(id='k7je0j4'), Comment(id='k7lfxsb'), Comment(id='k7ksb7j'), Comment(id='k7jn8ac'), Comment(id='k7ll266'), Comment(id='k7m1u7k'), Comment(id='k7m8r7a'), Comment(id='k7medx4'), Comment(id='k7onfpf'), Comment(id='k7qva3w'), Comment(id='k7lnlbc'), Comment(id='k7k9nbm'), Comment(id='k7l40hj'), Comment(id='k7lygmm'), Comment(id='k7m2vxz'), Comment(id='k7mughd'), Comment(id='k7qnrcv'), Comment(id='k7zlx50'), Comment(id='k7kewm7'), Comment(id='k7lnuir'), Comment(id='k7l6ff4'), Comment(id='k7j3o4h'), Comment(id='k7jt809'), Comment(id='k7jpdjm'), Comment(id='k7l3pql'), Comment(id='k7l65xk'), Comment(id='k7oxttg'), Comment(id='k7me6ct'), Comment(id='k7meuil'), Comment(id='k7ne4dc'), Comment(id='k7l6b08'), Comment(id='k7lorch'), Comment(id='k7l73zd'), Comment(id='k7jp0bs'), Comment(id='k7kmles'), Comment(id='k7k3kc7'), Comment(id='k7m6ige'), Comment(id='k7l8edr'), Comment(id='k7m6ows'), Comment(id='k7p6ynh'), Comment(id='k7rfsbi'), Comment(id='k7mgzt2'), Comment(id='k7mvlha'), Comment(id='k7lqeg9'), Comment(id='k7l9z3c'), Comment(id='k7jqf5w'), Comment(id='k7kqpzw'), Comment(id='k7k5oem'), Comment(id='k7mur9y'), Comment(id='k7musvg'), Comment(id='k7l9u3m'), Comment(id='k7mdgiy'), Comment(id='k7msyq3'), Comment(id='k7mdogb'), Comment(id='k7p8wxv'), Comment(id='k7rg5sk'), Comment(id='k7mha07'), Comment(id='k7no9hv'), Comment(id='k7lqk20'), Comment(id='k7lb5ji'), Comment(id='k7lj1m5'), Comment(id='k7jts3x'), Comment(id='k7n6n30'), Comment(id='k7u2hd0'), Comment(id='k7nwh90'), Comment(id='k7laz48'), Comment(id='k7llegq'), Comment(id='k7qhd8k'), Comment(id='k7n2bhy'), Comment(id='k7qznn7'), Comment(id='k7rgakh'), Comment(id='k7nyrql'), Comment(id='k7lqrl8'), Comment(id='k7lbetc'), Comment(id='k7lklyb'), Comment(id='k7jvzav'), Comment(id='k7nkxst'), Comment(id='k7oxm5h'), Comment(id='k7lbcjg'), Comment(id='k7lbxm6'), Comment(id='k7qkh8g'), Comment(id='k7ngc3b'), Comment(id='k7o228i'), Comment(id='k7lqxwu'), Comment(id='k7lc2ao'), Comment(id='k7l2xw6'), Comment(id='k7k5wng'), Comment(id='k7q55bt'), Comment(id='k7ld1o2'), Comment(id='k7ld342'), Comment(id='k7t3wna'), Comment(id='k7npauf'), Comment(id='k7lcbe3'), Comment(id='k7l3ifp'), Comment(id='k7kr8uv'), Comment(id='k7ldpbf'), Comment(id='k7nvqqy'), Comment(id='k7nvw6s'), Comment(id='k7lcq4f'), Comment(id='k7lhli5'), Comment(id='k7obr8c'), Comment(id='k7obzc4'), Comment(id='k7li9qf'), Comment(id='k7oxerb'), Comment(id='k7oxa1n'), <MoreComments count=0, children=[]>]"
17mt5b2,Excellent_Cost170,,2023-11-03 11:43:17+00:00,False,,False,False,True,False,/r/datascience/comments/17mt5b2/smart_goal_setting_does_it_work_for_data_science/,SMART goal setting does it work for data science,We have been asked to prepare SMART goals for next year's evaluations .,datascience,https://www.reddit.com/r/datascience/comments/17mt5b2/smart_goal_setting_does_it_work_for_data_science/,8,0,0.5,"[Comment(id='k7n6j3a'), Comment(id='k7nq3kk'), Comment(id='k7n5wct'), Comment(id='k7nd6xp'), Comment(id='k7ofjat'), Comment(id='k7mzk8k'), Comment(id='k7qyxji'), Comment(id='k7n8uat')]"
17m2b07,takenorinvalid,,2023-11-02 12:24:57+00:00,False,,False,False,True,False,/r/datascience/comments/17m2b07/how_do_you_avoid_phacking/,How do you avoid p-hacking?,"We've set up a Pre-Post Test model using the [Causal Impact](https://google.github.io/CausalImpact/CausalImpact.html) package in R, which basically works like this:

* The user feeds it a target and covariates
* The model uses the covariates to predict the target
* It uses the residuals in the post-test period to measure the effect of the change

Great -- except that I'm coming to a challenge I have again and again with statistical models, which is that tiny changes to the model completely change the results.

We are training the models on earlier data and checking the RMSE to ensure goodness of fit before using it on the actual test data, but I can use two models with near-identical RMSEs and have one test be positive and the other be negative.

The conventional wisdom I've always been told was not to peek at your data and not to tweak it once you've run the test, but that feels incorrect to me. My instinct is that, if you tweak your model slightly and get a different result, it's a good indicator that your results are not reproducible.

So I'm curious how other people handle this. I've been considering setting up the model to identify 5 settings with low RMSEs, run them all, and check for consistency of results, but that might be a bit drastic.

How do you other people handle this?",datascience,https://www.reddit.com/r/datascience/comments/17m2b07/how_do_you_avoid_phacking/,63,129,0.95,"[Comment(id='k7i02e0'), Comment(id='k7i26ek'), Comment(id='k7ijqka'), Comment(id='k7i2w1t'), Comment(id='k7jsk5q'), Comment(id='k7jhhqs'), Comment(id='k7i61dv'), Comment(id='k7jpjfp'), Comment(id='k7i1qh6'), Comment(id='k7phs46'), Comment(id='k7i8ynw'), Comment(id='k7i6cqk'), Comment(id='k7ihz1u'), Comment(id='k7iinnm'), Comment(id='k7jnljt'), Comment(id='k7kh8dc'), Comment(id='k7ku20h'), Comment(id='k7lqlqm'), Comment(id='k7m1gxd'), Comment(id='k7pjb3o'), Comment(id='k7vlez3'), Comment(id='k7iby3k'), Comment(id='k7ivov2'), Comment(id='k7i86n6'), Comment(id='k7jxr44'), Comment(id='k7jv2qk'), Comment(id='k7i56d3'), Comment(id='k7iddss'), Comment(id='k7ihpia'), Comment(id='k7ijrxy'), Comment(id='k7ieow5'), Comment(id='k7iywx7'), Comment(id='k7jnchy'), Comment(id='k7iebtv'), Comment(id='k7j9dr7'), Comment(id='k7ji2xd'), Comment(id='k7lpqsu'), Comment(id='k7ibxa0'), Comment(id='k7j1rpz'), Comment(id='k7i8iuk'), Comment(id='k7zkv32'), Comment(id='k7zkjys'), Comment(id='k7jo19l'), Comment(id='k7koswh'), Comment(id='k7ife8s'), Comment(id='k7mr7aa'), Comment(id='k7iswpp'), Comment(id='k7jbd9m'), Comment(id='k7kokbh'), Comment(id='k7zvp08'), Comment(id='k7ig8jo'), Comment(id='k7iva1e'), Comment(id='k7iyeo8'), Comment(id='k7jgwsw'), Comment(id='k7zzwov'), Comment(id='k7ih1rx'), Comment(id='k7iw8y0'), Comment(id='k7jrwgm'), Comment(id='k7ihbc9'), Comment(id='k7l1iiq'), Comment(id='k7jtdap'), Comment(id='k7kmihi'), Comment(id='k7l5j6s'), Comment(id='k7l7li1')]"
17m4paw,LionsBSanders20,,2023-11-02 14:27:14+00:00,False,,False,False,True,False,/r/datascience/comments/17m4paw/ds_team_leaders_when_requests_are_slow_or_little/,"DS Team Leaders, When requests are slow or little volume, what are you having your team work on in the meantime?","Title. We've given way, for now, to the Data Engineers and Architects to build out pipelines and such and until those are complete, we haven't had a ton of requests coming in.

When things are ""slow"" for your teams, what type of work are you having the junior scientists working on to maintain some level of productivity or skillset building?",datascience,https://www.reddit.com/r/datascience/comments/17m4paw/ds_team_leaders_when_requests_are_slow_or_little/,39,32,0.91,"[Comment(id='k7iglyd'), Comment(id='k7iludw'), Comment(id='k7imjt8'), Comment(id='k7ikf1c'), Comment(id='k7iliet'), Comment(id='k7ip5bq'), Comment(id='k7isa6h'), Comment(id='k7isqnx'), Comment(id='k7iwn94'), Comment(id='k7je0mh'), Comment(id='k7iioz5'), Comment(id='k7jw5c4'), Comment(id='k7muh4x'), Comment(id='k7pg18w'), Comment(id='k7qi1ze'), Comment(id='k7r1nvx'), Comment(id='k7un3x6'), Comment(id='k7im6p1'), Comment(id='k7k04wk'), Comment(id='k7k19fg'), Comment(id='k7imuwu'), Comment(id='k7jlu85'), Comment(id='k7iqh68'), Comment(id='k7k22ay'), Comment(id='k7k2ph9'), Comment(id='k7k2w32'), Comment(id='k7jja05'), Comment(id='k7k36ez'), Comment(id='k7k3g2k'), Comment(id='k7jm2da'), Comment(id='k7k3x17'), Comment(id='k7k3q7p'), Comment(id='k7jzn0l'), Comment(id='k7k0cvp'), Comment(id='k7k1c82'), Comment(id='k7k2f6q'), Comment(id='k7li1p6'), Comment(id='k7kaefz'), Comment(id='k7k0x5p')]"
17m6b4n,Tender_Figs,,2023-11-02 15:39:50+00:00,False,,False,False,True,False,/r/datascience/comments/17m6b4n/is_analytics_engineering_and_business/,Is analytics engineering and business intelligence experience beneficial for seeking DS roles?,"Or is it essentially seen as marginal? I suspect the larger companies would view it as marginal, and startups up to medium size (with small data teams) would be attracted by this experience. Is that a fair assumption?",datascience,https://www.reddit.com/r/datascience/comments/17m6b4n/is_analytics_engineering_and_business/,17,14,0.77,"[Comment(id='k7iripb'), Comment(id='k7j43p1'), Comment(id='k7kk1mt'), Comment(id='k7kb6lr'), Comment(id='k7smm1y'), Comment(id='k7ixofb'), Comment(id='k7l2utv'), Comment(id='k7muhof'), Comment(id='k7itbv7'), Comment(id='k7iv6pm'), Comment(id='k7ivuk5'), Comment(id='k7j1slv'), Comment(id='k7jf8zr'), Comment(id='k7j70tt'), Comment(id='k7jhav8'), Comment(id='k7jgppu'), Comment(id='k7jh0dh')]"
17meviz,house_lite,,2023-11-02 21:52:30+00:00,False,,False,False,True,False,/r/datascience/comments/17meviz/can_someone_help_explain_the_data_structure_of/,Can someone help explain the data structure of the m4 forecasting datasets?,,datascience,https://www.reddit.com/r/datascience/comments/17meviz/can_someone_help_explain_the_data_structure_of/,5,3,0.8,"[Comment(id='k7kfw6k'), Comment(id='k7licvh'), Comment(id='k7lqpez'), Comment(id='k7khs23'), Comment(id='k7kjtdv')]"
17lsxof,takemetojupyter,,2023-11-02 02:07:46+00:00,False,,False,False,True,False,/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,"qq - if I receive ""thanks but no thanks"" email months after application...","Does that mean my resume made it farther along in the decision process? That maybe I wasn't immediately auto-filtered out? Or does it mean nothing? 

I'm trying to understand how my resume faired against the algorithms... If anyone has tips on that or a library of the latest ""greenlight"" resume algorithm parser buzzwords, please, do share. 

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,11,26,0.81,"[Comment(id='k7gie1e'), Comment(id='k7gm2x2'), Comment(id='k7gejgs'), Comment(id='k7gh4ju'), Comment(id='k7gr70c'), Comment(id='k7hnv2j'), Comment(id='k7muizy'), Comment(id='k7gzp2w'), Comment(id='k7i8jnm'), Comment(id='k7hu809'), Comment(id='k7j3z0k')]"
17m4mmu,TheReal_KindStranger,,2023-11-02 14:23:44+00:00,False,,False,False,True,False,/r/datascience/comments/17m4mmu/running_glmm_with_binary_treatment_variable_and/,running glmm with binary treatment variable and time since treatment,"Hi , 

I have a dataset with a dependent variable and two explanatory variables. A binary treatment variable and quantitative time since treatment for the cases that received treatment and NA for none-treated cases.  

&#x200B;

Is it possible to include both in a single glmm? 

I'm using glmmtmb in R and the function can only handle NAs by omitting the cases with Na and it would mean here omitting all the non-treated cases from the analysis. 

I'd appreciate your thoughts and ideas.

 

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17m4mmu/running_glmm_with_binary_treatment_variable_and/,4,2,0.75,"[Comment(id='k7iie0f'), Comment(id='k7l52cr'), Comment(id='k7ir2m7'), Comment(id='k7ms87d')]"
17ltjt8,limedove,,2023-11-02 02:38:04+00:00,False,,False,False,True,False,/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,[SERIOUS] What do you not like about your boss or big bosses and how does that affect progress of your organization?,Curious about the DS arena,datascience,https://www.reddit.com/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,15,16,0.84,"[Comment(id='k7gifue'), Comment(id='k7h2qvc'), Comment(id='k7gqyvc'), Comment(id='k7i3tvg'), Comment(id='k7gpq7a'), Comment(id='k7gtqaq'), Comment(id='k7i39lm'), Comment(id='k7iis5o'), Comment(id='k82cya6'), Comment(id='k7l2yw7'), Comment(id='k7q8v5i'), Comment(id='k7gpyx5'), Comment(id='k7q89iy'), Comment(id='k7lj40j'), Comment(id='k7mwgdu')]"
17m17c7,cpluscplus,,2023-11-02 11:18:06+00:00,False,,False,False,True,False,/r/datascience/comments/17m17c7/can_somebody_share_their_experience_of_attending/,Can somebody share their experience of attending ICML conference?,"I'm planning to attend ICML 2024 in person. Can somebody share their experience of attending the conference? Is it worth attending if you don't have any paper to present? If yes, how to get the most out of it?",datascience,https://www.reddit.com/r/datascience/comments/17m17c7/can_somebody_share_their_experience_of_attending/,3,3,0.8,"[Comment(id='k7i9d76'), Comment(id='k7lrclr'), Comment(id='k7i9iw7')]"
17lrtkx,Actual_Plant_862,,2023-11-02 01:14:27+00:00,False,,False,False,True,False,/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,Help me understand if my approach is correct please!,"Hi all, I'm an junior data analyst. I'm currently learning all sorts of stats and techniques on my way to improving my skills.

Currently I'm investigating a dataset full of invoices and there are a few questions I'm trying to answer. 

For example how many orders are on time/late based on xyz checks which I've coded.
I've also found cost discrepancies between what was actually done and what was invoiced.

One task I've been assigned is to see what teams are ordering what services and I wanted to approach it with potentially a more nuanced approach.
I have recently been learning the theory and application of Association rules to do the following : 
 
I would like to know if I could split all the orders by teams and then code an association rule algorithm which would mean my results are specific to teams. 
E.g X team order y item and with y item z was also often ordered.


Outside of that is there any other kind of ""fun"" statistically backed learning I could do from invoices? 

Thanks for any advice!",datascience,https://www.reddit.com/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,5,7,0.74,"[Comment(id='k7gano0'), Comment(id='k7ga0kh'), Comment(id='k7gl0dq'), Comment(id='k7gl2jz'), Comment(id='k7j8jqt')]"
17le04v,DJAlaskaAndrew,Data Scientist MS|MBA ,2023-11-01 14:58:04+00:00,False,,False,False,True,False,/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,How to be Competitive for a Product Data Scientist Role?,"I'm a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I'm targeting appeared geared towards product data science. I'd like to hear from data scientists currently working in product roles:

\- How to stand out in terms of past experience, projects, resume, interview, etc?

\- What does a ""product"" data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?

\- What type of specific skills are you looking for outside of the core data science skillset?

I was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a ""product"", but I'm not sure if it's directly applicable, especially with regards to customer behavior.",datascience,https://www.reddit.com/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,24,45,0.87,"[Comment(id='k7dw0rv'), Comment(id='k7ev5sj'), Comment(id='k7gm7nr'), Comment(id='k7dx850'), Comment(id='k7dmrx9'), Comment(id='k7l44nu'), Comment(id='k7muk6m'), Comment(id='k7e6k6l'), Comment(id='k7hdjsd'), Comment(id='k7f5a75'), Comment(id='k7f5sfj'), Comment(id='k7f0ztz'), Comment(id='k7evfxh'), Comment(id='k7dnthe'), Comment(id='k7e9axv'), Comment(id='k7kq61n'), Comment(id='k7g7d1d'), Comment(id='k7f69lj'), Comment(id='k7f267i'), Comment(id='k7f0gyq'), Comment(id='k7mi08y'), Comment(id='k7flunr'), Comment(id='k7f25sm'), Comment(id='k7fu0ci'), Comment(id='k7g2k3s')]"
17kvjmp,nth_citizen,,2023-10-31 21:12:47+00:00,False,,False,False,True,False,/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,"Why some data science interviews suck, as an interviewer...","I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I'd give my experience from the other side of the desk which may go some way to showing why it can be so bad.

I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.

Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.

The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some 'calibration' briefing before the interviews; it was too late to speak to HR.

Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no 'calibration' brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.

I was dropped straight into a 'technical' interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.

There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be 'The candidate readily accepts new ideas'. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.

After a few of these there was the 'technical' section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.

Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.

Finally there was a group activity and we were supposed to observe the 'teamwork' but the team just split the tasks and got on with them individually so there was hardly anything to observe.

After this the HR bod asked us to complete all the assessments and submit them. Then we'd have a 'wash up'. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.

I also asked about the inappropriate technical questions and they said they didn't get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).

So, as you can see, HR ruin everything they touch and hiring is a HR process so it's terrible. Sorry if you had to go through this.",datascience,https://www.reddit.com/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,57,221,0.98,"[Comment(id='k7ah9us'), Comment(id='k7afkpn'), Comment(id='k7apu15'), Comment(id='k7agusa'), Comment(id='k7akpff'), Comment(id='k7aaang'), Comment(id='k7dn4f4'), Comment(id='k7annix'), Comment(id='k7c85vq'), Comment(id='k7d4vye'), Comment(id='k7d7msr'), Comment(id='k7bgpnw'), Comment(id='k7bj8x8'), Comment(id='k7bcavx'), Comment(id='k7cpgkg'), Comment(id='k7crelo'), Comment(id='k7lnwn9'), Comment(id='k7mukyd'), Comment(id='k7na8zb'), Comment(id='k7avauo'), Comment(id='k7b6fdc'), Comment(id='k7c1wwa'), Comment(id='k7bjbkx'), Comment(id='k7am65t'), Comment(id='k7anhof'), Comment(id='k7d5xfs'), Comment(id='k7azjm2'), Comment(id='k7c2yo6'), Comment(id='k7c3bo3'), Comment(id='k7c43cw'), Comment(id='k7co6gx'), Comment(id='k7b9joo'), Comment(id='k7b8jgg'), Comment(id='k7djw8b'), Comment(id='k7bkowz'), Comment(id='k7bdgly'), Comment(id='k7cq0z9'), Comment(id='k7g1x6r'), Comment(id='k7d4qkh'), Comment(id='k7bb9ef'), Comment(id='k7dnrn0'), Comment(id='k7c32ot'), Comment(id='k7cmiao'), Comment(id='k7bh92e'), Comment(id='k7cvek3'), Comment(id='k7h4jv6'), Comment(id='k7da6qn'), Comment(id='k7dfo31'), Comment(id='k7bmo7h'), Comment(id='k7d5s2w'), Comment(id='k7bkszh'), Comment(id='k7etpun'), Comment(id='k7bof37'), Comment(id='k7d6sgf'), Comment(id='k7d7qh3'), Comment(id='k7d9shg')]"
17kxd5s,CatOfGrey,,2023-10-31 22:33:54+00:00,False,,False,False,True,False,/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,Data folks of Reddit: How do you choose a random seed?,"From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. 

I always assumed that it was 'bad form' to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use ""42"" or ""365"" or ""1234"" all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? ",datascience,https://www.reddit.com/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,122,102,0.92,"[Comment(id='k7am1e8'), Comment(id='k7ay8wn'), Comment(id='k7al6fb'), Comment(id='k7amqcn'), Comment(id='k7al47v'), Comment(id='k7am6q9'), Comment(id='k7ap1t6'), Comment(id='k7al2qd'), Comment(id='k7aw76x'), Comment(id='k7b1x9y'), Comment(id='k7bawjl'), Comment(id='k7bfuk3'), Comment(id='k7c3wbe'), Comment(id='k7elmey'), Comment(id='k7aty7j'), Comment(id='k7al9zj'), Comment(id='k7aynti'), Comment(id='k7b3hux'), Comment(id='k7b7qwp'), Comment(id='k7bm48g'), Comment(id='k7do9ti'), Comment(id='k7efgs3'), Comment(id='k7egaof'), Comment(id='k7fopm2'), Comment(id='k7ar7e8'), Comment(id='k7b6xfb'), Comment(id='k7au5yp'), Comment(id='k7b7kdg'), Comment(id='k7c93j6'), Comment(id='k7b2s9b'), Comment(id='k7b3ucs'), Comment(id='k7b3w0b'), Comment(id='k7b43r1'), Comment(id='k7b455e'), Comment(id='k7b76nv'), Comment(id='k7bbetk'), Comment(id='k7bm21v'), Comment(id='k7bnura'), Comment(id='k7bnv75'), Comment(id='k7bojm8'), Comment(id='k7bsc6q'), Comment(id='k7bt7fa'), Comment(id='k7bx21b'), Comment(id='k7c1lc3'), Comment(id='k7c2b2i'), Comment(id='k7c30ue'), Comment(id='k7c3uvc'), Comment(id='k7c86lp'), Comment(id='k7cubna'), Comment(id='k7d3u1m'), Comment(id='k7d5ipm'), Comment(id='k7dbneb'), Comment(id='k7dgpkm'), Comment(id='k7djcc2'), Comment(id='k7dm9m9'), Comment(id='k7dmqik'), Comment(id='k7ds77f'), Comment(id='k7dyee9'), Comment(id='k7e5n1v'), Comment(id='k7emafd'), Comment(id='k7ew8ww'), Comment(id='k7ewe5h'), Comment(id='k7f2rw1'), Comment(id='k7f3nk8'), Comment(id='k7fntup'), Comment(id='k7fthax'), Comment(id='k7g97f4'), Comment(id='k7g9y9m'), Comment(id='k7ganw1'), Comment(id='k7gwu35'), Comment(id='k7kkkuw'), Comment(id='k7mullf'), Comment(id='k7so69w'), Comment(id='k7uj1ma'), Comment(id='k7uk300'), Comment(id='k7avjm6'), Comment(id='k7drar1'), Comment(id='k7cxe92'), Comment(id='k7azcya'), Comment(id='k7dd0ci'), Comment(id='k7c9a07'), Comment(id='k7b1oeo'), Comment(id='k7dhxeu'), Comment(id='k7d5fed'), Comment(id='k7cy4yc'), Comment(id='k7lzn3q'), Comment(id='k7b7cxb'), Comment(id='k7b18cj'), Comment(id='k7dej7t'), Comment(id='k7c5wva'), Comment(id='k7asjio'), Comment(id='k7b6dek'), Comment(id='k7e0ban'), Comment(id='k7dxayz'), Comment(id='k7d2bgx'), Comment(id='k7f0f1a'), Comment(id='k7avmfx'), Comment(id='k7b4kqx'), Comment(id='k7co4cp'), Comment(id='k7f0nou'), Comment(id='k7ayoys'), Comment(id='k7d13y0'), Comment(id='k7avsr1'), Comment(id='k7bla7d'), Comment(id='k7cfxl4'), Comment(id='k7jag3j'), Comment(id='k7dvrhf'), Comment(id='k7dadgm'), Comment(id='k7dww0k'), Comment(id='k7hacba'), Comment(id='k7b2vdc'), Comment(id='k7b77av'), Comment(id='k7dt7um'), Comment(id='k7ewj8c'), Comment(id='k7becii'), Comment(id='k7d90lt'), Comment(id='k7bf1v0'), Comment(id='k7imhrp'), Comment(id='k7bw8rf'), Comment(id='k7d9e6x'), Comment(id='k7bftl2'), Comment(id='k7fgy44')]"
17l11nx,Dependent_Mushroom98,,2023-11-01 01:32:37+00:00,False,,False,False,True,False,/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,Why should I learn LangChain? It’s like learning a whole new tool set on top of LLM/Transformer models…,If I don’t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..,datascience,https://www.reddit.com/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,26,29,0.81,"[Comment(id='k7bx827'), Comment(id='k7b8vi8'), Comment(id='k7bc1p1'), Comment(id='k7bqurc'), Comment(id='k7bn97g'), Comment(id='k7bytrk'), Comment(id='k7csakm'), Comment(id='k7dro1h'), Comment(id='k7ba8wb'), Comment(id='k7dtqor'), Comment(id='k7bsydb'), Comment(id='k7zirvx'), Comment(id='k7c6tce'), Comment(id='k7cy7je'), Comment(id='k7g8sjo'), Comment(id='k7dusnv'), Comment(id='k7g939e'), Comment(id='k7dwloa'), Comment(id='k7g9gax'), Comment(id='k7e2jw1'), Comment(id='k7elaaf'), Comment(id='k7f750k'), Comment(id='k7glzut'), Comment(id='k7elfe4'), Comment(id='k7elki0'), Comment(id='k7elouj')]"
17lffnz,SnooPineapples7791,,2023-11-01 16:02:18+00:00,False,,False,False,True,False,/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,Working on improving the process of converting documents into Embeddings (for vectorStores) for LLM applications but i need some ideas and complaints from you!,"I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.

I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.

But it seens my initial ideas of contribution were already done...

First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much better than they have already lol

I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.

Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them",datascience,https://www.reddit.com/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,1,2,0.67,[Comment(id='k7wpmnj')]
17koo01,_hairyberry_,,2023-10-31 16:11:08+00:00,False,,False,False,True,False,/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,Anyone else find time series work a little dull?,"Got assigned some TS projects at work and now have kind of carved out this niche at my company. It’s great career-wise but I feel like I’d enjoy working with other ML approaches more. 

Time series at the scale I’m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. 

It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. 

Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?",datascience,https://www.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,64,101,0.94,"[Comment(id='k78zvwd'), Comment(id='k791dfq'), Comment(id='k799iua'), Comment(id='k79nehl'), Comment(id='k790vfj'), Comment(id='k79pb2e'), Comment(id='k79i6yr'), Comment(id='k7anub0'), Comment(id='k7oxd3u'), Comment(id='k79zhdu'), Comment(id='k7aa8xo'), Comment(id='k7ab2zq'), Comment(id='k7auiqq'), Comment(id='k7a2s2z'), Comment(id='k79uiff'), Comment(id='k79rxkc'), Comment(id='k79pdot'), Comment(id='k7blboh'), Comment(id='k7bxnth'), Comment(id='k7cgxp6'), Comment(id='k7de69p'), Comment(id='k7dmkbp'), Comment(id='k7g0ko8'), Comment(id='k7mumxj'), Comment(id='k7v85ah'), Comment(id='k7982ln'), Comment(id='k79hdog'), Comment(id='k797039'), Comment(id='k7awg5r'), Comment(id='k7b5k2o'), Comment(id='k79itjd'), Comment(id='k7an3so'), Comment(id='k81uo60'), Comment(id='k7an05x'), Comment(id='k79ikzl'), Comment(id='k7am4eb'), Comment(id='k7akqnt'), Comment(id='k7aku1h'), Comment(id='k7amunh'), Comment(id='k7e7zrb'), Comment(id='k79l16s'), Comment(id='k7aanbj'), Comment(id='k7aznud'), Comment(id='k7aicz3'), Comment(id='k79b6hk'), Comment(id='k7aj9gv'), Comment(id='k79quc9'), Comment(id='k79lp7n'), Comment(id='k7as67k'), Comment(id='k7eci6z'), Comment(id='k7ajcoe'), Comment(id='k7e129l'), Comment(id='k7cu5qj'), Comment(id='k7aknyb'), Comment(id='k7a52yd'), Comment(id='k7ang0h'), Comment(id='k7emavt'), Comment(id='k7am49w'), Comment(id='k7cfbdd'), Comment(id='k7buzs3'), Comment(id='k7aqs5y'), Comment(id='k7dapgo'), Comment(id='k7ctsc7'), Comment(id='k7cf4cn')]"
17ktlc5,AnxiousEgg6284,,2023-10-31 19:46:26+00:00,False,,False,False,True,False,/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,"If you did an online MSc in Stats and/or DS or something in that area & liked it, what program was it and what did you like about it?","My company offers tuition assistance and I'm thinking about going back for a formal degree, but it'd need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there's gaps in my math and experience with some of the newer ML methods & neural networks in particular. 

I'm thinking of the Georgia Tech one but would be curious to hear about others.",datascience,https://www.reddit.com/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,12,16,0.9,"[Comment(id='k7aarz8'), Comment(id='k7bgye3'), Comment(id='k79zmul'), Comment(id='k7a292e'), Comment(id='k7a4omu'), Comment(id='k7fqh18'), Comment(id='k7bh1i8'), Comment(id='k7cl843'), Comment(id='k7exkfr'), Comment(id='k7bp1xc'), Comment(id='k7f9wfb'), Comment(id='k7qjecy')]"
17l8xdt,Thinker_Assignment,,2023-11-01 10:19:54+00:00,False,,False,False,True,False,/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,"Metabase, PowerBI and Gooddata capabilities: A comparison","Hello folks

For the ones of you who manage dashboards or semantic models in UI tools, here's an article describing 3 popular tools and their capabilities at doing this work

[https://dlthub.com/docs/blog/semantic-modeling-tools-comparison](https://dlthub.com/docs/blog/semantic-modeling-tools-comparison)

hope you enjoy the read and if you'd like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!",datascience,https://www.reddit.com/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,0,0,0.5,[]
17kvm37,Illustrious-Bed5587,,2023-10-31 21:15:49+00:00,False,,False,False,True,False,/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,Resources for technical interviews with focus on cleaning unstructured data?,I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?,datascience,https://www.reddit.com/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,5,5,0.78,"[Comment(id='k7ba2vz'), Comment(id='k7aq7vy'), Comment(id='k7d7x9s'), Comment(id='k7fqpb5')]"
17kp0nu,Dapper-Economy,,2023-10-31 16:26:38+00:00,False,,False,False,True,False,/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,How do you analyze your models?,"Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? 

My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren’t able to print summaries like this and I don’t think we should limit ourselves to GLR only for future projects. 

So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I’m not even sure how I would suggest using other algorithms for future business projects if they don’t agree with using a correlation matrix or features of importance to pick the features.",datascience,https://www.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,34,13,0.93,"[Comment(id='k78xxaq'), Comment(id='k79a858'), Comment(id='k79o5sb'), Comment(id='k79gm65'), Comment(id='k79qn1r'), Comment(id='k7addod'), Comment(id='k79wxkk'), Comment(id='k7diwr5'), Comment(id='k7gxm0h'), Comment(id='k79oczc'), Comment(id='k7dmsi1'), Comment(id='k7ex4uv'), Comment(id='k826ga9'), Comment(id='k78z6d5'), Comment(id='k7ai9ek'), Comment(id='k7abomm'), Comment(id='k79i92j'), Comment(id='k7ac186'), Comment(id='k7ifaog'), Comment(id='k7ahlpl'), Comment(id='k7iw8mx'), Comment(id='k7f8km7'), Comment(id='k79nyde'), Comment(id='k7aa0o9'), Comment(id='k7atf9k'), Comment(id='k7av4hz'), Comment(id='k7acks7'), Comment(id='k7abcd7'), Comment(id='k7ajyn6'), Comment(id='k7abgde'), Comment(id='k7aljlg'), Comment(id='k7acodz'), Comment(id='k7sn3in'), Comment(id='k7ae740')]"
17kpxml,ruckrawjers,,2023-10-31 17:07:33+00:00,False,,False,False,True,False,/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,automating ad-hoc SQL requests from stakeholders,"Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.

So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.

In the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served

DM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all",datascience,https://www.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,29,9,0.74,"[Comment(id='k79nn5s'), Comment(id='k7b2oq4'), Comment(id='k79htp2'), Comment(id='k7a068h'), Comment(id='k7c30nz'), Comment(id='k7d9ts2'), Comment(id='k79poy0'), Comment(id='k7ai4xx'), Comment(id='k7cwztd'), Comment(id='k7aymi0'), Comment(id='k7ayms7'), Comment(id='k79q7zl'), Comment(id='k7bd6li'), Comment(id='k7cxarq'), Comment(id='k7alucr'), Comment(id='k7ahb6r'), Comment(id='k7d0wv7'), Comment(id='k7aqww1'), Comment(id='k7d1ge3'), Comment(id='k7bd57c'), Comment(id='k7artlv'), Comment(id='k7atsxg'), Comment(id='k7d81ti'), Comment(id='k7at8gy'), Comment(id='k7b73zg'), Comment(id='k7bn85v'), Comment(id='k7b80fa'), Comment(id='k7eint8'), Comment(id='k7d6mq8')]"
17l3gak,Mission-Language8789,,2023-11-01 03:40:20+00:00,False,,False,False,True,False,/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,Thoughts on Krish Naik?,"I've been watching his videos for a while now and being a beginner, I assumed he was pretty good.

However, I've seen a few people criticise him for not knowing what he's talking about, and that he's only good for absolute beginners.",datascience,https://www.reddit.com/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,15,1,0.53,"[Comment(id='k7c8brh'), Comment(id='k7bsmbp'), Comment(id='k7c8dx2'), Comment(id='k7ci5l3'), Comment(id='k7bzgbd'), Comment(id='k7cbo5u'), Comment(id='k7cstez'), Comment(id='k7c2vr1'), Comment(id='k7d7tux'), Comment(id='k7giuwp'), Comment(id='k7sknav'), Comment(id='k7d021x'), Comment(id='k7c4qgz'), Comment(id='k7c9hmp')]"
17kvn2f,ExpressOcelot8977,,2023-10-31 21:16:59+00:00,False,,False,False,True,False,/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,Describe the analytics tool of your dreams…,I’ll compile answers and write an article with the summary,datascience,https://www.reddit.com/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,24,3,0.59,"[Comment(id='k7agjp0'), Comment(id='k7acd3t'), Comment(id='k7aewq9'), Comment(id='k7ai3uf'), Comment(id='k7boyi6'), Comment(id='k7cty8v'), Comment(id='k7b38uz'), Comment(id='k7aj5kl'), Comment(id='k7bch82'), Comment(id='k7apuw2'), Comment(id='k7bce98'), Comment(id='k7hnjhe'), Comment(id='k7smqis'), Comment(id='k7b9hwb'), Comment(id='k7acewc'), Comment(id='k7e9mpw'), Comment(id='k7b9848'), Comment(id='k7bxm8z'), Comment(id='k7d5yw5'), Comment(id='k7d1kw5'), Comment(id='k7c6nz2'), Comment(id='k7bct01'), Comment(id='k7d6f14'), Comment(id='k7bdddc')]"
17kmu0e,FreakedoutNeurotic98,,2023-10-31 14:51:22+00:00,False,,False,False,True,False,/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,Is Upwork a good place to find data science freelance gigs in the UK ?,Would appreciate other website suggestions too.,datascience,https://www.reddit.com/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,12,9,0.91,"[Comment(id='k78jc7v'), Comment(id='k7b3278'), Comment(id='k78ykku'), Comment(id='k7d7v63'), Comment(id='k7eusou'), Comment(id='k7lt360'), Comment(id='k78jmus'), Comment(id='k78ki9o'), Comment(id='k79la1s'), Comment(id='k78mtgv'), Comment(id='k78zx68'), Comment(id='k79kyy2')]"
17kmxnc,Total-Opposite-8396,,2023-10-31 14:56:04+00:00,False,,False,False,True,False,/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,What are the possible reasons for validation loss to fluctuate so much?,"Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.

I'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info.

https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&format=png&auto=webp&s=b20530593f527d138a190a33740e752692d984aa",datascience,https://www.reddit.com/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,2,5,1.0,"[Comment(id='k78q36e'), Comment(id='k7b4t8y')]"
17jtkgv,son_of_tv_c,,2023-10-30 13:36:51+00:00,False,,False,False,True,False,/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,Are all higher level data science jobs like this?,"I'm really not sure how to summarize this concisely in a neat title, so just let me explain.

At previous lower level jobs, we were organized. We had ticketing tracking systems, step-by-step procedures for all of the commonly done work, we had checklists that people could sign off on as they completed work. And most importantly, even for one-off requests, the primary mode of communication was email. That way, I had the project specifications and/or updates spelled out in front of me that I could refer back to whenever needed.

As I get higher up in the field at different companies, I'm finding the primary mode of communication is virtual meetings. All of the background, specifications, and next steps are given verbally, and I'm sitting here in these meetings furiously trying to write everything down that is being said. What's worse is that the ideas for the projects often aren't fully developed and we have to figure them out so I get a lot of ""do this, actually no, let's do it this way, but I'm actually thinking it would be better to approach it this way....."". AS you can imagine it makes fully understanding the next steps of a given projects difficult. If I use my judgement and approach it the way I feel is best, half the time it's end up not being what management wants and I have to waste their time and mine on rework. 

One of the ways I tried to work around management's brain dumps on me was to recap back to them what the next steps they wanted from me were, but they're ***super busy*** so they always join the meetings late, and as a result we frequently run out of time.  75% of the time I try to message or email them with questions they just don't respond, so the only way I can get any info out of them is via virtual meetings. This is creating an environment for me that makes mistakes easier to happen, and it's turning into a situation where I can do 9 things right, but if I missed or misunderstood the 10th thing, I'm getting crucified for it (meanwhile this is a common occurrence for management but that's a different rant.....) I'm being made to feel like it's a shortcoming of mine for not being able to take down everything accurately.

I know some people can thrive in these conditions. For me, it's tough. I'm definitely a scatterbrain and I try to compensate for this by being as organized as humanly possible, but it's just easier said than done when most everything is being given ONLY verbally. I understand that the higher you go in data science, the less routine and the more exploratory and R&D your work becomes, so having clearly documented procedures becomes less realistic. But if this is the way most of these positions are going to be, I really don't feel like this field is for me.",datascience,https://www.reddit.com/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,102,210,0.93,"[Comment(id='k736ud8'), Comment(id='k7393q5'), Comment(id='k73ewru'), Comment(id='k735wge'), Comment(id='k7397gs'), Comment(id='k73w16n'), Comment(id='k73jdk0'), Comment(id='k73bsuy'), Comment(id='k73zhy7'), Comment(id='k73hr0i'), Comment(id='k73to9u'), Comment(id='k73ufef'), Comment(id='k741hrl'), Comment(id='k742j9l'), Comment(id='k745fco'), Comment(id='k7486xb'), Comment(id='k748ae7'), Comment(id='k749i7v'), Comment(id='k74a6wc'), Comment(id='k74k2r5'), Comment(id='k75237v'), Comment(id='k752crf'), Comment(id='k75d5ud'), Comment(id='k75o3o7'), Comment(id='k762zpv'), Comment(id='k763oxa'), Comment(id='k76cb2r'), Comment(id='k76r2ji'), Comment(id='k76swrq'), Comment(id='k771fbw'), Comment(id='k77hnbv'), Comment(id='k77rn7v'), Comment(id='k783bbw'), Comment(id='k787dvu'), Comment(id='k78xhv5'), Comment(id='k795clc'), Comment(id='k79638f'), Comment(id='k7aof7y'), Comment(id='k7c820v'), Comment(id='k7cymwc'), Comment(id='k7d9xlc'), Comment(id='k7dfnav'), Comment(id='k7f7e10'), Comment(id='k7gibcr'), Comment(id='k7muoe5'), Comment(id='k7388bm'), Comment(id='k74y5ll'), Comment(id='k73fir6'), Comment(id='k744f0v'), Comment(id='k738xch'), Comment(id='k779on7'), Comment(id='k77wdsa'), Comment(id='k75ntfk'), Comment(id='k76zg67'), Comment(id='k7b8l77'), Comment(id='k73qop2'), Comment(id='k73c6zj'), Comment(id='k73liif'), Comment(id='k73owa6'), Comment(id='k73gi8j'), Comment(id='k73bd40'), Comment(id='k73qpni'), Comment(id='k745ryk'), Comment(id='k7bdhmp'), Comment(id='k771g6y'), Comment(id='k738oj4'), Comment(id='k73ly3a'), Comment(id='k7czenf'), Comment(id='k74q3wg'), Comment(id='k73eofx'), Comment(id='k757l6r'), Comment(id='k75c375'), Comment(id='k73n4tu'), Comment(id='k75sufy'), Comment(id='k77zhm9'), Comment(id='k76bap4'), Comment(id='k741mg3'), Comment(id='k73uoqp'), Comment(id='k7ecl81'), Comment(id='k73vdfn'), Comment(id='k78df45'), Comment(id='k77shpe'), Comment(id='k752se2'), Comment(id='k7445vz'), Comment(id='k7438o1'), Comment(id='k74rxga'), Comment(id='k75cxc0'), Comment(id='k73v68a'), Comment(id='k741wr1'), Comment(id='k747wpz'), Comment(id='k74ppwr'), Comment(id='k75nvia'), Comment(id='k74o0kv'), Comment(id='k78opse'), Comment(id='k74fo9r'), Comment(id='k746sm1'), Comment(id='k74g51j'), Comment(id='k7513a1'), Comment(id='k78teb8'), Comment(id='k74949k'), Comment(id='k790wtp'), Comment(id='k79323d')]"
17kfjr0,venkarafa,,2023-10-31 07:34:28+00:00,False,,False,False,True,False,/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,Is there any utility in using SHAP values for feature attribution in cases of Linear models and GLMs?," So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.

For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.

Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.

My question is : Would a SHAP value applied on top of the Linear regression model discover the same 'truth'. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?

What has been your experience? Has SHAP worked for you in case LM or GLM models?

What are the pitfalls of using SHAP?",datascience,https://www.reddit.com/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,3,7,1.0,"[Comment(id='k77jhur'), Comment(id='k7d84gv'), Comment(id='k7hhghu')]"
17jst3u,Throwawayforgainz99,,2023-10-30 12:58:31+00:00,False,,False,False,True,False,/r/datascience/comments/17jst3u/favorite_ml_example/,Favorite ML Example?,"I feel like a lot of kaggle examples use really simple data sets that you don’t ever find in the real world scenarios(like the Titanic data set for instance).

Does anyone know any notebooks/examples that start with really messy data? I really want to see someone go through the process of EDA/Feature engineering with data sets that have more than 20 variables.",datascience,https://www.reddit.com/r/datascience/comments/17jst3u/favorite_ml_example/,42,105,0.96,"[Comment(id='k73cjbc'), Comment(id='k73n0o8'), Comment(id='k74fknp'), Comment(id='k74medk'), Comment(id='k73duhg'), Comment(id='k75o3ob'), Comment(id='k73jbvg'), Comment(id='k775bp8'), Comment(id='k75qs9a'), Comment(id='k780jba'), Comment(id='k74h8nj'), Comment(id='k735m2g'), Comment(id='k75u35j'), Comment(id='k734cs7'), Comment(id='k73tejh'), Comment(id='k781x75'), Comment(id='k7dfwhc'), Comment(id='k7muqde'), Comment(id='k77vl4f'), Comment(id='k74h20p'), Comment(id='k754mfb'), Comment(id='k74783c'), Comment(id='k768wes'), Comment(id='k74ecqc'), Comment(id='k73jaov'), Comment(id='k7362d3'), Comment(id='k73mtqq'), Comment(id='k769eaq'), Comment(id='k7356tu'), Comment(id='k786syp'), Comment(id='k7ijzw4'), Comment(id='k74o11w'), Comment(id='k766f3l'), Comment(id='k7et3wm'), Comment(id='k767x38'), Comment(id='k7407sz'), Comment(id='k736aoi'), Comment(id='k77fsnm'), Comment(id='k7899cj'), Comment(id='k74stn2'), Comment(id='k7evujf')]"
17jxqm8,Unhappy_Technician68,,2023-10-30 16:45:20+00:00,False,,1698699696.0,False,True,False,/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,How does one find freelance or contract work? Short or long term would be fine.,"I work full time as a data scientist and I have 3 years experience now.  I've become significantly more efficient and experienced and I feel that I could take on more work than my company gives me.  My boss wouldn't mind if I took some extra work on the side, he's very flexible and I was wondering how people find contracts for short term gigs?  Are there any sites in particular people have had success with?  What do you typically bill at?  


Edit:  General vibe I'm getting is that this is a waste of time and after scrolling through the options on Upwork I'm coming to see it that way as well.",datascience,https://www.reddit.com/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,19,25,0.88,"[Comment(id='k746eyf'), Comment(id='k73yp0j'), Comment(id='k746f0n'), Comment(id='k77fh9j'), Comment(id='k7dwwam'), Comment(id='k747cbj'), Comment(id='k74lgec'), Comment(id='k77xjn4'), Comment(id='k7bdy8r'), Comment(id='k7d85we'), Comment(id='k7540id'), Comment(id='k748wz6'), Comment(id='k742x23'), Comment(id='k74kyjs'), Comment(id='k7cpw72'), Comment(id='k74nzn3'), Comment(id='k753f7w'), Comment(id='k7kv7ar'), Comment(id='k77zitb')]"
17jmq2n,EstablishmentHead569,,2023-10-30 06:00:30+00:00,False,,False,False,True,False,/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,Maintaining a work life balance,"How is everyone keeping a good work life balance in this industry? Or work in general. 

I am currently doing my masters as a full time DS and also doing certifications as requested by my managers. 

I am forcing myself to sleep earlier, but the daily screen time is just too draining for my eyes to keep up.",datascience,https://www.reddit.com/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,54,67,0.93,"[Comment(id='k722prt'), Comment(id='k722k7i'), Comment(id='k723i44'), Comment(id='k733kz1'), Comment(id='k72hw3b'), Comment(id='k72dakh'), Comment(id='k72jdoz'), Comment(id='k72n7ss'), Comment(id='k72wkrd'), Comment(id='k735n57'), Comment(id='k74llae'), Comment(id='k72csr2'), Comment(id='k7370x9'), Comment(id='k72pc88'), Comment(id='k72zgk3'), Comment(id='k731h5v'), Comment(id='k731i7b'), Comment(id='k734c4v'), Comment(id='k739thn'), Comment(id='k73k0c6'), Comment(id='k73t2bs'), Comment(id='k742kkd'), Comment(id='k74dv24'), Comment(id='k74hmbt'), Comment(id='k7ag38a'), Comment(id='k7b3ed8'), Comment(id='k7c87cb'), Comment(id='k7c87cl'), Comment(id='k7dg0gp'), Comment(id='k7ey3pl'), Comment(id='k75j4u4'), Comment(id='k74s5vy'), Comment(id='k7408dp'), Comment(id='k776goc'), Comment(id='k72kxdr'), Comment(id='k72tx4o'), Comment(id='k736f8e'), Comment(id='k72joe1'), Comment(id='k72hnjc'), Comment(id='k7cbv9m'), Comment(id='k75qj5i'), Comment(id='k72mbc4'), Comment(id='k739wal'), Comment(id='k737c86'), Comment(id='k77tq4m'), Comment(id='k792n1v'), Comment(id='k72mu6j'), Comment(id='k73q0ln'), Comment(id='k79wdw2'), Comment(id='k7arxgj'), Comment(id='k72rbbe'), Comment(id='k760p2i'), Comment(id='k7arwn1'), Comment(id='k766fw7')]"
17k3svb,soggypocket,,2023-10-30 21:10:02+00:00,False,,False,False,True,False,/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,Has anyone tried Cursor.sh AI editor for data science?,I've seen a few people talk cursor [https://cursor.sh/](https://cursor.sh/) for software saying that it was good. Has anyone tried it for data science?  ,datascience,https://www.reddit.com/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,3,3,0.67,"[Comment(id='k75k6tu'), Comment(id='k7828z8'), Comment(id='k757lrw')]"
17jrbh7,Hot-Profession4091,,2023-10-30 11:35:09+00:00,False,,False,False,True,False,/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,Recommendation for measuring similarity of paragraphs,"I’m doing some analysis and part of my data, possibly a very important part, is a text description of a product. I want to determine if there’s a correlation between the product description and performance, but to do this I need to cluster the descriptions into similar groups. I’m thinking text embeddings could be useful, but I’m unsure of which ones to use. Can anyone provide some advice?

Possibly more important, if I’m completely barking up the wrong tree, please let me know. ",datascience,https://www.reddit.com/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,14,4,1.0,"[Comment(id='k73wf95'), Comment(id='k74h4q5'), Comment(id='k774vqp'), Comment(id='k77alwv'), Comment(id='k72tny3'), Comment(id='k73lf0s'), Comment(id='k75i4k0'), Comment(id='k778ban'), Comment(id='k7b3m6p'), Comment(id='k7d87qs'), Comment(id='k73yjdi'), Comment(id='k74vgts'), Comment(id='k73lyun'), Comment(id='k750aiq')]"
17jygyq,missing-in-idleness,,2023-10-30 17:16:58+00:00,False,,False,False,True,False,/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,Where to Draw the Line between Proof of Concept and Deployment?,"Are you currently involved in a project that revolves around fulfilling customer requirements? As part of your responsibilities, are you tasked with deploying a functional data science project?

I'm referring to the point at which you determine that the project is prepared for delivery. Is it sufficient to provide a functional model based on a script or notebook, accompanied by a presentation that includes relevant metrics? Or do you also engage in the deployment phase? I'm somewhat perplexed because there is often a request for a ""proof of concept,"" but is functional code alone sufficient to satisfy this requirement?

I am a part of a small team and my team seldom deals with external clients, so I'm unsure about the boundaries between what should be accomplished before transitioning to a production-level stage. ",datascience,https://www.reddit.com/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,8,1,0.67,"[Comment(id='k74hzqz'), Comment(id='k779eh9'), Comment(id='k7c82ql'), Comment(id='k75504o'), Comment(id='k75q19q'), Comment(id='k75yphr'), Comment(id='k76so1q'), Comment(id='k7g114x')]"
17jgck2,AnxiousEgg6284,,2023-10-29 23:58:58+00:00,False,,False,False,True,False,/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,How have you approached training yourself to become better at business acumen/context for your DS work?,"This is the thing I'm struggling most with. Coming from an academic background, the concerns seem to be different but I'm still having trouble articulating exactly how, or what to do to get better at training myself to be more business-ybif that makes sense",datascience,https://www.reddit.com/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,23,20,0.84,"[Comment(id='k71ndsz'), Comment(id='k70yjdg'), Comment(id='k70wz6q'), Comment(id='k70wgi1'), Comment(id='k716078'), Comment(id='k71hs1n'), Comment(id='k71n029'), Comment(id='k73w7dc'), Comment(id='k71pkgm'), Comment(id='k71vihu'), Comment(id='k72dvnr'), Comment(id='k72wayn'), Comment(id='k736bbo'), Comment(id='k737x03'), Comment(id='k739ll5'), Comment(id='k73y2a8'), Comment(id='k74tal1'), Comment(id='k7ezyhu'), Comment(id='k7h4vph'), Comment(id='k72qxd2'), Comment(id='k7173kw'), Comment(id='k71rmml'), Comment(id='k71slxw')]"
17j3qc7,Objective-Test5021,,2023-10-29 14:10:10+00:00,False,,1698641722.0,False,True,False,/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,The job market is so frustrating,"Graduated 5 months ago with a MS in CS. Before I came to the US to pursue my masters, heard from a boat load of people that getting jobs after graduation was easy and that hardly anyone graduated without a couple offers in hand. That sentiment was echoed by other recent grads I met when I got here.

I always wanted to get into DS, so when everyone started looking for internships, I started looking for DS/DA/DE internships specifically. Gave a bunch of interviews, landed an offer in April of 2022. Just an unfortunate decision. The company had a new data science practice with no clear definition of what a Data Scientist does. Being a consulting firm, we basically jump from one case to another and use whatever tech is needed on a case to case basis.
Spent all summer just doing web scraping and OCR extractions. Also, my manager is super condescending and outright rude. He’s told me multiple times that he “can’t believe I have two degrees in Comp. Sci” and at team gatherings and social events, wouldn’t even look me in the eye or acknowledge my existence lol. On the last day of my summer internship, he was in my office literally laughing at my code which btw was based off a snippet he sent me.

Anyway, once this ordeal was done, the world went into a recession and I had to accept a return internship offer. Return internship because I hadn’t proven myself enough to land a full time role yet. Went through another 3 months of abuse and got a full time offer, been working FT for about 4-5 months now. 

At this point I can’t take it anymore. Every day at work I’m putting out fires with the fear that if I fuck up, I’ll either be publicly ridiculed or fired. Consulting being consulting, work life balance is non existent and I had to move to a city where I have no friends and no social life to at least escape the stress.

To all seniors and hiring managers etc, do you think the job market is going to get better? What’s the trend at your company?

EDIT: Thanks for all the support everyone, it’s a tough spot to be in mentally, but I’m thankful for at least have a job. I know so many people who don’t, so complaining sucks. Hopefully things improve for us all soon.",datascience,https://www.reddit.com/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,55,117,0.85,"[Comment(id='k6yd2a8'), Comment(id='k6yjrnd'), Comment(id='k6z38kj'), Comment(id='k717s2h'), Comment(id='k703hz5'), Comment(id='k6z9h0g'), Comment(id='k6zlrg1'), Comment(id='k71bw59'), Comment(id='k75fb85'), Comment(id='k6zzj1p'), Comment(id='k71ht8w'), Comment(id='k73amqs'), Comment(id='k7ex7xq'), Comment(id='k72yun7'), Comment(id='k6yj75b'), Comment(id='k70le0d'), Comment(id='k71i9pt'), Comment(id='k71svxs'), Comment(id='k71xb7a'), Comment(id='k725a2v'), Comment(id='k731joo'), Comment(id='k731k6j'), Comment(id='k731ks6'), Comment(id='k73tp9i'), Comment(id='k76ysr8'), Comment(id='k7b3svm'), Comment(id='k7bdkgs'), Comment(id='k7smsv6'), Comment(id='k6yfy5h'), Comment(id='k6ydbc0'), Comment(id='k79uu5g'), Comment(id='k6ypo4l'), Comment(id='k6z5yqg'), Comment(id='k719d57'), Comment(id='k71ymnc'), Comment(id='k6zhkaj'), Comment(id='k71hcek'), Comment(id='k7342vk'), Comment(id='k70mnnc'), Comment(id='k71vyh6'), Comment(id='k71ydlo'), Comment(id='k73u456'), Comment(id='k781tbv'), Comment(id='k6yi7mv'), Comment(id='k6yqt1e'), Comment(id='k6zyf23'), Comment(id='k71bgut'), Comment(id='k6zhu7d'), Comment(id='k739a12'), Comment(id='k70mpxi'), Comment(id='k70nkxg'), Comment(id='k71z3az'), Comment(id='k740bk5'), Comment(id='k6yoebn'), Comment(id='k70r5yz')]"
17jkxjp,AutoModerator,,2023-10-30 04:01:25+00:00,False,,False,False,True,False,/r/datascience/comments/17jkxjp/weekly_entering_transitioning_thread_30_oct_2023/,"Weekly Entering & Transitioning - Thread 30 Oct, 2023 - 06 Nov, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/17jkxjp/weekly_entering_transitioning_thread_30_oct_2023/,94,10,1.0,"[Comment(id='k74xjg4'), Comment(id='k72kyyb'), Comment(id='k75do1o'), Comment(id='k7b48l3'), Comment(id='k769lz1'), Comment(id='k790t2p'), Comment(id='k7as781'), Comment(id='k7e2a60'), Comment(id='k7j0jpk'), Comment(id='k7oq8qr'), Comment(id='k7qui4l'), Comment(id='k7qwxei'), Comment(id='k7sajq7'), Comment(id='k7nmsmg'), Comment(id='k75bsg0'), Comment(id='k771jnz'), Comment(id='k77mtea'), Comment(id='k79tf96'), Comment(id='k7bsl83'), Comment(id='k7dbaek'), Comment(id='k7fu40u'), Comment(id='k7gc0kh'), Comment(id='k7h66ei'), Comment(id='k7o9h31'), Comment(id='k7oaxtp'), Comment(id='k7ok7i6'), Comment(id='k7pg7lo'), Comment(id='k7s898u'), Comment(id='k7ve3w6'), Comment(id='k7w2d9j'), Comment(id='k754h7o'), Comment(id='k72qlbx'), Comment(id='k72r2pg'), Comment(id='k7o5zyv'), Comment(id='k75str7'), Comment(id='k769qa9'), Comment(id='k79y3tv'), Comment(id='k7c8zc9'), Comment(id='k7d3gnf'), Comment(id='k7getng'), Comment(id='k77xfn6'), Comment(id='k78u6ct'), Comment(id='k79xz8e'), Comment(id='k7lzpnk'), Comment(id='k7f4gsw'), Comment(id='k7i3toe'), Comment(id='k7n7qiv'), Comment(id='k7uab48'), Comment(id='k7yovjr'), Comment(id='k7tzldl'), Comment(id='k7zf0gf'), Comment(id='k7iclpg'), Comment(id='k783u5c'), Comment(id='k79omrb'), Comment(id='k7c8wr8'), Comment(id='k7g0a77'), Comment(id='k783rm1'), Comment(id='k7m00kj'), Comment(id='k7m5ifv'), Comment(id='k7ooy26'), Comment(id='k7h8122'), Comment(id='k7lzfd9'), Comment(id='k7lypug'), Comment(id='k7thhwi'), Comment(id='k7thy4h'), Comment(id='k7oo85t'), Comment(id='k7ynxsg'), Comment(id='k7ynkb9'), Comment(id='k75aui8'), Comment(id='k7dwb80'), Comment(id='k79ddh4'), Comment(id='k7qjov9'), Comment(id='k7kukl4'), Comment(id='k7iirhy'), Comment(id='k80zhq1'), Comment(id='k7ubluw'), Comment(id='k78uhek'), Comment(id='k7am0p0'), Comment(id='k7m539t'), Comment(id='k7p2vzf'), Comment(id='k7zjx1z'), Comment(id='k75dxk0'), Comment(id='k7o4zkr'), Comment(id='k7oohoo'), Comment(id='k7sm0u8'), Comment(id='k7ui7so'), Comment(id='k7zhh30'), Comment(id='k78xkw5'), Comment(id='k7apxol'), Comment(id='k7pb0gw'), Comment(id='k7zn5m9'), Comment(id='k75eswm'), Comment(id='k7uikgq'), Comment(id='k7pwl2c')]"
17jg57k,lowkeyripper,,2023-10-29 23:49:08+00:00,False,,False,False,True,False,/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,Python library to interactively filter a dataframe?,"For all intents and purposes its basically a Power BI table with slicers/filters, or a GUI approach of df[(mask1) & (mask2) & (mask3)].sort_values(by='col1') where you can interact with which columns to mask, how to mask them, and how to sort, resulting in a perfectly tailored table.

I have scraped a list of every game on Steam and I have a dataframe of like 180k games and 470+ columns and was thinking how cool it would be if I could make 
every a table as granular as I want it. e.g. find me games from 2008 that have 1000 total ratings and more than 95% steam review with the tag ""FPS"" sorted by the date it came out, and hide the majority of columns.

If something like this doesnt exist but is able to exist in something like Flask (that I have NO knowledge on), let me know. I just wanted to check if the wheel exists before rebuilding it. If what I want really is difficult to do, let me know and I can just make the same thing in Power BI. This will also make me appreciate Power BI as a tool.",datascience,https://www.reddit.com/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,18,18,0.95,"[Comment(id='k70wmdd'), Comment(id='k71s7dv'), Comment(id='k723dui'), Comment(id='k7187xf'), Comment(id='k71fbbr'), Comment(id='k726hmc'), Comment(id='k7b3zet'), Comment(id='k71airi'), Comment(id='k72bd25'), Comment(id='k765nfj'), Comment(id='k70xnky'), Comment(id='k70xfo6'), Comment(id='k70zwju'), Comment(id='k71adik'), Comment(id='k70y9ok'), Comment(id='k70z5f9'), Comment(id='k7129kq')]"
17j80cj,LowLab2791,,2023-10-29 17:33:58+00:00,False,,False,False,True,False,/r/datascience/comments/17j80cj/whats_your_educational_background/,What's your educational background,Hi r/datascience. I am interested to know the educational qualifications/background of the members of the group. Personally I have a Bachelor's degree in Maths + an MBA. Have been working in Banking + Analytics for the last 12 years. I know we have CS graduates in this group and those who have done MS in data science and Analytics. Would be good to know the diverse educational background of others as well.,datascience,https://www.reddit.com/r/datascience/comments/17j80cj/whats_your_educational_background/,174,48,0.83,"[Comment(id='k6zjg2j'), Comment(id='k6zhok8'), Comment(id='k706yvo'), Comment(id='k6znncq'), Comment(id='k6zsc21'), Comment(id='k6zzd0r'), Comment(id='k6zaq0c'), Comment(id='k708brj'), Comment(id='k6z987h'), Comment(id='k6zt476'), Comment(id='k6zymm4'), Comment(id='k70rh0s'), Comment(id='k6zqxik'), Comment(id='k6zxzlp'), Comment(id='k70940e'), Comment(id='k6zvb8f'), Comment(id='k6zx4j4'), Comment(id='k70i9cc'), Comment(id='k72ibnl'), Comment(id='k70lnnd'), Comment(id='k70lo7f'), Comment(id='k71a5jq'), Comment(id='k71muv9'), Comment(id='k71qw89'), Comment(id='k723lji'), Comment(id='k72kl60'), Comment(id='k71thyb'), Comment(id='k7287vl'), Comment(id='k7cwrve'), Comment(id='k6zhrcj'), Comment(id='k6zzjlb'), Comment(id='k70fhxq'), Comment(id='k6zuoqz'), Comment(id='k6zwkag'), Comment(id='k706lwe'), Comment(id='k70evbm'), Comment(id='k70nv2u'), Comment(id='k70qhjv'), Comment(id='k70vqsz'), Comment(id='k70z3st'), Comment(id='k7105l9'), Comment(id='k71f38d'), Comment(id='k71zm2x'), Comment(id='k72cued'), Comment(id='k72lto6'), Comment(id='k72te79'), Comment(id='k72wgkk'), Comment(id='k732ept'), Comment(id='k74qo3z'), Comment(id='k76ysoi'), Comment(id='k77gd5v'), Comment(id='k6zdqxw'), Comment(id='k6zqcv5'), Comment(id='k6zy6qc'), Comment(id='k722n98'), Comment(id='k72ct3n'), Comment(id='k7gy3vt'), Comment(id='k703n1t'), Comment(id='k70cyyv'), Comment(id='k70dqqz'), Comment(id='k70e97w'), Comment(id='k70mp0w'), Comment(id='k70sldk'), Comment(id='k70zivx'), Comment(id='k714wy4'), Comment(id='k71f8jw'), Comment(id='k71qnwe'), Comment(id='k71qwhl'), Comment(id='k71tn8k'), Comment(id='k71v3vb'), Comment(id='k72e7mn'), Comment(id='k72ecoq'), Comment(id='k72ol06'), Comment(id='k72t5i4'), Comment(id='k72x6bd'), Comment(id='k72z2g8'), Comment(id='k72zhc8'), Comment(id='k731m9y'), Comment(id='k735frg'), Comment(id='k73a9fc'), Comment(id='k746ou1'), Comment(id='k74m46l'), Comment(id='k750hml'), Comment(id='k768uce'), Comment(id='k77o6ie'), Comment(id='k782fj9'), Comment(id='k7844dz'), Comment(id='k7a42t9'), Comment(id='k7bemkm'), Comment(id='k7c8zol'), Comment(id='k7de7bh'), Comment(id='k7devkx'), Comment(id='k7eyzbj'), Comment(id='k7fmlhb'), Comment(id='k7jdq0z'), Comment(id='k7p7mcx'), Comment(id='k6zt1oq'), Comment(id='k71sbi4'), Comment(id='k732a0w'), Comment(id='k75e5i4'), Comment(id='k6zim3a'), Comment(id='k710t0q'), Comment(id='k74iu7r'), Comment(id='k71f6hd'), Comment(id='k759wyf'), Comment(id='k700ynh'), Comment(id='k767omk'), Comment(id='k71wt1q'), Comment(id='k70i2eb'), Comment(id='k6zylns'), Comment(id='k71td4b'), Comment(id='k75rcm1'), Comment(id='k75phgi'), Comment(id='k71myoo'), Comment(id='k70lup4'), Comment(id='k71wtz1'), Comment(id='k6zxfya'), Comment(id='k70mnc2'), Comment(id='k6zyt75'), Comment(id='k76znhb'), Comment(id='k72knk0'), Comment(id='k70lz42'), Comment(id='k79o0hs'), Comment(id='k6zuvh2'), Comment(id='k71zh47'), Comment(id='k73auii'), Comment(id='k75eavr'), Comment(id='k7014sh'), Comment(id='k7168mw'), Comment(id='k74sxxo'), Comment(id='k702x58'), Comment(id='k7p29fo'), Comment(id='k75a66l'), Comment(id='k75qx8c'), Comment(id='k700gtz'), Comment(id='k72lyox'), Comment(id='k71n0m0'), Comment(id='k719i80'), Comment(id='k73yxjq'), Comment(id='k70483q'), Comment(id='k736cfp'), Comment(id='k77t6nm'), Comment(id='k70nero'), Comment(id='k79vfo7'), Comment(id='k6zxcw1'), Comment(id='k72a0wj'), Comment(id='k73d6kq'), Comment(id='k70e0kb'), Comment(id='k71a2wz'), Comment(id='k705bg2'), Comment(id='k75cqnk'), Comment(id='k71x2db'), Comment(id='k7aeh1v'), Comment(id='k74c9as'), Comment(id='k70v6nf'), Comment(id='k6zyb1u'), Comment(id='k71drfr'), Comment(id='k70w2kz'), Comment(id='k75j0ox'), Comment(id='k82cy2u'), Comment(id='k79f3wz'), Comment(id='k70vv1x'), Comment(id='k7044en'), Comment(id='k71w5ti'), Comment(id='k75jkhz'), Comment(id='k79mypx'), Comment(id='k71rthj'), Comment(id='k75kslh'), Comment(id='k75mxso'), Comment(id='k72htco'), Comment(id='k75m1du'), Comment(id='k75oswy'), Comment(id='k75si4y'), Comment(id='k75oako')]"
17iztuz,julkar9,,2023-10-29 10:08:06+00:00,False,,False,True,True,False,/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,Python package for statistical data animations," 

Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot are available but I am planning to add other plots as well like choropleths, temporal graphs, etc.

Also please let me know if you find any issue.

**Pynimate** is available on [pypi](https://pypi.org/project/pynimate/).

[github](https://github.com/julkaar9/pynimate), [documentation](https://julkaar9.github.io/pynimate/)

Quick usage

    import pandas as pd
    from matplotlib import pyplot as plt
    
    import pynimate as nim
    
    df = pd.DataFrame(
        {
            ""time"": [""1960-01-01"", ""1961-01-01"", ""1962-01-01""],
            ""Afghanistan"": [1, 2, 3],
            ""Angola"": [2, 3, 4],
            ""Albania"": [1, 2, 5],
            ""USA"": [5, 3, 4],
            ""Argentina"": [1, 4, 5],
        }
    ).set_index(""time"")
    
    cnv = nim.Canvas()
    bar = nim.Barhplot.from_df(df, ""%Y-%m-%d"", ""2d"")
    bar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(""%b, %Y""))
    cnv.add_plot(bar)
    cnv.animate()
    plt.show()

&#x200B;

https://i.redd.it/27xu9yip74xb1.gif

A little more complex example

&#x200B;

https://i.redd.it/kycvoy4u74xb1.gif

(note: I am aware that animating line plots generally doesn't make any sense)",datascience,https://www.reddit.com/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,23,170,0.98,"[Comment(id='k6xqb6s'), Comment(id='k6xvjd1'), Comment(id='k6xt68g'), Comment(id='k6xp8x1'), Comment(id='k6yj44t'), Comment(id='k704o09'), Comment(id='k7067ku'), Comment(id='k71yrb7'), Comment(id='k72faoy'), Comment(id='k7356mo'), Comment(id='k7001wx'), Comment(id='k717fdg'), Comment(id='k6xqe6n'), Comment(id='k6xwwlc'), Comment(id='k6xwx8q'), Comment(id='k6y5g0s'), Comment(id='k6xq5bk'), Comment(id='k6ym971'), Comment(id='k721dup'), Comment(id='k705p7v'), Comment(id='k6y9f93'), Comment(id='k70e0f9'), Comment(id='k71toq9')]"
17ju0z8,David202023,,2023-10-30 13:58:48+00:00,False,,False,False,True,False,/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,"What is the best way to access computation power for a pet project on small LMMs and BERT fine-tuning, without spending a fortune?","I'm a data scientist with a pet project that could turn into something more, but I need more computation power. I have a PC with an RTX 2060 SUPER, but it's getting old. I'm considering Colab Pro+, but I prefer to work with VS Code and build my projects as folders rather than notebooks. I've also explored cloud options, but they seem expensive. My last resort is to buy a refurbished 16GB V100, but I'm hoping to find a more affordable solution.",datascience,https://www.reddit.com/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,8,1,0.6,"[Comment(id='k76t7jq'), Comment(id='k782qol'), Comment(id='k73usat'), Comment(id='k77adk9'), Comment(id='k774pd1'), Comment(id='k78q23k'), Comment(id='k78q5qu'), Comment(id='k78pl28')]"
17jg3hh,Careful_Engineer_700,,2023-10-29 23:46:52+00:00,False,,False,False,True,False,/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,Identifying time series patterns advice,"Hey you guys, I have something I am stuck at and need your advice.

Long story shirt in example:
Customer A: likes to buy at the beginning of the month only
Customer B: likes to buy at the end of each week when visited by an agent because he stocks
Customer C: likes to buy at the beginning, middle and end of the month.

And so on, you kinda get the problem.

I want to be able to identify this and I was thinking of a possible solution but I think it lacks experience: Decompose the seasonal component of each retailer’s time series and then cluster retailers whom purchasing seasonal components are similar with kmeans?

If you think this approach is invalid, please feel free to suggest something I could read.

Thanks.",datascience,https://www.reddit.com/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,9,1,0.6,"[Comment(id='k72egfp'), Comment(id='k74wuzi'), Comment(id='k72qrhr'), Comment(id='k73bum9'), Comment(id='k73rx8j'), Comment(id='k73xrfj'), Comment(id='k754e81'), Comment(id='k754xa2'), Comment(id='k759vzi')]"
17ie7f0,NewEcho2940,,2023-10-28 13:49:59+00:00,False,,False,False,True,False,/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,PSA: Don’t become DS. Be a DA instead.,"I’ve been on this board for a few years and noticed a trend. Many people saying they got a MS in DS and complain they only do excel or simple models. Recently, I see a lot of people saying they can’t get DS jobs. Here is the thing, most businesses need a lot more DA then DS. There are so many more basic data needs then complex ones. Most companies I’ve worked for have a ratio of about 5:1 DA to DS. Unless you’re a really strong and savvy DS candidate (smarter then me) you’re probably better off doing DA or SWE. I am a DS director and I spend 80% of my time doing DE and DA because that’s what the business needs.",datascience,https://www.reddit.com/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,199,460,0.88,"[Comment(id='k6tlm99'), Comment(id='k6tl4pi'), Comment(id='k6ttpbm'), Comment(id='k6u8yt4'), Comment(id='k6tzdlj'), Comment(id='k6tk1ei'), Comment(id='k6u1zis'), Comment(id='k6tv8ow'), Comment(id='k6u3gmn'), Comment(id='k6tm3fd'), Comment(id='k6tpglh'), Comment(id='k6tpi2g'), Comment(id='k6tsk72'), Comment(id='k6u73ih'), Comment(id='k6uj199'), Comment(id='k6ucnhd'), Comment(id='k6w13mh'), Comment(id='k6y7xfu'), Comment(id='k74glgf'), Comment(id='k6toj2y'), Comment(id='k6try18'), Comment(id='k6tpm2t'), Comment(id='k6vghy5'), Comment(id='k6u8a3x'), Comment(id='k6x4jlj'), Comment(id='k6ty411'), Comment(id='k6ueyyf'), Comment(id='k6umue4'), Comment(id='k6utesc'), Comment(id='k6v1z99'), Comment(id='k6vap6g'), Comment(id='k6vgiea'), Comment(id='k6vgivn'), Comment(id='k6vpdns'), Comment(id='k6wuglz'), Comment(id='k6xfapb'), Comment(id='k6yj6il'), Comment(id='k6zpbgv'), Comment(id='k72h2pu'), Comment(id='k731r5v'), Comment(id='k731rob'), Comment(id='k745efe'), Comment(id='k79qthh'), Comment(id='k7d8e9a'), Comment(id='k7dg8w0'), Comment(id='k7dj8s4'), Comment(id='k7ezm0a'), Comment(id='k7smu82'), Comment(id='k6to9dt'), Comment(id='k6ulq8e'), Comment(id='k6uwivi'), Comment(id='k6upktf'), Comment(id='k6urjwq'), Comment(id='k6vw0z5'), Comment(id='k72twjq'), Comment(id='k6u0x8s'), Comment(id='k6vlrw0'), Comment(id='k74zz2y'), Comment(id='k6tvj0u'), Comment(id='k6tleck'), Comment(id='k6tn3kl'), Comment(id='k6u631c'), Comment(id='k6u18ia'), Comment(id='k6umfu4'), Comment(id='k6xd5jn'), Comment(id='k6tug77'), Comment(id='k6uo3iy'), Comment(id='k6u34k0'), Comment(id='k6u7k63'), Comment(id='k6yz2qr'), Comment(id='k72ue6m'), Comment(id='k6u9p9l'), Comment(id='k6v2dif'), Comment(id='k728h8o'), Comment(id='k6tm6fa'), Comment(id='k6u58wr'), Comment(id='k6tle41'), Comment(id='k6u24tb'), Comment(id='k6v2mqe'), Comment(id='k6u7z46'), Comment(id='k6up0l6'), Comment(id='k6u9i3t'), Comment(id='k6tu9sc'), Comment(id='k6tvrwd'), Comment(id='k6uu8pt'), Comment(id='k6tsrjn'), Comment(id='k6x4lb9'), Comment(id='k6whp5j'), Comment(id='k7e0s7k'), Comment(id='k6twyeq'), Comment(id='k6vx2s5'), Comment(id='k6u4v5x'), Comment(id='k762lin'), Comment(id='k74tm6j'), Comment(id='k6vjenk'), Comment(id='k6w2yxn'), Comment(id='k70xy8d'), Comment(id='k6vyfpy'), Comment(id='k73472u'), Comment(id='k6vxaru'), Comment(id='k6vyrv2'), Comment(id='k6w7gr4'), Comment(id='k6tupps'), Comment(id='k6to1gy'), Comment(id='k6tp3mw'), Comment(id='k6tmlbb'), Comment(id='k6wnca0'), Comment(id='k6tu793'), Comment(id='k6u1s3p'), Comment(id='k6up7i8'), Comment(id='k6vk82g'), Comment(id='k6ulumy'), Comment(id='k6y3chd'), Comment(id='k6u87pd'), Comment(id='k6udvhm'), Comment(id='k6v5hb3'), Comment(id='k6tmsf5'), Comment(id='k6v15nt'), Comment(id='k6ttp6d'), Comment(id='k6wqsyw'), Comment(id='k6z47lt'), Comment(id='k6utmkq'), Comment(id='k6u3uqu'), Comment(id='k6ugr6s'), Comment(id='k6u1ror'), Comment(id='k6vco3l'), Comment(id='k6u14k8'), Comment(id='k6u3dmt'), Comment(id='k6tzeu1'), Comment(id='k6w08u8'), Comment(id='k6w3t8d'), Comment(id='k6xbofk'), Comment(id='k6zvfr6'), Comment(id='k6wg0vf'), Comment(id='k6ua0tw'), Comment(id='k6trkha'), Comment(id='k6u4qch'), Comment(id='k6todyc'), Comment(id='k6u7y9n'), Comment(id='k6tt5om'), Comment(id='k6u5u5h'), Comment(id='k6tu02d'), Comment(id='k6tt1fv'), Comment(id='k6tvjzx'), Comment(id='k742wra'), Comment(id='k6tn6a1'), Comment(id='k6woqbq'), Comment(id='k6u4rik'), Comment(id='k6u6i00'), Comment(id='k6u5dpg'), Comment(id='k6ur3lt'), Comment(id='k6vrm81'), Comment(id='k6yz7dg'), Comment(id='k6uijr6'), Comment(id='k6uie27'), Comment(id='k6z06ka'), Comment(id='k6toi2p'), Comment(id='k6truz0'), Comment(id='k6z6iu9'), Comment(id='k6uedjv'), Comment(id='k6u4jjc'), Comment(id='k71mxsv'), Comment(id='k6zyjyg'), Comment(id='k6y3csp'), Comment(id='k6zzwm9'), Comment(id='k6ubbxz'), Comment(id='k6uh2gd'), Comment(id='k6u50ib'), Comment(id='k6u99wf'), Comment(id='k6uowyp'), Comment(id='k6u1692'), Comment(id='k6uctc4'), Comment(id='k6uqqco'), Comment(id='k74qw8j'), Comment(id='k6uboss'), Comment(id='k6u6oci'), Comment(id='k6ue1ia'), Comment(id='k6ujsoh'), Comment(id='k6tv9ke'), Comment(id='k6v8ws6'), Comment(id='k6uebbz'), Comment(id='k6uor85'), Comment(id='k6ulcxc'), Comment(id='k6ueqm7'), Comment(id='k6up3zu'), Comment(id='k6uqjpi'), Comment(id='k6usrix'), Comment(id='k6ujins'), Comment(id='k6u6ytn'), Comment(id='k6u8cmv'), Comment(id='k6uhow4'), Comment(id='k6ujn68'), Comment(id='k77x36u'), Comment(id='k6uqa8h'), Comment(id='k6uodnc'), Comment(id='k6u9mlf'), Comment(id='k6uohl1'), Comment(id='k6vb6fc'), Comment(id='k6uooyn'), Comment(id='k6ur10x'), Comment(id='k6vl86y'), Comment(id='k6uv3iu')]"
17isfkx,evavibes,,2023-10-29 01:39:34+00:00,False,,False,False,True,False,/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,How’s the DA job market looking for people with experience?,"I’ve started applying around for data analyst roles this week and was wondering how people with 1-3 years experience are doing with their job searches

Asking since most posts on here are either like “no experience how do I break in” posts or like PhD data scientists with not much in between",datascience,https://www.reddit.com/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,33,27,0.83,"[Comment(id='k6wplfc'), Comment(id='k6x0s5r'), Comment(id='k6wufpg'), Comment(id='k6wglz3'), Comment(id='k6yea0l'), Comment(id='k6yjw55'), Comment(id='k7f152g'), Comment(id='k6wvo7o'), Comment(id='k6wovgd'), Comment(id='k6xstyt'), Comment(id='k6y28gh'), Comment(id='k6zno3b'), Comment(id='k70jx8g'), Comment(id='k6wukfz'), Comment(id='k715kb8'), Comment(id='k6x80mc'), Comment(id='k711jsk'), Comment(id='k7c8l9i'), Comment(id='k6yb635'), Comment(id='k6wqjv8'), Comment(id='k6wvhgy'), Comment(id='k6x3yqs'), Comment(id='k6wj4ej'), Comment(id='k6wqpb1'), Comment(id='k715o0v'), Comment(id='k6yfk62'), Comment(id='k6wzzcv'), Comment(id='k6yxbl9'), Comment(id='k6wmsun'), Comment(id='k6wwcq7'), Comment(id='k73pxl6'), Comment(id='k6wng6s'), Comment(id='k6wos5k')]"
17ih595,Yourteararedelicious,,2023-10-28 16:16:49+00:00,False,,1698511649.0,False,True,False,/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,"What would you classify my job as? DS, DA, DE, Glorified Excel Monkey","Officially I am a Data Scientist. I try to understand my value or worth outside of the government.

What I don't do:
AI, ML, modeling. 

What I do:
Develop new data pipelines,
Data exploration,
Produce data and dashboards from policy and new concepts,
Python, R, SQL, Databricks.


I feel a DS should be doing ML at minimum but our business needs are fast and dirty and the data is dirty. Dirty data = Dirty results is how I view ML stuff.

Edit: Punctuation because I forgot about Reddits mobile formats lol",datascience,https://www.reddit.com/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,69,85,0.9,"[Comment(id='k6u7zaa'), Comment(id='k6ujk6l'), Comment(id='k6u8sko'), Comment(id='k6ukucy'), Comment(id='k6ub0uc'), Comment(id='k6uxws5'), Comment(id='k6urkv5'), Comment(id='k6w13hv'), Comment(id='k6u9odn'), Comment(id='k6ulfc8'), Comment(id='k6uvu7z'), Comment(id='k6v65yo'), Comment(id='k72937l'), Comment(id='k6uq4dr'), Comment(id='k6vo9cz'), Comment(id='k6u7wya'), Comment(id='k6v87hp'), Comment(id='k6ux713'), Comment(id='k6vaeip'), Comment(id='k6vykqn'), Comment(id='k6yj8pu'), Comment(id='k6xcmwm'), Comment(id='k6xq06c'), Comment(id='k6xxnn1'), Comment(id='k7196vl'), Comment(id='k731soy'), Comment(id='k73dg10'), Comment(id='k775ch1'), Comment(id='k79rq1y'), Comment(id='k7c94i2'), Comment(id='k7sob10'), Comment(id='k6uja8w'), Comment(id='k6uyfl0'), Comment(id='k6wx34m'), Comment(id='k781e82'), Comment(id='k6uad5g'), Comment(id='k6votjs'), Comment(id='k6v96ia'), Comment(id='k70ax2i'), Comment(id='k6wbp0l'), Comment(id='k6un220'), Comment(id='k6ue14p'), Comment(id='k71gkc3'), Comment(id='k6uz8zk'), Comment(id='k6wlbg5'), Comment(id='k6uzl57'), Comment(id='k6va4fa'), Comment(id='k6uba6j'), Comment(id='k6wltk1'), Comment(id='k6uye0q'), Comment(id='k6vexql'), Comment(id='k6x6nvz'), Comment(id='k6vd9a8'), Comment(id='k73ib48'), Comment(id='k73dtt0'), Comment(id='k794ego'), Comment(id='k71hd32'), Comment(id='k6v1ywn'), Comment(id='k6vdkyx'), Comment(id='k6vv96v'), Comment(id='k71jott'), Comment(id='k6v8u4y'), Comment(id='k6vf4an'), Comment(id='k6vvgtb'), Comment(id='k6xojep'), Comment(id='k71kfkk'), Comment(id='k6vosd3'), Comment(id='k6w1u9y'), Comment(id='k6w71hs')]"
17ivru4,shar72944,,2023-10-29 05:04:29+00:00,False,,False,False,True,False,/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,Taking over new role as DS manager,"Not sure if the topic is allowed, but I would like to take opinions from senior data scientists and Analytics managers.

I work in finance as data scientist and work involves preparing data in required format,
Doing analysis and building models for products that we have in market , like propensity models for credit cards , credit risk models etc. 
I have worked as an individual contributor till now and have 5 years of experience. I have never managed anyone but have mentored and led few projects individually. 
I have a new offer for an analytics manager with a well known bank and I'll have to manage 6-7 data analysts/scientists and be responsible for the team’s performance. 

The pay jump is decent (40 percent higher than I currently make) and location is much closer to my home.
I don't have any problems with my current job and people I work with are also great. 

I was thinking if anyone else made that jump. 
Is the transition too steep from not managing anyone to 6-7 people?",datascience,https://www.reddit.com/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,13,8,0.83,"[Comment(id='k6x773o'), Comment(id='k6xey7d'), Comment(id='k6y0k4p'), Comment(id='k6z9f9t'), Comment(id='k70glpl'), Comment(id='k6yn8lm'), Comment(id='k71kk5v'), Comment(id='k6xf8zq'), Comment(id='k6xf3k9'), Comment(id='k6y1wes'), Comment(id='k6y249o'), Comment(id='k6zmh9j'), Comment(id='k73s2ig')]"
17ixgz7,charlesowo445,,2023-10-29 07:10:28+00:00,False,,False,False,True,False,/r/datascience/comments/17ixgz7/guesstimates/,Guesstimates,"Is there any book , podcast y'all can recommend  to study guesstimatation problem",datascience,https://www.reddit.com/r/datascience/comments/17ixgz7/guesstimates/,3,2,0.67,"[Comment(id='k6xhkgn'), Comment(id='k70iv0a'), Comment(id='k70song')]"
17huxxq,Vanishing-Rabbit,,2023-10-27 19:07:12+00:00,False,,False,False,True,False,/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,Didn't realize how insane the market is,"I work at FAANG as a DS manager. Opened up a Data Science position. Less than 24 hours later there were 1000+ applicants. 

I advertised the position on LinkedIn 

It's absolutely crazy. People have managed to get a hold of my personal and professional email address (I don't have these as public but they're a logical combination of first/last name).

I hired in the past, I have never seen anything like this.",datascience,https://www.reddit.com/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,239,706,0.96,"[Comment(id='k6q3ktn'), Comment(id='k6q1hi8'), Comment(id='k6pzvmt'), Comment(id='k6q3cgt'), Comment(id='k6q261o'), Comment(id='k6q5klj'), Comment(id='k6q04he'), Comment(id='k6q3v7d'), Comment(id='k6q9ttx'), Comment(id='k6q9vt4'), Comment(id='k6qjl2a'), Comment(id='k6q8qla'), Comment(id='k6qrpyb'), Comment(id='k6q3wb0'), Comment(id='k6q1ct8'), Comment(id='k6rcow8'), Comment(id='k6q2slq'), Comment(id='k6q5uth'), Comment(id='k6qhp5u'), Comment(id='k6q6uce'), Comment(id='k6spvbb'), Comment(id='k6qukmj'), Comment(id='k6q7e3e'), Comment(id='k6qmq0q'), Comment(id='k6qrhzm'), Comment(id='k6qwojb'), Comment(id='k6r72zf'), Comment(id='k6syi1t'), Comment(id='k6ueupk'), Comment(id='k6v1m02'), Comment(id='k6zp2r6'), Comment(id='k6r8l7i'), Comment(id='k6s9c03'), Comment(id='k6q62bp'), Comment(id='k6q6dup'), Comment(id='k6q9uqz'), Comment(id='k6qdbgu'), Comment(id='k6qniu3'), Comment(id='k6qr0kl'), Comment(id='k6rb63e'), Comment(id='k6rf75j'), Comment(id='k6rg5ql'), Comment(id='k6rm2o6'), Comment(id='k6rnaqr'), Comment(id='k6rnmx9'), Comment(id='k6s3o86'), Comment(id='k6s4oy8'), Comment(id='k6sdnw8'), Comment(id='k6sgl5n'), Comment(id='k6sn5ud'), Comment(id='k6sv0zl'), Comment(id='k6t0tn1'), Comment(id='k6t4h4h'), Comment(id='k6t73n8'), Comment(id='k6tc39c'), Comment(id='k6ton3t'), Comment(id='k6u8cdz'), Comment(id='k6u8pyq'), Comment(id='k6v5ec7'), Comment(id='k6v81vc'), Comment(id='k6vbrhr'), Comment(id='k6xk87y'), Comment(id='k6xso7r'), Comment(id='k6y7wps'), Comment(id='k6yjazr'), Comment(id='k70axkp'), Comment(id='k73wvsv'), Comment(id='k79173x'), Comment(id='k79x0uw'), Comment(id='k7c7rb7'), Comment(id='k7dgfed'), Comment(id='k7dj23f'), Comment(id='k7ezdjf'), Comment(id='k7smxup'), Comment(id='k6qq8a1'), Comment(id='k6q7xeu'), Comment(id='k6qmbme'), Comment(id='k6rhzg4'), Comment(id='k6qu8ul'), Comment(id='k6ryncv'), Comment(id='k6w4gpi'), Comment(id='k6t6p98'), Comment(id='k6wc0bt'), Comment(id='k6zkoto'), Comment(id='k6rf5t3'), Comment(id='k6qq1pg'), Comment(id='k6q64jj'), Comment(id='k6qjtnk'), Comment(id='k6rmqeg'), Comment(id='k6v4w6r'), Comment(id='k6q9jvv'), Comment(id='k6q9wv9'), Comment(id='k6qfub7'), Comment(id='k6q6msi'), Comment(id='k6qgsi5'), Comment(id='k6r64rm'), Comment(id='k6rjrek'), Comment(id='k6rs6bc'), Comment(id='k6qqmtg'), Comment(id='k6q3fov'), Comment(id='k6q85za'), Comment(id='k6qqedz'), Comment(id='k6qg7c6'), Comment(id='k6qh47g'), Comment(id='k6r6p8g'), Comment(id='k6sbbaq'), Comment(id='k6w3u5i'), Comment(id='k6qsmlo'), Comment(id='k6sr0sk'), Comment(id='k6styxx'), Comment(id='k6rfbrt'), Comment(id='k6s9o89'), Comment(id='k6t53gb'), Comment(id='k6qrk75'), Comment(id='k6sbts2'), Comment(id='k6qaypi'), Comment(id='k6qfv66'), Comment(id='k6rfh3p'), Comment(id='k6sbo83'), Comment(id='k6t7vu6'), Comment(id='k6vabl0'), Comment(id='k6sbvym'), Comment(id='k6tz0r7'), Comment(id='k6tl9vs'), Comment(id='k6ti3kw'), Comment(id='k6wc2yq'), Comment(id='k6sii1i'), Comment(id='k6qcit1'), Comment(id='k6qnjpz'), Comment(id='k6qzlwa'), Comment(id='k71pd4h'), Comment(id='k6qaa30'), Comment(id='k6sm12z'), Comment(id='k75oxkm'), Comment(id='k6s3f7o'), Comment(id='k6srf2c'), Comment(id='k6qufr6'), Comment(id='k6t0otl'), Comment(id='k6t6y2o'), Comment(id='k6rx26v'), Comment(id='k6qqcbk'), Comment(id='k6r1vtk'), Comment(id='k6qb4uj'), Comment(id='k6twx5q'), Comment(id='k6qctzq'), Comment(id='k6qd2s7'), Comment(id='k6st9ht'), Comment(id='k6qm30w'), Comment(id='k6qn07z'), Comment(id='k6teg6g'), Comment(id='k6q6128'), Comment(id='k6q8xt4'), Comment(id='k75ssb9'), Comment(id='k6qtvex'), Comment(id='k6tl1do'), Comment(id='k6srakx'), Comment(id='k6t1bm4'), Comment(id='k6ux74n'), Comment(id='k6sc2z3'), Comment(id='k6qhnky'), Comment(id='k6qfgpg'), Comment(id='k6qdbcr'), Comment(id='k6se71j'), Comment(id='k6tlpat'), Comment(id='k6t7xkc'), Comment(id='k6tzk6w'), Comment(id='k73w1kr'), Comment(id='k75sxo4'), Comment(id='k6t3v74'), Comment(id='k6qjsbq'), Comment(id='k6r5txy'), Comment(id='k70sdv1'), Comment(id='k6to8ig'), Comment(id='k75qdig'), Comment(id='k6w4n2m'), Comment(id='k6qqppf'), Comment(id='k6ujyfs'), Comment(id='k6savox'), Comment(id='k6uvpt9'), Comment(id='k71afe1'), Comment(id='k6qfe65'), Comment(id='k6sxrnn'), Comment(id='k6rci8z'), Comment(id='k6r6fd4'), Comment(id='k6qmms7'), Comment(id='k6q97f4'), Comment(id='k6qi19x'), Comment(id='k6qusx8'), Comment(id='k6vbje7'), Comment(id='k6sc7yi'), Comment(id='k6qi8p9'), Comment(id='k6qg87n'), Comment(id='k6w34d4'), Comment(id='k6t9r3h'), Comment(id='k791gl8'), Comment(id='k6qlilb'), Comment(id='k6t44li'), Comment(id='k6uuca6'), Comment(id='k719cpx'), Comment(id='k6ttrv4'), Comment(id='k75yuug'), Comment(id='k6qt2u5'), Comment(id='k6ulz81'), Comment(id='k6sq9zw'), Comment(id='k6qshn9'), Comment(id='k6qlp8t'), Comment(id='k6qozd4'), Comment(id='k6qhbwc'), Comment(id='k6ri0f9'), Comment(id='k6rij0y'), Comment(id='k6qudwc'), Comment(id='k6qkb0p'), Comment(id='k6scequ'), Comment(id='k6qr7hw'), Comment(id='k75rqdi'), Comment(id='k6qvdxt'), Comment(id='k6vrrr8'), Comment(id='k6troeo'), Comment(id='k6tvc2s'), Comment(id='k767jax'), Comment(id='k6uowaj'), Comment(id='k6si68m'), Comment(id='k6spp76'), Comment(id='k6rjgr9'), Comment(id='k6vz533'), Comment(id='k6scmlz'), Comment(id='k6qwl4m'), Comment(id='k6vw17b'), Comment(id='k6tx4c8'), Comment(id='k6v57k1'), Comment(id='k6wzqhc'), Comment(id='k6scrwv'), Comment(id='k6vb7rk'), Comment(id='k6xom5k'), Comment(id='k6u1p1j'), Comment(id='k6v7u6z'), Comment(id='k6z86by'), Comment(id='k6sdea4'), Comment(id='k6z1mmt'), Comment(id='k6zinpl'), Comment(id='k6sdjdf'), Comment(id='k70lpaz')]"
17ih45v,stryder517,,2023-10-28 16:15:17+00:00,False,,False,False,True,False,/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,Learning resources for a new DS manager?,"**Tl;dr -** Soon to be transferring over to a DS manager role from an analytics manager, and I do NOT want to be *that* leader. What are some recommended MOOCs, videos, books that can boost my technical knowledge over the next 2-3 months.

I have been on the analytics side for ~10 years, and have a strong foundation of SQL, python, data viz, and analysis, and a solid knowledge of math/stats (can still be improved). I’m lacking in the ML and deployment space, and have a couple months to study up here. Any strong recommendations of courses, videos, or problem sets to work through? (Books are also great, but I am painfully slow and may be more efficient with another medium). Thanks in advance.",datascience,https://www.reddit.com/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,5,5,0.86,"[Comment(id='k6uh5tm'), Comment(id='k6zv740'), Comment(id='k7beqtc'), Comment(id='k6uksgl')]"
17imqvk,whispertoke,,2023-10-28 20:48:46+00:00,False,,False,False,True,False,/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,"D.S. / Analytics Directors, What Tools Do You Use to Organize Your Work & Knowledge?",Curious what people are using to keep track of projects and general data/process documentation,datascience,https://www.reddit.com/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,11,2,0.62,"[Comment(id='k6vpxvu'), Comment(id='k6wcdya'), Comment(id='k6vdak5'), Comment(id='k6wl783'), Comment(id='k6ztazx'), Comment(id='k6ztxe0'), Comment(id='k6wwnn0'), Comment(id='k6zurbs'), Comment(id='k6ztidp'), Comment(id='k6xxf8s'), Comment(id='k6zue1d')]"
17i4ikr,Frosty_Pitch9052,,2023-10-28 02:58:39+00:00,False,,False,False,True,False,/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,When do you select features to use for your model?,"My issue is about doing EDA before or after feature selection. For example. say I have a dataset with tons and tons of features. Am I expected to analyze each and every feature in the dataset before choosing features or can I choose features that ""may"" matter based on logic and examine them there?",datascience,https://www.reddit.com/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,22,11,0.83,"[Comment(id='k6rtysn'), Comment(id='k6s99xh'), Comment(id='k6tkllz'), Comment(id='k6u9blb'), Comment(id='k6sw0r1'), Comment(id='k6tlga7'), Comment(id='k6uk08q'), Comment(id='k6v2bj9'), Comment(id='k6sg6nl'), Comment(id='k6stqhr'), Comment(id='k6wcp8a'), Comment(id='k7b4a9e'), Comment(id='k6yjxhy'), Comment(id='k6tnytw'), Comment(id='k6tpxiu'), Comment(id='k6tyvfd'), Comment(id='k6twnca'), Comment(id='k6ui59r'), Comment(id='k6uc2cw'), Comment(id='k6whxro'), Comment(id='k6ym0f7'), Comment(id='k76puaj')]"
17htzx6,tinkerpal,,2023-10-27 18:24:06+00:00,False,,1698431669.0,False,True,False,/r/datascience/comments/17htzx6/what_skills_should_data_scientist_with_1_yoe_is/,What skills should Data Scientist with 1 YOE is expected to know?,"I have completed over one year at my company as a Data Scientist. As a data scientist with master’s degree( in electrical and computer engineering) and 1 YOE, I was thinking about my career progress and was wondering if  my learning curve is good or bad. 

My experience so far at my company has been

 - developing a ML model( text classification model ) 
- lot of data manipulation and exploratory data analysis using sql , python and excel 
- using visualization tools like tableau 
- working with clustering algos and neural networks ( these models are existing and I haven’t developed).

But I don’t know model deployment, automation, parallelization and a lot more.

From the conversations in my team, I really feel overwhelmed by the amount of expertise and inputs they have and I do think it is with experience. But sometimes I wonder if I’m just underprepared and I have to improve but don’t know what resources to look at since from the experience I had so far, the code structure and everything is different. 

What was your experience ? Any tips and resources anyone can guide to?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17htzx6/what_skills_should_data_scientist_with_1_yoe_is/,12,32,0.85,"[Comment(id='k6q2oqh'), Comment(id='k6rovhz'), Comment(id='k6r3fev'), Comment(id='k6pykon'), Comment(id='k6sx9i4'), Comment(id='k6qza91'), Comment(id='k6q9w5g'), Comment(id='k6q5k38'), Comment(id='k6ycmmv'), Comment(id='k6yjcwm'), Comment(id='k6sw4mf'), Comment(id='k6rmdnz')]"
17hlvki,No_Constant8367,,2023-10-27 11:56:21+00:00,False,,False,False,True,False,/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,How to get better at PowerPoint?,"Unfortunately I have realised that at most jobs 80 percent of my time is spent on Ppt and 5 percent on the actual analysis. I was working in consulting and the best associates were the ones who could make the best presentations. Even at McKinsey, Bain etc my friends seem to mostly involved in making decks all day long. How do I get better at ppt? 
I used to feel that ppt would get redundant and hence didn’t really focus on it. Is it worth it to devote time in learning how to make beautiful ppts or is it a dying software and even investment banking and consulting will shift to something more sane/ AI will make it easy to make excellent ppts?",datascience,https://www.reddit.com/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,41,40,0.83,"[Comment(id='k6o75ab'), Comment(id='k6o9aao'), Comment(id='k6oj7nc'), Comment(id='k6pomni'), Comment(id='k6oh4q4'), Comment(id='k6oi10t'), Comment(id='k6qx6dt'), Comment(id='k6ogtlz'), Comment(id='k6o76in'), Comment(id='k6p73j2'), Comment(id='k6p9d24'), Comment(id='k6qjlg9'), Comment(id='k6rl2ya'), Comment(id='k6rq9me'), Comment(id='k6s1r0a'), Comment(id='k7sn5rw'), Comment(id='k6pcwkq'), Comment(id='k6pqluz'), Comment(id='k6ooxqz'), Comment(id='k6q95fd'), Comment(id='k6vqsdr'), Comment(id='k6zhf5c'), Comment(id='k6svo6b'), Comment(id='k701q41'), Comment(id='k6o8rol'), Comment(id='k6q1h44'), Comment(id='k6pi0gy'), Comment(id='k6pdiom'), Comment(id='k6peqpu'), Comment(id='k6s1ubr'), Comment(id='k6pxkge'), Comment(id='k6t80jl'), Comment(id='k705iim'), Comment(id='k73svd6'), Comment(id='k6ob94q'), Comment(id='k6ox3rx'), Comment(id='k6q51x2'), Comment(id='k6ptcsd'), Comment(id='k76vbhh'), Comment(id='k6onpd2'), Comment(id='k6pvsks')]"
17i2wn6,WadeEffingWilson,,2023-10-28 01:28:38+00:00,False,,False,False,True,False,/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,Has anyone successfully used Chernoff faces in any type of analysis (not including what they are and how they convey information)?,"I was reading through the supplemental material at the end of Blindsight and discovered that Chernoff faces are real. The in-story explanation that human brains are hardwired to read faces and the amount of information that can be encoded into them is suitable for higher dimensional (~18) data, especially given that the subconscious is more adept at processing complex problems than the conscious mind, is interesting enough of a concept, so discovering that it's real makes it even better.

I'm interested to see if they have been utilized before and if they still are in certain industries or niches (outside of customer satisfaction surveys and Wong-Baker scales). The fact that it can encode a high number of dimensions has piqued my interest to see if they can be used successfully and how difficult they are to interpret, for both analysts/statisticians and non-technical parties (stakeholders).",datascience,https://www.reddit.com/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,0,3,1.0,[]
17hicpp,NipponPanda,,2023-10-27 07:47:09+00:00,False,,False,False,True,False,/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,How much time do you guys spend in PowerPoint?,"I know this question might be a bit controversial to some but lately I've found myself spending an ungodly amount of time creating slides instead of doing other tasks.

Management wants each new project or idea laid out in meticolous detail in a PowerPoint before signing off on it and granting any type of access to data. Which means I need to create some really good looking PPT decks to even get the chance to explore our available data, it's quite frustrating and I'd rather spend the time doing something else.

By detail I mean like, budget, development timeline, target audience, documentation, blabla, before I even get a chance to look at the data and determine if it's useable in the first place.

Anyone else have this problem?",datascience,https://www.reddit.com/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,104,66,0.96,"[Comment(id='k6nl6gs'), Comment(id='k6npn85'), Comment(id='k6np1az'), Comment(id='k6nw2ak'), Comment(id='k6ns1gy'), Comment(id='k6o64pb'), Comment(id='k6nro8s'), Comment(id='k6o3uqf'), Comment(id='k6oxkas'), Comment(id='k6nnelj'), Comment(id='k6oedcj'), Comment(id='k6nqbu6'), Comment(id='k6nx3vc'), Comment(id='k6ofsf8'), Comment(id='k6ozcac'), Comment(id='k6pdxb5'), Comment(id='k6po7vh'), Comment(id='k6nk6v9'), Comment(id='k6o46i6'), Comment(id='k6nznly'), Comment(id='k6om7v4'), Comment(id='k6nxr6p'), Comment(id='k6o7kgd'), Comment(id='k6o83jg'), Comment(id='k6ocj8o'), Comment(id='k6ofa9n'), Comment(id='k6ofxef'), Comment(id='k6oh88w'), Comment(id='k6onr55'), Comment(id='k6ooyvr'), Comment(id='k6osddd'), Comment(id='k6our5j'), Comment(id='k6owl2g'), Comment(id='k6oysyd'), Comment(id='k6p47hi'), Comment(id='k6p805b'), Comment(id='k6p886t'), Comment(id='k6pcgn6'), Comment(id='k6pzhzc'), Comment(id='k6q0xis'), Comment(id='k6qtgd1'), Comment(id='k6rjv82'), Comment(id='k6sicv1'), Comment(id='k6yjelg'), Comment(id='k725b6v'), Comment(id='k731wji'), Comment(id='k73x9lq'), Comment(id='k7dglre'), Comment(id='k7ey00p'), Comment(id='k6nqf5g'), Comment(id='k6nsmne'), Comment(id='k6ppwxl'), Comment(id='k6ongwf'), Comment(id='k6pq1ro'), Comment(id='k6orthz'), Comment(id='k6olxqi'), Comment(id='k6omid1'), Comment(id='k6p6k8l'), Comment(id='k6q8imx'), Comment(id='k6nktny'), Comment(id='k6nlol2'), Comment(id='k6o0uep'), Comment(id='k6omcqo'), Comment(id='k6q790t'), Comment(id='k6oc2z5'), Comment(id='k6on583'), Comment(id='k6q6kcp'), Comment(id='k6oeget'), Comment(id='k6oqbea'), Comment(id='k6oe2dn'), Comment(id='k6ntimt'), Comment(id='k6rbpt9'), Comment(id='k6onttu'), Comment(id='k6pcbs4'), Comment(id='k6p6b91'), Comment(id='k6q8b2z'), Comment(id='k6op3zz'), Comment(id='k6pzvc8'), Comment(id='k6qhmbj'), Comment(id='k6rjlkj'), Comment(id='k6q5gno'), Comment(id='k6rc08n'), Comment(id='k6qcyco'), Comment(id='k6ouedv'), Comment(id='k6q6f4v'), Comment(id='k6qzvpi'), Comment(id='k6qg0hr'), Comment(id='k6p03lr'), Comment(id='k6r9wbg'), Comment(id='k6qig4a'), Comment(id='k6p4urz'), Comment(id='k6phi48'), Comment(id='k6qjsai'), Comment(id='k6q60pe'), Comment(id='k6qkv98'), Comment(id='k6qmrhs'), Comment(id='k6qox54'), <MoreComments count=0, children=[]>]"
17hvuft,Renatus_Cartesius,,2023-10-27 19:49:10+00:00,False,,False,False,True,False,/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,Good book on Bayesian statistics?,"From the perspective of someone who has absorbed the frequentist approach pretty well, and is comfortable with it, could you recommend a good book on Bayesian statistics?

Ideally with a focus on A/B testing.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,19,6,0.8,"[Comment(id='k6q7dgv'), Comment(id='k6qacqo'), Comment(id='k6qgme5'), Comment(id='k6xd10s'), Comment(id='k6rgmnd'), Comment(id='k6v2tmb'), Comment(id='k6z7fhr'), Comment(id='k731ywo'), Comment(id='k73204n'), Comment(id='k73ya9a'), Comment(id='k7bu9hf'), Comment(id='k76q0k2'), Comment(id='k6ukelw'), Comment(id='k7a4bni'), Comment(id='k6v9uu8'), Comment(id='k77dnb5'), Comment(id='k7ab5fg'), Comment(id='k7agr5i')]"
17h9xpo,Accurate_Green_7001,,2023-10-26 23:32:34+00:00,False,,False,False,True,False,/r/datascience/comments/17h9xpo/what_is_considered_a_highvalue_data_scientist_and/,"What is considered a ""high-value"" data scientist and how do you become one?","I'm a data scientist with a 2 years of experience. I've realised recently that all of my projects in industry follow the same basic blueprint which I learnt years ago:

1. Think of how to best frame the problem so it can be solved using data science.
2. Clean and process the data.
3. Extract features which give the highest accuracy
4. Sticking it into an sklearn algorithm and hoping it has good accuracy (or whatever metric is important for that specific problem).
5. If it has bad accuracy, redo step 3 or get more data. If it has good metrics, done.

My issue is: anyone who has done a data science boot camp can easily reproduce these steps. Coding in R and Python is super easy, especially nowadays with libraries like sklearn.

* Is a data scientist considered ""high-value"" because of step 1? Or is it the fact that they have lots of ideas about how something can be modelled which goes beyond the ""traditional"" models? 
* If it is the latter, is the only way to create more complex models to just gain more experience with a variety of problems, and coming across new techniques whilst researching? I find that I don't even know about the existence of many techniques unless it's pointed out to me by colleagues.

By ""complex"" model. I don't mean complicating the algorithm a model uses for the sake of it. I'm referring to a more robust model that takes more variables into account.

As data scientists get more experienced, in which ways can they provide more value to a business compared to say, an intern, who could probably do all the steps listed above relatively easily?",datascience,https://www.reddit.com/r/datascience/comments/17h9xpo/what_is_considered_a_highvalue_data_scientist_and/,96,242,0.95,"[Comment(id='k6mlkhv'), Comment(id='k6mj9uh'), Comment(id='k6n3yyg'), Comment(id='k6m0745'), Comment(id='k6mycrr'), Comment(id='k6n3grn'), Comment(id='k6mcbce'), Comment(id='k6moam1'), Comment(id='k6ngrwv'), Comment(id='k6mrk3h'), Comment(id='k6n23sz'), Comment(id='k6n2atc'), Comment(id='k6o0alh'), Comment(id='k6m18y4'), Comment(id='k6mke2m'), Comment(id='k6moij5'), Comment(id='k6m3x8t'), Comment(id='k6nfkio'), Comment(id='k6o30hn'), Comment(id='k6oi5k3'), Comment(id='k6oug3l'), Comment(id='k6mdafu'), Comment(id='k6m7usb'), Comment(id='k6mvtjl'), Comment(id='k6ng0rp'), Comment(id='k6mdmx5'), Comment(id='k6mlbbx'), Comment(id='k6mps7m'), Comment(id='k6nawrr'), Comment(id='k6o2i4s'), Comment(id='k6o8tm2'), Comment(id='k6omhy4'), Comment(id='k6ot8zt'), Comment(id='k6p831p'), Comment(id='k6pbhhx'), Comment(id='k6pir9f'), Comment(id='k6pwt0q'), Comment(id='k6px772'), Comment(id='k6qclf5'), Comment(id='k6qh79w'), Comment(id='k6qhl1u'), Comment(id='k6v2wl4'), Comment(id='k7h5fsd'), Comment(id='k6nfvxj'), Comment(id='k6otaa6'), Comment(id='k6mqeqd'), Comment(id='k6obrft'), Comment(id='k6op9mi'), Comment(id='k6r5i8m'), Comment(id='k6n1172'), Comment(id='k6nvsmo'), Comment(id='k6mm4av'), Comment(id='k6odfyk'), Comment(id='k6pwhlx'), Comment(id='k6odp2v'), Comment(id='k6p7hjh'), Comment(id='k6rexpb'), Comment(id='k6m0tgs'), Comment(id='k6mjjg5'), Comment(id='k6n939g'), Comment(id='k6o4npa'), Comment(id='k6n8p4z'), Comment(id='k6n4bsc'), Comment(id='k6n9szc'), Comment(id='k6mzdwf'), Comment(id='k6rfhdt'), Comment(id='k6n2bvw'), Comment(id='k6p725r'), Comment(id='k6olto3'), Comment(id='k6mz4zl'), Comment(id='k6m7xrv'), Comment(id='k6mvxx5'), Comment(id='k6o2kk1'), Comment(id='k6ofjxe'), Comment(id='k6otomw'), Comment(id='k6n395u'), Comment(id='k6plkuj'), Comment(id='k6mocsv'), Comment(id='k6nc131'), Comment(id='k6p8385'), Comment(id='k6qg06c'), Comment(id='k6qeecs'), Comment(id='k6qffgl'), Comment(id='k6sf7j1'), Comment(id='k6nt8uu'), Comment(id='k6pccrq'), Comment(id='k6mdqsh'), Comment(id='k6p0iap'), Comment(id='k6oh1em'), Comment(id='k6ouyw7'), Comment(id='k6ocyef'), Comment(id='k6riy2u'), Comment(id='k6pqctj'), Comment(id='k6pd37a'), Comment(id='k70o4ef'), Comment(id='k6ntn4v')]"
17hwt1l,Judessaa,,2023-10-27 20:33:27+00:00,False,,False,False,True,False,/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,What are your duties as a Data Scientist?,"Please elaborate on this. 

Including your role at the company, your day to day tasks, tools and languages you’re using. 

Thank you in advance!",datascience,https://www.reddit.com/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,6,4,0.63,"[Comment(id='k6qldnw'), Comment(id='k6qkq30'), Comment(id='k6s734j'), Comment(id='k6s749j'), Comment(id='k6s98v7'), Comment(id='k6tdmhl')]"
17hy5hl,Fine_Night_,,2023-10-27 21:34:52+00:00,False,,False,False,True,False,/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,Been put to investigate bugs for new project but no prior exp,"Hi there!

I’m working as a Data Analyst in my company and in my team we mostly use SQL and Tableau. I’ve mostly just used these two and Python (via Jupyter notebooks) on occasion to perform data cleaning /transformation for adhoc data sets.

So recently been covering for some other employee and have seemingly gotten myself into potentially being the one having to fix some potential bugs in a ML based Flask application that predicts product prices based on different conditions.

This is made up of 3 GitHub repos:
The model, the data pipelines and a Jupyter notebook containing code related to KMeans.


The data pipeline and model repos contain lots of Python source files with around 1000-1500 lines per file. All in all there could be easily more than 20,000 lines of code. I know this is not a lot but I don’t have experience in dealing with such large code bases.


I don’t have background in ML or product development (I previously worked as a IT BA 2-3 years back before transitioning to a DA role after having used SQL/Tableau for a few years, there is a separate BI team in the company but I’m in a data analyst specific team). 

My question is would it be common for DAs to be called to debug large complex ML web apps? I haven’t seen this in other companies previously. I would have thought this would fall on the product development teams or ML Engineers etc.

And what is the best way for me to start off getting used to the code base and understanding what everything does? The project certainly looks interesting and would make a good entry for me to a ML engineer role in the future or product development role but I’m nervous especially since my probation is ending in 2 weeks and I really don’t wanna f up. There’s no documentation or requirements documented except for a high level architecture diagram of the system.

Looking for advice thanks!



TL:DR;
A data analyst with no experience in product development put in charge to fix bugs for a large ML web app, looking for tips on how best to understand the code base and perform testing especially when there’s no documentation available for this app besides a high level architecture diagram. Also, wondering if it’s common for a data analysts to be asked to debug large ML web applications (flask based).",datascience,https://www.reddit.com/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,10,3,1.0,"[Comment(id='k6qt6j8'), Comment(id='k6t15ps'), Comment(id='k6rd56q'), Comment(id='k6t2ou7'), Comment(id='k6rt88u'), Comment(id='k6swcjx'), Comment(id='k6sxyd1'), Comment(id='k6t2x3t'), Comment(id='k6t8yuc'), Comment(id='k6tojyo')]"
17hj3ea,Slow_Act_4114,,2023-10-27 08:45:01+00:00,False,,False,False,True,False,/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,Usefulness of Six-Sigma,How useful would y'all rate a Six-Sigma certification?,datascience,https://www.reddit.com/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,49,31,0.85,"[Comment(id='k6o8iwn'), Comment(id='k6o2edv'), Comment(id='k6o9j4k'), Comment(id='k6owpmh'), Comment(id='k6og0s5'), Comment(id='k6ocofa'), Comment(id='k6ocugd'), Comment(id='k6np4n2'), Comment(id='k6on7cy'), Comment(id='k6pde3g'), Comment(id='k6oquz7'), Comment(id='k6p9kcs'), Comment(id='k6pxygt'), Comment(id='k6o6cmm'), Comment(id='k6or7l2'), Comment(id='k6p0stl'), Comment(id='k6npvvi'), Comment(id='k6oemqf'), Comment(id='k6omfwk'), Comment(id='k6ox5ku'), Comment(id='k6pduzf'), Comment(id='k6pmxek'), Comment(id='k6pwm72'), Comment(id='k6reyxd'), Comment(id='k6sxbgn'), Comment(id='k6tuyxr'), Comment(id='k6xgakh'), Comment(id='k6yjftz'), Comment(id='k7lo4hk'), Comment(id='k6ocqyh'), Comment(id='k6ol10f'), Comment(id='k6pqeyn'), Comment(id='k6pxyis'), Comment(id='k6sy9ih'), Comment(id='k6ocugb'), Comment(id='k6p51wf'), Comment(id='k6omb9v'), Comment(id='k6opo8r'), Comment(id='k6sq3xd'), Comment(id='k6q1zuq'), Comment(id='k6tzmmt'), Comment(id='k6oe8p2'), Comment(id='k6pdnp0'), Comment(id='k6ox38b'), Comment(id='k6q090p'), Comment(id='k6q5m7q'), Comment(id='k6oyjda'), Comment(id='k6q8za9'), Comment(id='k6pii8e')]"
17ht5l1,engkhaledeisa,,2023-10-27 17:46:33+00:00,False,,False,False,True,False,/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,Where I can find projects to contribute in?,"I took courses about pentaho,tableau and machine learning ...where I can find projects with open issues so I can solve it and increase my ability to solve problems in this career ..like open source android or web projects on github with open issues ....is there a specific website for data that I can contribute in and this contribution will have a positive effect in my c.v?",datascience,https://www.reddit.com/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,2,3,0.8,"[Comment(id='k6tbsd0'), Comment(id='k6x7s6p')]"
17h7eav,math_stat_gal,,2023-10-26 21:37:31+00:00,False,,False,False,True,False,/r/datascience/comments/17h7eav/finally/,Finally!,"Hey fellow data folks - Finally, after 17 months of applying for jobs, I’ve found one. The job title is strange, the pay is nothing to brag about (thanks Canada!) but I’m 100% certain of the positive impact it is going to have in my mental health. 

I’m so relieved and nervous and scared but also excited. 

It is tough out there but nothing else to be done other than try! 

Thanks for hearing me out.",datascience,https://www.reddit.com/r/datascience/comments/17h7eav/finally/,20,73,0.96,"[Comment(id='k6loeiy'), Comment(id='k6lloue'), Comment(id='k6mev5j'), Comment(id='k6po8j3'), Comment(id='k7bet1i'), Comment(id='k7exwzt'), Comment(id='k6nfzzu'), Comment(id='k7exw4y'), Comment(id='k6lo6n9'), Comment(id='k7f1r63'), Comment(id='k6lpmcp'), Comment(id='k6mzz2s'), Comment(id='k6lr5vn'), Comment(id='k6n0azt'), Comment(id='k6mjnyd'), Comment(id='k6mjxyd'), Comment(id='k6mla9g'), Comment(id='k6n3gvg'), Comment(id='k6n0hq0')]"
17h40ok,pg860,,2023-10-26 19:10:24+00:00,False,,1698394526.0,False,True,False,/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,Why Gradient Boosted Decision Trees are so underappreciated in the industry?,"GBDT allow you to iterate very fast, they require no data preprocessing, enable you to incorporate business heuristics directly as features, and immediately show if there is explanatory power in features in relation to the target.

On tabular data problems, they outperform Neural Networks, and many use cases in the industry have tabular datasets.

Because of those characteristics, [they are winning solutions to all tabular competitions on Kaggle](https://jobs-in-data.com/blog/data-science-skills#sota-ml-models).

And yet, somehow they are not very popular.

On the chart below, I summarized learnings from 9,261 job descriptions crawled from 1605 companies in Jun-Sep 2023 (source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist))

LGBM, XGboost, Catboost (combined together) are the 19th mentioned skill, e.g. with Tensorflow being x10 more popular.

It seems to me Neural Networks caught the attention of everyone, because of the deep-learning hype, which is justified for image, text, or speech data, but not justified for tabular data, which still represents many use - cases.

https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&format=png&auto=webp&s=b06cd263e22eb229a6be2df890faba7639d895d7

EDIT \[Answering the main lines of critique\]:

1/ ""Job posting descriptions are written by random people and hence meaningless"":

Granted, there is for sure some noise in the data generation process of writing job descriptions.

But why do those random people know so much more about deep learning, keras, tensorflow, pytorch than GBDT? In other words, why is there a systematic trend in the noise? When the noise has a trend, it ceases to be noise.

Very few people actually did try to answer this, and I am grateful to them, but none of the explanations seem to be more credible than the statement that GBDTs are indeed underappreciated in the industry.

2/ ""I myself use GBDT all the time so the headline is wrong""This is availability bias. The single person's opinion (or 20 people opinion) vs 10.000 data points.

3/ ""This is more the bias of the Academia""

The job postings are scraped from the industry.

However, I personally think this is the root cause of the phenomenon. Academia shapes the minds of industry practitioners. GBDTs are not interesting enough for Academia because they do not lead to AGI. Doesn't matter if they are super efficient and create lots of value in real life.",datascience,https://www.reddit.com/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,115,99,0.77,"[Comment(id='k6l0acr'), Comment(id='k6l7uca'), Comment(id='k6kwkht'), Comment(id='k6ljk8t'), Comment(id='k6l4w6b'), Comment(id='k6l0jx4'), Comment(id='k6lpo4e'), Comment(id='k6lll29'), Comment(id='k6l8g0e'), Comment(id='k6kzdjz'), Comment(id='k6llh98'), Comment(id='k6l6wl3'), Comment(id='k6lej19'), Comment(id='k6odiq6'), Comment(id='k6lco0z'), Comment(id='k6lsec8'), Comment(id='k6mh15t'), Comment(id='k6l9m2l'), Comment(id='k6m2dkd'), Comment(id='k6m2nck'), Comment(id='k6m5xhk'), Comment(id='k6nnh4q'), Comment(id='k6nxahn'), Comment(id='k6o4aws'), Comment(id='k6o70i5'), Comment(id='k6pdw8a'), Comment(id='k6q7slz'), Comment(id='k6r0kod'), Comment(id='k6redh8'), Comment(id='k6rezbe'), Comment(id='k6u93tz'), Comment(id='k6uyjj4'), Comment(id='k6ldzpo'), Comment(id='k6liat2'), Comment(id='k6lg5xv'), Comment(id='k6nylyr'), Comment(id='k6lgc6k'), Comment(id='k6maeib'), Comment(id='k6m98qq'), Comment(id='k6kxefo'), Comment(id='k6los02'), Comment(id='k6vmlrl'), Comment(id='k6li1cs'), Comment(id='k6l7flo'), Comment(id='k6luzdq'), Comment(id='k6llmdm'), Comment(id='k6l85tt'), Comment(id='k6lhuq1'), Comment(id='k6lqcoa'), Comment(id='k6lmq7w'), Comment(id='k6mrn1f'), Comment(id='k6rh14h'), Comment(id='k6l4upd'), Comment(id='k6l6cp3'), Comment(id='k6m17dz'), Comment(id='k6r2zgu'), Comment(id='k6l8jey'), Comment(id='k6lec1h'), Comment(id='k6lgh3i'), Comment(id='k6pwsh0'), Comment(id='k6lwfgf'), Comment(id='k6u0q4a'), Comment(id='k6m91kn'), Comment(id='k6lokm8'), Comment(id='k6ou0m5'), Comment(id='k6lqvhq'), Comment(id='k6ok4xg'), Comment(id='k6lz3wk'), Comment(id='k6n3mqo'), Comment(id='k6lfz7w'), Comment(id='k6mgxyj'), Comment(id='k6m1l1c'), Comment(id='k6lfbyr'), Comment(id='k6nx6wh'), Comment(id='k6llhuz'), Comment(id='k6lxwb6'), Comment(id='k6pxfso'), Comment(id='k6mg1zn'), Comment(id='k6mmkf9'), Comment(id='k6lp4kw'), Comment(id='k6lsuyc'), Comment(id='k6lzo49'), Comment(id='k6m00e7'), Comment(id='k6lh10g'), Comment(id='k6llr33'), Comment(id='k6ly2ni'), Comment(id='k6pzleh'), Comment(id='k6mgnbl'), Comment(id='k6lpowq'), Comment(id='k6m01pv'), Comment(id='k6lhw2v'), Comment(id='k6qyr3y'), Comment(id='k6lpwvl'), Comment(id='k6m06ri'), Comment(id='k6lize0'), Comment(id='k6lq76w'), Comment(id='k6ljn0h'), Comment(id='k6lqqnr'), Comment(id='k6lkb95'), Comment(id='k6ltijm'), Comment(id='k6lkpbm'), Comment(id='k6lxopx'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
17gyevz,Prestigious_Belt4965,,2023-10-26 14:57:39+00:00,False,,False,False,True,False,/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,"I'm a 'data analyst' who in practice is actually just a software engineer. Was I bamboozled, or did I misunderstand the role","my first job was as a consultant, doing a mix of implementation and data analytics. 

then i switched to a new job with the data analyst title, but I'm building production R scripts almost exclusively now; not a huge fan of wrangling with my team's complex/sparsely commented codebase and designing 'systems' (our scripts have to integrate with a variety of outside data sources).

I miss doing 'investigations', eg how do we better optimize this product, make more revenue, etc. now it feels like I'm an underpaid backend software engineer (making 85k but seems most SWEs are earning 100k+).

is data analytics in 2023 more similar to SWE? should I have expected this?",datascience,https://www.reddit.com/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,89,172,0.94,"[Comment(id='k6jrewc'), Comment(id='k6jovj7'), Comment(id='k6jstfs'), Comment(id='k6k169c'), Comment(id='k6jpjpo'), Comment(id='k6k7x9m'), Comment(id='k6k1jan'), Comment(id='k6jximi'), Comment(id='k6kr4w3'), Comment(id='k6k9z1r'), Comment(id='k6ki4cw'), Comment(id='k6keuuh'), Comment(id='k6k52rt'), Comment(id='k6l1w5n'), Comment(id='k6kb94r'), Comment(id='k6kdty9'), Comment(id='k6kdx4t'), Comment(id='k6kpbci'), Comment(id='k6kcy53'), Comment(id='k6jzl5w'), Comment(id='k6jx3d3'), Comment(id='k6kf6y2'), Comment(id='k6kb4k9'), Comment(id='k6km2pj'), Comment(id='k6kmjfq'), Comment(id='k6ktflm'), Comment(id='k6l0kyx'), Comment(id='k6lbkyb'), Comment(id='k6lc0yq'), Comment(id='k6ljs2k'), Comment(id='k6lqurr'), Comment(id='k6lqxvs'), Comment(id='k6lwdyn'), Comment(id='k6lzdzg'), Comment(id='k6m0puu'), Comment(id='k6m5hx5'), Comment(id='k6mqogz'), Comment(id='k6n6y4v'), Comment(id='k6noqka'), Comment(id='k733msb'), Comment(id='k78veze'), Comment(id='k6l0pd8'), Comment(id='k6nglpj'), Comment(id='k6n9j3o'), Comment(id='k6ki2dy'), Comment(id='k6k9get'), Comment(id='k6k5xwc'), Comment(id='k6khohz'), Comment(id='k7dew60'), Comment(id='k6kaa20'), Comment(id='k6l7s1x'), Comment(id='k6kch6l'), Comment(id='k6kbzx0'), Comment(id='k6nonhq'), Comment(id='k6ohjer'), Comment(id='k6kkotp'), Comment(id='k6ken5a'), Comment(id='k6kig5f'), Comment(id='k6k6lf7'), Comment(id='k6kiecf'), Comment(id='k6kcaib'), Comment(id='k6kmy5r'), Comment(id='k6lxwgx'), Comment(id='k6kgc5w'), Comment(id='k6kkzd6'), Comment(id='k6kltxx'), Comment(id='k6kjgwf'), Comment(id='k6kfmc0'), Comment(id='k6ke2hv'), Comment(id='k6kohfp'), Comment(id='k6l9ter'), Comment(id='k6koge2'), Comment(id='k6kocb6'), Comment(id='k6m0l9e'), Comment(id='k6kkhs3'), Comment(id='k6tmv7t'), Comment(id='k6kqsm2'), Comment(id='k6l14ei'), Comment(id='k6ltnad'), Comment(id='k6mkhqi'), Comment(id='k6m1fnf'), Comment(id='k6klspw'), Comment(id='k6kktbi'), Comment(id='k6uh9cv'), Comment(id='k6krw4h'), Comment(id='k6mrz3m'), Comment(id='k6kmgmv'), Comment(id='k6l7v09'), Comment(id='k6lbxjh'), Comment(id='k6lvvlz'), <MoreComments count=0, children=[]>]"
17gujdu,Maimonatorz,,2023-10-26 11:42:01+00:00,False,,False,False,True,False,/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,What are some good examples of catastrophic AI failures?,"I've recently did some searches about AI failures, the most catastrophic failure I read about was when [Zillow had to fire 2000 employees](https://www.geekwire.com/2021/zillow-shutter-home-buying-business-lay-off-2k-employees-big-real-estate-bet-falters/). 

I also saw some articles like this [one](https://www.science.org/doi/10.1126/science.aax2342), about biases in health algorithms, but all in all I didn't see much examples that had a measure of how much damage was actually done.

Are there more examples of AI failures on a large scale?",datascience,https://www.reddit.com/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,66,89,0.95,"[Comment(id='k6jguvn'), Comment(id='k6jvbmd'), Comment(id='k6jb394'), Comment(id='k6jnij4'), Comment(id='k6kgy1u'), Comment(id='k6j9oot'), Comment(id='k6jmyod'), Comment(id='k6jvtb1'), Comment(id='k6kldi6'), Comment(id='k6kdrig'), Comment(id='k6jwoye'), Comment(id='k6jdgtn'), Comment(id='k6koq2k'), Comment(id='k6l67de'), Comment(id='k6lujxx'), Comment(id='k6m4lxf'), Comment(id='k6mjs4n'), Comment(id='k6mxqz1'), Comment(id='k6my0u3'), Comment(id='k6jj1yk'), Comment(id='k6jxys8'), Comment(id='k6jkt4d'), Comment(id='k6lsrjj'), Comment(id='k6ne3hk'), Comment(id='k6l3z4k'), Comment(id='k6lbyib'), Comment(id='k6mff53'), Comment(id='k6mft4a'), Comment(id='k6ouvr4'), Comment(id='k6jkmfe'), Comment(id='k6llbrl'), Comment(id='k6lhdzw'), Comment(id='k6kb1wx'), Comment(id='k6lq5u5'), Comment(id='k6l49f6'), Comment(id='k6me8fx'), Comment(id='k6ntgxj'), Comment(id='k6jl481'), Comment(id='k6naxfy'), Comment(id='k6pkluv'), Comment(id='k6klgaa'), Comment(id='k6jp71y'), Comment(id='k6odhpd'), Comment(id='k6n1nzg'), Comment(id='k6p4riw'), Comment(id='k6jhsw5'), Comment(id='k6jmw0a'), Comment(id='k6l5asg'), Comment(id='k6jisvs'), Comment(id='k6m5521'), Comment(id='k6jmyfk'), Comment(id='k6l49ir'), Comment(id='k6k74u9'), Comment(id='k6jlonn'), Comment(id='k6n1995'), Comment(id='k6ljpni'), Comment(id='k6jmq54'), Comment(id='k6kq6cs'), Comment(id='k6k64ns'), Comment(id='k6jnj9v'), Comment(id='k6kacj0'), Comment(id='k6l2my0'), Comment(id='k6o3fn0'), Comment(id='k6jrbzn'), Comment(id='k6o2l87'), Comment(id='k6jxci3'), Comment(id='k6ltl4s')]"
17hh6i7,daftpunkapi,,2023-10-27 06:22:26+00:00,False,,False,False,True,False,/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,Streaming Data Observability & Quality,"We have been exploring the space of ""Streaming Data Observability & Quality"". We do have some thoughts and questions and would love to get members view on them. 

**Q1.** Many vendors are shifting left by moving data quality checks from the warehouse to Kafka / messaging systems. What are the benefits of shifting-left ?

**Q2.** Can you rank the feature set by importance (according to you) ? What other features would you like to see in a streaming data quality tool ?

* Broker observability & pipeline monitoring (events per second, consumer lag etc.)
* Schema checks and Dead Letter Queues (with replayability)
* Validation on data values (numeric distributions & profiling, volume, freshness, segmentation etc.)
* Stream lineage to perform RCA

**Q3.** Who would be an ideal candidate (industry, streaming scale, team size) where there is an urgent need to monitor, observe and validate data in streaming pipelines?  


https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&format=pjpg&auto=webp&s=c1b368112465cfa5be67258dd2a52313cdb4cdb6",datascience,https://www.reddit.com/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,0,2,0.75,[]
17hv82d,blacksnowboader,,2023-10-27 19:20:35+00:00,False,,False,False,True,False,/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,What is the worst case of PHDitis that you have seen?,Title,datascience,https://www.reddit.com/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,26,0,0.38,"[Comment(id='k6q1xjo'), Comment(id='k6r909p'), Comment(id='k6r9l0o'), Comment(id='k6qjjl9'), Comment(id='k6q2uu3'), Comment(id='k6uh36z'), Comment(id='k6qdbix'), Comment(id='k6qfokh'), Comment(id='k6qog98'), Comment(id='k6t4453'), Comment(id='k6tebbh'), Comment(id='k6rekrs'), Comment(id='k6qk564'), Comment(id='k6qqflx'), Comment(id='k757tme'), Comment(id='k6ulkjv'), Comment(id='k6qkazg'), Comment(id='k6qpj64'), Comment(id='k6uy462'), Comment(id='k6v2bmc'), Comment(id='k6qkhfw'), Comment(id='k6qkrxk'), Comment(id='k6r1cvx'), Comment(id='k6qqyii'), Comment(id='k6qlkej'), Comment(id='k6qmc79')]"
17h8k9y,exodusgg,,2023-10-26 22:28:41+00:00,False,,False,False,True,False,/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,Machine Learning projects on jupyter,"Hello everyone,

Im a recent Data Science graduate and experimenting with different machine learning models on a various datasets from kaggle. The idea is to be more comfortable with tensorflow (& other libaries) and different datasets. 

Im doing all this on jupyter notebook, is there a tool data scientist use to publish their work. I want to create a online portfolio which i can showcase the different ML implementations in interviews and to recruiters. 

Im using github but was wondering if there specific tools or practices of data scientists which i might aswell implement in my workflow

Thanks",datascience,https://www.reddit.com/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,13,6,0.8,"[Comment(id='k6m6kiv'), Comment(id='k6nfn5r'), Comment(id='k6v2mdo'), Comment(id='k6xt7hw'), Comment(id='k6ns9eq'), Comment(id='k6ogg69'), Comment(id='k6otnus'), Comment(id='k6owyxc'), Comment(id='k6p2ki3'), Comment(id='k6p5plp'), Comment(id='k6pvc8v'), Comment(id='k6q0u1l'), Comment(id='k6qadyp')]"
17gx6q4,NewManufacturer3888,,2023-10-26 13:59:51+00:00,False,,False,False,True,False,/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,"What is the most unique, out of the box, or exciting application of DS you’ve used/thought of?","Can be in work, as a passion project/academic project, or just an idea. Was it successful? If not, why not? Would love to be inspired & motivated by all of your experiences, and who knows, maybe it’ll help someone think about a current project in a new way.",datascience,https://www.reddit.com/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,16,21,0.89,"[Comment(id='k6kktmh'), Comment(id='k6jilk1'), Comment(id='k6ke80k'), Comment(id='k6jlip7'), Comment(id='k6jugx8'), Comment(id='k6lue0f'), Comment(id='k6n4vxq'), Comment(id='k6n70rf'), Comment(id='k6u9sgk'), Comment(id='k6jun0m'), Comment(id='k6l5vdg'), Comment(id='k6l69bm'), Comment(id='k6jy1ha'), Comment(id='k6k0vpv'), Comment(id='k6nht0y'), Comment(id='k6l5rab')]"
17hfao4,smart_cat_22,,2023-10-27 04:17:42+00:00,False,,False,False,True,False,/r/datascience/comments/17hfao4/what_skills_should_i_gain_to_be_a_full_stack_data/,"What skills should I gain to be a ""Full Stack Data Scientist""?",,datascience,https://www.reddit.com/r/datascience/comments/17hfao4/what_skills_should_i_gain_to_be_a_full_stack_data/,3,1,0.67,"[Comment(id='k6otrye'), Comment(id='k6p539h'), Comment(id='k6u6t8p')]"
17go3pk,furioncruz,,2023-10-26 04:13:19+00:00,False,,False,False,True,False,/r/datascience/comments/17go3pk/ab_test_in_real_life/,A/B test in real life,"My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn't conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. 

Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?",datascience,https://www.reddit.com/r/datascience/comments/17go3pk/ab_test_in_real_life/,39,75,0.98,"[Comment(id='k6ir3rp'), Comment(id='k6hzxra'), Comment(id='k6ijdtq'), Comment(id='k6iwobo'), Comment(id='k6jjj1c'), Comment(id='k6llapn'), Comment(id='k6j2hfs'), Comment(id='k6igkjn'), Comment(id='k6n9gfe'), Comment(id='k6lymf2'), Comment(id='k6j6wgx'), Comment(id='k6n7onk'), Comment(id='k6i2kuf'), Comment(id='k6in1v1'), Comment(id='k6iyaxe'), Comment(id='k6j2b00'), Comment(id='k6novgy'), Comment(id='k6pam5l'), Comment(id='k6norb7'), Comment(id='k6j2su4'), Comment(id='k6inqev'), Comment(id='k6no7o6'), Comment(id='k6nonp1'), Comment(id='k6i4eec'), Comment(id='k6lt3j0'), Comment(id='k6iuhzr'), Comment(id='k6jc94s'), Comment(id='k6jgjro'), Comment(id='k6k1gc7'), Comment(id='k6iqh9u'), Comment(id='k6pdean'), Comment(id='k6j9xaa'), Comment(id='k6jtwy5'), Comment(id='k6nv3ie'), Comment(id='k6i62a2'), Comment(id='k6ky92f'), Comment(id='k6jkn3a'), Comment(id='k6nwcqq'), Comment(id='k6l4sq6')]"
17h7ri5,No_Match_7225,,2023-10-26 21:53:39+00:00,False,,False,False,True,False,/r/datascience/comments/17h7ri5/data_science_student_advice/,Data science student advice,"Hey guys so I was told that as a data science student I should do things like leetcode as a hobby to help me out to land internships and to make it look better when looking for jobs, I currently have 0 experience in the field, 0 internships, so what could I do to make me stand out in this market? I’m set to graduate may 2024.",datascience,https://www.reddit.com/r/datascience/comments/17h7ri5/data_science_student_advice/,4,3,0.67,"[Comment(id='k6lv9zo'), Comment(id='k6mp3kh'), Comment(id='k7c8pvj'), Comment(id='k7ksfnj')]"
17h0uio,soupqueen6869,,2023-10-26 16:47:45+00:00,False,,False,False,True,False,/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,What website do I use to make a portfolio?,Hi! I’m applying to data science/ analytics jobs and internships right now. I have extensive personal and academic projects that I need to put in an online portfolio for hiring managers to see. What do you all recommend for this? Thanks!,datascience,https://www.reddit.com/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,5,6,1.0,"[Comment(id='k6kboht'), Comment(id='k6l65ei'), Comment(id='k6mwfl9'), Comment(id='k6okodi'), Comment(id='k6ly4gq')]"
17h5xor,DhammaVicaya,,2023-10-26 20:33:27+00:00,False,,1698352658.0,False,True,False,/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,"Severance for US-based data science manager, director?",What is a typical severance package for manager or director of data science (or data engineering) for US companies. How many weeks severance per years tenure? What did yours look like?,datascience,https://www.reddit.com/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,10,2,0.75,"[Comment(id='k6mlrn5'), Comment(id='k6lbvs7'), Comment(id='k6qdvwz'), Comment(id='k6uywp4'), Comment(id='k6n1qrr'), Comment(id='k6oay0b'), Comment(id='k6ob2mf'), Comment(id='k6obyj6'), Comment(id='k6og33f'), Comment(id='k6om09j')]"
17gfqqp,Mackelday,,2023-10-25 21:32:31+00:00,False,,1698270328.0,False,True,False,/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,How to survive at nightmare employer?,"I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I'm slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?

Red flags include:

* No data / inaccessible data / data flying around in Excel
* Management is not ""ML literate""
* More work dealing with red tape than actual work
* 2x more managers than workers driving projects
* Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it
* No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.
* Because we work directly in prod, we don't have permission to save our processed data to tables or csv's - it must be done in memory every single day
* No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can't download unapproved libraries or pre-trained models without security review (even just for exploration)

My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025",datascience,https://www.reddit.com/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,72,134,0.95,"[Comment(id='k6gnkxd'), Comment(id='k6gn9sm'), Comment(id='k6gvxlr'), Comment(id='k6gz4zz'), Comment(id='k6gwlnj'), Comment(id='k6gy6ux'), Comment(id='k6gg0zp'), Comment(id='k6h729t'), Comment(id='k6girei'), Comment(id='k6i3sok'), Comment(id='k6htzrz'), Comment(id='k6ih65t'), Comment(id='k6gn6w8'), Comment(id='k6hm1fd'), Comment(id='k6hwj5z'), Comment(id='k6hwq3r'), Comment(id='k6hz3ct'), Comment(id='k6i6ns1'), Comment(id='k6i8599'), Comment(id='k6ifbip'), Comment(id='k6itjj6'), Comment(id='k6iwluk'), Comment(id='k6j06hn'), Comment(id='k6j0czn'), Comment(id='k6j24lb'), Comment(id='k6jgoaz'), Comment(id='k6jktiu'), Comment(id='k6jmqsl'), Comment(id='k6jmuxo'), Comment(id='k6jtq0x'), Comment(id='k6lg9h8'), Comment(id='k6ncr26'), Comment(id='k6nh6tp'), Comment(id='k7ewn3e'), Comment(id='k6kn1c0'), Comment(id='k6j1ebs'), Comment(id='k6ixfb8'), Comment(id='k6gyp0j'), Comment(id='k6j9qcm'), Comment(id='k6h2zki'), Comment(id='k6h4orh'), Comment(id='k6hnjit'), Comment(id='k6l2ng3'), Comment(id='k6h3gqh'), Comment(id='k6ji7gg'), Comment(id='k6it3xh'), Comment(id='k6gh12d'), Comment(id='k6ggxfu'), Comment(id='k6juuz8'), Comment(id='k6jbx1h'), Comment(id='k6ojj0c'), Comment(id='k6jcbyz'), Comment(id='k6k0u1o'), Comment(id='k6j8437'), Comment(id='k6km1ty'), Comment(id='k6j8yyk'), Comment(id='k6je9rd'), Comment(id='k6itqxy'), Comment(id='k6m3xhh'), Comment(id='k6gzkxd'), Comment(id='k6igwmw'), Comment(id='k6ghhgp'), Comment(id='k6ll39w'), Comment(id='k6ly1bx'), Comment(id='k6l4dw6'), Comment(id='k6gi8di'), Comment(id='k6gin55'), Comment(id='k6gyrwt'), Comment(id='k6gv3m8'), Comment(id='k6gk3ar'), Comment(id='k6gxvx3')]"
17h23wx,donhuell,,2023-10-26 17:45:08+00:00,False,,False,False,True,False,/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,"Is it just me, or is the requirements / specifications process a complete nightmare?","I find the data specifications / requirements process to be awful. It's legit one of my least favorite aspects of this job.

For context, I work in an academia-adjacent industry, and I'm typically working with subject matter research experts. They are responsible for writing programming specifications for our projects, which are supposed to serve as an outline for programming and development for the data science team. Sometimes PMs will write them as well. For ex. something like:


    1. Load data from [data source]
    2. Confirm variables `x`, `y`, and `z` are correct data types
    3. Merge data (outer join) with [other dataset]
    	a. output a table of merge %
    4. Deduplicate on ID variable
    5. Filter by ...
    6. etc.
    7. export files to [server location]

As a data scientist, I am supposed to generally follow these steps to produce the result we are looking for. If I disagree with a step, or need to add some logic, I'll go in to the document and edit it. So it's a shared responsibility between my team and the research / project management team. The above steps are a very simplified example - sometimes these types of requirement documents can be like 15 pages long, with a ton of rules and nested logic / requests.

These documents tend to be written in Microsoft Word, which is messy and hard to version control when working across large teams. It's very easy to miss updates and lose track of which specifications have changed.

I can't help but think this process could be so much cleaner and efficient.",datascience,https://www.reddit.com/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,1,3,1.0,[Comment(id='k6mgbyr')]
17gxa3v,Bunshin69,,2023-10-26 14:03:51+00:00,False,,False,False,True,False,/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,"Intro to Statistical Learning, With Applications in Python (ISLP) How long could it take to study this book?","Sorry if this is a weird question I just need what people with more experience think about my situation. For some context. I am doing a Master in Data Science but finished my degree in biology. I study full time but I have two other classes at the same time this semester. And one of my class is blasting through this book by giving a little over an hr lecture per chapter and plan to finish the book in a semester. It is clear to me the lectures don’t cover all the contents either does not cover some details or leave some parts out.  While you could absolutely give lectures like this, it does take some time to fully grasp all the concepts, especially when I have to do 2 other classes. I feel like I can’t keep up so just wondering how long people here take to study it if they did or if they are familiar with it, hopefully can tell me if what I am feeling is natural within the context I provided or if it is because of my lack of experience in programming. Do I need to get more of my shit together? Or should I feel less shit about having to catch up slower and investing more time hopefully during holidays and stuff.",datascience,https://www.reddit.com/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,14,4,0.75,"[Comment(id='k6jjlbc'), Comment(id='k6jlhsd'), Comment(id='k6kogyd'), Comment(id='k6v6v98'), Comment(id='k6yi71i'), Comment(id='k723s9l'), Comment(id='k7snd6w'), Comment(id='k6jwiid'), Comment(id='k6kdlzv'), Comment(id='k6n7m0o'), Comment(id='k6kpkrx'), Comment(id='k6n90l7'), Comment(id='k6n77t2')]"
17gtqqz,First_Beginning6365,,2023-10-26 10:51:37+00:00,False,,False,False,True,False,/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/,How are data science interviews for entry level different from senior level (L5-L6). How is the interview preparation different?,,datascience,https://www.reddit.com/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/,9,8,0.79,"[Comment(id='k6jlil7'), Comment(id='k6jlv5p'), Comment(id='k6lt7lr'), Comment(id='k6m26i0'), Comment(id='k6m2nyh'), Comment(id='k6nxpx2'), Comment(id='k6m3q5c'), Comment(id='k6o4k4h'), Comment(id='k6o4l0t')]"
17gyvk2,Eastern-Habit6458,,2023-10-26 15:19:24+00:00,False,,False,False,True,False,/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,Need guidance to publish a paper,"Hello All,

I am a student pursuing an MS in data science. I have done a few projects involving EDA and implemented a few ML algorithms. I am very enthusiastic about researching something and publishing a paper on it. However, I have no idea where to start or how to choose a research topic. Can someone among you guide me on this? At this point, I do not want to pursue a PhD but want to conduct independent research on a topic.",datascience,https://www.reddit.com/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,3,3,1.0,"[Comment(id='k6naoe0'), Comment(id='k7c8tc5'), Comment(id='k6wlj3t')]"
17h6bty,Practical-Wing-6143,,2023-10-26 20:50:56+00:00,False,,False,False,True,False,/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,Aspiring Data scientist who needs some guidance on a career path,"So I am currently a junior in school working towards a degree in applied and computational mathematics with a minor in cs, and I was wondering what type of opportunities I should be actively looking for and seeking out in order to be successful. I am trying to apply to data science internships but it is a bit harder this year and I'm not really getting any interviews.   
I am also kind of struggling on understanding what projects I should be doing because a lot of the requirements I see on job postings are very high level topics I just haven't learned yet. For example here is a list of common requirements I have seen:  


* Expertise in statistical methods and experimental design and analysis  
* Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning
* Deployment of microservices and data pipeline and monitoring the performance of Kubernetes application and Data infrastructure.
* Hands-on experience with experimentation design, A/B testing, or probabilistic modeling are a plus!
* Experience with mathematical modeling techniques (e.g., linear and integer programming, statistical modeling, system dynamics modeling) 
* Experience with quantitative analysis of complex systems, probability and statistics  
* Strong background/interest in experimentation, recommendation systems, & data visualization   


I haven't really taken courses on these, and getting started with projects using these high level topics is also pretty challenging since theres a learning curve. I'm just not sure what I should actively be doing since my applications are going nowhere and there's so many topics to learn and study on my own. Just looking for some guidance, any advice is welcome.",datascience,https://www.reddit.com/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,4,1,0.55,"[Comment(id='k6ljm5j'), Comment(id='k6ljxf2'), Comment(id='k6loaty'), Comment(id='k6mscpk')]"
17gwjgc,KamdynS7,,2023-10-26 13:28:36+00:00,False,,False,False,True,False,/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,Freelance Data Science in small businesses,"My brother-in-law(call him James) co-owns a small business with two of his colleagues who provide services to small businesses. These services include website design, marketing(everything from SEO optimization to email lists to whatever), and graphic design. James recently reached out to me to ask if I would do part-time work for them as a data analyst/data scientist. My background is in quantitative political science. I know how to do pretty much everything data scientists do at a low level (ML algorithms, acquiring data, cleaning data, etc.) but I don't know very well how to apply these techniques to a business. So from that, I have two questions: 

1. How are ML algorithms used for businesses? I'll give some examples of how I imagine it working. K-means clustering can be used for targeted advertisements based on the groups customers are put in. Linear regression can be used to predict sales based on some other independent variable. Decision trees can be used to determine what factors might lead to a customer discontinuing the use of a service. Am I on the correct track? Are these incorrect or are there others I am missing? I would love to hear about ways you guys use ML in your job. I know how to do A/B testing conceptually and do a ton of hypothesis testing in my work so that part of the job I am not worried about (and honestly looking at these two methods it seems they will be used more often than ML). 
2. Can data science even be done with small businesses? My main concern is about the quality of the data. It may require me to organize the data which could take a considerable amount of time and might venture into some data engineering spheres in which I really don't have experience. And then will there even be enough data? Is there some critical mass of sales that is needed before one can begin analyzing a company's metrics? I believe most of the people this service works with a smaller companies that might not have the robust data that F500 companies do. 

I hope these two questions make sense. I'm not trying to get quick and dirty information about data science. If I'm pointed in the direction of how to use these algorithms I can research them on my own. I just wanted some advice from people in the field. For reference, I use mostly Stata in my poli sci work, but I can do most of it in Python as well. Stata is just better for the small studies I do lol. ",datascience,https://www.reddit.com/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,7,3,0.71,"[Comment(id='k6jci38'), Comment(id='k6kfjfe'), Comment(id='k6jdham'), Comment(id='k6qv9ww'), Comment(id='k6lt096'), Comment(id='k6jes86'), Comment(id='k6o9m31')]"
17gum8s,Beginning-Scholar105,,2023-10-26 11:46:52+00:00,False,,False,False,True,False,/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,"If you really want to practice data science with real-world projects, then check out DataWars.","**Data science community, I'm here to tell you about a new platform that's going to revolutionize the way you learn data science: DataWars**

I've been using it for a few weeks now, and I'm absolutely blown away. It's the most immersive and hands-on way to learn data science that I've ever experienced.

With DataWars Live Labs, you can:

* Write code in real time and get immediate feedback on your progress.
* Validate your understanding of key concepts.
* Check the correctness of your code.
* Work on interactive projects that are designed to help you learn and practice.

If you're serious about learning data science, I highly recommend checking out DataWars Live Labs. It's the best way to learn quickly and master the skills you need to succeed.

**Here are a few specific things that I love about DataWars Live Labs:**

* The projects are really well-designed and engaging. They cover a wide range of topics, from Python, data cleaning, and wrangling to machine learning and much more.
* The feedback loop is instant. As you write code, you can see immediately whether it's working correctly. This makes it easy to learn from your mistakes and improve your skills quickly.
* Their Discord server is great.

Overall, I'm extremely impressed with DataWars. It's the best way to learn data science that I've ever used. I highly recommend it to anyone who wants to learn data science quickly and master the skills they need to succeed.",datascience,https://www.reddit.com/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,2,4,0.7,[Comment(id='k6nx197')]
17hbxka,Antique-Nothing-4315,,2023-10-27 01:14:02+00:00,False,,False,False,True,False,/r/datascience/comments/17hbxka/question/,Question,"Hello, g12 student here looking to apply to a university program, im an Ontario student wanting to apply to a Data Science program and I was wondering if the program and degree is worth it, or whether I should choose something else. What jobs would a bachelor's in Data Science degree open me up to? (ofc I will do my masters). What salary ranges typically are those jobs (Canada and US) and how much do you make as a Data Scientist/ML engineer etc. Is a comp sci program better than a Data Science program? can I get into ML engineering with a data sci degree?",datascience,https://www.reddit.com/r/datascience/comments/17hbxka/question/,0,0,0.2,[]
17h41a9,Samia_Tisha,,2023-10-26 19:11:07+00:00,False,,False,False,False,False,/r/datascience/comments/17h41a9/can_anyone_tell_me_if_the_machine_learning/,Can anyone tell me if the machine learning workflow is correct or not? Could anyone please refer to tutorials or blogs to learn the proper workflow? Any suggestions are welcome.,,datascience,/r/u_Samia_Tisha/comments/17h3xve/can_anyone_tell_me_if_the_machine_learning/,0,0,0.5,[]
17h3hj7,Suza_330,,2023-10-26 18:46:39+00:00,False,,False,False,True,False,/r/datascience/comments/17h3hj7/data_science_upskilling/,data science upskilling," **How to upskill for data science in 2023, I have 3 years of relevant work experience, plus 7 years total but learning has almost stopped. Could you suggest resources/websites to take profile** ",datascience,https://www.reddit.com/r/datascience/comments/17h3hj7/data_science_upskilling/,1,0,0.33,[Comment(id='k6yil4d')]
17h37bq,Rebeca_nura,,2023-10-26 18:34:02+00:00,False,,False,False,True,False,/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,Help! Cloud services on the Data Science field,"Hello all, I want to ask to you some questions about Cloud services on the Data Science field.

&#x200B;

Currently I´m working on a marketing agency with around 80 employees, and my team is in charge of the data management, we have been working on an ETL process that cleans data coming from APIs and upload it in Big Query. We scheduled the daily ETL process with Pythonanywhere, but now our client want us to implement a top notch platform to absorb the work of Pythonanywhere. I know that there are some options that I can use as Azure or AWS but my self and my team is complete ignorant of the topic, for those of you that already worked in projects that use this technolgies, which is the best approach to start learn it? are there any courses or certifications that you recomment? for scheduling the run of python code is there a specific module of Azure or AWS that I have to learn?

&#x200B;

Thank you!

&#x200B;

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,0,1,0.67,[]
17h2z94,trevor12345677,,2023-10-26 18:24:20+00:00,False,,False,False,True,False,/r/datascience/comments/17h2z94/learning_programming/,Learning programming!,"I am a student getting my masters in applied statistics. I’ve never experienced much with programming but have now found a major passion for it. I have a little over a year left till I finish up my masters. What different programs should I focus on? I am using R with my school and will get great practice with it. I want to be proficient in 2-3 programs when applying for next job when I graduate? What languages do you recommend and where do you recommend learning it from? I love futuristic/forecasting  modeling and looking to get into that type of work. 

Thank you for any help/advice!",datascience,https://www.reddit.com/r/datascience/comments/17h2z94/learning_programming/,6,1,0.67,"[Comment(id='k6kpxzc'), Comment(id='k6kptol'), Comment(id='k751vum'), Comment(id='k7gsw23'), Comment(id='k6kq3om'), Comment(id='k6kucrj')]"
17h2gwb,nacho_biznis,,2023-10-26 18:01:37+00:00,False,,False,False,True,False,/r/datascience/comments/17h2gwb/how_to_predict_office_relocation/,How to predict office relocation,"Does anyone have a good feel of how to formulate the task of predicting if a company will have to relocate in following X months? Say I can construct a dataset with info on employees, area, building details and some financial numbers. I know the months in which they move or not. So zeros and ones here for the label. I haven't managed to find any relevant literature or code or blog post on a similar topic. Is this a binary classification problem? What algorithms to use? How to account for class imbalance that case? Any pointers would be much appreciated.",datascience,https://www.reddit.com/r/datascience/comments/17h2gwb/how_to_predict_office_relocation/,3,1,0.67,"[Comment(id='k6kvdth'), Comment(id='k6mvwhb')]"
17h2bxq,SussyAutist,,2023-10-26 17:55:23+00:00,False,,False,False,True,False,/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,Suggestions for my internship project,"Hello guys,

I am currently doing a project for my internship. It involves image detection which I have more or less dealt with. The main thing now for me to do is that I have to compare the mass or brightness of each of the blue holes with the reference chart circled red. The blue dots in the red circle have varying uniform opacity and I have to see how the outside blue dots compare with the reference dots. I cannot seem to figure out how to go about doing this. I was thinking of a graph, but it does not seem convenient or maybe a 3d graph(?). I would be grateful if you guys can give me suggestions.

&#x200B;

https://preview.redd.it/jaefgmgh4lwb1.png?width=717&format=png&auto=webp&s=8c03ed5cc6732c8748f548c5742824c952815156",datascience,https://www.reddit.com/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,0,0,0.5,[]
17gx81s,CursorInsight,,2023-10-26 14:01:22+00:00,False,,False,False,False,False,/r/datascience/comments/17gx81s/we_are_the_founders_of_cursor_insight_the_human/,"We are the founders of Cursor Insight, the human motion experts. AMA!",,datascience,/r/IAmA/comments/17gv9im/we_are_the_founders_of_cursor_insight_the_human/,0,2,1.0,[]
17h1y9t,house_lite,,2023-10-26 17:38:04+00:00,False,,False,False,False,False,/r/datascience/comments/17h1y9t/i_created_a_shiny_app_for_data_scientists/,I created a shiny app for data scientists,,datascience,https://github.com/AdrianAntico/Quantico,0,1,1.0,[]
17gwwlp,Distinct-Swan2019,,2023-10-26 13:46:09+00:00,False,,False,False,True,False,/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,Feature Pyramid Network vs U-Net,"Hi everyone, 

I was working on my thesis research when I encountered the concept of Feature Pyramid Network, i have read something about it but still i have some doubts. My main question is: ""What is (or are) the difference(s) with respect to the U-Net architecture?""",datascience,https://www.reddit.com/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,1,2,1.0,[Comment(id='k6m1ete')]
17g7kqf,cptsanderzz,,2023-10-25 15:36:00+00:00,False,,False,False,True,False,/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,Is the future of data science drag and drop?,"I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don’t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can’t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone’s thoughts?",datascience,https://www.reddit.com/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,147,114,0.78,"[Comment(id='k6ep0on'), Comment(id='k6et8aj'), Comment(id='k6f6uhl'), Comment(id='k6eyet7'), Comment(id='k6evrt4'), Comment(id='k6f3dl8'), Comment(id='k6equu8'), Comment(id='k6etbvj'), Comment(id='k6etuk9'), Comment(id='k6f2rak'), Comment(id='k6euh1u'), Comment(id='k6eq0l1'), Comment(id='k6f5b0s'), Comment(id='k6fgf5v'), Comment(id='k6fin9k'), Comment(id='k6fq8fj'), Comment(id='k6eyfb4'), Comment(id='k6fdxxe'), Comment(id='k6fx22n'), Comment(id='k6gkwi7'), Comment(id='k6it5ou'), Comment(id='k6eugcx'), Comment(id='k6fewku'), Comment(id='k6faxsy'), Comment(id='k6f1haa'), Comment(id='k6f6bo9'), Comment(id='k6f7leh'), Comment(id='k6fa062'), Comment(id='k6fia3p'), Comment(id='k6flemy'), Comment(id='k6fw955'), Comment(id='k6fxyup'), Comment(id='k6fzh9l'), Comment(id='k6fzkaa'), Comment(id='k6g0w08'), Comment(id='k6g4c76'), Comment(id='k6g9arb'), Comment(id='k6gb07x'), Comment(id='k6gcbjc'), Comment(id='k6gdhrb'), Comment(id='k6gkqj8'), Comment(id='k6gw50m'), Comment(id='k6g0huq'), Comment(id='k6fusab'), Comment(id='k6ey5bj'), Comment(id='k6glrea'), Comment(id='k6fovaq'), Comment(id='k6gx91z'), Comment(id='k6gzg2a'), Comment(id='k6hdt9m'), Comment(id='k6hi2yb'), Comment(id='k6hokd9'), Comment(id='k6hu44y'), Comment(id='k6ibw2q'), Comment(id='k6if1mz'), Comment(id='k6ir5a3'), Comment(id='k6j6cck'), Comment(id='k6k552r'), Comment(id='k6kuxbc'), Comment(id='k7snhgv'), Comment(id='k6ev5ee'), Comment(id='k6fy2g3'), Comment(id='k6gjsk9'), Comment(id='k6fhv4f'), Comment(id='k6irq3o'), Comment(id='k6ffqro'), Comment(id='k6favmx'), Comment(id='k6gw1ur'), Comment(id='k6iduzk'), Comment(id='k6hhrhf'), Comment(id='k6f2rr2'), Comment(id='k6fudy9'), Comment(id='k6g7uur'), Comment(id='k6gfgjo'), Comment(id='k6fufns'), Comment(id='k6f5c9l'), Comment(id='k6g7xdw'), Comment(id='k6gdyl1'), Comment(id='k6iujdl'), Comment(id='k6fbmyz'), Comment(id='k6fci1k'), Comment(id='k6j3abp'), Comment(id='k6gectz'), Comment(id='k6itm47'), Comment(id='k6fz7ll'), Comment(id='k6fjvgs'), Comment(id='k6fhdeo'), Comment(id='k6fdfnc'), Comment(id='k6f6bpg'), Comment(id='k6ffx4z'), Comment(id='k6fbgbm'), Comment(id='k6g82f9'), Comment(id='k6g7q48'), Comment(id='k6gkgz7'), Comment(id='k6ghg6v'), Comment(id='k6gl8g7'), Comment(id='k6g2plb'), Comment(id='k6itq4z'), Comment(id='k6gkho5'), Comment(id='k6g5tn0'), Comment(id='k6goaej'), Comment(id='k6h4lqh'), Comment(id='k6jv6tu'), Comment(id='k6fwbgy'), Comment(id='k6gdoq6'), Comment(id='k6kqkms'), Comment(id='k6f7t9k'), Comment(id='k6gvo1r'), Comment(id='k6flm40'), Comment(id='k6fkxqu'), Comment(id='k6hgbnv'), Comment(id='k6iuw1f'), Comment(id='k6gtl0u'), Comment(id='k6iuzb2'), Comment(id='k6jyfka'), Comment(id='k6g9tzd'), Comment(id='k6gv2cy'), Comment(id='k6jwtrv'), Comment(id='k6ff727'), Comment(id='k6flcv7'), Comment(id='k6fv4ne'), Comment(id='k6fc9mm'), Comment(id='k6i1i82'), Comment(id='k6ifmfe'), Comment(id='k6iv9pe'), Comment(id='k6h1xpr'), Comment(id='k6iad6j'), Comment(id='k6k5cqb'), Comment(id='k6gb8vu'), Comment(id='k6gvoc7'), Comment(id='k6m9z5a'), Comment(id='k6fnxvg'), Comment(id='k6iv4l5'), Comment(id='k6k71lz'), Comment(id='k6ggqhq'), Comment(id='k6h6zc1'), Comment(id='k6hkxjp'), Comment(id='k6maufe'), Comment(id='k6gdnga'), Comment(id='k6l4sod'), Comment(id='k6gu3ho'), Comment(id='k6hdosk'), Comment(id='k6lak6t'), Comment(id='k6guh62'), Comment(id='k6jdyac'), Comment(id='k6nrubp'), Comment(id='k6o1az5')]"
17h10e0,Alert_Pea_4855,,2023-10-26 16:55:07+00:00,False,,False,False,False,False,/r/datascience/comments/17h10e0/data_strategy_mastery_valuable_tips_for_data_pros/,Data Strategy Mastery: Valuable Tips for Data Pros and Companies Aiming to Level Up,"Hi folks, I just published an article where I shared some of the tips I've learned based on my research and experience for building a data strategy and leveling up your business. Curious to learn more? Dive in here",datascience,https://meysamraz.medium.com/data-strategy-mastery-valuable-tips-for-data-pros-and-companies-aiming-to-level-up-69b17606e7e4,0,1,1.0,[]
17h56j2,Silence_the_Slayer99,,2023-10-26 20:00:35+00:00,False,,False,False,True,False,/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,How to Apply What I Learn in Data Science and Find a Job?,"Hello All. Just looking to tap into your expertise and experience 😊

I’m a non-technical Project Management Officer with robust Excel skills and some knowledge about IT Systems. Now, I’m highly interested in becoming a Data Scientist as well and have taken some online courses to get up to speed.

Here’s my dilemma. I don’t have much experience yet with creating PowerBI reports and using Python language. I’m intimidated (yet intrigued) with this complex field.

How can I take on projects to properly apply what I’ve been learning so far? Also, how can I apply for jobs related to this field while still being a beginner (but willing to learn in the job)?

Many thanks in advance for your advices. Thank you 😊",datascience,https://www.reddit.com/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,6,0,0.25,"[Comment(id='k6lg4t9'), Comment(id='k6s1u7e'), Comment(id='k73y70w'), Comment(id='k75zq7q'), Comment(id='k79fdxn'), Comment(id='k7he44l')]"
17gzyzp,smokeyScraper,,2023-10-26 16:09:25+00:00,False,,False,False,True,False,/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,Convert Stata(.DTA) files to .csv,"Hello, can anyone help me out. I want to convert a huge .dta file(~3GB) to .csv file but I am not able to do so using python due to its large size. I also tried on kaggle but it said memory limit exceeded. Can anyone help me out?",datascience,https://www.reddit.com/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,6,1,0.67,"[Comment(id='k6k2gaj'), Comment(id='k6knkk7'), Comment(id='k6kjdr8'), Comment(id='k6l5157'), Comment(id='k6l8vz2'), Comment(id='k6n7mkk')]"
17gya2d,former_pothead,,2023-10-26 14:51:18+00:00,False,,False,False,True,False,/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,Thoughts about MS in Data Intelligence (MSDI) in University of South Florida?,"USF accepted my application for the [MSDI program](https://www.usf.edu/engineering/imse/graduate/ms-data-intelligence.aspx). I'm here considering if I accept the acceptance letter and join in January, or wait until August 2024 to join Georgia Tech's Online Master of Science in Analytics.",datascience,https://www.reddit.com/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,0,0,0.5,[]
17gtvwl,First_Beginning6365,,2023-10-26 11:01:04+00:00,False,,False,False,True,False,/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,Are data science answering frameworks helpful?,"Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  **Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.**   


I have seen and found this framework for answering such questions:  


Step1: Ask clarifying questions on problems and constraints 

Step 2: Establish Metrics 

Step 3: Understand your data sources 

Step 4: Explore your data 

Step 5: Data Cleanup 

Step 6: Feature Engineering 

Step 7: Model Selection and training 

Step 8: Deployment 

Step 9: Iterate 

I would love to get inputs on need and usefulness of such frameworks?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,2,2,0.75,"[Comment(id='k6j5kgc'), Comment(id='k6jdq60')]"
17gtslo,Glum-Bat8771,,2023-10-26 10:55:13+00:00,False,,1698353625.0,False,True,False,/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,Dealing with features of questionable predictive power and confounding variables,"Hello all, I encountered this data analytics / data science challenge at work, wondering how y’all would have solved it.

**Background:**

I was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.

Given that we weren't producing the product descriptions ourselves, our focus was on **features we could influence**. We **did not include** aspects such as:

* brand reputation, 
* type of product, 
* price

, even if they were vital factors driving user engagement.

Our attention was instead directed at a few controllable features:

* whether or not the descriptions exceeded a certain length (we could provide feedback on these to vendors)
* whether or not our in-house ML model could categorize the product (affecting its searchability)
* the presence of vendor ratings,
* etc.

To clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn't. So, my dataset consisted of all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.

**Approach:**

My next steps? I initiated numerous student t-tests. 

For instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What's the engagement disparity between products that had vendor ratings va those that didn’t? 

Given the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. 

Note: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren't for UX / political reasons.

**Results:**

With extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging.

Yet, the findings weren't consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.

My next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.

I never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.

**What could I have done differently?**

In retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?

I would love to hear your thoughts!",datascience,https://www.reddit.com/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,4,2,1.0,"[Comment(id='k6t20zp'), Comment(id='k6tistt'), Comment(id='k6tk55h'), Comment(id='k6tx69a')]"
17gtgb0,cinderbl0ckgardener,,2023-10-26 10:31:59+00:00,False,,False,False,True,False,/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,How to qualify for a job in Data Science,"I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. 

Any additional skills I need to learn?",datascience,https://www.reddit.com/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,3,2,0.67,"[Comment(id='k6irjk7'), Comment(id='k6itceg'), Comment(id='k6iy2pu')]"
17gc0b4,VastDragonfruit847,,2023-10-25 18:49:15+00:00,False,,False,False,True,False,/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,Is a Convex Optimization class good for Data Science?," For context, I am a Master's student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.

This is what the course page says : 

Student Learning Outcomes: 

Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.

Detailed Content: 

Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems – applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation – applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle – primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  


  
I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?",datascience,https://www.reddit.com/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,22,33,0.97,"[Comment(id='k6fqqdz'), Comment(id='k6g2hhd'), Comment(id='k6h23na'), Comment(id='k6gqhhp'), Comment(id='k6fy0lg'), Comment(id='k6hj85d'), Comment(id='k6iceu3'), Comment(id='k6hepsg'), Comment(id='k6ht6aw'), Comment(id='k6iwuh5'), Comment(id='k6lhq66'), Comment(id='k74sodb'), Comment(id='k6fverf'), Comment(id='k6gb0aq'), Comment(id='k74t4c9'), Comment(id='k6i9n0b'), Comment(id='k6iuy1p'), Comment(id='k6iuexz'), Comment(id='k74vkn4'), Comment(id='k6hest2'), Comment(id='k6jn2py'), Comment(id='k753ele')]"
17gwd7z,kaisoma,,2023-10-26 13:19:52+00:00,False,,False,False,False,False,/r/datascience/comments/17gwd7z/git_version_controlled_datasets_in_your_own_s3/,Git Version Controlled Datasets in your own S3,"I’m building Underhive, a collaboration platform for ML Teams. I’ve just put out the first product up which helps you use your own storage backend for Git-LFS.

Please email me at: support@underhive.in.
If you want to help and be one of the first beta clients.
We’re also giving free usage for upto 200GBs for the next 6 months to beta clients.  
Try out: https://underhive.in (please use on Desktop, the mobile version is broken right now)",datascience,https://i.redd.it/pkoix1xasjwb1.jpg,5,1,0.67,"[Comment(id='k6ktvdb'), Comment(id='k6kwunw'), Comment(id='k6phzwo'), Comment(id='k6piaqr'), Comment(id='k6yxi5j')]"
17h0yms,battleaxe37,,2023-10-26 16:52:51+00:00,False,,False,False,False,False,/r/datascience/comments/17h0yms/residuals/,Residuals,"I am trying to get the residuals to white noise but there are two different behaviors on residuals. Any ideas on how I should transform this? Or what should I do. I tried log/sqrt. Doesn’t really do shit. Dataset is a hourly data for a couple years. The graph behavior is seasonal yearly, and daily aswell. But right now I just care about the yearly. Any advice?",datascience,https://i.redd.it/4f064j4bukwb1.jpg,7,0,0.4,"[Comment(id='k6klrn0'), Comment(id='k6kgjba'), Comment(id='k6kugqc'), Comment(id='k6klz7d'), Comment(id='k6krr7q'), Comment(id='k6lm98f'), Comment(id='k6mm9f1')]"
17gvhga,Slow_Act_4114,,2023-10-26 12:34:24+00:00,False,,False,False,True,False,/r/datascience/comments/17gvhga/questions_for_knime_users/,Questions for KNIME Users,"Hey everybody,  
I started to use KNIME fpr work, but have some issues with it. I am currently taking the DW1 Exam, but I dont have any idea on how to do that. Can someone please help me? using ChatGPT feels like cheating.  
Thanks in advance ",datascience,https://www.reddit.com/r/datascience/comments/17gvhga/questions_for_knime_users/,0,1,1.0,[]
17goc84,daufoi21,,2023-10-26 04:27:37+00:00,False,,False,False,True,False,/r/datascience/comments/17goc84/having_a_second_job_on_1099/,having a second job on 1099,"I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I'm doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?",datascience,https://www.reddit.com/r/datascience/comments/17goc84/having_a_second_job_on_1099/,5,3,0.8,"[Comment(id='k6iwq7u'), Comment(id='k6ibn3k'), Comment(id='k6ncakw'), Comment(id='k6nciqv'), Comment(id='k6rt21a')]"
17fzssg,One_Ad_3499,,2023-10-25 08:09:19+00:00,False,,False,False,True,False,/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,I am intern and i hate Tableau. Can u give some copium?,I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety,datascience,https://www.reddit.com/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,83,102,0.86,"[Comment(id='k6d981d'), Comment(id='k6du5l8'), Comment(id='k6dhefm'), Comment(id='k6d9gxu'), Comment(id='k6dcgkx'), Comment(id='k6e9tdi'), Comment(id='k6dwlwc'), Comment(id='k6daxza'), Comment(id='k6efg55'), Comment(id='k6dbifn'), Comment(id='k6dqr0b'), Comment(id='k6ed5ro'), Comment(id='k6eh7fp'), Comment(id='k6f5wa5'), Comment(id='k6fc13y'), Comment(id='k6f6n8d'), Comment(id='k6fbae8'), Comment(id='k6dyx5x'), Comment(id='k6h27xy'), Comment(id='k6dihh2'), Comment(id='k6elmnt'), Comment(id='k6et8z6'), Comment(id='k6eu41t'), Comment(id='k6exs0r'), Comment(id='k6f0793'), Comment(id='k6gotdy'), Comment(id='k6hrmoy'), Comment(id='k6hsdw2'), Comment(id='k6huen8'), Comment(id='k6iptfn'), Comment(id='k7snwkr'), Comment(id='k6d9q9c'), Comment(id='k6gevtk'), Comment(id='k6edr5c'), Comment(id='k6duyqg'), Comment(id='k6gokwu'), Comment(id='k6ecxim'), Comment(id='k6eqvdz'), Comment(id='k6d9obm'), Comment(id='k6fr7dc'), Comment(id='k6dgrqg'), Comment(id='k6ddjev'), Comment(id='k6g08lz'), Comment(id='k6eb80m'), Comment(id='k6ehxvv'), Comment(id='k6esoun'), Comment(id='k6dbgfi'), Comment(id='k6fkufo'), Comment(id='k6f5n5b'), Comment(id='k6e2vaw'), Comment(id='k6jlaht'), Comment(id='k6f5zyu'), Comment(id='k6i37uk'), Comment(id='k6f511k'), Comment(id='k6fhx9i'), Comment(id='k6giw78'), Comment(id='k6jbl92'), Comment(id='k6ee6da'), Comment(id='k6etd01'), Comment(id='k6ewsz4'), Comment(id='k6dwt2x'), Comment(id='k6dzouy'), Comment(id='k6garmz'), Comment(id='k6if7a9'), Comment(id='k6fkzx9'), Comment(id='k6f61t1'), Comment(id='k6ex5sg'), Comment(id='k6e77m7'), Comment(id='k6g1a2b'), Comment(id='k6jdp7z'), Comment(id='k6jkwrz'), Comment(id='k6eef9x'), Comment(id='k6evjtn'), Comment(id='k6febx7'), Comment(id='k6flhao'), Comment(id='k6hgcy1'), Comment(id='k6excsa'), Comment(id='k6jkqam'), Comment(id='k6exhcy'), Comment(id='k6o743i'), Comment(id='k6f1v39'), Comment(id='k6eyrua'), Comment(id='k6fjrmw')]"
17gqxzh,ChrisReynolds83,,2023-10-26 07:25:24+00:00,False,,False,False,True,False,/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,Imputation of multiple missing values,"I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.

The tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.

I'm looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS ([Missing Data Imputation using Generative Adversarial Nets](https://arxiv.org/abs/1806.02920)) and [MissForest](https://academic.oup.com/bioinformatics/article/28/1/112/219101). Does anybody have any other suggestions of imputers that might work?",datascience,https://www.reddit.com/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,1,1,1.0,[Comment(id='k6ic7lb')]
17gn08a,jshkk,,2023-10-26 03:11:14+00:00,False,,False,True,True,False,/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,"Evaluation Metric Flowchart (possibly handy, interested in feedback!)","&#x200B;

I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are ""less wrong"" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 ""means something""), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!

My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.

https://preview.redd.it/7nplhw2npgwb1.png?width=7162&format=png&auto=webp&s=9bf42afad02bccdb791e88016a78862c7d7faa32",datascience,https://www.reddit.com/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,0,2,0.76,[]
17gpxlq,SaiyWolf,,2023-10-26 06:12:35+00:00,False,,False,False,True,False,/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,How can you learn to find the insights,I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?,datascience,https://www.reddit.com/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,6,1,0.67,"[Comment(id='k6is1wz'), Comment(id='k6k13c4'), Comment(id='k6mhcxp'), Comment(id='k6j7y7o'), Comment(id='k6izg9t'), Comment(id='k6j2zd7')]"
17g6gbt,Tender_Figs,,2023-10-25 14:45:41+00:00,False,,False,False,True,False,/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,How do you maintain motivation in your data role?,"Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?

Additionally, how do you maintain motivation when you're working with a domain that you don't like? Not tolerate, generally don't like. ",datascience,https://www.reddit.com/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,8,18,0.92,"[Comment(id='k6egvcp'), Comment(id='k6ejin3'), Comment(id='k6eylco'), Comment(id='k6fvhgj'), Comment(id='k6hdfzm'), Comment(id='k6jcg5p'), Comment(id='k6jdbav'), Comment(id='k6kryjc')]"
17fsjf2,Excellent_Cost170,,2023-10-25 00:54:36+00:00,False,,False,False,True,False,/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,"Tired of armchair coworker and armchair manager saying ""Analysis paralysis"""," I have an older coworker and a manager both from the same culture who doesn't have much experience in data science. They've been focused on dashboarding but have been given the title of 'data scientist.' They often mention 'analysis paralysis' when discussions about strategy arise. When I speak about ML feasibility analysis, or when I insist on spending time studying the data to understand the problem, or when I emphasize asking what the stakeholder actually wants instead of just creating something and trying to sell it to them, there's resistance. They typically aren't the ones doing the hands-on work. They seem to prefer just doing things. Even when there's a data quality issue, they just plow through. Has that been your experience? People who say ""analysis paralysis"" often don't actually do things; they just sit on the side or take credit when things work out.",datascience,https://www.reddit.com/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,106,185,0.93,"[Comment(id='k6c3yfu'), Comment(id='k6c3s40'), Comment(id='k6d345i'), Comment(id='k6ctrmh'), Comment(id='k6d928q'), Comment(id='k6c2h2m'), Comment(id='k6c0rq3'), Comment(id='k6d7804'), Comment(id='k6dxiyk'), Comment(id='k6emh52'), Comment(id='k6cgibe'), Comment(id='k6d2m83'), Comment(id='k6cit36'), Comment(id='k6dgxiq'), Comment(id='k6dxfdc'), Comment(id='k6e2v02'), Comment(id='k6fefsw'), Comment(id='k6du91o'), Comment(id='k6e4klf'), Comment(id='k6e46ia'), Comment(id='k6dwl6x'), Comment(id='k6e55bs'), Comment(id='k6ejl4q'), Comment(id='k6elvf7'), Comment(id='k6ez0yn'), Comment(id='k6f3tcl'), Comment(id='k6fqvpp'), Comment(id='k6imxz9'), Comment(id='k6c4ug5'), Comment(id='k6d8ez8'), Comment(id='k6efzic'), Comment(id='k6fjchp'), Comment(id='k6htc1e'), Comment(id='k6d588y'), Comment(id='k6eero2'), Comment(id='k6c5kzl'), Comment(id='k6drcxf'), Comment(id='k6g317y'), Comment(id='k6cls45'), Comment(id='k6es5ne'), Comment(id='k6f4vkp'), Comment(id='k6c4idg'), Comment(id='k6edy14'), Comment(id='k6epf7o'), Comment(id='k6clxp4'), Comment(id='k6eo4tq'), Comment(id='k6en5s7'), Comment(id='k6fm7it'), Comment(id='k6cg3oj'), Comment(id='k6eja13'), Comment(id='k6csejg'), Comment(id='k6e608e'), Comment(id='k6fl8xk'), Comment(id='k6erl2g'), Comment(id='k6euw8i'), Comment(id='k6g3kb0'), Comment(id='k6d9gkk'), Comment(id='k6dif78'), Comment(id='k6c8e12'), Comment(id='k6cfqhb'), Comment(id='k6ess1t'), Comment(id='k6e06hn'), Comment(id='k6edvcg'), Comment(id='k6gpizv'), Comment(id='k6cnea1'), Comment(id='k6etiqu'), Comment(id='k6cah36'), Comment(id='k6d1zk5'), Comment(id='k6etfi3'), Comment(id='k6fmusy'), Comment(id='k6d98az'), Comment(id='k6diwjs'), Comment(id='k6ejku9'), Comment(id='k6d3toq'), Comment(id='k6ddjdu'), Comment(id='k6fp8a3'), Comment(id='k6ehl2h'), Comment(id='k6dmwbl'), Comment(id='k6dqhep'), Comment(id='k6d9p3l'), Comment(id='k6dkgv7'), Comment(id='k6eilo6'), Comment(id='k6efiiq'), Comment(id='k6evd8e'), Comment(id='k6fdo19'), Comment(id='k6dnxbq'), Comment(id='k6e7u28'), Comment(id='k6dsb6h'), Comment(id='k6frx8l'), Comment(id='k6e3daa'), Comment(id='k6e5l7g'), Comment(id='k6dql3r'), Comment(id='k6dtrqu'), Comment(id='k6dwxhn'), Comment(id='k6dztzb'), Comment(id='k6f3h8r'), Comment(id='k6eivfs'), Comment(id='k6ft0i8'), Comment(id='k6e3obv'), Comment(id='k6dz85n'), Comment(id='k6e12yv'), Comment(id='k6f5zzm'), Comment(id='k6e3td6'), Comment(id='k6iy9k1'), Comment(id='k6e4cg7'), Comment(id='k6exj7p'), Comment(id='k6f5vmv')]"
17g8cbj,jakeblack06,,2023-10-25 16:09:12+00:00,False,,False,False,True,False,/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,What is the most suitable model for my problem?,"I know you would have heard so many people asking this question, but please bear with me.

I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes & GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don't know how to go about selelcting a model that suits the data the most because I don't have enough experience to just select any model based on experience and I didn't find any ""algorithm"" which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.",datascience,https://www.reddit.com/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,9,8,0.85,"[Comment(id='k6evp8t'), Comment(id='k6ew4iv'), Comment(id='k6g1y1p'), Comment(id='k6fkqr0'), Comment(id='k6i3m5d'), Comment(id='k6ir34q'), Comment(id='k6iigit'), Comment(id='k6jnxkr'), Comment(id='k6hvx3s')]"
17gn7d8,LegitimateAd4716,,2023-10-26 03:21:30+00:00,False,,False,False,True,False,/r/datascience/comments/17gn7d8/how_to_proceed/,How to proceed…,I’m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I’m pursuing right now also promised placement opportunities but I do not want to wait till the end…,datascience,https://www.reddit.com/r/datascience/comments/17gn7d8/how_to_proceed/,3,0,0.5,"[Comment(id='k6htj1h'), Comment(id='k6i3ksm'), Comment(id='k6jap1k')]"
17g8iu2,Jbor941197,,2023-10-25 16:17:02+00:00,False,,False,False,True,False,/r/datascience/comments/17g8iu2/learning_cloud_platforms/,Learning Cloud Platforms,"I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer's life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it's so different from data science where we focus on concepts vs tools. 

One reason Im curious is if you're the head of an analytics department how do you manage all of this? How would you know how much work something is?",datascience,https://www.reddit.com/r/datascience/comments/17g8iu2/learning_cloud_platforms/,0,7,0.9,[]
17gkbw1,Time_Law_2659,,2023-10-26 00:56:17+00:00,False,,False,False,True,False,/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,Reducing Goals Using Dats,We work in an items per hr setting with 100's of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.,datascience,https://www.reddit.com/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,0,0,0.33,[]
17fjgzu,CadeOCarimbo,,2023-10-24 18:20:44+00:00,False,,False,False,True,False,/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,Do you ever feel dumb when you see data scientists doing exceptional stuff when you are just there doing mundane data-stuff?,"Please don't take this post seriously, but I can't help but think that those guys who work at OpenAI, Midjourney,  Google, whatever, despite being Data Scientists just like me (for 6 years, not someone trying to break in), are delivering stuff that I would never be able to, even though we have the same titles on LinkedIn? 

I mean, I'm totally okay with with calling myself a mediocre data Scientist as it is pretty much a choice that I made by enjoying my free time instead of studying my ass off and going for a PhD, but still. Saying that OpenAI staff and myself both are data Scientist feels like saying Messi and some player from a local amateur team are both soccer players.",datascience,https://www.reddit.com/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,73,273,0.96,"[Comment(id='k6agm6d'), Comment(id='k6aa1ws'), Comment(id='k6actvn'), Comment(id='k6acwd9'), Comment(id='k6ao1uc'), Comment(id='k6ab2g2'), Comment(id='k6aidsz'), Comment(id='k6axj8v'), Comment(id='k6apqic'), Comment(id='k6auucq'), Comment(id='k6angtx'), Comment(id='k6an3b3'), Comment(id='k6csqg1'), Comment(id='k6awmz3'), Comment(id='k6bey4r'), Comment(id='k6bbd8k'), Comment(id='k6bfvnh'), Comment(id='k6c16uf'), Comment(id='k6c1ln2'), Comment(id='k6c2f3g'), Comment(id='k6d2fjy'), Comment(id='k6apnng'), Comment(id='k6awfjp'), Comment(id='k6bb307'), Comment(id='k6bdrl9'), Comment(id='k6bsjkn'), Comment(id='k6cfd76'), Comment(id='k6csmpe'), Comment(id='k6cvabi'), Comment(id='k6d8ft0'), Comment(id='k6dbunh'), Comment(id='k6dwjyg'), Comment(id='k6euy2c'), Comment(id='k6ahzae'), Comment(id='k6c4n9w'), Comment(id='k6d0jp7'), Comment(id='k6dibik'), Comment(id='k6cl1l6'), Comment(id='k6cx380'), Comment(id='k6d082p'), Comment(id='k6drap0'), Comment(id='k6dtv9d'), Comment(id='k6cj8ut'), Comment(id='k6ckrl4'), Comment(id='k6f87w5'), Comment(id='k6f9uqy'), Comment(id='k6ficil'), Comment(id='k7so3vl'), Comment(id='k6azt4x'), Comment(id='k6aq5nh'), Comment(id='k6cmsu6'), Comment(id='k6aiigi'), Comment(id='k6ab30n'), Comment(id='k6enkby'), Comment(id='k6agm4s'), Comment(id='k6bu2ab'), Comment(id='k6ba8gr'), Comment(id='k6dwkb6'), Comment(id='k6btq98'), Comment(id='k6bo7u5'), Comment(id='k6dd0js'), Comment(id='k6dbve7'), Comment(id='k6b70yq'), Comment(id='k6aq46a'), Comment(id='k6adpso'), Comment(id='k6dfsyf'), Comment(id='k6dnh7j'), Comment(id='k6jppm9'), Comment(id='k6apvvd'), Comment(id='k6e8oa3'), Comment(id='k6gm0tj'), Comment(id='k6caima'), Comment(id='k6ilkwq')]"
17fw3zm,PerceptionHot9236,,2023-10-25 03:57:17+00:00,False,,False,False,True,False,/r/datascience/comments/17fw3zm/tech_stack/,Tech Stack,"Data Scientists of Reddit, what’s the tech Stack do you use? If you are working in MAANG companies or dealing with huge huge amounts of data, does normal machine learning algorithms work? Is Big Data stack( Hadoop, Spark..) part of your daily drive ? Do you use any other programming language, except Python/R for day to day usage? Are there any tools or technologies that are very useful but major part of the data people don’t know?

I’m Masters in Data Science student, I’m just wondering how real world works, all my projects/assignments just involve python, sklearn library and a famous dataset from kaggle.",datascience,https://www.reddit.com/r/datascience/comments/17fw3zm/tech_stack/,52,40,0.91,"[Comment(id='k6cv3fw'), Comment(id='k6cujt8'), Comment(id='k6cyvcm'), Comment(id='k6cx7po'), Comment(id='k6cnsfu'), Comment(id='k6cxg1b'), Comment(id='k6d880l'), Comment(id='k6dvvtz'), Comment(id='k6dwdwz'), Comment(id='k6ea8jx'), Comment(id='k6emjw9'), Comment(id='k6gqjld'), Comment(id='k6fzhqg'), Comment(id='k6g8rei'), Comment(id='k6gqca6'), Comment(id='k6gr8pa'), Comment(id='k6cnf6g'), Comment(id='k6cpqq0'), Comment(id='k6d44l5'), Comment(id='k6fktyq'), Comment(id='k6cylxj'), Comment(id='k6e1zwh'), Comment(id='k6czxva'), Comment(id='k6dj9gm'), Comment(id='k6emc14'), Comment(id='k6gxzjt'), Comment(id='k6czaan'), Comment(id='k6cogob'), Comment(id='k6e6moi'), Comment(id='k6gvcjn'), Comment(id='k6d11vp'), Comment(id='k6ejpe5'), Comment(id='k6d1s0w'), Comment(id='k6ef102'), Comment(id='k6foce4'), Comment(id='k6d5zx2'), Comment(id='k6ebwjy'), Comment(id='k6ex3wn'), Comment(id='k6dlsq3'), Comment(id='k6e19vz'), Comment(id='k6ec3ke'), Comment(id='k6f4bco'), Comment(id='k6i7ibb'), Comment(id='k6ezz18'), Comment(id='k6jfm5v'), Comment(id='k6gd5u3'), Comment(id='k6h8cx4'), Comment(id='k6kxih8'), Comment(id='k6gs2jb'), Comment(id='k6hatit'), Comment(id='k6q7ig8'), Comment(id='k6hgoiz'), Comment(id='k6hlh8w')]"
17g55zm,Total-Opposite-8396,,2023-10-25 13:44:41+00:00,False,,1698242330.0,False,True,False,/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,Need help understanding if the model here is overfitting or not.,"&#x200B;

[ ](https://preview.redd.it/4cikjimrrcwb1.png?width=1546&format=png&auto=webp&s=8aac443256e5e5f18497718aa7d928d143a41b9b)

I've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?

Edit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info.",datascience,https://www.reddit.com/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,13,7,0.74,"[Comment(id='k6e6wm1'), Comment(id='k6f2g10'), Comment(id='k6ekh71'), Comment(id='k6efn7n'), Comment(id='k6f3ys4'), Comment(id='k6e7f6u'), Comment(id='k6e8tmh'), Comment(id='k6ean7r'), Comment(id='k6eaqjt'), Comment(id='k6ebtiq'), Comment(id='k6ebxh2'), Comment(id='k6enfhm'), Comment(id='k6edxml')]"
17gnj7i,Nickaroo321,,2023-10-26 03:39:22+00:00,False,,False,False,True,False,/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/,How to get into data science entry level position with an engineering degree?,,datascience,https://www.reddit.com/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/,7,0,0.5,"[Comment(id='k6hskfe'), Comment(id='k6htymm'), Comment(id='k6i2rjt'), Comment(id='k6mf0a9'), Comment(id='k6i2lv9'), Comment(id='k6j3rae'), Comment(id='k6jccvi')]"
17g41qs,honeyplease,,2023-10-25 12:52:02+00:00,False,,False,False,True,False,/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,"Data scientists reporting to CTO/equivalent (1 step below CEO), what's your job title?",Any company size (please include in response if possible).,datascience,https://www.reddit.com/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,23,5,0.6,"[Comment(id='k6e0tgx'), Comment(id='k6e8la6'), Comment(id='k6ei2vj'), Comment(id='k6ef5qh'), Comment(id='k6ecyzh'), Comment(id='k6fa7bn'), Comment(id='k6givy1'), Comment(id='k6gvrsc'), Comment(id='k6h44s8'), Comment(id='k6efe68'), Comment(id='k6e8bpz'), Comment(id='k6ec37n'), Comment(id='k6hicnk'), Comment(id='k6r2qs8'), Comment(id='k6f60g6'), Comment(id='k6gnlit'), Comment(id='k6f7jbw'), Comment(id='k6hjjas'), Comment(id='k6efn5g'), Comment(id='k6rarud'), Comment(id='k6fkmnm'), Comment(id='k6gn5o3'), Comment(id='k6g01xy')]"
17gej5o,LucasSaysHello,,2023-10-25 20:41:31+00:00,False,,False,False,True,False,/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,Vector DB directory structuring - ideal?,"Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.

If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.

Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a ""big bucket"" structure in which everything is kept in the same place?",datascience,https://www.reddit.com/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,0,1,1.0,[]
17g7vsr,CarbonHero,,2023-10-25 15:49:51+00:00,False,,False,False,True,False,/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,Worthwhile to post personal and pro-bono projects under my company page in order to list experience?,"I have a company page and branding package set up on LinkedIn – is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?

Some details: I'm a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I've created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.",datascience,https://www.reddit.com/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,0,2,0.67,[]
17g9mzj,lucasso13,,2023-10-25 17:04:58+00:00,False,,False,False,True,False,/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,Cloud computing trends in data science," Hey there, fellow data science people,

I'm reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I'm having a bit of a struggle finding my first gig.

Here's where I need advice. I'm curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I'm learning a cloud platform that'll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.

And last but not least, I'm all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. 

Thank you a lot in advance",datascience,https://www.reddit.com/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,1,1,0.67,[Comment(id='k74uxx2')]
17g01rn,ade17_in,,2023-10-25 08:28:04+00:00,False,,False,False,True,False,/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,"[P][R] Test-Val scores, how much difference isn't problematic.","Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.

1. I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)
2. The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.

&#x200B;

https://preview.redd.it/nseqy1mw5bwb1.png?width=577&format=png&auto=webp&s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58

Do share any experiences or suggestions!",datascience,https://www.reddit.com/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,0,3,1.0,[]
17g1rz7,sigma_chungus,,2023-10-25 10:37:10+00:00,False,,False,False,True,False,/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,Choosing between google data studio (Looker studio now I guess) and Tableau.,"Hey there. 
We are going to start working with Google sheets and podio.
We wanted to know which tool would be easier to learn and start working with. 
We are still beginners and we don't have access to paid versions and I got confused searching online.

What would be the pros and cons of using each tool. 

Thanks in advance.",datascience,https://www.reddit.com/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,3,1,0.6,"[Comment(id='k6dlbdu'), Comment(id='k6g5fmo'), Comment(id='k6ge41y')]"
17fthoj,MaAleem,,2023-10-25 01:41:20+00:00,False,,False,False,True,False,/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,keras tuner vs keras classifier vs neural network search,"i know this technique called keras tuner for tuning the model's hyperparameters . and then i also found that using for loop we can also select number of layers . and then i heard of this keras classifier that is used to search optimum number of layers and one more technique i head of is NAS Neural Network Search .   


keras tuner vs ( keras classifier ) keras.wrappers.scikit-learn.kerasClassifier vs neural network search (NAS)

can someone please help me with the difference among these three and what cases each can be considered ?",datascience,https://www.reddit.com/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,2,3,1.0,"[Comment(id='k6fovnd'), Comment(id='k6fw0b8')]"
17fytrb,mint_warios,,2023-10-25 06:55:35+00:00,False,,False,False,True,False,/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,The role of data scientists in NLP,"As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it's not ""advanced prompt engineering""?",datascience,https://www.reddit.com/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,22,0,0.44,"[Comment(id='k6d9may'), Comment(id='k6d7rnq'), Comment(id='k6d7qeu'), Comment(id='k6dcnlj'), Comment(id='k6de183'), Comment(id='k6du8ql'), Comment(id='k6ds7ui'), Comment(id='k6db6rb'), Comment(id='k6fae18'), Comment(id='k6de9tv'), Comment(id='k6di34a'), Comment(id='k6dehtu'), Comment(id='k6dxj71'), Comment(id='k6e0wbw'), Comment(id='k6eyv2q'), Comment(id='k6djsje'), Comment(id='k6dxum9'), Comment(id='k6e2bse'), Comment(id='k6dmyh5'), Comment(id='k6f00o3'), Comment(id='k6e51tm'), Comment(id='k6e56dy')]"
17eu3rm,wagwagtail,,2023-10-23 20:23:38+00:00,False,,1698095922.0,False,True,False,/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,Contractors who are called Data Scientists but can't do what I'd expect. What to do next.,"Ok so, I was hired as a senior member of a pre-existing data science team. I now manage a few other team members (who were there before me). They are all contractors and their day rate is HIGH. They are all 'Data Scientists' and graduates.

I'm older. I've done lots of technical roles and I'm not really sure what my official title is. I can do data science but I really just build stuff. I've done Data Engineering in the past, MLOps, DevOps, Cloud etc. I'm a jack of all trades, master of none.

Now, I know what ***I think*** a 'Data Scientist' should be able to do:

1. Pandas, Numpy, Scikit learn, matplotlib blah blah blah
2. Version control (Git)
3. Managing virtual environments
4. Debugging within an IDE
5. Scoping out a project, ideation, exploration
6. Report writing skills/communication skills
7. Some exposure to clean code conventions (PEP-8)
8. Some exposure to SQL like syntax
9. bit of linux would be cool (I can teach them)
10. bit of cloud would be cool (I can teach them)

I've had to mentor the team HARD. Most of the team did not know what Git was, most of the team had never debugged their code, never made a venv. In fact I have had to teach them steps 1-5. That would be fine if they were now hitting the ground running, but the moment I stop mentoring them, the productivity stops. No initiative.

And yet, I want to hire externally. I want to give them the opportunity to apply but I just know they won't measure up against the talent pool out there. I've hired Data Scientists before and I know how good people are out there.

Am I totally wrong? Do I need to cut them some slack? Anyone got any comments?

edit: spelling",datascience,https://www.reddit.com/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,198,212,0.94,"[Comment(id='k65pr3d'), Comment(id='k65toz9'), Comment(id='k65ld63'), Comment(id='k65s0tu'), Comment(id='k65v93g'), Comment(id='k65ypi4'), Comment(id='k66iui6'), Comment(id='k65vs6l'), Comment(id='k65ylsl'), Comment(id='k65w2k0'), Comment(id='k670dsb'), Comment(id='k65pm94'), Comment(id='k66kjp9'), Comment(id='k65xiy2'), Comment(id='k65xegj'), Comment(id='k66ixd1'), Comment(id='k66j28p'), Comment(id='k66jbf7'), Comment(id='k66u4aq'), Comment(id='k67178i'), Comment(id='k67vh6k'), Comment(id='k68hf21'), Comment(id='k68lk0r'), Comment(id='k68nsgd'), Comment(id='k66i9g8'), Comment(id='k66jxtl'), Comment(id='k664mvl'), Comment(id='k665s57'), Comment(id='k667pn7'), Comment(id='k66mx7x'), Comment(id='k66pinj'), Comment(id='k66wtcp'), Comment(id='k66ztau'), Comment(id='k67nfw9'), Comment(id='k68937z'), Comment(id='k68zdhf'), Comment(id='k693j7x'), Comment(id='k698vzf'), Comment(id='k69fprc'), Comment(id='k6c5zhb'), Comment(id='k65yr2k'), Comment(id='k65zr5h'), Comment(id='k65tv30'), Comment(id='k65tlix'), Comment(id='k65w72l'), Comment(id='k66eri4'), Comment(id='k66fm1c'), Comment(id='k66gd3h'), Comment(id='k66hvue'), Comment(id='k66o3fx'), Comment(id='k66oko3'), Comment(id='k66tgk0'), Comment(id='k66ui6s'), Comment(id='k66ya1t'), Comment(id='k671le7'), Comment(id='k672raq'), Comment(id='k676d8e'), Comment(id='k67jhz8'), Comment(id='k67pfm3'), Comment(id='k67r3kk'), Comment(id='k67sck1'), Comment(id='k67xw12'), Comment(id='k67yziu'), Comment(id='k686t5q'), Comment(id='k68c25t'), Comment(id='k68kiw6'), Comment(id='k68l5al'), Comment(id='k68o1o0'), Comment(id='k68ojlo'), Comment(id='k68vrqu'), Comment(id='k68ws5o'), Comment(id='k697nkm'), Comment(id='k69d6v0'), Comment(id='k69ilfr'), Comment(id='k69n2ul'), Comment(id='k69oo8o'), Comment(id='k69q7au'), Comment(id='k69qw0z'), Comment(id='k6a28o7'), Comment(id='k6a64uv'), Comment(id='k6a6oe9'), Comment(id='k6ae7ir'), Comment(id='k6ai62s'), Comment(id='k6aimpe'), Comment(id='k6amw9j'), Comment(id='k6aucnu'), Comment(id='k6b7p23'), Comment(id='k6bi76k'), Comment(id='k6bmq08'), Comment(id='k6bysio'), Comment(id='k6cmqnt'), Comment(id='k6cveae'), Comment(id='k6e2wbb'), Comment(id='k6ergu7'), Comment(id='k6mmtlk'), Comment(id='k6rr7oj'), Comment(id='k6xe9ct'), Comment(id='k67saqm'), Comment(id='k6cka7w'), Comment(id='k68s2nu'), Comment(id='k65twv1'), Comment(id='k67iigc'), Comment(id='k65lppg'), Comment(id='k65sbeo'), Comment(id='k675pp8'), Comment(id='k667egb'), Comment(id='k675itl'), Comment(id='k661m8d'), Comment(id='k674hhw'), Comment(id='k697r5m'), Comment(id='k65w0yr'), Comment(id='k65xqf9'), Comment(id='k67rdur'), Comment(id='k6904a2'), Comment(id='k69t0in'), Comment(id='k65q2mm'), Comment(id='k67tike'), Comment(id='k661mio'), Comment(id='k681i16'), Comment(id='k6bfqjg'), Comment(id='k68krkc'), Comment(id='k66k9n6'), Comment(id='k66pwr1'), Comment(id='k68x04l'), Comment(id='k664sl2'), Comment(id='k66qd7a'), Comment(id='k67cod7'), Comment(id='k67d9zs'), Comment(id='k67b50p'), Comment(id='k6e3jn3'), Comment(id='k65zc9p'), Comment(id='k6698c0'), Comment(id='k65u4w1'), Comment(id='k65xm9m'), Comment(id='k68w9sw'), Comment(id='k697w34'), Comment(id='k6854po'), Comment(id='k65unkq'), Comment(id='k68mmdj'), Comment(id='k6a14z6'), Comment(id='k66ifpl'), Comment(id='k65mqcu'), Comment(id='k65t6c9'), Comment(id='k6a7y07'), Comment(id='k668xmo'), Comment(id='k6627em'), Comment(id='k67y789'), Comment(id='k65y97s'), Comment(id='k6bqn88'), Comment(id='k6axjoz'), Comment(id='k66fhrb'), Comment(id='k687wag'), Comment(id='k68muxo'), Comment(id='k6761s3'), Comment(id='k6658h9'), Comment(id='k664zov'), Comment(id='k688axv'), Comment(id='k68h0r9'), Comment(id='k6fjcf9'), Comment(id='k65uer7'), Comment(id='k6982l1'), Comment(id='k69lbsc'), Comment(id='k69xx33'), Comment(id='k69o5qs'), Comment(id='k67fa2p'), Comment(id='k6710a5'), Comment(id='k6dnvan'), Comment(id='k65tgbm'), Comment(id='k66oxqi'), Comment(id='k68cc0q'), Comment(id='k6l2fgc'), Comment(id='k66iumh'), Comment(id='k67ymvn'), Comment(id='k665eoa'), Comment(id='k6g7v4z'), Comment(id='k65uwo6'), Comment(id='k69qzzr'), Comment(id='k67q6sk'), Comment(id='k662e7s'), Comment(id='k6610ar'), Comment(id='k66tg38'), Comment(id='k68fvnj'), Comment(id='k67287z'), Comment(id='k6737pi'), Comment(id='k6jcntk'), Comment(id='k65v2wl'), Comment(id='k662vht'), Comment(id='k67m69e'), Comment(id='k67yvcr'), Comment(id='k68tfmu'), Comment(id='k677vwd'), Comment(id='k65vbxb'), Comment(id='k67swgc'), Comment(id='k6a7fex'), Comment(id='k67p4ay'), Comment(id='k65vg1m'), Comment(id='k6abnqc'), Comment(id='k65vt1p')]"
17fzyic,PaulLaughlin,,2023-10-25 08:21:07+00:00,False,,False,False,False,False,/r/datascience/comments/17fzyic/human_behaviour_is_more_complex_than_too_much/,Human behaviour is more complex than too much shallow analysis (why you need to dig deeper),,datascience,https://www.customerinsightleader.com/opinion/human-behaviour-is-more-complex-than-too-much-shallow-analysis/,2,0,0.3,"[Comment(id='k6dl5et'), Comment(id='k6dl6p0')]"
17ffp2f,cooljackiex,,2023-10-24 15:37:22+00:00,False,,False,False,True,False,/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,Consulting for coffee shops,Does anyone have experience consulting for small businesses like coffee shops or even smaller stores? There's a store near me that I would love to offer my services to for free -- but not sure how I can present myself as being useful to them and wanting them to actually work with me.,datascience,https://www.reddit.com/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,10,3,0.72,"[Comment(id='k6alhbk'), Comment(id='k6a23qe'), Comment(id='k6agb5o'), Comment(id='k6boj3k'), Comment(id='k6dqjc4'), Comment(id='k6ct2ch'), Comment(id='k6a2ixm'), Comment(id='k6d9qh9'), Comment(id='k6ej6lj'), Comment(id='k6fq2oe')]"
17fdltj,RandomBarry,,2023-10-24 14:03:55+00:00,False,,False,False,True,False,/r/datascience/comments/17fdltj/mysql_to_big_data/,"Mysql to ""Big Data""","Hi Folks,

Looking for some advice, have an ecommerce store, decent volume of data in 10m orders over the past few years etc. \~ 10GB of data.

Was looking to get the data into data studio (looker), crashed. Then looked at power bi, crashed on publishing just the order data (\~1GB)

Are there alternatives? What would the best sync to a reporting tool be?",datascience,https://www.reddit.com/r/datascience/comments/17fdltj/mysql_to_big_data/,20,4,0.67,"[Comment(id='k69f1mx'), Comment(id='k6a4739'), Comment(id='k6abumm'), Comment(id='k6czuv9'), Comment(id='k695950'), Comment(id='k6bybhb'), Comment(id='k6anw6u'), Comment(id='k6d5j5d'), Comment(id='k6ao1z3'), Comment(id='k69yzw2'), Comment(id='k6exqa6'), Comment(id='k6ay96f'), Comment(id='k6a045y'), Comment(id='k6f0fbk'), Comment(id='k6a0q7j'), Comment(id='k6a2j6d'), Comment(id='k6ao3yk'), Comment(id='k6a53ec'), Comment(id='k6a7tbn')]"
17fjeyw,hasty-beaver,,2023-10-24 18:18:28+00:00,False,,False,False,True,False,/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,"In the context of topic modeling, what should be done when the highest coherence value, given a specific 'k' value and a particular metric, does not result in interpretable topics?","Hi everyone,

I'm currently working on an LDA Topic Modeling project applied to a specific field. Essentially, I want to label different subcategories within this field. The data I'm dealing with is relatively complex and messy.

While I'm aware of the ongoing challenge of automatic topic modeling, which still requires human judgment and supervision after topics have been generated, I've read that certain metrics attempt to replace human judgment when it comes to evaluating the coherence of words within a topic (like C\_V metric). Thus, they need to be maximized (I suppose?).

However, I've also read that the most crucial consideration, in the end, is to create topics that are understandable to humans.

I find myself in a situation where I have a larger number of topics, let's say 7 < k < 10, where the Coherence metric (C\_V) peaks at 0.48, which, based on what I've read, seems like a good score. However, what happens is that, for the most, the topics themselves do not make sense at all. 

In contrast, when I set my number of topics to 3-4, I have much more interpretable topics. This might be because of the implication of summarization, which means fewer topics that gather more latent topics within the same topic.

Considering that this project is being revised by a professor, how can I justify what is going on? I know that there's specific literature out there stating that Coherence is not an entirely reliable judgement parameter, but haven't managed to find anything consistent. 

Thank you.",datascience,https://www.reddit.com/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,2,1,1.0,"[Comment(id='k6azcp6'), Comment(id='k6dtegr')]"
17esy03,htii_,,2023-10-23 19:34:26+00:00,False,,False,False,True,False,/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,"Outside of Generative AI, what are the big advances currently happening in Data Science?","There's been a lot of chatter about AI, specifically things like LLAMA 2, GPT-4, etc. But, what have been some recent advancements not in the AI sphere that are important in Data Science?",datascience,https://www.reddit.com/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,34,50,0.9,"[Comment(id='k66dk2t'), Comment(id='k66avg6'), Comment(id='k66lfeg'), Comment(id='k671ttt'), Comment(id='k66p54b'), Comment(id='k6830t2'), Comment(id='k6764p5'), Comment(id='k67yiek'), Comment(id='k6a0suj'), Comment(id='k6hk65a'), Comment(id='k68p658'), Comment(id='k680kse'), Comment(id='k68d230'), Comment(id='k6ahjdt'), Comment(id='k66s27r'), Comment(id='k66qq3e'), Comment(id='k68tu8k'), Comment(id='k68xaoj'), Comment(id='k671w58'), Comment(id='k785asj'), Comment(id='k6ahuo6'), Comment(id='k68m36l'), Comment(id='k6a71be'), Comment(id='k69e6ra'), Comment(id='k69adkb'), Comment(id='k6a1pqf'), Comment(id='k68k4my'), Comment(id='k69xoa1'), Comment(id='k69wmyh'), Comment(id='k6cfy7j'), Comment(id='k6c6f64'), Comment(id='k6cmvjm'), Comment(id='k6i6hno'), Comment(id='k6dcq6f'), Comment(id='k6i82bl')]"
17eot80,Alucard2051,,2023-10-23 16:39:32+00:00,False,,False,False,True,False,/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,What do you do in SQL vs Pandas?,"My work primarily stores data in a full databases. Pandas has a lot of similar functionality to SQL in regards to the ability to group data and preform calculations, even being able to take full on SQL queries to import data. Do you guys do all your calculations in the query itself, or in python after the data has been imported? What about with grouping data?",datascience,https://www.reddit.com/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,64,64,0.94,"[Comment(id='k64r5sd'), Comment(id='k64l7t8'), Comment(id='k64l887'), Comment(id='k65h29d'), Comment(id='k65jmxt'), Comment(id='k65hrki'), Comment(id='k66koip'), Comment(id='k64ljh0'), Comment(id='k64msly'), Comment(id='k64ypmr'), Comment(id='k64vgk2'), Comment(id='k67b23o'), Comment(id='k67spdn'), Comment(id='k660495'), Comment(id='k662wlc'), Comment(id='k67jqt6'), Comment(id='k66q2ss'), Comment(id='k64pdap'), Comment(id='k64tzrk'), Comment(id='k65j73g'), Comment(id='k666kyo'), Comment(id='k686vjr'), Comment(id='k68c9fu'), Comment(id='k69a9kw'), Comment(id='k69rl3w'), Comment(id='k69sj76'), Comment(id='k69whph'), Comment(id='k6ae5gh'), Comment(id='k6agkg3'), Comment(id='k6agy2y'), Comment(id='k6ndhay'), Comment(id='k7533m5'), Comment(id='k65vfpz'), Comment(id='k66w1ps'), Comment(id='k66ueec'), Comment(id='k66q0mo'), Comment(id='k65xeza'), Comment(id='k662p0i'), Comment(id='k65ttuw'), Comment(id='k66fmuw'), Comment(id='k6g6bfg'), Comment(id='k66geez'), Comment(id='k683spg'), Comment(id='k6g71n3'), Comment(id='k664dpz'), Comment(id='k66q3y1'), Comment(id='k64q1kj'), Comment(id='k65gsp8'), Comment(id='k68dd5l'), Comment(id='k67ua27'), Comment(id='k662h4o'), Comment(id='k6g6g32'), Comment(id='k66n7at'), Comment(id='k69b1ca'), Comment(id='k665cp3'), Comment(id='k65up3t'), Comment(id='k68ny79'), Comment(id='k663jw6'), Comment(id='k66q0ie'), Comment(id='k6bl9no'), Comment(id='k67eee9'), Comment(id='k68vfvv'), Comment(id='k665cwr')]"
17el93s,NewEcho2940,,2023-10-23 14:07:26+00:00,False,,False,False,True,False,/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,What do fellow Data Science Directors do?,"I am a director and I feel like I barely do ""Data Science"" any more. My job is mostly about working with engineers and architects to facilitate data collection and data tools (python, spark) for my team. Is this relevant for career advancement or do I need to refocus more on hard skills and learning new stuff.",datascience,https://www.reddit.com/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,41,83,0.95,"[Comment(id='k640rvt'), Comment(id='k63w0zo'), Comment(id='k641kqk'), Comment(id='k645bqs'), Comment(id='k64auvc'), Comment(id='k642vmr'), Comment(id='k647z56'), Comment(id='k64d05u'), Comment(id='k64wr5v'), Comment(id='k655siu'), Comment(id='k65vrbq'), Comment(id='k63wuy4'), Comment(id='k64mmad'), Comment(id='k64aa29'), Comment(id='k66f1or'), Comment(id='k66n66v'), Comment(id='k67edlf'), Comment(id='k6bm67b'), Comment(id='k645sb8'), Comment(id='k641xvv'), Comment(id='k63zfy8'), Comment(id='k63yb49'), Comment(id='k647yw3'), Comment(id='k64h3s9'), Comment(id='k65x326'), Comment(id='k63y2ly'), Comment(id='k64h6a5'), Comment(id='k64ifjx'), Comment(id='k65ogwo'), Comment(id='k65kpvb'), Comment(id='k63zi0j'), Comment(id='k64wn7x'), Comment(id='k65t0by'), Comment(id='k66lc6b'), Comment(id='k63zxnx'), Comment(id='k64gxvv'), Comment(id='k652j4h'), Comment(id='k643z5v'), Comment(id='k642ih7'), Comment(id='k6457up'), Comment(id='k64jaxv'), Comment(id='k66ysyh')]"
17fbj3u,Thinker_Assignment,,2023-10-24 12:24:31+00:00,False,,False,False,True,False,/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,ConnectorX + Arrow + dlt loading: Up to 30x speed gains in test,"Hey folks

over at [https://pypi.org/project/dlt/](https://pypi.org/project/dlt/) we added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -> analytics copying can go up to 30x faster over a classic sqlite connector.

Read about the benchmark comparison and the underlying technology here: [https://dlthub.com/docs/blog/dlt-arrow-loading](https://dlthub.com/docs/blog/dlt-arrow-loading)

One disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine or batch on extraction. Code example how to use: [https://dlthub.com/docs/examples/connector\_x\_arrow/](https://dlthub.com/docs/examples/connector_x_arrow/)

By adding this support, we also enable these sources:[https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas](https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas)

If you need help, don't miss the gpt helper link at the bottom of our docs or the slack link at the top.

Feedback is very welcome!

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,0,1,1.0,[]
17er8bt,Dependent_Mushroom98,,2023-10-23 18:22:45+00:00,False,,False,False,True,False,/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,"Besides FAANG, what other companies out there are doing actual DS or MLE work?","In my present company we are just chasing ad hoc analytical  work - these never gets into production. The processes are very ad hoc, not streamlined, no structure to it, running from personal notebooks. It’s very demoralizing to see models developed from 2017 that are in production and have not been refreshed thought the data it used for inference is constantly changing as my company looks at market finance data. 

I’m wondering what are other good companies to look out for that are either applying best practices in DS/ML and not just the talk or building product/services. 

I understand recent news in GenAI is sparking lot of conversations but which companies out there are grabbing it by the horns and taking the lead? Perhaps if you are fortunate to work for one such company you may want to share your story. Appreciate your insights very much!",datascience,https://www.reddit.com/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,17,20,0.76,"[Comment(id='k6549xo'), Comment(id='k657byg'), Comment(id='k65oihw'), Comment(id='k65ivyp'), Comment(id='k66rjlq'), Comment(id='k6cyzeu'), Comment(id='k6674ft'), Comment(id='k66s2bl'), Comment(id='k6657r0'), Comment(id='k67ou44'), Comment(id='k69nfiy'), Comment(id='k6b1q1o'), Comment(id='k6cm7n6'), Comment(id='k6574i0'), Comment(id='k65o7di'), Comment(id='k67s98g'), Comment(id='k65pcgb')]"
17eiqbl,helliun,,2023-10-23 12:03:41+00:00,False,,False,False,False,False,/r/datascience/comments/17eiqbl/pandasbased_library_for_graphing_emotion_events/,Pandas-based library for graphing emotion events with LMs for in-depth sentiment analysis,,datascience,https://i.redd.it/hdls4kgrzxvb1.jpg,6,50,0.96,"[Comment(id='k63edjy'), Comment(id='k63j8xe'), Comment(id='k64kb5d'), Comment(id='k64nhe2'), Comment(id='k64ogtg'), Comment(id='k650q78')]"
17f7jo6,QFA_official,,2023-10-24 07:59:09+00:00,False,,False,False,True,False,/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,Machine learning for Asset Allocation and long/short decisions in a Tactical Asset Allocation Strategy,"&#x200B;

I'd love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I'd love to hear any thoughts on Machine Learning directly applicable to time-series data specifically here I am applying machine learning to drive asset allocation in an investmen portfolio

[https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model](https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model)

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,0,1,0.67,[]
17efkcz,limedove,,2023-10-23 08:32:14+00:00,False,,False,False,True,False,/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/,What are the non-data scientist tasks that you still do in your data scientist role?,,datascience,https://www.reddit.com/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/,69,64,0.92,"[Comment(id='k62x1cj'), Comment(id='k63bs6s'), Comment(id='k633wh0'), Comment(id='k641xuv'), Comment(id='k63kdpb'), Comment(id='k658kkp'), Comment(id='k639vvi'), Comment(id='k63az12'), Comment(id='k647cdh'), Comment(id='k63tkxo'), Comment(id='k657zv2'), Comment(id='k66aoy2'), Comment(id='k63gg2w'), Comment(id='k62xnv7'), Comment(id='k63v5uy'), Comment(id='k642twt'), Comment(id='k660ngc'), Comment(id='k69gvcu'), Comment(id='k63djd4'), Comment(id='k63mven'), Comment(id='k64tfo0'), Comment(id='k63tstv'), Comment(id='k64q7na'), Comment(id='k65sc0j'), Comment(id='k66vnmr'), Comment(id='k68hxay'), Comment(id='k69nn44'), Comment(id='k6aawwc'), Comment(id='k6dm0jm'), Comment(id='k644naf'), Comment(id='k63eacx'), Comment(id='k63l6fn'), Comment(id='k64hjhn'), Comment(id='k63we5c'), Comment(id='k6873jb'), Comment(id='k647adk'), Comment(id='k64nx12'), Comment(id='k6584uf'), Comment(id='k63safw'), Comment(id='k6417oc'), Comment(id='k63960e'), Comment(id='k64c2x1'), Comment(id='k63x3wb'), Comment(id='k63u7jh'), Comment(id='k6dnmx1'), Comment(id='k6dnpck'), Comment(id='k64vz8k'), Comment(id='k680wvo'), Comment(id='k66oyz2'), Comment(id='k63n5hs'), Comment(id='k645321'), Comment(id='k642m7g'), Comment(id='k67cg2r'), Comment(id='k63g15a'), Comment(id='k64cafs'), Comment(id='k63uyd6'), Comment(id='k6fd8ux'), Comment(id='k63rn95'), Comment(id='k64y1mv'), Comment(id='k661ssq'), Comment(id='k69fxip'), Comment(id='k644weq'), Comment(id='k64efbi'), Comment(id='k64bnhb'), Comment(id='k65vnwl'), Comment(id='k645hua'), Comment(id='k64ki7t'), Comment(id='k65ho6q'), Comment(id='k67bvrc'), Comment(id='k67xzqv')]"
17f6c47,Efficient-Middle-701,,2023-10-24 06:31:46+00:00,False,,False,False,True,False,/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,Data science in floriculture/horticulture,Anyone having experience in this sector? Looking for a seasoned data scientist in this sector,datascience,https://www.reddit.com/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,1,1,1.0,[Comment(id='k6awln3')]
17f3whi,unknow_from_vietnam,,2023-10-24 03:58:06+00:00,False,,False,False,True,False,/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,[Discussion] Paraphrase for Writing Tone,"Hi Everyone,

Recently, I have been doing a task related to paraphrasing in writing tones. Specifically, I'm trying to fine-tune the pre-trained model (text generation model) to create a model capable of rewriting according to the transmitted tone.

Currently, I am trying to crawl data (about 1500 samples) for training. However, the results were not as good as I thought. I'm currently quite stuck, can you guys suggest to me some research or open-source or pre-trained models that you've tried?

Thank you

P/s: model I have tried

[https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic](https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic)

[https://huggingface.co/Vamsi/T5\_Paraphrase\_Paws](https://huggingface.co/Vamsi/T5_Paraphrase_Paws)

[https://huggingface.co/humarin/chatgpt\_paraphraser\_on\_T5\_base](https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base)",datascience,https://www.reddit.com/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,0,0,0.5,[]
17f02jx,citizenofacceptance,,2023-10-24 00:46:13+00:00,False,,1698109573.0,False,True,False,/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,Anyone have a good blog or resource on Product-led experimentation?,"Would be nice to understand frameworks , experiment types, how to determine what experiment to use , and where and when to apply them to a saas company and help them prioritize a roadmap against it. 
",datascience,https://www.reddit.com/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,8,1,1.0,"[Comment(id='k678scn'), Comment(id='k678a6k'), Comment(id='k66r3d3'), Comment(id='k66wqi2'), Comment(id='k66s8hw'), Comment(id='k66w2bd'), Comment(id='k66wer5'), Comment(id='k676ts2')]"
17eug5a,FrozenSoul90,,2023-10-23 20:37:58+00:00,False,,False,False,True,False,/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,Any pointers / resources on how one would implement a ML model for product demand transference and substititabilty,"I am currently undergoing Apprenticeships programme for ML, and looking for projects in our organization.

""Demand Transference and Substititabilty"" in retail food stores is one of the ideas that came up. So i am trying to find on how to implement it and if we have all the required data before finalising the project selection. 

Any resources or information would be great :)",datascience,https://www.reddit.com/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,2,2,0.75,"[Comment(id='k67wu40'), Comment(id='k68tgwu')]"
17eu7oy,ExpressOcelot8977,,2023-10-23 20:28:20+00:00,False,,False,False,True,False,/r/datascience/comments/17eu7oy/why_would_anyone_start_to_use_hex_whats_the_need/,Why would anyone start to use Hex? What’s the need or situation?,,datascience,https://www.reddit.com/r/datascience/comments/17eu7oy/why_would_anyone_start_to_use_hex_whats_the_need/,15,2,0.58,"[Comment(id='k65xff5'), Comment(id='k65ty20'), Comment(id='k66i3yt'), Comment(id='k67pjon'), Comment(id='k67b2at'), Comment(id='k67ppq3'), Comment(id='k68eutk'), Comment(id='k675ukh'), Comment(id='k67q1j9'), Comment(id='k6a5x8o'), Comment(id='k6814s7'), Comment(id='k6a78n0'), Comment(id='k6a5qrv'), Comment(id='k6ane69'), Comment(id='k6avx9k')]"
17ew2w4,bbmr__95,,2023-10-23 21:45:22+00:00,False,,False,False,True,False,/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,Estimating sales of a new store,"I've got the task to estimate the sales level of a store in a place near a mall and a office area. Would like to know if somebody here has made a similar task reacently or has any idea of how can i get an estimation.

I have data of 6 more stores of the same company (sales, transactions, area fo the store, #people near a 15 minute isochrone, if the stores are near offices, colleges, residential areas, etc).

I've been planning to run a regression model or a decision tree and later use trained model to estimate the sales level of the new position, but just having 6 stores makes it hard to have a consistent estimation.

What other options could i do to have a good estimation of this new position? what other things i have to consider o look for to have as data in my model? is there any framework for this kind of task?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,4,1,1.0,"[Comment(id='k664obo'), Comment(id='k7mt2ok'), Comment(id='k6b6djh'), Comment(id='k6bfseu')]"
17euytw,Notgen3ric,,2023-10-23 20:59:51+00:00,False,,False,False,True,False,/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,Best way to go about showing progress as work is done to a dataset,"Hello there,

I'm an undergrad student that is currently working on a Kaggle dataset and I want to document my progression and be able to share it as I go. In addition, I'd really want to get involved with the DS community. Now, I do have deficiency in certain tools like GitHub which is a place I could post my work. However, I do also want to be able to include it in my resume as I think it would make it more appealing for recruiters in the future. What is the best way to go about this? Just create a reddit or LinkedIn Post (like a progress post) or simply just have it up on GitHub and learn how to use the tool ? Thank you in advance for your suggestions.",datascience,https://www.reddit.com/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,7,1,0.6,"[Comment(id='k65tomo'), Comment(id='k67faim'), Comment(id='k662ouo'), Comment(id='k65zjen'), Comment(id='k6bfssh'), Comment(id='k679ywx'), Comment(id='k6edwv8')]"
17eriso,oh5oh5,,2023-10-23 18:35:12+00:00,False,,False,False,True,False,/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,PG extension (Apache AGE) for adding graph analytics functionality,"I have talked this previously, that like, I am working as a data analyst but is it worth to learn graph database. I got some comments that saying master SQL first, then learn other tools. For me, learning a new fun tool is for my free time so I thought, OK, I will just try it. It is been a month almost and came back to think like,,, I don't feel the graph database is that much worth to learn especially if I consider the size of the market.

However, maybe, if there's a PG extension that adds graph analytics to PG database, which I use everyday, it would be fun because I can actually utilize it with my PG data. Apache AGE is an open-source PG extension that really solves the problem that I'm having right now. I will leave the [github link](https://github.com/apache/age) and a [webinar link](https://us06web.zoom.us/webinar/register/2516980853755/WN_mzhlCggCQ_ytIxiGb9ioTg) that they (I guess Apache Foundation?) organize like bi-weekly. For those who are having same thought process with me, I think you guys also can just try? What do you think?",datascience,https://www.reddit.com/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,0,1,1.0,[]
17erhca,Dependent_Mushroom98,,2023-10-23 18:33:25+00:00,False,,False,False,True,False,/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,Relational database to graph database using NLP/LLM?,I’m looking to discover new relationships that exist in the relational database and then generate ingestion script to populate a graph database. Are there tools already exhausting for this and what are their limitations? Can we he new LLMs come to rescue?,datascience,https://www.reddit.com/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,0,1,1.0,[]
17epzut,ConsiderationRoyal87,,2023-10-23 17:29:20+00:00,False,,1698088665.0,False,True,False,/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,Good survey of predictive techniques?,"Currently on a job search, and of course many DS roles are seeking prediction/forecasting skills. Can anyone recommend an overview of different predictive techniques? It could be an article, video, book, or even your own explanation.

There are so many things one could learn about regression, machine learning, etc. and I would find it useful to have some sort of organizing framework for various methods of prediction.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,5,0,0.4,"[Comment(id='k66vzqt'), Comment(id='k66dozv'), Comment(id='k64unqy'), Comment(id='k66sxpm'), Comment(id='k66wfi1')]"
17dtmqe,jumpi3y,,2023-10-22 13:45:03+00:00,False,,False,False,True,False,/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,How do you guys practise using MySQL,Hi I'm fairly new to Data Science and I'm only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?,datascience,https://www.reddit.com/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,74,153,0.95,"[Comment(id='k5z2y4s'), Comment(id='k5zkb8i'), Comment(id='k5z3qzk'), Comment(id='k5yy66e'), Comment(id='k62frdx'), Comment(id='k5yt8gt'), Comment(id='k5zl4l8'), Comment(id='k5z2vfo'), Comment(id='k5ztdl3'), Comment(id='k5ywyd6'), Comment(id='k5zhivr'), Comment(id='k5zmun3'), Comment(id='k61i8aq'), Comment(id='k62whf4'), Comment(id='k5zwqzc'), Comment(id='k61itgf'), Comment(id='k5zk4ic'), Comment(id='k5zn9cs'), Comment(id='k5zp94o'), Comment(id='k5zv9or'), Comment(id='k604blo'), Comment(id='k604ycs'), Comment(id='k60d18d'), Comment(id='k60di6n'), Comment(id='k60dkyc'), Comment(id='k60g554'), Comment(id='k610zr5'), Comment(id='k6114ka'), Comment(id='k61fhy1'), Comment(id='k61pgz9'), Comment(id='k61wfkr'), Comment(id='k61wtbo'), Comment(id='k61yg2l'), Comment(id='k620fq3'), Comment(id='k62267c'), Comment(id='k627nd9'), Comment(id='k62hu5q'), Comment(id='k62kwsq'), Comment(id='k63dlpe'), Comment(id='k64st70'), Comment(id='k64wt7d'), Comment(id='k656nso'), Comment(id='k5zetis'), Comment(id='k61cl6n'), Comment(id='k62i8cg'), Comment(id='k5z4log'), Comment(id='k60cy14'), Comment(id='k63uads'), Comment(id='k64qzjc'), Comment(id='k5zbwjy'), Comment(id='k5zm69n'), Comment(id='k5yzr8s'), Comment(id='k5z6rbf'), Comment(id='k60nndz'), Comment(id='k632i16'), Comment(id='k60b0rk'), Comment(id='k6280ik'), Comment(id='k63f6ec'), Comment(id='k5z7h25'), Comment(id='k65q68d'), Comment(id='k66huxq'), Comment(id='k5z4fg9'), Comment(id='k5z7j90'), Comment(id='k64uzhl'), Comment(id='k60zf7p'), Comment(id='k63lejq'), Comment(id='k5zjtjo'), Comment(id='k5zmice'), Comment(id='k6dirb0'), Comment(id='k6128l3'), Comment(id='k67wpon'), Comment(id='k62xkov'), Comment(id='k684ehr'), Comment(id='k68649l')]"
17enm4q,Pristine-Sound-484,,2023-10-23 15:49:48+00:00,False,,1698095309.0,False,True,False,/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,Address parsing with NLP or with regex,"Hi i am working on this a project and its a module of a huge project where i have to write code  to parse address provided.

I was first using Libpostal but for the provided data, libpostal is not effiecient and i want to create my custom parsing.

I am trying to use regex but it seems very complicated. Can anyone help me if there’s any other way .

I found it is possible using NLP with spaCy.

Please guide",datascience,https://www.reddit.com/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,12,0,0.5,"[Comment(id='k64diam'), Comment(id='k64v4fg'), Comment(id='k657ctj'), Comment(id='k64wq9c'), Comment(id='k65rpte'), Comment(id='k65rque'), Comment(id='k7sl1z9'), Comment(id='k651ap4'), Comment(id='k66ec0q'), Comment(id='k676u05'), Comment(id='k676sny'), Comment(id='k69poin')]"
17en64n,Individual-School-07,,2023-10-23 15:30:41+00:00,False,,False,False,True,False,/r/datascience/comments/17en64n/project_interface/,Project Interface.,"Hello,

I'm updating my Portfolio to get back to DS. Working on a project I'd like to put the algorithm into an interface. Is it better to try and do it using other programming languages like JavaScript or Python is sufficient using Flask or Streamlit ? ",datascience,https://www.reddit.com/r/datascience/comments/17en64n/project_interface/,2,1,1.0,"[Comment(id='k64vhi1'), Comment(id='k69b7p6')]"
17exd28,indusop,,2023-10-23 22:40:26+00:00,False,,False,False,False,False,/r/datascience/comments/17exd28/just_read_the_fascinating_article_about/,Just read the fascinating article about deployment of website using streamlit.How easy it has become to deploy and develop any website using this tool,,datascience,https://medium.com/@harshsmj1504/ipl-win-predictor-easy-streamlit-development-and-deployment-guide-bce15bce99b1,3,0,0.17,"[Comment(id='k67dyur'), Comment(id='k67sitd'), Comment(id='k6apmp6')]"
17em9tn,h3dgyy,,2023-10-23 14:53:56+00:00,False,,False,False,True,False,/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,Looking for a Data Science Program,I am a software engineer with 10yo experience. Can someone recommend a good Data Science program? I am willing to spend 3-6 months to get a deep understanding of the fundamentals.,datascience,https://www.reddit.com/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,2,0,0.5,"[Comment(id='k64gy1q'), Comment(id='k67k5ll')]"
17e01li,Aware_Value4603,,2023-10-22 18:38:37+00:00,False,,False,False,True,False,/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,Do you remember the syntax of the tools you use?,"To all the data science professionals, enthusiasts and learners, do y'all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? 

I have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there's also R, C++ and other languages that sometimes come into the picture. 

This made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. 

Also, if you use any resources which are popular, please share in the comments.",datascience,https://www.reddit.com/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,36,39,0.85,"[Comment(id='k6012ot'), Comment(id='k60bd67'), Comment(id='k60u0kw'), Comment(id='k61lrz3'), Comment(id='k616bch'), Comment(id='k61ie4d'), Comment(id='k61ei9w'), Comment(id='k61flcj'), Comment(id='k60oxu5'), Comment(id='k614bqo'), Comment(id='k61pw4d'), Comment(id='k61ynjq'), Comment(id='k622h1l'), Comment(id='k624byw'), Comment(id='k640h3u'), Comment(id='k61ltzq'), Comment(id='k60rmdt'), Comment(id='k61lfyb'), Comment(id='k62f9rf'), Comment(id='k618mq6'), Comment(id='k63zx5h'), Comment(id='k61zrcn'), Comment(id='k61vi3b'), Comment(id='k63z0sd'), Comment(id='k62h2by'), Comment(id='k61zg4y'), Comment(id='k63ho8s'), Comment(id='k63kfsf'), Comment(id='k61zmty'), Comment(id='k62hd7g'), Comment(id='k629o32'), Comment(id='k62s1sa'), Comment(id='k62hsxx'), Comment(id='k67ovw3'), Comment(id='k67oky3'), Comment(id='k67yat8')]"
17eh6kb,Asleep-Fun-6508,,2023-10-23 10:29:38+00:00,False,,False,False,True,False,/r/datascience/comments/17eh6kb/productivity_help/,Productivity help,"Happy monday guys! 

Quick question – what do you do on light days where you don’t have much(or any) work and want to maintain your productivity, especially when working from home? 

I would love to increase my theory/stress on learning new skills! So if you’re one who reads books/blogs would love to know what you guys read or any book recommendations

Cheers guys, have a great week!",datascience,https://www.reddit.com/r/datascience/comments/17eh6kb/productivity_help/,6,2,0.63,"[Comment(id='k63bp1u'), Comment(id='k63ggmw'), Comment(id='k64owg7'), Comment(id='k64213r'), Comment(id='k64n6v5'), Comment(id='k6gss3p')]"
17eafwm,ResponsibleGazelle76,,2023-10-23 02:52:24+00:00,False,,1698030264.0,True,True,False,/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,What problems would you like to be solved?,"I'm a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it's not out there, etc. Looking to help :)",datascience,https://www.reddit.com/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,43,9,0.61,"[Comment(id='k6256hn'), Comment(id='k62mk5y'), Comment(id='k62azo7'), Comment(id='k62p2ze'), Comment(id='k6316iz'), Comment(id='k62b4ls'), Comment(id='k628hic'), Comment(id='k62w5ol'), Comment(id='k62olth'), Comment(id='k66decm'), Comment(id='k63lg75'), Comment(id='k638bfl'), Comment(id='k63qdpr'), Comment(id='k69gbef'), Comment(id='k6gt7f2'), Comment(id='k62hhdz'), Comment(id='k62zogx'), Comment(id='k69ghwk'), Comment(id='k63d4sh'), Comment(id='k63hxv3'), Comment(id='k63gpha'), Comment(id='k64320u'), Comment(id='k65kedk'), Comment(id='k62c2zf'), Comment(id='k62ukr1'), Comment(id='k64hiow'), Comment(id='k62nukl'), Comment(id='k62ctf1'), Comment(id='k62ztl4'), Comment(id='k64ivws'), Comment(id='k63femi'), Comment(id='k63paqn'), Comment(id='k6439of'), Comment(id='k65wkmq'), Comment(id='k63e4iv'), Comment(id='k63e5xm'), Comment(id='k63jc2u'), Comment(id='k6d6shh'), Comment(id='k674r84'), Comment(id='k63kmgy'), Comment(id='k63foz0'), Comment(id='k646wbt'), Comment(id='k64jgl2')]"
17eboh0,AutoModerator,,2023-10-23 04:01:26+00:00,False,,False,False,True,False,/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/,"Weekly Entering & Transitioning - Thread 23 Oct, 2023 - 30 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/,107,5,0.86,"[Comment(id='k64b5fi'), Comment(id='k64jjlb'), Comment(id='k6mq40h'), Comment(id='k6v0ylu'), Comment(id='k6xctcw'), Comment(id='k6ymhye'), Comment(id='k6z6wq9'), Comment(id='k62vvie'), Comment(id='k63tomr'), Comment(id='k63yp33'), Comment(id='k6489qw'), Comment(id='k64uot0'), Comment(id='k650z2t'), Comment(id='k65w9fe'), Comment(id='k67t828'), Comment(id='k67vky9'), Comment(id='k6b9py4'), Comment(id='k6bd9mu'), Comment(id='k6c1cpw'), Comment(id='k6fdhqa'), Comment(id='k6fix9g'), Comment(id='k6gj1h7'), Comment(id='k6gy6ub'), Comment(id='k6he4s7'), Comment(id='k6i4t8z'), Comment(id='k6j907k'), Comment(id='k6ky1dn'), Comment(id='k6lgrld'), Comment(id='k6mvuj2'), Comment(id='k6pn2hz'), Comment(id='k6t2z1l'), Comment(id='k6u2885'), Comment(id='k6ywbnk'), Comment(id='k6zq8qt'), Comment(id='k71atex'), Comment(id='k664661'), Comment(id='k6896bi'), Comment(id='k6928k0'), Comment(id='k67x0ye'), Comment(id='k6wvbgu'), Comment(id='k6wucf1'), Comment(id='k6ysvo9'), Comment(id='k70qtds'), Comment(id='k63ve9k'), Comment(id='k67wj49'), Comment(id='k664ba1'), Comment(id='k67wrwm'), Comment(id='k67xjap'), Comment(id='k681mq3'), Comment(id='k688mfl'), Comment(id='k67y0ro'), Comment(id='k67vnb0'), Comment(id='k67y5ad'), Comment(id='k6ci9rn'), Comment(id='k6ww4rm'), Comment(id='k6ww04s'), Comment(id='k6wvry2'), Comment(id='k6iqe2d'), Comment(id='k6xjvno'), Comment(id='k6jjtbt'), Comment(id='k6l6kc2'), Comment(id='k6jjpif'), Comment(id='k6wvhsz'), Comment(id='k6nsc2j'), Comment(id='k6wv5am'), Comment(id='k6pnsie'), Comment(id='k6uxccp'), Comment(id='k6wuorf'), Comment(id='k667h1j'), Comment(id='k6z5waj'), Comment(id='k686cz0'), Comment(id='k6869tq'), Comment(id='k664im4'), Comment(id='k69xaxh'), Comment(id='k69iz14'), Comment(id='k69b3cc'), Comment(id='k685925'), Comment(id='k67yi8g'), Comment(id='k6cpil2'), Comment(id='k6jlxx1'), Comment(id='k6mil47'), Comment(id='k71dmhe'), Comment(id='k6x73oc'), Comment(id='k6wux8d'), Comment(id='k6wurqs'), Comment(id='k6y59y2'), Comment(id='k6zhw55'), Comment(id='k699qr2'), Comment(id='k676f1q'), Comment(id='k688976'), Comment(id='k69mpky'), Comment(id='k6cpl8y'), Comment(id='k6jo8up'), Comment(id='k6s57v2'), Comment(id='k71hubs'), Comment(id='k6zfqnp'), Comment(id='k6xg2ld'), Comment(id='k6zgssv'), Comment(id='k68mgyy'), Comment(id='k6zfh39'), Comment(id='k6zl6a9'), Comment(id='k6zrm7s'), Comment(id='k701o9n'), Comment(id='k702dbm'), Comment(id='k704z1k')]"
17e7m1p,feldomatic,,2023-10-23 00:26:13+00:00,False,,False,False,True,False,/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,Native Linux Users: How do you setup your DS Environment?,"Not talking folks who work off linux servers or VMs, I'm talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)

I do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.

I was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.

Rolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.

Not against going back to Anaconda, but I'm curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going.",datascience,https://www.reddit.com/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,19,9,0.74,"[Comment(id='k61keba'), Comment(id='k61ik7o'), Comment(id='k61onnf'), Comment(id='k61z9g1'), Comment(id='k61l95j'), Comment(id='k61tltp'), Comment(id='k62n6ap'), Comment(id='k62okk4'), Comment(id='k62p2fw'), Comment(id='k6297at'), Comment(id='k64yj6j'), Comment(id='k694bwp'), Comment(id='k69k2dz'), Comment(id='k61ls59'), Comment(id='k61iuox'), Comment(id='k61zdup'), Comment(id='k6fivso'), Comment(id='k63i6su'), Comment(id='k6fkls7')]"
17erxid,DellSucksTbh,,2023-10-23 18:52:34+00:00,False,,False,False,True,False,/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,How many hours do other data analysts work?,"Separating things like meetings and actually sitting down and writing code/working through problems, what's your workload like?

I work for an academic department and I can't tell if things are...off lol. It's my first real job btw. ",datascience,https://www.reddit.com/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,8,0,0.42,"[Comment(id='k65dnmh'), Comment(id='k65clrn'), Comment(id='k66dhew'), Comment(id='k68ltct'), Comment(id='k65l55c'), Comment(id='k65vihb'), Comment(id='k6870o8'), Comment(id='k686zav')]"
17e02jy,errOnCaution_,,2023-10-22 18:39:54+00:00,False,,1698098429.0,False,True,False,/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,The obsession/hate for DS undergrad degrees,"I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren't technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.

That being said, a ton of programs for DS out there including the one I'm taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.

&#x200B;

Just a rant, I've been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?

Edit: most people are assuming I want to immediately jump into a DS role. I do not. I plan on being an analyst or some other entry level adjacent role before for a few years before switching to DS or DE.

I think most any undergraduate would fall flat on their face besides the most technical and self taught alongside their classes if they jumped into DS from the getgo, assuming someone with even a year more experience doesn't beat you to the punch first.


If you disagree with something I, or anyone else says in here, instead of down voting to all oblivion tell myself or that person you disagree with *why* they're wrong and need to switch their viewpoint. I'll be making a summary of the points I've seen in here in a few days for people to look through in the future.

----------------------------------------------------------------------------------

Here's the summary of points I've seen made here that have convinced me to switch to CS/Stats minor for anyone in the future who might also have the same question whether or not to choose or switch away from a DS undergrad degree. If I missed anything shoot me a message.

1. CS/Stats is a much more flexible degree path, if the landscape of data as a whole changes, this degree structure is going to be vastly more resistant to changes in what a ""Data Scientist"" even is in the labor market. This choice will also set you up much post for grad school.

2. DS degree graduates, no matter how quality the program is, will be passed in comparison to a CS major. Pre-conceived notions are hard to change and DS degrees are very new / lack a generalized structure compared to CS and Stats majors that more or less have an expected outcome quality in graduates.

3. DS degree graduates as a result of the lack of a single path / consistent course training, *will have gaps in basic skills/knowledge CS/Stats minor graduates won't*. It's best to embrace the filter classes of CS degrees to make sure you aren't falling flat on your face if you get into a DS role.

4. Whether you're choosing something more programming focused like Data Engineering, or something more research / statistically focused like a Data Scientist, CS/Stats will just flat out prepare you better for those jobs while keeping your options open for other roles in CompSci if you end up changing your mind.

5. DS degrees are fine if you plan on being an Analyst, but then again, there are a lot of other non-technical degrees that can become analysts.

6. Projects are not weighted as heavily as people might think, recruiters most likely will not be looking at them unless in very specific scenarios which is why having a better base of CS/Stats tends to work out better.

7. Some aspects of CS degrees will suck but in the grand scheme of being more marketable, the difference in prestige and chances of landing a job vs a DS degree is significant enough to switch degrees or choose CS/Stats to begin with. 

8. In a summarized sense, getting a CS/Stats minor focus is a more pure form of what DS courses should be, but aren't.

Thanks to everyone who didn't just downvote the post and wrote their own perspective, I'll be talking with a counselor to switch to CS & Stats minor tomorrow.

And good luck to anyone in the future coming to this post for answers, it is worth choosing a CS degree and if you have any questions and you're coming through here months or years from now, read through the comments on here to make sure you're making the best decisions for your career.",datascience,https://www.reddit.com/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,109,25,0.66,"[Comment(id='k60tmzn'), Comment(id='k60bnd5'), Comment(id='k60my9q'), Comment(id='k61ftu0'), Comment(id='k60a7k6'), Comment(id='k61pl23'), Comment(id='k61s89x'), Comment(id='k62ovwt'), Comment(id='k63iotf'), Comment(id='k60m3t7'), Comment(id='k606d91'), Comment(id='k60parb'), Comment(id='k61w9cs'), Comment(id='k6147qr'), Comment(id='k60regh'), Comment(id='k6147a4'), Comment(id='k61g84i'), Comment(id='k6237vv'), Comment(id='k635fcl'), Comment(id='k6366ne'), Comment(id='k64153d'), Comment(id='k650d46'), Comment(id='k6591jx'), Comment(id='k65uj81'), Comment(id='k619z48'), Comment(id='k62o4m0'), Comment(id='k60u5a7'), Comment(id='k64s7au'), Comment(id='k60p95h'), Comment(id='k62om0c'), Comment(id='k62oj7v'), Comment(id='k60s12y'), Comment(id='k61qtim'), Comment(id='k6362lw'), Comment(id='k636cxs'), Comment(id='k6470xc'), Comment(id='k60rhm6'), Comment(id='k60z6h0'), Comment(id='k60rswk'), Comment(id='k60g1gl'), Comment(id='k60sfms'), Comment(id='k60t4hu'), Comment(id='k614p14'), Comment(id='k60xbpf'), Comment(id='k60to05'), Comment(id='k637cpt'), Comment(id='k642x5y'), Comment(id='k65bhge'), Comment(id='k6600pi'), Comment(id='k61oyci'), Comment(id='k617i3t'), Comment(id='k61o4yc'), Comment(id='k631ccr'), Comment(id='k62oazg'), Comment(id='k64tekn'), Comment(id='k60s2ri'), Comment(id='k66lnyn'), Comment(id='k6323y3'), Comment(id='k64ezya'), Comment(id='k646ha0'), Comment(id='k60s3m6'), Comment(id='k61511q'), Comment(id='k62dks5'), Comment(id='k60jceg'), Comment(id='k60h257'), Comment(id='k60th0v'), Comment(id='k626pkb'), Comment(id='k60zim1'), Comment(id='k60vyap'), Comment(id='k60yir7'), Comment(id='k6385pf'), Comment(id='k6448u3'), Comment(id='k618kpn'), Comment(id='k60trli'), Comment(id='k6471yj'), Comment(id='k652mii'), Comment(id='k64q9in'), Comment(id='k60snj0'), Comment(id='k60p5bz'), Comment(id='k611n8m'), Comment(id='k63a8u3'), Comment(id='k646c8b'), Comment(id='k61asq4'), Comment(id='k6122tb'), Comment(id='k65m6ps'), Comment(id='k60sksb'), Comment(id='k6125kn'), Comment(id='k63atro'), Comment(id='k64cq7y'), Comment(id='k612p7g'), Comment(id='k65oekz'), Comment(id='k60toju'), Comment(id='k612iup'), Comment(id='k64jry6'), Comment(id='k613a7u'), Comment(id='k65tcqs'), Comment(id='k60ufd0'), Comment(id='k636qer'), Comment(id='k6148yv'), Comment(id='k61439j'), Comment(id='k65tmk6'), Comment(id='k60v7bl'), Comment(id='k63tiez'), Comment(id='k6157p1'), Comment(id='k60x1xn'), Comment(id='k641liu'), Comment(id='k616tjo'), Comment(id='k60yjpj'), Comment(id='k61875x'), <MoreComments count=0, children=[]>]"
17eirhz,grchelp2018,,2023-10-23 12:05:24+00:00,False,,False,False,True,False,/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,Wondering whether the following problem is workable?,"So I need to explore an odd problem. We have an old dataset of interview sessions (its not our dataset). It works as follows.

The candidate comes in, goes through several rounds of interviews (from 1 - 5) each with its own interviewer. (We know the number of interviewers)

After each round, the candidate rates the interviewer (score from 0 to 5). (We do not have this data)

Finally, an overall score is calculated for the entire interview session based on the ratings for each round. (We know the overall score but we do not know how it was calculated)

So essentially, the dataset is roughly off the form:

session_id, score, [interviewer_id1, interviewer_id2, interviewer_id3 ...] (This list is unordered)

The question is: given a particular interviewer_id, is it possible to determine whether he generally got positive or negative ratings?

For context, I write software and don't know much beyond stats 101 so I would appreciate any and all pointers. I would ordinarily say no to the above question but I have met people who've been able to pull signals out of noise so it behoves me to ask.

Thanks.",datascience,https://www.reddit.com/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,3,1,0.6,"[Comment(id='k647cpf'), Comment(id='k63rvwl'), Comment(id='k697t0x')]"
17egeux,qtalen,,2023-10-23 09:35:52+00:00,False,,1698064078.0,False,True,False,/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,How to Optimize Multidimensional Numpy Array Operations with Numexpr,"# A real-world case study of performance optimization in Numpy

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).

&#x200B;

[ How to Optimize Multidimensional Numpy Array Operations with Numexpr. Photo Credit: Created by Author, Canva. ](https://preview.redd.it/r24q1n674yvb1.png?width=1387&format=png&auto=webp&s=ab8950800797f55f538fdb1343df6d275bd07152)

This is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use [Numexpr expressions](https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions) in multidimensional Numpy arrays to achieve substantial performance improvements.

There aren't many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.

# Introduction

Recently, while reviewing some of my old work, I stumbled upon this piece of code:

    def predict(X, w, b):
        z = np.dot(X, w)
        y_hat = sigmoid(z)
        y_pred = np.zeros((y_hat.shape[0], 1))
    
        for i in range(y_hat.shape[0]):
            if y_hat[i, 0] < 0.5:
                y_pred[i, 0] = 0
            else:
                y_pred[i, 0] = 1
        return y_pred

This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning.

But heavens, who would use a `for loop` to iterate over Numpy ndarray?

You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior.

That's right, the person who wrote this code was me when I was younger.

With a sense of responsibility, I plan to rewrite this code with the Numexpr library today.

Along the way, I will show you how to use Numexpr and Numexpr's `where` expression in multidimensional Numpy arrays to achieve significant performance improvements.

## Code Implementation

If you are not familiar with the basic usage of Numexpr, you can refer to this article:

[https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/)

This article uses a real-world example to demonstrate the specific usage of Numexpr's API and expressions in Numpy and Pandas.

*where(bool, number1, number2): number* *- number1 if the bool condition is true, number2 otherwise.*

The above is the usage of the where expression in Numpy.

When dealing with matrix data, you may used to using Pandas `DataFrame`. But since the `eval` method of Pandas does not support the `where` expression, you can only choose to use Numexpr in multidimensional Numpy ndarray.

Don't worry, I'll explain it to you right away.

Before starting, we need to import the necessary packages and implement a `generate_ndarray` method to generate a specific size ndarray for testing:

    from typing import Callable
    import time
    
    import numpy as np
    import numexpr as ne
    import matplotlib.pyplot as plt
    
    rng = np.random.default_rng(seed=4000)
    
    def generate_ndarray(rows: int) -> np.ndarray:
        result_array = rng.random((rows, 1))
        return result_array

First, we generate a matrix of 200 rows to see if it is the test data we want:

    In:  arr = generate_ndarray(200)
         print(f""The dimension of this array: {arr.ndim}"")
         print(f""The shape of this array: {arr.shape}"")
    
    
    Out: The dimension of this array: 2
         The shape of this array: (200, 1)

To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape `(200, 1)` Of course, you can also test other shapes of ndarray according to your needs.

Then, we start writing the specific use of Numexpr in the `numexpr_to_binary` method:

* First, we use the index to separate the columns that need to be processed.
* Then, use the where expression of Numexpr to process the values.
* Finally, merge the processed columns with other columns to generate the required results.

Since the ndarray's shape here is `(200, 1)`, there is only one column, so I add a new dimension.

The code is as follows:

    def numexpr_to_binary(np_array: np.ndarray) -> np.ndarray:
        temp = np_array[:, 0]
        temp = ne.evaluate(""where(temp<0.5, 0, 1)"")
        return temp[:, np.newaxis]

We can test the result with an array of 10 rows to see if it is what I want:

    arr = generate_ndarray(10)
    result = numexpr_to_binary(arr)
    
    mapping = np.column_stack((arr, result))
    mapping

[ I test an array of 10 rows and the result is what I want. Image by Author ](https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&format=png&auto=webp&s=d6977cc422be66a8c37980554c1478e76d2d326c)

Look, the match is correct. Our task is completed.

The entire process can be demonstrated with the following figure:

&#x200B;

[ The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author ](https://preview.redd.it/aw26lp8q8xvb1.png?width=915&format=png&auto=webp&s=df44481e44b2dc48b3acd522b51327b9030e2335)

## Performance Comparison

After the code implementation, we need to compare the Numexpr implementation version with the previous `for each` implementation version to confirm that there has been a performance improvement.

First, we implement a `numexpr_example` method. This method is based on the implementation of Numexpr:

    def numexpr_example(rows: int) -> np.ndarray:
        orig_arr = generate_ndarray(rows)
        the_result = numexpr_to_binary(orig_arr)
        return the_result

Then, we need to supplement a `for_loop_example` method. This method refers to the original code I need to rewrite and is used as a performance benchmark:

    def for_loop_example(rows: int) -> np.ndarray:
        the_arr = generate_ndarray(rows)
        for i in range(the_arr.shape[0]):
            if the_arr[i][0] < 0.5:
                the_arr[i][0] = 0
            else:
                the_arr[i][0] = 1
        return the_arr

Then, I wrote a test method `time_method`. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts:

    def time_method(method: Callable):
        time_dict = dict()
        for i in range(9):
            begin = time.perf_counter()
            rows = 10 ** i
            method(rows)
            end = time.perf_counter()
            time_dict[i] = end - begin
        return time_dict

We test the numexpr version and the `for_loop` version separately, and use `matplotlib` to draw the time required for different amounts of data:

    t_m = time_method(for_loop_example)
    t_m_2 = time_method(numexpr_example)
    plt.plot(t_m.keys(), t_m.values(), c=""red"", linestyle=""solid"")
    plt.plot(t_m_2.keys(), t_m_2.values(), c=""green"", linestyle=""dashed"")
    plt.legend([""for loop"", ""numexpr""])
    plt.xlabel(""exponent"")
    plt.ylabel(""time"")
    plt.show()

[ The Numexpr version of the implementation has a huge performance improvement. Image by Author ](https://preview.redd.it/i5trs6h79xvb1.png?width=595&format=png&auto=webp&s=d508bddb500f8065c75921c1905f14e414ccf932)

It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement.

## Conclusion

After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement.

This article mainly uses two features of Numexpr:

1. Numexpr allows calculations to be performed in a vectorized manner.
2. During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.

Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me.

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).",datascience,https://www.reddit.com/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,0,1,1.0,[]
17ef06x,balackdynamite,,2023-10-23 07:48:30+00:00,False,,False,False,False,False,/r/datascience/comments/17ef06x/how_to_do_a_time_series_forecast_on_sentiment/,How to do a time series forecast on sentiment?,"
I'm using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.

In all cases I can see a few problems:

* gaps with no data (tried filling in - red)
* a sudden drop in sentiment from 15th June

How would you go about doing a forecast on that data? What's advice can you give?",datascience,https://i.redd.it/slcxmqkgqwvb1.jpg,9,0,0.4,"[Comment(id='k631pq6'), Comment(id='k67e4mx'), Comment(id='k67ugls'), Comment(id='k67wyz1'), Comment(id='k67sf76'), Comment(id='k68vckg'), Comment(id='k6dnwhn'), Comment(id='k6dqmbz'), Comment(id='k6dsw58')]"
17dsyjh,noserviceyet,,2023-10-22 13:11:33+00:00,False,,False,False,True,False,/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/,The Changing Landscape of Data Science,"It's fascinating to see how the field of Data Science has evolved in recent years. Just a few years ago, there weren't many dedicated PhD programs in Data Science, and professionals from various STEM backgrounds often considered it as an alternative career option. However, today, we have a plethora of Master's and even a few PhD programs specializing in Data Science. This transformation has turned Data Science into a distinct field, encompassing everything from analytics to ethics.

Will candidates with PhDs in traditional STEM fields become less favored for Data Science jobs in the future, with Data Science program graduates taking the lead? 

Will the field place more emphasis on specialized education as it continues to mature?

What are your thoughts on this matter?",datascience,https://www.reddit.com/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/,27,29,0.8,"[Comment(id='k5yz0ev'), Comment(id='k5ysdr4'), Comment(id='k5z6fxa'), Comment(id='k5yvv2v'), Comment(id='k606qnv'), Comment(id='k5zpqun'), Comment(id='k64qyza'), Comment(id='k60godd'), Comment(id='k60avt6'), Comment(id='k609fio'), Comment(id='k61nr0r'), Comment(id='k60jz28'), Comment(id='k5z4dc2'), Comment(id='k5z8chr'), Comment(id='k62zkm2'), Comment(id='k5zaa3b'), Comment(id='k5z8kmz'), Comment(id='k63bno4'), Comment(id='k65zd3a'), Comment(id='k61joxb'), Comment(id='k66kvhv'), Comment(id='k5zjavw'), Comment(id='k635c4b'), Comment(id='k6e8rps'), Comment(id='k61kvjf'), Comment(id='k61ncvh'), Comment(id='k68z88s')]"
17eeucx,Utterizi,,2023-10-23 07:35:17+00:00,False,,False,False,True,False,/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,"Title not matching tasks, am I making it a big deal?","I am studying a master’s in data science and working as a “junior data scientist” as my first ever job at a start up. Problem is, even though I have ended the more “data science” part of my degree (ML, advanced math/statistics etc.), at work, I’m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don’t remember anything from them. 

I’m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there’s no way I can make it past any of them because of the discrepency between my title and actual experience.",datascience,https://www.reddit.com/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,11,2,0.62,"[Comment(id='k62x5oz'), Comment(id='k635n39'), Comment(id='k62ytz2'), Comment(id='k62ujyp'), Comment(id='k630c0v'), Comment(id='k65wfnb'), Comment(id='k63552g'), Comment(id='k63ex6q'), Comment(id='k63fr30'), Comment(id='k63gbv0'), Comment(id='k63gryq')]"
17egh5m,Mysterious_Run_5081,,2023-10-23 09:40:33+00:00,False,,False,False,True,False,/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,Which features/factors help determine the likelihood of developing tooth decay?,"I’m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet…",datascience,https://www.reddit.com/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,4,0,0.2,"[Comment(id='k63fope'), Comment(id='k644q8f'), Comment(id='k679m2m'), Comment(id='k63sb9z')]"
17deo3d,_CynicalCyanide,,2023-10-21 22:46:18+00:00,False,,False,False,True,False,/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,Where do the data nerds hang out?,"Drop the top subReddits and discord communities where the top data scientists and data analysts hang out. What content do they consume, what are the talking about, how do I sign up?",datascience,https://www.reddit.com/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,93,180,0.91,"[Comment(id='k5wva2f'), Comment(id='k5w9qk1'), Comment(id='k5wb8ju'), Comment(id='k5x0hxt'), Comment(id='k5wad7u'), Comment(id='k5x7wsf'), Comment(id='k5wl35u'), Comment(id='k5xls74'), Comment(id='k5xl9sg'), Comment(id='k5yb1lb'), Comment(id='k5xb8zu'), Comment(id='k5y43z2'), Comment(id='k5wujud'), Comment(id='k5wg2gp'), Comment(id='k5xhg2h'), Comment(id='k5wajqp'), Comment(id='k5xbjoc'), Comment(id='k5wewxi'), Comment(id='k60anrt'), Comment(id='k62q65y'), Comment(id='k63l9e9'), Comment(id='k5wl1vs'), Comment(id='k5wlmwa'), Comment(id='k5x9q3e'), Comment(id='k5wtljx'), Comment(id='k62y63g'), Comment(id='k5xl101'), Comment(id='k5xuaj5'), Comment(id='k5wdxa4'), Comment(id='k5wjbsy'), Comment(id='k5wlu6v'), Comment(id='k5wmgop'), Comment(id='k5wj3p7'), Comment(id='k5yapfh'), Comment(id='k5xn4xq'), Comment(id='k5xqxme'), Comment(id='k5zikia'), Comment(id='k5zpqcq'), Comment(id='k5zt95p'), Comment(id='k600da6'), Comment(id='k603v9q'), Comment(id='k60tgz8'), Comment(id='k60vame'), Comment(id='k63jljr'), Comment(id='k6ftw64'), Comment(id='k5yzz1c'), Comment(id='k5ziizo'), Comment(id='k5yyq2h'), Comment(id='k5xq9zy'), Comment(id='k5xxw28'), Comment(id='k5x8bx7'), Comment(id='k5zts64'), Comment(id='k5wg736'), Comment(id='k5wuz8o'), Comment(id='k5xm83d'), Comment(id='k5yatk9'), Comment(id='k5wuhfj'), Comment(id='k5xyzqy'), Comment(id='k5ys8b5'), Comment(id='k5yaxqi'), Comment(id='k5yfxzx'), Comment(id='k6hdpqn'), Comment(id='k5yx43j'), Comment(id='k5xe6mc'), Comment(id='k5xe93z'), Comment(id='k5wlrar'), Comment(id='k5xeah6'), Comment(id='k62y2c7'), Comment(id='k60zopd'), Comment(id='k5we10k'), Comment(id='k5x8ema'), Comment(id='k5yavea'), Comment(id='k61i3l3'), Comment(id='k61i7zp'), Comment(id='k61c6mp'), Comment(id='k61c5fu'), Comment(id='k5wv7pa'), Comment(id='k5ynpr4'), Comment(id='k5y6967'), Comment(id='k5ylwow'), Comment(id='k5yygp2'), Comment(id='k5zcbrq'), Comment(id='k5xxhvj'), Comment(id='k5xekrv'), Comment(id='k63hr6c'), Comment(id='k5ww4pe'), Comment(id='k5zvhyk'), Comment(id='k5ykh46'), Comment(id='k5xists'), Comment(id='k63uikt'), Comment(id='k5wwqua')]"
17ebi8s,charlesowo445,,2023-10-23 03:51:23+00:00,False,,False,False,True,False,/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,Hey guys how is mongodb for analytics,"Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . 
So the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?",datascience,https://www.reddit.com/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,1,0,0.25,[Comment(id='k64602c')]
17d3aze,ssiddharth408,,2023-10-21 14:04:22+00:00,False,,False,False,True,False,/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,Is pytorch not good for production,"I have to write a ML algorithm from scratch and confused whether to use tensorflow or pytorch. I really like pytorch as it's more pythonic but I found articles and other things which suggests tensorflow is more suited for production environment than pytorch. So, I am confused what to use and why pytorch is not suitable for production environment and why tensorflow is suitable for production environment.",datascience,https://www.reddit.com/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,62,81,0.93,"[Comment(id='k5uuuev'), Comment(id='k5umqnt'), Comment(id='k5um0pe'), Comment(id='k5u5aj5'), Comment(id='k5v377o'), Comment(id='k5u123l'), Comment(id='k5uq8rc'), Comment(id='k5u5wtz'), Comment(id='k5vddvs'), Comment(id='k6ptjsw'), Comment(id='k5v8pw7'), Comment(id='k5w3v6m'), Comment(id='k5vlr5h'), Comment(id='k5uqk0m'), Comment(id='k5wky8x'), Comment(id='k5wkk4t'), Comment(id='k5uwm4o'), Comment(id='k5y30ac'), Comment(id='k5vhx72'), Comment(id='k5uzaxt'), Comment(id='k5uw58w'), Comment(id='k5z92c6'), Comment(id='k5uicrc'), Comment(id='k5v7ufo'), Comment(id='k5u5gns'), Comment(id='k5ur476'), Comment(id='k5vfnx7'), Comment(id='k5u63a1'), Comment(id='k6tw0hl'), Comment(id='k5wdlv8'), Comment(id='k5xn50q'), Comment(id='k5ygs5z'), Comment(id='k5y38lr'), Comment(id='k5vgcfp'), Comment(id='k5uwp6h'), Comment(id='k5vayzx'), Comment(id='k64n14u'), Comment(id='k5wlxlj'), Comment(id='k5ujs7e'), Comment(id='k5vo9ol'), Comment(id='k5u6ero'), Comment(id='k5yqtnc'), Comment(id='k5yhl2m'), Comment(id='k5ybzl9'), Comment(id='k5vs4oz'), Comment(id='k5w9azp'), Comment(id='k5wk514'), Comment(id='k5veg16'), Comment(id='k5wdhpe'), Comment(id='k627rwy'), Comment(id='k5ydrko'), Comment(id='k5u91as'), Comment(id='k5u6y7n'), Comment(id='k5yy6sj'), Comment(id='k5yddly'), Comment(id='k622pdl'), Comment(id='k5wqa7n'), Comment(id='k5y1eop'), Comment(id='k5yywwa'), Comment(id='k5u9wsi'), Comment(id='k5u9iek'), Comment(id='k5ur61m'), Comment(id='k5vfkej'), Comment(id='k5w1j8m')]"
17d6ufx,Odd_Discipline9354,,2023-10-21 16:48:03+00:00,False,,1697911189.0,False,True,False,/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,Is handling errors with Random Forest more superior compared to mean or zero imputation?,"Hi, I came upon [this post in Linkedin](https://www.linkedin.com/feed/update/urn:li:activity:7121482516829507584?utm_source=share&utm_medium=member_android), in which a guy talks about how handling errors with imputing means or zero have many flaws (changes distributions, alters summary statistics, inflates/deflates specific values), and instead suggests to use this library called ""MissForest"" imputer to handle errors using a random forest algorithm.

**My question is, are there any reasons to be skeptical about this post?** I believe there should be, since I have not really heard of other well established reference books talking about using Random Forest to handle errors over imputation using mean or zero.

My own speculation is that, unless your data has missing values that are in the hundreds or take up a significant portion of your entire dataset, using the mean/zero imputation is computationally cheaper while delivering similar results as the Random Forest algorithm.

I am more curious about whether this proposed solution has flaws in its methodology itself.",datascience,https://www.reddit.com/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,7,20,0.85,"[Comment(id='k5v03da'), Comment(id='k5vaq9e'), Comment(id='k5wqkec'), Comment(id='k5x5n88'), Comment(id='k6348du'), Comment(id='k61nzb9'), Comment(id='k62116y')]"
17cv8nq,Accomplished_Ad_5697,,2023-10-21 05:23:21+00:00,False,,False,False,True,False,/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,Why should I learn Java if Python have libraries offset it shortfall?,"I am studying Python and R to work in Data, and my mentor said that I should learn Java. I think it is regards to Machine Learning, but Python has an extensive libraries that helps offset it short fall. The problem that I can never finish a crash course book on Python is it's speed, but I read that NumPy and Pandas help make it faster. So my question is, what benefits are there to learn Java for Data Science if I see majority of people learn Python and most certification for data professions used Python and/or R?",datascience,https://www.reddit.com/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,77,86,0.83,"[Comment(id='k5suq7j'), Comment(id='k5sk2t7'), Comment(id='k5syl6x'), Comment(id='k5skrke'), Comment(id='k5sz06q'), Comment(id='k5sln5l'), Comment(id='k5sln4s'), Comment(id='k5so9lr'), Comment(id='k5sqfwp'), Comment(id='k5uw1a6'), Comment(id='k5snl1s'), Comment(id='k5sx23i'), Comment(id='k5tqbxn'), Comment(id='k5terww'), Comment(id='k5t9ezw'), Comment(id='k5ta86n'), Comment(id='k5sv3g5'), Comment(id='k5sn68o'), Comment(id='k5sple2'), Comment(id='k5t62u4'), Comment(id='k5tikuq'), Comment(id='k5srcy7'), Comment(id='k5tr8o7'), Comment(id='k5tws96'), Comment(id='k5txmb4'), Comment(id='k5u0g7j'), Comment(id='k5u8v6p'), Comment(id='k5uafff'), Comment(id='k5ud70n'), Comment(id='k5unl4s'), Comment(id='k5up43r'), Comment(id='k5upvvs'), Comment(id='k5uqwea'), Comment(id='k5usfr7'), Comment(id='k5usl5i'), Comment(id='k5vburu'), Comment(id='k5ve072'), Comment(id='k5wuv4f'), Comment(id='k5znqp9'), Comment(id='k62i03i'), Comment(id='k5tx9ro'), Comment(id='k5u4vuq'), Comment(id='k5u8t0f'), Comment(id='k5tv3vm'), Comment(id='k5ub2st'), Comment(id='k5t3odm'), Comment(id='k5sliji'), Comment(id='k5tdal9'), Comment(id='k5u3osx'), Comment(id='k5u8z9z'), Comment(id='k5t5t63'), Comment(id='k5swy8n'), Comment(id='k5uzqzf'), Comment(id='k63mmc5'), Comment(id='k5ss0j4'), Comment(id='k5u3c42'), Comment(id='k5tw18y'), Comment(id='k5u3vzk'), Comment(id='k5w884p'), Comment(id='k5vxevc'), Comment(id='k5t9gqt'), Comment(id='k5tvnbm'), Comment(id='k5tqaqd'), Comment(id='k5u4k9l'), Comment(id='k5t3jla'), Comment(id='k5u94s6'), Comment(id='k5uiq1y'), Comment(id='k5suicq'), Comment(id='k5u483g'), Comment(id='k5wczs6'), Comment(id='k5wey8q'), Comment(id='k5u2hgt'), Comment(id='k5u2nir'), Comment(id='k5sx6iq'), Comment(id='k5zt01z'), Comment(id='k5u9920'), Comment(id='k613v17')]"
17czsvd,X_Drake,,2023-10-21 10:45:52+00:00,False,,False,False,True,False,/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,How often do companies outsource for entry-level data roles?,"I've been studying for Data Analyst roles for a while now, and I'm really looking forward to working with data. I was just wondering how often companies outsource for entry-level data analyst roles? Because this role is usually remote or hybrid, I think that a lot of companies probably are, but they're hard to find or most likely prefer locals than to outsource.   
Before I started, I did my own research and met with 8 accomplished Data Analysts/ Scientists/ Engineers Mentors from US/Canada/Germany/UK in The Mentoring Club and confirmed how I would start and learn to transition to this role.  


I talked to them and confirmed that the best skills to acquire would be   
Excel, SQL, Python or R (or Both), Power BI or Tableau (or Both)  


I started with very basic SQL in Khan Academy and SQLZoo and I enjoyed it a lot and confirmed my love to transition to working with Data. 

After that, I took the IBM Data Analyst Professional Certificate (almost everyone I talked to was against taking the Google Data Analytics Certificate) which covered SQL, Python, IBM Cognos, and EDA.

Then I took DataCamp's Data Analyst in SQL to further hone my skills in SQL, I feel more confident with my SQL skills after taking this course.

Now, I'm currently taking DataCamp's Data Analyst in Power BI course and am about 70% done with it.

On every single course, I really love what I'm learning and enjoying it so far. I really love working with data. Whenever I solve a ""problem"" from my courses, I feel very satisfied like an itch in the brain is gone. Every time I make an amazing visual in Power BI, I actually smile and feel proud. Every time I learn something new I actually love it. When I first used ""Key Influencers"" in Power BI, I was so amazed and really wanted to work more with this feature.

&#x200B;

My current problem is, that I don't really want to work as a Data Analyst for a company in my country, but rather as a full-time remote for a company in the US, Canada, or Europe even without benefits, even at minimum wage, as long as they give me 40 hours per week, growth in skills, and opportunity to train/learn.

So I'm just wondering how viable would that be in your experience with your companies, do you work remotely with people from other countries in entry-level roles?",datascience,https://www.reddit.com/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,14,14,0.82,"[Comment(id='k5tp9vb'), Comment(id='k5tqaj9'), Comment(id='k5trz9t'), Comment(id='k5uc9lp'), Comment(id='k5zpbx3'), Comment(id='k5tu8fh'), Comment(id='k5tw1kf'), Comment(id='k5tv9v8'), Comment(id='k5v3f8o'), Comment(id='k5unokf'), Comment(id='k5zn987'), Comment(id='k5vluko'), Comment(id='k5urool'), Comment(id='k5vy7wf')]"
17cfb97,InevitableTraining69,,2023-10-20 16:27:36+00:00,False,,False,False,True,False,/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,I have never had a manager in my entire career that provided any value to me,"In my entire career, I have never had a single manager that provided any value to me personally. Here's a recap of all of the managers I've had in my career. 


1. Terrific manager. Hired me, made me feel welcome, immediately left the company two weeks after I started



2. Replaced first manager, and immediately put me on performance improvement plan to try and get rid of me. Would find formatting errors, any sort of mistake or human error at all to tell me that I was a sloppy employee. Completely ignored any benefit I provided, and had no interest in working with me. Just wanted to build their own team, and I was in their way because I was already there


3. Hired me, and instead letting me get oriented into my role, decided to do what she called ""trial by fire"", just throw me into the deep and and see if I sink or swim. I excelled in my position, did everything better than expected, received praise often, but passed up for a promotion because only one person can be promoted. 


4. Completely incompetent, never actually did any of the subject that they were managing a team for. Ended up being fired for sexual harassment against many women on our team 



5. Came from another team to replace previous manager, gave me mountains of work and impossible goals and expectations to achieve, and even when achieving them, made up a bunch of excuses as to why I can't be promoted that made no sense. Glass ceiling, basically, can't be promoted unless you tell me that you want to be promoted, and X amount of years have passed, need X amount of outstanding performance reviews, etc


6. Actually a really good manager and all around good person. For the first year, great to work under them, they let me get situated in the role, let me get exposure to many different teams and departments, let me explore and provided coaching. However, after the first year, became very lazy as a manager. Never at their desk, always driving somewhere, scheduling meetings and then being 15 plus minutes late to them because again, they are driving somewhere, or not doing their job. Became extremely lazy and let errors slip through their fingers, and blame team members for them. Began making excuses when people wanted to be promoted 


7. The director above the previous manager in bullet point above. Completely worthless leader who came aboard to replace another director, and their first mission was to interrogate everyone on the team, and determine if their career goals were to stay in their current position. Anyone who desired career growth, or wanted to move up into management, or had career aspirations was immediately let go because they're ""Not a fit for our organizational goals"" 



The most common thing I have seen is that it is impossible to get promoted. Most positions at analyst level are designed so that no one can proceed into other positions because they want you to stay exactly where you are currently and not move up, they try to make it as difficult as possible for you to move up into other roles in the company. If you don't want to sit exactly where you are for at least 5 to 10 years, you're a bad employee, and there is no way to be promoted.",datascience,https://www.reddit.com/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,131,258,0.89,"[Comment(id='k5poyaw'), Comment(id='k5pslmm'), Comment(id='k5qy6zx'), Comment(id='k5ri8fk'), Comment(id='k5pmvsv'), Comment(id='k5pmd65'), Comment(id='k5pu0bg'), Comment(id='k5r0u2s'), Comment(id='k5q9kbm'), Comment(id='k5qpefz'), Comment(id='k5r4dyc'), Comment(id='k5sc66s'), Comment(id='k5quyfi'), Comment(id='k5rds8j'), Comment(id='k5rxo32'), Comment(id='k5qoeh1'), Comment(id='k5pt1ev'), Comment(id='k5pyl2y'), Comment(id='k5r82fx'), Comment(id='k5rdio4'), Comment(id='k5s8f45'), Comment(id='k5pooit'), Comment(id='k5povvl'), Comment(id='k5qdh8c'), Comment(id='k5s2j6y'), Comment(id='k5q13a6'), Comment(id='k5q22g9'), Comment(id='k5r0yf3'), Comment(id='k5s2ju4'), Comment(id='k5s69w7'), Comment(id='k5s84gi'), Comment(id='k5salbe'), Comment(id='k5shjz1'), Comment(id='k5sl3aa'), Comment(id='k5swrx7'), Comment(id='k5t6fs6'), Comment(id='k5t6hpv'), Comment(id='k5t92l9'), Comment(id='k5tm6rt'), Comment(id='k5tnorv'), Comment(id='k5u1f53'), Comment(id='k5ud6fn'), Comment(id='k5uq0cv'), Comment(id='k5w4eju'), Comment(id='k5wsm4l'), Comment(id='k606f2j'), Comment(id='k613ke0'), Comment(id='k68rjeo'), Comment(id='k69334x'), Comment(id='k694mvi'), Comment(id='k5q7gsl'), Comment(id='k5u46bi'), Comment(id='k5pub33'), Comment(id='k5q7ohf'), Comment(id='k5x5fxd'), Comment(id='k5t99li'), Comment(id='k5rqf0n'), Comment(id='k5vbok1'), Comment(id='k612v7k'), Comment(id='k5pyoz6'), Comment(id='k5sjhsd'), Comment(id='k5poy0f'), Comment(id='k5puhbb'), Comment(id='k5qj55n'), Comment(id='k5tea15'), Comment(id='k5pxf3y'), Comment(id='k5r1uxz'), Comment(id='k5tbydy'), Comment(id='k5qhr2j'), Comment(id='k5rym2s'), Comment(id='k5ycc47'), Comment(id='k5t124w'), Comment(id='k5ryxsq'), Comment(id='k67qnoq'), Comment(id='k5pw14r'), Comment(id='k5pt9m9'), Comment(id='k5qgaej'), Comment(id='k5q4ssx'), Comment(id='k5qx9q9'), Comment(id='k5t8wr9'), Comment(id='k5qdj83'), Comment(id='k5t34yh'), Comment(id='k5rw2l7'), Comment(id='k5t4a6o'), Comment(id='k5u71xe'), Comment(id='k5qomwe'), Comment(id='k5t6r7g'), Comment(id='k5r39sa'), Comment(id='k5tbu2c'), Comment(id='k5ppqli'), Comment(id='k5qrgfs'), Comment(id='k5t9uhh'), Comment(id='k5tgifc'), Comment(id='k5pycej'), Comment(id='k5q2w3i'), Comment(id='k5sxk6x'), Comment(id='k5t6xh0'), Comment(id='k5qm97s'), Comment(id='k5xb5pm'), Comment(id='k5yc7zc'), Comment(id='k5vvjn1'), Comment(id='k62gagi'), Comment(id='k5seuvk'), Comment(id='k5q0xdd'), Comment(id='k5pycdl'), Comment(id='k5qnkqk'), Comment(id='k5qkeyz'), Comment(id='k5s0g91'), Comment(id='k5t9997'), Comment(id='k5tjv4c'), Comment(id='k5u87i7'), Comment(id='k5ug1v1'), Comment(id='k5tegds'), Comment(id='k5pyqy3'), Comment(id='k5t6nqj'), Comment(id='k5tb8er'), Comment(id='k5x5wco'), Comment(id='k5yd0h0'), Comment(id='k5r1rxn'), Comment(id='k5q7dlo'), Comment(id='k5q8cj3'), Comment(id='k5sa7yw'), Comment(id='k5tjwvt'), Comment(id='k5vpyeh'), Comment(id='k5v1gmy'), Comment(id='k5t7hrb'), Comment(id='k74ne1z'), Comment(id='k5t96s3'), Comment(id='k5qmx8c'), Comment(id='k5x5l3u'), Comment(id='k74one4'), Comment(id='k5qt68e'), Comment(id='k5xfdfq'), Comment(id='k5xk4zj')]"
17cy5av,Total-Opposite-8396,,2023-10-21 08:48:07+00:00,False,,False,False,True,False,/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,Need some practical advice on choosing from different CNN model architectures.,"Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also covered a little Neural Style Transfer. 

 I am now looking forward to build some projects. Most probably on object detection and image classification. After consuming all of the stuff that I mentioned above, I am confident enough that I can build an application in the real world, though I still have a few questions and need to talk to someone who can channel my thoughts in the right direction.  

If you could give me just a rough overview of how you approach a computer vision problem that'll be great. Especially, when you see a computer vision problem to solve, how do you make decision on which architecture to choose from to solve a given problem at hand. Since there are many architectures and research papers and every architecture works in a unique way to solve unique problems, how do you know which one to choose from? How do you make your way down from 100s of options to choose from, to a few where you can then start experimenting with those few options? Just need some practical advice on approaching an object detection or image classification problem.

Also, there might be some knowledge gaps that I have, I feel like I have em, but I don't know what I don't know at this point. So, I just need someone who can maybe channel me in the right direction.",datascience,https://www.reddit.com/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,2,4,0.7,"[Comment(id='k5tattz'), Comment(id='k7wetka')]"
17ccv2x,SHJPEM,,2023-10-20 14:40:44+00:00,False,,False,False,True,False,/r/datascience/comments/17ccv2x/whats_one_file_or_other_digital_resource_which_if/,What's one file or other digital resource which if deleted would most affect the world?,,datascience,https://www.reddit.com/r/datascience/comments/17ccv2x/whats_one_file_or_other_digital_resource_which_if/,16,37,0.85,"[Comment(id='k5p2p7v'), Comment(id='k5qs7uz'), Comment(id='k5pf21q'), Comment(id='k5qac51'), Comment(id='k5qs7zi'), Comment(id='k5pxgph'), Comment(id='k5qz60i'), Comment(id='k5stz8f'), Comment(id='k5p8j1w'), Comment(id='k5qf8a8'), Comment(id='k5vpwbj'), Comment(id='k5t471a'), Comment(id='k5pkunj'), Comment(id='k5vohlh'), Comment(id='k5posqt')]"
17cce10,Ty4Readin,,2023-10-20 14:19:09+00:00,False,,1697812122.0,False,True,False,/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,Dataset splitting by time & why you should do it,"I know this is likely to be controversial but I wanted to open up the discussion.

I think most problems and datasets should be split by time rather than uniform iid sampling for train-valid-test.

I almost always get pushback when I suggest this because it makes cross-validation more difficult to implement and can reduce the training dataset size in some folds.

Most people will say it's not necessary to split by time (e.g. test set in the future relative to train) because there is no time-wise dependency. However, the problem is that almost every data distribution involving human interactions will tend to shift over time and contain some dependency.

Let me give you one example: Let's say we have a web app that lets users submit a picture of an animal and we predict whether it's a dog or not. This seems like a simple problem where you could split by iid because there can't be any data leakage, right?

But if you think about it, the distribution of photos that get submitted is likely to change over time. It could be from new dog breeds becoming more popular, or from a shift in the types of users that use the platform and the dogs they submit. It could even be due to new phones/cameras being used, or people start posing their photos slightly differently or maybe covid hits and now your service is only getting indoor photos with different lighting whereas previously you got mostly outdoor shots.

These are all hypothetical examples and you could come up with a million different ones. The point being that the distribution of data for many many (most?) problems will change over time and our goal is almost always to train on historical data and predict on future unseen data.

So with that context, I think it often makes sense to at least test a time-split approach and observe whether there's a difference with simple iid CV approach. I think you could possibly be surprised by the result.",datascience,https://www.reddit.com/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,49,26,0.82,"[Comment(id='k5pe43l'), Comment(id='k5p7s41'), Comment(id='k5p0j8t'), Comment(id='k5pcmiu'), Comment(id='k5pft3g'), Comment(id='k5pm1kq'), Comment(id='k5pa55u'), Comment(id='k5pa567'), Comment(id='k5qfhjt'), Comment(id='k5qp1sh'), Comment(id='k5oz31x'), Comment(id='k5phqc5'), Comment(id='k5ptd7m'), Comment(id='k5pmxum'), Comment(id='k5qf70l'), Comment(id='k5pv859'), Comment(id='k5qmzj9'), Comment(id='k5p1ob5'), Comment(id='k5pr09b'), Comment(id='k5pqc5o'), Comment(id='k5pm0av'), Comment(id='k5pp3pu'), Comment(id='k5pq0p8'), Comment(id='k5piahq'), Comment(id='k5qny1b'), Comment(id='k5qh34f'), Comment(id='k5pk1v0'), Comment(id='k5qptu2'), Comment(id='k5ppuqe'), Comment(id='k5qg9uq'), Comment(id='k5qhjp0'), Comment(id='k5qjid6'), Comment(id='k5rfu9r'), Comment(id='k5r53yt'), Comment(id='k5psfod'), Comment(id='k5ps93y'), Comment(id='k5psj1l'), Comment(id='k5qhuyp'), Comment(id='k5qjhdn'), Comment(id='k5q3gmz'), Comment(id='k5re2w6'), Comment(id='k5pvaz4'), Comment(id='k5pt6rp'), Comment(id='k5qhwxc'), Comment(id='k5px79v'), Comment(id='k5pvlrk'), Comment(id='k5qng8d'), Comment(id='k5pxa4a'), Comment(id='k5r8l1w'), Comment(id='k5rfhv8')]"
17d2v13,Careful_Engineer_700,,2023-10-21 13:42:26+00:00,False,,False,False,True,False,/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,"Soooo, my manager thinks it’s a good idea to assign a mentor on me,","I am a sales operations analyst -by name- and I do what a typical junior data scientist does, I am an analyst from a team of four, I am the only one with exposure to proper statistical analyses and machine learning.

One colleague of mine -my mentor- has been at the company for a year before me, and he knows some python and is good at SQL. He is no where near my level at those two, but he’s a god-level suck-up! 
He can stay at the office after hours for no compensation just cause our manager said he needed to see something that would normally take a whole day to achieve, asked at 5:00 pm and needed to be ready in the morning.

The problem is raised because of a project I was leading, I automated the process of making routes for sales agents, I made it assign a 1 to retailers if we visit today will more likely make an order. I made it for the region I am operating in only -more on that later- and I also used clustering to get them the best routes possible in terms of likelihood to order and geographic coordinates. It made the success rate go from 40% to a big fat 60%. My manager appreciated that as much and thought its a great idea to make it for all regions, I designed an ab test and will run it for 2 weeks, as we have biweekly seasonality.

I prepared analyses for the test results and it was time for a meeting with other managers to discuss what it achieved. This was the forst time this team was doing an ab test, since I am the only one who actually understand it, I owned it.

When I shows the numbers, one region showed insignificant results, and I found that its seasonality is not biweekly, rather monthly and the mode of operations there is different, and it was -my mentor’s- region.

My manager said: why are you complicating things? Man, show me some pivot tables of agents who worked without your model and the ones who worked with and who is better, I disagreed as their performances might include other factors that are not controlled by mt model, pricing and geography and the agent himself.

My mentor already has the pivots ready, presented the numbers and he was happy.

After, my manager rambelled on for half an hour about my attitude and pointed out every thing that I fis wrong since I started working in the company, and assigned him as anentor to me, stating how much of an inpact on my coding skills and analytical skills he will add.

We started working in projexts together and had to take his way of doing things, and I don’t like how he lets me do all the work and take credit for it.

I started looking for new jobs and no luck the market is really tough especially that I know little tools, power bi and its dax, excel and python and sql.

What should i learn to get jobs as a junior data scientist? While searching, what should I do about my situation?",datascience,https://www.reddit.com/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,16,0,0.42,"[Comment(id='k5u16w6'), Comment(id='k5tzyt0'), Comment(id='k5ui6e2'), Comment(id='k5u4ze0'), Comment(id='k5udrl3'), Comment(id='k5u1qby'), Comment(id='k5u1g16'), Comment(id='k5ux6is'), Comment(id='k5ui1ma'), Comment(id='k5u7viy'), Comment(id='k5uk4wu'), Comment(id='k5x5rrz'), Comment(id='k5v0719'), Comment(id='k5uwn59'), Comment(id='k5uw0s5'), Comment(id='k5uwskg')]"
17c78g5,Stochastic_berserker,,2023-10-20 09:35:39+00:00,False,,False,False,True,False,/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,Thoughts on DS roles,"I’ve been working as a DS for a couple of years now and would like to share my thoughts on the role(s).


- Big corp: Benefits and salary good but can get stuck in deploying large products where your hard earned skills aren’t used. Best place to be during new projects where you accumulate alot of skills from SWE, IT and more.


- Consulting: Not Big4 but what I’ve experienced is basically BI and DE. The managers have no idea what DS is and just regurgitates names of cloud services. Compensation model is outdated and not realistic for DS. 


What are your experiences?",datascience,https://www.reddit.com/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,15,26,0.91,"[Comment(id='k5o6mec'), Comment(id='k5ollhi'), Comment(id='k5p77wq'), Comment(id='k5owmjz'), Comment(id='k5oqi8q'), Comment(id='k5ovrj5'), Comment(id='k5peiyp'), Comment(id='k5qs8wu'), Comment(id='k5odhos'), Comment(id='k5owz56'), Comment(id='k5p52do'), Comment(id='k5sz5pa'), Comment(id='k5syw3n'), Comment(id='k5oxb7i'), Comment(id='k5oz5o0')]"
17clbmx,Different-General700,,2023-10-20 20:59:40+00:00,False,,False,False,True,False,/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,Inviting initial users for dynamic data documentation tool,"I'm building a product that integrates with your codebases and takes your database metadata to create dynamic documentation of your data. Every time someone makes a new code change that affects the data, you're updated with how the code change altered tables, labels, cols, etc.

Let me know if you'd like to try it out. I'll send you a link and would love to get your feedback.

I'll provide a repo and public postgres database that you can connect to demo (if you don't have one that you want to connect).",datascience,https://www.reddit.com/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,5,3,1.0,"[Comment(id='k5r2coj'), Comment(id='k5r2ps8'), Comment(id='k5r4318'), Comment(id='k5r5dc6'), Comment(id='k5r6cdu')]"
17cnntn,BeginningDeer4329,,2023-10-20 22:42:46+00:00,False,,False,False,True,False,/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,Help needed with a quadratic optimization problem,"Hi, I am trying to solve finance-related quadratic optimization problem using CVXPY python library. I have a maximize objective function with a Beta variable which is subject to certain constraints. I am getting the output for Beta values from 1-10. But at certain beta values (e.g., 0, 1), the output is optimally inaccurate and the objective is not even satisfying constraints. Why would the program give solutions which does not satisfy constraints? More generally, can someone recommend some literature to solve such problems?",datascience,https://www.reddit.com/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,2,2,1.0,"[Comment(id='k5r8ylu'), Comment(id='k5rf6ub')]"
17cie3b,Usual-Goat,,2023-10-20 18:46:28+00:00,False,,False,False,True,False,/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,Help with analysis of incomplete experimental design,"I am trying to determine the amount of confounding and predictive power of the current experimental design is?  
I just started working on a project helping out with a test campaign of a fairly complicated system at my company. There are many variables that can be independently tuned, and there is a test series planned to 'qualify' the engine against its specification requirements.   


One of the objectives of the test series is to quantify the 'coefficient of influence' of a number of factors. Because of the number of factors involved, a full factorial DOE is out of the question, and because there are many objectives in the test series, its difficult to even design a nice, neat experimental design that follows canonical fractional factorial designs.   


We do have a test matrix built, and i was wondering if there is a way to just analyze what the predictive power of the current test matrix is in the first place. We know and accept that there will be some degree of confounding two-variable and three-variable + interaction effects in the main effects, which is alright for us. Is there a way to analyze what the amount of confounding and predictive power of the current experimental design is?  


Knowing the current capability and limitations of our experimental designs would be very helpful it turns out i need to propose alteration of our test matrix (which can be costly)  


I don't have any real statistics background, and i don't think our company would pay for a software like minitab and i don't know how to use such a software either.   


Any guidance on this problem would be most appreciated.   
",datascience,https://www.reddit.com/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,4,1,0.67,"[Comment(id='k664vnc'), Comment(id='k5rgpy3'), Comment(id='k5to9ju'), Comment(id='k5udh4h')]"
17cgmof,LiterateSeagull,,2023-10-20 17:26:34+00:00,False,,False,False,True,False,/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,Can you fit a code in a gamble?,"How would you encode information into improbable events? For example, if you could influence the outcome of a roulette wheel or lottery draw, over as long a period as necessary, what would be the most efficient way of encoding data into the outcomes?

Perhaps a better example would be drawing from a deck of a million unique cards, and only yelling yahtzee when a specific one is drawn. Say you can add a few extra of the card to the deck whenever you want and boost the probability slightly. That would theoretically increase the frequency of the yahtzees from the right timescale perspective.

So if our hero does a million shuffled drawings a day, he might get 0-3 yahtzees. With careful timing, you can slip an extra card into the deck whenever you want, doubling his probability for the next drawing.

How would you encode as much data as possible in the frequency of this man yelling yahtzee?",datascience,https://www.reddit.com/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,20,0,0.43,"[Comment(id='k5r0th3'), Comment(id='k5qckw3'), Comment(id='k5qji34'), Comment(id='k5qawia'), Comment(id='k5rxmgq'), Comment(id='k5qak5e'), Comment(id='k5qk2mb'), Comment(id='k5qnqn1'), Comment(id='k5qu14w'), Comment(id='k5rcgxd'), Comment(id='k5rlr8y'), Comment(id='k5snurs'), Comment(id='k5x6k2g'), Comment(id='k5qqxu5'), Comment(id='k5qvgig'), Comment(id='k5slpvp'), Comment(id='k5qz3au'), Comment(id='k5ufaoe'), Comment(id='k5r0ii6'), Comment(id='k5s3szu')]"
17c0z6e,EthicalArtisan,,2023-10-20 02:49:57+00:00,False,,False,False,True,False,/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,Any data imputation technique shares?,"Hello, 

I’ve been reading up some articles from kaggle and blogs about data imputation. I’m wondering if there’s a complete guide that introduces all the methods to data imputation. I’m interested to see all the pros and cons and the usage of different situations. 

Thanks for sharing!",datascience,https://www.reddit.com/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,15,9,0.77,"[Comment(id='k5n5be1'), Comment(id='k5n5s79'), Comment(id='k5n1twr'), Comment(id='k5nmcpr'), Comment(id='k61oq9t'), Comment(id='k5ng5hk'), Comment(id='k5ngd4q'), Comment(id='k5n2nem'), Comment(id='k5pcfpd'), Comment(id='k5nptnt'), Comment(id='k5obd1y'), Comment(id='k5pc89d'), Comment(id='k5pbuag'), Comment(id='k5rmbtg'), Comment(id='k5r101h')]"
17c2u6b,Difficult-Big-3890,,2023-10-20 04:34:22+00:00,False,,1697782002.0,False,True,False,/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,Do you use CRUD or like apps to bridge the gap between business users and DS/DA teams?,"In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don't see much talk about this skill/use case of analytics. So curious to hear other's thoughts and experiences. Do you concur? Why or why not?

PS: I understand it's probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don't fall in this category. Pls feel free to bunk this too!",datascience,https://www.reddit.com/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,19,6,0.8,"[Comment(id='k5oq3r9'), Comment(id='k5op1zr'), Comment(id='k5op282'), Comment(id='k5nnqqg'), Comment(id='k5nl8zn'), Comment(id='k5ovcop'), Comment(id='k5ovj71'), Comment(id='k5numm6'), Comment(id='k5oi5ax'), Comment(id='k5nllf1'), Comment(id='k5oy14z'), Comment(id='k5ozg0n'), Comment(id='k5nv227'), Comment(id='k5oz8xg'), Comment(id='k5p0jv0'), Comment(id='k5nvmb0'), Comment(id='k5p0ycj'), Comment(id='k5qx776'), Comment(id='k5p1mlc')]"
17bmc70,David202023,,2023-10-19 15:50:31+00:00,False,,False,False,True,False,/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,[rant] Required - A designated tread for transitioning to DS and repeating questions,"Mods, where are you? There are countless posts every week with questions that were answered already.  

Should I learn Python? 
Masters degree worth it?
Job market sucks, what projects should I do?

All of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren’t even phrased correctly.

All of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master.",datascience,https://www.reddit.com/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,27,43,0.79,"[Comment(id='k5khmrs'), Comment(id='k5kp7ox'), Comment(id='k5k7ag5'), Comment(id='k5l0erh'), Comment(id='k5l0ogv'), Comment(id='k5k6ivk'), Comment(id='k5lsakx'), Comment(id='k5l26w2'), Comment(id='k5ma4dk'), Comment(id='k5n805b'), Comment(id='k5nv0v6'), Comment(id='k5mz78s'), <MoreComments count=6, children=['k5lgu5j', 'k5l6guf', 'k5kpd57']>, Comment(id='k5kpkg6'), Comment(id='k5lfd59'), Comment(id='k5k7c87'), Comment(id='k5ltk72'), Comment(id='k5k7xku'), Comment(id='k5l14s4'), Comment(id='k5lud2b'), Comment(id='k5lj7ho'), Comment(id='k5lnibd')]"
17bqhb0,19andoverlol,,2023-10-19 18:50:52+00:00,False,,False,False,True,False,/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,Predictive vs Explanatory modeling,"In my past work I've become familiar with various techniques for *predictive* modeling--NNs, of course, but also more ""classical"" methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I've loved using sklearn and nltk, and I haven't even gotten to using pytorch yet).

All that said, I haven't worked as much so far with *explanatory* modeling and I'm looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What's more, in the explanatory environment, there's a much greater emphasis on *model interpretability*--that is to say, models like NNs or even random forests that can get kind of ""black boxy"" are disfavored compared to simpler models with much more straightforward interpretability.

So what's the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??",datascience,https://www.reddit.com/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,26,11,0.87,"[Comment(id='k5l9t81'), Comment(id='k5n0wme'), Comment(id='k5nbcgr'), Comment(id='k5lfpoz'), Comment(id='k5olacx'), Comment(id='k5moxup'), Comment(id='k5mlidy'), Comment(id='k5mn6qy'), Comment(id='k5naffs'), Comment(id='k5ti108'), Comment(id='k5macto'), Comment(id='k5ndg1y'), Comment(id='k5n0saj'), Comment(id='k5nh52f'), Comment(id='k5nib9p'), Comment(id='k5nn98n'), Comment(id='k5nov7a'), Comment(id='k5nozhm'), Comment(id='k5p1ag1'), Comment(id='k5np6m1'), Comment(id='k5pc3f9'), Comment(id='k5nptjj'), Comment(id='k5odija'), Comment(id='k5oznac'), Comment(id='k5p1nub'), <MoreComments count=0, children=[]>]"
17bg00y,honghuiying,,2023-10-19 10:31:31+00:00,False,,1697711887.0,False,True,False,/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,Use cases of Advanced Math in Data Science and Machine Learning,"I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles.",datascience,https://www.reddit.com/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,21,28,0.89,"[Comment(id='k5j1d9a'), Comment(id='k5jamk0'), Comment(id='k5jb6xu'), Comment(id='k5jugq7'), Comment(id='k5kcx4n'), Comment(id='k5m8a77'), Comment(id='k5mby34'), Comment(id='k5rn8wo'), Comment(id='k66owdw'), Comment(id='k5j2oxl'), Comment(id='k5n7jh9'), Comment(id='k5nzrse'), Comment(id='k5kroum'), Comment(id='k5rndlw'), Comment(id='k5naxdx'), Comment(id='k5n8c0b'), Comment(id='k5nwmzg'), Comment(id='k5s0sjc'), Comment(id='k5poaah'), Comment(id='k5sawlb'), Comment(id='k5vuwvp')]"
17bxccu,HStuart18,,2023-10-19 23:49:52+00:00,False,,False,False,True,False,/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,Sharing large files for collaboration,"Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won't suit my current job. I'm thinking S3, but wondering if anyone has a better idea. Haven't used Git LFS either so curious about this one too. Cheers",datascience,https://www.reddit.com/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,3,2,0.76,"[Comment(id='k5n60ol'), Comment(id='k5mdkai'), Comment(id='k5mm6e5')]"
17avmi5,Consistent-Design-57,,2023-10-18 17:00:32+00:00,False,,1697713310.0,False,True,False,/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,Where are all the entry level jobs? Which MS program should I go for? Some tips from a hiring manager at an F50,"The bulk of this subreddit is filled with people trying to break into data science, completing certifications and getting MS degrees from diploma mills but with no real guidance. Oftentimes the advice I see here is from people without DS jobs trying to help other people without DS jobs on projects etc. It's more or less blind leading the blind.

Here's an insider perspective from me. I'm a hiring manager at an F50 financial services company you've probably heard of, I've been working for \~4 years and I'll share how entry-level roles actually get hired into.

There's a few different pathways. I've listed them in order of where the bulk of our candidate pool and current hires comes from

1. We pick MS students from very specific programs that we trust. These programs have been around for a while, we have a relationship with the school and have a good idea of the curriculum. Georgia Tech, Columbia, UVa, UC Berkeley, UW Seattle, NCSU are some universities we hire from. We don't come back every year to hire, just the years that we need positions filled. Sometimes you'll look around at teams here and 40% of them went to the same program. They're stellar hires. The programs that we hire from are incredibly competitive to get into, are not diploma mills, and most importantly, their programs have been around longer than the DS hype. How does the hiring process work? We just reach out to the career counselor at the school, they put out an interest list for students who want to work for us, we flip through the resumes and pick the students we like to interview. It's very streamlined both for us as an employer and for the student. Although I didn't come from this path (I was a referred by a friend during the hiring boom and just have a PhD), I'm actively involved in the hiring efforts.
2. We host hackathons every year for students to participate in. The winners of these hackathons typically get brought back to interview for internship positions, and if they perform well we pick them up as full time hires.
3. Generic career fairs at universities. If you go a to a university, you've probably seen career fairs with companies that come to recruit.
4. Referrals from our current employees. Typically they refer a candidate to us, we interview them, and if we like them, we'll punt them over to the recruiter to get the process started for hiring them. Typically the hiring manager has seen the resume before the recruiter has because the resume came straight to their inbox from one of their colleagues
5. Internal mobility of someone who shows promise but just needs an opportunity. We've already worked with them in some capacity, know them to be bright, and are willing to give them a shot even if they don't have the skills.
6. Far and away the worst and hardest way to get a job, our recruiter sends us their resume after screening candidates who applied online through the job portal. Our recruiters know more or less what to look for (I'm thankful ours are not trash)

This is true not just for our company but a lot of large companies broadly. I know Home Depot, Microsoft and few other large retail companies some of my network works at hire candidates this way.

Is it fair to the general population? No. But as employees at a company we have limited resources to put into finding quality candidates and we typically use pathways that we know work, and work well in generating high quality hires.

EDIT: Some actionable advice for those who are feeling disheartened. I'll add just a couple of points here:

1. If you already have your MS in this field or a related one and are looking for a job, reach out to your network. Go to the career fairs at your university and see if you can get some data-adjacent job in finance, marketing, operations or sales where you might be working with data scientists. Then you can try to transition internally into the roles that might be interesting to you.
2. There are also non-profit data organizations like Data Kind and others. They have working data scientists already volunteering time there, you can get involved, get some real world experience with non-profit data sets and leverage that to set yourself apart. It's a fantastic way to get some experience AND build your professional network.
3. Work on an open-source library and making it better. You'll learn some best practices. If you make it through the online hiring screen, this will really set you apart from other candidates
4. If you are pre MS and just figuring out where you want to go, research the program's career outcomes before picking a school. No school can guarantee you a job, but many have strong alumni and industry networks that make finding a job way easier. Do not go just because it looks like it's easy to get into. If it's easy to get into, it means that they're a new program who came in with the hype train

EDIT 2: I think some people are getting the wrong idea about ""prestige"" where the companies I'm aware of only hire from Ivies or public universities that are as strong as Ivies. That's not always the case - some schools have deliberately cultivated relationships with employers to generate a talent pipeline for their students. They're not always a top 10 school, but programs with very strong industry connections.

For example, Penn State is an example of a school with very strong industry ties to companies in NJ, PA and NY for engineering students. These students can go to job fairs or sign up for company interest lists for their degree program at their schools, talk directly to working alumni and recruiters and get their resume in front of a hiring manager that way. It's about the relationship that the university has cultivated to the local industries that hire and their ability to generate candidates that can feed that talent pipeline.",datascience,https://www.reddit.com/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,156,300,0.91,"[Comment(id='k5ferif'), Comment(id='k5gv8gb'), Comment(id='k5fnamv'), Comment(id='k5fie63'), Comment(id='k5hlz0u'), Comment(id='k5gq4a7'), Comment(id='k5g7mq9'), Comment(id='k5gi3ky'), Comment(id='k5g6od8'), Comment(id='k5fta4j'), Comment(id='k5frd44'), Comment(id='k5hcoot'), Comment(id='k5gsuxd'), Comment(id='k5hx4jw'), Comment(id='k5g9dow'), Comment(id='k5gqa4r'), Comment(id='k5flxnc'), Comment(id='k5h9tlx'), Comment(id='k5imqsk'), Comment(id='k5jfgud'), Comment(id='k5ibxbe'), Comment(id='k5gm9el'), Comment(id='k5jgc7y'), Comment(id='k5i6749'), Comment(id='k5ga5yn'), Comment(id='k5imooj'), Comment(id='k5iz9md'), Comment(id='k5gvzfe'), Comment(id='k5gi5v6'), Comment(id='k5ghgjf'), Comment(id='k5gl944'), Comment(id='k5i7405'), Comment(id='k5iklq4'), Comment(id='k5ilofs'), Comment(id='k5j6yyw'), Comment(id='k5jfm7e'), Comment(id='k5lwx60'), Comment(id='k5n0pjw'), Comment(id='k5zx3ag'), Comment(id='k5fjb3c'), Comment(id='k5fg16b'), Comment(id='k5imvfg'), Comment(id='k5gzpom'), Comment(id='k5x03d2'), Comment(id='k5gwku4'), Comment(id='k5ifzbu'), Comment(id='k5fj5q4'), Comment(id='k5hpxqc'), Comment(id='k5i5477'), Comment(id='k5gx2wd'), Comment(id='k5hg3of'), Comment(id='k5j7m1p'), Comment(id='k5gojba'), Comment(id='k5g7zhe'), Comment(id='k5j34wx'), Comment(id='k5fth19'), Comment(id='k5frm9n'), Comment(id='k5ifsao'), Comment(id='k5iumdp'), Comment(id='k5gwqtm'), Comment(id='k5gwy28'), Comment(id='k5fnkph'), Comment(id='k5nai5f'), Comment(id='k5i8wvy'), Comment(id='k5i4o8n'), Comment(id='k5jfwuv'), Comment(id='k5iscr7'), Comment(id='k5iupz2'), Comment(id='k5gn5lr'), Comment(id='k5itp9i'), Comment(id='k5isj5s'), Comment(id='k5j1vtz'), Comment(id='k5gwf9e'), Comment(id='k5h2yfd'), Comment(id='k5hair9'), Comment(id='k5iutau'), Comment(id='k5ism4q'), Comment(id='k5fo8ml'), Comment(id='k5ibdus'), Comment(id='k5jr3r9'), Comment(id='k5ioybo'), Comment(id='k5fi0t9'), Comment(id='k5itfbg'), Comment(id='k5ip244'), Comment(id='k5jrkq1'), Comment(id='k5h2kyi'), Comment(id='k5xgb1m'), Comment(id='k5jo7wo'), Comment(id='k5iiqmj'), Comment(id='k5go8pf'), Comment(id='k5g0orm'), Comment(id='k5hysb7'), Comment(id='k5ip5vl'), Comment(id='k5kgssn'), Comment(id='k5gap05'), Comment(id='k5goly5'), Comment(id='k5q6tlg'), Comment(id='k5frtwk'), Comment(id='k5sr7lv'), Comment(id='k5jp9t7'), Comment(id='k5gig2j'), Comment(id='k5kzusl'), Comment(id='k5jn11j'), Comment(id='k5j1412'), Comment(id='k5gnaed'), Comment(id='k5iu6gs'), Comment(id='k5hhl6a'), Comment(id='k5jll9c'), Comment(id='k5hdn4d'), Comment(id='k5ja81n'), Comment(id='k5iugmw'), Comment(id='k5kg2rx'), Comment(id='k5itxxt'), Comment(id='k5ipnpz'), Comment(id='k5l3404'), Comment(id='k5gxlss'), Comment(id='k5g1y4b'), Comment(id='k5ga4a7'), Comment(id='k5jd4e2'), Comment(id='k5gora9'), Comment(id='k5i4z7e'), Comment(id='k5i6y7n'), Comment(id='k5fsmco'), Comment(id='k5go7ci'), Comment(id='k5mewld'), Comment(id='k5j1bnq'), Comment(id='k5gnm6p'), Comment(id='k5hy1i3'), Comment(id='k5iuaxp'), Comment(id='k5ju243'), Comment(id='k5kpul6'), Comment(id='k5it2q0'), Comment(id='k5iqtae'), Comment(id='k5ls0uh'), Comment(id='k5iu9m0'), Comment(id='k5gdfj1'), Comment(id='k5gp7ua'), Comment(id='k5ihlwg'), Comment(id='k5icl2z'), Comment(id='k5j5q4u'), Comment(id='k5gcwkr'), Comment(id='k5g7elh'), Comment(id='k5j1cvt'), Comment(id='k5go3l2'), Comment(id='k5gnx68'), Comment(id='k5iux61'), Comment(id='k5iupfm'), Comment(id='k5mcyw2'), Comment(id='k5icxqw'), Comment(id='k5j6jnn'), Comment(id='k5icldw'), Comment(id='k5go7rg'), Comment(id='k5id366'), Comment(id='k5jjz1h'), Comment(id='k5gofy5'), Comment(id='k5idewd'), Comment(id='k5kayv5'), Comment(id='k5gop17'), Comment(id='k5idl5c'), Comment(id='k5kmb4l'), Comment(id='k5gwnew'), Comment(id='k5kpegr'), <MoreComments count=0, children=[]>]"
17bobx9,Kilroy_was_here__,,2023-10-19 17:17:58+00:00,False,,False,False,True,False,/r/datascience/comments/17bobx9/wrong_data_in_dataset/,Wrong data in dataset,"I have a very broad question about building a model using xgboost and feature selection. 

As an example, let’s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score > x. 

In this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it’s due to random chance. 

My assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts.",datascience,https://www.reddit.com/r/datascience/comments/17bobx9/wrong_data_in_dataset/,2,3,0.81,"[Comment(id='k5l0wwl'), Comment(id='k5m9q40')]"
17b32vd,WadeEffingWilson,,2023-10-18 22:18:57+00:00,False,,False,False,True,False,/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,"Those that have moved from a technical position to a leadership/supervisory position, do you regret it?","Do you still perform technical duties or is it nonstop meetings and people management? If it's the latter, do you miss the hands-on technical aspects or is it better on the leadership side?",datascience,https://www.reddit.com/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,40,46,0.93,"[Comment(id='k5h0z34'), Comment(id='k5gyz47'), Comment(id='k5i9958'), Comment(id='k5ijf4g'), Comment(id='k5hyhcp'), Comment(id='k5gzbru'), Comment(id='k5hnhn5'), Comment(id='k5ilel9'), Comment(id='k5j13uk'), Comment(id='k5kmn77'), Comment(id='k5gxk9a'), Comment(id='k5h5c35'), Comment(id='k5hoh4z'), Comment(id='k5joy6a'), Comment(id='k5kc6bv'), Comment(id='k5lpogx'), Comment(id='k5nzysk'), Comment(id='k5njgsp'), Comment(id='k5rg6iw'), Comment(id='k5nayq3'), Comment(id='k5i1cvg'), Comment(id='k5nabda'), Comment(id='k5kwi5h'), Comment(id='k5h7i7y'), Comment(id='k5nhix7'), Comment(id='k5h3xfm'), Comment(id='k5h7tyf'), Comment(id='k5itjiy'), Comment(id='k5nbae7'), Comment(id='k5rfcxy'), Comment(id='k5m6ry3'), Comment(id='k5nd9g6'), Comment(id='k5npi6j'), Comment(id='k5hch2g'), Comment(id='k5hhbel'), Comment(id='k5j3vxy'), Comment(id='k5ne671'), Comment(id='k5j9mb8'), Comment(id='k5nevqu'), Comment(id='k5omkmq')]"
17ar38i,jujuman1313,,2023-10-18 13:41:03+00:00,False,,False,False,True,False,/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,LLM domination on job descriptions,"Can anyone explain why many companies asking for LLM experience for data scientist roles?  
It wasn't there like 6-8 months ago, now around %70 of the job descriptions asking for that and it goes like Python, SQL and LLM. Looks a bit weird to be honest.  
What are they doing, creating their own chatgpt?  
",datascience,https://www.reddit.com/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,69,175,0.96,"[Comment(id='k5eq0p4'), Comment(id='k5egkrr'), Comment(id='k5enrc9'), Comment(id='k5eyofu'), Comment(id='k5eqcd2'), Comment(id='k5es29z'), Comment(id='k5fl1v7'), Comment(id='k5exe4t'), Comment(id='k5eq86c'), Comment(id='k5fsx60'), Comment(id='k5f4xg6'), Comment(id='k5f99gb'), Comment(id='k5euxn1'), Comment(id='k5eut37'), Comment(id='k5g32y7'), Comment(id='k5iny9u'), Comment(id='k5izquf'), Comment(id='k5j5lo3'), Comment(id='k5k6vap'), Comment(id='k5l1qu3'), Comment(id='k5mus0u'), Comment(id='k5oig9m'), Comment(id='k6369mb'), Comment(id='k5ev3y8'), Comment(id='k5exntj'), Comment(id='k5f0ubg'), Comment(id='k5exw4e'), Comment(id='k5fefsc'), Comment(id='k5k0xnd'), Comment(id='k5gykd5'), Comment(id='k5f98hp'), Comment(id='k5qatgn'), Comment(id='k5fccbk'), Comment(id='k5f5l1e'), Comment(id='k5f3m4z'), Comment(id='k5f4qbx'), Comment(id='k5f9c2u'), Comment(id='k5ewfq2'), Comment(id='k5frn5k'), Comment(id='k5ilsx9'), Comment(id='k5iyjnj'), Comment(id='k5mv1jo'), Comment(id='k6dwsfq'), Comment(id='k5expwl'), Comment(id='k5ic9bo'), Comment(id='k5f0let'), Comment(id='k5gjll1'), Comment(id='k5f4hib'), Comment(id='k5fe4du'), Comment(id='k5o5w59'), Comment(id='k61jbqg'), Comment(id='k5m66dz'), Comment(id='k5fojes'), Comment(id='k5g5eam'), Comment(id='k5fk6tt'), Comment(id='k5eyck0'), Comment(id='k6esj0j'), Comment(id='k5oh89h'), Comment(id='k5f9dcd'), Comment(id='k5f797o'), Comment(id='k5gi13e'), Comment(id='k5pqv30'), Comment(id='k5g60el'), Comment(id='k5g9zgk'), Comment(id='k5f6qwp'), Comment(id='k5i16pl'), Comment(id='k5fqo8a'), Comment(id='k5qfhqd'), Comment(id='k5g6j9i'), Comment(id='k5jv5xm')]"
17ay21z,Turbulent-City-9377,,2023-10-18 18:44:19+00:00,False,,False,False,True,False,/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,"What's better as a data scientist ""precursor role"": a software developer or a business analyst?","I've been offered the opportunity to transfer to my firm's IT department after I expressed interested in and demonstrated proficiency in data science (coming from a quantitative but not pure DS department). The IT department doesn't have a specific data science ""role"" though -- only software developer and business analyst. Given I want to eventually settle into a pure data scientist role -- and pursue a Masters in such (I'm 24) -- which of these two roles would you choose if you were taking a career-level view? 

In the software dev role, I'd get hands-on experience with writing code everyday, but it would be chiefly in a software development environment -- not data science. With the BA role, I would have hands-on experience with product management and dashboarding and Confluence, but not so much writing code. I'm torn. I just ultimately want to be in a role where I can dive into datasets everyday and always have a numpy-pandas-matplotlib-sklearn environment open on my computer.

Any advice would be greatly appreciated! Thanks so much.",datascience,https://www.reddit.com/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,42,39,0.84,"[Comment(id='k5ghezz'), Comment(id='k5fvait'), Comment(id='k5ge4zm'), Comment(id='k5gt6kn'), Comment(id='k5gvpqd'), Comment(id='k5gbz8r'), Comment(id='k5ig356'), Comment(id='k5hypub'), Comment(id='k5go4cy'), Comment(id='k5maaxd'), Comment(id='k5gw6un'), Comment(id='k5k2od7'), Comment(id='k5fwh92'), Comment(id='k5ged6f'), Comment(id='k5gefjj'), Comment(id='k5gn36k'), Comment(id='k5lrpik'), Comment(id='k5gv3q8'), Comment(id='k5gwf3j'), Comment(id='k5gcwgw'), Comment(id='k5ge5cq'), Comment(id='k5gm8zw'), Comment(id='k5ite05'), Comment(id='k5go82a'), Comment(id='k5mieyr'), Comment(id='k5h14t0'), Comment(id='k5is6te'), Comment(id='k5gq91h'), Comment(id='k5gnpaf'), Comment(id='k5kfmcv'), Comment(id='k5ge6co'), Comment(id='k5o2kum'), Comment(id='k5h7zjd'), Comment(id='k5jg7z2'), Comment(id='k5h19sz'), Comment(id='k5jfwaz'), Comment(id='k5ijpkg'), Comment(id='k5p9s12'), Comment(id='k5hifa0'), Comment(id='k5kjtyj'), Comment(id='k5pcrwd'), Comment(id='k5hnhxs')]"
17becn2,mesheaa,,2023-10-19 08:33:57+00:00,False,,1697811936.0,False,True,False,/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,Different loss function than evaluation metric,"Hi all,

I am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.

Do you know why gaze angular error is not used as loss as well?

&#x200B;

\[Edit\]

I tried now angular error as loss and it is really terrible. 

Like L1 loss results in a gaze angle error of around 2°, while my custom loss is resulting in errors around 50°. I though about using multi-loss approach, for example l1 + angular error to consider the depth length. What do you guys think of that?",datascience,https://www.reddit.com/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,2,3,1.0,"[Comment(id='k5j2vge'), Comment(id='k5jlnn4')]"
17az6v2,EagerMonkey,,2023-10-18 19:31:56+00:00,False,,False,False,True,False,/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,Will Understanding Advanced Data Structures Make Me a Better Data Scientist?,"I'm a data scientist with 5 yoe now, and I've never needed to implement a tree, a linked list, a graph, a stack, or a queue. If I need a decision tree, I use a package like sklearn. If I'm doing graph analysis, typically I treat it like a matrix. I don't even have any idea what models might need a queue, but maybe that's really important for data processing or training somewhere?

&#x200B;

Have any of you really needed to implement these data structures, or do you just use packages that are using them under the hood? Would I actually be meaningfully better at my day to day job if I knew when and how to use a linked list or a stack?",datascience,https://www.reddit.com/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,14,22,0.82,"[Comment(id='k5gewj9'), Comment(id='k5g5vfq'), Comment(id='k5hcts2'), Comment(id='k5gw49n'), Comment(id='k5gzz1d'), Comment(id='k5rh6hp'), Comment(id='k5hnh8o'), Comment(id='k5hodik'), Comment(id='k5hoomp'), Comment(id='k5h0yok'), Comment(id='k5ggh4a'), Comment(id='k5hh243'), Comment(id='k5innm2'), Comment(id='k5n5ywu')]"
17bf3cx,CursorInsight,,2023-10-19 09:28:19+00:00,False,,False,False,True,False,/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,Programming language for machine learning and data analysis – Our choice,"&#x200B;

## Python

Undoubtedly, **the uncrowned king** of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching, **is Python**. This is down to several reasons; the three most important among them are its **maturity**, the enormous **community**, and, last but not least, a **vast array of robust third-party libraries**. But even if Python is a magnanimous sovereign that many developers love, it doesn’t mean that there can’t be contenders occasionally.

## Julia

Fourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a **friendly syntax**, offers **efficient mathematical computations** out of the box, at a **performance on par with compiled languages**. And thus, [**Julia**](https://julialang.org/) was born (here’s a manifesto explaining [**why**](https://julialang.org/blog/2012/02/why-we-created-julia/) in more detail). Its first version was launched a bit more than eleven years ago.

## Our choice

Many in-depth comparisons of Python and Julia on the web (such as [**this one**](https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac) or [**this**](https://www.turing.com/kb/julia-vs-python)) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia’s growing popularity, we are sure more will follow. In the rest of this blog post, however, let’s explore why we picked Julia for our purposes. And that’s not to say that we don’t use Python for data science. On the contrary, we **often run analyses in both ecosystems simultaneously** to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.

## The advantages of Julia

So what makes Julia so compelling to us?

## Language features

Julia has:

* a friendly, easy-to-read (and write) syntax;
*  a flexible and expressive (part static, part dynamic) type system;
*  powerful mathematical notations, such as built-in vector and matrix operations;
*  efficient [**multiple dispatches**](https://en.wikipedia.org/wiki/Multiple_dispatch), a form of function polymorphism working with runtime types;
*  convenient and reliable parallel computing facilities;
*  meta-programming with macros and generated functions.

## Fast code execution

Julia compiles the source code to **native binary at runtime** via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer; **the benefits start to shine when a piece of code is run multiple times**. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.

## Built-in package management

Julia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of **stable and well-designed packages** is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.

## Interactive tools

Julia offers an **advanced** [**REPL**](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) with all the goodies of an interpreted language environment. These include:

* code and variable inspection,
*  code completion,
*  an interactive debugger,
*  benchmarking and profiling tools,
*  and a built-in help system.

**With third-party libraries, it can also be extended** with [**syntax highlighting**](https://github.com/KristofferC/OhMyREPL.jl), [**source code lookup**](https://github.com/tkf/InteractiveCodeSearch.jl) (even for base libraries), automatic [**code reload**](https://timholy.github.io/Revise.jl/stable/), and many more exciting, modern features.

All these together make Julia an **ideal environment for rapid prototyping**.

## From prototyping to production code

Because of the high-level interactive tools and fast code execution, **the transition from a rapid prototype to production-ready code can be as continuous as you’d like**. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.

Thanks to its friendly syntax and built-in package management, **the road to maintainable code is well paved**. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.

As a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.

## The disadvantages of Julia

That said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:

* the very powerful tool of broadcasting and vectorization can be intimidating at first;
* [**time to first plot**](https://discourse.julialang.org/t/time-to-first-plot-clarification/58534) can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;
*  many packages never reach a stable state or just become unmaintained; others are poorly designed or written;
* [**releasing a binary package**](https://github.com/JuliaLang/PackageCompiler.jl) can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.

## Summary

In conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.

Still, in the past years, **Julia has proved to be our reliable and faithful companion**. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!",datascience,https://www.reddit.com/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,18,0,0.48,"[Comment(id='k5jf19l'), Comment(id='k5j0r5o'), Comment(id='k5iytwh'), Comment(id='k5j7ukl'), Comment(id='k5jdtg0'), Comment(id='k5jwl6m'), Comment(id='k5jvi58'), Comment(id='k5jhfve'), Comment(id='k5k748m'), Comment(id='k5kbsax'), Comment(id='k5mulv3'), Comment(id='k5n8vd6'), Comment(id='k5jxwld'), Comment(id='k5lm34l'), Comment(id='k5lsoe4'), Comment(id='k5p9tpk'), Comment(id='k5pagdu'), Comment(id='k5pfens')]"
17bdzis,MandM-DataScience,,2023-10-19 08:06:47+00:00,False,,False,False,True,False,/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,Market Timing & Risk Management - Portfolio allocation,"Hi everyone!  
Is it possible to create a market timing strategy using unsupervised learning? 

Let's find out.

Relevant Topics:

* Used S&P500 data
* Segmenting Time series using Online Change Detection Point
* Clustering segments with KMeans
* Risk Allocation
* Value at Risk

Here's the notebook:  
[https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook](https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook)

Every and each comment / feedback is greatly appreciated!

Thank you!  
M&M",datascience,https://www.reddit.com/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,0,1,1.0,[]
17ajqwd,treaty_tonvis,,2023-10-18 06:12:22+00:00,False,,False,False,True,False,/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,Shit scared of Leetcode!,"I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you'll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can't do anything beyond Leetcode easy, my mind just doesn't accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don't practice that problem in every few days. 

Someone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?",datascience,https://www.reddit.com/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,54,56,0.89,"[Comment(id='k5dcx0n'), Comment(id='k5du4v1'), Comment(id='k5eqffk'), Comment(id='k5dd0a6'), Comment(id='k5dc293'), Comment(id='k5djtng'), Comment(id='k5fvl12'), Comment(id='k5edix5'), Comment(id='k5eqbgc'), Comment(id='k5eyqg7'), Comment(id='k5g08lg'), Comment(id='k5n93lf'), Comment(id='k5eemek'), Comment(id='k5fcc0y'), Comment(id='k5ho35a'), Comment(id='k5j2lql'), Comment(id='k5j2pgh'), Comment(id='k5lybfa'), Comment(id='k5mazo9'), Comment(id='k617vpl'), Comment(id='k5evdso'), Comment(id='k5ed2lh'), Comment(id='k5eder1'), Comment(id='k5hsxxk'), Comment(id='k5edcvz'), Comment(id='k5deok8'), Comment(id='k5fezs8'), Comment(id='k5eco1j'), Comment(id='k5hu2h8'), Comment(id='k5htsp8'), Comment(id='k5evxp3'), Comment(id='k5htq9j'), Comment(id='k5htzaz'), Comment(id='k5hu8st'), Comment(id='k5htvy8'), Comment(id='k5fgs31'), Comment(id='k5hub78'), Comment(id='k5euitx'), Comment(id='k5dxpv5'), Comment(id='k5ewzo0'), Comment(id='k5ecfco'), Comment(id='k5htew8'), Comment(id='k5evlbb'), Comment(id='k5ibh3l'), Comment(id='k5ip175'), Comment(id='k5hstd7'), Comment(id='k5fffvk'), Comment(id='k5ed12z'), Comment(id='k5htl9n'), Comment(id='k5fju9a'), Comment(id='k5ht6aa'), Comment(id='k5ht6po'), Comment(id='k5ht73y'), Comment(id='k5hwjvj')]"
17b3lup,_degamus_,,2023-10-18 22:42:20+00:00,False,,False,False,True,False,/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,Advice on imbalanced datasets with many missing values,"Hi! I am currently working on a binary classification model for a highly imbalanced dataset with lots of missing values in there. I tried using multiple techniques for resampling (Random, SMOTE, and SMOTETomak) and imputation (MICE), as well as a bit of tweaking of class weights and loss function, but still I am not able to get higher than this.

CatBoost Accuracy:  0.843492894540015
              precision    recall  f1-score   support

         0.0       0.95      0.87      0.91      4775
         1.0       0.36      0.62      0.46       573

    accuracy                           0.84      5348
   macro avg       0.66      0.74      0.68      5348
weighted avg       0.89      0.84      0.86      5348

Any ideas on what can I also try considering such results and above mentioned trials? Any feature engineering techniques that I might not know? 

Also one of the interesting things about dataset is relatively large amount of categorical features - 30 out of 140 (two of them have 2k different options, others are in the range from 3 to 30). I used multiple different methods for encoding here depending on the amount of categories - One Hot, Binary and Target.

One of the main issues of the dataset is lack of context so I'm mostly trying to improve both precision and recall (and f1 as a result) at least to somewhat degree.

Thanks in advance for any possible ideas?",datascience,https://www.reddit.com/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,5,2,1.0,"[Comment(id='k5hfqul'), Comment(id='k5kq66q'), Comment(id='k5jahml'), Comment(id='k5kqpb5'), Comment(id='k5kswin')]"
17aba8a,Sea-Bodybuilder-1277,,2023-10-17 22:55:29+00:00,False,,1697588397.0,False,True,False,/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,I'm giving up finding a job. I feel like I'll have better luck applying to PhD programs. This is a rant.,"Just recently graduated in May with a BS statistics from texas a&m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I'm almost done with the meta coursera front-end prof certificate and I'm gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I've thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn't get any traffic, maybe it'll look good on a resume.

I'm disenchanted with it all, I'm hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn't a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as ""pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference"", I'm not asking any questions. It's just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says ""I'm of value"" and ""people can rely on me"", and knowing people. Especially when employers aren't going to ask my professors how I was like,  I imagine I'll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I'm just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I'm pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can't get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don't mind taking tests, and I know how to live with a low overhead (I don't buy stuff I don't need). I know what really matters, your basic needs, family, a few good friends. Ok, that's not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don't.",datascience,https://www.reddit.com/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,152,149,0.83,"[Comment(id='k5buczl'), Comment(id='k5ca88v'), Comment(id='k5by4od'), Comment(id='k5ctnt2'), Comment(id='k5cwg09'), Comment(id='k5c80vt'), Comment(id='k5bz1d9'), Comment(id='k5caxok'), Comment(id='k5c5286'), Comment(id='k5cg8lq'), Comment(id='k5casjl'), Comment(id='k5cnlw7'), Comment(id='k5dmeml'), Comment(id='k5f1hcb'), Comment(id='k5gta2w'), Comment(id='k5c5vf7'), Comment(id='k5ci932'), Comment(id='k5ccd69'), Comment(id='k5dfb2n'), Comment(id='k5ecgx8'), Comment(id='k5elyu7'), Comment(id='k5d5t89'), Comment(id='k5d7a25'), Comment(id='k5bxzcp'), Comment(id='k5dkann'), Comment(id='k5dotl7'), Comment(id='k5dze6d'), Comment(id='k5e5tao'), Comment(id='k5ed4op'), Comment(id='k5ed9lk'), Comment(id='k5ee868'), Comment(id='k5ee9xy'), Comment(id='k5ejrxa'), Comment(id='k5f2r17'), Comment(id='k5fhrjm'), Comment(id='k5fiv7e'), Comment(id='k5gp0l3'), Comment(id='k5hijid'), Comment(id='k5hmfbd'), Comment(id='k5s7jud'), Comment(id='k5bunrc'), Comment(id='k5dpnsj'), Comment(id='k5cajzp'), Comment(id='k5f3ygk'), Comment(id='k5ei40z'), Comment(id='k5c8qow'), Comment(id='k5cy1j3'), Comment(id='k5byff1'), Comment(id='k5d045p'), Comment(id='k5cvw20'), Comment(id='k5dfsp7'), Comment(id='k5c0nza'), Comment(id='k5e550m'), Comment(id='k5c645e'), Comment(id='k5cgh7i'), Comment(id='k5cbb2u'), Comment(id='k5cof2j'), Comment(id='k5c6d2d'), Comment(id='k5cileb'), Comment(id='k5cfkh7'), Comment(id='k5evnrk'), Comment(id='k5ex818'), Comment(id='k5d7miy'), Comment(id='k5c88t9'), Comment(id='k5c9fc9'), Comment(id='k5eyguv'), Comment(id='k5euipf'), Comment(id='k5ew13f'), Comment(id='k5ex0ed'), Comment(id='k5c2f7n'), Comment(id='k5bv89r'), Comment(id='k5f4o19'), Comment(id='k5funt5'), Comment(id='k5f3v4u'), Comment(id='k5czyhl'), Comment(id='k5f5e0k'), Comment(id='k5cayai'), Comment(id='k5ca317'), Comment(id='k5elfkm'), Comment(id='k5e7vpj'), Comment(id='k5cy1ix'), Comment(id='k5drl6l'), Comment(id='k5e4amz'), Comment(id='k5c28bb'), Comment(id='k5c2nvs'), Comment(id='k5cmb61'), Comment(id='k5ca54u'), Comment(id='k5curzh'), Comment(id='k5c8uj8'), Comment(id='k5cjlxo'), Comment(id='k5dymvz'), Comment(id='k5d81i7'), Comment(id='k5ca9ad'), Comment(id='k5exoie'), Comment(id='k5f2h5z'), Comment(id='k5dyooz'), Comment(id='k5bxa0a'), Comment(id='k5hwpbc'), Comment(id='k5f6w21'), Comment(id='k5dvnjj'), Comment(id='k5fkjhg'), Comment(id='k5eovl0'), Comment(id='k5eyba9'), Comment(id='k5f6z9t'), Comment(id='k5eu8pr'), Comment(id='k5c2own'), Comment(id='k5cgnlk'), Comment(id='k5c3fmt'), Comment(id='k5ey64e'), Comment(id='k5cf24j'), Comment(id='k5cbvxd'), Comment(id='k5ckkfm'), Comment(id='k5d8b10'), Comment(id='k5hzqq7'), Comment(id='k5f548l'), Comment(id='k5ejkk0'), Comment(id='k5f3ftj'), Comment(id='k5ivum5'), Comment(id='k5fqiex'), Comment(id='k5eu1w7'), Comment(id='k5c36cc'), Comment(id='k5capxg'), Comment(id='k5cgula'), Comment(id='k5ciw4s'), Comment(id='k5g2atx'), Comment(id='k5ci0oc'), Comment(id='k5ffz5k'), Comment(id='k5g1w15'), Comment(id='k5c9jyx'), Comment(id='k5f8luh'), Comment(id='k5chu3k'), Comment(id='k5d93iv'), Comment(id='k5eq82h'), Comment(id='k5jnhq9'), Comment(id='k5frl08'), Comment(id='k5c4dnc'), Comment(id='k5chiew'), Comment(id='k5cjc3x'), Comment(id='k5d9qyv'), Comment(id='k5evju0'), Comment(id='k5kvmrn'), Comment(id='k5ft7ku'), Comment(id='k5ewo98'), Comment(id='k5shvf6'), Comment(id='k5fzks1'), Comment(id='k5f39iv'), Comment(id='k5n5yrd'), Comment(id='k5g3gsn'), Comment(id='k5ggx6d'), <MoreComments count=0, children=[]>]"
17b2d08,CaptainVJ,,2023-10-18 21:48:19+00:00,False,,False,False,True,False,/r/datascience/comments/17b2d08/binary_classification_question/,Binary classification question?,"So I’m trying to build a model to find some inappropriate payments. So I have the data of all payments made, however, some of them were audited while the vast majority aren’t. 

The ones that aren’t audited are just automatically approved while the ones that are audited are approved or rejected based on auditors judgment. So my plan is to just use all the payments that has been audited as the population and ignore the payments that have never been audited since they don’t really tell us much.  

So probably about 1% of payments are audited and if that about 7% are rejected. 

Now the issue is that most of the payments that were rejected were for minor issues. Maybe the person who’s entered the payment made a slight typo for the invoice number, so that was rejected and they had to resubmit it, or something minor. 

Those payments aren’t abiding by some minor rules and they need to be rejected and resubmitted after being corrected. They’re wrong but not really worth the time because we aren’t saving any money. Unfortunately, that’s about 70% of rejected payments. 

Now the other 30% is where the real savings is happening, potential fraud, the accountant mistyped the amount to be paid or whatever. And that’s what I’m really trying to find, if I find the others that’s cool but doesn’t really do much. 

How would I go about selecting my data for that. Would I just ignore the 60% of rejected payments that aren’t that big of a deal and proceed without. If so, would I also reduce the number the number of payments that were accepted as well by 60%. 

Or any alternative suggestions?",datascience,https://www.reddit.com/r/datascience/comments/17b2d08/binary_classification_question/,1,1,0.67,[Comment(id='k5hdd3b')]
17ax0xj,The_powerful_onion,,2023-10-18 17:59:55+00:00,False,,False,False,True,False,/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,Project ideas that combine Data Science (Data Analytics) and Digital Marketing,"Hello everyone! I am currently working in digital marketing (I’m entry level) and I have a degree in data analytics. I would like to be able to combine both fields, and I’m looking for any good project ideas to do so (preferably using R or Python). Any ideas are helpful!",datascience,https://www.reddit.com/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,4,2,1.0,"[Comment(id='k5iifzg'), Comment(id='k5ftof9'), Comment(id='k5jyrno'), Comment(id='k5fu1x0')]"
17aq5r0,RecoverMotor,,2023-10-18 12:56:53+00:00,False,,False,False,True,False,/r/datascience/comments/17aq5r0/microsoft_azure/,Microsoft Azure,"I am Data analyst with 2 years of experience and in the companies that I have work, I have not had any experience with data processing in cloud services. I am interested in learn Azure, AWS or Google cloud for data science and get the certifications. Could you tell me what is better, and how important are those certificates in my career path?.
Thanks!!!",datascience,https://www.reddit.com/r/datascience/comments/17aq5r0/microsoft_azure/,1,4,0.84,[Comment(id='k5kvtpr')]
17a79kw,wildwildwildebeast,,2023-10-17 20:03:17+00:00,False,,False,False,True,False,/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/,Interview Take Home task seemed unreasonable,"I am finishing my my masters degree in data analytics. Previously I've worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. 

I got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn't get home till 10pm.

Fast forward this morning. I wake up at 8.i get started on the R project at 9am.

The data was some of the messiness I've seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. 

I'm not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven't asked me to do anything like that in such a short time. Is this to be expected going forward?",datascience,https://www.reddit.com/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/,58,100,0.95,"[Comment(id='k5bh3pz'), Comment(id='k5b76i6'), Comment(id='k5bonvg'), Comment(id='k5b6bl8'), Comment(id='k5bkydj'), Comment(id='k5c088s'), Comment(id='k5be4f3'), Comment(id='k5cqdjx'), Comment(id='k5crchr'), Comment(id='k5cfgjq'), Comment(id='k5ciusw'), Comment(id='k5cp189'), Comment(id='k5exzwb'), Comment(id='k5b1pps'), Comment(id='k5bzvwz'), Comment(id='k5bqc7r'), Comment(id='k5cdgbj'), Comment(id='k5cj7bw'), Comment(id='k5ba7be'), Comment(id='k5bphpj'), Comment(id='k5cdr0u'), Comment(id='k5cp1ng'), Comment(id='k5dterp'), Comment(id='k5duubw'), Comment(id='k5e0i40'), Comment(id='k5etosj'), Comment(id='k5hguyl'), Comment(id='k5c4hef'), Comment(id='k5bzdhm'), Comment(id='k5c59lz'), Comment(id='k5bt51y'), Comment(id='k5c2axh'), Comment(id='k5ctx6g'), Comment(id='k5d71wv'), Comment(id='k5hkk20'), Comment(id='k5cru3n'), Comment(id='k5co026'), Comment(id='k5bzejx'), Comment(id='k5c1dg9'), Comment(id='k5dgj8a'), Comment(id='k5c8h83'), Comment(id='k5dsi94'), Comment(id='k5dj9vn'), Comment(id='k5e1j7f'), Comment(id='k5cdafz'), Comment(id='k5djeid'), Comment(id='k5cqbaw'), Comment(id='k5ems69'), Comment(id='k5dq5h7'), Comment(id='k5fajuy'), Comment(id='k5c6gas'), Comment(id='k5cpvbc'), Comment(id='k5cxnzu'), Comment(id='k5d47yb'), Comment(id='k5e4wf5'), Comment(id='k5esxv5'), Comment(id='k5cy87a'), Comment(id='k5fd4vg'), Comment(id='k5d3qnb')]"
17atfvp,cdtmh,,2023-10-18 15:26:22+00:00,False,,False,False,True,False,/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,Pricing Analysis Career Progression to Data Science,"I was a DS in an insurance company (essentially a pricing analyst), I was doing a lot of XGB and GLM models etc. It was enjoyable but I have a degree in DS so I always wanted to move into something which would project me into more complex/cool modelling.

Anyway, my question, I moved to London and am now looking for a new job but the currently tough market is looking for much more experience than I currently have in data science related work (I have 1 year). Would taking a Pricing Analyst role (doing the same algorithms as before) hurt my progression or help it in the eventual goal of being in something machine learning related down the line.

I think it would strengthen my prediction models, but at the same time I wouldn't be exercising what I did in my MSc degree. What do you think?",datascience,https://www.reddit.com/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,2,2,1.0,"[Comment(id='k5f82ia'), Comment(id='k5f883f')]"
17al968,Asleep-Fun-6508,,2023-10-18 07:56:32+00:00,False,,False,False,True,False,/r/datascience/comments/17al968/forecasting_sales/,Forecasting sales,"So i’m working on a project that forecasts sales of products in a series. Curious to know the best approach to model “cascaded” products i.e old version of the series when the new one launches.
Using a Recursive multistep regression approach to forecast with some features

Appreciate the help, thanks 🙏🏼",datascience,https://www.reddit.com/r/datascience/comments/17al968/forecasting_sales/,4,6,1.0,"[Comment(id='k5dj1jt'), Comment(id='k5e90qa'), Comment(id='k5dpe35'), Comment(id='k5dpza7')]"
17alvvb,jaegarbong,,2023-10-18 08:42:00+00:00,False,,False,False,True,False,/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,How can I show knowledge in topics I haven't worked on professionally?,"I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. 

The topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.

My problem is how can I show this in my recruiters such that they don't just ignore my personal projects section. ",datascience,https://www.reddit.com/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,3,3,0.81,"[Comment(id='k5e0kh2'), Comment(id='k7slmwv')]"
17ad4og,relativefluffy,,2023-10-18 00:19:45+00:00,False,,False,False,True,False,/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,Where do you start if you are new to mathematical models,I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters,datascience,https://www.reddit.com/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,10,12,0.88,"[Comment(id='k5cbhtj'), Comment(id='k5cfvsa'), Comment(id='k5crdvh'), Comment(id='k5dl6pp'), Comment(id='k5cmf1t'), Comment(id='k5c4kz1'), Comment(id='k5e79mh'), Comment(id='k5cz5g4'), Comment(id='k5dkgc0'), Comment(id='k5dztnv')]"
179huzu,softwareitcounts,,2023-10-16 21:51:33+00:00,False,,False,True,False,False,/r/datascience/comments/179huzu/meme_mondays/,Meme Mondays,,datascience,https://i.redd.it/zxdz4pm6ymub1.png,99,1656,0.98,"[Comment(id='k57i6jw'), Comment(id='k583pad'), Comment(id='k58ghzy'), Comment(id='k586b9s'), Comment(id='k570knd'), Comment(id='k571zj7'), Comment(id='k57qkuu'), Comment(id='k594mix'), Comment(id='k57zbbv'), Comment(id='k59yet2'), Comment(id='k58xmqf'), Comment(id='k58tn8n'), Comment(id='k59iy03'), Comment(id='k575kvk'), Comment(id='k59gjac'), Comment(id='k59lzh2'), Comment(id='k5adwwq'), Comment(id='k5b1x4p'), Comment(id='k5c0wt3'), Comment(id='k5cabb7'), Comment(id='k5dgncr'), Comment(id='k58pf1v'), Comment(id='k58qq2k'), Comment(id='k597da7'), Comment(id='k58ya18'), Comment(id='k59u8jg'), Comment(id='k5a31mz'), Comment(id='k5afb9l'), Comment(id='k5az13g'), Comment(id='k5cm9n5'), Comment(id='k5d0l23'), Comment(id='k5d86mo'), Comment(id='k5e541z'), Comment(id='k7dizl9'), Comment(id='k7hnfkh'), Comment(id='k59gy0c'), Comment(id='k57pdn7'), Comment(id='k57wmlw'), Comment(id='k5huyz6'), Comment(id='k5ba7dc'), Comment(id='k58nak8'), Comment(id='k5anan4'), Comment(id='k58dsf8'), Comment(id='k579q4m'), Comment(id='k57ac9z'), Comment(id='k57ntiw'), Comment(id='k58dqij'), Comment(id='k5a5sph'), Comment(id='k5cjtw6'), Comment(id='k5az82f'), Comment(id='k5c70ki'), Comment(id='k59h72c'), Comment(id='k5m22b3'), Comment(id='k5azcyx'), Comment(id='k5a8sgd'), Comment(id='k5focj2'), Comment(id='k58wi1z'), Comment(id='k596354'), Comment(id='k5ah6bc'), Comment(id='k5a2hn1'), Comment(id='k5a360m'), Comment(id='k57py64'), Comment(id='k58qya2'), Comment(id='k5a7mhs'), Comment(id='k5agofj'), Comment(id='k58drgd'), Comment(id='k599ohk'), Comment(id='k59ebn0'), Comment(id='k5ap7vj'), Comment(id='k57nahp'), Comment(id='k58j3cy'), Comment(id='k5aufaw'), Comment(id='k5dzep0'), Comment(id='k5clzi0'), Comment(id='k5eexzi'), Comment(id='k5efegl'), Comment(id='k5d0yq4'), Comment(id='k5c5gou'), Comment(id='k59c105'), Comment(id='k5d9kxq'), Comment(id='k5aalen'), Comment(id='k57tjz7'), Comment(id='k57uru6'), Comment(id='k5ctpey'), Comment(id='k59e9wk'), Comment(id='k5a6ah1'), Comment(id='k591jyr'), Comment(id='k59p8kz'), Comment(id='k59hfej'), Comment(id='k5dkxjb'), Comment(id='k5e3fhm'), Comment(id='k59gs3l'), Comment(id='k5du9r9'), Comment(id='k5p5jf3'), Comment(id='k5a02p7'), Comment(id='k5bgn2o'), Comment(id='k5a85sf'), Comment(id='k5bh31z'), Comment(id='k5aalcb')]"
17ayhj7,Jogy-Bogy,,2023-10-18 19:02:14+00:00,False,,False,False,False,False,/r/datascience/comments/17ayhj7/mainspring_routine_planner/,Mainspring - Routine Planner,"Hey everyone,
I'm an indie app developer, building in public on Threads.
Recently I launched Mainspring, a new routine planner app that helps you keep track of your every-day actions with a simple and intuitive UI.

Why is Mainspring different?
I built it with simplicity in mind, everyone have different goals with these kind of apps, some want to just track events, others want to keep themselves motivated, Mainspring will be a great fit for a broad number of people. Mainspring also provides motivational and beautiful statistics and graphs that can be viewed to empower progress.

Your full event history can be viewed and is beneficial if you want to remember when you last did something (e.g. when did I last got a haircut). 

Check it out and let me know what you think. 

iOS: https://apps.apple.com/app/mainspring-routine-planner/id6467129951

Android:
https://play.google.com/store/apps/details?id=com.naamapps.mainspring",datascience,https://www.reddit.com/gallery/17ayhj7,0,0,0.38,[]
17alwcz,zurdosios,,2023-10-18 08:43:00+00:00,False,,1697628721.0,False,True,False,/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,"DAGitty Question: Testable Implications only describes independencies, but not dependencies","Why does the DAGitty ""Testable Dependencies"" function only describe independencies, but not spurious correlations?

&#x200B;

E.g, if I have B->A<-C,

DAGitty just tells me that

B ⊥ C is the only testable (in)dependency

Why shouldn't we expect also

B⊥̸C|A

(i.e, B and C have a spurious correlation given A)?",datascience,https://www.reddit.com/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,0,2,1.0,[]
17a6ken,MultiPass10,,2023-10-17 19:33:18+00:00,False,,False,False,True,False,/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,"Converting XGBoost decision models to ""if-then"" statements","I am aware of a few tools that aid in converting XGBoost decision trees to ""if-then"" statements. I'm curious if anyone has experience with this approach, and how feasible/successful was the outcome?",datascience,https://www.reddit.com/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,17,16,0.87,"[Comment(id='k5ayfsc'), Comment(id='k5ckr3a'), Comment(id='k5bj13d'), Comment(id='k5btv5a'), Comment(id='k5brlkb'), Comment(id='k5ax0ch'), Comment(id='k5dd6yt'), Comment(id='k5cf4lt'), Comment(id='k5cfgs9'), Comment(id='k5e7laj'), Comment(id='k5biawr'), Comment(id='k5by20s'), Comment(id='k5dbna8'), Comment(id='k5cjqmv'), Comment(id='k5dldc3'), Comment(id='k5e0ykj'), Comment(id='k5eeaeo')]"
17aveed,7sidedleaf,,2023-10-18 16:50:55+00:00,False,,False,False,True,False,/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,Question for Data Scientists in their day to day work,"How often do you guys use calculus and linear algebra for your work? I've heard that for data science, especially machine learning, that it's important to understand linear algebra and calculus, but how true is this statement? I've taken some stats and probability courses in college for my minor, but haven't taken anything past calc 1 or linear algebra. Are these must-haves for your day to day work?",datascience,https://www.reddit.com/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,16,0,0.36,"[Comment(id='k5fde3b'), Comment(id='k5g030m'), Comment(id='k5fj3j7'), Comment(id='k5i8fm9'), Comment(id='k5incff'), Comment(id='k5ff024'), Comment(id='k5hfrk3'), Comment(id='k5jacrp'), Comment(id='k5izk0z'), Comment(id='k5izlem'), Comment(id='k5g217j'), Comment(id='k5izmm4'), Comment(id='k5j01ki'), Comment(id='k5jzz0b'), Comment(id='k5j499m'), Comment(id='k5j57n0')]"
17amx3l,CanberraMogul,,2023-10-18 09:53:58+00:00,False,,False,False,True,False,/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,Graduate US/International Career Opportunities," I'm about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.

I'm currently exploring career opportunities in the US and other international locations. I'm curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!

Thank you in advance!",datascience,https://www.reddit.com/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,0,0,0.33,[]
179uwm2,Round_Inflation_2199,,2023-10-17 10:07:15+00:00,False,,False,False,True,False,/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,Moving to USA or Staying in UAE,"Hi Folks

I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).

Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.

I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.

Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  


&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,81,66,0.84,"[Comment(id='k58r154'), Comment(id='k58teyf'), Comment(id='k59jkm5'), Comment(id='k58vej0'), Comment(id='k5a4f3b'), Comment(id='k5918re'), Comment(id='k59a7s9'), Comment(id='k58wyo9'), Comment(id='k5a65ss'), Comment(id='k5a3y8y'), Comment(id='k5a3qij'), Comment(id='k5a94uw'), Comment(id='k59b6da'), Comment(id='k5a7o3e'), Comment(id='k59reqj'), Comment(id='k59nybo'), Comment(id='k5a0sje'), Comment(id='k5aiubf'), Comment(id='k5aq09r'), Comment(id='k5b3311'), Comment(id='k5bbrc7'), Comment(id='k5c6fhw'), Comment(id='k590v17'), Comment(id='k59ztv9'), Comment(id='k59sc0b'), Comment(id='k59axvn'), Comment(id='k590iz0'), Comment(id='k5bq1o8'), Comment(id='k5caunb'), Comment(id='k5auh0j'), Comment(id='k59snzd'), Comment(id='k5bbpau'), Comment(id='k5cbc3i'), Comment(id='k59p9dz'), Comment(id='k5a0ql6'), Comment(id='k5b5uqu'), Comment(id='k5b91qx'), Comment(id='k5b9xpj'), Comment(id='k5bfd93'), Comment(id='k5bucr4'), Comment(id='k5bx1n6'), Comment(id='k5c4zkj'), Comment(id='k5c6ubc'), Comment(id='k5c6we5'), Comment(id='k5crzs4'), Comment(id='k5czuww'), Comment(id='k5d7fu1'), Comment(id='k5ddxie'), Comment(id='k5hlbhg'), Comment(id='k5i8irh'), Comment(id='k5a7kje'), Comment(id='k5aiipp'), Comment(id='k5hmkb5'), Comment(id='k5a69ie'), Comment(id='k58ytqr'), Comment(id='k5ai0o6'), Comment(id='k5c8rvl'), Comment(id='k5a6s4g'), Comment(id='k5lt2ol'), Comment(id='k5akh9n'), Comment(id='k5d0ymw'), Comment(id='k5bc2gx'), Comment(id='k5aqbme'), Comment(id='k5c9oli'), Comment(id='k5a91t3'), Comment(id='k5d4gz7'), Comment(id='k5hm06v'), Comment(id='k5bx9lg'), Comment(id='k5bg2mr'), Comment(id='k5awsvv'), Comment(id='k5cavzf'), Comment(id='k5adiof'), Comment(id='k5c1gdj'), Comment(id='k5bjqgq'), Comment(id='k5azphd'), Comment(id='k5cb59j'), Comment(id='k5ae7ma'), Comment(id='k5d4l3f'), Comment(id='k5afsda'), Comment(id='k5ao8yx')]"
17ag1pr,DanRobin1r,,2023-10-18 02:37:46+00:00,False,,False,False,True,False,/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/,Anyone here that knows where to find scientific papers about regression models for Sports results?,,datascience,https://www.reddit.com/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/,1,3,1.0,[Comment(id='k5d5zrr')]
17alfw3,NFTHUNTERXX,,2023-10-18 08:09:16+00:00,False,,False,False,True,False,/r/datascience/comments/17alfw3/fuel_consumption/,Fuel consumption,"Hello everyone 

I hope you have an amazing day so far.

I want to create a model to predict/estimate furl consumption of ships for their voyages. I'm thinking to consider weight,wind speed, wind direction etc. Any suggestions of what model should I create?",datascience,https://www.reddit.com/r/datascience/comments/17alfw3/fuel_consumption/,3,0,0.33,"[Comment(id='k5dzhky'), Comment(id='k7slqdn'), Comment(id='k6dhuhc')]"
17al56s,redd-dev,,2023-10-18 07:48:41+00:00,False,,False,False,True,False,/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,What are some of the best library frameworks to use for speech2text and text2speech AI chatbot,"Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? 

I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?",datascience,https://www.reddit.com/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,0,1,1.0,[]
17ajf0e,IamFromNigeria,,2023-10-18 05:50:24+00:00,False,,False,False,True,False,/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,What's the best way to implement Shaq and Anchor (XAI) techniques,"Anyone done something on XAI where you use SHAP and Anchor model to explain your model?

I implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so",datascience,https://www.reddit.com/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,0,1,1.0,[]
17aaayg,SpecialEngineer7951,,2023-10-17 22:12:46+00:00,False,,False,False,False,False,/r/datascience/comments/17aaayg/we_built_an_opensource_platform_to_process/,We built An Open-Source platform to process relational and Graph Query simultaneously,,datascience,https://github.com/apache/age,4,4,1.0,"[Comment(id='k70ssox'), Comment(id='k5blg07'), Comment(id='k74828g'), Comment(id='k5blvse')]"
17a9bma,Administrative_Bar46,,2023-10-17 21:31:23+00:00,False,,False,False,True,False,/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,Moving to Big Tech from big government contractor,"Hello all,

 I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.

I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?",datascience,https://www.reddit.com/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,2,4,0.83,"[Comment(id='k5edslm'), Comment(id='k5eo4ir')]"
17ai9df,Rcpiv,,2023-10-18 04:37:37+00:00,False,,False,False,True,False,/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,What makes a good take home?,Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate’s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.,datascience,https://www.reddit.com/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,34,2,0.55,"[Comment(id='k5d2ezq'), Comment(id='k5f474x'), Comment(id='k5d545b'), Comment(id='k5dhxg4'), Comment(id='k5ehutr'), Comment(id='k5eapqx'), Comment(id='k5f6wlc'), Comment(id='k5dtx1t'), Comment(id='k5egcho'), Comment(id='k5di1rg'), Comment(id='k5ghzlb'), Comment(id='k5gx94p'), Comment(id='k5laxkb'), Comment(id='k5d4hxc'), Comment(id='k5l7pq1'), Comment(id='k5e838h'), Comment(id='k5f22la'), Comment(id='k5gsjqh'), Comment(id='k5ejqid'), Comment(id='k5dibtt'), Comment(id='k5ic5l5'), Comment(id='k5d4ojr'), Comment(id='k5lgquv'), Comment(id='k5ei3rq'), Comment(id='k5eajn6'), Comment(id='k5f4ws0'), Comment(id='k5epmy3'), Comment(id='k5e8xw7'), Comment(id='k5eiaev'), Comment(id='k5ecm7k'), Comment(id='k5egvcf'), Comment(id='k5f590m'), Comment(id='k5em7qb'), Comment(id='k5gwk2b'), Comment(id='k5gzz52')]"
17adx4s,spx416,,2023-10-18 00:56:21+00:00,False,,False,False,True,False,/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,Performance issues with dbscan,I’m looking to clustering on a dimensionally reduced dataset of 3D vectors. I’ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I’m looking for. I also tried using dbscan but I’ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I’d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.,datascience,https://www.reddit.com/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,6,1,1.0,"[Comment(id='k5co1b5'), Comment(id='k5e8wgh'), Comment(id='k5e91yq'), Comment(id='k6fmjaj'), Comment(id='k5eidq4'), Comment(id='k6fnnyy')]"
179ub5l,VGFenohmen,,2023-10-17 09:25:13+00:00,False,,False,False,True,False,/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,Predict maximum capacity of parking lots,"Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.

The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.

Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.

How would you recommend approaching this task?",datascience,https://www.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,36,15,0.78,"[Comment(id='k58p12q'), Comment(id='k592zrb'), Comment(id='k58sk7b'), Comment(id='k58nns5'), Comment(id='k59raol'), Comment(id='k59evw5'), Comment(id='k59lp3g'), Comment(id='k59mc5j'), Comment(id='k5adgep'), Comment(id='k58tjqk'), Comment(id='k5bisec'), Comment(id='k5dwa30'), Comment(id='k5adzj5'), Comment(id='k5apbhn'), Comment(id='k5alt5o'), Comment(id='k5atrvj'), Comment(id='k5ci6vm'), Comment(id='k58q4ue'), Comment(id='k58sn62'), Comment(id='k5d7vlz'), Comment(id='k5a9m0v'), Comment(id='k58t1wn'), Comment(id='k58ohj5'), Comment(id='k59gd3x'), Comment(id='k598ry3'), Comment(id='k58vfnm'), Comment(id='k58tqzg'), Comment(id='k5a1v7b'), Comment(id='k5amicq'), Comment(id='k5b1l9m'), Comment(id='k5cjcah'), Comment(id='k58qctu'), Comment(id='k5d5cqr'), Comment(id='k59xnzx'), Comment(id='k5awv7v'), Comment(id='k58szg3')]"
17a6t46,After_Reception1696,,2023-10-17 19:43:44+00:00,False,,False,False,True,False,/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,Seeking Advice on Machine Learning Algorithm Selection for Competitions," 

Hello, fellow data science enthusiasts! I'm participating in some machine learning competitions and I'm looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!

1. Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?
2. What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?
3. Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?

Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!""",datascience,https://www.reddit.com/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,1,2,1.0,[Comment(id='k5b0v02')]
17aba8j,glassAlloy,,2023-10-17 22:55:30+00:00,False,,False,False,True,False,/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals," 

Hey!

**Startup:**

\- Apply Script dot com ""Connect business and data professionals via pre-recorded standardized video interviews.""

**More details:**

**Problems with Traditional Hiring**

\- Outdated: The current method of conducting interviews has become overly complex and outdated.

\- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.

\- Expensive: The man-hours invested by HR and engineering teams are costly.

\- Constraining: Interviews are fixed to specific times and locations.

\- Cumbersome: The experience is challenging for both businesses and professionals.

**Our Solution**

\+ Talent Identification: We find top talent that matches your job post.

\+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.

\+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.

\+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.

\+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.

\+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.

\+ Transparency: Applicants receive immediate feedback on their applications to avoid being ""ghosted.""

**Life cycle stage:**

\- Validation: Currently looking to run our ***#1st pilot B2B*** with our first client.

**My role:**

\- Founder

**Goals for this month:**

\- Secure my first client for the pilot.

\- Obtain feedback from both the employee and business sides.

\- Optimize the product based on the feedback received.

**How can I** **help?**

\- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.

\- in the USA.

Thx for the feedback ;)",datascience,https://www.reddit.com/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,0,1,1.0,[]
179yve1,Whole-Ad-8370,,2023-10-17 13:52:45+00:00,False,,1697551029.0,False,True,False,/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,What does it mean to get a take-home assignment before screening call?,"This has happened to me twice now, dunno if it’s a new trend in recruitment processes. I’m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I’m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master’s in a computational quantitative field and so know the stats/theory behind most models).

 I didn’t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn’t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. 

Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it’s hard to find time to interview, which is the main reason I don’t want a super dragged out process)",datascience,https://www.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,6,4,0.7,"[Comment(id='k59cj2m'), Comment(id='k59ym10'), Comment(id='k59j8ee'), Comment(id='k5aidf8'), Comment(id='k5ctu9x'), Comment(id='k59dx9l')]"
17aatez,Medical-Author-8166,,2023-10-17 22:35:10+00:00,False,,False,False,True,False,/r/datascience/comments/17aatez/is_the_30th_percentile_of_a_standard_normal/,Is the 30th percentile of a standard normal distribution closer to one standard deviation below the mean or two standard deviations below the mean?,,datascience,https://www.reddit.com/r/datascience/comments/17aatez/is_the_30th_percentile_of_a_standard_normal/,3,0,0.43,"[Comment(id='k5bpgax'), Comment(id='k5brewz'), Comment(id='k5c4q1v')]"
179ebar,Expendable_0,,2023-10-16 19:25:33+00:00,False,,1697484790.0,False,True,False,/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,Why employers want experience over education,"**Creativity**: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn't be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, ""that is impossible."" How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give ""impossible"" tasks.

**Dirty Data**: I understand that provided or toy datasets can sometimes be dirty. They don't come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don't link to each other naturally, do regression tests because they don't update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.

**Being easy to work with**: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.

There are many others, but these are three big ones. If you don't have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won't be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.",datascience,https://www.reddit.com/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,79,146,0.85,"[Comment(id='k55ul4u'), Comment(id='k56qpim'), Comment(id='k55zthp'), Comment(id='k5678hg'), Comment(id='k5742tf'), Comment(id='k574ewi'), Comment(id='k57euj7'), Comment(id='k56uvhp'), Comment(id='k56bksh'), Comment(id='k56mb2l'), Comment(id='k573ffk'), Comment(id='k57s4m0'), Comment(id='k5bw5j5'), Comment(id='k5fhsg3'), Comment(id='k5kztrs'), Comment(id='k57fmia'), Comment(id='k57onbw'), Comment(id='k57v139'), Comment(id='k58rgcf'), Comment(id='k57ao25'), Comment(id='k56umhe'), Comment(id='k584dzh'), Comment(id='k56v1pp'), Comment(id='k583d95'), Comment(id='k56exxp'), Comment(id='k5776tc'), Comment(id='k58q76m'), Comment(id='k56zkzx'), Comment(id='k56egso'), Comment(id='k576lnh'), Comment(id='k56n0tb'), Comment(id='k581vbx'), Comment(id='k59uwi6'), Comment(id='k57tjxt'), Comment(id='k57i7aq'), Comment(id='k5bwsw0'), Comment(id='k58izzw'), Comment(id='k56xhgv'), Comment(id='k56md7j'), Comment(id='k577edu'), Comment(id='k58snz2'), Comment(id='k59i8pe'), Comment(id='k56eunj'), Comment(id='k56qc9x'), Comment(id='k57rsa9'), Comment(id='k56opl3'), Comment(id='k57wsyv'), Comment(id='k59r1ia'), Comment(id='k57sy9w'), Comment(id='k59x9hl'), Comment(id='k58ijxg'), Comment(id='k59sh6q'), Comment(id='k58t91n'), Comment(id='k56gnv7'), Comment(id='k577dx0'), Comment(id='k56s1fe'), Comment(id='k57s4ov'), Comment(id='k56pnq7'), Comment(id='k59qq67'), Comment(id='k580ot8'), Comment(id='k5a7oz9'), Comment(id='k5aedxv'), Comment(id='k58xy37'), Comment(id='k56jlg1'), Comment(id='k56i7pv'), Comment(id='k56naol'), Comment(id='k56t2s3'), Comment(id='k58cx31'), Comment(id='k56vlnv'), Comment(id='k59ebix'), Comment(id='k5bn7wb'), Comment(id='k593v2w'), Comment(id='k56m2pv'), Comment(id='k56ihz3'), Comment(id='k56ntwb'), Comment(id='k56tgy2'), Comment(id='k56vvie'), Comment(id='k59tddx'), Comment(id='k5ahvxe')]"
17aahht,Chadsmithbass,,2023-10-17 22:20:40+00:00,False,,False,False,True,False,/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,Anyone got interview call from Kodiak Robotics?,"Hey y'all, I have a 15 minute interview coming up with Kodiak.ai (Kodiak Robotics). Wondering what it's about. Any help is greatly appreciated!",datascience,https://www.reddit.com/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,3,1,0.67,"[Comment(id='k5q1kkt'), Comment(id='k74mk43'), Comment(id='k5qfefn'), Comment(id='k5qgc7b')]"
17a2wb4,brw12,,2023-10-17 16:54:00+00:00,False,,False,False,True,False,/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,"Q: How to extract learnings from my spreadsheets, beyond simple correlations?","**TL;DR:**

Below, I describe the info I'm tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don't. **My question is, does this algorithm already exist in some code library?** Or do I have to code it myself?

**Background:**

I've been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.

**Regression algorithm:**

I used to work at a data science company where we would run studies we called ""regression hill climbs"", where we would iterate like this:

1. identify the output factor (AKA ""dependent variable""); in this case, it would be energy level on a given day
2. for every input factor (AKA ""independent variable"", e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor
3. start with an empty ""model"", a set of independent variables
4. start with a correlation between model and dependent variable of 0
5. repeat until no more variables are selected to add to the model:
   1. filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) 
   2. of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model's variables (to best predict the dependent variable)
   3. select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)

This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). 

**Why it matters:**

For instance, if I have nights where I'm more disciplined overall -- say, when I don't drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there's a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.

Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it's very hard to isolate it as a factor; this algorithm helps.

**What I'm looking for:**

A code library -- presumably in python -- that is built to perform such a ""regression hill climb"", and allow for the various thresholds and other settings to be specified.

Does anyone know of such a library? Or, is there something different I should do, or some way I'm misunderstanding the problem?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,2,2,0.75,"[Comment(id='k5a4cor'), Comment(id='k5d175t')]"
179ztob,Cryptocheets,,2023-10-17 14:36:34+00:00,False,,False,False,True,False,/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,Should data-scientists look for their own datasets or be provided by the hiring company?,"Hi,   


We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   


Thank you",datascience,https://www.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,12,3,0.6,"[Comment(id='k59szy9'), Comment(id='k59ls8v'), Comment(id='k59jv1f'), Comment(id='k5aj2vy'), Comment(id='k59okme'), Comment(id='k5a2x90'), Comment(id='k5aaicw'), Comment(id='k5ak7yz'), Comment(id='k5a9rnf'), Comment(id='k5bpko3'), Comment(id='k5ddioo')]"
17a5u8t,ratatsnow,,2023-10-17 19:01:29+00:00,False,,False,False,True,False,/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,Time series data filtering - keep outliers and remove only flat trend,"I'm building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.

I thought about 2 solutions:

1. sample data for each product in a way that keeps 'outliers' in dataset (i.e. spikes for visibility and dips to get notified that maybe it's time to buy it). Not sure if it's easy 
2. get rid of data points for which data trends flat based on moving average

&#x200B;

Any better idea that is easy to implement?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,1,1,1.0,[Comment(id='k5bw7jz')]
17a5thj,TheOmerAngi,,2023-10-17 19:00:44+00:00,False,,False,False,True,False,/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,Does anyone have a good glossary for data science?,I'm looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It's mostly for myself to test my knowledge. Anything from regression types to p values and much more.,datascience,https://www.reddit.com/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,1,1,0.6,[Comment(id='k5b7w8c')]
17a5plc,KobeOrNotKobe,,2023-10-17 18:55:57+00:00,False,,False,False,True,False,/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,Live 2023 Election Results (Also Future Results),"Specifically for Kentucky but I'm trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this [comment](https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&utm_medium=web2x&context=3), but can't figure out what it would be for a single state's off off year election

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,0,0,0.5,[]
179z4yq,niksteel123,,2023-10-17 14:05:00+00:00,False,,False,False,True,False,/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,Shared Public Contextual Database for RAG,"Hey Guys,  
It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   


Do you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  


\-  


For context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. ",datascience,https://www.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,1,2,1.0,[]
179945p,MikeyCyrus,,2023-10-16 15:47:51+00:00,False,,False,False,True,False,/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,How many companies actually have a clear plan for their data?,"I have been working as a ""data scientist"" in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with ""data scientist"" titles in the whole org but they are in a separate silo from me. 

Generally I am tossed tasks that don't make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like ""build us a chatbot"". I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  

Now they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can't imagine that project was less than a few million as well. 

In all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don't even realize the consultants will likely build a very similar model to SAP. 

Are most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I've worked here. It seems like they have no vision or clue what they are doing.",datascience,https://www.reddit.com/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,48,112,0.95,"[Comment(id='k54pytz'), Comment(id='k55pbnt'), Comment(id='k54u7ze'), Comment(id='k54vmla'), Comment(id='k55em9x'), Comment(id='k54z0d5'), Comment(id='k5655yb'), Comment(id='k55nwva'), Comment(id='k56w5sq'), Comment(id='k55w2dy'), Comment(id='k55gbhg'), Comment(id='k56ozy9'), Comment(id='k58puwe'), Comment(id='k5faelc'), Comment(id='k55nxex'), Comment(id='k54v7l8'), Comment(id='k564zrz'), Comment(id='k569uvu'), Comment(id='k56a4b7'), Comment(id='k57obqm'), Comment(id='k5lz1gl'), Comment(id='k55gyq7'), Comment(id='k56anqb'), Comment(id='k56uz15'), Comment(id='k56xl5z'), Comment(id='k582eat'), Comment(id='k56o4kk'), Comment(id='k55oudm'), Comment(id='k56asyg'), Comment(id='k57avlx'), Comment(id='k5fds4y'), Comment(id='k56aya6'), Comment(id='k55hbhz'), Comment(id='k560dz2'), Comment(id='k57ansd'), Comment(id='k56zcyt'), Comment(id='k57doxf'), Comment(id='k56x5lx'), Comment(id='k579wft'), Comment(id='k5axitk'), Comment(id='k5fj98e'), Comment(id='k58ax9a'), Comment(id='k57dlm5'), Comment(id='k572nc7'), Comment(id='k59a8i5'), Comment(id='k573gzc'), Comment(id='k57e0a6'), Comment(id='k57k8q2')]"
179ykfd,growth_man,,2023-10-17 13:38:01+00:00,False,,False,False,False,False,/r/datascience/comments/179ykfd/how_to_build_data_products_deploy_part_34/,How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences,,datascience,https://moderndata101.substack.com/p/how-to-build-data-products-deploy,0,2,1.0,[]
17a25ns,forgotendream,,2023-10-17 16:20:55+00:00,False,,False,False,True,False,/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,How good are the Linkedin Learning Paths?,"Hi all,

&#x200B;

I have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.   
Has anyone tried them or what do you guys think of them?  
I saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.

&#x200B;

Is it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.

&#x200B;

Appreciate the input or help.",datascience,https://www.reddit.com/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,3,1,0.6,"[Comment(id='k5a21pm'), Comment(id='k5bfhkw'), Comment(id='k5d1us6')]"
179r5li,dec_dev,,2023-10-17 05:36:36+00:00,False,,False,False,True,False,/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,Repetitive airflow pipeline problems,"Hi r/datascience,

From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,0,5,0.86,[]
179etbr,Relative_Practice_93,,2023-10-16 19:46:15+00:00,False,,1697514908.0,False,True,False,/r/datascience/comments/179etbr/regretting_data_science/,Regretting Data Science,"I was wondering if there are other people out there who regret choosing data science as a career path.

For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.

I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).

In the fall of the 2nd year of my Master's I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I'm stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.

I can't really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I'm personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. 

Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don't know if every job feels like this and I have to suck it up, or if I should just leave. I've only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.

I'd love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I'm having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.",datascience,https://www.reddit.com/r/datascience/comments/179etbr/regretting_data_science/,28,25,0.84,"[Comment(id='k55z708'), Comment(id='k55slcj'), Comment(id='k56bu63'), Comment(id='k5634vg'), Comment(id='k57hrut'), Comment(id='k56ij4d'), Comment(id='k56ejih'), Comment(id='k57n7z6'), Comment(id='k56u2fd'), Comment(id='k56765a'), Comment(id='k5c1moq'), Comment(id='k57hzsx'), Comment(id='k55srkw'), Comment(id='k57ndc6'), Comment(id='k56jvg0'), Comment(id='k59orrs'), Comment(id='k57xg9u'), Comment(id='k59cnta'), Comment(id='k57x7d8'), Comment(id='k583v5b'), Comment(id='k55sxn0'), Comment(id='k57vkx6'), Comment(id='k57trds'), Comment(id='k57nr21'), Comment(id='k580p5t'), Comment(id='k57x9c5'), Comment(id='k58mdvv'), Comment(id='k59ib8d')]"
179u12d,CursorInsight,,2023-10-17 09:04:31+00:00,False,,False,False,True,False,/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values,"Hey fellow Redditors!

Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!

In this discussion, we delve into the concept of ""features"" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.

# 💡 What's a Feature?  

In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.

 The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. 

# 📊 Analyzing the appropriate time series

The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. 

**Unmasking forgery through speed analysis**

Let’s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**

Now, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won’t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature’s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**

Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.

Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.

In theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**

From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.

# 🔍 Describing Time Series with Scalar Values 

 We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.

Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.

To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.

Two lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.

In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.

On the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.

These are the basic features we utilize for analysis.

Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! 💬🕺🏽💻",datascience,https://www.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,0,2,1.0,[]
1799oao,shayanjm,,2023-10-16 16:11:12+00:00,False,,False,True,True,False,/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,Decoding LLM Uncertainties for Better Predictability,"Hi all,

Building off our last research post, we wanted to figure out ways to quantify ""ambiguity"" and ""uncertainty"" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: ""Structural"" and ""Conceptual"" uncertainty.

In a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.

You can play around with this yourself in the [demo](https://uncertainty.demos.watchful.io/) or read about it in more detail in the [blog post](https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability)",datascience,https://www.reddit.com/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,1,13,0.77,[Comment(id='k573zg0')]
179kwrd,throwaWayne2,,2023-10-17 00:07:44+00:00,False,,False,False,True,False,/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?,"My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.

 Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.

I really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.
How should I approach this? Anything in particular I should show?

I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)",datascience,https://www.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,7,2,0.56,"[Comment(id='k57b452'), Comment(id='k57xjdz'), Comment(id='k56z5ep'), Comment(id='k58g6zw'), Comment(id='k5743ep'), Comment(id='k59oikb'), Comment(id='k59qwb1'), Comment(id='k5799g3')]"
179q91p,SaxTeacher1988,,2023-10-17 04:40:44+00:00,False,,False,False,True,False,/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,Cruise Ship Musicians Scheduling,"I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!",datascience,https://www.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,12,1,0.67,"[Comment(id='k57y1k4'), Comment(id='k57x84l'), Comment(id='k58cd0f'), Comment(id='k5b9l06'), Comment(id='k5ba6h5'), Comment(id='k5b9enm'), Comment(id='k5broj7'), Comment(id='k5bbgq6'), Comment(id='k5cmqn8'), Comment(id='k5caegf'), Comment(id='k5cnh0y'), Comment(id='k5cm7zd')]"
17941v2,Illustrious-Class-65,,2023-10-16 11:44:31+00:00,False,,False,False,True,False,/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,What would be a good curriculum for a data scientist to learn about forecasting?,"Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!",datascience,https://www.reddit.com/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,9,16,0.9,"[Comment(id='k543p01'), Comment(id='k545dg5'), Comment(id='k5dck0c'), Comment(id='k548awu'), Comment(id='k5489aa'), Comment(id='k589w6q'), Comment(id='k59r1sj'), Comment(id='k54l13b')]"
178vvrk,n96j77,,2023-10-16 02:40:43+00:00,False,,False,False,True,False,/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,Identity Crisis in Data Science,"Anyone else confused where they fit in data science? There's a huge range of backgrounds, from bootcamps to Ph.D.s. I've found DS quite unwelcoming because of this. Everyone is trying to distinguish themselves from the ""fakers,"" while most companies needs are quite basic.

I've been working on a DS master's degree for a year. I certainly know more than the typical data analyst or self-taught MOOCs student, but I'm overwhelmed by the interdisciplinary nature of the field. I've invested countless hours and thousands of dollars, yet there's a lifetime more to learn. This makes me question whether I want to continue in the field. When I talk to computer scientists, they're all very encouraging and emphasize that, although difficult, everyone can learn to code. When I talk to other data scientists, I get an air of elitism.

I think this happens because data science is a relatively new field. Other specialized skills like accounting, law, or finance have had time to settle into a list of requirements and utilize certifications where necessary. Since we have one title to describe a huge population, people end up getting defensive so they're not grouped together with the less qualified. Maybe overtime this resolves itself as data science expands into more titles. For now, I feel caught between both sides of the argument. I have no desire to get a PhD and a lot of imposter syndrome. It leaves me feeling like I should have gone MBA -> product management and called it a day.  On the flip side, when I explain basic stats at work, I'm met with blank stares, leading me to think the push for Ph.Ds is more about ego than practicality. My hope is to see clearer distinction in titles and more encouragement in the field than discouragement. 

For those of you in the middle like me, where have y'all had success? What kinds of industries, companies, or roles do you target?",datascience,https://www.reddit.com/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,32,72,0.86,"[Comment(id='k52p0qj'), Comment(id='k53l1pu'), Comment(id='k53lm74'), Comment(id='k54qax6'), Comment(id='k5594oy'), Comment(id='k54rqgu'), Comment(id='k54wsd5'), Comment(id='k5461uf'), Comment(id='k55lzwh'), Comment(id='k59by9v'), Comment(id='k549gfa'), Comment(id='k590k9d'), Comment(id='k542yms'), Comment(id='k589tat'), Comment(id='k5g3igx'), Comment(id='k5mt8ly'), Comment(id='k542h18'), Comment(id='k53gzln'), Comment(id='k59e3rq'), Comment(id='k53kgv0'), Comment(id='k54548e'), Comment(id='k54r4rb'), Comment(id='k59ewdq'), Comment(id='k58ak4s'), Comment(id='k55gnam'), Comment(id='k58b6k4'), Comment(id='k5actod'), Comment(id='k54td1a'), Comment(id='k59j6gh'), Comment(id='k545jhj'), Comment(id='k58qb15'), Comment(id='k59do90'), Comment(id='k59bi3s')]"
1796r3n,dmalyugina,,2023-10-16 14:04:58+00:00,False,,False,False,True,False,/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,Free Open-source ML observability course: starts today 🚀,"Hi everyone, I’m one of the people who work on [Evidently](https://github.com/evidentlyai/evidently), an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.

We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.

💻 Code examples and end-to-end deployment blueprints.  
✅ Open-source focused. You’ll work with tools like Evidently, MLflow, Airflow, and Grafana.  
❤️ Free and open to everyone.  
🗓 You can join the cohort that starts on October 16, 2023, or learn at your own pace.

Course info and notes: [https://learn.evidentlyai.com/](https://learn.evidentlyai.com/)

Hope you’ll find the course useful!",datascience,https://www.reddit.com/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,0,5,0.78,[]
179q60m,Awkward-Block-5005,,2023-10-17 04:35:30+00:00,False,,False,False,True,False,/r/datascience/comments/179q60m/time_series_forcasting/,Time series forcasting,"Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.
As we can plot univariate time series on plot and train GaN's to complete that plot.

Not so much work is in going on this feild.
Why ?",datascience,https://www.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/,6,0,0.2,"[Comment(id='k5898bl'), Comment(id='k59p7gc'), Comment(id='k58dum0'), Comment(id='k589gpc'), Comment(id='k59pqzs'), Comment(id='k59rckb')]"
1792cy2,IGetToSkrtWhenIWant,,2023-10-16 09:54:40+00:00,False,,False,False,True,False,/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,"Hitting a bottleneck (500+ applications over the past half year with barely any interviews at all). Any advice on job searching, applications, or even transitioning from another field?","I've been job searching for awhile now, and while I understand that the job market in general is rough right now, I have to imagine that struggling to even get initial interviews means that I'm doing something wrong. 

For context, I'm pretty much graduated with a BA in Economics at Boston University. I have some part-time and internship experience: about half a year of working the front desk of a small hotel (I have not put this on my resume since I worked the job for side money, not for work experience), a few months as a Sales Representative, a few months as a Dispute Resolution Analyst for the Better Business Bureau, and a few other internship experiences during my high school years. Obviously, none of my work experience is related to working with data or analysis, other than some of my Economics coursework, completing the Google Data Analytics certificate, and a guided project with Python (NumPy, Pandas, Seaborn) in Exploratory Data Analysis on Coursera. In any case, I know that my work experience is pretty weak/nonexistent and I've been struggling to even get an initial interview for entry-level/no-experience-required roles. So what can I do in terms of job searching/applications? Should I focus more on my resume/work experience by completing my own projects that demonstrate self-taught skills (Excel, SQL, Python, etc.)? Or should I give up on trying to apply for data/analyst roles and instead try to transition in through a different field like Marketing, Consulting, etc? Any and all feedback that can help me get past this current bottleneck would be greatly appreciated!",datascience,https://www.reddit.com/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,12,10,0.92,"[Comment(id='k58461w'), Comment(id='k586e4o'), Comment(id='k5cjycy'), Comment(id='k56y69t'), Comment(id='k554l2l'), Comment(id='k53uao1'), Comment(id='k58fmuo'), Comment(id='k58erfq'), Comment(id='k581hru'), Comment(id='k569ggu'), Comment(id='k5aqfcr'), Comment(id='k58e0va')]"
1792wrc,pg860,,2023-10-16 10:31:22+00:00,False,,False,False,True,False,/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,Popularity of Data Visualization tools mentioned in data-science/ml job descriptions," Source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)

About the dataset: 9,261 jobs crawled from 1605 companies worldwide in June-Sep 2023

https://preview.redd.it/dympbqa3ljub1.png?width=2560&format=png&auto=webp&s=e5db457072a89a08528d73fe0c064adc45372dea",datascience,https://www.reddit.com/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,2,6,0.69,"[Comment(id='k5hg99k'), Comment(id='k5ijqx7')]"
178wh2z,Much-Focus-1408,,2023-10-16 03:12:54+00:00,False,,False,False,True,False,/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,What are the best sites to review DS topics/study for interviews?,"It’s been a while and all I really do in my job is NLP and googling. I haven’t used SQL, stats, etc.. in such a long time. I’ve looked at leetcode and interviewquery, but there’s a lot out there.

What would you recommend using? Thanks!",datascience,https://www.reddit.com/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,13,24,0.9,"[Comment(id='k52tf24'), Comment(id='k52zdh0'), Comment(id='k53ji8o'), Comment(id='k53j7hg'), Comment(id='k53l94u'), Comment(id='k53sb3i'), Comment(id='k53ysoo'), Comment(id='k5dcqyz'), Comment(id='k52w471'), Comment(id='k52zzjb'), Comment(id='k53j9tl'), Comment(id='k54rpbl'), Comment(id='k54piao')]"
178r037,daufoi21,,2023-10-15 22:32:40+00:00,False,,False,False,True,False,/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,Not getting noticed for data science jobs,"I've been a data scientist with 3 (almost 4) years experience and a Masters. Is there somewhere you guys go to get your resume critiqued or improved? I've tried sending it to a career counselor and she thought it was good. Also, I met someone who works in the industry through a career fair, and he said it is ""impressive"". Nevertheless, I apply to job after job, only to get rejection emails. After 4 months, I've had one interview and that was through a referral. Even the hiring manager said the resume looks good for the job (before interview). This happens even if I tailor my resume, apply to jobs that I feel I'm highly qualified, and am early in applying (within a week of job posting). I feel like I'm wasting time, and this is just the first step. Interviewing is going to be another battle, and at this rate I will never find something!",datascience,https://www.reddit.com/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,37,54,0.86,"[Comment(id='k51hkkl'), Comment(id='k528lfo'), Comment(id='k527x1e'), Comment(id='k52574k'), Comment(id='k536c6w'), Comment(id='k53zfdt'), Comment(id='k54icil'), Comment(id='k53r36q'), Comment(id='k51yhrj'), Comment(id='k52sqv3'), Comment(id='k53npqj'), Comment(id='k55a3ti'), Comment(id='k5nger7'), Comment(id='k53w0dg'), Comment(id='k51jb7z'), Comment(id='k58a1g1'), Comment(id='k6ncpjk'), Comment(id='k53ok7w'), Comment(id='k56z71n'), Comment(id='k54h4ki'), Comment(id='k54ctq1'), Comment(id='k55pgtd'), Comment(id='k55b0gm'), Comment(id='k56cubz'), Comment(id='k55pjcy'), Comment(id='k53497p'), Comment(id='k54ws8d'), Comment(id='k561fyd'), Comment(id='k55gump'), Comment(id='k575koo'), Comment(id='k582dza'), Comment(id='k568qn3'), Comment(id='k564dcq'), Comment(id='k55yvh6'), Comment(id='k577i30'), Comment(id='k56aic4'), Comment(id='k5ccmno')]"
178juum,Puzzled_Implement_78,,2023-10-15 17:05:01+00:00,False,,False,False,True,False,/r/datascience/comments/178juum/do_you_folks_leetcode/,Do you folks Leetcode?,"I come from more of a engineering(non-software) background and never learned Data Structures and Algorithms. I want to start applying for jobs next year(3 YOE), how often are you asked Leetcode questions in interviews? I'm trying to figure out a plan of action to get prepared.",datascience,https://www.reddit.com/r/datascience/comments/178juum/do_you_folks_leetcode/,76,114,0.96,"[Comment(id='k50j355'), Comment(id='k51ekpu'), Comment(id='k50hpqz'), Comment(id='k50jjtx'), Comment(id='k50ypt9'), Comment(id='k50irx5'), Comment(id='k521mv8'), Comment(id='k5192e5'), Comment(id='k513mfb'), Comment(id='k50xfdi'), Comment(id='k503689'), Comment(id='k51w3al'), Comment(id='k52dzem'), Comment(id='k50r3fn'), Comment(id='k50c7um'), Comment(id='k51ipgj'), Comment(id='k50nc5f'), Comment(id='k5183ou'), Comment(id='k51cjh6'), Comment(id='k51ioi9'), Comment(id='k52o3q5'), Comment(id='k51dklu'), Comment(id='k51de20'), Comment(id='k52pkpg'), Comment(id='k52qkml'), Comment(id='k532pv2'), Comment(id='k532zea'), Comment(id='k542ews'), Comment(id='k549lat'), Comment(id='k54btso'), Comment(id='k54cqtu'), Comment(id='k54xcrh'), Comment(id='k55egot'), Comment(id='k55uzwa'), Comment(id='k56dnat'), Comment(id='k50w4ei'), Comment(id='k50n3t2'), Comment(id='k531n3l'), Comment(id='k52uyhy'), Comment(id='k51kxps'), Comment(id='k51qycz'), Comment(id='k51o8zs'), Comment(id='k5365mb'), Comment(id='k50xwfe'), Comment(id='k51m7ez'), Comment(id='k53hsv2'), Comment(id='k5350d2'), Comment(id='k52zyuk'), Comment(id='k50tvwv'), Comment(id='k535hg0'), Comment(id='k56wpyi'), Comment(id='k52v1bg'), Comment(id='k52xm4k'), Comment(id='k51y10k'), Comment(id='k51xtoi'), Comment(id='k53l8al'), Comment(id='k51ptvd'), Comment(id='k528xpm'), Comment(id='k52qmmm'), Comment(id='k51f06u'), Comment(id='k7mvoqx'), Comment(id='k54l5px'), Comment(id='k57slch'), Comment(id='k52vrdr'), Comment(id='k52o3f4'), Comment(id='k52onpk'), Comment(id='k529lpg'), Comment(id='k52954i'), Comment(id='k7mvgr9'), Comment(id='k5535ww'), Comment(id='k55o765'), Comment(id='k5502gg'), Comment(id='k52x2h0'), Comment(id='k55fc6e'), Comment(id='k532m0o'), Comment(id='k5357b5')]"
178fhbg,BladeClickerQQ,,2023-10-15 13:34:34+00:00,False,,1697725332.0,False,True,False,/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,Will being data analyst in casino resort ruin my career?,"Updated:

Thank you so much for all the suggestions and comments! The community is so supportive and enthusiastic. I read every comments very carefully, probably more than one time for most, and they are very insightful and play a vital role in my decision making, whether thumbs up or down.

I have been thinking about this almost every minutes in the past few days. In the end, I decided to take this offer. For me this decision is very complicated. Actually I am not sure how long I will stay, but it's always important to make my first step.

Thank you again for all the comments! 

\--------------------------------------------------------------------

As a new graduate recently I am getting a data analyst offer from a casino resort. It's a hard time for new grad and after two times of withdrawals of my offers, this is the only one I have in my hands. The job duty is about analyzing campaign performance, analyzing customer patterns, and forecasting business trends.  They are also working on breaking data silos utilizing cloud service so ETL jobs should also be expected.

Overall the project sounds pretty attractive to me. My only concern is the business itself. One of my friends (not in US) gave me a strong suggestion that don't easily go into this industry. He was working in an operation role for company building mobile casinos, and the business logic was so different from other industries that it's hard to get out of this. Many people have a bias toward this career so he had a hard time changing jobs.

I am scared, to be honest. But I am not sure to what extent his thoughts work in my scenario. Casino Resort still looks much different from mobile casinos and his role was not data analyst. I wonder how you guys think about this.  Should I take this offer?",datascience,https://www.reddit.com/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,131,211,0.88,"[Comment(id='k4z5ti7'), Comment(id='k4z957p'), Comment(id='k4zhffy'), Comment(id='k4zeekt'), Comment(id='k4zgppa'), Comment(id='k4zghgl'), Comment(id='k4zi4pa'), Comment(id='k50wdu6'), Comment(id='k4zqdyj'), Comment(id='k4zf7e0'), Comment(id='k4zovsj'), Comment(id='k527kqs'), Comment(id='k4zkr14'), Comment(id='k4zmnxn'), Comment(id='k4znqoh'), Comment(id='k4zqgqp'), Comment(id='k4zrcrd'), Comment(id='k4zsvw4'), Comment(id='k50k8uk'), Comment(id='k50u523'), Comment(id='k4zge9z'), Comment(id='k4zx83e'), Comment(id='k50hbz9'), Comment(id='k50w662'), Comment(id='k53xwjk'), Comment(id='k542856'), Comment(id='k4zmxwi'), Comment(id='k51a3gs'), Comment(id='k507rbn'), Comment(id='k4zrtx2'), Comment(id='k4zrxe8'), Comment(id='k4zt5d2'), Comment(id='k4zwyb1'), Comment(id='k4zyf8m'), Comment(id='k4zyjbq'), Comment(id='k504g4j'), Comment(id='k505keg'), Comment(id='k50cg4y'), Comment(id='k50evfx'), Comment(id='k50i329'), Comment(id='k50ouuv'), Comment(id='k50p46l'), Comment(id='k50sz3s'), Comment(id='k5101qa'), Comment(id='k514r73'), Comment(id='k519r38'), Comment(id='k51bf68'), Comment(id='k51bfl9'), Comment(id='k51is78'), Comment(id='k51sain'), Comment(id='k51whpj'), Comment(id='k51xwjl'), Comment(id='k5228ok'), Comment(id='k5234a5'), Comment(id='k52b4en'), Comment(id='k52lk8s'), Comment(id='k5308a2'), Comment(id='k53d376'), Comment(id='k53hfz4'), Comment(id='k53m7yz'), Comment(id='k53tdpc'), Comment(id='k54l5kg'), Comment(id='k54q6el'), Comment(id='k54z23j'), Comment(id='k54za1x'), Comment(id='k556fwa'), Comment(id='k56n1ht'), Comment(id='k56sh1u'), Comment(id='k56xqrm'), Comment(id='k5d13tp'), Comment(id='k50dck9'), Comment(id='k4zekq3'), Comment(id='k4zixm3'), Comment(id='k50j1xh'), Comment(id='k505bm4'), Comment(id='k50pvok'), Comment(id='k51iw08'), Comment(id='k51ie7m'), Comment(id='k4zryn4'), Comment(id='k4zut0c'), Comment(id='k4zmurq'), Comment(id='k50werh'), Comment(id='k531j3s'), Comment(id='k50z3um'), Comment(id='k50bdjb'), Comment(id='k5jsdj0'), Comment(id='k51h1fq'), Comment(id='k51issk'), Comment(id='k50p0b6'), Comment(id='k52n0qu'), Comment(id='k51bmoy'), Comment(id='k51n706'), Comment(id='k550t2u'), Comment(id='k51ivoz'), Comment(id='k530eb0'), Comment(id='k508m8t'), Comment(id='k4zvaju'), Comment(id='k5133bj'), Comment(id='k508bd9'), Comment(id='k508flk'), Comment(id='k51btqs'), Comment(id='k54zh01'), Comment(id='k51020p'), Comment(id='k51dvis'), Comment(id='k551f15'), Comment(id='k5jxqqq'), Comment(id='k52r9ar'), Comment(id='k5284ne'), Comment(id='k51jvkz'), Comment(id='k52f3b2'), Comment(id='k542eu7'), Comment(id='k52as6d'), Comment(id='k51xmlg'), Comment(id='k51jegv'), Comment(id='k544j0n'), Comment(id='k52bsn2'), Comment(id='k50lmws'), Comment(id='k512k3o'), Comment(id='k55slgg'), Comment(id='k53yb2h'), Comment(id='k52i4n1'), Comment(id='k52ptd8'), Comment(id='k52c3ws'), Comment(id='k51r6i7'), Comment(id='k50t00c'), Comment(id='k512rvt'), Comment(id='k57418s'), Comment(id='k540at0'), Comment(id='k53rgb6'), Comment(id='k51sstx'), Comment(id='k55h6jq'), Comment(id='k5casuq')]"
1796piu,benjaminwootton81,,2023-10-16 14:02:59+00:00,False,,False,False,False,False,/r/datascience/comments/1796piu/forecasting_using_clickhouse_machine_learning/,Forecasting Using Clickhouse Machine Learning Functions,,datascience,https://ensembleanalytics.io/blog/forecasting-using-clickhouse,0,2,1.0,[]
178ztsj,Green_Ad6024,,2023-10-16 06:48:45+00:00,False,,False,False,True,False,/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,Which Model is best for Word Embedding?,"Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. Thank you for your guidance. ",datascience,https://www.reddit.com/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,1,7,1.0,[Comment(id='k53n40z')]
178erav,ah-know-knee-mousse,,2023-10-15 12:54:11+00:00,False,,False,False,False,False,/r/datascience/comments/178erav/is_this_normal_qualification/,Is this normal qualification?,,datascience,https://i.redd.it/ek2tuv1p5dub1.jpg,56,154,0.9,"[Comment(id='k4z02zu'), Comment(id='k4z2vji'), Comment(id='k4zc9wv'), Comment(id='k4yzhcy'), Comment(id='k503n9k'), Comment(id='k4z1wjf'), Comment(id='k4zmp9v'), Comment(id='k50jlf2'), Comment(id='k4zzkax'), Comment(id='k513qy6'), Comment(id='k51sho5'), Comment(id='k52s0eg'), Comment(id='k5345h7'), Comment(id='k4zn02i'), Comment(id='k504lm9'), Comment(id='k4zkyst'), Comment(id='k50zfw5'), Comment(id='k51ib88'), Comment(id='k50tjtp'), Comment(id='k51htfk'), Comment(id='k522r3i'), Comment(id='k52mtmu'), Comment(id='k53mqd4'), Comment(id='k52eyj2'), Comment(id='k54brge'), Comment(id='k54x02e'), Comment(id='k58db1w'), Comment(id='k5ce3iq'), Comment(id='k4z82cv'), Comment(id='k4z1vsm'), Comment(id='k52o62v'), Comment(id='k4z8c4t'), Comment(id='k53npt5'), Comment(id='k53ql6f'), Comment(id='k4z5xlf'), Comment(id='k4zyitp'), Comment(id='k50tkjf'), Comment(id='k52o9fi'), Comment(id='k50uss4'), Comment(id='k52od19'), Comment(id='k51b6w7'), Comment(id='k53074n'), Comment(id='k53oc3t'), Comment(id='k53o0yu'), Comment(id='k4z98ii'), Comment(id='k4z2n0t'), Comment(id='k4zzoy5'), Comment(id='k4zakda'), Comment(id='k52kw5y'), Comment(id='k51d8n6'), Comment(id='k514urm'), Comment(id='k543y29'), Comment(id='k5405de'), Comment(id='k540wty'), Comment(id='k5419nj')]"
1794e1d,Hasneverbeenhere,,2023-10-16 12:04:03+00:00,False,,False,False,True,False,/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/,"When using bagging or boosting to combine decision trees, which algorithm takes more time to train?",,datascience,https://www.reddit.com/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/,2,1,0.57,"[Comment(id='k53twcw'), Comment(id='k53vxb1')]"
1791y53,getoutofmybus,,2023-10-16 09:25:22+00:00,False,,False,False,True,False,/r/datascience/comments/1791y53/ml_engineering_courses_certs/,ML Engineering Courses/ Certs,"I'm an MSc graduate with some DS experience and I'm looking to move to a ML Engineering role. Are there any courses you would recommend? My Masters was in applied math and my UG was in mathematics, so I have the maths and stats, and have done a lot of work with neural nets and PyTorch. ",datascience,https://www.reddit.com/r/datascience/comments/1791y53/ml_engineering_courses_certs/,2,3,1.0,"[Comment(id='k574y1b'), Comment(id='k57or75')]"
1798de7,G4L1C,,2023-10-16 15:15:58+00:00,False,,False,False,True,False,/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,[Applied Data Science in Marketing] How to measure marginal returns and elasticity of marketing campaigns,"Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:

\- The law of diminishing returns

\- ROAS and Marginal ROAS

\- Advertisement elasticity on Returns

Hope that it is useful for everybody. Any feedback is welcome.

[https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html](https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html)",datascience,https://www.reddit.com/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,0,1,1.0,[]
178yk7k,siliconBoy69,,2023-10-16 05:19:46+00:00,False,,False,False,True,False,/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,Is my idea worth pursuing ?,"I'm a software engineer, while building AI side projects I noticed that it takes a while to setup the MLOPs and cloud infra for deploying and building models so, I'm creating a low-code platform for finetuning and deploying ai models (B2B mostly). do you guys think there is a market for this product ?",datascience,https://www.reddit.com/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,5,4,0.75,"[Comment(id='k52zamo'), Comment(id='k53lyar'), Comment(id='k530l09'), Comment(id='k5358xo'), Comment(id='k53q27s')]"
17932k1,Individual-School-07,,2023-10-16 10:42:35+00:00,False,,False,False,True,False,/r/datascience/comments/17932k1/data_science_protfolio/,Data Science Protfolio,"Hello everyone,

I'm a former data science student who started to work in IT audit but decided to go back to DS.  I am rebuilding my portfolio with new projects. Any great project ideas ?   
Here are some projects i think about, please don't hesitate to give your opinion on which to choose :   


* Credit Card attrition.
* Black&white video/ picture coloring and improving.
* License plate recognition
* Facebook Friend Recommendation
* Quora Question Pair Similarity
* Credit scoring improvement
* Disease Outbreak Prediction
* Product Recommendation system
* Housing Price Predictor
* Sentiment Analysis
* Stock Price Forecasting
* Flight Delay Prediction
* Fire Outbreak Prediction
* Game Outcome Prediction
* Object Detection in Videos
* Influencer Detection

Thank you in advance for your response.

P.S : If anyone has great mentorship platforms or any other way of mentorship please don't hesitate.",datascience,https://www.reddit.com/r/datascience/comments/17932k1/data_science_protfolio/,3,2,0.75,"[Comment(id='k5ar3h5'), Comment(id='k6a3xnu'), Comment(id='k6hui5o')]"
178ifs7,kafka399,,2023-10-15 15:58:48+00:00,False,,False,False,True,False,/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,Causal inference as a blind spot of data scientists,"Do you use Causal Inference as a data scientist? I wrote an article to reflect why it took so long for data scientists to discover Causal Inference and and tried to give an inspirational overview (just look at the images). 

[http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/](http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/)",datascience,https://www.reddit.com/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,61,65,0.88,"[Comment(id='k4zqstn'), Comment(id='k4zr6uu'), Comment(id='k4zut2b'), Comment(id='k52t43f'), Comment(id='k53fieb'), Comment(id='k512j4z'), Comment(id='k50jboe'), Comment(id='k524dk7'), Comment(id='k52qtxx'), Comment(id='k52bto3'), Comment(id='k52xh9p'), Comment(id='k52ylo1'), Comment(id='k577slc'), Comment(id='k5342qc'), Comment(id='k53eqhl'), Comment(id='k54pri9'), Comment(id='k6uzot0'), Comment(id='k50bvht'), Comment(id='k5287ve'), Comment(id='k512mr9'), Comment(id='k5111qz'), Comment(id='k50j6lg'), Comment(id='k514dtj'), Comment(id='k53mrni'), Comment(id='k4zvhk1'), Comment(id='k50cj5x'), Comment(id='k51xlfx'), Comment(id='k53o2tr'), Comment(id='k53111v'), Comment(id='k5916lw'), Comment(id='k55dujt'), Comment(id='k52kl9m'), Comment(id='k53c86g'), Comment(id='k50k6oj'), Comment(id='k50qaqr'), Comment(id='k55xueo'), Comment(id='k526002'), Comment(id='k507fwh'), Comment(id='k51pgzx'), Comment(id='k52cv0e'), Comment(id='k52cbz8'), Comment(id='k521wdg'), Comment(id='k50o2sb'), Comment(id='k512a1j'), Comment(id='k55yhgn'), Comment(id='k50hlv1'), Comment(id='k52dbyu'), Comment(id='k524ba6'), Comment(id='k51beju'), Comment(id='k5686ne'), Comment(id='k50ktf4'), Comment(id='k524w2o'), Comment(id='k53jdgz'), Comment(id='k56g5mj'), Comment(id='k50q9wk'), Comment(id='k53fshx'), Comment(id='k56nwy0'), Comment(id='k50rqf7'), Comment(id='k53j99e'), Comment(id='k56p9vb'), Comment(id='k50sbse'), Comment(id='k56ppra'), Comment(id='k5btvcn')]"
1796r9j,Tasty_Potential7670,,2023-10-16 14:05:11+00:00,False,,False,False,True,False,/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,Sap ui5 fiori vs data science,"I'm in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? 

Mainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today's decision",datascience,https://www.reddit.com/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,5,1,0.67,"[Comment(id='k54dpnh'), Comment(id='k54esg1'), Comment(id='k54oavs'), Comment(id='k552q9n'), Comment(id='k57iyj6')]"
1796ecp,datasciencewithmarco,,2023-10-16 13:48:48+00:00,False,,False,False,True,False,/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,Advice on my approach for a project,"For my project, I need to identify existing to users to start using a product. 

I have different ideas that I want to try, but I would like to have your input.

&#x200B;

**Idea 1**: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster

&#x200B;

**Idea 2:** Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.

&#x200B;

**Idea 3:** Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.

&#x200B;

Let me know what you think or if I am on the right track!",datascience,https://www.reddit.com/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,2,1,1.0,"[Comment(id='k548aay'), Comment(id='k57rwe7')]"
17961eu,orangepie000,,2023-10-16 13:31:19+00:00,False,,False,False,True,False,/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,Sharing is caring - with Gorudo.io," Sharing is caring - Creators can share your trade diary with your Members any time using [Gorudo.io](https://Gorudo.io)

&#x200B;

https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&format=pjpg&auto=webp&s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3",datascience,https://www.reddit.com/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,1,0,0.5,[Comment(id='k542vrm')]
178xboh,AutoModerator,,2023-10-16 04:01:27+00:00,False,,False,False,True,False,/r/datascience/comments/178xboh/weekly_entering_transitioning_thread_16_oct_2023/,"Weekly Entering & Transitioning - Thread 16 Oct, 2023 - 23 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/178xboh/weekly_entering_transitioning_thread_16_oct_2023/,105,5,1.0,"[Comment(id='k5akqzt'), Comment(id='k5cvzld'), Comment(id='k5k1tmo'), Comment(id='k5ddfd6'), Comment(id='k5ms68z'), Comment(id='k5agrg1'), Comment(id='k5dpr7o'), Comment(id='k53ezuz'), Comment(id='k5hzue3'), Comment(id='k5nmemq'), Comment(id='k5u6vpy'), Comment(id='k5url6f'), Comment(id='k5vfm4w'), Comment(id='k5wc3u4'), Comment(id='k5wj8wf'), Comment(id='k5wxds6'), Comment(id='k5y4fj7'), Comment(id='k5y52a1'), Comment(id='k52zczn'), Comment(id='k53dpki'), Comment(id='k55p0ru'), Comment(id='k56afd5'), Comment(id='k57fn1u'), Comment(id='k5by0x2'), Comment(id='k5hsd1z'), Comment(id='k5hwabd'), Comment(id='k5jddh2'), Comment(id='k5l1gtq'), Comment(id='k5lgmw2'), Comment(id='k5n8j9k'), Comment(id='k5oz4g9'), Comment(id='k5pccqj'), Comment(id='k5pt60l'), Comment(id='k5se5w4'), Comment(id='k5t7udd'), Comment(id='k5tsk9n'), Comment(id='k5z588c'), Comment(id='k609wgb'), Comment(id='k60qayy'), Comment(id='k5lpjsp'), Comment(id='k5i0rtg'), Comment(id='k5lp7g1'), Comment(id='k5p08ha'), Comment(id='k5lmvy4'), Comment(id='k5e9dkg'), Comment(id='k5ajfpo'), Comment(id='k5q6m1p'), Comment(id='k5lmlev'), Comment(id='k5641v8'), Comment(id='k5oyvzj'), Comment(id='k5u71ri'), Comment(id='k5vhs6e'), Comment(id='k5c83l8'), Comment(id='k5dgxp6'), Comment(id='k563rtp'), Comment(id='k59rmoh'), Comment(id='k59sxpp'), Comment(id='k5dghu8'), Comment(id='k5lolbs'), Comment(id='k5m3va6'), Comment(id='k5n911w'), Comment(id='k5kb0ft'), Comment(id='k5p0mzp'), Comment(id='k5umt2d'), Comment(id='k5rmhy9'), Comment(id='k5vyd8f'), Comment(id='k5ulu0l'), Comment(id='k5ul8n6'), Comment(id='k5vxx6w'), Comment(id='k5tws15'), Comment(id='k64up4g'), Comment(id='k5p3fne'), Comment(id='k5ukhxd'), Comment(id='k5zddt6'), Comment(id='k5vi01l'), Comment(id='k5dpyxn'), Comment(id='k565kd7'), Comment(id='k59z7ax'), Comment(id='k5e0x34'), Comment(id='k5lsh2g'), Comment(id='k5m46hg'), Comment(id='k5nbg9m'), Comment(id='k5rn8kf'), Comment(id='k62mcc8'), Comment(id='k62uruj'), Comment(id='k5w1d2o'), Comment(id='k5uq8uz'), Comment(id='k5vjp8a'), Comment(id='k5drvld'), Comment(id='k56eq27'), Comment(id='k5e385h'), Comment(id='k5lvgts'), Comment(id='k640bfs'), Comment(id='k5z7kl9'), Comment(id='k5uqny5'), Comment(id='k5du31u'), Comment(id='k56fg98'), Comment(id='k5ek0t4'), Comment(id='k5lvxe4'), Comment(id='k62uto9'), Comment(id='k5ur1o6'), Comment(id='k5e2e2z'), Comment(id='k56h7wi'), Comment(id='k5us6r3'), Comment(id='k56ia8g'), Comment(id='k5ushgi')]"
17950k5,CombinationThese993,,2023-10-16 12:38:26+00:00,False,,False,False,True,False,/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,Interpretation of logistic regression in absolute terms,"I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.

The problem is very unbalanced, most people will not concert.

Now....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.
I.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.

How would you go about solving this?",datascience,https://www.reddit.com/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,0,1,1.0,[]
178zw5j,Green_Ad6024,,2023-10-16 06:53:42+00:00,False,,False,False,True,False,/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,Which Model is best for Word Level Embeddings Generation?," Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. 

I have tried ""[https://tfhub.dev/google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4)"" but it gives high score even there is no matching between words.

Thank you for your guidance. ",datascience,https://www.reddit.com/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,1,2,1.0,[Comment(id='k53efne')]
1792i6s,you_ako,,2023-10-16 10:03:59+00:00,False,,False,False,True,False,/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,How remove highly skewed feature,"Hey everyone,
I work actually in a ML project for binary classification problem. When I did the EDA, I found that there are some numerical features highly skewed ( almost close to zero) and we plotted the histogram of each feature by class I have the same distribution... 

Can someone help to solve this problem 🙏🏻",datascience,https://www.reddit.com/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,4,1,0.67,"[Comment(id='k53vwdw'), Comment(id='k53z9wm'), Comment(id='k53nqga'), Comment(id='k53omk9')]"
178yb8k,arya_Kumar,,2023-10-16 05:03:09+00:00,False,,False,False,True,False,/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,How to use PPO policy network to find global min of a function ?,"Hello everyone, I have been given a task where I have to find the minimum of a function. I know i can easily do this using Gradient descent but I have been specifically told to use PPO policy network and explore-exploit framework.

Is it even possible? If so then how should I go about achieving this?

link to the function formula is given here: [https://www.sfu.ca/\~ssurjano/holder.html](https://www.sfu.ca/~ssurjano/holder.html)",datascience,https://www.reddit.com/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,0,2,1.0,[]
178eu2m,InterestingBasil,,2023-10-15 12:58:50+00:00,False,,False,False,True,False,/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,Build a Data Science App with Just Python: A Streamlit Guide," td/dr: easily build a SaaS with just python + zero front-end knowledge using streamlit.

I wrote this short guide which allows you to create a Data Science micro-SaaS MVP with stripe integration using Streamlit python package. I thought folks here might find it useful. Example of a zillow clone below.

[A Comprehensive Guide to Building and Deploying a Scalable SaaS Web App with Python, Streamlit, MongoDB, and Stripe](https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86)

[example of Streamlit SaaS](https://preview.redd.it/xl4z0dtf6dub1.png?width=1510&format=png&auto=webp&s=82643795b248c160de48cdc0f2fee9b0c6ac19ed)",datascience,https://www.reddit.com/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,10,35,0.89,"[Comment(id='k4zprr4'), Comment(id='k4zdnqv'), Comment(id='k4zqh5n'), Comment(id='k50tknv'), Comment(id='k50kex7'), Comment(id='k50kggc'), Comment(id='k50kbxi'), Comment(id='k53o692'), Comment(id='k5207qx'), Comment(id='k520h5o')]"
178shmx,Practical_Laugh6208,,2023-10-15 23:45:09+00:00,False,,False,False,True,False,/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,The ML project failure funnel,"Hello there. 

I've been thinking a lot recently about ML projects that failed and tried to organize and write up my thoughts. Do y'all see it this way?  

[https://www.kobrosly.net/ML\_failure\_funnel.html](https://www.kobrosly.net/ML_failure_funnel.html)",datascience,https://www.reddit.com/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,2,4,0.7,"[Comment(id='k522ujh'), Comment(id='k52jleq')]"
1786pqr,Equal_Astronaut_5696,,2023-10-15 03:39:31+00:00,False,,False,False,True,False,/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,"How to handle ""A.I."" obsessed management?","Just wondering how to handle management that thinks ChatGPT is a sentiment being that is going to that is self learning entity that solves every problem. I was asked to give a presentation on how LLMs work and indicated they are  not considered classical A.I. After I was sent crackpot articles on how Chapt is thinking and learning, reading and learning how to talk.  Management literally is asking with every data science  project  if we incorporate ChatGPT A.I.. Im in a leadership role so have to try hard not to poo poo  this enthusiasm but its hard. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,48,157,0.98,"[Comment(id='k4xt94t'), Comment(id='k4ybfgp'), Comment(id='k4xovlh'), Comment(id='k4ycc53'), Comment(id='k4ygsps'), Comment(id='k4yqf74'), Comment(id='k4z2hnn'), Comment(id='k4xq79w'), Comment(id='k51qs3m'), Comment(id='k4xwg3m'), Comment(id='k4yvpt5'), Comment(id='k4xzr8n'), Comment(id='k4yza3y'), Comment(id='k4z0z79'), Comment(id='k4zbg3h'), Comment(id='k4zlkk1'), Comment(id='k4zwbu7'), Comment(id='k50no68'), Comment(id='k50oll7'), Comment(id='k50uf3w'), Comment(id='k51acrg'), Comment(id='k53z1q9'), Comment(id='k4zb9wp'), Comment(id='k52caum'), Comment(id='k4z2mrh'), Comment(id='k52bj4q'), Comment(id='k50nchy'), Comment(id='k50r72x'), Comment(id='k4xx3qn'), Comment(id='k4yaz1x'), Comment(id='k4ydwvt'), Comment(id='k4xxfk7'), Comment(id='k4yflqt'), Comment(id='k4xzvdh'), Comment(id='k4y013k'), Comment(id='k4yeg6d'), Comment(id='k4z2iia'), Comment(id='k4yfq6p'), Comment(id='k4zx9f7'), Comment(id='k52bm1k'), Comment(id='k53njpo'), Comment(id='k4y3ywm'), Comment(id='k4y336o'), Comment(id='k4z7i2h'), Comment(id='k4y72o7'), Comment(id='k4zc50e')]"
178oz6c,sn9691,,2023-10-15 21:02:07+00:00,False,,False,False,True,False,/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,Opinions about the insurance industry?,"Apologies if this is the wrong place to ask. I was recently hired as a data scientist in a (motor) finance company. What is your opinion about this industry? Are insurance skills transferable to other industries too and if so, which ones do you think are closest?",datascience,https://www.reddit.com/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,1,6,1.0,[Comment(id='k53tg0l')]
178z2x2,gumiho34,,2023-10-16 05:55:26+00:00,False,,False,False,True,False,/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,Data science/analytics project idea for friend's business,"Hi everyone. My friend has a small business (think ecommerce) and asked me if i can help in any way. I have a math background but I'm interested in trying some sort of DS/DA side project. Any ideas on what topics / results i should look for?

Sorry if this is open ended; this kind of project seems very different from college projects where they tell you to do a,b,c and put it in a presentation.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,5,1,0.67,"[Comment(id='k53lbqz'), Comment(id='k54k539'), Comment(id='k54npl0'), Comment(id='k54qjco'), Comment(id='k54rzg4')]"
178yyfo,Vegetable-Hospital79,,2023-10-16 05:46:38+00:00,False,,False,False,False,False,/r/datascience/comments/178yyfo/ms_in_statistics_at_east_bay_location_vs_ms_in/,MS in Statistics at East Bay location vs MS in Data Science in top 150 ranked University.,,datascience,/r/gradadmissions/comments/178ysg4/ms_in_statistics_at_east_bay_location_vs_ms_in/,1,1,0.67,[Comment(id='k56qqul')]
178ioxq,Much-Focus-1408,,2023-10-15 16:10:02+00:00,False,,1697510944.0,False,True,False,/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,Mgmt and team want me to put a model in production without data. What do I do?,"Edit: thank you for all of your help!! I spoke with legal and said where I was, where I was going to be, and asked for more time to get the data. The data is slowly coming in; very excited! 

Feeling incredibly anxious since this goes against my ethical morals. 

I trained a model on data that won’t be used anymore; however, they want to use this model for data/KPIs that I’ve never seen before. They overpromised to senior leadership because the company is suffering. And they want me to over-deliver and do the paperwork/put this model into production.

I’ve asked to delay the deadline to get access to the KPIs for the model, but all they did was move the model due date up by…. A month. 

I’m having panic attacks and can’t sleep because this is just setting me up to fail. I’m so burnt out after speaking with management/teams. They just want to push this model into production, no matter what. 

How do you handle that? I’ve escalated the problem to other pp in mgmt and they said to just do it because of how important the model is. I’m 1000% sure that I’ll be seen as a scapegoat because there’s no way you can have a good model if there’s no data to train it/the wrong data.

For example, the OG data was on cats, but now they want me to look at data about ligers. It’s ridiculous and I’m not sure what to do. 

I haven’t been able to deliver the paperwork like they want/legal review because I know that this model isn’t good, but they want this to go into production so badly that the paperwork/things I’m saying aren’t correct. It’s due tomorrow, but there’s no way I can feasibly do that. I’ve tried meds and even thought of taking myself out of office this week to avoid this, but I lack the PTO. I got sick from the lack of sleep and I’m finding myself procrastinating on anything else because this ask seems so unethical. So many people at my company/role are getting laid off, and I should do this, but I just can’t do this. It’s related to my performance goals, too.",datascience,https://www.reddit.com/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,32,9,0.72,"[Comment(id='k4ztjq6'), Comment(id='k509wli'), Comment(id='k50a69t'), Comment(id='k50q2jw'), Comment(id='k50f0gg'), Comment(id='k53xr3c'), Comment(id='k542g5s'), Comment(id='k4zuns5'), Comment(id='k50e628'), Comment(id='k50dso2'), Comment(id='k50uixv'), Comment(id='k50fomz'), Comment(id='k502uwi'), Comment(id='k51h7ck'), Comment(id='k5184if'), Comment(id='k51ckkr'), Comment(id='k50im3j'), Comment(id='k504xqr'), Comment(id='k5386ks'), Comment(id='k52c1xg'), Comment(id='k519omq'), Comment(id='k50j6tb'), Comment(id='k509vv8'), Comment(id='k53e6i2'), Comment(id='k51mumw'), Comment(id='k50metr'), Comment(id='k51symt'), Comment(id='k50ecfn'), Comment(id='k50muqx'), Comment(id='k50fiy0'), Comment(id='k50n2o3'), Comment(id='k50k53w')]"
178kkpc,indiancaptainamerica,,2023-10-15 17:39:17+00:00,False,,False,False,True,False,/r/datascience/comments/178kkpc/casual_inference/,Casual Inference,"I am aware about the experiment design process in simple business model, but experiment design is lot more complicated in two sided or three sided marketplace. Can anyone help me to understand how the experiment design works in three sided marketplace like Uber or Amazon ?",datascience,https://www.reddit.com/r/datascience/comments/178kkpc/casual_inference/,5,5,0.78,"[Comment(id='k526cix'), Comment(id='k53p6mc'), Comment(id='k5446wh'), Comment(id='k54utzv'), Comment(id='k545a7f')]"
178lcts,Objective-Test5021,,2023-10-15 18:15:37+00:00,False,,1697394042.0,False,True,False,/r/datascience/comments/178lcts/is_my_experience_not_good/,Is my experience not good?,"
For some context, I’m a 24 year old international who recently graduated with a MS in CS in the US. Throughout my bachelors and while applying for internships during my first year, I always wanted to do DS. This was primarily based on a misconception however. 

During my bachelors I was not serious about coursework or coding, not in the slightest. It was only when covid hit and I realized I’ll be going to the US soon, did I start looking into some actual coding stuff. Started off with Python and thought DS was all about pandas, numpy and scikit learn and decided this is what I wanted to do. Obviously as I started grad school and learnt more about the actual nuances of ML and DS, I realized I was nowhere near good enough with my foundations in stats and math. 

I do consider myself to be a problem solver though, so despite not having a great base and starting off with grad level concepts in school, I was able to get upto speed and score a good grade. 

After this, I landed my first internship in “Data Science” at a consulting firm. Through 3 months, all I did was a ton of web scraping and ETL operations. Applying traditional ML in litigation casework is not easy because eventually all cases or most cases end up in front of a jury. So I never got to apply all that math in a professional environment. 

Since then, the world went through a “recession” and I couldn’t even land a single other interview. Did another internship with these guys and switched my focus to development based cases. Started building dashboards in Javascript and backends in C#. The closest DS related work I have done is integrating Azure OpenAI LLM APIs into a VueJs frond end through a .NET backend. Did this for 2 reasons, one, web scraping and ETL was redundant and boring. Two, the manager in charge of those cases is awful, constantly undermining my credentials, never even making eye contact during a conversation, insanely condescending and even told me multiple times that he doesn’t believe I have 2 degrees in CS. 

Anyway, at this point, I have been doing this for about 10 months. Based on my work that has transcended into more software development, do you think I should exclusively apply to SWE jobs to find a way out? What could my options be? Also, does this kind of a resume where you jump from one tech stack to another hurt? I haven’t received any interviews in about a year. Wondering if this is the general state of the world or is something fundamentally wrong with my work exp and if I’m stuck where I am.",datascience,https://www.reddit.com/r/datascience/comments/178lcts/is_my_experience_not_good/,9,5,0.73,"[Comment(id='k50o2sl'), Comment(id='k51nzdl'), Comment(id='k53bgtg'), Comment(id='k50qteg'), Comment(id='k51vstc'), Comment(id='k51y9d8'), Comment(id='k545fex'), Comment(id='k51vut4'), Comment(id='k51ybpw')]"
178eum0,Rebec1990,,2023-10-15 12:59:45+00:00,False,,False,False,True,False,/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,Data analytics leadership and imposter syndrome?,"Data analytics leadership and imposter syndrome?

I have found myself in and out of data analytics leadership roles in the past decade, mixed with hands-on data analyst work. I know I have some legit skills (eg, I have lots of experience in inferential statistics, research, can speak to the outcomes well, etc), but I can’t seem to shake the feeling of not deserving to be in a leadership position. For example, I recently hired a data analyst to expand my existing team and going through all the resumes showed me all the things that I can’t do (work in specific coding languages, predictive modeling, just to name a few). At several points, I asked myself why these people shouldn’t be MY boss because they clearly have to teach me lots of valuable skills. 

So please talk to me about the value-add of analytics leadership: what does a good leader bring to the table? Is it okay to not be able to do everything yourself? Is this imposter syndrome and do others recognize it?",datascience,https://www.reddit.com/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,13,13,0.88,"[Comment(id='k4z07f3'), Comment(id='k4z1etq'), Comment(id='k4zd9dd'), Comment(id='k4zltwk'), Comment(id='k4zdukg'), Comment(id='k51fe53'), Comment(id='k539sf6'), Comment(id='k4ze9bw'), Comment(id='k51fpyo'), Comment(id='k4zgq9m'), Comment(id='k51sj5s'), Comment(id='k51t5wc'), Comment(id='k51vm36')]"
178vkg9,CrazyProfessionalp,,2023-10-16 02:24:19+00:00,False,,False,False,True,False,/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,What is the best tool or way to measure uncertainties using machine learning ?,"I have a certain data that I measure the uncertainty via Monte Carlo, but I was wondering if there is a practical way to do that using machine learning.",datascience,https://www.reddit.com/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,2,1,0.6,"[Comment(id='k52sla7'), Comment(id='k52cejj')]"
178kwz8,Patient-Sun-5806,,2023-10-15 17:55:34+00:00,False,,False,False,True,False,/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,Get masters if my bachelors is in data sci?,I’m seeing a lot of people recommending people that have a degree in econ/cs/math to get a masters in data science or statistics. Will I need one if my whole bachelors is based in pure data science anyway?,datascience,https://www.reddit.com/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,3,4,1.0,"[Comment(id='k529zaz'), Comment(id='k53935d'), Comment(id='k51198e')]"
1780308,crattikal,,2023-10-14 21:53:27+00:00,False,,1697326415.0,False,True,False,/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,Took me over a year but I finally got a data analyst job,"Graduated summer of 2022 with a MS in Analytics after discovering the field by accident while exploring possible new fields, as I got burnt out from crazy hours at a previous database engineer role. I kept getting far in interview processes but never the role, although in hindsight I dropped out of a few interview processes that I maybe shouldn't have since I'd be the only analyst in the company. Finally got one this week, albeit as a data engineer/analyst supporting another analyst, right after taking a customer service role as I was giving up and planning on going to grad school next year for something completely different. Still processing this as I can barely believe it.",datascience,https://www.reddit.com/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,15,131,0.97,"[Comment(id='k4x7qas'), Comment(id='k4wfv8u'), Comment(id='k4wq2se'), Comment(id='k4wta4i'), Comment(id='k4x0m6c'), Comment(id='k4xkeie'), Comment(id='k4x5dwu'), Comment(id='k4zenpw'), Comment(id='k52j87b'), Comment(id='k4x99tz'), Comment(id='k50hc99'), Comment(id='k4yk6zs'), Comment(id='k4zglkn'), Comment(id='k50h3dk'), Comment(id='k50h6ix')]"
178neqa,hellohibyebye13,,2023-10-15 19:49:51+00:00,False,,False,False,True,False,/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,c3AI data scientist interview,"Has anyone interviewed at c3ai? I've read there are 3 stages of b2b interviews: ML/stats fundamentals, pandas/numpy/python coding, case study. 

What kind of questions are asked, especially in the case study portion? what exactly does the coding part inolve? also for stats - is it enough to cover hypothesis testing, p-values, PCA, etc? 

Any insight is appreciated!",datascience,https://www.reddit.com/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,4,2,0.75,"[Comment(id='k53vsn1'), Comment(id='k584uwi'), Comment(id='k5hc23e'), Comment(id='k5i146v')]"
178j8v9,TheFibonacci1235,,2023-10-15 16:35:34+00:00,False,,1697390123.0,False,True,False,/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,Tips on Data Science Jobs Abroad,"I am a 27-year-old guy who lives in the Netherlands and has about 2.5 years of experience in data science/software engineering. I've always dreamt of going on an international adventure and working abroad in Europe. Unfortunately, I have not yet been able to or have had the courage to take the leap. Now, with my girlfriend going on an exchange at the start of 2024, it feels like the perfect time to explore the possibilities of finding a job abroad.

I'm looking for tips, help, or experiences on how to tackle this big project. How do you start to look for jobs or projects? I know LinkedIn of course, but I'm wondering if there are also companies hiring people for a fixed-time contract. Or are there any businesses or platforms that connect job seekers with such companies? I'm uncertain about committing to an indefinite job, and I think for example a 6-month project might provide more security.

I'd appreciate any advice or stories that people are willing to share about their experiences working abroad. Thank you in advance for your support and wisdom!",datascience,https://www.reddit.com/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,0,3,1.0,[]
178l850,Zealousideal-Yak5547,,2023-10-15 18:09:43+00:00,False,,False,False,True,False,/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,Price effect on room occupancy rate,"Hello wonderful people,
I've been ask to study the effect of price on the final room occupancy rate for the hostels of my company.

So here are the data :
For a date (t), and for a specific room type, I have the occupancy Rate (OR, between 0 and 1), a set of categorical ordinal variables (total of 90 variables) that represent an indexed price of the room at a date (t-z). In other words, I know what was the indexed price of a specific room from the date being analysed back to 90 days before.

As I said, those exogenous variables are categorical ordinal. For example : PRICE1, PRINCE2... PRICE10, with price2 being more expensive than PRICE1. It is an indexed price in the sense that it drives the applied price on different booking network (booking.com, Expedia, our own website...)

How would you approach this subject ? I had in mind to try fitting an ARIMA model and look at the model parameters, but with the categorical ordinal variables, it would mean one-hour encoding and therefore having a huuuge dimensionality...

What do you guys think ? 💪",datascience,https://www.reddit.com/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,4,2,0.75,"[Comment(id='k50al27'), Comment(id='k58eabp'), Comment(id='k50e2d2'), Comment(id='k58ectw')]"
1784jir,maple_enthusiast,,2023-10-15 01:38:43+00:00,False,,1697769719.0,False,True,False,/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,"I am interviewing my future boss, what should I ask them?","As the title suggests I am going to be having 1-on-1 interviews with 3 candidates to replace my previous boss. Others within my team as well as higher ups will also be interviewing them separately. I will be given some instruction and there will be some coordination between all of us involved in this process. As this is a new experience for me (and likely a little unusual for most people to be choosing their boss), I am wondering if anyone has any suggestions as to questions that might be a bit outside of the basics you'd find on any old list of interview questions.   


For context, I have worked as a data analyst/data scientist/statistician (there isn't really a distinction between these roles in my area) for about 4.5 years now and have been in this current job for 2 years. I work in healthcare analytics with some of my work being straightforward research for the purposes of publication and other work with hospitals, governments, etc. trying to leverage their data to improve different aspects of their work and responsibilities. I am based outside of the U.S.A. and this is not for an American company FYI.

Update: Appreciate all the feedback. There were some really great responses in here that I will definitely be using.",datascience,https://www.reddit.com/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,28,31,0.98,"[Comment(id='k4xbgew'), Comment(id='k4xbabk'), Comment(id='k4x8tvf'), Comment(id='k4yaadh'), Comment(id='k4xdnj6'), Comment(id='k4yecxu'), Comment(id='k4y4ws6'), Comment(id='k4ynxjp'), Comment(id='k4xcbj7'), Comment(id='k4xk35o'), Comment(id='k4xwwb7'), Comment(id='k4ykt1k'), Comment(id='k4znf7v'), Comment(id='k506m89'), Comment(id='k50bers'), Comment(id='k5a5iun'), Comment(id='k4xwnih'), Comment(id='k4z8wb5'), Comment(id='k4xicxu'), Comment(id='k4y4tj4'), Comment(id='k5myw08'), Comment(id='k4ycsp1'), Comment(id='k4zo1wd'), Comment(id='k4xwp9n'), Comment(id='k4ytoo4'), Comment(id='k4yfm0g'), Comment(id='k4yuzl4'), Comment(id='k532ie3')]"
178vkrx,CrazyProfessionalp,,2023-10-16 02:24:45+00:00,False,,False,False,True,False,/r/datascience/comments/178vkrx/what_is_the_best_tool_way_to_make_forecast_using/,What is the best tool/ way to make forecast using machine learning ?,,datascience,https://www.reddit.com/r/datascience/comments/178vkrx/what_is_the_best_tool_way_to_make_forecast_using/,1,0,0.2,[Comment(id='k52glo6')]
178kwzn,Humble_Engineer1124,,2023-10-15 17:55:35+00:00,False,,False,False,True,False,/r/datascience/comments/178kwzn/going_back_to_school/,Going back to school,"Hello!

I’m going back to school full time in the spring. I’m double majoring in data science and interactive media and getting my B.S. in both. I’m projected to be graduated by Spring of 2027. What internships should I start looking into and how far along in school should I start applying? I’m new to this field and have done alot of research into the type of jobs I can get but just wanted outside opinion.",datascience,https://www.reddit.com/r/datascience/comments/178kwzn/going_back_to_school/,0,1,1.0,[]
1785em4,krhymme,,2023-10-15 02:25:57+00:00,False,,False,False,True,False,/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,Company building an LLM App. Need some understanding if my opinions are reasonable.,"I'm your generic mid-career data scientist who sometimes functions as an ML engineer. I've been tasked with advising a team building an LLM application to automate 'data analysis' for non-technical customers. My role is to bring some wisdom and system design expertise to the team. The team is compromised of two people: a young, eager software engineer who calls themselves a ""Langchain Developer"" and a senior technical director who believes in the macro trends around Generative AI and wants to learn more about applying the techonology.

The idea is a customer types a vague question in to a field  *e.g.* ""Is my business meeting my customer retention goals"" and the output would be a visualization of some descriptive metrics and an interpretation of the data.

The design presented to me by the Langchain developer sounds overly complex and a bit unhinged to me. I'm looking for an external opinion to make sure my opinions are well grounded or make sense.

1. This project is my first time using LangChain. From reading through the LangChain code,  and building some basic examples, the library feels over abstracted.  You have to navigate a tangled mess of private variables to even find the prompt the tool is using. I am *really* concerned about putting Langchain code in production since it seems difficult to debug and modify. Why can't we use a DAG or state machine instead?
2. The langchain developer doesn't present any systematic way to deal with hallucination. Generally, the strategy verbalized is too play ""wack a mole"" every time they see or measure a hallucination. If hallucinations are rare, then sure, and I'd be a bit more comfortable with this approach. But I've see no evidence that's the case.
3. The scalable ways to measure hallucination often use an LLM to judge it's own output. Generally, I try to avoid feedback loops between models. Is that too strong of an opinion to have when working with LLMs?

Appreciate the responses!",datascience,https://www.reddit.com/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,15,17,0.95,"[Comment(id='k4xqx0i'), Comment(id='k4xlrk4'), Comment(id='k4xnfk8'), Comment(id='k4y0f5w'), Comment(id='k4xlmqo'), Comment(id='k4xsl3b'), Comment(id='k4xzbve'), Comment(id='k527i7e'), Comment(id='k53g9g1'), Comment(id='k549d2b'), Comment(id='k4zdaf9'), Comment(id='k4yooh0'), Comment(id='k50ipo5'), Comment(id='k4ys9rk'), Comment(id='k50j2wb')]"
178nz28,No-Dot-6385,,2023-10-15 20:16:06+00:00,False,,False,False,True,False,/r/datascience/comments/178nz28/biologist_phd_data_scientist/,Biologist (PhD) --> Data Scientist?,"I'm just starting a PhD in a life science field (at a top university, if it matters). I've been wanting to learn more about the data science field and whether having a PhD in a biology domain would be helpful for data scientists positions within biotech, healthcare, etc. I plan to complete a computational certificate that my program offers, and my thesis project should involve a good amount of data science on top of wet-lab work.

Would this be a good career path? Will not having a degree in computer science, data science, etc. put me at a disadvantage?",datascience,https://www.reddit.com/r/datascience/comments/178nz28/biologist_phd_data_scientist/,4,0,0.33,"[Comment(id='k50wxy2'), Comment(id='k518pct'), Comment(id='k50x7rm'), Comment(id='k510b7i')]"
178dsvv,alexey_timin,,2023-10-15 11:55:07+00:00,False,,False,False,False,False,/r/datascience/comments/178dsvv/from_lab_to_live_implementing_opensource_ai/,From Lab to Live: Implementing Open-Source AI Models for Real-Time Unsupervised Anomaly Detection in Images,,datascience,https://www.reduct.store/computer-vision/edge-computing/ai/Implementing-open-source-ai-anomaly-detection/,0,2,1.0,[]
177qnvc,cptsanderzz,,2023-10-14 14:21:20+00:00,False,,False,False,True,False,/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,Should I pursue a PhD,"So I’m in my late 20s, I received a bachelor of science in math and a master of science in data analytics. I have been working as a “Data Science Consultant” for 2 years now. I really just don’t find the work challenging or interesting. My field of interests include NLP, Policy, Media, and International Relations (I know very niche). The data science market is terrible and I’m applying to jobs and getting a few interviews, but not roles I’m really interested in. I think I would really enjoy doing applied data science research, like how can we use data science, statistics, etc. to address this issue. The problem is all of these jobs I see are reserved for PhDs. I just keep going back and forth on whether this should be something I pursue or not. What would you all recommend for someone in my shoes?",datascience,https://www.reddit.com/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,79,77,0.89,"[Comment(id='k4vsj9o'), Comment(id='k4usdoe'), Comment(id='k4w2mzt'), Comment(id='k4ul2e9'), Comment(id='k4vpj2b'), Comment(id='k4v94fu'), Comment(id='k4ujnxx'), Comment(id='k4w1005'), Comment(id='k4w6nez'), Comment(id='k4ww2aj'), Comment(id='k4x4e1p'), Comment(id='k4xcm13'), Comment(id='k4v3uxs'), Comment(id='k4vk3cr'), Comment(id='k4vnscb'), Comment(id='k4wvfr7'), Comment(id='k4wqrjz'), Comment(id='k4vaajt'), Comment(id='k4vtl7n'), Comment(id='k4w2mji'), Comment(id='k4wdqye'), Comment(id='k4wk87n'), Comment(id='k4wo18s'), Comment(id='k4xnh3c'), Comment(id='k4yuigh'), Comment(id='k4yyenk'), Comment(id='k4z0fsd'), Comment(id='k4zcr7i'), Comment(id='k4zpkjp'), Comment(id='k4vtlcy'), Comment(id='k4xlo7s'), Comment(id='k4uu0l5'), Comment(id='k4w43cs'), Comment(id='k4v2dfc'), Comment(id='k4un88l'), Comment(id='k4upzic'), Comment(id='k4vt8bq'), Comment(id='k4va8nf'), Comment(id='k4uuxsu'), Comment(id='k53jsu3'), Comment(id='k4w26g3'), Comment(id='k4vfoxz'), Comment(id='k4valf8'), Comment(id='k4vkq47'), Comment(id='k4wffld'), Comment(id='k4way0d'), Comment(id='k4uu7yu'), Comment(id='k4wcblh'), Comment(id='k4vufdi'), Comment(id='k4uszfr'), Comment(id='k4vtq6e'), Comment(id='k4vbv21'), Comment(id='k4uv5y4'), Comment(id='k53n2me'), Comment(id='k4vm4xi'), Comment(id='k4uupw9'), Comment(id='k4uuftk'), Comment(id='k4vu2vj'), Comment(id='k4vc9jz'), Comment(id='k4vg422'), Comment(id='k4v10gc'), Comment(id='k4uw0in'), Comment(id='k4vv6r1'), Comment(id='k4vno8r'), Comment(id='k4vhmpz'), Comment(id='k4v2nx3'), Comment(id='k4vzqb9'), Comment(id='k4w8sph'), Comment(id='k4vi2pj'), Comment(id='k4vr1oi'), Comment(id='k4v7lmw'), Comment(id='k4whu6s'), Comment(id='k4v9rht'), Comment(id='k4yus43'), Comment(id='k4vupiy'), Comment(id='k4yyhxn'), Comment(id='k4zndjr'), <MoreComments count=0, children=[]>]"
178bdnk,xTH13M0x,,2023-10-15 09:01:36+00:00,False,,False,False,True,False,/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,Looking for a tool for image recognition,"Hi, I'm looking for a tool to easily categorize a huge amount of images. Best case would be, if i could use the tool with a python library. Could you recommend anything?",datascience,https://www.reddit.com/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,0,2,1.0,[]
178rqxf,Ordinary_Jelly_6344,,2023-10-15 23:08:02+00:00,False,,False,False,True,False,/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,What do data scientist do when their data isn't reliable?," 

\#Apple, #Question, #Data\_Scientists,

What do data scientist do when their data isn't reliable? Looking for answers other than the easily Googled/ChatGPTed validate, clean, imputation, transformation, documentation, source investigation, quality assessment, etc.

\#Context, 

A project my team and I are working on we regularly release builds using Testflight. 

An observation is that Apple has incorrect analytics even within their walled garden from AppStoreConnect to TestFlight.

Specifically, in this screencast/video we can see that the version of the app which the App Store Connect dashboard says I've currently got installed is 1.0.1+26 which was installed today October 15th 2023.  


[https://youtube.com/shorts/Sc2NrvAKFlA?feature=share](https://youtube.com/shorts/Sc2NrvAKFlA?feature=share)

But at the beginning & end of the video, we clearly see that I haven't installed that version yet; I still need to update.

I accept data between differing aggregators being ""off"" no problem. 

\#Unpopular\_Opinion

However seeing this behavior within a platform/company which is the largest, most well-funded, arguably among the most technical in the world makes me doubt the value of data analytics/science.   


How can we be sure of our analysis if we can't be sure of our data? It's disconcerting.

Not trying to flame data scientists here, trying to figure out how to feel cause I do believe we have to have analytics/benchmarks to make informed decisions but this conundrum is causing cognitive dissonance.  


Looking forward to seeing everyones feedback.  
",datascience,https://www.reddit.com/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,5,0,0.35,"[Comment(id='k51qrte'), Comment(id='k526sef'), Comment(id='k51rnq0'), Comment(id='k51rtko'), Comment(id='k52alii')]"
178e7fp,asatenata,,2023-10-15 12:20:59+00:00,False,,False,False,True,False,/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,Finding ds job after life sciences degree,"During my BSc biochemistry degree I realised that I’m much more interested in analytics and data science than pure science. My dissertation was about analysing existing mitochondria proteins databases for which I used R, excel and Prism. I graduated from university as adult (M27) and I’ve been a quality manager in a local coffee shop chain for the last two years. What are my chances to get into data science field without cs/math degree and what would be the best strategy to land a job? For context I live in the UK.",datascience,https://www.reddit.com/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,3,1,0.6,"[Comment(id='k4yxejx'), Comment(id='k4zrb3z'), Comment(id='k4z1r71')]"
177w76r,Historical_Leek_9012,,2023-10-14 18:47:52+00:00,False,,False,False,True,False,/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,Do companies consider it cheating to Google/chat gpt stuff on hackerrank tests?,"Curious because I just took an assessment. Not like I googled the full question. I just had chat gpt fix some syntax issues and googled some functions I couldn’t remember the exact way to write. I think if they asked me about it, I’d just explain that’s what I did — same as when I’m writing code outside an assessment. But I’m curious what’s considered the norm in assessments for jobs.

Edit: there was nothing on the assessment that said either way.",datascience,https://www.reddit.com/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,26,24,0.79,"[Comment(id='k4w28v7'), Comment(id='k4yagwt'), Comment(id='k4wrifw'), Comment(id='k4wgmy7'), Comment(id='k4wo9nr'), Comment(id='k4whlrw'), Comment(id='k4y3t0l'), Comment(id='k4yjr0c'), Comment(id='k4z6umu'), Comment(id='k4w2sab'), Comment(id='k4xj4pt'), Comment(id='k4y5svf'), Comment(id='k4z5osm'), Comment(id='k4ybldm'), Comment(id='k4xkddn'), Comment(id='k4y9j9k'), Comment(id='k50muww'), Comment(id='k4z7ot3'), Comment(id='k4xltfh'), Comment(id='k4zdrpj'), Comment(id='k4zrsxz'), Comment(id='k4y9n6l'), Comment(id='k4zsj6w'), Comment(id='k4z21nx')]"
178cy0s,indusop,,2023-10-15 10:57:48+00:00,False,,False,False,False,False,/r/datascience/comments/178cy0s/interested_about_cricket_and_data_science_here_is/,Interested about cricket and data science ? Here is my new article on medium about building the IPl Win Predictor from scratch please have a look!!,,datascience,https://medium.com/@harshsmj1504/ipl-win-predictor-analyzing-winning-probabilities-d9f4f38e0226,0,1,0.67,[]
178csio,Economy_Tap7557,,2023-10-15 10:46:46+00:00,False,,False,False,True,False,/r/datascience/comments/178csio/walmart_data_science_internship/,Walmart Data Science Internship,"Hey Guys , I have my Walmart first round karat interview next week .

Any tips would be helpful:)

Thanks in advance",datascience,https://www.reddit.com/r/datascience/comments/178csio/walmart_data_science_internship/,2,1,1.0,"[Comment(id='k7f3cw3'), Comment(id='k7ofpgs')]"
178byoc,Informal-Assist2642,,2023-10-15 09:45:53+00:00,False,,False,False,True,False,/r/datascience/comments/178byoc/comprehending_research_papers/,Comprehending Research Papers,"Hi DS community, Was just wondering what are the approaches you guys take reading and comprehending Research papers and the maths behind it. I have developed a keen interest reading research; however, For me digesting the whole research paper takes a lot of time (5-6)hours. Since, I plan to go for PHD, this is the skill I want to polish the most. I was wondering, what approaches you guys take for the following.

*  Maths portion (which I enjoy I must say), here mostly I try to rederive the equations on paper to understand better. 
* The reference papers that I have to revisit to gain praticle insights about the research at hand ( most time I read them Abstract, intro, conclusion and diagrams to extract important insights only and other time I read them end-to-end.

Thanks again.",datascience,https://www.reddit.com/r/datascience/comments/178byoc/comprehending_research_papers/,0,1,1.0,[]
17798wz,anon_throwaway09557,,2023-10-13 21:28:48+00:00,False,,1697238048.0,False,True,False,/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,Warning to would be master’s graduates in “data science”,"I teach data science at a university (going anonymous for obvious reasons). I won't mention the institution name or location, though I think this is something typical across all non-prestigious universities. Basically, master's courses in data science, especially those of 1 year and marketed to international students, are a scam. 

Essentially, because there is pressure to pass all the students, we cannot give any material that is too challenging. I don't want to put challenging material in the course because I want them to fail--I put it because challenge is how students **grow** and **learn**. Aside from being a data analyst, being even an entry-level data scientist requires being good at a lot of things, and knowing the material deeply, not just superficially. Likewise, data engineers have to be good software engineers.

But apparently, asking the students to implement a trivial function in Python is too much. Just working with high-level libraries won't be enough to get my students a job in the field. OK, maybe you don’t have to implement algorithms from scratch, but you have to at least wrangle data. The theoretical content is OK, but the practical element is far from sufficient.

It is my belief that only one of my students, a software developer, will go on to get a high-paying job in the data field. Some might become data analysts (which pays thousands less), and likely a few will never get into a data career.

Universities write all sorts of crap in their marketing spiel that bears no resemblance to reality. And students, nor parents, don’t know any better, because how many people are actually qualified to judge whether a DS curriculum is good? Nor is it enough to see the topics, you have to see the *assignments*. If a DS course doesn’t have at least one serious course in statistics, any SQL, and doesn’t make you solve real programming problems, it's no good.",datascience,https://www.reddit.com/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,292,620,0.96,"[Comment(id='k4rjlcy'), Comment(id='k4s0cfn'), Comment(id='k4s8tfk'), Comment(id='k4sd9uz'), Comment(id='k4rqkq3'), Comment(id='k4ru1hm'), Comment(id='k4rys5l'), Comment(id='k4t85wh'), Comment(id='k4roh5h'), Comment(id='k4rxb7d'), Comment(id='k4rzkug'), Comment(id='k4svmqy'), Comment(id='k4runfq'), Comment(id='k4s5i6s'), Comment(id='k4t6kre'), Comment(id='k4roruh'), Comment(id='k4sjihu'), Comment(id='k4saxq4'), Comment(id='k4sgp8m'), Comment(id='k4t5h1m'), Comment(id='k4te9zn'), Comment(id='k4thotz'), Comment(id='k4ux0yp'), Comment(id='k4ryqbw'), Comment(id='k4s4gdo'), Comment(id='k4shgvr'), Comment(id='k4sc5vy'), Comment(id='k4sv4dv'), Comment(id='k4rr43n'), Comment(id='k4ryddd'), Comment(id='k4sno2n'), Comment(id='k4szqw5'), Comment(id='k4t9utc'), Comment(id='k4tm1sq'), Comment(id='k4tmf8w'), Comment(id='k4us629'), Comment(id='k4w5zi5'), Comment(id='k4wwqlt'), Comment(id='k4ziiv4'), Comment(id='k4rzaf7'), Comment(id='k4t70m8'), Comment(id='k4tt1s5'), Comment(id='k4tuq1h'), Comment(id='k4s37wt'), Comment(id='k4s9059'), Comment(id='k4tbkhm'), Comment(id='k4rmt6x'), Comment(id='k4rv3yr'), Comment(id='k4svv91'), Comment(id='k4s7pfm'), Comment(id='k4t2pvv'), Comment(id='k4swpoi'), Comment(id='k4swvdb'), Comment(id='k4t1cfl'), Comment(id='k4t4zm9'), Comment(id='k4te8ai'), Comment(id='k4thtzr'), Comment(id='k4tih1g'), Comment(id='k4tlc09'), Comment(id='k4tpa2x'), Comment(id='k4tswvb'), Comment(id='k4u201m'), Comment(id='k4u4ry5'), Comment(id='k4u5xhz'), Comment(id='k4ua9kf'), Comment(id='k4uehk5'), Comment(id='k4uky6t'), Comment(id='k4up9fn'), Comment(id='k4uqe8i'), Comment(id='k4uqkw9'), Comment(id='k4uty0u'), Comment(id='k4vcyzz'), Comment(id='k4vm650'), Comment(id='k4whsv3'), Comment(id='k4wnntd'), Comment(id='k4wpjga'), Comment(id='k4wzzhb'), Comment(id='k4xdbdc'), Comment(id='k4xfr8b'), Comment(id='k4xi5d8'), Comment(id='k4xjzno'), Comment(id='k4xnfnu'), Comment(id='k4yk7yy'), Comment(id='k4zew3c'), Comment(id='k54pn8x'), Comment(id='k575969'), Comment(id='k6icqn3'), Comment(id='k7dj430'), Comment(id='k7dj5gb'), Comment(id='k4rs0z6'), Comment(id='k4s0ddc'), Comment(id='k4srges'), Comment(id='k4rylpl'), Comment(id='k4vw8hy'), Comment(id='k4vfgs6'), Comment(id='k4xbu16'), Comment(id='k4ydjd2'), Comment(id='k4yrc1y'), Comment(id='k4tpk4k'), Comment(id='k4t0g4e'), Comment(id='k4tpphx'), Comment(id='k4uczej'), Comment(id='k4te2w6'), Comment(id='k4w04xu'), Comment(id='k4sraym'), Comment(id='k4trlco'), Comment(id='k4t2czz'), Comment(id='k4tgf4j'), Comment(id='k4tm6ed'), Comment(id='k4ta3ah'), Comment(id='k4ux54z'), Comment(id='k4wh8ly'), Comment(id='k4wiabv'), Comment(id='k4ubidi'), Comment(id='k4ryccl'), Comment(id='k4xwnll'), Comment(id='k4sl68m'), Comment(id='k6rxm7a'), Comment(id='k4sszjk'), Comment(id='k4udkqa'), Comment(id='k4t9xs2'), Comment(id='k576ak2'), Comment(id='k4rowrl'), Comment(id='k4sbs3m'), Comment(id='k4sdmu0'), Comment(id='k4wxrhw'), Comment(id='k4uykmg'), Comment(id='k4w0bf2'), Comment(id='k4rwdvn'), Comment(id='k4s7a8y'), Comment(id='k4t6at0'), Comment(id='k4tpt5a'), Comment(id='k4rozen'), Comment(id='k4rp9pn'), Comment(id='k4ru1va'), Comment(id='k4rw98s'), Comment(id='k4v71uy'), Comment(id='k55rw9d'), Comment(id='k4snldc'), Comment(id='k4tsgfb'), Comment(id='k4v9c1i'), Comment(id='k4sv8e4'), Comment(id='k4tcl83'), Comment(id='k4tqaco'), Comment(id='k4s8lde'), Comment(id='k4t7xkp'), Comment(id='k4to1la'), Comment(id='k4tnq8a'), Comment(id='k4tmuzl'), Comment(id='k4ym999'), Comment(id='k4sdx2q'), Comment(id='k4uiono'), Comment(id='k4sszlv'), Comment(id='k4szivc'), Comment(id='k4zi96f'), Comment(id='k4rn09i'), Comment(id='k4rurii'), Comment(id='k4rwkhu'), Comment(id='k4rzeq5'), Comment(id='k4rw5bv'), Comment(id='k4sn5r3'), Comment(id='k4se0ef'), Comment(id='k4toao9'), Comment(id='k4tpee8'), Comment(id='k4tnb3r'), Comment(id='k4tn82q'), Comment(id='k4wo1qk'), Comment(id='k56as3b'), Comment(id='k7sp538'), Comment(id='k4rvra1'), Comment(id='k4sst3z'), Comment(id='k4tepzj'), Comment(id='k4scsxu'), Comment(id='k4u2sdc'), Comment(id='k4xhrms'), Comment(id='k4xpgec'), Comment(id='k4w0152'), Comment(id='k4t4dna'), Comment(id='k4t1dmf'), Comment(id='k4v7x21'), Comment(id='k4wk9wa'), Comment(id='k4tlq5h'), Comment(id='k4ukg9t'), Comment(id='k4t4sz7'), Comment(id='k4t1nha'), Comment(id='k4vh58d'), Comment(id='k50v8e1'), Comment(id='k4rq297'), Comment(id='k4tm5gh'), Comment(id='k4t64w5'), Comment(id='k4veygp'), Comment(id='k4slpni'), Comment(id='k4u4aqy'), Comment(id='k4rqf42'), Comment(id='k4sd4fx'), Comment(id='k4rt6ns'), Comment(id='k4sua63'), Comment(id='k4v0nb8'), Comment(id='k55vwyf'), Comment(id='k4u91pz'), Comment(id='k4u92vo'), Comment(id='k4u95fs'), Comment(id='k4u22mg'), Comment(id='k4uyrdo'), Comment(id='k4ydgqe'), Comment(id='k4tof14'), Comment(id='k4tdau8'), Comment(id='k4sn44l'), Comment(id='k4toqib'), Comment(id='k4ro8n6'), Comment(id='k4rvk2c'), Comment(id='k4rwyxq'), Comment(id='k4s0ydf'), Comment(id='k4uihd4'), Comment(id='k592imp'), Comment(id='k4t2tlk'), Comment(id='k4tjwov'), Comment(id='k4s9ajj'), Comment(id='k4uq3nd'), Comment(id='k4vnqbv'), Comment(id='k4ugj4r'), Comment(id='k4zfguu'), Comment(id='k4swk7e'), Comment(id='k4ty704'), Comment(id='k4sm7rp'), Comment(id='k4wge24'), Comment(id='k4t6b30'), Comment(id='k4t2gsi'), Comment(id='k4wukmj'), Comment(id='k4tsqor'), Comment(id='k4vqv76'), Comment(id='k4vt5cc'), Comment(id='k4urrz9'), Comment(id='k4vu60d'), Comment(id='k50xntd'), Comment(id='k4x6841'), Comment(id='k4rrucn'), Comment(id='k4s12yk'), Comment(id='k4rwk1p'), Comment(id='k4rwenj'), Comment(id='k4v5vq2'), Comment(id='k55zk1j'), Comment(id='k4vbll2'), Comment(id='k4vj2gl'), Comment(id='k4uzs5o'), Comment(id='k4v8pzv'), Comment(id='k4ropir'), Comment(id='k4rs3xy'), Comment(id='k4rvqs7'), Comment(id='k592zmn'), Comment(id='k4tmk1c'), Comment(id='k4u2dyc'), Comment(id='k4u3j1c'), Comment(id='k4s9jwo'), Comment(id='k4tm2v9'), Comment(id='k4uqb7t'), Comment(id='k54yets'), Comment(id='k4ui63c'), Comment(id='k4w0uza'), Comment(id='k4vedrk'), Comment(id='k4tb9c8'), Comment(id='k4xs56m'), Comment(id='k4ug631'), Comment(id='k4uuitz'), Comment(id='k4sth96'), Comment(id='k4usfe5'), Comment(id='k4vc444'), Comment(id='k5602w6'), Comment(id='k4vk08y'), Comment(id='k4vtiht'), Comment(id='k4vcfr6'), Comment(id='k4rzfz7'), Comment(id='k4rw405'), Comment(id='k5chosd'), Comment(id='k4s9p49'), Comment(id='k4t7sn8'), Comment(id='k4uvqh5'), Comment(id='k4upoza'), Comment(id='k4unges'), Comment(id='k4vie9f'), Comment(id='k4uty2g'), Comment(id='k4vcif1'), Comment(id='k4vnkjk'), Comment(id='k4vuzjc'), Comment(id='k4s5yvm'), Comment(id='k4rwrdp'), Comment(id='k4sjkrz'), Comment(id='k4uvthd'), Comment(id='k4tmi9t'), Comment(id='k4vfuq5'), Comment(id='k4w2qxy'), Comment(id='k4veqzx'), Comment(id='k4vxejz'), Comment(id='k4x3m32'), Comment(id='k4sjqqe'), Comment(id='k4xmfoq'), Comment(id='k4xoo3i')]"
1786d5a,Neurosymbolic,,2023-10-15 03:19:34+00:00,False,,False,False,True,False,/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,Supercharging Reinforcement Learning with Logic,"Deep reinforcement learning has led to a variety of compelling results.  However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly.  Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.

&#x200B;

https://preview.redd.it/x7050xg2baub1.png?width=1786&format=png&auto=webp&s=14929e5614404808c85d48922e0af947f8d52b90

We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).

&#x200B;

https://preview.redd.it/k1ntxyh3baub1.png?width=1636&format=png&auto=webp&s=bdf0bb030a0a4d38034460d52940593e6a57cb32

However, the benefits of our semantic proxy go well beyond performance.  The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity.  PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false).  We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.

Preprint: [https://arxiv.org/abs/2310.06835](https://arxiv.org/abs/2310.06835)

Video: [https://youtu.be/9e6ZHJEJzgw](https://youtu.be/9e6ZHJEJzgw)

Code for PyReason-as-a-Sim (integration with DQN): [https://github.com/lab-v2/pyreason-rl-sim](https://github.com/lab-v2/pyreason-rl-sim)

Code for PyReason Gym: [https://github.com/lab-v2/pyreason-gym](https://github.com/lab-v2/pyreason-gym)

PyReason home: [https://neurosymbolic.asu.edu/pyreason/](https://neurosymbolic.asu.edu/pyreason/)",datascience,https://www.reddit.com/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,1,2,0.76,[Comment(id='k5hyxkh')]
1788uk9,hassaan84s,,2023-10-15 05:57:20+00:00,False,,1697507767.0,False,True,False,/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,AI-based Research tool to help brainstorm novel ideas,"Hey folks,

I developed a research tool [https://demo-idea-factory.ngrok.dev/](https://demo-idea-factory.ngrok.dev/) to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.

I would be happy to get your feedback on its usefulness for data science related research problems.

Thank you in advance!",datascience,https://www.reddit.com/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,2,1,0.67,"[Comment(id='k4ybzkb'), Comment(id='k4znxzi')]"
1787v23,sarmientoj24,,2023-10-15 04:51:18+00:00,False,,False,False,True,False,/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,Embed multi-dimensional data points for visualizing and inserting a new data in the plot,"Say, I have an N group of students. And I have their normalized test scores for 8 subjects from 0 to 1. 

I want to create a model that can put the data points into 2D plot showing which students are similar to each other. I will show the visualization of the data points.

Lastly, if someone gives their data point, I want to show them where they are in the plot, show which students are most similar to the new data point.

Which amongst PCA, tSNE, UMAP is suitable for this? Or are there other options like VAEs for tabular data?

The new data point is a test point and the N group of students are the training points.",datascience,https://www.reddit.com/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,0,1,1.0,[]
1786ci4,Talion07,,2023-10-15 03:18:31+00:00,False,,1697341666.0,False,True,False,/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,Does the big 4 tag really matter?,"So basically is a data analytics job (SQL and power bi viz) is better than a data scientist job (hands on python, model building and cloud) at a national company ?


Or just joining the big 4 in hopes of getting promoted to a job with more hands on coding is the right way to go?",datascience,https://www.reddit.com/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,12,1,0.54,"[Comment(id='k4xmrws'), Comment(id='k4y091z'), Comment(id='k4yam55'), Comment(id='k4y8c3u'), Comment(id='k4yq11n'), Comment(id='k5590se'), Comment(id='k4xnqif'), Comment(id='k4y5lxx'), Comment(id='k4xp7w7'), Comment(id='k51d3ym'), Comment(id='k4y5zc3'), Comment(id='k50o754')]"
177rzkj,Careful_Till8105,,2023-10-14 15:24:46+00:00,False,,False,False,True,False,/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,Why do we maximize likelihood of theta in logistic regression?,"Very new to the topic.  
I do not understand why we want to maximize the likelihood of the parameter theta: isn't the likelihood we care about just the likelihood of output y? What is the point of maximizing the parameter's likelihood?

Apologies if this is a silly question and thank you so much for your input",datascience,https://www.reddit.com/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,10,8,0.75,"[Comment(id='k4ute59'), Comment(id='k4vn4vo'), Comment(id='k4vmo9b'), Comment(id='k4vifyp'), Comment(id='k4wll6k'), Comment(id='k4yzyh3'), Comment(id='k4z61qe'), Comment(id='k4z1rn0'), Comment(id='k4z45pf'), Comment(id='k4z4g9c')]"
177k8pw,Much-Egg7130,,2023-10-14 07:44:38+00:00,False,,False,False,True,False,/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,Do you also often deal with problems that turn out to be some kind of constrained optimisation problems?,"I've been working in the role of a data scientist for about 3 years at a large corporate. My training is as a physicist. I'm often involved in early stage proofs-of-concept for different departments so we're often in exchange with ""innovation managers"" whose role is to find use cases for ""AI"", as they call it. As a result, I often get pitched ideas for new projects from those managers.  


Now, upon closer inspection, many of these problems involve, at their technical core, an optimisation problem, where an objective function has to be optimised in the presence of constraints. I find these problems intriguing but I usually feel overwhelmed tackling them, as I lack the training to deal with them and I feel there is no good tooling around to help me model them, not to mention choosing and tuning the solver, benchmarking and then finally bringing them in production. 

As a result (and also for other reasons), those projects usually don't get realised.

I wonder whether others here face the same challenge or whether this is particular to me and if there are others, how you deal with it. Thanks",datascience,https://www.reddit.com/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,16,28,0.95,"[Comment(id='k4tlt01'), Comment(id='k4torfx'), Comment(id='k4tpdkv'), Comment(id='k4ubq8k'), Comment(id='k4u7ulc'), Comment(id='k4tzf34'), Comment(id='k4vk000'), Comment(id='k4v4n6t'), Comment(id='k4vgvh7'), Comment(id='k4vqs5u'), Comment(id='k4uz641'), Comment(id='k4wqbg1'), Comment(id='k4yy1ox'), Comment(id='k500pyv'), Comment(id='k504tx5'), Comment(id='k50uotd')]"
1788zxi,604korupt,,2023-10-15 06:07:11+00:00,False,,False,False,True,False,/r/datascience/comments/1788zxi/in_1_year_of_data_science_in_college_what_do_you/,"In 1 year of data science in college, what do you guys learn? Let me know!",,datascience,https://www.reddit.com/r/datascience/comments/1788zxi/in_1_year_of_data_science_in_college_what_do_you/,8,0,0.2,"[Comment(id='k4yezla'), Comment(id='k4y7ad2'), Comment(id='k4yarmt'), Comment(id='k4yhi4u'), Comment(id='k51oig2'), Comment(id='k4y8sg8'), Comment(id='k5315q5'), Comment(id='k4ya3rk')]"
177ifms,Excellent_Cost170,,2023-10-14 05:38:42+00:00,False,,1697290127.0,False,True,False,/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,How to handle incompetent manager while looking for another job," 

I work in a large federal government agency, and regrettably, I have an extremely incompetent manager who spent many years working on dashboarding before being promoted to lead our team. My manager lacks any prior experience as a data scientist, data engineer, or machine learning engineer and is unwilling to learn in these areas. Given the nature of government employment, the likelihood of termination or layoffs is exceedingly low. The organization comprises both employees and contractors with the title of ""data scientists,"" but there's no clear plan on how to utilize their skills effectively. Additionally, our data governance and data quality processes are almost nonexistent.

There is a  significant fraud problem resulting in multimillion-dollar losses. One of the major challenges is that there are multiple definitions of fraud within the organization, making it nearly impossible to get straight answers when seeking guidance from supposed subject matter experts. Furthermore, various teams within the agency have different agendas when trying to address the fraud problem.

The CIO has recently directed us, likely influenced by management consultants, to use machine learning to solve the fraud problem. Nevertheless, it's apparent that there are many low-hanging fruit solutions, like process changes, that don't require machine learning and could significantly alleviate the issue.

Now, our manager is pressuring our team to build a machine learning model to supposedly save X millions of dollars. It appears that many people here are more interested in showcasing flashy tools and ideas to the directors and CIO, rather than delving into the details of the problem. Some of the other data scientists are demonstrating the use of complex machine learning techniques without truly understanding the problem statement or the models they are building. To make matters worse, we don't even have a clear, agreed-upon estimate of how much money we are losing.

In this chaotic environment, the manager wants us to build a model simply because someone in another team has done something similar. Our manager is focused on marketing and doesn't seem to care about the necessary details. I've suggested that we should invest time in understanding the data and conduct a feasibility study to determine if machine learning is an appropriate solution before committing to creating elaborate models. However, my manager either doesn't grasp the importance of understanding the data or simply doesn't care. Today he said I want each of you to build a model and compare results.

I know that the right thing to do is to leave the company or the team, and I am actively working on it. In the meantime, how can I handle this situation in the best possible way?",datascience,https://www.reddit.com/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,21,28,0.93,"[Comment(id='k4t7tm5'), Comment(id='k4tewzl'), Comment(id='k4tusld'), Comment(id='k4u6v0k'), Comment(id='k4th6fa'), Comment(id='k4u0bp9'), Comment(id='k4uey4a'), Comment(id='k4tufzu'), Comment(id='k4v97z7'), Comment(id='k4w95b7'), Comment(id='k4uvbti'), Comment(id='k4uad0w'), Comment(id='k4uxgk5'), Comment(id='k4ufpc4'), Comment(id='k4ub2nm'), Comment(id='k4vhpun'), Comment(id='k4v2eru'), Comment(id='k4v30b6'), Comment(id='k4uena2'), Comment(id='k4w1o3e'), Comment(id='k4ukrss')]"
1786ftu,CrazyProfessionalp,,2023-10-15 03:23:46+00:00,False,,False,False,True,False,/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,What are the best data science courses for curriculum in US?,"I’m planning to live in NY, and wanted to known the best online or live short courses , pos graduation courses and/or masters related with data science , and possibly with sustainability as well?",datascience,https://www.reddit.com/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,0,0,0.33,[]
1781xnk,Darktrader21,,2023-10-14 23:25:38+00:00,False,,False,False,True,False,/r/datascience/comments/1781xnk/need_help_in_my_senior_project/,Need help in my senior project,"I am graduating soon in a Bachelor in DS and I am starting early on my senior project, it is my first complete DS project I'll be doing so I am sure I would be facing concerns and struggles throughout this project, I have been taking taking some online courses apart from university so I have some basic knowledge to start with, and I am confident that I can get all the necessary data for this project and preprocess it to begin the analysis. 

I just need a data scientist with some decent or more experience that I can contact and use his/her help while pursuing my project (AKA a mentor) , I know most of you guys are busy most of the time, I am not asking to teach me how to crawl or to handle my project yourself, I will only be asking questions for clarifications and using your opinion and review on the progress of my project. 

Yes there exist chatgpt and of course I'll be using its aid, but it won't help me as much as a data scientist who had enough experience to handle real world projects to check the quality of my work. So I hope whoever of you guys is down to help to let me know in the comments, and thanks in advance :) 

The project is about a football team's probability to win the league, the data will be gathered based from the performance stats of the team in the first half of the season, and I'll analyze it to forecast the performance in the next half and calculate the chance of my selected team winning the league upon its rivals which of whom's data will also be considered throughout this project. 

Again thanks in advance for anyone that would be down to help me, I am patiently waiting for your response in the comment section of this post :) or you can contact me directly if you want and I would be very greatful. Peace ✌️",datascience,https://www.reddit.com/r/datascience/comments/1781xnk/need_help_in_my_senior_project/,0,0,0.5,[]
1778u49,linamagr,,2023-10-13 21:11:14+00:00,False,,False,False,True,False,/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,What are good questions to ask in interviews to validate the quality of your future boss?,"Not many people pay attention to this even though most people know that when you are interviewing for your next data scientist roles, you are also interviewing your next boss!

You've done a great job answering all the technical questions, but asking good questions are also critical but not much effort was put into this is what I've seen typically. 

So what are some good questions to ask your next prospect boss?

As a hiring manager myself, here are some of my favorite questions from my best candidates:

**To learn more about the day-to-day:**

* What's the day-to-day like for you (or for a data scientist on your team)?
* What percentage of your time (a DS on the team) is spent on coding?
* What percentage for other tasks? And what are those tasks?

**To learn more about ownership:**

* How are projects assigned across the team?
* How do team members collaborate?
* How is the scope of a project typically determined? 

**There are more you can ask to learn more about scope of projects and to learn more about room for adaptability:**

More detailed questions here:

[https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview](https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview)

What did you ask that got you great insights about your interviewer? 

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,32,93,0.97,"[Comment(id='k4rfsd1'), Comment(id='k4rfiov'), Comment(id='k4rpqb2'), Comment(id='k4rw43t'), Comment(id='k4smlkx'), Comment(id='k4sssbb'), Comment(id='k4ub0fn'), Comment(id='k4roqna'), Comment(id='k4sbobh'), Comment(id='k4wat9l'), Comment(id='k4tq3p5'), Comment(id='k4wj1w9'), Comment(id='k4rrhag'), Comment(id='k4relqv'), Comment(id='k4rrmga'), Comment(id='k4rgaiz'), Comment(id='k4rpran'), Comment(id='k4rx2gv'), Comment(id='k4rwhfo'), Comment(id='k4vsjir'), Comment(id='k4rg0m6'), Comment(id='k4uxdag'), Comment(id='k4spj82'), Comment(id='k4xntiy'), Comment(id='k4rt44w'), Comment(id='k4rzjlx'), Comment(id='k4u620e'), Comment(id='k4vwxu4'), Comment(id='k4rx86l'), Comment(id='k4rwtoa'), Comment(id='k4uxxmm')]"
177zdxe,DansePaladinDanse,,2023-10-14 21:20:34+00:00,False,,False,False,True,False,/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,Can I get a UK perspective on how important personal projects are for beginner data analyst roles?,"I have a degree in computer science and 1 year of experience as a data analyst done in the middle of my degree. Looking online a lot of the advice on standing out recommends doing personal projects. However, it also all seems very US-centric. Data analysts from the UK, how important do you feel personal projects are to get hired for beginner roles?",datascience,https://www.reddit.com/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,1,1,0.67,[Comment(id='k4xpwkj')]
177yjgm,SmokeSlurp,,2023-10-14 20:40:15+00:00,False,,False,False,True,False,/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,What is the best UI creator for DS projects?,"Im new to the Data science community and just started my first job as a robotics engineer. 

Im wondering how I can take my data science skills to the next level and so Ive made [this showcase](https://visualstudycode.com/stochastic-gradient-descent-for-robotics/) on stochastic gradient descent for robotics, as the first step in visualization and UI experience. Let me know your thoughts!",datascience,https://www.reddit.com/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,0,0,0.5,[]
177r3bk,saasthom,,2023-10-14 14:41:54+00:00,False,,False,False,True,False,/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,Data Science Scoping Questions (Looking for feedback from DS consultants),"Hi everyone! I work in the consulting arm of a data science software company. I scope data science projects with my clients regularly using the following questions. Would love some feedback if there is anything missing/I should be asking them in a different way:

Questions about client

* What is your project budget?
* Describe your familiarity with data science and data analytics
* Describe the nature of your business (feel free to include any links to your website)

Questions about the project

* What are the main objectives you want to achieve with this project? Try to be as specific as possible, using numbers
* Describe the current situation (without this project)
* Describe the envisioned situation if the project is a success (e.g. how will you use the project output?)
* Who will benefit from the most from this project? Who else will be impacted?

Questions about the data

* Describe the nature of your data in your own words. (prompts include how do you normally access this data? How is it normally used?)
* What data sources do you have for this project? Where do they come from?
* Are there any public data sources that might help?
* In what format is the data available (e.g., CSV, Excel, SQL Database)?
* Would you consider your data structured, semi-structured, or unstructured?
* How much data do you have (e.g. rows, records, or file size)
* Is it possible to collect more data? Would it be difficult to do so?
* Does your data need to be labeled? If so, what is the corresponding effort?
* How would you rate the quality of the available data? Are there any known issues? (missing values, conflicts, outliers, reliability)
* Please send over an example of your data if possible

Other questions

* What is your current technical set-up? Describe the tools you currently use may be relevant to the project
* Do you foresee any technical integration requirements?
* Is there any additional information or specific requirements that have not been covered? (cybersecurity, data privacy, ethical considerations)

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,0,3,0.81,[]
178744m,leaderdebordel,,2023-10-15 04:03:36+00:00,False,,False,False,True,False,/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,What’s the best AI tool for statistical coding?,"Is git copilot going to be a major asset for stats coding, in R for instance?",datascience,https://www.reddit.com/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,4,0,0.27,"[Comment(id='k4y8f7a'), Comment(id='k4zpt2l'), Comment(id='k4yk9kk')]"
177xuon,lovelylavenderchild,,2023-10-14 20:06:55+00:00,False,,False,False,True,False,/r/datascience/comments/177xuon/question_on_school_options/,Question on School options,"Hey there! 

I'm currently transferring to Indiana University Northwest in Spring 2024 from a community college for my Data Science degree and got an internship next summer. 

The thing is I also applied to UIC and got rejected with some weird reasoning but after talking to a faculty member, they were recommending I take a break and apply again in the summer to undecided and then transferring into the Data Science program.

I'm wondering if I should consider transferring to UIC instead and also if that hinders my internship for Summer 2024.",datascience,https://www.reddit.com/r/datascience/comments/177xuon/question_on_school_options/,3,1,0.67,"[Comment(id='k4xo8hj'), Comment(id='k4wzmrp'), Comment(id='k4xqj5z')]"
1775fq0,TheEnlightenedMan,,2023-10-13 18:34:28+00:00,False,,False,False,True,False,/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,"In your time working with data science at a corporation, what cool things did you pick up / learn that school didn't teach you?",Can't wait to read your comment!,datascience,https://www.reddit.com/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,64,107,0.99,"[Comment(id='k4r4t1p'), Comment(id='k4qy557'), Comment(id='k4rasof'), Comment(id='k4rcy4a'), Comment(id='k4r8ri9'), Comment(id='k4rd1tq'), Comment(id='k4rliaj'), Comment(id='k4qq0wg'), Comment(id='k4rhtnv'), Comment(id='k4rhqkl'), Comment(id='k4r7e31'), Comment(id='k4uovsr'), Comment(id='k4wealo'), Comment(id='k4rydfm'), Comment(id='k4us0sp'), Comment(id='k4tdpri'), Comment(id='k4s2x4v'), Comment(id='k4sw8yz'), Comment(id='k4s41d9'), Comment(id='k4weayr'), Comment(id='k4rdmos'), Comment(id='k4rsix1'), Comment(id='k4wpugb'), Comment(id='k4rv47g'), Comment(id='k4rlt7p'), Comment(id='k4rkh7j'), Comment(id='k4ucncu'), Comment(id='k4snkui'), Comment(id='k4wqk42'), Comment(id='k4ru3z1'), Comment(id='k4savjs'), Comment(id='k4r150u'), Comment(id='k4r9411'), Comment(id='k4wyxkt'), Comment(id='k4u37u0'), Comment(id='k4rsckg'), Comment(id='k4rvjfr'), Comment(id='k4tfrw2'), Comment(id='k4u3069'), Comment(id='k4sarao'), Comment(id='k4r55zd'), Comment(id='k4rdgbo'), Comment(id='k4yru8a'), Comment(id='k4sm858'), Comment(id='k4t118m'), Comment(id='k4td6o8'), Comment(id='k4timyt'), Comment(id='k4ucduv'), Comment(id='k5z2sl4'), Comment(id='k4rtn96'), Comment(id='k4u3z43'), Comment(id='k4vafmv'), Comment(id='k5z453e'), Comment(id='k4viak2'), Comment(id='k5acz55'), Comment(id='k5z7z9n'), Comment(id='k5afg44'), Comment(id='k605yaz'), Comment(id='k5zie7c'), Comment(id='k5amhlb'), Comment(id='k5zq96p'), Comment(id='k5an4rc'), Comment(id='k5zvtn4')]"
177479m,VodkaRain,,2023-10-13 17:38:39+00:00,False,,False,False,True,False,/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,It's been two months since I was laid off as a DS. Any advice on how to deal with current market.,"Two months ago, I was laid off from my role as a data scientist after 2 years. It was ""reduction in force"" and my role was affected. 

Some background:

* Previous Role: Data Scientist 1
* 2 yrs of xp, master's in statistics
* Had a big tech company as long term client at previous role (13 months)
* I was in top 10% of performers (98% billable hours and internal recognition for innovation)
* Was confirmed for promotion.

It took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I'm laid off. What should I do about this market? I barely see any positions open for someone like my self.",datascience,https://www.reddit.com/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,84,124,0.92,"[Comment(id='k4qhkaa'), Comment(id='k4qj6lo'), Comment(id='k4qqr07'), Comment(id='k4qx50t'), Comment(id='k4qvjze'), Comment(id='k4qs8tk'), Comment(id='k4ryzjw'), Comment(id='k4rs89d'), Comment(id='k4sawbd'), Comment(id='k4s57kb'), Comment(id='k4rh723'), Comment(id='k4sodwh'), Comment(id='k4r67yr'), Comment(id='k4r0u5t'), Comment(id='k4rvu6q'), Comment(id='k4t8h96'), Comment(id='k4tpwwm'), Comment(id='k4tvxbt'), Comment(id='k4u5idv'), Comment(id='k4uoucs'), Comment(id='k4uqyao'), Comment(id='k4vizd9'), Comment(id='k4wrfaa'), Comment(id='k4ygmhf'), Comment(id='k4zrqwl'), Comment(id='k4qmhnp'), Comment(id='k4r3br9'), Comment(id='k4v59ch'), Comment(id='k4qvf1l'), Comment(id='k4rj2rf'), Comment(id='k4seuhi'), Comment(id='k4v7mx2'), Comment(id='k4rax06'), Comment(id='k4r1ia8'), Comment(id='k4urdh8'), Comment(id='k4sbrgq'), Comment(id='k4s70bh'), Comment(id='k4svpq5'), Comment(id='k4rhwcq'), Comment(id='k4rx8ts'), Comment(id='k4ugu0f'), Comment(id='k4rthxu'), Comment(id='k4qudeq'), Comment(id='k4r75o5'), Comment(id='k4r5e0n'), Comment(id='k4rrxv3'), Comment(id='k4tjtux'), Comment(id='k4uqzts'), Comment(id='k4saee8'), Comment(id='k4t4o5l'), Comment(id='k4s03xt'), Comment(id='k4vciho'), Comment(id='k4s2t8d'), Comment(id='k4stdta'), Comment(id='k4qv0rg'), Comment(id='k4reren'), Comment(id='k4soque'), Comment(id='k4rbear'), Comment(id='k4sp1gb'), Comment(id='k4rboda'), Comment(id='k4syy0z'), Comment(id='k4tqqcb'), Comment(id='k4wnvwv'), Comment(id='k4rtndc'), Comment(id='k4s1uoj'), Comment(id='k4s9sto'), Comment(id='k4tepte'), Comment(id='k4u3sbj'), Comment(id='k4splst'), Comment(id='k4roqmw'), Comment(id='k4stxj1'), Comment(id='k4tfjy6'), Comment(id='k4v02mz'), Comment(id='k4uji45'), Comment(id='k4s27u3'), Comment(id='k4s9wvm'), Comment(id='k4sbjtv'), Comment(id='k4rptdq'), Comment(id='k4su23z'), Comment(id='k4usbm2'), Comment(id='k4tzorn'), Comment(id='k4xhl0h'), Comment(id='k4znd0i'), Comment(id='k4sbwko'), Comment(id='k4u8ken')]"
177q65k,IcaroRibeiro,,2023-10-14 13:58:17+00:00,False,,1697292201.0,False,True,False,/r/datascience/comments/177q65k/do_i_need_more_statistics/,Do I need more statistics?,"Hello everyone,

&#x200B;

I'm relatively new to the field of Data Science, with approximately 6 months of experience. Prior to this role, I worked as a Machine Learning Engineer for a year and a half.

In my current position, I spend a significant portion of my time conducting data analysis, applying basic statistical techniques (hypothesis testing, regression analysis, etc), and developing standard banking models (so far, I've worked in churn rate prediction, client clustering, and currently studying to help building a recommendation system)

I'm currently pursuing a Master's degree in Computer Science, with a research focus on weather forecasting. This research involves the use of time series analysis and machine learning. As we progress in our research, we are also delving into deep learning models, the goal is to build state of art models.

My academic background is in computer science. In both bachelor's and master's I've completed classes in basic linear algebra, three levels of calculus (up to Multivariate Calculus and First Order Differential Equations), discrete mathematics, two statistics courses, one time series analysis course, and several classes focused on machine learning algorithms and artificial intelligence.

While I generally have a good understanding of the mathematical principles behind machine learning models, there are certain areas where I struggle. For instance, I've never fully comprehended why the kernel trick is effective in SVMs (got the intuition, but not the maths)

When it comes to statistics, I feel that my knowledge is lacking. I can effectively work with machine learning frameworks, but there are specific statistical topics where my knowledge is either superficial or non-existent. These include:

&#x200B;

* Post hoc analysis
* Survival analysis
* Multivariate statistics, such as PCA, MANOVA, and Factor analysis
* Markov Processes

Given my current role and academic pursuits, I'm wondering if it's essential to address these knowledge gaps immediately or if it would be more practical to focus on completing my Master's degree first.

I would greatly appreciate any guidance on how to begin studying these statistical concepts effectively.",datascience,https://www.reddit.com/r/datascience/comments/177q65k/do_i_need_more_statistics/,3,2,0.76,"[Comment(id='k4um0p4'), Comment(id='k4v3ih7'), Comment(id='k4un9g5')]"
177cfpy,Dataman-Calgary,,2023-10-13 23:57:43+00:00,False,,False,False,True,False,/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,Hourly salary Data Scientist Canada,"I got contacted by a recruiter today for an immediate hire for an ""Intermediate level data scientist"" at an energy company in Calgary. This would be a contract position for one year, full-time, hybrid (2 days from home per week), and required 5 years of experience.

The salary was 46.5 CAD/hour, no benefits and required you as a contractor to be incorporated.

I have a PhD, a completed post doctoral position, over 3 years of work experience as an independent contractor in a variety of industries as a data scientist and was honestly surprised by the low hourly rate. The majority of my clients have not been from the energy sector though, so maybe this is why?

After mentioning that this was below the hourly rate that I would consider a position, comparing this to a base salary of a full time employee coming with benefits such as healthcare, pension plan, paid time off, etc, while also not requiring the overhead of costs you have as a incorporated business in regards to bookkeeping, invoicing, taxes, etc, the rate was increased to 47 CAD/hour. 

I thought I'd throw it on here to keep these kind of salaries transparent and see if other Calgary/Canada-based data scientists have had similar experiences in this job market.",datascience,https://www.reddit.com/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,14,25,0.86,"[Comment(id='k4sggdd'), Comment(id='k4s47c7'), Comment(id='k4s3ijd'), Comment(id='k4tvhre'), Comment(id='k4ucj3c'), Comment(id='k4st4bw'), Comment(id='k4u695u'), Comment(id='k4uf8vb'), Comment(id='k4wjrjr'), Comment(id='k4s4wmg'), Comment(id='k4s4sq8'), Comment(id='k4w371l'), Comment(id='k4v31bx'), Comment(id='k4s82k0')]"
177qw2v,fouried96,,2023-10-14 14:32:12+00:00,False,,False,False,True,False,/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,How much stock would you put in Andrew Ng's ML/DL course?,"Hi! I have a Bsc (Honours) in Applied Mathematics, and I have done various courses on Udemy on ML and DL by SuperDataScience. I have also done some self work on Kaggle.
I am currently a Robotics Process Automatiom (RPA) developer. I'd love to move into the DS/ML/DL/AI space. I do of course use some AI tools within my automation solutions. I miss doing the Mathematics though. I really loved studying it.

Anyways, it's been a while since I've done any studying or self-work in the AI space, and I was wondering what your thoughts on the renowned Andrew Ng Deep Learning course are? I know I'd really enjoy doing it, but how much would it help me in getting closer to a job in the AI space?

Note: I haven't done any mathematics for quite a few years, as a I graduated end of 2018, so I would also need to spend sometime relearning some of the work I learnt in my degree. I also do not want to go into academia, despite my love of research, because it often involves lecturing (which I dislike) and it will generally not pay as well - I want to have enough money to live a comfortable life and travel the world.

Thanks",datascience,https://www.reddit.com/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,9,1,0.53,"[Comment(id='k4ulrut'), Comment(id='k4vatrc'), Comment(id='k4x8r1n'), Comment(id='k4vkazj'), Comment(id='k4uoalo'), Comment(id='k4vjscx'), Comment(id='k4z390w'), Comment(id='k4up8ph'), Comment(id='k4zx5c8')]"
177q2t2,Final_Teach_5838,,2023-10-14 13:53:54+00:00,False,,False,False,True,False,/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,Choosing the Right Academic Path for Job Security and Career Growth in Europe,"After spending considerable time researching on the Data Science (DS) field, I've noticed two significant challenges: 

1. The difficulty of breaking into DS as a fresher 
2. The necessity for a specialized niche in a particular domain, such as healthcare or business, which often requires prior field experience or a related bachelor's degree.

I'm a final year bachelor's in Technology student (specialization-Information Technology ) and possess average coding skill. My aspirations involve pursuing higher education and professional opportunities in Europe, particularly in German universities.

Despite some institutions prioritizing revenue generation and offering below average DS programs(as repeatedly mentioned in this sub), low cost German public universities offers numerous DS programs taught in English, welcoming international students. Personally, I'm drawn to the profound impact DS can have on decision-making processes (specifically policy making), which makes it a very rewarding field.

I'm at a crossroads between pursuing a Master's in Computer Science (CS) with a DS track or opting for a specialized Data Science degree. Which academic path would provide more job security and a stronger foothold in the European job market for a background like mine?

There are some courses that have intersection of two disciplines like policy making and DS. Will those courses limit me to certain domain and thus affect my chances of getting jobs? or Will the specialization in a field actually be more beneficial?

Furthermore, I'm curious if I can smoothly transition into DS roles after gaining several years of experience working with other technologies in the IT sector.

Thank you in advance for your time and guidance!",datascience,https://www.reddit.com/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,5,1,0.67,"[Comment(id='k4ugjrn'), Comment(id='k4wlnp8'), Comment(id='k4ui7ng'), Comment(id='k55vzps'), Comment(id='k566mki')]"
177lhhw,malirkan,,2023-10-14 09:15:59+00:00,False,,False,False,True,False,/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,"What were the worst misconceptions/requirements of senior management in data science projects in connection with web applications (lead generation & churn, content generation, data driven marketing, etc.)?"," TL;DR: **Biggest fails and your most loved data science solutions** in **web related applications**, which you have experienced **in your data science career**.

*(Similar posts were previously removed for unclear reasons, so I have reworded the post. Please let me be clear: this is not a homework exercise, nor is it breaking any other rule in my opinion! My last attempt...)*

I  am just curious in your personal data science experience of common web  applications like e-commerce, lead generation, web marketing and so on.

Upper   management often wants solutions or applications which have a positive  imapct in selling products, gaining more customers or at least improve  existing products and services which can be used in marketing. And you  know, sometimes it's all about slapping the ""AI"" label on products.

What  were the worst misconceptions/requirements of senior management?  In  contrast: What unexpectedly  worked well? I.e. Data may be very limited  on training due to data  protection rules, but still lead to ""good""  models which are production  ready.

In  my experience it was not  a big deal to produce a working model. But I  failed to deploy or  integrate the model into an existing solution. The  guys which were  responsible to implement the model api failed to  present the results in a  nice way or the UX was just terrible.

Another  fail requirement: ""generate automatic A/B landing pages in a web  application"". So the requirement was to automatically generate different  versions of landing pages based on the visitor flows (or origin  parameters: organic vs direct hits). It would be technically possible,  but imho at least 2000h of work ot get good results.

I look forward to an exciting exchange of experiences!",datascience,https://www.reddit.com/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,2,2,0.6,"[Comment(id='k4uuejs'), Comment(id='k4y8qvs')]"
177ffq9,CatalystNZ,,2023-10-14 02:35:44+00:00,False,,False,False,True,False,/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,"For binary classification, where the focus is to avoid FP, can you help with which metrics to use?","I hope it's ok for me to ask questions here, please point me elsewhere if that's not the case.

I have a binary classification model for identifying profitable trades, and I have just learned how AUC works (which took my smooth brain a lot longer than perhaps it would for you fine folk).

Anyway, would someone mind providing some pointers about which Classification metrics (Accuracy, AUC are the ones I already know) would be beneficial to understand, when comparing and understanding models? Or is AUC the de-facto standard?

I'm reading books on this topic, but finding that it can be difficult to follow.

Thanks",datascience,https://www.reddit.com/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,8,2,0.67,"[Comment(id='k4sn9hk'), Comment(id='k4ss2zr'), Comment(id='k4t53bz'), Comment(id='k4t5vxz'), Comment(id='k4taghd'), Comment(id='k4told1'), Comment(id='k4ts3mc'), Comment(id='k4twp2r')]"
177dfyv,Dr_Rhombus,,2023-10-14 00:49:17+00:00,False,,False,False,True,False,/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,"Customer Growth Accounting (churn, resurrections, etc) framework","Does anyone have a good resource to share that lays out customer growth accounting framework (churn, resurrections, etc), and how it's used?",datascience,https://www.reddit.com/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,0,2,1.0,[]
1778xvq,hownottopetacat,,2023-10-13 21:15:48+00:00,False,,False,False,True,False,/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,How does your team organize ideas?,"While I understand that some industries have a pretty shallow pool of ideas, what do those with a lot of ideas use to organize them into a way that allows project tracking and or understanding relationships between them?",datascience,https://www.reddit.com/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,3,3,1.0,"[Comment(id='k4rwjbr'), Comment(id='k4vb0jv'), Comment(id='k51o4ea')]"
177b4po,RaccoonFew5715,,2023-10-13 22:53:29+00:00,False,,False,False,True,False,/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,Demand forecasting FMCG company,"Hello guys,  im kinda new in the data science area,  i was wondering what might be the best approach to tacle a demand forecasting  per sku project for the next 6 months in an fmcg distribution company , i have the sales per customer per sku per salesman for the last 2 years ( daily) but i prefer to give more weight to the last year data since its very different fot the previous one.

Ps: the customer data is not always accurate since the salesman can sometimes close a sale with partner A and pass it as its customer B , so the sale quantity per sku is always correct, the customer not always (75% accurate)

Thaanks in advance!!",datascience,https://www.reddit.com/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,19,2,0.75,"[Comment(id='k4rznm9'), Comment(id='k4tqbvg'), Comment(id='k4s9ea5'), Comment(id='k4sblgh'), Comment(id='k4tuzps'), Comment(id='k4tlejk'), Comment(id='k4tjwzs'), Comment(id='k4tyc0t'), Comment(id='k4uugx5'), Comment(id='k4u438m'), Comment(id='k4uw326'), Comment(id='k4uvapt'), Comment(id='k4uip70'), Comment(id='k4uwlza'), Comment(id='k4uw14w'), Comment(id='k4uizjd'), Comment(id='k4uxckw'), Comment(id='k4uxr67'), Comment(id='k4uy3aq')]"
176nzqe,Smart_Donut_9558,,2023-10-13 02:13:16+00:00,False,,False,False,True,False,/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,"Got hit with a layoff today but they offered to shop me around internally, any advice?","I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a ""reorganization"" by a higher up and that my role had been eliminated.

Anyways, they offered to help shop me around to some other internal teams and I'll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I'd really appreciate it.

Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there's no training period, I'm already familiar with all the datasets and industry. I'm going to spend tomorrow trying to summarize all the work I've done at the company since I got hired.

Some other key details below:

- Was told I was rehire eligible. They specifically said that severance wouldn't be impacted if I boomeranged unless I switched teams before final date (1 month).
- Worked for over a year and have 2.5 years of experience in data science.
- Probably was on the bottom half of performers, but I wasn't the worst. I was the most recent hire though. My boss's boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.
- The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.

I'm going to keep the ranting to a minimum because this post is pretty identifiable, but I'm honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that's life but god damn.",datascience,https://www.reddit.com/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,45,85,0.91,"[Comment(id='k4njdny'), Comment(id='k4nkm07'), Comment(id='k4nl72h'), Comment(id='k4nmjdv'), Comment(id='k4nn7x8'), Comment(id='k4nwtjh'), Comment(id='k4o2t6d'), Comment(id='k4nslof'), Comment(id='k4oksx9'), Comment(id='k4oviw9'), Comment(id='k4papv0'), Comment(id='k4phhz7'), Comment(id='k4nz96i'), Comment(id='k4od8e8'), Comment(id='k4og91k'), Comment(id='k4ow3gp'), Comment(id='k4pizfa'), Comment(id='k4pw2bz'), Comment(id='k4qbbzd'), Comment(id='k4qku9f'), Comment(id='k4qqm8n'), Comment(id='k4ribso'), Comment(id='k4s9v3p'), Comment(id='k4usoks'), Comment(id='k4nkdso'), Comment(id='k4nm3ca'), Comment(id='k4oos8d'), Comment(id='k4ol3i1'), Comment(id='k4ri5mt'), Comment(id='k4w5rbr'), Comment(id='k4nn5hk'), Comment(id='k4nn3yw'), Comment(id='k4nvdt9'), Comment(id='k4q77ye'), Comment(id='k4qg84e'), Comment(id='k4pf6ql'), Comment(id='k4pm5eq'), Comment(id='k4rmurr'), Comment(id='k4pf2k5'), Comment(id='k4pr2r6'), Comment(id='k4rn7cm'), Comment(id='k4q88hd'), Comment(id='k4roa1l'), Comment(id='k4qc1in'), Comment(id='k4rpp6y')]"
1771460,Born_Buy7037,,2023-10-13 15:17:53+00:00,False,,False,False,True,False,/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,What are the best practices for interviewing data science candidates?,My experience as a candidate wasn't always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate's technical aptitude and work ethic on the job.,datascience,https://www.reddit.com/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,6,7,0.77,"[Comment(id='k4py03o'), Comment(id='k4pyade'), Comment(id='k4rel25'), Comment(id='k4st7tr'), Comment(id='k4smwq7'), Comment(id='k54dwz6')]"
177dgos,Dr_Rhombus,,2023-10-14 00:50:20+00:00,False,,False,False,True,False,/r/datascience/comments/177dgos/holdout_experiments/,Holdout Experiments,Does anyone have a good resource to share on long term holdout experiments and what they're used for?,datascience,https://www.reddit.com/r/datascience/comments/177dgos/holdout_experiments/,0,1,1.0,[]
1778n6i,elffuostnevel,,2023-10-13 21:02:47+00:00,False,,False,False,True,False,/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/,Book recommendations about Descriptive Statistics for an Economics freshman.,"Good day to everyone.  I started taking a course called ""Descriptive Statistics"" at university and I want to improve myself outside of class.  The professor recommended Cleff's ""Exploratory Data Analysis"" as a reference book, but I would also like to hear your opinions.  Thank you.",datascience,https://www.reddit.com/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/,0,2,0.75,[]
1773x9b,RebeccaMayy,,2023-10-13 17:25:32+00:00,False,,False,False,True,False,/r/datascience/comments/1773x9b/i_want_to_improve_more/,I want to improve more!,"Hi everyone,



First time posting here so not sure this is where it belongs.



I do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I've not had much experience in SQL or Power BI, neither of which the internship need either.



I wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?



Nothing to publish, solely extra academic learning I can play with. Thanks !",datascience,https://www.reddit.com/r/datascience/comments/1773x9b/i_want_to_improve_more/,1,3,1.0,[Comment(id='k4r7kn5')]
176zysn,rubiesordiamonds,,2023-10-13 14:25:23+00:00,False,,False,False,False,False,/r/datascience/comments/176zysn/james_lamb_light_gbm_on_getting_into_open_source/,James Lamb (Light GBM) on getting into open source from a data science background,,datascience,https://open.substack.com/pub/onceamaintainer/p/once-a-maintainer-james-lamb?r=2773u5&utm_campaign=post&utm_medium=web,0,4,0.84,[]
1772in6,ResearchShort4056,,2023-10-13 16:20:34+00:00,False,,False,False,True,False,/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,Fraud Detection Machine learning project,"https://preview.redd.it/ha6kw13ewztb1.png?width=966&format=png&auto=webp&s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,1,2,0.75,[Comment(id='k4rt3mg')]
17666j9,Excellent_Cost170,,2023-10-12 12:48:01+00:00,False,,False,False,True,False,/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,How ballsy do you have to be to take on the role of Senior Data Scientist at both McDonald's and Burger King simultaneously (remote)," If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? ",datascience,https://www.reddit.com/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,124,302,0.88,"[Comment(id='k4k0f5j'), Comment(id='k4k3ve5'), Comment(id='k4k31ot'), Comment(id='k4k1dmn'), Comment(id='k4k5evi'), Comment(id='k4k7qnu'), Comment(id='k4k57r2'), Comment(id='k4kba4a'), Comment(id='k4kfqfh'), Comment(id='k4kdpiy'), Comment(id='k4kxunf'), Comment(id='k4kinq0'), Comment(id='k4l0lcz'), Comment(id='k4kb4zf'), Comment(id='k4kax1i'), Comment(id='k4k30i1'), Comment(id='k4kqudx'), Comment(id='k4lhcsa'), Comment(id='k4n7vqo'), Comment(id='k4l9l4e'), Comment(id='k4lel3h'), Comment(id='k4ll59g'), Comment(id='k4raz0f'), Comment(id='k4kb1dc'), Comment(id='k4ks3fa'), Comment(id='k4k47n3'), Comment(id='k4kewct'), Comment(id='k4l7lns'), Comment(id='k4k62zl'), Comment(id='k4k9tyg'), Comment(id='k4kbk9h'), Comment(id='k4kjgym'), Comment(id='k4kjm7l'), Comment(id='k4klcjv'), Comment(id='k4kn5su'), Comment(id='k4knqod'), Comment(id='k4kwz4k'), Comment(id='k4l0dk3'), Comment(id='k4l0s81'), Comment(id='k4l6ei8'), Comment(id='k4l9moc'), Comment(id='k4lkgr2'), Comment(id='k4m1l47'), Comment(id='k4m1z0r'), Comment(id='k4m4cbu'), Comment(id='k4mbzzb'), Comment(id='k4mcaz6'), Comment(id='k4mew4o'), Comment(id='k4mf9xh'), Comment(id='k4miehh'), Comment(id='k4n5ck3'), Comment(id='k4n82ib'), Comment(id='k4nc7pl'), Comment(id='k4nm2vm'), Comment(id='k4o7r2w'), Comment(id='k4pxdrw'), Comment(id='k4pzcku'), Comment(id='k4qh5c6'), Comment(id='k4sgvez'), Comment(id='k4x1n28'), Comment(id='k4yiuns'), Comment(id='k4k0mra'), Comment(id='k4leomw'), Comment(id='k4ktwyc'), Comment(id='k4kfmqj'), Comment(id='k4kz21b'), Comment(id='k4km0ly'), Comment(id='k4k2s2h'), Comment(id='k4k6zdf'), Comment(id='k4kaj3y'), Comment(id='k4kl8f7'), Comment(id='k4knqwz'), Comment(id='k4ll1i3'), Comment(id='k4kdaod'), Comment(id='k4lxc29'), Comment(id='k4l8e1u'), Comment(id='k4kmxmn'), Comment(id='k4nzn9i'), Comment(id='k4llbj1'), Comment(id='k4m0tog'), Comment(id='k4m2u0n'), Comment(id='k4ktbla'), Comment(id='k4k12pj'), Comment(id='k4l3jfe'), Comment(id='k4wib49'), Comment(id='k4l6v4d'), Comment(id='k4lmpas'), Comment(id='k4lsozz'), Comment(id='k4pzihu'), Comment(id='k4kjgig'), Comment(id='k4kbx3z'), Comment(id='k4krv2h'), Comment(id='k4kt2no'), Comment(id='k4l3gsu'), Comment(id='k4n9n3n'), Comment(id='k4l6mm9'), Comment(id='k4ka7fb'), Comment(id='k4lx6ur'), Comment(id='k4mxaje'), Comment(id='k4qqdcg'), Comment(id='k4qv36o'), Comment(id='k4l7lie'), Comment(id='k4kjlg5'), Comment(id='k4m29l6'), Comment(id='k4l3wnz'), Comment(id='k4m770l'), Comment(id='k4l7u2t'), Comment(id='k4kw6a0'), Comment(id='k4l3u2c'), Comment(id='k4l8jsh'), Comment(id='k4lbexq'), Comment(id='k4liam0'), Comment(id='k4n4p91'), Comment(id='k4n70la'), Comment(id='k4o2d1i'), Comment(id='k4n4tll'), Comment(id='k4sirg3'), Comment(id='k4mkag3'), Comment(id='k4lb47k'), Comment(id='k4m8mun'), Comment(id='k4lqwy9'), Comment(id='k4nc1m1'), Comment(id='k4ny6hs'), Comment(id='k4ldlas'), Comment(id='k4lgduv')]"
1775rtq,Aggravating_Sand352,,2023-10-13 18:49:21+00:00,False,,False,False,True,False,/r/datascience/comments/1775rtq/guidance_on_language_model/,Guidance on Language Model,I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I'd preferably like to use an offline language model or one that would be safe to put in our code,datascience,https://www.reddit.com/r/datascience/comments/1775rtq/guidance_on_language_model/,5,0,0.33,"[Comment(id='k4qvrqk'), Comment(id='k4qudyt'), Comment(id='k4s384b'), Comment(id='k4t5ci6'), Comment(id='k54em1e')]"
1775qrn,TechSavvyGal,,2023-10-13 18:48:01+00:00,False,,False,False,True,False,/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,Fetching User Details for Triggered AWS Glue Job,"I'm implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as ""created by"" and ""last modified by."" For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I'm aware of CloudTrail's Lookup Events API, but I'm looking for an alternative approach to retrieve this information from the server-side without using a client library.",datascience,https://www.reddit.com/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,0,1,1.0,[]
176yuks,lfelipecl,,2023-10-13 13:32:31+00:00,False,,1697204435.0,False,True,False,/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,Guidance to analyze data reliability and variables related,"Hello guys and girls,

I'm a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.

All this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.

But to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. 

So, I have this database with data not audited and data audited with it's outcomes: data needed to be corrected and don't.

We want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc

So I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it's not representative as it's not a random sample, so how to look to it? 

Obs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.

Thanks in advance.",datascience,https://www.reddit.com/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,1,2,1.0,[Comment(id='k4sl9md')]
17770fv,Kairo1004,,2023-10-13 19:47:06+00:00,False,,False,False,False,False,/r/datascience/comments/17770fv/how_to_perform_monte_carlo_simulation_on_the/,How to Perform Monte Carlo Simulation on the Stock Market,,datascience,https://www.youtube.com/watch?v=O3K4nrXyqwc,0,0,0.38,[]
176de18,OutcomeSerious,,2023-10-12 18:07:47+00:00,False,,False,False,True,False,/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,What is a personal side project that you have worked on that has increased your efficiency or has saved you money?,"This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.


For example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it's likely the cheapest price in the interval that I should place the order.


I'm currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don't usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!",datascience,https://www.reddit.com/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,38,55,0.93,"[Comment(id='k4miiry'), Comment(id='k4lh080'), Comment(id='k4m78jg'), Comment(id='k4oaoye'), Comment(id='k4lluil'), Comment(id='k4lvvv9'), Comment(id='k4mxq8i'), Comment(id='k4m5m3z'), Comment(id='k4mqzbt'), Comment(id='k4pjpno'), Comment(id='k4nrhpd'), Comment(id='k4ptabo'), Comment(id='k4q8pa6'), Comment(id='k4rviat'), Comment(id='k4pqruy'), Comment(id='k4pwoqq'), Comment(id='k4ojbyi'), Comment(id='k4ojzn8'), Comment(id='k4mf2ti'), Comment(id='k4psoaf'), Comment(id='k4n9rfm'), Comment(id='k4qg3q7'), Comment(id='k4qfyhx'), Comment(id='k6ls2ag'), Comment(id='k4ov9f6'), Comment(id='k4mnkow'), Comment(id='k4mzijx'), Comment(id='k4pl4ia'), Comment(id='k4revky'), Comment(id='k4q4dgq'), Comment(id='k4mwcab'), Comment(id='k4n1zjw'), Comment(id='k4phuq6'), Comment(id='k4r1ezd'), Comment(id='k4qa4sy'), Comment(id='k4mxa7w'), Comment(id='k4pjr0j'), Comment(id='k4qb9dy')]"
1771jsh,Purple_Bite_9579,,2023-10-13 15:37:09+00:00,False,,False,False,True,False,/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,Traffic Data Source for Senior Project,"Hi All, 

I am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).

I have store sales & customer but need the traffic data. 

How would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).

I tried government data and websites and the information is available but not to the public and it isn't quite the information needed. 

Welcoming all suggestions, thanks everyone!",datascience,https://www.reddit.com/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,1,1,1.0,[Comment(id='k4qjuob')]
176tcip,MLwithMe1617,,2023-10-13 07:44:36+00:00,False,,False,False,False,False,/r/datascience/comments/176tcip/dive_into_a_comprehensive_guide_on_multilinear/,"📊💡 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! 📈🧪",,datascience,https://www.youtube.com/watch?v=SHa-58-n6ew,0,4,1.0,[]
1777d0q,Zestyclose-Ad-7154,,2023-10-13 20:03:56+00:00,False,,False,False,True,False,/r/datascience/comments/1777d0q/ocean_protocol/,Ocean protocol,What do you think guys -> [https://twitter.com/Cesar\_Ges/status/1712541730053173280](https://twitter.com/Cesar_Ges/status/1712541730053173280),datascience,https://www.reddit.com/r/datascience/comments/1777d0q/ocean_protocol/,0,0,0.33,[]
1763k33,Exotic_Avocado6164,,2023-10-12 10:18:44+00:00,False,,False,False,True,False,/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/,"If you were starting over again, How would you go about getting a Data Science job?",,datascience,https://www.reddit.com/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/,66,104,0.93,"[Comment(id='k4jx3ao'), Comment(id='k4kdy97'), Comment(id='k4kgdea'), Comment(id='k4jlygj'), Comment(id='k4jks3q'), Comment(id='k4k0dg3'), Comment(id='k4k9kw2'), Comment(id='k4l6kq7'), Comment(id='k4k5ujf'), Comment(id='k4jsesq'), Comment(id='k4k63cc'), Comment(id='k4ks9rs'), Comment(id='k4k7907'), Comment(id='k4my79v'), Comment(id='k55jrbq'), Comment(id='k4k4obv'), Comment(id='k4o9d1k'), Comment(id='k4kri56'), Comment(id='k4ma9ff'), Comment(id='k4n2lsh'), Comment(id='k4n3dpy'), Comment(id='k4nd9d1'), Comment(id='k4ns7td'), Comment(id='k4o4rdn'), Comment(id='k4p024a'), Comment(id='k4su34r'), Comment(id='k52w1dw'), Comment(id='k4m6e8m'), Comment(id='k4kyil9'), Comment(id='k4mlvlt'), Comment(id='k4wpb8l'), Comment(id='k4mjja4'), Comment(id='k4nnkgr'), Comment(id='k4oog3q'), Comment(id='k4qq54j'), Comment(id='k4que6s'), Comment(id='k4pu1xl'), Comment(id='k4k75vr'), Comment(id='k4kpy9g'), Comment(id='k4k75n4'), Comment(id='k4k6tq1'), Comment(id='k4jnm7g'), Comment(id='k4k73lo'), Comment(id='k4k2fbe'), Comment(id='k4kvlaf'), Comment(id='k4n2mu2'), Comment(id='k4ougsu'), Comment(id='k4kiyph'), Comment(id='k4krjt1'), Comment(id='k4lz4pi'), Comment(id='k4lzzqq'), Comment(id='k4jnv23'), Comment(id='k4jnz3c'), Comment(id='k4k712b'), Comment(id='k4kq2q5'), Comment(id='k4lhw8l'), Comment(id='k4l3zjw'), Comment(id='k4k7a9n'), Comment(id='k4k423i'), Comment(id='k4l35sd'), Comment(id='k4kfug4'), Comment(id='k4kgv19'), Comment(id='k4l9bcj'), Comment(id='k4l9oez'), Comment(id='k4lamqy'), Comment(id='k4lh1av')]"
176t8at,Additional_Guide5439,,2023-10-13 07:35:42+00:00,False,,False,False,True,False,/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,Seeking Recommendations for Multivariate Time Series Analysis Resources with a Focus on Economics/Finance and R Applications,"Hello everyone,

I recently completed **Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition**. It's a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I'm looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any **books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)**? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?",datascience,https://www.reddit.com/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,3,2,1.0,"[Comment(id='k4t70qu'), Comment(id='k4tmvc8'), Comment(id='k4t7frt')]"
1767l3b,LossFirst2657,,2023-10-12 13:55:57+00:00,False,,False,False,True,False,/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/,How much of an effect does this job market have on people who were Data Scientists for a solid 3-5 years?,Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.,datascience,https://www.reddit.com/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/,25,49,0.91,"[Comment(id='k4kegb1'), Comment(id='k4kchvy'), Comment(id='k4kwmaw'), Comment(id='k4kjbyj'), Comment(id='k4kqvkc'), Comment(id='k4ln1vt'), Comment(id='k4k9t0t'), Comment(id='k4ks6f4'), Comment(id='k4ndsaz'), Comment(id='k4n3w40'), Comment(id='k4qtfbi'), Comment(id='k4khilt'), Comment(id='k4n2g4g'), Comment(id='k4kql53'), Comment(id='k4l0f4f'), Comment(id='k4mjswr'), Comment(id='k4m40om'), Comment(id='k4kp0hp'), Comment(id='k4ngj42'), Comment(id='k4kct8y'), Comment(id='k4ldvj2'), Comment(id='k4mhc1j'), Comment(id='k4kr0x3'), Comment(id='k4o1ldr'), Comment(id='k4llm1w')]"
176uhmx,FrancisGrant1,,2023-10-13 09:08:14+00:00,False,,False,False,True,False,/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,Guides that explore statistical theory and concepts through analysis in R using tidyverse,"During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field's ""Discovering Statistics Using R"" book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.

  
Several years later, I've left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field's ""Discovering Statistics Using R"", which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.

  
As a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don't know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,1,1,0.6,[Comment(id='k4pceql')]
176tcyw,sarafpiyush98,,2023-10-13 07:45:33+00:00,False,,False,False,True,False,/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,Alphanumeric Search Algorithm?,"I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are \~ 150k stores in the dataset.

I can distribute these into \~21k regions with varying number of stores (max \~5k) and search locally within and that aligns with the problem statement.

My current method involves:  
Loop for region  
Calculate distance of first store from all other stores  
Loop for each store  
dist col = dist col - dist store(current loop iteration)  
filter for dist col <= 150m

store\_ref = current loop iteration

check if dist (store\_ref and store in iteration <=100m)

if yes,

check similarity,

if similarity>threshold, add to list/dataframe

&#x200B;

&#x200B;

This is a 3 level loop of max \~21k \* 5k \* 600 iterations and is taking too long. 

I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  
",datascience,https://www.reddit.com/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,2,1,1.0,"[Comment(id='k4pjep1'), Comment(id='k4rpngp')]"
176drw8,a157reverse,,2023-10-12 18:24:13+00:00,False,,False,False,True,False,/r/datascience/comments/176drw8/explainable_ai_scepticism/,Explainable AI Scepticism,"For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. 

Not surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. 

However, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. 

Things like SHAP values of LIME are okay in some instances with a stable model, but we've seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. 

This blog post summarizes most of my thoughts clearly: https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/

Anyways, I guess what I'm asking is are there practicioners out there that hold a different view? Are there advancements in this space that I'm unaware of? I know there's a lot of effort going into the explainable AI space right now, but I'm pessimistic that it's even possible for us to have a good explaination for many models. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/176drw8/explainable_ai_scepticism/,6,8,0.84,"[Comment(id='k4mv0wo'), Comment(id='k4lluk8'), Comment(id='k4lkuib'), Comment(id='k4nc74e'), Comment(id='k4n1a8p'), Comment(id='k4mc060')]"
1769ler,Legitimate_Ebb3623,,2023-10-12 15:25:21+00:00,False,,False,False,True,False,/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,Coding sometimes scares me. Is this the wrong field for me?,"I have been working as a ""Data Scientist"" for a little over 2 years but in my company I'm primarily tasked with developing MVPs with the company's  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company's technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. 

In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.

I'm trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?",datascience,https://www.reddit.com/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,27,16,0.73,"[Comment(id='k4koo77'), Comment(id='k4kqzez'), Comment(id='k4lmyje'), Comment(id='k4lsn2q'), Comment(id='k4m4s4z'), Comment(id='k4laaw0'), Comment(id='k4ldixc'), Comment(id='k4n2cex'), Comment(id='k4ly0xf'), Comment(id='k4l6vxr'), Comment(id='k4lt910'), Comment(id='k4m8ti3'), Comment(id='k4o2nhm'), Comment(id='k4o8yvt'), Comment(id='k4q813b'), Comment(id='k4mzokq'), Comment(id='k4krjus'), Comment(id='k4o2dc6'), Comment(id='k4mapt0'), Comment(id='k4m1bb4'), Comment(id='k4n0y2c'), Comment(id='k4kv1ag'), Comment(id='k4ktno9'), Comment(id='k4mevu8'), Comment(id='k4n3q4q'), Comment(id='k4n3hpb'), Comment(id='k4mxku5')]"
176h4n3,Reasonable-Farmer186,,2023-10-12 20:52:03+00:00,False,,False,False,True,False,/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,Resources on Monte Carlo Simulations (Python),"Hi all,

I have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.

Thanks! Any advice would be appreciated.",datascience,https://www.reddit.com/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,4,4,1.0,"[Comment(id='k4n3e32'), Comment(id='k4ov8gn'), Comment(id='k4ubuvi'), Comment(id='k4pzsal')]"
176oxj5,CharmingSurprise4939,,2023-10-13 03:03:28+00:00,False,,False,False,False,False,/r/datascience/comments/176oxj5/two_different_ways_to_execute_python_code_on_an/,Two different ways to execute Python code on an EC2 instance,,datascience,https://medium.com/@hello_prism/running-a-python-script-on-an-ec2-instance-8691589b3080,0,1,0.67,[]
176ojaz,CheapBanana1050,,2023-10-13 02:42:01+00:00,False,,False,False,True,False,/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,On handling multi-label/multi-value categorical features and high cardinality.,"Hi all, I'm working on a binary classification problem with all input features being categorical (and nominal).

The problem I'm facing is that each input example can contain multiple values of a feature and there are too many different values.

(For example, multi-value feature being a 'Hobbies' feature that contains a list of strings:

>data = {'User': \['User1', 'User2', 'User3'\],'Hobbies': \[\['Soccer', 'Swimming', 'Hiking'\],\['Swimming', 'Cycling'\],\['Soccer', 'Hiking'\]\]}

)

I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0's.  I searched for other suggestions that address this issue and [this article](https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4) stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.

The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I'm not sure about this approach.

How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I'm new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn't address the multiple-value nature of the features.

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,3,1,0.67,"[Comment(id='k4nvwr0'), Comment(id='k4ry8aj'), Comment(id='k4o6mhp')]"
176rwg6,Active_Cranberry7606,,2023-10-13 06:05:00+00:00,False,,False,False,True,False,/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,High Performance Teams: Is the Balance of Personal and Professional Connections Vital for Team Synergy? Should you really KNOW and CARE about your colleagues?," I've been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?

I've heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it's all about the work, and personal connections might be secondary.

I'd love to hear your thoughts and experiences on this matter:

1. Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?
2. Conversely, have you been on a high-performance team where personal relationships weren't a focal point, yet it still excelled in achieving its goals?
3. What are your thoughts on the balance between personal connections and professional performance within a team?
4. Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?

Feel free to share your insights, anecdotes, or opinions. I'm genuinely curious to see the various perspectives on this topic. Let's have a meaningful discussion!

 ",datascience,https://www.reddit.com/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,3,0,0.43,"[Comment(id='k4odd4n'), Comment(id='k4pc5ro'), Comment(id='k4q5ye5')]"
176tmht,Additional_Guide5439,,2023-10-13 08:05:11+00:00,False,,1697209194.0,False,True,False,/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,What are your thoughts on time series analysis and forecasting with Generative models like TimeGPT,"Recently i was in conversation with professor Rob Hyndman and he told how TimeGPT was a promising model that could be used for prediction tasks. For those who don't know this is an excerpt from the company website:-

TimeGPT, developed by Nixtla, is a generative pre-trained transformer model specialized in prediction tasks. TimeGPT was trained on the largest collection of data in history – over 100 billion rows of financial, weather, energy, and web data – and democratizes the power of time-series analysis.

So what are your thoughts on such models and where do you think the future lies for forecasting tasks when compared to statistical models like ARIMA or state space models.",datascience,https://www.reddit.com/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,3,0,0.38,"[Comment(id='k4ouol8'), Comment(id='k4p654j'), Comment(id='k4qecdk'), Comment(id='k4qhnwp'), Comment(id='k4qou92')]"
176n9lw,are-you-kittenme,,2023-10-13 01:34:39+00:00,False,,False,False,True,False,/r/datascience/comments/176n9lw/is_networking_key/,Is networking key?,I'm autistic. I have really bad social anxiety. Is networking key in getting a job? I am just getting started in school.. i've been a stay at home mom for the last 9 years. Am i wasting my time?,datascience,https://www.reddit.com/r/datascience/comments/176n9lw/is_networking_key/,7,1,0.54,"[Comment(id='k4ncsnm'), Comment(id='k4qbdxy'), Comment(id='k4nxpq0'), Comment(id='k4ncwqn'), Comment(id='k4nqtao'), Comment(id='k4ppl6s'), Comment(id='k4qz20t')]"
1769vr7,ma-d-ghost,,2023-10-12 15:37:44+00:00,False,,False,False,True,False,/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,I feel like I’m stuck with my scientific research,"Hi, I’m writing this post hoping to get some advice from everyone. I’m studying for a Master's degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I've completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.

However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I'm stuck at this stage; one month has passed, and I haven't been able to discover anything new beyond what they have pointed out. I'm really worried that I might disappoint my mentors, as they've been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I'm afraid that I might be slowing down the whole team :(",datascience,https://www.reddit.com/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,7,7,0.77,"[Comment(id='k4ksjm7'), Comment(id='k4mf14m'), Comment(id='k4kz1uc'), Comment(id='k4l7nui'), Comment(id='k4li2et'), Comment(id='k4lisiz'), Comment(id='k4li7k0')]"
176c3gh,mangos5,,2023-10-12 17:12:43+00:00,False,,False,False,True,False,/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,What to do when looking for a job,Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?,datascience,https://www.reddit.com/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,3,3,0.67,"[Comment(id='k4lyjsr'), Comment(id='k4l8rnk'), Comment(id='k4lx50u')]"
1769z7v,Legitimate_Ebb3623,,2023-10-12 15:41:54+00:00,False,,False,False,True,False,/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,can any research scientists share their experience?,"I'm interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.

I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?

How did you get the role? If I'm interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?",datascience,https://www.reddit.com/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,2,5,0.78,"[Comment(id='k4l045x'), Comment(id='k4mnv6e')]"
176di2y,AlternativeSea4330,,2023-10-12 18:12:34+00:00,False,,False,False,True,False,/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,What's Pandas .loc time complexity?," Hi guys, i'm doing research on Pandas, and I've read various posts here and there on the web, but i haven't reached a definitive conclusion regarding the question i posed. I'd like to understand how Pandas stores indices and what the time complexity of lookup operations performed with **loc** is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, [https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas](https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas), which discusses the topic, but there's no concrete evidence that this is true. Can anyone help me? Thanks a lot.",datascience,https://www.reddit.com/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,5,4,0.83,"[Comment(id='k4loa8h'), Comment(id='k4wqgtq'), Comment(id='k4lh33a'), Comment(id='k4m2wom'), Comment(id='k4yeoz9')]"
176fpo0,FierceTeletubby,,2023-10-12 19:50:19+00:00,False,,False,False,True,False,/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,CVXPY: Why Norm constraint is not DCP?,"\`cp.norm(weights, 1).is\_dcp()\` returns true. Then why this code works:

&#x200B;

    import cvxpy as cp
    import numpy as np
    inputs = np.random.normal(0, 1, (100, 300))
    inputs_mean = inputs.mean(axis=1) # shape (features,)
    inputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)
    weights = cp.Variable(len(inputs))
    risk = cp.quad_form(weights, inputs_cov)
    constraints = [
    # cp.norm(weights, 1) == 1.,
    cp.sum(weights) == 1.,
    ]
    problem = cp.Problem(cp.Minimize(risk), constraints)
    problem.solve(verbose=True)
    weights.value

But if you use the first constraint (\`cp.norm\`) instead of the second, it does not:

&#x200B;

    DCPError: Problem does not follow DCP rules. Specifically:
    The following constraints are not DCP:
    norm1(var456) == 1.0 , because the following subexpressions are not:
    |-- norm1(var456) == 1.0

&#x200B;

Why is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,6,0,0.5,"[Comment(id='k4nmgsq'), Comment(id='k4nmkdj'), Comment(id='k4sc2i6'), Comment(id='k4sbt1x'), Comment(id='k4trt78'), Comment(id='k4vlx6i')]"
176aamb,emotional-Limit-2000,,2023-10-12 15:55:38+00:00,False,,False,False,True,False,/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,Need problem statements for a project,"I want to make a project in which I'm thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn't already a solution however I'm not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y'all have any suggestions please let me know it'll be genuinely appreciated!",datascience,https://www.reddit.com/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,5,2,0.75,"[Comment(id='k4kzspi'), Comment(id='k4l27cu'), Comment(id='k4otgro'), Comment(id='k4ll478'), Comment(id='k4pr62r')]"
176bn2q,Ashfan007,,2023-10-12 16:53:02+00:00,False,,False,False,True,False,/r/datascience/comments/176bn2q/recommend_data_science_course/,Recommend data science course,"I'm a beginner in data science, Can someone recommend some good Data Science courses? ",datascience,https://www.reddit.com/r/datascience/comments/176bn2q/recommend_data_science_course/,2,0,0.5,"[Comment(id='k4r354e'), Comment(id='k4rchk9')]"
1769fk8,ergodym,,2023-10-12 15:18:09+00:00,False,,False,False,True,False,/r/datascience/comments/1769fk8/ds_exits_or_pivots/,DS exits or pivots,What's the most creative exit or pivot you have done (or seen others do) after being a DS for some time?,datascience,https://www.reddit.com/r/datascience/comments/1769fk8/ds_exits_or_pivots/,0,1,0.67,[]
17686qn,Kenny9184,,2023-10-12 14:23:22+00:00,False,,False,False,True,False,/r/datascience/comments/17686qn/career_planning/,Career planning,"Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?",datascience,https://www.reddit.com/r/datascience/comments/17686qn/career_planning/,1,1,1.0,[Comment(id='k4kh917')]
175jep1,every_other_freackle,,2023-10-11 17:14:02+00:00,False,,1697083575.0,False,True,False,/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,How do you store your ad hoc experiments?,"Let’s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?


How would you store/archive this project?
Committing Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that’s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?

What tool / workflow am I missing here?

I keep hearning notebooks are great for experiments but I don’t see what the workflow is like for these experiments…

EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..",datascience,https://www.reddit.com/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,31,48,0.94,"[Comment(id='k4gc614'), Comment(id='k4htcop'), Comment(id='k4g6nsu'), Comment(id='k4g824f'), Comment(id='k4h2gku'), Comment(id='k4h9ght'), Comment(id='k4ies8a'), Comment(id='k4g4b2v'), Comment(id='k4g4om5'), Comment(id='k4gryxn'), Comment(id='k4gjnx5'), Comment(id='k4go9iy'), Comment(id='k4hv2qw'), Comment(id='k4iav2t'), Comment(id='k4iuwca'), Comment(id='k4g8l5d'), Comment(id='k4gjtzi'), Comment(id='k4gxuu3'), Comment(id='k4h9qz4'), Comment(id='k4hmeya'), Comment(id='k4jsex7'), Comment(id='k4jxuh2'), Comment(id='k4h7wlx'), Comment(id='k4irek6'), Comment(id='k4htvp7'), Comment(id='k4j72kl'), Comment(id='k4hojhk'), Comment(id='k4g4zub'), Comment(id='k4hqywb'), Comment(id='k4j7h21'), Comment(id='k4kkaup')]"
1761n34,ZebZ,,2023-10-12 08:07:02+00:00,False,,False,False,True,False,/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,Existing relational database to new vector database?,"I'm in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things ""AI"").

Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.

If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.

My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I'm not sure where to start, and I'm getting hung up on that there doesn't seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.

I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I'd equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That's half of it. But I'm not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I'm most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like ""Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?""

Basically, all this is a very long-winded, rambling way to get to three questions:

1. Are there any examples of converting a remotely complex RDMS into a vector database?

2. How much massaging beyond basic denormalization and pre-aggregation do I need to do?

3. Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?",datascience,https://www.reddit.com/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,1,3,0.8,[Comment(id='k4jnc0y')]
175ptfa,greathassan,,2023-10-11 21:42:37+00:00,False,,False,False,True,False,/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,Where to spend £5k budget for professional development in Data Science,"Hi everyone,

I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around £5,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. 

Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. ",datascience,https://www.reddit.com/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,24,13,0.84,"[Comment(id='k4jatm9'), Comment(id='k4iy6cr'), Comment(id='k4lwjse'), Comment(id='k4o5q3c'), Comment(id='k4jer4s'), Comment(id='k4iqwug'), Comment(id='k4k5307'), Comment(id='k4juht2'), Comment(id='k4jdcf9'), Comment(id='k4k1rrf'), Comment(id='k4mmvfc'), Comment(id='k4u2vy0'), Comment(id='k4jujm8'), Comment(id='k4iwf1g'), Comment(id='k4ju9zg'), Comment(id='k4lorju'), Comment(id='k4k1u05'), Comment(id='k4juuqf'), Comment(id='k4iwu1p'), Comment(id='k4k230u'), Comment(id='k4ja9fx'), Comment(id='k4k9es7'), Comment(id='k4jud78'), Comment(id='k4ktggp')]"
175caah,Diligent_Trust2569,,2023-10-11 11:59:15+00:00,False,,False,False,True,False,/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,How important is being appreciated and team fit as a factor to stay in a role with average salary given slow adoption of data science solutions?,"My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.

I am the “lead”/senior data scientist in an R&D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.

  I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.

I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.",datascience,https://www.reddit.com/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,85,73,0.86,"[Comment(id='k4f1nih'), Comment(id='k4enf76'), Comment(id='k4f5wrw'), Comment(id='k4f87kh'), Comment(id='k4es6cr'), Comment(id='k4fegtp'), Comment(id='k4fc5lt'), Comment(id='k4fdu0k'), Comment(id='k4fpnui'), Comment(id='k4erroz'), Comment(id='k4eo7sm'), Comment(id='k4g5l8z'), Comment(id='k4g8p9w'), Comment(id='k4gc0h5'), Comment(id='k4hit1f'), Comment(id='k4hmdgr'), Comment(id='k4i57cx'), Comment(id='k4ib4ox'), Comment(id='k4jflqu'), Comment(id='k4vipwh'), Comment(id='k5ccpe1'), Comment(id='k4fx64p'), Comment(id='k4ev5h6'), Comment(id='k4f2708'), Comment(id='k4hlprh'), Comment(id='k4enkch'), Comment(id='k4fiuls'), Comment(id='k4f8p2n'), Comment(id='k4esf4a'), Comment(id='k4fu3te'), Comment(id='k4erwol'), Comment(id='k4i5spr'), Comment(id='k4eolli'), Comment(id='k4fs8l5'), Comment(id='k4fi8g0'), Comment(id='k4exnop'), Comment(id='k4f0klz'), Comment(id='k4l82sw'), Comment(id='k4oocq2'), Comment(id='k4g91xi'), Comment(id='k4i5ffh'), Comment(id='k50uhd8'), Comment(id='k4fxdi3'), Comment(id='k4fg853'), Comment(id='k4fa8pk'), Comment(id='k4enuro'), Comment(id='k4eo8f3'), Comment(id='k4g4n5x'), Comment(id='k4fmd4w'), Comment(id='k4esl1s'), Comment(id='k4l7lyt'), Comment(id='k4exh32'), Comment(id='k4l7q7n'), Comment(id='k4fp1i0'), Comment(id='k4l6ryz'), Comment(id='k4fnqwb'), Comment(id='k4f2qdd'), Comment(id='k4fji1m'), Comment(id='k4lahiy'), Comment(id='k4ie5ay'), Comment(id='k4f55ut'), Comment(id='k4f3bsu'), Comment(id='k4g0uta'), Comment(id='k4f5apt'), Comment(id='k4f57lc'), Comment(id='k4f580y'), Comment(id='k4g3yjo'), Comment(id='k4f71vu'), Comment(id='k4f6pj2'), Comment(id='k4g982c'), Comment(id='k4f8vjh'), Comment(id='k4hor0s'), Comment(id='k4gb0ah'), Comment(id='k4getvp'), Comment(id='k4gi7aj'), <MoreComments count=0, children=[]>]"
175nbtg,childofaether,,2023-10-11 20:00:04+00:00,False,,False,False,True,False,/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,Any value to an unrelated advanced degree to get into DS?,"I'm a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.

I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don't care about non-CS scientific education ?

What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?

I'm interested in Data Science and I'm looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn't want to pursue more formal education if it doesn't really give me more options other than a false hope and wasted time applying for DS positions I can't get.",datascience,https://www.reddit.com/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,14,11,0.93,"[Comment(id='k4gusbf'), Comment(id='k4ipbmt'), Comment(id='k4i6w4m'), Comment(id='k4jzgld'), Comment(id='k4hu782'), Comment(id='k4h9fem'), Comment(id='k4jwu0t'), Comment(id='k4h6ya9'), Comment(id='k4khvr9'), Comment(id='k4jttgq'), Comment(id='k4h8kjp'), Comment(id='k4tgc69'), Comment(id='k4hcdve'), Comment(id='k4he77g')]"
175gyx0,Pineapple_throw_105,,2023-10-11 15:35:13+00:00,False,,False,False,True,False,/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,What are grid search alternatives?,Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.,datascience,https://www.reddit.com/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,40,22,0.81,"[Comment(id='k4flkjc'), Comment(id='k4gdiul'), Comment(id='k4fhzz2'), Comment(id='k4ghn8a'), Comment(id='k4fl779'), Comment(id='k4ggxre'), Comment(id='k4frddj'), Comment(id='k4gelne'), Comment(id='k4gb1so'), Comment(id='k4gkubn'), Comment(id='k4gld9c'), Comment(id='k4gtnzc'), Comment(id='k4h4zp0'), Comment(id='k4iupfb'), Comment(id='k4ix6qx'), Comment(id='k4ixf7v'), Comment(id='k4j0jjq'), Comment(id='k4jidy7'), Comment(id='k4hotqi'), Comment(id='k4glz54'), Comment(id='k4gm7mp'), Comment(id='k4h7lhv'), Comment(id='k4h9mck'), Comment(id='k4jccog'), Comment(id='k4mlcss'), Comment(id='k4uza7q'), Comment(id='k4h3lx5'), Comment(id='k4it7mn'), Comment(id='k4fisk2'), Comment(id='k4i6ei4'), Comment(id='k4h7dr3'), Comment(id='k4gj3x9'), Comment(id='k4hk707'), Comment(id='k4j9mmd'), Comment(id='k4j79w8'), Comment(id='k4fjppo'), Comment(id='k4hx8gt'), Comment(id='k4jmd3q'), Comment(id='k4i9mth'), Comment(id='k4m8arc')]"
175x92z,ProductOk7316,,2023-10-12 03:32:18+00:00,False,,False,False,True,False,/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,SHAP Deep Reinforcement Learning,"Hi Guys,

Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. 

&#x200B;

Thanks. ",datascience,https://www.reddit.com/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,0,2,1.0,[]
1760xpw,RevolutionaryPen4661,,2023-10-12 07:17:19+00:00,False,,False,False,False,False,/r/datascience/comments/1760xpw/markdown_to_html/,Markdown To HTML,,datascience,/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/,2,0,0.33,"[Comment(id='k4j8nj9'), Comment(id='k4lce34')]"
175oh0k,Fincho64,,2023-10-11 20:47:01+00:00,False,,False,False,True,False,/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,"Julia leads Rust, Zig, Go and Java in data processing benchmark","[https://github.com/jinyus/related\_post\_gen](https://github.com/jinyus/related_post_gen)

https://preview.redd.it/ii0dm13dymtb1.png?width=849&format=png&auto=webp&s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f",datascience,https://www.reddit.com/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,0,8,1.0,[]
175q00o,EncryptedMyst,,2023-10-11 21:50:27+00:00,False,,False,False,True,False,/r/datascience/comments/175q00o/security_measures_at_my_workplace/,Security measures at my workplace,"I work for a pretty big Aerospace manufacturing company where my job title is 'Digital Engineer'. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can't disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.

I would of course like to use Python's Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.

My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven't really been exposed to it yet.",datascience,https://www.reddit.com/r/datascience/comments/175q00o/security_measures_at_my_workplace/,7,4,0.75,"[Comment(id='k4ib4xr'), Comment(id='k4hqaa5'), Comment(id='k4j4xwy'), Comment(id='k4hdau6'), Comment(id='k4j3fyq'), Comment(id='k4lesad'), Comment(id='k4j2d8n')]"
175qvkx,Bulky_Gap_7072,,2023-10-11 22:27:06+00:00,False,,False,False,True,False,/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,Predicting what features lead to long wait times,"I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. 

I work on a team of \~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. 

I think there's a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.

When you have one value (duration) that you're trying to make predictions about, but you don't have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?",datascience,https://www.reddit.com/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,4,3,0.81,"[Comment(id='k4hoem4'), Comment(id='k4hfggr'), Comment(id='k4hmd1f'), Comment(id='k4i2vd5')]"
174wmnk,Utterizi,,2023-10-10 21:24:57+00:00,False,,False,False,True,False,/r/datascience/comments/174wmnk/sucking_at_my_job/,Sucking at my job?,"Got into my first job about 10 months ago. I study a master’s on data science and I’m about to finish school in 2-3 months. I’m doing okay, my lowest score is B+ and I’m working on a churn project. 

I got my job through a friend, the company knew I was recently starting my master’s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I’d bring a new perspective to the team. 

Things started ok and I’m doing pretty good on every day tasks, but whenever I’m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. 

It’s not that I’m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.

I’m starting to feel like I’m wasting company’s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything.",datascience,https://www.reddit.com/r/datascience/comments/174wmnk/sucking_at_my_job/,41,144,0.94,"[Comment(id='k4c8zqt'), Comment(id='k4ck3ll'), Comment(id='k4c1ui2'), Comment(id='k4c74qi'), Comment(id='k4cxl4z'), Comment(id='k4cb16t'), Comment(id='k4cwr9u'), Comment(id='k4c2iw8'), Comment(id='k4d7h4b'), Comment(id='k4ccrmj'), Comment(id='k4d4cfk'), Comment(id='k4d1ioj'), Comment(id='k4chs3f'), Comment(id='k4cqfhs'), Comment(id='k4eowwq'), Comment(id='k4f9bxy'), Comment(id='k4cpdpm'), Comment(id='k4c4blt'), Comment(id='k4e3yxq'), Comment(id='k4dy4oi'), Comment(id='k4e1q57'), Comment(id='k4fmjx3'), Comment(id='k4fpvnh'), Comment(id='k4h545c'), Comment(id='k4h621d'), Comment(id='k4j9h5u'), Comment(id='k4drtln'), Comment(id='k4irnm0'), Comment(id='k4cq8cu'), Comment(id='k4cgy6v'), Comment(id='k4dduqi'), Comment(id='k4f0rer'), Comment(id='k4g9n6y'), Comment(id='k4dx4m5'), Comment(id='k4dwwsh'), Comment(id='k4crzij'), Comment(id='k4dmubl'), Comment(id='k4erqqm'), Comment(id='k4cu9n0'), Comment(id='k4d55z7'), Comment(id='k4dcyow')]"
175mipy,aesthetic-mango,,2023-10-11 19:25:33+00:00,False,,False,False,True,False,/r/datascience/comments/175mipy/rsession_crashingphobia/,R-SESSION CRASHING-PHOBIA,"I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I'd say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE ''SESSION CRASHED''!

Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?

P.S. i sadly mustn't split the dataset. 

Thanks a lot, i wish you nothing but simple datasets. ",datascience,https://www.reddit.com/r/datascience/comments/175mipy/rsession_crashingphobia/,9,0,0.5,"[Comment(id='k4gq8p8'), Comment(id='k4h9f4q'), Comment(id='k4h2xw5'), Comment(id='k4h7zg3'), Comment(id='k4hc7p8'), Comment(id='k4hcnaw'), Comment(id='k4i0y1y'), Comment(id='k4iysp6'), Comment(id='k4krpa7')]"
175errf,oblivious_horizon,,2023-10-11 14:03:12+00:00,False,,False,False,True,False,/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,Predicted raw probabilities or threshold-adjusted ones?,"I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? 

For example, suppose I get a probability as 0.55. Which means, in face value, that there's more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I'm concerned with ONLY the probability, isnt that deceiving or wrong? 

Any suggestions are appreciated.",datascience,https://www.reddit.com/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,5,2,1.0,"[Comment(id='k4fbbou'), Comment(id='k4fk9kl'), Comment(id='k4gflhs'), Comment(id='k4q3o9f'), Comment(id='k4q2nm6')]"
1754v9n,DapperAd8264,,2023-10-11 03:48:56+00:00,False,,False,False,True,False,/r/datascience/comments/1754v9n/data_science_for_sales/,Data Science for Sales,"I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I’m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company’s CRM data and my company’s product offering is price benchmarking.",datascience,https://www.reddit.com/r/datascience/comments/1754v9n/data_science_for_sales/,21,12,0.78,"[Comment(id='k4djgtc'), Comment(id='k4dt0nf'), Comment(id='k4e3ogs'), Comment(id='k4f8qvl'), Comment(id='k4fc636'), Comment(id='k4fli2l'), Comment(id='k4fqeov'), Comment(id='k4dtzs5'), Comment(id='k4f4wg7'), Comment(id='k4fnoom'), Comment(id='k4duhw3'), Comment(id='k4fprpi'), Comment(id='k4fc0n0'), Comment(id='k4fj57p'), Comment(id='k4fjl9k'), Comment(id='k4flomz'), Comment(id='k4flgco'), Comment(id='k4g4kmi'), Comment(id='k4g958r'), Comment(id='k4gfob8'), Comment(id='k4gi1ej')]"
174pvw9,databro92,,2023-10-10 16:47:12+00:00,False,,False,False,True,False,/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,"Can anyone provide an easy to understand real world example of tensors, and how they are used?","One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You're just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...


And recently I've been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don't understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I'm not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. 


So how would you explain what a tensor is in real world terms?",datascience,https://www.reddit.com/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,63,70,0.85,"[Comment(id='k4b45q5'), Comment(id='k4azn5b'), Comment(id='k4d7v0k'), Comment(id='k4awwxb'), Comment(id='k4btnr5'), Comment(id='k4b4b47'), Comment(id='k4brnvo'), Comment(id='k4deyev'), Comment(id='k4asjpn'), Comment(id='k4bv9mo'), Comment(id='k4c2e7o'), Comment(id='k4avlkg'), Comment(id='k4bq0wn'), Comment(id='k4brzzz'), Comment(id='k4co1k2'), Comment(id='k4ctvrp'), Comment(id='k4d5fir'), Comment(id='k4e7j9a'), Comment(id='k4ec6we'), Comment(id='k4etd8g'), Comment(id='k4etej1'), Comment(id='k4fetce'), Comment(id='k4gmuk6'), Comment(id='k4ha1re'), Comment(id='k4hpc60'), Comment(id='k4jbvkt'), Comment(id='k4bxl4w'), Comment(id='k4be01h'), Comment(id='k4b56fn'), Comment(id='k4b7e2y'), Comment(id='k4e6irh'), Comment(id='k4bs5t9'), Comment(id='k4brqdm'), Comment(id='k4bfy1n'), Comment(id='k4aung7'), Comment(id='k4c0oy0'), Comment(id='k4buw35'), Comment(id='k4ctfua'), Comment(id='k4bcqk3'), Comment(id='k4c44t8'), Comment(id='k4bc9f6'), Comment(id='k4f76kr'), Comment(id='k4c3rfm'), Comment(id='k4daoun'), Comment(id='k4cu8qt'), Comment(id='k4axs9i'), Comment(id='k4c3yf9'), Comment(id='k4d6rrn'), Comment(id='k4comqh'), Comment(id='k4buxek'), Comment(id='k4ftkda'), Comment(id='k4c7xdi'), Comment(id='k4dcqhf'), Comment(id='k4dmu34'), Comment(id='k4cxl9y'), Comment(id='k4ccbm6'), Comment(id='k4cakgc'), Comment(id='k4d7tmv'), Comment(id='k4fuzjo'), Comment(id='k4ciinf'), Comment(id='k4cgkn8'), Comment(id='k4f7yc2'), Comment(id='k4d9n0u'), Comment(id='k4e6p0f'), Comment(id='k4fx32o'), Comment(id='k4clqs9'), Comment(id='k4da4b1')]"
1756hae,DboS3dan,,2023-10-11 05:26:52+00:00,False,,False,False,True,False,/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,A/B Testing Product or User Split,"I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is ‘attractive’, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.

If I want to do A/B test on this to see if this ‘attractive’ indication makes those items sell at a higher rate, how would you design the test? Would you:
1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?
2. Identify those items and only show the ‘attractive’ indicator to half of the users. Meaning that half the users will see the existing experience (no ‘attractive’ indicator at all) and half will see the ‘attractive’ indicator on all 500 items, then compare how they sell by user group?

Intuitively #1 makes more sense to me, but I’m not finding a lot of literature to support this methodology. How would you design such a test and what’s your rationale?

Please note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.

Thanks",datascience,https://www.reddit.com/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,5,5,0.86,"[Comment(id='k4evnsd'), Comment(id='k4dwy6n'), Comment(id='k4eu9y6'), Comment(id='k4fqd64'), Comment(id='k4fr4u6')]"
174gxvo,Fluxan,,2023-10-10 09:29:59+00:00,False,,1696936462.0,False,True,False,/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,"How can data science be used to ""make the world a better place""?","I see a lot of data scientists in this subreddit describing their work as using different types of methods to, in the end, improve company performance and/or profits.

I was wondering, if you have examples for how data science is used for social benefit instead of the bottom line of profits?",datascience,https://www.reddit.com/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,99,129,0.89,"[Comment(id='k495xjm'), Comment(id='k49bw3c'), Comment(id='k49g65e'), Comment(id='k49b2ea'), Comment(id='k499a90'), Comment(id='k49jenp'), Comment(id='k496ho7'), Comment(id='k49tira'), Comment(id='k49bunw'), Comment(id='k494fos'), Comment(id='k49u248'), Comment(id='k4a0gfl'), Comment(id='k4a6ag3'), Comment(id='k49frsk'), Comment(id='k4afevl'), Comment(id='k4aiwli'), Comment(id='k4aj59g'), Comment(id='k4ate5q'), Comment(id='k4bpc3a'), Comment(id='k4bqxv6'), Comment(id='k4ececu'), Comment(id='k49aoou'), Comment(id='k4bd7e7'), Comment(id='k49f22a'), Comment(id='k4chqxv'), Comment(id='k4a4bnm'), Comment(id='k49ozat'), Comment(id='k4abki2'), Comment(id='k4aikyi'), Comment(id='k4aqprh'), Comment(id='k4aqwse'), Comment(id='k4awke9'), Comment(id='k4b6wdw'), Comment(id='k4baze2'), Comment(id='k4bbunf'), Comment(id='k4bhxkt'), Comment(id='k4bjpp8'), Comment(id='k4bo864'), Comment(id='k4boq0j'), Comment(id='k4bt2er'), Comment(id='k4by5yt'), Comment(id='k4byq7w'), Comment(id='k4c3yap'), Comment(id='k4c5543'), Comment(id='k4cmqet'), Comment(id='k4cmx4t'), Comment(id='k4d4p86'), Comment(id='k4d65e3'), Comment(id='k4dwogy'), Comment(id='k4dxqgc'), Comment(id='k4e5ih4'), Comment(id='k4e7qnx'), Comment(id='k4eb99k'), Comment(id='k4fa08l'), Comment(id='k4i2r53'), Comment(id='k4iezk6'), Comment(id='k4atln4'), Comment(id='k4azge6'), Comment(id='k4ckk71'), Comment(id='k4awm4p'), Comment(id='k4btj98'), Comment(id='k4bi2ib'), Comment(id='k4b3wc4'), Comment(id='k4bu2af'), Comment(id='k4atj62'), Comment(id='k4b9c4z'), Comment(id='k4aakar'), Comment(id='k4acyin'), Comment(id='k4a3etj'), Comment(id='k4igbyh'), Comment(id='k4anufe'), Comment(id='k49crmf'), Comment(id='k4bepb9'), Comment(id='k4ewrxm'), Comment(id='k4gn9a6'), Comment(id='k4gjwca'), Comment(id='k4f4uyo'), Comment(id='k4b4ms1'), Comment(id='k4c6rsj'), Comment(id='k4drzmk'), Comment(id='k4adqta'), Comment(id='k4b595q'), Comment(id='k49f8bj'), Comment(id='k4fxvsn'), Comment(id='k4kj0cb'), Comment(id='k4gm7iu'), Comment(id='k4gccfz'), Comment(id='k4emxhq'), Comment(id='k4ajeal'), Comment(id='k4chzpk'), Comment(id='k49g9co'), Comment(id='k4gfb8u'), Comment(id='k4n2x22'), Comment(id='k4davwm'), Comment(id='k4dv2dj'), Comment(id='k49j4ka'), Comment(id='k49nqlf')]"
174n6w2,timusw,,2023-10-10 14:53:14+00:00,False,,False,False,True,False,/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,How quickly should you be expected to start producing?,"How soon would you expect a new Senior Data Scientist to start churning out models, analysis, reports, experiments, etc? What would you think dictates this expectation?",datascience,https://www.reddit.com/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,33,47,0.89,"[Comment(id='k4a5n0g'), Comment(id='k4aku9z'), Comment(id='k4bp1of'), Comment(id='k4c75wq'), Comment(id='k4cg760'), Comment(id='k4b30w9'), Comment(id='k4b7yt8'), Comment(id='k4bn82w'), Comment(id='k4bbb1h'), Comment(id='k4ag1na'), Comment(id='k4apo13'), Comment(id='k4dwtmu'), Comment(id='k4a9kr3'), Comment(id='k4b88zr'), Comment(id='k4c1lux'), Comment(id='k4bprqn'), Comment(id='k4c0xy2'), Comment(id='k4abwnf'), Comment(id='k4agcy5'), Comment(id='k4aj8oh'), Comment(id='k4aqc0g'), Comment(id='k4beo0x'), Comment(id='k4c9vtl'), Comment(id='k4c852m'), Comment(id='k4c55e0'), Comment(id='k4aonn9'), Comment(id='k4cpnw1'), Comment(id='k4clugy'), Comment(id='k4b88eb'), Comment(id='k4aqbsh'), Comment(id='k4arh1d'), Comment(id='k4cl5cx'), Comment(id='k4fho3j')]"
175qent,Silly_Valley,,2023-10-11 22:07:24+00:00,False,,1697072739.0,False,True,False,/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,Is fitting functions to data (with chi2 and all that) data analysis or data science?,&#x200B;,datascience,https://www.reddit.com/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,53,0,0.33,"[Comment(id='k4hg8i1'), Comment(id='k4hnbqi'), Comment(id='k4hd1le'), Comment(id='k4j3caz'), Comment(id='k4vcroi'), Comment(id='k4hhil4'), Comment(id='k4hnz9b'), Comment(id='k4hhnkz'), Comment(id='k4x1a9t'), Comment(id='k4hhsov'), Comment(id='k4hrd6d'), Comment(id='k4hrsyu'), Comment(id='k4hry9e'), Comment(id='k4jc60v'), Comment(id='k4l222a'), Comment(id='k4i28zz'), Comment(id='k4x2t9v'), Comment(id='k4hin8n'), Comment(id='k4i0gj4'), Comment(id='k4hwwku'), Comment(id='k4k9fs5'), Comment(id='k4l2o6k'), Comment(id='k4i4kr7'), Comment(id='k4xj93q'), Comment(id='k4hk78k'), Comment(id='k4hmdpl'), Comment(id='k4i1gca'), Comment(id='k4l483m'), Comment(id='k4ibwxm'), Comment(id='k4hndhx'), Comment(id='k4hp2b6'), Comment(id='k4i5qh6'), Comment(id='k4lcgpb'), Comment(id='k4hrwd0'), Comment(id='k4hq48p'), Comment(id='k4i6bkl'), Comment(id='k4hxfgt'), Comment(id='k4i0lqu'), Comment(id='k4i8lhu'), Comment(id='k4hzowq'), Comment(id='k4i0eoe'), Comment(id='k4i01ru'), Comment(id='k4ie08m'), Comment(id='k4i8y0u'), Comment(id='k4i16q1'), Comment(id='k4i2kdm'), Comment(id='k4i9zbp'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
175nces,philemil,,2023-10-11 20:00:38+00:00,False,,False,False,True,False,/r/datascience/comments/175nces/fraud_detection_thesis/,Fraud Detection Thesis,"Hello.

I have to do a project for my thesis.
I have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it’s being laundered.

What do you say about it?
 How should I approach this topic and how to do it?
Any ideas? Thanks.",datascience,https://www.reddit.com/r/datascience/comments/175nces/fraud_detection_thesis/,12,0,0.2,"[Comment(id='k4gvfo3'), Comment(id='k4iyjvm'), Comment(id='k4hj6h8'), Comment(id='k4i9laz'), Comment(id='k4gs0b0'), Comment(id='k4oatke'), Comment(id='k4iys74'), Comment(id='k4iysyb'), Comment(id='k4gurdo'), Comment(id='k4izg34'), Comment(id='k4gw4gl'), Comment(id='k4iyvwr')]"
1755h3b,jacobwlyman,,2023-10-11 04:23:10+00:00,False,,False,False,True,False,/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,Has anyone used Comet for experiment tracking?,Hey! Has anyone used Comet (https://www.comet.com) for their experiment tracking? I’m looking into the product and am curious if anyone here has enjoyed using it,datascience,https://www.reddit.com/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,2,2,1.0,"[Comment(id='k4fdkqz'), Comment(id='k4o5hvl')]"
1752wat,Breadskinjinhojiak,,2023-10-11 02:09:33+00:00,False,,False,False,True,False,/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,"How does SEMRUSH, and other big analytic crawler works?",I'm trying to build something similar where websites can be crawled and refresh daily,datascience,https://www.reddit.com/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,2,4,0.75,"[Comment(id='k4fi3oq'), Comment(id='k4fkywl')]"
17578q8,Prestigious_Virus_33,,2023-10-11 06:16:01+00:00,False,,False,False,True,False,/r/datascience/comments/17578q8/creating_a_visualizations_map/,Creating a Visualizations Map,"Hi Everyone

I am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. 

I am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). 

My question is beyond a refresher training I wanted to make a map for the ~~lazy~~ some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it.",datascience,https://www.reddit.com/r/datascience/comments/17578q8/creating_a_visualizations_map/,2,1,0.67,"[Comment(id='k4igcpn'), Comment(id='k53nqgo')]"
174pkt1,data_scallion,,2023-10-10 16:33:39+00:00,False,,False,False,True,False,/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,Advancements in extracting tabular data from PDFs?,"Hi everyone!

Is there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I'm currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it's very time-consuming and tedious.  Is there a better way?

I've used Langchain and OpenAI to build ""Chat with your document"" apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don't think this solution will work.

&#x200B;

Thank you for your input,

Data Scallion",datascience,https://www.reddit.com/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,7,9,0.91,"[Comment(id='k4b1pw3'), Comment(id='k5iwq5b'), Comment(id='k4cu9ff'), Comment(id='k4dmeer'), Comment(id='k4igldg'), Comment(id='k4bafvb'), Comment(id='k4cpfuc')]"
174sfb2,valkaress,,2023-10-10 18:33:34+00:00,False,,False,False,True,False,/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,[US] What are some hubs for data science or data analytics?,"I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.

What are the top 5 or 10 DS hubs in the US, and then what's 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I'm assuming is Chicago)?",datascience,https://www.reddit.com/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,14,4,0.61,"[Comment(id='k4bbiuq'), Comment(id='k4bq193'), Comment(id='k4is2uv'), Comment(id='k4bvdye'), Comment(id='k4fji8q'), Comment(id='k4bc2gw'), Comment(id='k4by8h2'), Comment(id='k54yd91'), Comment(id='k4euqdh'), Comment(id='k4g0jqj'), Comment(id='k4d2fkf'), Comment(id='k4c79ew'), Comment(id='k4isa6a'), Comment(id='k57zpgm')]"
174wama,HyenaJack94,,2023-10-10 21:11:20+00:00,False,,False,False,True,False,/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,Question animal tracking data and filling in periods of sleep?,"I'm working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?",datascience,https://www.reddit.com/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,0,1,0.67,[]
1748bph,AbramoNauseus,,2023-10-10 00:56:37+00:00,False,,False,False,True,False,/r/datascience/comments/1748bph/tough_spot/,Tough spot,"
Hey everyone,

I recently joined a company as a data scientist and found that their data warehouse is in dire shape. It seems they haven't invested enough time in validating their data, resulting in most tables being unreliable for modeling or reporting. The analysts are reporting incorrect data and the upper management knows it. To add to the challenge, there's only one overburdened data engineer here, so I'm pretty much on my own in navigating this.

I've been identifying and communicating these data issues to upper management, but I also need to produce some models. The warehouse is poorly built, many tables with no data, a lot of columns in one table meaning they didn't bother creating more dimension tables. And worst of all, the data in tables is simply wrong. My current thought is to pivot temporarily:

1. Use existing, validated CSVs and Excel files to begin my analyses and model building.
2. Parallelly, work on gradually rectifying the data warehouse issues.
3. Eventually, transition the models to source data directly from the fixed warehouse.

Has anyone faced a similar situation? How did you handle it? Any advice or alternative approaches would be greatly appreciated!",datascience,https://www.reddit.com/r/datascience/comments/1748bph/tough_spot/,17,25,0.93,"[Comment(id='k47roe1'), Comment(id='k494qtb'), Comment(id='k48uwzt'), Comment(id='k49isbv'), Comment(id='k4a5atj'), Comment(id='k4ble15'), Comment(id='k4ar8ch'), Comment(id='k4b7ta0'), Comment(id='k4b7xlr'), Comment(id='k47v8mr'), Comment(id='k48605i'), Comment(id='k49uzyb'), Comment(id='k4ahgwk'), Comment(id='k4ai1cx'), Comment(id='k4bvtg4'), Comment(id='k4aty0z'), Comment(id='k4h0xjz')]"
174ml3k,InsightIndustry,,2023-10-10 14:26:44+00:00,False,,False,False,True,False,/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,Highcharts for Python v.1.4.0 Released,"Hi Everyone - Just a quick note to let you know that we just released v.1.4.0 of the [Highcharts for Python Toolkit](https://core-docs.highchartspython.com/) (Highcharts Core for Python, Highcharts Stock for Python, Highcharts Maps for Python, and Highcharts Gantt for Python).

While technically this is a minor release since everything remains backwards compatible and new functionality is purely additive, it still brings a ton of significant improvements across all libraries in the toolkit:

**Performance Improvements**

* 50 - 90% faster when rendering a chart in Jupyter (or when serializing it from Python to JS object literal notation)
* 30 - 90% faster when serializing a chart configuration from Python to JSON

Both major performance improvements depend somewhat on the chart configuration, but in any case it should be quite significant.

**Usability / Quality of Life Improvements**

* **Support for NumPy**

  Now we can create charts and data series directly from NumPy arrays.

* **Simpler API / Reduced Verbosity**

  While the toolkit still supports the full power of Highcharts (JS), the Python toolkit now supports ""naive"" usage and smart defaults. The toolkit will attempt to assemble charts and data series for you as best it can based on your data, even without an explicit configuration. Great for quick-and-dirty experimentation!

* **Python to JavaScript Conversion**

  Now we can write our Highcharts formatter or callback functions in Python, rather than JavaScript. With one method call, we can convert a Python callable/function into its JavaScript equivalent. This relies on integration with either OpenAI's GPT models or Anthropic's Claude model, so you will need to have an account with one (or both) of them to use the functionality. Because AI is generating the JavaScript code, best practice is to review the generated JS code before including it in any production application, but for quick data science work, or to streamline the development / configuration of visualizations, it can be super useful. [We even have a tutorial on how to use this feature here.](https://core-docs.highchartspython.com/en/latest/tutorials/callbacks.html)

* **Series-first Visualization**

  We no longer have to combine series objects and charts to produce a visualization. Now, we can visualize individual series directly with one method call, no need to assemble them into a chart object.

* **Data and Property Propagation**

  When configuring our data points, we no longer have to adjust each data point individually. To set the same property value on all data points, just set the property on the series and it will get automatically propagated across all data points.

* **Series Type Conversion**

  We can now convert one series to a different series type with one method call.

**Bug Fixes**

* Fixed a bug causing a conflict in certain circumstances where Jupyter Notebook uses RequireJS.
* Fixed a bug preventing certain chart-specific required Highcharts (JS) modules from loading correctly in Jupyter Notebook/Labs.

We're already hard at work on the next release, with more improvements coming, but while we work on it, if you're looking for high-end data visualization you'll find the Highcharts for Python Toolkit useful.

Here are all the more detailed links:

* [Highcharts for Python on Github](https://github.com/highcharts-for-python)
* [Highcharts for Python Website](https://highchartspython.com)
* Highcharts Core for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-core)
  * [PyPi](https://pypi.org/project/highcharts-core/)
  * [Documentation](https://core-docs.highchartspython.com)

* Highcharts Stock for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-stock)
  * [PyPi](https://pypi.org/project/highcharts-stock/)
  * [Documentation](https://stock-docs.highchartspython.com)

* Highcharts Maps for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-maps)
  * [PyPi](https://pypi.org/project/highcharts-maps/)
  * [Documentation](https://maps-docs.highchartspython.com)

* Highcharts Gantt for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-gantt)
  * [PyPi](https://pypi.org/project/highcharts-gantt/)
  * [Documentation](https://gantt-docs.highchartspython.com)

Please let us know what you think!",datascience,https://www.reddit.com/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,2,2,0.76,"[Comment(id='k4fckfy'), Comment(id='k4fjlpj')]"
174f1cc,Salt-Page1396,,2023-10-10 07:13:22+00:00,False,,False,False,True,False,/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,Why would I use Tableu/BI over Streamlit? Is there any advantage?,"Asides from skill issue

Is there any benefit to using Tableu/BI over streamlit given that coding isn't the issue? ",datascience,https://www.reddit.com/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,30,6,0.63,"[Comment(id='k48z3lk'), Comment(id='k48zzkd'), Comment(id='k490z7j'), Comment(id='k48w3ar'), Comment(id='k4bvlwm'), Comment(id='k49llm4'), Comment(id='k4aauwo'), Comment(id='k4cygff'), Comment(id='k4ed330'), Comment(id='k49ewvp'), Comment(id='k4bp26n'), Comment(id='k4cx6vz'), Comment(id='k49eopa'), Comment(id='k4btuac'), Comment(id='k48woxm'), Comment(id='k4c4v6s'), Comment(id='k49fmn1'), Comment(id='k4d48sn'), Comment(id='k49s91x'), Comment(id='k49erhm'), Comment(id='k48xawj'), Comment(id='k4c51sb'), Comment(id='k49gap4'), Comment(id='k4a2a4u'), Comment(id='k4e00bv'), Comment(id='k4e01gd'), Comment(id='k49gbnf'), Comment(id='k4cmygk'), Comment(id='k4e1faw'), Comment(id='k4d31nc')]"
174dzeb,mingzhouren,,2023-10-10 06:01:32+00:00,False,,False,False,True,False,/r/datascience/comments/174dzeb/explainable_boosting_machines/,Explainable boosting machines,Just curious how many people out there favor explainable boosting machines over bread and butter methods like lgbm or xgbm. Should I learn this or is it a fad?,datascience,https://www.reddit.com/r/datascience/comments/174dzeb/explainable_boosting_machines/,13,6,1.0,"[Comment(id='k4b9tps'), Comment(id='k4acoyo'), Comment(id='k4a23in'), Comment(id='k48p5hc'), Comment(id='k4cscyc'), Comment(id='k4bjg7i'), Comment(id='k4bjn0k'), Comment(id='k4bjyht'), Comment(id='k4doz7o'), Comment(id='k4bjqcj'), Comment(id='k4c1k51'), Comment(id='k4bl6h6'), Comment(id='k4dwwh4')]"
173txze,Exotic_Avocado6164,,2023-10-09 14:59:08+00:00,False,,False,False,True,False,/r/datascience/comments/173txze/data_scientists_how_many_hours_a_week_do_you_work/,Data scientists - How many hours a week do you work?,,datascience,https://www.reddit.com/r/datascience/comments/173txze/data_scientists_how_many_hours_a_week_do_you_work/,77,93,0.89,"[Comment(id='k4595hl'), Comment(id='k45v38q'), Comment(id='k465fz8'), Comment(id='k46nqzs'), Comment(id='k459ws7'), Comment(id='k468f36'), Comment(id='k476o5x'), Comment(id='k45k91y'), Comment(id='k480olb'), Comment(id='k467isa'), Comment(id='k4679ct'), Comment(id='k45o6yq'), Comment(id='k451quv'), Comment(id='k48tteu'), Comment(id='k48eefh'), Comment(id='k45nqkl'), Comment(id='k479pts'), Comment(id='k45g4iy'), Comment(id='k47vsxz'), Comment(id='k48x39z'), Comment(id='k491vwz'), Comment(id='k47gcd6'), Comment(id='k470rnn'), Comment(id='k48aksa'), Comment(id='k481jmp'), Comment(id='k46qeer'), Comment(id='k45gb2e'), Comment(id='k47rgn2'), Comment(id='k47ysab'), Comment(id='k48ojl5'), Comment(id='k4a9q2s'), Comment(id='k4alq3t'), Comment(id='k4aznfb'), Comment(id='k4ba1gt'), Comment(id='k4bme1d'), Comment(id='k4bvoj5'), Comment(id='k4c0kqu'), Comment(id='k4ccnpy'), Comment(id='k4dwhch'), Comment(id='k4jisci'), Comment(id='k4kgpw9'), Comment(id='k47pcec'), Comment(id='k45mug7'), Comment(id='k48opo2'), Comment(id='k4788z8'), Comment(id='k47b9c2'), Comment(id='k482v5y'), Comment(id='k48nfez'), Comment(id='k4eed6m'), Comment(id='k45oi55'), Comment(id='k4jindf'), Comment(id='k4a2aqe'), Comment(id='k46ocym'), Comment(id='k49nkv0'), Comment(id='k460tbv'), Comment(id='k45j6qi'), Comment(id='k4dw1f2'), Comment(id='k471s7k'), Comment(id='k48owo6'), Comment(id='k4c4wum'), Comment(id='k49bhih'), Comment(id='k48ox6e'), Comment(id='k4aq9uq'), Comment(id='k475xlj'), Comment(id='k478bjd'), Comment(id='k49oaup'), Comment(id='k45jr9r'), Comment(id='k4847m2'), Comment(id='k479lsc'), Comment(id='k45qew9'), Comment(id='k4610la'), Comment(id='k45wjx2'), Comment(id='k47eq2h'), Comment(id='k46kc00'), Comment(id='k47pj6i'), Comment(id='k47ub7u'), Comment(id='k4841em'), Comment(id='k484my5')]"
17404sl,Expendable_0,,2023-10-09 19:08:14+00:00,False,,False,False,True,False,/r/datascience/comments/17404sl/are_you_happy_with_your_job/,Are you happy with your job?,"I see so many complaints of people who hate their job or can't find one. I am starting to wonder if this industry is awful and I have just been lucky, or if the negatives just pop up more.

How happy are you with your job?",datascience,https://www.reddit.com/r/datascience/comments/17404sl/are_you_happy_with_your_job/,47,39,0.87,"[Comment(id='k46e9tu'), Comment(id='k46ha5l'), Comment(id='k46jmnd'), Comment(id='k46fzof'), Comment(id='k46sr3m'), Comment(id='k467j6r'), Comment(id='k47ip0e'), Comment(id='k4aghny'), Comment(id='k46bj03'), Comment(id='k46bkax'), Comment(id='k483be9'), Comment(id='k4973p2'), Comment(id='k4alo9g'), Comment(id='k485iqz'), Comment(id='k46y2v7'), Comment(id='k4732nv'), Comment(id='k4737fp'), Comment(id='k474ahy'), Comment(id='k47l84n'), Comment(id='k47p2n9'), Comment(id='k47r7m7'), Comment(id='k484iiw'), Comment(id='k485vig'), Comment(id='k48a4x6'), Comment(id='k48ihdv'), Comment(id='k48mqmo'), Comment(id='k48sah8'), Comment(id='k48t1ku'), Comment(id='k48tqex'), Comment(id='k48ws10'), Comment(id='k491abk'), Comment(id='k49eqnt'), Comment(id='k4acq33'), Comment(id='k4ba54a'), Comment(id='k4fms6j'), Comment(id='k4gom2o'), Comment(id='k471st8'), Comment(id='k4cco3q'), Comment(id='k46eh6x'), Comment(id='k4azrho'), Comment(id='k46szcu'), Comment(id='k492s17'), Comment(id='k4onj10'), Comment(id='k4ap0i0'), Comment(id='k48scno'), Comment(id='k4azuxp'), Comment(id='k49iu4b'), Comment(id='k4bebbm')]"
173ubu3,Federal_Nose_6428,,2023-10-09 15:14:40+00:00,False,,False,False,True,False,/r/datascience/comments/173ubu3/what_are_some_red_flags_to_look_out_for_in_a_job/,What are some red flags to look out for in a job interview for a data job?,,datascience,https://www.reddit.com/r/datascience/comments/173ubu3/what_are_some_red_flags_to_look_out_for_in_a_job/,60,66,0.93,"[Comment(id='k45r2ik'), Comment(id='k47jigl'), Comment(id='k456123'), Comment(id='k468kb7'), Comment(id='k46lps9'), Comment(id='k47pdi7'), Comment(id='k46xo0l'), Comment(id='k45ud75'), Comment(id='k46x25z'), Comment(id='k48r4p8'), Comment(id='k48hz83'), Comment(id='k45f32r'), Comment(id='k49qhzs'), Comment(id='k4a0ds0'), Comment(id='k46rzj9'), Comment(id='k4b9v8v'), Comment(id='k49kfb5'), Comment(id='k4cjoxa'), Comment(id='k4euoz0'), Comment(id='k4fffb8'), Comment(id='k4i78ub'), Comment(id='k491b92'), Comment(id='k49ekzh'), Comment(id='k49p7t1'), Comment(id='k4cuoyl'), Comment(id='k49dgoj'), Comment(id='k491d0v'), Comment(id='k4fl4zv'), Comment(id='k456eou'), Comment(id='k45b5zm'), Comment(id='k488rts'), Comment(id='k48xx1r'), Comment(id='k491h3p'), Comment(id='k4am5mz'), Comment(id='k4fe5ja'), Comment(id='k47ui0t'), Comment(id='k48oalq'), Comment(id='k491o7v'), Comment(id='k4666jq'), Comment(id='k4fh4s6'), Comment(id='k4fh6i9'), Comment(id='k4fn242'), Comment(id='k4fljp5'), Comment(id='k49gxx3'), Comment(id='k49kaso'), Comment(id='k4g2jb9'), Comment(id='k4cuvqz'), Comment(id='k4cxjmc'), Comment(id='k4cxfpa'), Comment(id='k4g29ot'), Comment(id='k45cjnm'), Comment(id='k45fjb3'), Comment(id='k47cxhy'), Comment(id='k4f8lmd'), Comment(id='k4gcqme'), Comment(id='k46dp9w'), Comment(id='k491lkv'), Comment(id='k4evmml'), Comment(id='k47xs4g'), Comment(id='k4998v1'), Comment(id='k47yg4m'), Comment(id='k4f3c6m')]"
1740tx7,career-throwaway-oof,,2023-10-09 19:36:40+00:00,False,,1696880385.0,False,True,False,/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,How to work with product managers,"Hi all, I’m in the midst of a job search and one question I’ve been asked a few times is how I work with product managers. 

In truth, I’ve worked with product managers very little, and when I did, the partnerships were not fruitful. They generally wanted me to do exactly what they asked with minimal input from me on whether that task was worthwhile. In the worst cases, it felt like my entire job was just to keep the PM happy. This is quite different from my interactions with other stakeholders like managers, execs, etc, who have typically valued a more collaborative approach. I don’t know if this is typical—just my experience. 

Rather than ask for interview advice, I’m hoping I can prompt a more interesting discussion here on how to work well with product managers. What makes a good product manager? When is it worth pushing back on requests, and when should we just put our heads down and do what is asked? How do you balance the needs of PMs with those of other stakeholders?",datascience,https://www.reddit.com/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,14,22,0.93,"[Comment(id='k46g4ug'), Comment(id='k470jk5'), Comment(id='k46cjfk'), Comment(id='k46vslf'), Comment(id='k47hb41'), Comment(id='k48jhfq'), Comment(id='k47v77o'), Comment(id='k47x5bl'), Comment(id='k46vge8'), Comment(id='k48j3j1'), Comment(id='k4d476n'), Comment(id='k46x4dy'), Comment(id='k4k7sc8'), Comment(id='k4mvux8')]"
173l7aj,foreignparent,,2023-10-09 06:43:06+00:00,False,,False,False,True,False,/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,Most valuable data science project you've worked on for a company?,"(Previous post was removed for unclear reason)

I'm curious to hear about the impactful data science projects you've had the opportunity to work on in the corporate world. Whether it's in healthcare, finance, e-commerce, or any other industry, I'd love to know about the projects that made a significant difference.

I understand it may not be possible to go into details, but please share your experiences:

1. The industry or sector you were working in.
2. A brief description of the project.
3. The impact or results the project had on the company. 

Just to clarify, when I say “valuable” I mean from the company’s perspective.",datascience,https://www.reddit.com/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,34,57,0.96,"[Comment(id='k44jrhf'), Comment(id='k43oecx'), Comment(id='k448vyi'), Comment(id='k43yu5r'), Comment(id='k44habs'), Comment(id='k44x6qt'), Comment(id='k44s7b4'), Comment(id='k44vkg0'), Comment(id='k457ycz'), Comment(id='k46o385'), Comment(id='k44fio9'), Comment(id='k447g9k'), Comment(id='k45rmbs'), Comment(id='k46r2rp'), Comment(id='k44img2'), Comment(id='k467d6l'), Comment(id='k46rcxb'), Comment(id='k49il2s'), Comment(id='k45xy15'), Comment(id='k492vk9'), Comment(id='k44dmlc'), Comment(id='k44hbwv'), Comment(id='k44a8gr'), Comment(id='k444mwn'), Comment(id='k469x0c'), Comment(id='k4696us'), Comment(id='k469sge'), Comment(id='k469hja'), Comment(id='k469by7'), Comment(id='k46dnja'), Comment(id='k447455'), Comment(id='k46lrga'), Comment(id='k48w5uk'), Comment(id='k48xbm3')]"
173hj19,derpgod123,,2023-10-09 03:01:41+00:00,False,,False,False,True,False,/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,Why aren't there more decision support algos for doctors for differential diagnosing?,"Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn't there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?

Shit, like I'm playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn't be that hard for a machine to do right? I can't imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account ",datascience,https://www.reddit.com/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,52,47,0.91,"[Comment(id='k43na9y'), Comment(id='k432nig'), Comment(id='k43qtpl'), Comment(id='k431y9a'), Comment(id='k43ix8v'), Comment(id='k43wquf'), Comment(id='k435bnv'), Comment(id='k435rwq'), Comment(id='k43nqgy'), Comment(id='k43r8d6'), Comment(id='k436lj5'), Comment(id='k43astm'), Comment(id='k43sor1'), Comment(id='k43ixou'), Comment(id='k43wofv'), Comment(id='k43wyrc'), Comment(id='k44kg8d'), Comment(id='k44pczp'), Comment(id='k45xtnk'), Comment(id='k47h1eb'), Comment(id='k47hu3t'), Comment(id='k48gxj5'), Comment(id='k44s5e0'), Comment(id='k448cui'), Comment(id='k44fyqy'), Comment(id='k45rctg'), Comment(id='k48jt30'), Comment(id='k442wut'), Comment(id='k43yfrj'), Comment(id='k44hul4'), Comment(id='k44n1j6'), Comment(id='k44xlpj'), Comment(id='k4565xq'), Comment(id='k440kk9'), Comment(id='k433j0o'), Comment(id='k469bsh'), Comment(id='k433qsg'), Comment(id='k44jbcs'), Comment(id='k436ev9'), Comment(id='k43tuju'), Comment(id='k44qq4s'), Comment(id='k443a7d'), Comment(id='k44y7z8'), Comment(id='k49fxyw'), Comment(id='k48lmiw'), Comment(id='k48l9hc'), Comment(id='k44j49b'), Comment(id='k43yqwc'), Comment(id='k447i6z'), Comment(id='k49ix17'), Comment(id='k44rux8')]"
173hmq4,Ok_Post_149,,2023-10-09 03:06:59+00:00,False,,1696822436.0,False,True,False,/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,What data science tools have the best user experience?,"Data Science community, I've got a question for you:

Which data science tools do you find most user-friendly?

I just went live with a project I've been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I'm working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you're able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn't mind a few people ripping everything that sucks with the user experience.

Anyways, I'd love to learn about everyone's favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.

Project link: [https://www.burla.dev/](https://www.burla.dev/)",datascience,https://www.reddit.com/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,18,22,0.77,"[Comment(id='k4322c9'), Comment(id='k43268p'), Comment(id='k440au8'), Comment(id='k43y6ri'), Comment(id='k45wzpt'), Comment(id='k47oeom'), Comment(id='k432xbe'), Comment(id='k432zly'), Comment(id='k45ouzr'), Comment(id='k43nuzb'), Comment(id='k4348wc'), Comment(id='k468f8i'), Comment(id='k45oihs'), Comment(id='k45oo65'), Comment(id='k434v6r'), Comment(id='k445byg'), Comment(id='k48sjh8'), Comment(id='k49r9fi')]"
173broc,Sensitive-Main-6700,,2023-10-08 22:22:16+00:00,False,,1696808736.0,False,True,False,/r/datascience/comments/173broc/how_to_validate_data/,How to validate data?,"I'm an SWE (**not a data scientist**) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.

I started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don't think they solve the issue of validating *changes in data* (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.

What I'm looking for is a tool that validates changes in data by comparing the previous value with the new value.

In some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there's obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).

This is just an example, but it would be helpful if we can call an API to do this sort of validation for us.

And instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I'm just brainstorming here.

Would highly appreciate some recommendations/tips for tackling this problem. Thank you!",datascience,https://www.reddit.com/r/datascience/comments/173broc/how_to_validate_data/,23,52,0.9,"[Comment(id='k41yq9a'), Comment(id='k421tol'), Comment(id='k422sj4'), Comment(id='k421dna'), Comment(id='k422ynx'), Comment(id='k43mi1n'), Comment(id='k41yjnk'), Comment(id='k423dyc'), Comment(id='k423io6'), Comment(id='k427om7'), Comment(id='k42ot9n'), Comment(id='k43b5x9'), Comment(id='k43b757'), Comment(id='k43l2n0'), Comment(id='k43ncs5'), Comment(id='k43qoo8'), Comment(id='k43rtsf'), Comment(id='k43wmjy'), Comment(id='k43x7bu'), Comment(id='k4252lx'), Comment(id='k43wt3o'), Comment(id='k43r6i6'), Comment(id='k4aebfg')]"
173yyz7,Candid-Translator-89,,2023-10-09 18:22:15+00:00,False,,False,False,True,False,/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,Is there a good industry use of stable diffusion that I'm not aware of?,Working on a deep learning project with some friends. They really want to build something with SD. Will I be able to use these skills in industry?,datascience,https://www.reddit.com/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,3,1,0.67,"[Comment(id='k477yp7'), Comment(id='k49g1j3'), Comment(id='k48crau')]"
172zdgx,cazzobomba,,2023-10-08 13:38:28+00:00,False,,False,False,True,False,/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,How do data scientist managers manage data scientists?,"As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?

Some of my thoughts:

1. As a manager, I can support my DSs by **NOT** micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.

2. I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. 

3. There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. 

4. The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team’s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. 

5. Some managers think PD is solely the DS’s responsibility. Thoughts?

6. How do you deal with HR when there are no clear DS role descriptions?

Not a simple optimization problem!",datascience,https://www.reddit.com/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,56,120,0.95,"[Comment(id='k3zv5vr'), Comment(id='k3zskda'), Comment(id='k406kuj'), Comment(id='k40e484'), Comment(id='k40laxh'), Comment(id='k40y9xd'), Comment(id='k4006ff'), Comment(id='k40i917'), Comment(id='k40tqm3'), Comment(id='k430ft4'), Comment(id='k40girr'), Comment(id='k40drfp'), Comment(id='k41fq14'), Comment(id='k41qazt'), Comment(id='k41uik3'), Comment(id='k428fl7'), Comment(id='k439u22'), Comment(id='k443vk2'), Comment(id='k419h6n'), Comment(id='k418csp'), Comment(id='k40riq8'), Comment(id='k41u615'), Comment(id='k40o9t3'), Comment(id='k40qume'), Comment(id='k437eyk'), Comment(id='k40l9c8'), Comment(id='k404pbh'), Comment(id='k40ffhv'), Comment(id='k4007ui'), Comment(id='k40qada'), Comment(id='k434u9b'), Comment(id='k434ehz'), Comment(id='k41mstb'), Comment(id='k422r3w'), Comment(id='k41ntgo'), Comment(id='k40tdd5'), Comment(id='k4199e9'), Comment(id='k41rdb8'), Comment(id='k43vfmb'), Comment(id='k40hfr2'), Comment(id='k40us6a'), Comment(id='k4351sz'), Comment(id='k43ad8v'), Comment(id='k44ixb9'), Comment(id='k40uw10'), Comment(id='k436i3d'), Comment(id='k40v1qs'), Comment(id='k412wqt'), Comment(id='k42m2m7'), Comment(id='k454pcn'), Comment(id='k413quf'), Comment(id='k439df5'), Comment(id='k45g57r'), Comment(id='k43ykos'), Comment(id='k46cri9'), Comment(id='k440xf6')]"
173cl4s,,,2023-10-08 22:59:12+00:00,False,,False,False,True,False,/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,Is it possible to automate the labeling of strings of text?,"A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.

This seems like a problem for NLP but I'm unsure of where to start or just not confident. It's been at least 7 years since I've done any real 'data science' stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you've used that you like and could share.

Am I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?

I'm really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I'm not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?

Thanks for your thoughtfulness on this :)",datascience,https://www.reddit.com/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,22,15,0.9,"[Comment(id='k4243pl'), Comment(id='k42c9xi'), Comment(id='k46bna1'), Comment(id='k46r0r3'), Comment(id='k43trqs'), Comment(id='k43iu62'), Comment(id='k476b9m'), Comment(id='k4783dl'), Comment(id='k4ihp48'), Comment(id='k433qpq'), Comment(id='k4g9rdj'), Comment(id='k42f4lx'), Comment(id='k46ydgo'), Comment(id='k444u7i'), Comment(id='k44kp6f'), Comment(id='k43r4b7'), Comment(id='k478quq'), Comment(id='k43p987'), Comment(id='k46zwe6'), Comment(id='k44fp1j'), Comment(id='k4ii003'), Comment(id='k4741bc')]"
173izkk,Ok_Waltz_5145,,2023-10-09 04:23:12+00:00,False,,False,False,True,False,/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,What is the best package /approach for matching text in python?,"I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?",datascience,https://www.reddit.com/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,2,5,0.86,"[Comment(id='k43vxiz'), Comment(id='k43gz9o')]"
173im0f,AutoModerator,,2023-10-09 04:01:25+00:00,False,,False,False,True,False,/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/,"Weekly Entering & Transitioning - Thread 09 Oct, 2023 - 16 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/,83,6,1.0,"[Comment(id='k45hnzr'), Comment(id='k4ce35o'), Comment(id='k4bnmrt'), Comment(id='k4qswvz'), Comment(id='k439tu6'), Comment(id='k45ix8i'), Comment(id='k46fp42'), Comment(id='k46zfal'), Comment(id='k485kf9'), Comment(id='k48c51h'), Comment(id='k48ib26'), Comment(id='k48la36'), Comment(id='k49l8u3'), Comment(id='k49l99d'), Comment(id='k49ypvo'), Comment(id='k4b5cu8'), Comment(id='k4c08jg'), Comment(id='k4c59ka'), Comment(id='k4cr7yu'), Comment(id='k4d2pqn'), Comment(id='k4dpvwj'), Comment(id='k4e3f4q'), Comment(id='k4f565h'), Comment(id='k4gbwlv'), Comment(id='k4gdzk7'), Comment(id='k4gf6mg'), Comment(id='k4h2tin'), Comment(id='k4hf22l'), Comment(id='k4lhb94'), Comment(id='k4ml68y'), Comment(id='k4n180b'), Comment(id='k4oc951'), Comment(id='k4shgwe'), Comment(id='k4td4c8'), Comment(id='k4u2osu'), Comment(id='k4vk7xv'), Comment(id='k50temo'), Comment(id='k52kc78'), Comment(id='k45qtig'), Comment(id='k45pif1'), Comment(id='k4kpbf3'), Comment(id='k4979x8'), Comment(id='k48tict'), Comment(id='k4dwklq'), Comment(id='k49r9kx'), Comment(id='k4xi6zc'), Comment(id='k4la7no'), Comment(id='k4rvmvp'), Comment(id='k4xhwez'), Comment(id='k4pf2y4'), Comment(id='k4r3occ'), Comment(id='k4rvdum'), Comment(id='k4kr8ya'), Comment(id='k4xgs00'), Comment(id='k4pivmt'), Comment(id='k4pehdi'), Comment(id='k4ruljj'), Comment(id='k4xfw39'), Comment(id='k527zpr'), Comment(id='k4fqdrf'), Comment(id='k4603wa'), Comment(id='k4krz1i'), Comment(id='k4lfwni'), Comment(id='k4a3jhp'), Comment(id='k4m7jgg'), Comment(id='k4u86k3'), Comment(id='k4rewnf'), Comment(id='k4yxiw7'), Comment(id='k780beg'), Comment(id='k4fvl2c'), Comment(id='k462t2k'), Comment(id='k4pceoq'), Comment(id='k4uob1i'), Comment(id='k4xh5lb'), Comment(id='k4zo3fw'), Comment(id='k78oajb'), Comment(id='k4gsaze'), Comment(id='k468sv4'), Comment(id='k4vrkkx'), Comment(id='k4zoy2g'), Comment(id='k78qkfm'), Comment(id='k46ag0d'), Comment(id='k78rwpe'), Comment(id='k46g0e8')]"
173dd6h,,,2023-10-08 23:34:25+00:00,False,,False,False,True,False,/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,What advice would you give someone starting out on learning to collaborate on large projects and not be the sole person responsible for a model build?,"I'm starting out on a team that is very collaborative and I've realized that while I've worked with other people before, I'm not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. 

Does anyone have advice for dealing with what almost feels like getting territorial over a model? It's nothing against the people on my team - they've all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like ""I built that."" It also almost feels like it's my fault for not being able to do all of the work myself, like if I was a better worker I'd be able to get more of the work done and people wouldn't have to pick up my slack.

Is this something that just goes away with time if you continue working on a team that works in this way? I didn't expect there to be an emotional challenge component to this and I'm struggling to know what to do and how to adapt, especially because this doesn't feel like the kind of thing you can really share/get support from coworkers on, because they're the ones working on it with me if that makes sense.",datascience,https://www.reddit.com/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,3,11,1.0,"[Comment(id='k43k12v'), Comment(id='k42hws3'), Comment(id='k42zske')]"
173cxz4,EcstaticStructure830,,2023-10-08 23:14:48+00:00,False,,False,False,True,False,/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/,"What is currently the most in demand Analytics/DS by Healthcare institutions (hospitals, clinics, big pharma, government, etc.)?",,datascience,https://www.reddit.com/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/,2,7,0.82,"[Comment(id='k42cd1p'), Comment(id='k43qiua')]"
172gy7a,dopplegangery,,2023-10-07 21:08:48+00:00,False,,False,False,True,False,/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,"Should we use non-linear models for ""linear"" data?","So I had an argument with an interviewer who asked me why I didn't just use a non-linear classification model on the linearly separable data that I had in one of my projects that I described to him, even though I had no computational constraints. I told him that it was because, irrespective of computational cost, a linear model is always preferable if you have linear data because it is simpler and captures general pattern while non-linear models might overfit on  local patterns. But he kept disagreeing and saying that the only advantage that a linear model would have is computational cost and explainability even though I was actually getting better results with a logistic regression.

Who do you think was missing something here and why?",datascience,https://www.reddit.com/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,123,159,0.95,"[Comment(id='k3wlel7'), Comment(id='k3wpzmq'), Comment(id='k3wm9xj'), Comment(id='k3wm6rg'), Comment(id='k3wt6nt'), Comment(id='k3wv1bu'), Comment(id='k3wlocb'), Comment(id='k3x6pz7'), Comment(id='k3x01te'), Comment(id='k3x243y'), Comment(id='k3x88yj'), Comment(id='k3x5k2s'), Comment(id='k3wv81r'), Comment(id='k3wwz5y'), Comment(id='k3wy2is'), Comment(id='k3x77v4'), Comment(id='k3xa4ti'), Comment(id='k400ltn'), Comment(id='k40513j'), Comment(id='k3wslpb'), Comment(id='k3wt2fh'), Comment(id='k3xgqgc'), Comment(id='k3wutmv'), Comment(id='k3xivis'), Comment(id='k3y8nw5'), Comment(id='k3ypmqw'), Comment(id='k3zc4k5'), Comment(id='k3zi3y5'), Comment(id='k3zo6wz'), Comment(id='k40ejpr'), Comment(id='k40fzt4'), Comment(id='k40g6ff'), Comment(id='k40oia8'), Comment(id='k43nqae'), Comment(id='k3z11kb'), Comment(id='k3wwovs'), Comment(id='k3zd3wr'), Comment(id='k3yfbev'), Comment(id='k3yfy9x'), Comment(id='k3x9itg'), Comment(id='k3yfsj4'), Comment(id='k41dre2'), Comment(id='k41e5je'), Comment(id='k3xrk0h'), Comment(id='k3x6edx'), Comment(id='k3wx7dl'), Comment(id='k3xkesd'), Comment(id='k41fq1g'), Comment(id='k43ayps'), Comment(id='k408n0n'), Comment(id='k3x6q0g'), Comment(id='k3x69lz'), Comment(id='k3xsx4z'), Comment(id='k3x4ic8'), Comment(id='k3xw7cy'), Comment(id='k3yevmi'), Comment(id='k3yeown'), Comment(id='k3zsz0v'), Comment(id='k40f4ao'), Comment(id='k40h6bx'), Comment(id='k40uv1e'), Comment(id='k3znsgg'), Comment(id='k40re9m'), Comment(id='k41d1ph'), Comment(id='k3yj1t2'), Comment(id='k3yhswa'), Comment(id='k3xmu5a'), Comment(id='k3xmu8m'), Comment(id='k3wxdsw'), Comment(id='k3x87nj'), Comment(id='k3ysjft'), Comment(id='k3xw2up'), Comment(id='k3xwwq5'), Comment(id='k40nppk'), Comment(id='k40kc1h'), Comment(id='k41fm2k'), Comment(id='k41d8qw'), Comment(id='k41fcrl'), Comment(id='k3yrkw4'), Comment(id='k41hs3x'), Comment(id='k3xwc8h'), Comment(id='k3xqbbf'), Comment(id='k3wxzm8'), Comment(id='k3xjui8'), Comment(id='k3xqny2'), Comment(id='k3x8t9g'), Comment(id='k3xyl8e'), Comment(id='k41ekk6'), Comment(id='k41u1x7'), Comment(id='k40qiv4'), Comment(id='k40v399'), Comment(id='k41mzt3'), Comment(id='k41fu5m'), Comment(id='k47i4n6'), Comment(id='k41t8qi'), Comment(id='k3xs3vl'), Comment(id='k3y5vxh'), Comment(id='k3xvb67'), Comment(id='k3xrz6l'), Comment(id='k3xqwb2'), Comment(id='k3x9dsp'), Comment(id='k3ysn3r'), Comment(id='k41f3hh'), Comment(id='k40zcx8'), Comment(id='k41nxzl'), Comment(id='k41loa1'), Comment(id='k47q9sz'), Comment(id='k43ks2o'), Comment(id='k3xsrud'), Comment(id='k3y6tub'), Comment(id='k3y91ei'), Comment(id='k3ytj98'), Comment(id='k3z1zrb'), Comment(id='k41knq6'), Comment(id='k41tm0o'), Comment(id='k41ob61'), Comment(id='k41mqnk'), Comment(id='k40tynr'), Comment(id='k3z4ikr'), Comment(id='k41ojvh'), Comment(id='k41or6n'), Comment(id='k422s4p'), Comment(id='k41q4ni'), Comment(id='k41qn1h'), <MoreComments count=0, children=[]>]"
17369yn,fhckgkgkgjdh,,2023-10-08 18:31:50+00:00,False,,False,False,True,False,/r/datascience/comments/17369yn/running_arima_models/,Running ARIMA Models,Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!,datascience,https://www.reddit.com/r/datascience/comments/17369yn/running_arima_models/,3,3,0.72,"[Comment(id='k416br8'), Comment(id='k42cqlz'), Comment(id='k43frda')]"
1731r1r,nuriel8833,,2023-10-08 15:19:43+00:00,False,,False,False,True,False,/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,Automation of insights extraction from Clustering,"So I've been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don't think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?

The only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don't know how much I'm up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let's say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).

Is there even any method to do that? Or should I just insist that it is not feasible?  
Thanks",datascience,https://www.reddit.com/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,0,2,0.76,[]
17316vc,AutomaticResearch337,,2023-10-08 14:57:58+00:00,False,,False,False,True,False,/r/datascience/comments/17316vc/image_detection_with_cnn_model/,Image Detection with CNN Model,"I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. 

I don't know how will i link the annotated JSON file of the images when training. Does anyone know how?",datascience,https://www.reddit.com/r/datascience/comments/17316vc/image_detection_with_cnn_model/,9,2,0.67,"[Comment(id='k4083wj'), Comment(id='k4108dl'), Comment(id='k43df3o'), Comment(id='k7wedu4'), Comment(id='k4ef4q8'), Comment(id='k44s6ta'), Comment(id='k4ef7u6'), Comment(id='k4efayn'), Comment(id='k4eggyh')]"
17212yf,HStuart18,,2023-10-07 08:19:09+00:00,False,,1696733213.0,False,True,False,/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,Why are there no good graph visualisation programs?,"Does anyone know of any half decent graph/network visualisation programs? Gephi is very frustrating to use (can only view up to 20 attribute columns at once, can't inspect node/edge attributes from the graph view, attribute values only allow you to copy the abbreviated scientific notation form etc.)

This is what I am trying to do... I have a graph (heterogenous but I can compress it to homogenous if absolutely necessary) and I want to be able to interactively visualise said graph. If I click on a node or edge, I wish to be able to see the attributes of that node or edge. Preferably, I'd also be able to colour nodes and edges by attribute.

There seems to be a few small bespoke projects but from the few I've tried, none have achieved what I have outlined above - what I would have thought to be the bare minimum for a graph visualisation application.

&#x200B;

**EDIT**

Cytoscape standalone is definitely the way to go for me. Would highly recommend over Gephi. Still had to flatten my heterogenous graph, appending all attributes across all types, but with a specified `TYPE` attribute you can conditionally colour within Cytoscape so it gets you there in the end (bit annoying that every node/edge has redundant attributes from other node/edge types but it's not the end of the world.) Thanks for all the suggestions.",datascience,https://www.reddit.com/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,40,77,0.9,"[Comment(id='k3u5ia6'), Comment(id='k3tw1hh'), Comment(id='k3tuscs'), Comment(id='k3uks9y'), Comment(id='k3ui37f'), Comment(id='k3w4556'), Comment(id='k3v3xa4'), Comment(id='k3u01v0'), Comment(id='k3uoduj'), Comment(id='k3v0bf5'), Comment(id='k3v7ftg'), Comment(id='k3vjv8d'), Comment(id='k3vx33v'), Comment(id='k3tv630'), Comment(id='k3ujtbw'), Comment(id='k3vfwyv'), Comment(id='k3vqd7n'), Comment(id='k3vsktt'), Comment(id='k3wc8d2'), Comment(id='k3wnvsj'), Comment(id='k42vjzs'), Comment(id='k4a570y'), Comment(id='k4hfk6h'), Comment(id='k3u6cba'), Comment(id='k3u1mkw'), Comment(id='k3u1ftg'), Comment(id='k3uvfy0'), Comment(id='k3u2282'), Comment(id='k3vupqe'), Comment(id='k3ws5lx'), Comment(id='k3u2dpa'), Comment(id='k42yaci'), Comment(id='k3u909t'), Comment(id='k3u7zt1'), Comment(id='k3upd7k'), Comment(id='k3uu3lo'), Comment(id='k3vjy4n'), Comment(id='k3wvhlf'), Comment(id='k3u8bpq'), Comment(id='k3yow0d')]"
1726i2h,Skilinger,,2023-10-07 13:33:11+00:00,False,,False,False,True,False,/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,How do I make use of other parameters' forecasts for time series forecasting?,"Topic might be a bit confusing, let me elaborate. For example let's say I'm working on a time series forecasting problem and I found that temperature is highly correlated with my target. But I also know it's a time series problem, so I want to boost my model by giving it probable temperature for the target dates. How do I do that? I can't wrap my head around it",datascience,https://www.reddit.com/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,15,7,0.78,"[Comment(id='k3uy9gj'), Comment(id='k3vi39v'), Comment(id='k3ut9p8'), Comment(id='k3vdgk2'), Comment(id='k3wlws1'), Comment(id='k3xdwut'), Comment(id='k4029sh'), Comment(id='k3vwi4m'), Comment(id='k3uy3jf'), Comment(id='k3v28qu'), Comment(id='k3vd17u'), Comment(id='k3vw60p'), Comment(id='k3vg1wl'), Comment(id='k3vx4vh'), Comment(id='k3vzdom')]"
172ko0y,jrdubbleu,,2023-10-07 23:51:53+00:00,False,,False,False,True,False,/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,Data Cleaning & Wrangling Standards?,"Are there any industry standard frameworks for data cleaning and wrangling? Naming conventions, order of operations (when to do imputation, detecting careless cases, etc.) that companies and researchers use to make shareable uniform datasets?",datascience,https://www.reddit.com/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,4,0,0.5,"[Comment(id='k405vme'), Comment(id='k3xc77t'), Comment(id='k41b75l'), Comment(id='k465tj8')]"
172subu,shostakophiles,,2023-10-08 07:13:14+00:00,False,,False,False,True,False,/r/datascience/comments/172subu/a_controversial_request_but_please_help_me_out_in/,"a controversial request, but please help me out in defending that sarcasm doesn't affect sentiment analysis","bit more context— me and my groupmates are conducting a study in which we would determine a person's MBTI (a personality classification method) based on their posts on twitter using sentiment analysis. 

since our research focuses on personality classification instead of identifying a statement's positive and negative connotations, we decided to exclude sarcasm out of the equation since we treat every user's word as a determining factor of their MBTI. but our thesis moderator asked the concern regarding sarcasm out of curiosity and we still have quite some struggles defending this idea.

any help would be appreciated, thanks!",datascience,https://www.reddit.com/r/datascience/comments/172subu/a_controversial_request_but_please_help_me_out_in/,32,0,0.41,"[Comment(id='k3ys8se'), Comment(id='k3yzmao'), Comment(id='k3ynbx4'), Comment(id='k3z2vkg'), Comment(id='k3z016z'), Comment(id='k3zbpix'), Comment(id='k3zj01d'), Comment(id='k3z91m6'), Comment(id='k40fyf6'), Comment(id='k3zr5wz'), Comment(id='k3zf5y4'), Comment(id='k41vgg2'), Comment(id='k404q6m'), Comment(id='k3z3k09'), Comment(id='k41agwz'), Comment(id='k42lyb3'), Comment(id='k4knfxn'), Comment(id='k3z90bp'), Comment(id='k3z7x2w'), Comment(id='k41v8nz'), Comment(id='k3zgq5x'), Comment(id='k3zm4ng'), Comment(id='k3znj7l'), Comment(id='k3z9m59'), Comment(id='k40iw3f'), Comment(id='k3zvl5s'), Comment(id='k43jcff'), Comment(id='k4awad6'), Comment(id='k43j1s1'), Comment(id='k4b09tp'), Comment(id='k4b5u52'), Comment(id='k4b784o')]"
1729cnh,Aislin777,,2023-10-07 15:42:34+00:00,False,,1696693907.0,False,True,False,/r/datascience/comments/1729cnh/webbased_app_recommendations/,Web-based App Recommendations,"Hi all! 

I'm attempting to add some value at work. For context, I'm a Data Analytics Consultant at a small consulting firm where most of the data-related work is done by the DA team based out of India. The issue is that they just blew $10 million on a low-code app to streamline some of our company's offerings. Bottom line, it doesn't work and when it does it only works for cookie cutter cases. Regardless, they're the ones who get the funding and I'm the only Data Analyst in the US, where I was told they don't see the value in true DA/DS. What I would like to do is use open-source tools to recreate what the team in India was trying to do. Some of the base features would be being able to allow clients to fill out a survey of questions, read that to a SQL server I'll have to build, and publish multiple different dashboards (we currently use Tableau, but I figure I will need a web-based dashboard, such as Dash). 

When I was researching tools, they all read like ads, so I wanted to see what open-source tools others recommend from experience. For programming, I mainly use Python, though I am family with R as well. I'm also fine upskilling where needed, within reason (the bottleneck is time due to required chargeability at work and Master's coursework load).

Thanks in advance!

Edit: UI/UX will be pretty important since it is client work.",datascience,https://www.reddit.com/r/datascience/comments/1729cnh/webbased_app_recommendations/,8,3,1.0,"[Comment(id='k407xb2'), Comment(id='k47ppoy'), Comment(id='k3vb2a6'), Comment(id='k3xnsdj'), Comment(id='k41045r'), Comment(id='k481zwu'), Comment(id='k3wrec2'), Comment(id='k3yeb0w')]"
171jptd,mkworkplay,,2023-10-06 18:21:08+00:00,False,,False,False,True,False,/r/datascience/comments/171jptd/is_there_any_benefit_for_a_data_analyst_to_learn_c/,Is there any benefit for a Data Analyst to learn C#?,"I know that SQL and R / Python are the main languages to use, but is there any helpful reason to learn C#?",datascience,https://www.reddit.com/r/datascience/comments/171jptd/is_there_any_benefit_for_a_data_analyst_to_learn_c/,103,66,0.88,"[Comment(id='k3r2nr3'), Comment(id='k3r2i2w'), Comment(id='k3rimv8'), Comment(id='k3seaic'), Comment(id='k3rk203'), Comment(id='k3rvt01'), Comment(id='k3u1oz0'), Comment(id='k3rly1o'), Comment(id='k3sysg8'), Comment(id='k3r200a'), Comment(id='k3r7fod'), Comment(id='k3s5yjn'), Comment(id='k3sqb90'), Comment(id='k3tyrzl'), Comment(id='k3swtat'), Comment(id='k3rx14m'), Comment(id='k3t0iau'), Comment(id='k3t6v5x'), Comment(id='k3uxl7a'), Comment(id='k3v7m56'), Comment(id='k3vr4td'), Comment(id='k3xmin7'), Comment(id='k408thg'), Comment(id='k3r2i03'), Comment(id='k3rah4e'), Comment(id='k3s1ytd'), Comment(id='k3sb1je'), Comment(id='k3sno08'), Comment(id='k3rbax1'), Comment(id='k3rsxsy'), Comment(id='k3t3vyh'), Comment(id='k3txn82'), Comment(id='k3sik8i'), Comment(id='k3rb5um'), Comment(id='k3sil3f'), Comment(id='k3sqn5g'), Comment(id='k3t7uq7'), Comment(id='k3ue6ra'), Comment(id='k3wrmbk'), Comment(id='k3y9xeo'), Comment(id='k3yvt4y'), Comment(id='k41xqry'), Comment(id='k3tggru'), Comment(id='k3xqizn'), Comment(id='k3r8ot7'), Comment(id='k3rw97z'), Comment(id='k3rkyrl'), Comment(id='k3rvvnp'), Comment(id='k3rw8ei'), Comment(id='k3sqrfy'), Comment(id='k409hvo'), Comment(id='k3rbvdw'), Comment(id='k3rwveh'), Comment(id='k3rbdnf'), Comment(id='k3xrs84'), Comment(id='k3rbff3'), Comment(id='k3rgt85'), Comment(id='k3s0gmx'), Comment(id='k3rywzo'), Comment(id='k3su7my'), Comment(id='k3ufnqv'), Comment(id='k3rmxdh'), Comment(id='k3ruohk'), Comment(id='k3xixhw'), Comment(id='k3sr0yd'), Comment(id='k3t8ay7'), Comment(id='k3rj0q1'), Comment(id='k3tv5gt'), Comment(id='k3rcvub'), Comment(id='k3re26s'), Comment(id='k3rxtv1'), Comment(id='k3rwjei'), Comment(id='k3uj17q'), Comment(id='k3vrcls'), Comment(id='k3rqgi4'), Comment(id='k3tist8'), Comment(id='k3s9xrl'), Comment(id='k3x4m4m'), Comment(id='k3rqipq'), Comment(id='k3rxuyf'), Comment(id='k3ryffl'), Comment(id='k3rwxn4'), Comment(id='k3v6jsr'), Comment(id='k3vdet1'), Comment(id='k3uv747'), Comment(id='k3uhawa'), Comment(id='k3rvehz'), Comment(id='k3s53nh'), Comment(id='k3s2381'), Comment(id='k3s0mcb'), Comment(id='k3rx7ne'), Comment(id='k3vmyzq'), Comment(id='k3vjxa0'), Comment(id='k3ryejb'), Comment(id='k3sx772'), Comment(id='k3s5ujn'), Comment(id='k3ry404'), Comment(id='k3rxsde'), Comment(id='k3ryzp4'), Comment(id='k3rz971'), Comment(id='k3rzrvl'), <MoreComments count=0, children=[]>]"
171872q,pg860,,2023-10-06 09:52:28+00:00,False,,1696586317.0,False,True,False,/r/datascience/comments/171872q/the_most_soughtafter_data_science_skills/,The most sought-after Data Science skills,"I've analyzed 9,261 job openings' descriptions in Data Science, Machine Learning and ML OPS ([https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)) and prepared a list of the most sought-after skills. It turns out that the most desired skill is ... Communication - for all roles.

https://preview.redd.it/ey54l3290ksb1.png?width=2560&format=png&auto=webp&s=7a1746fa0d9ed2293374c54fce312a237d7d2eda

Communication actually surpasses Python in popularity, which I am really shocked about because it seems that for a Data Scientist, the most frequent communication should be with a computer.

https://preview.redd.it/b7ozarxq0ksb1.png?width=2560&format=png&auto=webp&s=3e8fc32e864ba4b0ed0edaf4e56daee4cadc6b62

About the dataset: 9,261 Job openings crawled from 1605 companies worldwide, between June-Sep 2023.",datascience,https://www.reddit.com/r/datascience/comments/171872q/the_most_soughtafter_data_science_skills/,89,314,0.94,"[Comment(id='k3p34te'), Comment(id='k3pbk3n'), Comment(id='k3p3n0u'), Comment(id='k3pc9sx'), Comment(id='k3ptn22'), Comment(id='k3pjppr'), Comment(id='k3qa8hr'), Comment(id='k3rr1rb'), Comment(id='k3p3ohs'), Comment(id='k3pemi6'), Comment(id='k3qft14'), Comment(id='k3qr6cy'), Comment(id='k3quk9a'), Comment(id='k3t9q5q'), Comment(id='k3pqko6'), Comment(id='k3q9n7t'), Comment(id='k3rdf7j'), Comment(id='k3rwypz'), Comment(id='k3rx7bs'), Comment(id='k3s6xcd'), Comment(id='k3s9mdw'), Comment(id='k3sgpv7'), Comment(id='k3ppktv'), Comment(id='k3pkv1v'), Comment(id='k3q6vgo'), Comment(id='k3qaq5f'), Comment(id='k3q0mas'), Comment(id='k3q5h3k'), Comment(id='k3r0nye'), Comment(id='k3r1aeb'), Comment(id='k3r6tue'), Comment(id='k3rc4vl'), Comment(id='k3s79mf'), Comment(id='k3sgifo'), Comment(id='k3u1j4z'), Comment(id='k3uisgw'), Comment(id='k3v2br6'), Comment(id='k3v9i0b'), Comment(id='k3wqwyb'), Comment(id='k41kd97'), Comment(id='k432gjj'), Comment(id='k7dja5l'), Comment(id='k3ph0jx'), Comment(id='k3riz6j'), Comment(id='k3q1c92'), Comment(id='k3sduo0'), Comment(id='k3qq43t'), Comment(id='k3s0wxa'), Comment(id='k3u7ocy'), Comment(id='k3rhsi2'), Comment(id='k3pr8r4'), Comment(id='k3u1vu9'), Comment(id='k3q1pef'), Comment(id='k3r5jm4'), Comment(id='k3r7zb2'), Comment(id='k3r7qji'), Comment(id='k3rw40n'), Comment(id='k3paa5a'), Comment(id='k3q1bee'), Comment(id='k3prafo'), Comment(id='k3pu098'), Comment(id='k3sue9z'), Comment(id='k3v54lu'), Comment(id='k3s1z5v'), Comment(id='k3prdxl'), Comment(id='k3ty88e'), Comment(id='k3phkij'), Comment(id='k3stj0g'), Comment(id='k3r2o93'), Comment(id='k3tdlkv'), Comment(id='k3s7own'), Comment(id='k3pp19a'), Comment(id='k3pvjvl'), Comment(id='k3pjb73'), Comment(id='k3qaw88'), Comment(id='k3ptmcc'), Comment(id='k3uetwk'), Comment(id='k3tluqr'), Comment(id='k3v4jni'), Comment(id='k3pps6w'), Comment(id='k3qjmem'), Comment(id='k3rliju'), Comment(id='k3urqps'), Comment(id='k3wttm3'), Comment(id='k3qthtj'), Comment(id='k3qz8wh'), Comment(id='k3ty3i2'), Comment(id='k3qz41f'), Comment(id='k3rdvm5')]"
171yhvm,EnPaceRequiescat,,2023-10-07 05:40:05+00:00,False,,False,False,True,False,/r/datascience/comments/171yhvm/clickable_plots/,Clickable plots?,"Hi all, I was wondering if there are packages/tools that allow one to click on data points and trigger actions, e.g. for interactive sites.

Example workflow for this:

\- plot helps to visualize data, click on a set of interesting outliers, those points are auto-selected and incorporated into a list, so that I can show a dynamic dataframe showing all of the selected points for more inspection.

\- click on a point to link to a new page view

I.e. tools like plotly allow me to inspect data nicely, even with hover data to show more information, or even the index of a point in a data frame. But then if I want to inspect and work with a set of points that I find interesting, right now I awkwardly have to manually note the data points, select them by code, and do something else. I'd like to do this in a more seamless way with a slicker interface.  


I think this might be possible with something like d3 but I'm wondering if there are easier to use tools. Thanks!

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/171yhvm/clickable_plots/,16,6,0.88,"[Comment(id='k3tngj9'), Comment(id='k3tp1mp'), Comment(id='k3tncop'), Comment(id='k3whc5z'), Comment(id='k3tio4y'), Comment(id='k3uvika'), Comment(id='k3uwxft'), Comment(id='k4dt5iq'), Comment(id='k464mfu'), Comment(id='k3tljgb'), Comment(id='k3uw4ba'), Comment(id='k4ef708'), Comment(id='k3unq0s'), Comment(id='k3yw7j8'), Comment(id='k3v1jhp'), Comment(id='k3v3pkl')]"
171mgku,Odd-Struggle-3873,,2023-10-06 20:13:10+00:00,False,,False,False,True,False,/r/datascience/comments/171mgku/huge_data_issues/,Huge data issues,"So today it broke me, after weeks of battles. I work for a large international company but this company is so immature. It’s like a teenager that doesn’t know what its limbs are doing.

I know a large part of our work is cleaning data but my issues go beyond this. The data are fundamentally flawed, joins don’t work and literally no-one claims ownership of this, 30-70% of some features are just missing. I think this will be the demise of the company. Sometimes I literally cannot do my job.

Has any one here where worked for such a company? Has anyone ever successfully led change in such a situation?",datascience,https://www.reddit.com/r/datascience/comments/171mgku/huge_data_issues/,10,10,0.86,"[Comment(id='k3rprrf'), Comment(id='k3s2wm7'), Comment(id='k3svtn2'), Comment(id='k3zbjsi'), Comment(id='k42wjnx'), Comment(id='k3t0r1w'), Comment(id='k3spbis'), Comment(id='k3tior2'), Comment(id='k3zi3vh'), Comment(id='k3tijmu')]"
171magw,PM_ME_SomethingNow,,2023-10-06 20:06:11+00:00,False,,False,False,True,False,/r/datascience/comments/171magw/eye_tracking_data/,Eye Tracking Data,"Hey all,

I am a neuroscience Ph.D. student working with some eye-tracking data. The typical approach in my lab has been to try and fit the data to a GLM. Which is fine as a first pass, but I don't want to be limited to just that. I am curious if anyone else here has worked with eye-tracking data and can point me in the right direction. As far as the details are concerned, I am collecting eye-tracking data in few experimental contexts. I would go into detail, but I want to stay at least a bit vague for privacy concerns. 

But to give you some idea of what I am doing, I have one task where participants are looking for a certain stimulus among distractor stimuli. The primary measurable output of this experiment is what stimulus they move their eyes to. But I am sure there is more information captured in the eye-tracking data that we can leverage. Another experiment is looking at overall gaze stability to infer cognitive mechanisms. 

If anyone is interested, I am willing to go in to more detail via PM. Any help would be appreciated! My first instinct to use some form of logistic regression or SVM and check performance. Let me know if I am on the right track.",datascience,https://www.reddit.com/r/datascience/comments/171magw/eye_tracking_data/,6,6,0.8,"[Comment(id='k3s04ja'), Comment(id='k3rk98w'), Comment(id='k409y3u'), Comment(id='k3t29qs'), Comment(id='k3t2j0g'), Comment(id='k3tnlar')]"
171p218,WadeEffingWilson,,2023-10-06 21:59:00+00:00,False,,1696630136.0,False,True,False,/r/datascience/comments/171p218/is_it_possible_to_have_a_nongaussian_mixture_and/,Is it possible to have a non-Gaussian mixture and can it be easily decomposed?,"I'm trying to work out a theory that the population distribution I have is a mixture. Specifically, I'm wanting to see if meaningful clusters exist in this single variable. The variable is a similarity measurement between a lot of smaller sets, so there's an expectation (and observation) that the distribution is heavily right skewed. I'm not sure if it's exponential, chi-squared, wiebull, or poisson but I think that's less about the geometry and more about the mechanisms that created it.

To be clear, the means of each would be different. The population shows multiple modes. 

I'm used to decomposing mixtures where there's an expectation that they are each normally distributed but I'm completely lost when that assumption isn't held up. I want to say that k-means (gmm being a generalization of this) assumes normal distributions. Would hierarchical clustering work here or is it subject to the same assumption?

I'm not super sharp on stats. I know enough to get by but it's an ongoing learning process. Apologize if I've made a mistake or an incorrect assumption.",datascience,https://www.reddit.com/r/datascience/comments/171p218/is_it_possible_to_have_a_nongaussian_mixture_and/,13,4,0.75,"[Comment(id='k3s2fgi'), Comment(id='k3tgbp8'), Comment(id='k3u2h5j'), Comment(id='k3sj7sj'), Comment(id='k3u2c4d'), Comment(id='k3u6j8a'), Comment(id='k3tje4n'), Comment(id='k3tanoa'), Comment(id='k3wwr0t'), Comment(id='k3vgdo7'), Comment(id='k3vpc33'), Comment(id='k3vyy13'), Comment(id='k3wgvu5')]"
171mmpq,spx416,,2023-10-06 20:20:18+00:00,False,,False,False,True,False,/r/datascience/comments/171mmpq/plotting_precalculated_embeddings_onto/,Plotting pre-calculated embeddings onto tensorboard projector,"Hello, I have a file with embeddings already calculated and I want to use tensorboard to project those embeddings. I have no need for metadata at this point. I want to know how to do it, all the tutorials I have seen use their own machine learning model to calculate the embeddings and then save to a checkpoint but I don't need to do that. Any tutorial or resource is greatly appreciated. ",datascience,https://www.reddit.com/r/datascience/comments/171mmpq/plotting_precalculated_embeddings_onto/,0,0,0.5,[]
1717sp8,Salt_Macaron_6582,,2023-10-06 09:25:54+00:00,False,,False,False,True,False,/r/datascience/comments/1717sp8/software_engineering_to_ml_engineeringmlops/,Software Engineering to ML engineering/MLOps,"Is software experience valued in the world of machine learning on the operations side? I'm currently working as a fullstack software engineer while rounding of a BSc in artificial intelligence. I develop applications for machine learning projects and am involved in A/B testing, some minor langchain stuff, data vizualisation, data modelling so there is relatively much alignment with AI. I was wondering whether this experience is valuable if I would want to switch to an engineering heavy ML role. Is there a lot demand for people that can deploy models, do A/B testing, make APIs, and maybe do some light modelling while not being at the level of the phds and MSc CS people that qualify for the straight up data science/research enyineer roles in terms of maths/ML?",datascience,https://www.reddit.com/r/datascience/comments/1717sp8/software_engineering_to_ml_engineeringmlops/,3,5,1.0,"[Comment(id='k3p7qg3'), Comment(id='k3phppv'), Comment(id='k473h3s')]"
170jlh2,LeaguePrototype,,2023-10-05 14:35:53+00:00,False,,False,False,True,False,/r/datascience/comments/170jlh2/lessons_from_my_2_year_job_search/,Lessons From my 2 Year Job Search,"I just wanted to share some insights from my lengthy job hunt that recently ended on a somewhat positive note. If this resonates with people, I might expand it into a Medium article. My aim is to discuss my experiences, help others, and encourage debate to refine these ideas. I've already applied these learnings to help friends land decent jobs, so I hope it helps you too. This is particularly aimed at those starting their careers in data.

A bit about me: I have 7 years of statistics education and a Master's from a reputable U.S. public school. Graduated amid COVID, I became a model & bottle promoter in Europe while freelancing as a data scientist/analyst. Landed a corperate Data Analyst role last month.

1: Experience Over Education

Your education should solely be a stepping stone to gain experience, be it through internships, entry-level positions, or research. Don't overestimate the power of theoretical knowledge; practical experience reigns supreme. Grades only serve as a ticket to initial experiences.

2 and 3: Refer to Point 1

4: Understanding HR/Recruiters

When writing your resume or preparing for interviews, keep it simple but impactful. Recruiters skim through resumes, so your accomplishments should stand out and be quantifiable. Misrepresenting numbers isn't advisable but emphasizing impact is.

5: Always Be Active

If you're job-hunting, always have a project in the works. Freelance gigs are relatively easy to find, and they add valuable experience to your resume. Keep records of your work—publish articles, maintain a GitHub repository, or hold onto contracts.

6: Networking and Luck

Networking is crucial, and often it's not about what you know but who you know. Being at the right place at the right time can spell success. Lack of social skills will be a bottleneck to career growth even when technical skills are stellar.

7: Company Culture vs Reality

Companies may claim to value innovation and talent, but what they're really looking for are reliable candidates who won't mess up. They're impressed by practical business experience, not academic projects or grades. Phrases like ""innovative culture"", ""entrepreneurial"",  ""solving the largest problems"", ""looking for the most talented people"", etc. are all lies especially for starting out.

8: Avoid Targeting Remote Jobs

Targeting only remote jobs was my biggest mistake. Remote positions usually require a significant amount of experience, so aim for local opportunities or consider relocating.

Final Words
Always prioritize your needs over the company's. Don't shy away from promoting yourself or taking new offers even at the last minute. Most companies are self-centered, and as an employee, you should adopt the same approach to your advantage.

Hope this helps, and I'd love to hear your thoughts!",datascience,https://www.reddit.com/r/datascience/comments/170jlh2/lessons_from_my_2_year_job_search/,39,158,0.95,"[Comment(id='k3l8m8v'), Comment(id='k3l7atc'), Comment(id='k3l8bd1'), Comment(id='k3om8j1'), Comment(id='k3owu0q'), Comment(id='k3m0g9b'), Comment(id='k3nn7j8'), Comment(id='k3pbhf3'), Comment(id='k3x8e6f'), Comment(id='k49k3ut'), Comment(id='k3m2om8'), Comment(id='k3lj9i8'), Comment(id='k3ljyi6'), Comment(id='k3lf5jl'), Comment(id='k3lbb1e'), Comment(id='k3mn56q'), Comment(id='k3ow0zf'), Comment(id='k3oqf80'), Comment(id='k3pbp93'), Comment(id='k49t0mw'), Comment(id='k3mi8to'), Comment(id='k3p388a'), Comment(id='k3mvljq'), Comment(id='k3ld0qz'), Comment(id='k3lixzy'), Comment(id='k3n2vo0'), Comment(id='k3mq7zu'), Comment(id='k3qji37'), Comment(id='k49xjiz'), Comment(id='k3n4wyu'), Comment(id='k3nh72q'), Comment(id='k3lw0vl'), Comment(id='k3ojbdo'), Comment(id='k3qtdrj'), Comment(id='k3n3cg6'), Comment(id='k3ojprc'), Comment(id='k3ovgc3'), Comment(id='k3okecr'), Comment(id='k3q0xa7')]"
1719n3t,LegitimateAd4716,,2023-10-06 11:18:14+00:00,False,,False,False,False,False,/r/datascience/comments/1719n3t/removing_outliers_using_dbscan/,Removing outliers using DBScan,I’m working on this used cars dataset. I need to remove the outliers as there are a lot of them. Would DBscan be a good method to implement.. if yes then on which all columns??,datascience,https://i.redd.it/0hs2dhpdgksb1.jpg,8,0,0.5,"[Comment(id='k3pf4ln'), Comment(id='k3rqodh'), Comment(id='k3ply3p'), Comment(id='k40bed1'), Comment(id='k3s2898'), Comment(id='k3sgi4i'), Comment(id='k3pswzc'), Comment(id='k3tbrea')]"
170zg4y,unbrkbleheaven,,2023-10-06 01:24:32+00:00,False,,False,False,True,False,/r/datascience/comments/170zg4y/is_it_worth_it_double_majoring_in_economics_and/,Is it worth it double majoring in Economics and Science?,"I plan on transferring universities to pursue an Economics degree and maybe also double majoring in Data Science, however I noticed many Data Science job listings also accept Economics degrees. Is it pointless to major in both and I should try to diversify it, or would majoring in both actually make me a stronger candidate?",datascience,https://www.reddit.com/r/datascience/comments/170zg4y/is_it_worth_it_double_majoring_in_economics_and/,3,4,1.0,"[Comment(id='k3nwjvl'), Comment(id='k3owsyr'), Comment(id='k4j9g0y')]"
1713ly9,jaegarbong,,2023-10-06 04:55:50+00:00,False,,False,False,True,False,/r/datascience/comments/1713ly9/is_it_good_to_ask_questions_regarding_a_takehome/,Is it good to ask questions regarding a take-home case study?,"I have been given a case study as a next step in my interview. I have a few questions and doubts regarding the same.

Some of these doubts are about the terms they have used and their relevance to the dataset. 

Will it seem bad if I send out questions regarding this?",datascience,https://www.reddit.com/r/datascience/comments/1713ly9/is_it_good_to_ask_questions_regarding_a_takehome/,3,2,1.0,"[Comment(id='k3ojqpo'), Comment(id='k3xw6da'), Comment(id='k3orvl1')]"
1716zm9,Raspberrry314,,2023-10-06 08:31:18+00:00,False,,False,False,True,False,/r/datascience/comments/1716zm9/survival_analysis_employee_churn/,Survival Analysis - Employee churn,"Hey everyone  


I am working on a project for uni and I have chosen employee churn as my topic. One of the predictors, ""Reason for Termination"", has absconded, resigned, terminated and contract expired.

&#x200B;

Since I am looking for reasons why employees are churning and how to prevent it, should I exclude the option ""contract expired""? Absconded, resigned and terminated are all factors that aa company would want to prevent when hiring an employee but should they look out for employees who have had their contract expired since this is not really a red flag, for lack of a better term. 

&#x200B;

How would I handle the entries relating to contract expired?  ",datascience,https://www.reddit.com/r/datascience/comments/1716zm9/survival_analysis_employee_churn/,8,1,1.0,"[Comment(id='k3oxnzb'), Comment(id='k40c09i'), Comment(id='k3oxx1g'), Comment(id='k3oy6xi'), Comment(id='k3oyes8'), Comment(id='k3oymgu'), Comment(id='k3pbk1u'), Comment(id='k3p2kog'), Comment(id='k3p33we')]"
1716u3j,Warm_Cicada_8313,,2023-10-06 08:21:11+00:00,False,,False,False,True,False,/r/datascience/comments/1716u3j/a_phd_in_economics_or_masters_in_data_analytics/,A PhD in Economics or Masters in Data Analytics - Suggestions needed.,"Hi everybody, hope you areall doing good. I need some suggestions, like the title says. 

Here is a little introduction about me - I have done my bachelors and masters in Economics (From Pakistan). Now, I was thinking to continue my studies further, I was determined to do PhD in Economics from USA, i was planning to apply this year but I decided to take a break this year and see what is it I actually want. During my masters and bachelors we have had various assignments and projects that would require us to analyse/visualise data and draw meaningful insights out of the analysis, using softwares like STATA, EViews, SPSS, Excel. I have always like playing around with data and using softwares. 

Now the thing is, i am in a quandary whether i should do a PhD in economics or do another masters in data analytics program. I am not sure which one is a wise choice, is there any one who has opted for data analytics with economics being their major? how did it go? which programs are better in this regard?

how should i take a start towards it? i have started to learn R language, what else can be helpful in this regard?

Looking forward to some valuable suggestions/advice, 

thanks",datascience,https://www.reddit.com/r/datascience/comments/1716u3j/a_phd_in_economics_or_masters_in_data_analytics/,1,0,0.5,[Comment(id='k3ro6e4')]
1716aw9,khaled__alekasir,,2023-10-06 07:43:57+00:00,False,,False,False,True,False,/r/datascience/comments/1716aw9/machine_learning_and_statistic_online_courses/,Machine learning and statistic online courses,"Today I was looking for an online course in ML and I ran into [this](https://twitter.com/caglar_ee) twitter (X) page which contains addresses to a lot of useful free online courses in AI, ML, RL and statistics.

I think it may be helpful to others to post it here.",datascience,https://www.reddit.com/r/datascience/comments/1716aw9/machine_learning_and_statistic_online_courses/,0,1,1.0,[]
170loiv,RightProfile0,,2023-10-05 16:01:36+00:00,False,,1696521895.0,False,True,False,/r/datascience/comments/170loiv/do_most_companies_use_awsazure/,Do most companies use AWS/Azure?,"I understand these cloud computings as essentially borrowing ""highly efficient computers"" from amazon, microsoft, etc so I can do things more efficiently without worrying too much about hardware level logistics.

I'm trying to build some long term meaningful portfolio.

Is it realistic to build my own website and deploy the machine learning model (or statistical, whatever)  that has some regular updates? (hopefully it is useful as well)

I'm relatively proficient at anything related to math/stats but not so much on cloud computing.

Is this how things are done in the industry?

Would most jobs I apply in the States use cloud computing?

How much would this cost if I want to do this?

Any insight is appreciated!!

&#x200B;

(I'm on my way to get cert for AWS practitioner, but I'm also wanting to get some other ones too if it will be useful for this project. )",datascience,https://www.reddit.com/r/datascience/comments/170loiv/do_most_companies_use_awsazure/,14,17,0.84,"[Comment(id='k3m2ars'), Comment(id='k3mz5ob'), Comment(id='k3lgam1'), Comment(id='k3naexl'), Comment(id='k3o50fh'), Comment(id='k3nirjz'), Comment(id='k3o1ycm'), Comment(id='k3n5slt'), Comment(id='k3q67dt'), Comment(id='k3o570f'), Comment(id='k3o32a2'), Comment(id='k3nivfd'), Comment(id='k48r85b'), Comment(id='k3o5jpd')]"
170jcmg,MarzCallz,,2023-10-05 14:25:35+00:00,False,,False,False,True,False,/r/datascience/comments/170jcmg/bayesian_recommendations/,Bayesian recommendations?,"Hello! Any recommendations (books, courses, articles, blog, podcast, whatever existent) to learn about Bayesian statistics for business and testing?",datascience,https://www.reddit.com/r/datascience/comments/170jcmg/bayesian_recommendations/,32,21,1.0,"[Comment(id='k3lhubj'), Comment(id='k3oeb8m'), Comment(id='k3nww2p'), Comment(id='k3lhg4b'), Comment(id='k3o1p6m'), Comment(id='k3qyg18'), Comment(id='k41ofy7'), Comment(id='k3lq21t'), Comment(id='k3kxh9k'), Comment(id='k3n3b13'), Comment(id='k3loozt'), Comment(id='k41okyf'), Comment(id='k3o6ars'), Comment(id='k3mlgpu'), Comment(id='k50dnp8'), Comment(id='k50dqyi'), Comment(id='k50ed7x'), Comment(id='k3mlkky'), Comment(id='k3mucaa'), Comment(id='k3lfbc3'), Comment(id='k3nk4o0'), Comment(id='k50e5ds'), Comment(id='k3n3g3e'), Comment(id='k3m8akf'), Comment(id='k428ry2'), Comment(id='k52l5mg'), Comment(id='k3ndu6e'), Comment(id='k3mbgrx'), Comment(id='k50dcy3'), Comment(id='k50dl0w'), Comment(id='k3mca7l'), Comment(id='k3nh4kb')]"
1714os7,Order-Various,,2023-10-06 06:00:32+00:00,False,,False,False,True,False,/r/datascience/comments/1714os7/is_it_bad_if_i_cant_visualize_dataframe_in/,Is it bad if i can't visualize DataFrame in Jupyter Notebook and pandas without turn it into Excel ?,"To be familiar with Excel but totally struggle with Jupyter Notebook, I usually turn the df to spreadsheet using pd.df.to\_excel(). Working with excel, I usually can do more and able to figure out stuff that can't be done with JN. Further more, using JN make me feel that i would miss something important in the dataset. Is this a bad practice and is there any tips to upgrade my dataskill with Jupyter ?",datascience,https://www.reddit.com/r/datascience/comments/1714os7/is_it_bad_if_i_cant_visualize_dataframe_in/,4,1,1.0,"[Comment(id='k3omfzi'), Comment(id='k3qs281'), Comment(id='k3wtiwo'), Comment(id='k3p8wgr')]"
1714oc4,CKJ_1630,,2023-10-06 05:59:53+00:00,False,,False,False,True,False,/r/datascience/comments/1714oc4/guidance/,Guidance,I want to learn data science. I don't know anything about it. Please suggest data science beginner level books. Or free online resources from where I can learn. Or should I go far six months offline paid data science course in my city? Other suggestions will also be accepted.,datascience,https://www.reddit.com/r/datascience/comments/1714oc4/guidance/,3,0,0.5,"[Comment(id='k3q2pjg'), Comment(id='k3pcscu'), Comment(id='k3q38bt')]"
170pl0q,Quick_Conflict_533,,2023-10-05 18:35:52+00:00,False,,False,False,True,False,/r/datascience/comments/170pl0q/best_cloud_solution_for_ml_on_huge_dataset/,Best cloud solution for ML on huge dataset,"Hi, It would be a great help to me if you could suggest me different ways I can do ML my dataset. My laptop is very old and my dataset is about 300k row x 150k columns. So rigorous feature engineering, different models and neural nets will be done also with cv and many more. 

I dont have a huge budget but I need to make it work. What are the options I could potentially explore to make my work fast as well.",datascience,https://www.reddit.com/r/datascience/comments/170pl0q/best_cloud_solution_for_ml_on_huge_dataset/,21,8,0.83,"[Comment(id='k3mnf7o'), Comment(id='k3o8hal'), Comment(id='k3mc5ss'), Comment(id='k3o48f0'), Comment(id='k3mbpxx'), Comment(id='k3mpszs'), Comment(id='k3o8i25'), Comment(id='k3otspp'), Comment(id='k3q9t13'), Comment(id='k3qhc4i'), Comment(id='k3y0im0'), Comment(id='k3n78tl'), Comment(id='k3mq66p'), Comment(id='k3oiyu2'), Comment(id='k3n8l5x'), Comment(id='k3mt66f'), Comment(id='k3p8xhg'), Comment(id='k3mu4ah'), Comment(id='k3oaqpj'), Comment(id='k44z3qm'), Comment(id='k3muuvh')]"
1709s0h,nondualist369,,2023-10-05 05:30:43+00:00,False,,False,False,False,False,/r/datascience/comments/1709s0h/handling_class_imbalance_in_multiclass/,Handling class imbalance in multiclass classification.,I have been working on multi-class classification assignment to determine type of network attack. There is huge imbalance in classes. How to deal with it.,datascience,https://i.redd.it/z9uay6welbsb1.jpg,45,79,0.94,"[Comment(id='k3kpfr4'), Comment(id='k3kw2o6'), Comment(id='k3kf98f'), Comment(id='k3m3so6'), Comment(id='k3kells'), Comment(id='k3l0vvx'), Comment(id='k3nbng2'), Comment(id='k3jkikd'), Comment(id='k3kkly2'), Comment(id='k3mikzf'), Comment(id='k3liy1r'), Comment(id='k3n4p2n'), Comment(id='k3kojpv'), Comment(id='k3lm1t6'), Comment(id='k3loyib'), Comment(id='k3m01k1'), Comment(id='k3msa1b'), Comment(id='k3ndkwx'), Comment(id='k3sohdy'), Comment(id='k3kut33'), Comment(id='k3qgxbd'), Comment(id='k3ml4hc'), Comment(id='k3qy4c5'), Comment(id='k3li84d'), Comment(id='k3k9e5u'), Comment(id='k3jtsrn'), Comment(id='k3jl2nh'), Comment(id='k3lcvsq'), Comment(id='k3lctf1'), Comment(id='k3n81f9'), Comment(id='k3loujp'), Comment(id='k3lc492'), Comment(id='k3oqz4z'), Comment(id='k3kjcu6'), Comment(id='k3jq1fs'), Comment(id='k3qydf9'), Comment(id='k3n068z'), Comment(id='k3lwpta'), Comment(id='k3n7qxk'), Comment(id='k3r2i0o'), Comment(id='k3lxqc4'), Comment(id='k3n8sg1'), Comment(id='k3m24v9'), Comment(id='k3m3xpi'), Comment(id='k3m6429')]"
1713g99,the_tallest_fish,,2023-10-06 04:46:37+00:00,False,,False,False,True,False,/r/datascience/comments/1713g99/what_exactly_is_the_job_scope_for_a_data_scientist/,What exactly is the job scope for a data scientist??,"I’m a ML engineer who recently joined a company and have been working closely with a senior data scientist for a few months now. He’s been working here a year before me, apparently had 10 years of experience and was working for a consultancy before this. He has been getting increasingly frustrating to work with.

Most of what he does is making charts and dashboards with SQL, meeting with the higher-ups of the business and overpromising them a bunch of “AI features” without any considerations to feasibility or cost. 

Anything that I asked of him that requires him using any technology outside a Jupyter notebook, he will claim that “it is not my job scope, I am not an engineer.” This includes basic things like version control or remote training. He believes that all he needs to do is to provide a POC… except..

..the POC he built on the notebook is completely unusable. I’m talking about stray lines of codes scatter across cells, not even a single function in sight, and utterly inefficient use of pandas. The worst of all, is that the POC model is trained on a subset of the actual data because, and I quote “my machine ran out of memory trying to fit the whole thing”, but don’t worry because “I’ve stratified the sampling.” (tbf the data is over 80gb.. but still)

I know that DS are not supposed to write production ready code, but this notebook is completely worthless. In my previous job I worked on automating testing and monitoring ML pipeline with a much bigger team, so I didn’t work with data scientists so directly. Last week, I chatted with my coworker in marketing, and apparently she tried to ask him for some analysis for user signups, and he replied with the same excuse: “this is not my job scope, I’m not a data analyst.” So now I have no idea what he actually does.

At this point, I have no idea what a data scientist’s job scope is or what to expect. I know many people on this sub claims that DS is more of a business role, but is this normal? I’m starting to think that he’s a fraud, but you can’t possibly do that for 10 years. 

I have no idea what to do. Is this normal for data scientists? Should I just readjust my expectation and rewrite the whole thing?",datascience,https://www.reddit.com/r/datascience/comments/1713g99/what_exactly_is_the_job_scope_for_a_data_scientist/,6,0,0.5,"[Comment(id='k3pcbkb'), Comment(id='k3qlh7i'), Comment(id='k3ohqhq'), Comment(id='k3t2xs4'), Comment(id='k3yb8j2'), Comment(id='k3qj0ya')]"
170alzu,TheEnlightenedMan,,2023-10-05 06:21:06+00:00,False,,False,False,True,False,/r/datascience/comments/170alzu/whats_one_hard_thing_about_being_a_data_scientist/,What's one hard thing about being a data scientist?,"Hello everyone!

I've been diving into the world of data science and i'm curious about the challenges/inconveniences you experience as a data scientist/analyst.

I'd love to hear your thoughts about this. As a data scientist, what's one little hiccup or challenge you often come across in your daily work?

Looking forward to your insights!",datascience,https://www.reddit.com/r/datascience/comments/170alzu/whats_one_hard_thing_about_being_a_data_scientist/,88,61,0.85,"[Comment(id='k3jjbbe'), Comment(id='k3kaqsa'), Comment(id='k3kldx4'), Comment(id='k3jjv94'), Comment(id='k3jsh9x'), Comment(id='k3koiad'), Comment(id='k3kruea'), Comment(id='k3kpduh'), Comment(id='k3l2rnh'), Comment(id='k3jyvq8'), Comment(id='k3kjtyg'), Comment(id='k3ksq2k'), Comment(id='k3k9t7d'), Comment(id='k3llw5k'), Comment(id='k3lx1s9'), Comment(id='k3m3ubd'), Comment(id='k3oe51f'), Comment(id='k3jniud'), Comment(id='k3jtohv'), Comment(id='k3kfy6f'), Comment(id='k3kfdk9'), Comment(id='k3lk98q'), Comment(id='k3mlb63'), Comment(id='k3tp8kb'), Comment(id='k3kcz2h'), Comment(id='k3kwm59'), Comment(id='k3l5ty5'), Comment(id='k3ma9ew'), Comment(id='k3nfitf'), Comment(id='k3nggpm'), Comment(id='k3nnrig'), Comment(id='k3omkbr'), Comment(id='k3onumg'), Comment(id='k3ot3y6'), Comment(id='k3p16pe'), Comment(id='k3pjh4c'), Comment(id='k3s75h5'), Comment(id='k3kkecq'), Comment(id='k3km60d'), Comment(id='k3jl14q'), Comment(id='k3l1h6u'), Comment(id='k3kmzyy'), Comment(id='k3kgb79'), Comment(id='k3kk1hq'), Comment(id='k3lz566'), Comment(id='k3lpsgb'), Comment(id='k3jl3id'), Comment(id='k3kg3ds'), Comment(id='k3knp8k'), Comment(id='k3kjxm8'), Comment(id='k3kqato'), Comment(id='k3lifpe'), Comment(id='k3x0kxc'), Comment(id='k3n4uld'), Comment(id='k3l2uer'), Comment(id='k3n4p4j'), Comment(id='k3ogtcg'), Comment(id='k3kge1c'), Comment(id='k3x1bo5'), Comment(id='k3x2pjr'), Comment(id='k3x1lyn'), Comment(id='k3x1zp1'), Comment(id='k3wzs2i'), Comment(id='k3js82a'), Comment(id='k3lenzo'), Comment(id='k3mdk95'), Comment(id='k3kmt13'), Comment(id='k3jlqwb'), Comment(id='k3kl2s6'), Comment(id='k3lzzjv'), Comment(id='k3kspjw'), Comment(id='k3yd9hv'), Comment(id='k3l3bbu'), Comment(id='k3mrtt5'), Comment(id='k3jnwy6'), Comment(id='k3juhoi'), Comment(id='k3knt31'), Comment(id='k3mxvoz'), Comment(id='k3l43wj'), Comment(id='k3ktpq5'), Comment(id='k3n0cqp'), Comment(id='k3kida7'), Comment(id='k3kpeee'), Comment(id='k3kpy0m'), Comment(id='k3lior3'), Comment(id='k3ndrhx'), Comment(id='k43ra5c'), Comment(id='k45i7o8')]"
1712czz,sunblockheaven,,2023-10-06 03:45:43+00:00,False,,False,False,True,False,/r/datascience/comments/1712czz/questionanswers_model_what_to_us/,Question-Answers Model. What to us?,"I have a project with a list of customer feedback and worker’s responses (so a QA model) These answers are related to internal company policies, so knowledge has to be trained. 

That being said, I’ve read into a few keywords, such as using DBSCAN to cluster, Seq2Seq. 

My question is: 
1. What should be my approach? 
2. How do I use a model from an open model from Huggingface that I don’t have to train for machine understanding towards English? 
3. How to generate output based on my datasets of questions-answers? 

Thank you for your help in advance!",datascience,https://www.reddit.com/r/datascience/comments/1712czz/questionanswers_model_what_to_us/,0,1,1.0,[]
170ymu9,Agitated-Duty2577,,2023-10-06 00:46:12+00:00,False,,False,False,True,False,/r/datascience/comments/170ymu9/looking_for_a_tutor_for_sas_programming_anyone/,Looking for a tutor for SAS programming-- anyone?,"I am learning SAS for my thesis project and looking for someone to tutor me in writing SAS code. I am familiar with the online resources for learning SAS... but finding it takes many hours to troubleshoot errors and I am also working full-time while completing my thesis.

I would be looking for 1-2 hours per week of virtual help with this from now until December and I will pay. If you are experienced with SAS and interested, or know of a pool of SAS programmers I could contact, please message me and I can provide more details!",datascience,https://www.reddit.com/r/datascience/comments/170ymu9/looking_for_a_tutor_for_sas_programming_anyone/,0,1,1.0,[]
1712php,norfkens2,,2023-10-06 04:04:50+00:00,False,,False,False,True,False,/r/datascience/comments/1712php/why_is_data_science_still_so_hyped/,Why is data science still so hyped?,"It's a bunch of really cool jobs but where does all the hype still come from?

And why are there so many beginners that try to enter when it has been really difficult to enter the job market in the past couple of years?

Also, I've seen a lot of people wanting to transition into DS without having an understanding of what the job actually looks like. That's not a criticism of the individuals but it shows to me that there's a perception and weird incentivisation going on in the broader public.

It can't be the ""sexiest job"" label alone anymore and it feels to me like there's an delay/disconnect of 3-8 years between what people's expectations are and what is actually going on.

Don't get me wrong, I'm super happy that data work is getting so much attention but I really struggle putting the societal dynamics that must be at play here into words.

Are these normal time scales for these effects to be playing out? Is it down to DS being such a young discipline?

Any thoughts?",datascience,https://www.reddit.com/r/datascience/comments/1712php/why_is_data_science_still_so_hyped/,66,0,0.44,"[Comment(id='k3oc3pi'), Comment(id='k3og2z8'), Comment(id='k3oir30'), Comment(id='k3pdazt'), Comment(id='k3p00ic'), Comment(id='k3owlsb'), Comment(id='k3ov50w'), Comment(id='k3pit3q'), Comment(id='k3q28qa'), Comment(id='k3re6kn'), Comment(id='k3sto4x'), Comment(id='k3p3xwz'), Comment(id='k3pe6tv'), Comment(id='k3pk9lb'), Comment(id='k3pobuq'), Comment(id='k3q5p5j'), Comment(id='k3sdj1k'), Comment(id='k3t6csc'), Comment(id='k3ohs6l'), Comment(id='k3p0fye'), Comment(id='k3p4ffz'), Comment(id='k3p2p56'), Comment(id='k3taxls'), Comment(id='k3xn97g'), Comment(id='k3odp0w'), Comment(id='k3p1wse'), Comment(id='k3qyecy'), Comment(id='k3ohro7'), Comment(id='k3qwx7r'), Comment(id='k3qh107'), Comment(id='k3qxalq'), Comment(id='k3tkpx7'), Comment(id='k3ozh8x'), Comment(id='k3phzlc'), Comment(id='k3ubwss'), Comment(id='k3q51um'), Comment(id='k3tpbd1'), Comment(id='k3ts7fo'), Comment(id='k3ts5d3'), Comment(id='k3q5c9t'), Comment(id='k3tpuog'), Comment(id='k3trqly'), Comment(id='k3okidh'), Comment(id='k3ojqm6'), Comment(id='k3q6awm'), Comment(id='k3poqf9'), Comment(id='k3q5yn9'), Comment(id='k3sat0m'), Comment(id='k3q60ed'), Comment(id='k3tqleg'), Comment(id='k3ycui5'), Comment(id='k3r09hv'), Comment(id='k3tkfxl'), Comment(id='k3p06zh'), Comment(id='k3q6hjh'), Comment(id='k3qx56m'), Comment(id='k3tpves'), Comment(id='k3ootai'), Comment(id='k3ub229'), Comment(id='k3sc2gf'), Comment(id='k3reel6'), Comment(id='k3qsswv'), Comment(id='k3tkdas'), Comment(id='k3saku4'), Comment(id='k3tjx3k'), Comment(id='k3u0kkg')]"
170ob14,obewanjacobi,,2023-10-05 17:45:45+00:00,False,,False,False,True,False,/r/datascience/comments/170ob14/text_alias_modeling/,Text Alias Modeling,"I have a dataset of true names in one column, and aliases in another. The idea is that a single name in the true column can have multiple aliases in the alias column. I need to build a model that will train on this data and learn to map aliases to true names to automate when more aliases get created for one of my teams at work. 

I've tried a standard neural net by first vectorizing the string values in each column, but that had really poor results, and then started looking into Word Embedding models, but that doesn't seem to fit exactly what I'm doing here in the project.   


So I'm looking for recommendations on models that I can use to try and accomplish this task. I've been Googling for a couple of days but nothing quite fits the scenario I have, most text models don't seem to map text to text but instead text to a quantitative value. Thanks for the insight!",datascience,https://www.reddit.com/r/datascience/comments/170ob14/text_alias_modeling/,14,1,0.67,"[Comment(id='k3nb8rn'), Comment(id='k3scf07'), Comment(id='k3oozbi'), Comment(id='k3ne2ys'), Comment(id='k3prbc8'), Comment(id='k3ngsap'), Comment(id='k3r2ncn'), Comment(id='k3scmse'), Comment(id='k3nj2de'), Comment(id='k3rhn2j'), Comment(id='k3sd2di'), Comment(id='k3t724y'), Comment(id='k3sg09k'), Comment(id='k3t9pvo')]"
16zw1dz,EcoNerd007,,2023-10-04 19:21:03+00:00,False,,False,False,True,False,/r/datascience/comments/16zw1dz/data_sciences_in_the_plural/,Data Science(s) in the plural,"I am lead of a new Data Science Division. The management team at our company is insistent that Data Sciences in the plural is a better fit. On my team we have statisticians, database managers, geospatial geographers, programmers, and data scientists. We are also incorporating machine learning as well. Google searches almost exclusively mention Data Science in the singular. Does anyone have any opinions or suggestions? Should I bow down and embrace the plural or should I be adamant about the norm of the singular?",datascience,https://www.reddit.com/r/datascience/comments/16zw1dz/data_sciences_in_the_plural/,38,43,0.84,"[Comment(id='k3h590v'), Comment(id='k3h37dp'), Comment(id='k3i36bv'), Comment(id='k3hazx4'), Comment(id='k3h355o'), Comment(id='k3h4t1j'), Comment(id='k3h7p3x'), Comment(id='k3hltts'), Comment(id='k3hlfiz'), Comment(id='k3lgb5w'), Comment(id='k3h9ve8'), Comment(id='k3ieoja'), Comment(id='k3hwrc4'), Comment(id='k3i5qgg'), Comment(id='k3icvxt'), Comment(id='k3ixh41'), Comment(id='k3ixh58'), Comment(id='k3iy4gj'), Comment(id='k3iztim'), Comment(id='k3jfmzp'), Comment(id='k3k7qh6'), Comment(id='k3kh745'), Comment(id='k3kpbib'), Comment(id='k3n4gba'), Comment(id='k3ijifi'), Comment(id='k3jsclx'), Comment(id='k3hcmk8'), Comment(id='k3ljh6k'), Comment(id='k3mixoy'), Comment(id='k3hs761'), Comment(id='k3h7z2p'), Comment(id='k3lie4w'), Comment(id='k3nx8wd'), Comment(id='k3ma2rd'), Comment(id='k3hk5bh'), Comment(id='k3i4bgu'), Comment(id='k3lpns1'), Comment(id='k3mao0v')]"
170e4n7,Odd-Concert-4591,,2023-10-05 10:07:42+00:00,False,,False,False,True,False,/r/datascience/comments/170e4n7/product_name_matching_entity_resolution_or_enity/,Product name matching - Entity Resolution or Enity Linkage or both?,"**Context**

I am at the start of a project where I would like to map/match/link external product names to the respective internal product names. The goal should be to ingest related external information (e.g. stock number) of the external products into our system by joining the same products based on their product names. Short, the external product name should be matched to the internal representation of the product name.

&#x200B;

**Problem and Question**

I'm now doing some research about potential solutions and I'm having difficulties finding out if the nature of the problem can be allocated to Entity Resolution or Entity Linkage or if it even includes both of them. I'm asking this because I'm afraid to go down the wrong path when researching for a potential way to tackle the problem. I have seen the post about [key differences about entity linking and entity matching](https://datascience.stackexchange.com/questions/115528/exemplify-key-differences-between-entity-linking-and-entity-matching#:~:text=As%20depicted%20below%2C%20entity%20linking,reference%20repository%20or%20knowledge%20base.&text=However%2C%20in%20entity%20matching%20the,knowledge%20base%20do%20not%20exist.&text=mirror%2Dimage), but it's still hard for me to allocate the nature of my problem to one of them. Can please someone tell me if the problem can be allocated to Entity Resolution, Entity Linkage or both, and why this is the case?

&#x200B;

Thanks a lot!",datascience,https://www.reddit.com/r/datascience/comments/170e4n7/product_name_matching_entity_resolution_or_enity/,0,2,1.0,[]
16zwzv6,Dependent_Mushroom98,,2023-10-04 20:00:30+00:00,False,,False,False,True,False,/r/datascience/comments/16zwzv6/can_we_take_the_probabilities_from_one_model_and/,Can we take the probabilities from one model and make it a feature to the other model along with additional features?,"When my team mate used the probabilities from one model and used as feature to the other model the probabilities from first model was highest on the feature importance map for the second model.

Is this an example of stacked model or is it better to have trained both models with additional features and compare the accuracy of both models rather than reporting the accuracy of the linked model in step 1. 

Please share your experience. Thanks",datascience,https://www.reddit.com/r/datascience/comments/16zwzv6/can_we_take_the_probabilities_from_one_model_and/,9,15,0.94,"[Comment(id='k3hw4lb'), Comment(id='k3hhna9'), Comment(id='k3hozae'), Comment(id='k3ham0x'), Comment(id='k3jtyp7'), Comment(id='k3qu48m'), Comment(id='k3ixmpo'), Comment(id='k3kl5cm'), Comment(id='k3kid2f')]"
170coig,Relevant-Cycle9169,,2023-10-05 08:33:56+00:00,False,,False,False,True,False,/r/datascience/comments/170coig/classificationpredicting_of_outliers/,Classification/predicting of outliers,"I have a skewed depandant variable with few high natural outliers, I want to perform regression on it without removing outliers and also improve rmse score, how can I handle them? using feature engineering? build a model to classify them?  
Thank you",datascience,https://www.reddit.com/r/datascience/comments/170coig/classificationpredicting_of_outliers/,1,1,0.67,[Comment(id='k3oa2ko')]
1709cts,deonvin,,2023-10-05 05:06:23+00:00,False,,False,False,True,False,/r/datascience/comments/1709cts/optimising_inputs_to_ml_model/,Optimising Inputs to ML Model,"If you create an ML model, is it advisable to do a black box optimisation and find the optimal inputs to get the maximum/minimum output?

 Or does it only make sense to use ML models predictively, not prescriptively?",datascience,https://www.reddit.com/r/datascience/comments/1709cts/optimising_inputs_to_ml_model/,1,1,1.0,[Comment(id='k3o9ubo')]
1708utp,din38ah,,2023-10-05 04:38:20+00:00,False,,False,False,True,False,/r/datascience/comments/1708utp/sas_how_to_query_the_outlier_from_the_output_of/,sas - how to query the outlier from the output of the proc sgplot,"Here is the piece of code that write the data to a table:

    ods output sgplot=boxplot_data;
    proc sgplot data=mylib.calendar;
    vbox price;
    run;

and the data in the table looking like this:

&#x200B;

https://preview.redd.it/ngr15k82bbsb1.png?width=786&format=png&auto=webp&s=ace90c47416f4429d21e9cc78cbc26e1906441a4

Now, I want to query this data where the BOX(price)\_\_ST = 'FAROUTLIER' 

with this code:

    proc sql;
    select * 
       from boxplot_data (obs=50);
    where ""BOX(price)__ST"" = 'FAROUTLIER'
    quit;

But it didn't work. I can't query the column that has the ""\_\_"" in its name.

And the table properties show the column name and its label. But I can't query the label either.

&#x200B;

https://preview.redd.it/nufe0xksbbsb1.png?width=598&format=png&auto=webp&s=87279934c18e17dc763a8313ff2f919c7619e447

Any one done this before? How did you do it?

&#x200B;

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/1708utp/sas_how_to_query_the_outlier_from_the_output_of/,3,1,1.0,"[Comment(id='k40ee6d'), Comment(id='k41snbf'), Comment(id='k40gt7q')]"
16z8pez,Potanee,,2023-10-04 00:34:58+00:00,False,,False,False,True,False,/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/,What do corporate data scientists struggle with the most at work?,"As a data scientist, if you could let someone else solve something for you what would it be?

I was curious to know the problems data scientists face. This can be anywhere from collecting data and cleaning data to making and deploying machine learning models.",datascience,https://www.reddit.com/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/,121,134,0.97,"[Comment(id='k3d9lyk'), Comment(id='k3da5xh'), Comment(id='k3d6xsc'), Comment(id='k3d56uk'), Comment(id='k3d8606'), Comment(id='k3d7l89'), Comment(id='k3dme0k'), Comment(id='k3dhmdv'), Comment(id='k3dba6i'), Comment(id='k3dbdo0'), Comment(id='k3df8mb'), Comment(id='k3di6rb'), Comment(id='k3e8rah'), Comment(id='k3d9m15'), Comment(id='k3d7jon'), Comment(id='k3e8za0'), Comment(id='k3dcnjg'), Comment(id='k3e9kk9'), Comment(id='k3dp8zi'), Comment(id='k3drss7'), Comment(id='k3f5upz'), Comment(id='k3e6sd0'), Comment(id='k3egi0w'), Comment(id='k3dru09'), Comment(id='k3dw6sb'), Comment(id='k3dymvz'), Comment(id='k3f1mxt'), Comment(id='k3f6l2n'), Comment(id='k3fgwup'), Comment(id='k3fx3hc'), Comment(id='k459j90'), Comment(id='k3dgbph'), Comment(id='k3ebm2t'), Comment(id='k3drem3'), Comment(id='k3ee9q5'), Comment(id='k3ek4rm'), Comment(id='k3ettfu'), Comment(id='k3ez8zw'), Comment(id='k3f0pmn'), Comment(id='k3f76io'), Comment(id='k3femjw'), Comment(id='k3fh2vk'), Comment(id='k3fkh8d'), Comment(id='k3fmedx'), Comment(id='k3fzube'), Comment(id='k3jx3rr'), Comment(id='k3jxu39'), Comment(id='k3rgp10'), Comment(id='k414wxg'), Comment(id='k3dcnvm'), Comment(id='k3dliqj'), Comment(id='k3dr18g'), Comment(id='k3dksll'), Comment(id='k3e6fy4'), Comment(id='k3e68t1'), Comment(id='k3fj9jj'), Comment(id='k3gqioc'), Comment(id='k3hx03c'), Comment(id='k3gsv91'), Comment(id='k3kl360'), Comment(id='k3dcti9'), Comment(id='k3dlwaa'), Comment(id='k3d8iee'), Comment(id='k3ebh5l'), Comment(id='k3eqj7e'), Comment(id='k3ddim1'), Comment(id='k3dl0ds'), Comment(id='k3d5efw'), Comment(id='k3dmasq'), Comment(id='k3eiw1k'), Comment(id='k3f6ydz'), Comment(id='k3h320z'), Comment(id='k3eo4tj'), Comment(id='k3dwyad'), Comment(id='k3ez4hh'), Comment(id='k3faeut'), Comment(id='k3fkk3m'), Comment(id='k3ga6fg'), Comment(id='k3dcz35'), Comment(id='k3fx25i'), Comment(id='k3dds2z'), Comment(id='k3danan'), Comment(id='k3hx357'), Comment(id='k3d7mtr'), Comment(id='k3eb93y'), Comment(id='k3dpcac'), Comment(id='k3jl5xo'), Comment(id='k3f5nst'), Comment(id='k3jm3zs'), Comment(id='k3jmpt9'), Comment(id='k3de575'), Comment(id='k3fuxju'), Comment(id='k3gsmt7'), Comment(id='k3jjer3'), Comment(id='k3hg7wc'), Comment(id='k3dedua'), Comment(id='k3drlk4'), Comment(id='k3er1x8'), Comment(id='k3d6dww'), Comment(id='k404bet'), Comment(id='k3hgtxa'), Comment(id='k3d805u'), Comment(id='k3g0mlf'), Comment(id='k3eo86a'), Comment(id='k3f9vkr'), Comment(id='k3f6x1e'), Comment(id='k3k3y5j'), Comment(id='k3et84n'), Comment(id='k3fv42k'), Comment(id='k3q6cmz'), Comment(id='k3fxhj6'), Comment(id='k3gys2e'), Comment(id='k40nwm8'), Comment(id='k3dfmbq'), Comment(id='k3fa5eu'), Comment(id='k3hfwaq'), Comment(id='k3fvrob'), Comment(id='k3ksts6'), Comment(id='k3dkj37'), Comment(id='k3fyu1f'), Comment(id='k3i657f'), Comment(id='k3g00d8')]"
16zzta7,KillingTimeSince99,,2023-10-04 21:51:25+00:00,False,,False,False,True,False,/r/datascience/comments/16zzta7/looking_for_a_tool_to_help_map_two_databases/,Looking for a tool to help map two databases schemas against each other,"I have two relational databases with \~30 tables each. While they both hold essentially the same data, the schema for each is wildly different. I eventually need to migrate the data so I'd like to build a good 1-for-1 schema map for each column from the origin database to where that would go in the destination database (or to note that it's data that doesn't need to move, for one reason or another).

I could certainly just manually build this all in Excel but that's boring and a time drain. Any good tools, preferably but not necessarily visual, that folks know that might work for this project? 

I've seen lots of good schema mapping tools online, but unclear that any of them are well suited for connecting the dots between two different database schemas.",datascience,https://www.reddit.com/r/datascience/comments/16zzta7/looking_for_a_tool_to_help_map_two_databases/,4,2,1.0,"[Comment(id='k3i5ryx'), Comment(id='k3i9gbb'), Comment(id='k3n3ucw'), Comment(id='k3s0j2z')]"
16zldu3,Breadskinjinhojiak,,2023-10-04 12:03:18+00:00,False,,False,False,True,False,/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/,What are some good scraping software to use for task automation?,"suppose that i have 1000 sites that i need to build a script to extract individually and need the data to be refreshed weekly, what are some tools/software that can help me to automate such task?",datascience,https://www.reddit.com/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/,1,5,1.0,[Comment(id='k3g7za1')]
16zsikw,meWhoObserves,,2023-10-04 16:59:17+00:00,False,,False,False,True,False,/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/,How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model?,"So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!

So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found, then it should return ""No object found"" or like that.",datascience,https://www.reddit.com/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/,1,2,1.0,[Comment(id='k3oam2b')]
16zh6dt,WadeEffingWilson,,2023-10-04 07:56:43+00:00,False,,False,False,True,False,/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/,"When building out a matrix profile for a time series, what tests can be used to determine that both the bin size and window size are optimal?","I'm playing around with adapting matrix profiles to my time series data and I want to ensure that the data and parameters are set correctly.

I'm working with a month's worth of data placed into 5-minute bins (288 samples/day). I initially rebinned to 1-hour but I wasn't sure whether or not that might hide certain higher frequency patterns or if it would just make it too noisy.

I'm also attempting to tune the window_size parameter used by the STUMPY python library (stumpy.stumpy function). This adjusts the length of the segments that the matrix profile algorithm uses to compare to measure similarity. If the window size is too small (fewer points), you are more likely to get incidental matches. If it's too large, you're less likely to appropriately match similar patterns.

There is seasonality in the series that reflects diurnal patters (activity spikes during peak operational hours and drops out during off-peak hours). Because of this, I wanted a window size of at least half a day (144 for 5m bins, 12 for 1h bins) or a third of a day (96 for 5m bins, 8 for 1h bins) to achieve the Nyquist frequency of the seasonality, if that makes sense.

Are there any tests that I could run to help identify and optimize both the size of the time bins and the window size?

One thing I noticed is that when adjusting the window size, the rate of change of the number of detected motifs isn't linear. I have a hunch that I could probably plot it out and use the elbow method but I need a sanity check before I try it out.

For the bin size, I usually use a Power Spectral Density plot to identify dominant frequencies (I mostly use that for selecting seasonality parameters for decompositions). For the 1h bucket series, there are 1-3 dominant frequencies well above the noise floor, which is good. However, when I use the 5m bucket series, there doesn't appear to be any dominant frequencies, just noise. Would that suggest that the 5m bucket series is suboptimal in terms of bin size compared to the 1h series?

I just need a second set of eyes on it to make sure I'm not misinterpreting or misunderstanding something. I'm also open to suggestions or ideas, if any are available.",datascience,https://www.reddit.com/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/,10,10,0.92,"[Comment(id='k3hma51'), Comment(id='k3i5omg'), Comment(id='k3fam9w'), Comment(id='k3i5eg6'), Comment(id='k3hslz2'), Comment(id='k3fealb'), Comment(id='k3hth1g'), Comment(id='k3fesxa'), Comment(id='k3hv1lh'), Comment(id='k3fg800')]"
16z2cge,bic-boy,,2023-10-03 20:21:49+00:00,False,,False,False,True,False,/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/,Do you just learn on the job?,"I studied data science in college, and I’m in my first job in a start up (been here about a year). There are three on our data science team (manager, another graduate and myself). Due to being in a start up, we all work on individual projects (as we do consultancy). Mainly data processing in sql/python + analysis

My manager is up to their neck in work, and I’d like if they had more time to actually teach us things. I am just learning by googling and doing. I think ideally in my head I would like to work on more projects with them, or maybe even shadow them once in a while and see how they would approach a problem or see their workflow. Is this normal?

I can read their code and analysis but I just feel isolated and would learn a lot more by actually interacting with them while working

Since joining have learned a lot more about ETL pipelines and cloud technologies, but honestly I’m not sure how much more I can learn here that I can’t learn in any other job.

I can do the work but I feel like I could be a lot more effective and efficient.

Do you just learn by doing in your job? Am I gaining the most knowledge that I can here? Is this normal? How did you advance to the next level?",datascience,https://www.reddit.com/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/,37,68,0.94,"[Comment(id='k3c4xzn'), Comment(id='k3ci13s'), Comment(id='k3c65bd'), Comment(id='k3di9l5'), Comment(id='k3c8lcz'), Comment(id='k3cqydl'), Comment(id='k3c1vsv'), Comment(id='k3d6n7w'), Comment(id='k3cuko4'), Comment(id='k3edyyy'), Comment(id='k3e361d'), Comment(id='k3czmbx'), Comment(id='k3h7v1x'), Comment(id='k3d7v17'), Comment(id='k3erv1i'), Comment(id='k3ftp0e'), Comment(id='k3yblyp'), Comment(id='k3dc691'), Comment(id='k3ca6cz'), Comment(id='k3et31e'), Comment(id='k3edh3d'), Comment(id='k49l365'), Comment(id='k3frrhq'), Comment(id='k49l57q'), Comment(id='k3ei4k9'), Comment(id='k3etmne'), Comment(id='k3cypui'), Comment(id='k3ezoqf'), Comment(id='k3f69xe'), Comment(id='k3elktn'), Comment(id='k3hvg8d'), Comment(id='k3i6uug'), Comment(id='k3f524v'), Comment(id='k3jzqmk'), Comment(id='k3i77zl'), Comment(id='k3gb9pt'), Comment(id='k3hqk87')]"
16znm3n,_rshaedy,,2023-10-04 13:43:40+00:00,False,,False,False,True,False,/r/datascience/comments/16znm3n/ais_data_cannibalism/,AI’s Data Cannibalism,"I'm looking to read more on this topic mentioned in the title.

&#x200B;

Feel free to suggest books and articles",datascience,https://www.reddit.com/r/datascience/comments/16znm3n/ais_data_cannibalism/,6,1,0.56,"[Comment(id='k3fgifd'), Comment(id='k3flbfb'), Comment(id='k3pwcoa'), Comment(id='k3ua3d8'), Comment(id='k3flee1'), Comment(id='k3xw8rv')]"
16ysfr3,jpnoro2003,,2023-10-03 13:48:54+00:00,False,,False,False,True,False,/r/datascience/comments/16ysfr3/how_often_do_you_use_operations_research_or_in/,How often do you use Operations Research (OR) in your work?,"I'm studying Operations Research in university, and I was wondering how often data scientists in different fields use OR, Linear programming, etc. In their work, and what tools they use. Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16ysfr3/how_often_do_you_use_operations_research_or_in/,40,73,0.97,"[Comment(id='k3ack12'), Comment(id='k3aj7h9'), Comment(id='k3ammm1'), Comment(id='k3cetpm'), Comment(id='k3ag51d'), Comment(id='k3b2q9x'), Comment(id='k3cf5gi'), Comment(id='k3b8xxg'), Comment(id='k3c5xx6'), Comment(id='k3eimvd'), Comment(id='k3autak'), Comment(id='k3ajlb5'), Comment(id='k3ddnn0'), Comment(id='k3b7gkl'), Comment(id='k3bcjz8'), Comment(id='k3bd80r'), Comment(id='k3byw57'), Comment(id='k3c15gz'), Comment(id='k3ckql5'), Comment(id='k3dkcuo'), Comment(id='k3emdix'), Comment(id='k4fr371'), Comment(id='k3c9sak'), Comment(id='k3f4zmv'), Comment(id='k3bi3fv'), Comment(id='k3cfs1v'), Comment(id='k3hb37j'), Comment(id='k3atz2p'), Comment(id='k3llmnc'), Comment(id='k3iyb9h'), Comment(id='k3c2n4v'), Comment(id='k3cfilr'), Comment(id='k3f7szn'), Comment(id='k3dbuwq'), Comment(id='k3cf2al'), Comment(id='k3dbrv3'), Comment(id='k3hq47i'), Comment(id='k3ayg51'), Comment(id='k3fh1ty'), Comment(id='k3dbnor')]"
16zi4jk,Kniggi,,2023-10-04 08:58:44+00:00,False,,False,False,True,False,/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/,Using pre-trained models as features?," Hey everyone!

Currently,  I am working on a project around music emotion classifcation/regression  model. Basically I am trying to predict a score to each emotion on a  given song.

The problem is that my  dataset has quite imbalanced scores (y). Most scores are centered  around a certain score range. Therefore, having difficulties predicting  scores that are further away of the mean values.

I  had this idea to bring in pre-trained (on other datasets and problems)  audio classification models into this as there are a bunch of good  performing pre-trained classification models out there already. The  prediction of these pre-trained models should be used as features (e.g.  prediction of genre, instrument etc) beside the original spectorgram in  my model.

I know this won't solve  the problem of imbalances in the scores but I thought maybe this could  improve the performance as the model would have more features to work  with.

Does this make sense?

I appreciate any input.",datascience,https://www.reddit.com/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/,3,2,0.75,"[Comment(id='k3f74c7'), Comment(id='k3g82u6'), Comment(id='k3ihmey')]"
16zcw19,Libran10,,2023-10-04 03:47:45+00:00,False,,False,False,True,False,/r/datascience/comments/16zcw19/project_ideas/,Project Ideas,"Hey guys
I’m looking for a project idea in Computer Vision. Been browsing through multiple datasets but haven’t been able to think of an idea that has not been implemented before. Can you guys help me out with some ideas? I’m a grad student. Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16zcw19/project_ideas/,9,2,0.67,"[Comment(id='k3ealhx'), Comment(id='k3eumvm'), Comment(id='k3eurfy'), Comment(id='k3l7z88'), Comment(id='k3ebt7a'), Comment(id='k3oatn9'), Comment(id='k4nnimi'), Comment(id='k4no40j'), Comment(id='k4np1ty')]"
16zi29z,Alertt_53,,2023-10-04 08:54:27+00:00,False,,1696410240.0,False,True,False,/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/,Seeking Feedback Mechanism for Our Python/Dash Analytics Platform,"We are in the process of developing a data analytics platform for our client. This platform is primarily built using Python and Dash. We're exploring options to allow our clients to provide comments on each section of the analytics platform containing multiple pages.

Does anyone know of any methods or tools that would facilitate this interactive feedback mechanism.

&#x200B;

It would be better if we could track individual user comments. ",datascience,https://www.reddit.com/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/,1,0,0.5,[]
16z8v18,MLquestionAccount,,2023-10-04 00:41:55+00:00,False,,False,False,True,False,/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/,"What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?","I am considering comparing mutual information scores, but I also don't think I understand MI well enough. 

For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is ""bad"" since this means X, Y would be redundant. I am not sure if my understanding here is correct. 

Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using ""present"" (1) and ""absent"" (0). The main issue I have run into doing this is that I am trying to then create a **distribution** to compare the features (such as seeing what percent of 1s and 0s I find in each feature), but here is the issue: 

Let's say that feature A has 50% 1s and 50% 0s, and feature B also has 50% 1s and 50% 0s. So, it will look as if the distribution of their values is identical, though it could be that feature A and B are ""opposites"":

Feat. A: [0, 0, 1, 1]

Feat. B: [1, 1, 0, 0]

So, I wonder if there is a better way to compare the distributions of the features once I have made the data ""present"" (1) and ""absent"" (0). 

I am also looking at making a Probability Density Function for each feature to compare them, but it's not clear to me how I would go about creating such a PDF for each feature given that I don't know what the probabilities associated actually are. Should I be binning the data then finding what percentage falls in these intervals?

______

Overall, I am looking for advice on where to find useful information on how to compare features for **unsupervised** feature selection, particularly in regards to how to use and compare mutual information scores, how to create PDFs for features, and how to compare distributions between features after they have been binned to avoid the problem I mentioned (with how [0, 0, 1, 1] and [1, 1, 0, 0] would appear to have the same distribution). 

Relevant textbook resources and other reliable source recommendations would be much appreciated. 

Thank you.",datascience,https://www.reddit.com/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/,4,4,1.0,"[Comment(id='k3f8m3o'), Comment(id='k3fjr8z'), Comment(id='k41alw2'), Comment(id='k5d9j7w')]"
16ygt96,samjenkins377,,2023-10-03 03:02:54+00:00,False,,False,False,True,False,/r/datascience/comments/16ygt96/the_lack_of_quality_on_this_sub/,The [lack of] quality on this sub,"It’s been clear this sub has been abandoned by its mods:

*Inactive on Reddit (>1year with no posts/comments):*
u/shaggorama, u/vogt4nick, u/StatsPhD

*Inactive on the Sub (>30d with no posts/comments):*
u/Geckel, u/browneyesays, u/mhermans, u/patrickSwayzeNU

*Active within the last 30d:*
u/dfphd, u/JaJan1, u/Omega037


Here are some of the posts obviously rule-breaking or off-topic that mods do NOT remove:

- [A person asking for online DA tools](https://reddit.com/r/datascience/s/wVrQkHrI4H)
- [A person asking about datasets](https://reddit.com/r/datascience/s/sAvfpDOc4I)
- [A person asking for recruiter’s responses lead times](https://reddit.com/r/datascience/s/b7ssIgMuik)
- [A person asking about cover letters](https://reddit.com/r/datascience/s/3sdLpNhMmL)
- ... the list goes on with absolute beginner questions, and low-quality posts. 

All these posts were written in less than 1 week. As we can see, mods do nothing.

The last post a mod did on the sub was 145 days ago.

What can be done to get the mods to act upon the rules they set themselves? At this pace, we’ll lose the few experienced DS who still roam around here.",datascience,https://www.reddit.com/r/datascience/comments/16ygt96/the_lack_of_quality_on_this_sub/,123,201,0.9,"[Comment(id='k3d1gs3'), Comment(id='k39tova'), Comment(id='k38reb7'), Comment(id='k38qb1d'), Comment(id='k39nkcr'), Comment(id='k394mvy'), Comment(id='k38ih2h'), Comment(id='k38q7o0'), Comment(id='k3a364q'), Comment(id='k38o886'), Comment(id='k399jrc'), Comment(id='k38v0xb'), Comment(id='k39uuin'), Comment(id='k38z44l'), Comment(id='k3ngqzm'), Comment(id='k38wcoz'), Comment(id='k399qmz'), Comment(id='k3a3h3h'), Comment(id='k3abk7z'), Comment(id='k3a4kc8'), Comment(id='k3aigvb'), Comment(id='k3bvp8c'), Comment(id='k3a60ig'), Comment(id='k3bicg4'), Comment(id='k3bolnq'), Comment(id='k3ekcu9'), Comment(id='k3kqfh9'), Comment(id='k3d1tbe'), Comment(id='k3a3y8y'), Comment(id='k3chzas'), Comment(id='k399c02'), Comment(id='k39szg0'), Comment(id='k3d4gp2'), Comment(id='k3d205c'), Comment(id='k39ro9t'), Comment(id='k3d259a'), Comment(id='k39v6ij'), Comment(id='k38l5s0'), Comment(id='k3a40aw'), Comment(id='k3aludy'), Comment(id='k38oloc'), Comment(id='k3d2t1b'), Comment(id='k3a585m'), Comment(id='k39zi4m'), Comment(id='k397n49'), Comment(id='k3d35aq'), Comment(id='k39schz'), Comment(id='k3acz1l'), Comment(id='k3d2y0t'), Comment(id='k3d3dgb'), Comment(id='k3c5yam'), Comment(id='k3a2jni'), Comment(id='k3a575k'), Comment(id='k39s68c'), Comment(id='k39zzg2'), Comment(id='k39xo6c'), Comment(id='k3a6u4l'), Comment(id='k38ottj'), Comment(id='k38wnbv'), Comment(id='k3a94qr'), Comment(id='k39b372'), Comment(id='k3a54g1'), Comment(id='k3a103e'), Comment(id='k3b94do'), Comment(id='k3a7ccd'), Comment(id='k3a68m2'), Comment(id='k3ajbsi'), Comment(id='k3axwzz'), Comment(id='k3a7p4h'), Comment(id='k39qrel'), Comment(id='k39mdi2'), Comment(id='k39ecf9'), Comment(id='k3a3wze'), Comment(id='k3bvf45'), Comment(id='k3a7el7'), Comment(id='k3asq65'), Comment(id='k39fecx'), Comment(id='k3acu7b'), Comment(id='k3cf7fu'), Comment(id='k3anyik'), Comment(id='k3aa9qi'), Comment(id='k39kqo1'), Comment(id='k3dy3ia'), Comment(id='k3aprhm'), Comment(id='k3ab5gz'), Comment(id='k39v9yt'), Comment(id='k3aqa7e'), Comment(id='k3ablzz'), Comment(id='k3f8yij'), Comment(id='k3aqil1'), Comment(id='k3ac1aa'), Comment(id='k3as2t5'), Comment(id='k3dng03'), Comment(id='k3aemec'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
16ylnuy,Scroller94,,2023-10-03 07:49:05+00:00,False,,False,False,True,False,/r/datascience/comments/16ylnuy/what_aspect_of_data_science_do_you_enjoy_the_most/,What aspect of Data Science do you enjoy the most?,"What part shines the brightest on your day/s? Do you never get enough of presenting data? The sense of pride & accomplishment when the project is finished? Just writing code in your favorite language?

My favorite in my limited experience is the idea spitballing phase of figuring out a solution. Throwing spaghetti at the wall, seeing what sticks and diving into how we could apply it to the problem at hand. I think it boils down to a sense of camaraderie & the chaotic diving down rabbit holes.",datascience,https://www.reddit.com/r/datascience/comments/16ylnuy/what_aspect_of_data_science_do_you_enjoy_the_most/,28,44,0.91,"[Comment(id='k39a3sh'), Comment(id='k3a04ri'), Comment(id='k39hppz'), Comment(id='k398q9g'), Comment(id='k39stp0'), Comment(id='k399d3j'), Comment(id='k3aa2oy'), Comment(id='k3a734h'), Comment(id='k398nd2'), Comment(id='k3ayew0'), Comment(id='k39tc4f'), Comment(id='k3a7cbl'), Comment(id='k3ee7dq'), Comment(id='k39y9eu'), Comment(id='k3agsus'), Comment(id='k3bf8lk'), Comment(id='k3cxym5'), Comment(id='k3d1usx'), Comment(id='k39ggho'), Comment(id='k3bbqnu'), Comment(id='k39u948'), Comment(id='k3bxvyt'), Comment(id='k3aevyo'), Comment(id='k3a2dql'), Comment(id='k39azaf'), Comment(id='k3ard1p'), Comment(id='k3foi6o'), Comment(id='k3a7bsn')]"
16yc89t,RuinedRyan,,2023-10-02 23:33:32+00:00,False,,False,False,True,False,/r/datascience/comments/16yc89t/hiring_hell/,Hiring hell,"Gonna keep this short because I know we hate talking about hiring 24/7, but I genuinely couldn’t believe what my team just went through. 

Medium sized financial firm and from top, there’s 10 or so positions specifically for new grads next May.

We posted our position and got 200+ applicants in a week. 

And sifting through them were a nightmare. So so many people who weren’t new grads when the description specifically said that, were analysts using excel, weren’t graduating programs but data boot camps, had rip-off personal projects at the top of their resume. 

It was infuriating. 
Finally got down to 10 for interviews, and ended up reaching out to internship managers to inquire about the kids. Several good reviews and we had 3 really impress us in technical interviews. 

Ended up with a pretty good one that accepted graduating with Comp Sci and Math, but still, it’s mind boggling that so many people apply to job postings they’re WAY under qualified for.  

Just a rant.",datascience,https://www.reddit.com/r/datascience/comments/16yc89t/hiring_hell/,123,195,0.69,"[Comment(id='k37wh7z'), Comment(id='k38e6ni'), Comment(id='k37p3pn'), Comment(id='k37xcj2'), Comment(id='k37wimu'), Comment(id='k38jw78'), Comment(id='k38fgl0'), Comment(id='k37y86c'), Comment(id='k385t5f'), Comment(id='k381jcp'), Comment(id='k37ziuq'), Comment(id='k37r73k'), Comment(id='k38h93g'), Comment(id='k37npiq'), Comment(id='k38chag'), Comment(id='k37qpzs'), Comment(id='k385whk'), Comment(id='k38nt7z'), Comment(id='k39d3fb'), Comment(id='k3997qb'), Comment(id='k38w9zp'), Comment(id='k38fy3f'), Comment(id='k392b28'), Comment(id='k39d7l8'), Comment(id='k39h0cs'), Comment(id='k38nl67'), Comment(id='k39sghj'), Comment(id='k38r6pw'), Comment(id='k38viws'), Comment(id='k39emal'), Comment(id='k38i8pq'), Comment(id='k38j7y5'), Comment(id='k3ar301'), Comment(id='k3b5dl4'), Comment(id='k3c0miu'), Comment(id='k38ncfz'), Comment(id='k3824xc'), Comment(id='k37ui5x'), Comment(id='k387cjn'), Comment(id='k38hh6t'), Comment(id='k38vir3'), Comment(id='k3b2gsu'), Comment(id='k3g72ue'), Comment(id='k38b046'), Comment(id='k397vrr'), Comment(id='k39ekri'), Comment(id='k38g2lx'), Comment(id='k38rqdh'), Comment(id='k39uj9z'), Comment(id='k39ur89'), Comment(id='k3a06ga'), Comment(id='k3a8i2g'), Comment(id='k3atp19'), Comment(id='k3ax455'), Comment(id='k3clsl0'), Comment(id='k3dt0rj'), Comment(id='k3egla7'), Comment(id='k38lrdo'), Comment(id='k380iq3'), Comment(id='k37xcp2'), Comment(id='k3atm9y'), Comment(id='k3adotc'), Comment(id='k37rtel'), Comment(id='k38uzsm'), Comment(id='k38woyx'), Comment(id='k3ag4fw'), Comment(id='k393abo'), Comment(id='k38461e'), Comment(id='k38ltoj'), Comment(id='k383cik'), Comment(id='k37vz49'), Comment(id='k37qlc2'), Comment(id='k37vt5g'), Comment(id='k39kh6j'), Comment(id='k4l95oj'), Comment(id='k38mrtq'), Comment(id='k392pji'), Comment(id='k39wwi4'), Comment(id='k38n7su'), Comment(id='k38nijz'), Comment(id='k39aif3'), Comment(id='k382uxw'), Comment(id='k38567s'), Comment(id='k3834c2'), Comment(id='k38gtd5'), Comment(id='k38wjt3'), Comment(id='k37zsmw'), Comment(id='k38n2ti'), Comment(id='k3cxzqh'), Comment(id='k381gid'), Comment(id='k37whfs'), Comment(id='k38ws7p'), Comment(id='k3a2yck'), Comment(id='k3agx8k'), Comment(id='k3eafuo'), Comment(id='k3c3wxo'), Comment(id='k382tq7'), Comment(id='k387wh9'), Comment(id='k39wr7o'), Comment(id='k3812up'), Comment(id='k4l9lf2'), Comment(id='k3ab4z5'), Comment(id='k38jmab'), Comment(id='k38pxj8'), Comment(id='k38wfgd'), Comment(id='k3830m1'), Comment(id='k3d0spr'), Comment(id='k3e1hxi'), Comment(id='k3ako9i'), Comment(id='k384oc6'), Comment(id='k3ajloa'), Comment(id='k39j40f'), Comment(id='k384l97'), Comment(id='k4lcfzw'), Comment(id='k3bmeyj'), Comment(id='k3e9ucn'), Comment(id='k3hs8oz'), Comment(id='k3gt09t'), Comment(id='k3a8fm7'), Comment(id='k39jhae'), Comment(id='k3fvam2'), Comment(id='k3hwfix'), Comment(id='k3i4do6')]"
16z8d2e,John198777,,2023-10-04 00:19:50+00:00,False,,False,False,True,False,/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/,Do you worry that outsourcing will take your job?,"I work in consultancy but I'm considering a pivot into data analysis. However, I am worried that companies can easily hire data analysts and scientists in other countries for a lot cheaper whereas consultancy is better protected against this due to the importance of face to face meetings, on site work and local knowledge.

Due to Covid, many companies have learnt how to create remote teams, which may accelerate this change further. 

Is this a major risk over the next five to 10 years? Can we expect fewer jobs in The West and lower wages due to outsourcing to other countries and remote working?",datascience,https://www.reddit.com/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/,18,2,0.56,"[Comment(id='k3d3q7r'), Comment(id='k3d54dg'), Comment(id='k3dbimf'), Comment(id='k3d9d6y'), Comment(id='k3dpukc'), Comment(id='k3evsh9'), Comment(id='k3ewaij'), Comment(id='k3dgxwp'), Comment(id='k3e2sjb'), Comment(id='k3giw1a'), Comment(id='k3gu1cs'), Comment(id='k3lb9k8'), Comment(id='k3obho7'), Comment(id='k3gb7mh'), Comment(id='k3dh797'), Comment(id='k3fx1iz'), Comment(id='k3hm59a'), Comment(id='k3hyd1o'), Comment(id='k3hynia')]"
16zgo76,swesweee,,2023-10-04 07:23:48+00:00,False,,False,False,True,False,/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/,Does anyone know any tools that helps people convert their python code into streamlit apps?,"I am a data scientist. I usually build ML models and convert them into streamlit apps. Does anyone know any tools that helps automatically convert my python/ML code into streamlit app so i can save the hassle.

&#x200B;

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/,4,0,0.33,"[Comment(id='k3o5nvz'), Comment(id='k3fbmv4'), Comment(id='k3ow43j'), Comment(id='k3o5qe3')]"
16yyleb,combrade,,2023-10-03 17:52:01+00:00,False,,False,False,True,False,/r/datascience/comments/16yyleb/doing_parttime_social_science_research/,Doing Part-Time Social Science Research,"I was wondering if this was an option as I just finished my master's degree, and I'm iffy about going for my Ph.D. My interest in research is Political Science research with Quantitative Methods.

I know that some think-tanks have unaffiliated fellows. and I know a few individuals that are Non-Resident Fellows at CSIS, but they're very senior and sometimes teach ML courses at universities as well.  

I basically just want to get a nonpaying part-time research analyst role so I can do academic research while not quitting my job in tech as a Data Engineer. Some of my friends have suggested just reaching out to professors asking if I can do research with them and if they need help doing research in R. But a think-tank or nonprofit would be great as then I can put that research on my resume or Linkedin.",datascience,https://www.reddit.com/r/datascience/comments/16yyleb/doing_parttime_social_science_research/,5,4,0.83,"[Comment(id='k3bfef7'), Comment(id='k3bwy6u'), Comment(id='k3d22zv'), Comment(id='k3d29pn'), Comment(id='k3d5lk1')]"
16yybuq,smarvin2,,2023-10-03 17:41:29+00:00,False,,False,False,False,False,/r/datascience/comments/16yybuq/indexing_large_datasets_a_5x_improvement_in/,Indexing Large Datasets - A 5x Improvement in Vector Recall Speed When Moving from IVFFlat to HNSW,,datascience,https://postgresml.org/blog/speeding-up-vector-recall-by-5x-with-hnsw,0,3,1.0,[]
16yvbbr,CryptographerDry7458,,2023-10-03 15:44:20+00:00,False,,False,False,True,False,/r/datascience/comments/16yvbbr/what_is_your_goto_for_data_quality_in_computer/,What is your go-to for data quality in Computer Vision?,"For those working on CV (unstructured data), how to you approach data quality?

I've been working with data quality for structured data, and I have my methods for assessing data quality, but I'm fairly new to CV and a bit confused about how to evaluate the quality of my data, specifically for computer vision applications.

I know that data quality is crucial for the success of any machine learning project, but when it comes to images and videos, what are the key factors I should be looking at to ensure that my data is up to par?

Are there any specific metrics or tools I should be using to measure the quality of my training data? And how can I tell if my dataset is biased or unrepresentative of the real-world scenarios I'm trying to tackle?

Any guidance or advice on assessing data quality for computer vision would be appreciated! Thanks in advance",datascience,https://www.reddit.com/r/datascience/comments/16yvbbr/what_is_your_goto_for_data_quality_in_computer/,4,5,1.0,"[Comment(id='k3dsh5q'), Comment(id='k49gykm'), Comment(id='k73t5ne'), Comment(id='k3dsje2')]"
16z0pwh,matus_pikuliak,,2023-10-03 19:16:22+00:00,False,,False,True,False,False,/r/datascience/comments/16z0pwh/multilingual_reading_skills_of_language_models/,Multilingual Reading Skills of Language Models,,datascience,https://www.opensamizdat.com/posts/belebele/,0,2,1.0,[]
16y0vfi,Excellent_Cost170,,2023-10-02 16:15:28+00:00,False,,False,False,True,False,/r/datascience/comments/16y0vfi/what_i_wish_i_had_known_earlier_in_my_career/,"What I wish I had known earlier in my career, particularly with disorganized companies"," I'm quoting directly from a Reddit user named funbike. This is the rule you should abide by in organizations. I also made the same mistake when I joined a company, attempting to prove myself.

"" 

After being a fool in my early career trying too hard to impress, this is how I handle this kind of thing these days:

* Document EVERYTHING. Follow-up verbal conversations with summary email. When things go south, I'll be able to prove I warned them.
* Give *realistic* estimates on how long things will take. Whatever I say is usually twice how long I actually think it will take, because things never go like you think.
* Make it clear that that longer-term estimates will be less accurate the farther out they are, because software is notoriously difficult to estimate.
* Tell them to their face that we *will not* make the unrealistic dates they've set, and to prevent in future to always consult first.
* I will *not* work overtime due to artificial deadlines. I'll do O/T for extreme exceptional cases only, such as a one-time short-term crisis or for a regulatory-mandated deadline. By 6pm I'll be at my house.
* Explain quality should never be abandoned for speed. It will violently backfire in the end, with the opposite effect.

I stand my ground. I can make them mildly unhappy now, or furiously disappointed in our results in the future. I'll take the first one please.

Even if you were to heroically meet their unreasonable date, they'll just expect more next time. You'll burn out and maybe the next time you'll have an embarrassing failure even with crazy overtime. They'll say ""tsk, tsk"" and blame you. Don't fall into this trap""",datascience,https://www.reddit.com/r/datascience/comments/16y0vfi/what_i_wish_i_had_known_earlier_in_my_career/,50,256,0.99,"[Comment(id='k35vxwf'), Comment(id='k36653b'), Comment(id='k369cmd'), Comment(id='k36bxct'), Comment(id='k36zmvt'), Comment(id='k36cnd5'), Comment(id='k35z35n'), Comment(id='k36afmj'), Comment(id='k37mbo8'), Comment(id='k370cce'), Comment(id='k37vhc8'), Comment(id='k36a2ld'), Comment(id='k35x0nu'), Comment(id='k36gk6c'), Comment(id='k37avyb'), Comment(id='k37fm70'), Comment(id='k37wg3w'), Comment(id='k3827fz'), Comment(id='k38b3qe'), Comment(id='k39a8m2'), Comment(id='k3aizmv'), Comment(id='k3c9yyj'), Comment(id='k368wd5'), Comment(id='k36co7r'), Comment(id='k374vzl'), Comment(id='k3axbus'), Comment(id='k36d433'), Comment(id='k39mobf'), Comment(id='k36fxh8'), Comment(id='k361ra2'), Comment(id='k3fuivb'), Comment(id='k370m5u'), Comment(id='k36fm7b'), Comment(id='k38asxy'), Comment(id='k3tzma8'), Comment(id='k37c1rx'), Comment(id='k36gli8'), Comment(id='k37hp5y'), Comment(id='k36glzj'), Comment(id='k36olbt'), Comment(id='k3hv8ph'), Comment(id='k370rwk'), Comment(id='k36jzdn'), Comment(id='k3umbn3'), Comment(id='k37fuqi'), Comment(id='k37cybm'), Comment(id='k37jzo0'), Comment(id='k36jfr4'), Comment(id='k379ju8'), Comment(id='k36mcww')]"
16z0gck,Dry-Growth4940,,2023-10-03 19:05:25+00:00,False,,False,False,True,False,/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/,Code Signal Data Analytics Framework Questions ?,"Was wondering if anyone gave the Data Analytics Framework assessment. 

Time crunch is a major factor I feel. The last of the questions and ability not to view SQL ctes were nightmare. 

&#x200B;

Score 338/600 after solving 10 questions out of 15. Is this any good ? ",datascience,https://www.reddit.com/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/,6,1,1.0,"[Comment(id='k56qsp1'), Comment(id='k5fle0q'), Comment(id='k6a798h'), Comment(id='k56rwmy'), Comment(id='k5gj085'), Comment(id='k5iimix')]"
16yqueg,BenchLeague,,2023-10-03 12:39:48+00:00,False,,False,False,False,False,/r/datascience/comments/16yqueg/network_theory_to_model_cfb_outcomes/,Network Theory to Model CFB outcomes,"Just thought I post some projects I have been working on in my free time. Trying to figure out the most objective way to rank fbs teams. 

Any cool projects y’all are working on?",datascience,https://i.redd.it/cz0ybu57gzrb1.jpg,0,2,1.0,[]
16xldj9,Inevitable-Quality15,,2023-10-02 03:00:49+00:00,False,,False,False,True,False,/r/datascience/comments/16xldj9/what_industries_wont_you_work_in_again_in/,What industries wont you work in again in datascience?,"For me,

Advertising -  Ive never had to help more co-workers with sql joins in my life. most analyst and data engineers ive worked with had horrible technical skills and leadership was ok with that.  They just bought them alteryx and my email box continuously got spammed emails on a loop because they kept forgetting the one record node and all my data started getting dupes in my database.

Finance -  I started my career at a large financial institution and want something a bit more laid back.

&#x200B;

On the flipside, ive had good experience in automotive. all my coworkers were extremely technically competent and i learned alot. i did some cool projects too that got me started in datascience",datascience,https://www.reddit.com/r/datascience/comments/16xldj9/what_industries_wont_you_work_in_again_in/,130,249,0.97,"[Comment(id='k33lsa9'), Comment(id='k34dk7b'), Comment(id='k33mk7r'), Comment(id='k33ffxv'), Comment(id='k34vf4g'), Comment(id='k34gbuk'), Comment(id='k33drr3'), Comment(id='k33rmhz'), Comment(id='k34i5ok'), Comment(id='k34n4yn'), Comment(id='k345t6k'), Comment(id='k35l6nf'), Comment(id='k36yo3o'), Comment(id='k35i7jd'), Comment(id='k35hvnf'), Comment(id='k350o2e'), Comment(id='k357cgn'), Comment(id='k35bsaw'), Comment(id='k35jlpy'), Comment(id='k35nnqj'), Comment(id='k367z37'), Comment(id='k38gqjf'), Comment(id='k33revz'), Comment(id='k357vnn'), Comment(id='k35mptj'), Comment(id='k35v4aw'), Comment(id='k37e28l'), Comment(id='k37oiq8'), Comment(id='k37ri77'), Comment(id='k387e9s'), Comment(id='k38orwk'), Comment(id='k38qzkk'), Comment(id='k38sqq9'), Comment(id='k3bn3gn'), Comment(id='k3bsc8e'), Comment(id='k3c67nr'), Comment(id='k3nvtqx'), Comment(id='k345212'), Comment(id='k357ja2'), Comment(id='k36wlap'), Comment(id='k35in0v'), Comment(id='k35s9im'), Comment(id='k38hy9s'), Comment(id='k359iow'), Comment(id='k34udfq'), Comment(id='k34upef'), Comment(id='k38iu7n'), Comment(id='k3f0zws'), Comment(id='k34isg2'), Comment(id='k34lrvt'), Comment(id='k35si1w'), Comment(id='k35ym5q'), Comment(id='k37cn3a'), Comment(id='k35y12c'), Comment(id='k34vmhs'), Comment(id='k34o4ii'), Comment(id='k33uzet'), Comment(id='k33i02t'), Comment(id='k33i5x3'), Comment(id='k35oesc'), Comment(id='k34x5ou'), Comment(id='k34tddn'), Comment(id='k35mv86'), Comment(id='k35aman'), Comment(id='k37d8sy'), Comment(id='k38x4se'), Comment(id='k34nui3'), Comment(id='k34yyi1'), Comment(id='k34szgo'), Comment(id='k38prma'), Comment(id='k34nvx5'), Comment(id='k35hwqi'), Comment(id='k38t3n0'), Comment(id='k39ab0g'), Comment(id='k36vkv4'), Comment(id='k34lwlo'), Comment(id='k38t4ih'), Comment(id='k36yyfe'), Comment(id='k35xyqr'), Comment(id='k35yhad'), Comment(id='k349263'), Comment(id='k35g5ww'), Comment(id='k3br1jg'), Comment(id='k3dgcvl'), Comment(id='k35yhzm'), Comment(id='k387qhq'), Comment(id='k3budz6'), Comment(id='k36za99'), Comment(id='k37u959'), Comment(id='k3966k9'), Comment(id='k35q74a'), Comment(id='k38wt6g'), Comment(id='k35t85h'), Comment(id='k35ptdj'), Comment(id='k33rg5f'), Comment(id='k3andqi'), Comment(id='k37k5h6'), Comment(id='k36fc0r'), Comment(id='k34o8tm'), Comment(id='k3gqb27'), Comment(id='k34nqii'), Comment(id='k35nbkb'), Comment(id='k37btgp'), Comment(id='k3641it'), Comment(id='k34lcov'), Comment(id='k3gwykk'), Comment(id='k3bv0am'), Comment(id='k3709bc'), Comment(id='k373fie'), Comment(id='k37cwjd'), Comment(id='k362p1x'), Comment(id='k36g8cy'), Comment(id='k33s5t3'), Comment(id='k37nylc'), Comment(id='k38x3ij'), Comment(id='k34oeu7'), Comment(id='k35tjqp'), Comment(id='k37paot'), Comment(id='k36bipi'), Comment(id='k34y5wm'), Comment(id='k3bv9mk'), Comment(id='k35yqgy'), Comment(id='k38huwx'), Comment(id='k37qhnx'), Comment(id='k34yx35'), Comment(id='k372ftp'), Comment(id='k39m4yx'), Comment(id='k382yl6'), Comment(id='k355jvo'), Comment(id='k35gddr'), Comment(id='k35m22u')]"
16z3y8h,,,2023-10-03 21:23:41+00:00,False,,False,False,True,False,/r/datascience/comments/16z3y8h/llms/,LLMs?,"I'm a FAANG data scientist with 5+ years of experience; I've grown increasingly concerned that LLMs will begin to replace a LOT of the work that data professionals currently do. From easy things like dashboard generation to tough things like specific deep dive research questions, seem like we're walking into a world where the skillset of the analyst / scientist is a pre-req for a different position as opposed to a job in and of itself.

Thoughts? How are you preparing for much of this work to become automated? What other skills do you think are on the horizon (please don't say prompt engineering)?",datascience,https://www.reddit.com/r/datascience/comments/16z3y8h/llms/,117,0,0.44,"[Comment(id='k3cdclm'), Comment(id='k3cd14p'), Comment(id='k3cipdn'), Comment(id='k3cusmu'), Comment(id='k3cn72w'), Comment(id='k3cudur'), Comment(id='k3czrkc'), Comment(id='k3cnfke'), Comment(id='k3cftbh'), Comment(id='k3co3ht'), Comment(id='k3e2gjb'), Comment(id='k3ckgut'), Comment(id='k3cnj7g'), Comment(id='k3cmtg1'), Comment(id='k3cza8w'), Comment(id='k3clbi9'), Comment(id='k3cmzp1'), Comment(id='k3cx6sq'), Comment(id='k3d38yc'), Comment(id='k3d7nq5'), Comment(id='k3d9lob'), Comment(id='k3dl0oq'), Comment(id='k3edaz2'), Comment(id='k3ej8m3'), Comment(id='k3fegna'), Comment(id='k3gufbi'), Comment(id='k3jy9m7'), Comment(id='k3l5two'), Comment(id='k3oxh29'), Comment(id='k406o1k'), Comment(id='k3cfxyd'), Comment(id='k3cjghv'), Comment(id='k3d9na8'), Comment(id='k3cfd5g'), Comment(id='k3cvcij'), Comment(id='k3gcjkg'), Comment(id='k3ox4z1'), Comment(id='k3cxyet'), Comment(id='k3ciewu'), Comment(id='k3cdzlo'), Comment(id='k3cjvui'), Comment(id='k3dbll4'), Comment(id='k3czvpp'), Comment(id='k3co8qm'), Comment(id='k3cgf4d'), Comment(id='k3cld6w'), Comment(id='k3cobaq'), Comment(id='k3cohgf'), Comment(id='k3d9pks'), Comment(id='k3cxv5p'), Comment(id='k3dabrp'), Comment(id='k3gttym'), Comment(id='k3cxlw9'), Comment(id='k3doso3'), Comment(id='k3czfm7'), Comment(id='k3gcr5o'), Comment(id='k3fe52d'), Comment(id='k3d96ls'), Comment(id='k3d8o5s'), Comment(id='k3ckjed'), Comment(id='k3cfatq'), Comment(id='k3cvngk'), Comment(id='k3cl6ud'), Comment(id='k3dcq1u'), Comment(id='k3d3mqy'), Comment(id='k3culqo'), Comment(id='k3ch9sd'), Comment(id='k3cylve'), Comment(id='k3dghzp'), Comment(id='k3cz36o'), Comment(id='k3cnpsp'), Comment(id='k3crzr0'), Comment(id='k3d09t7'), Comment(id='k3doc4t'), Comment(id='k3dt17z'), Comment(id='k3ei8gc'), Comment(id='k3fl4c5'), Comment(id='k3dd3dj'), Comment(id='k3ddsz3'), Comment(id='k3dm46v'), Comment(id='k3coaij'), Comment(id='k3d3x26'), Comment(id='k3cukvj'), Comment(id='k3cfvw4'), Comment(id='k3d9emw'), Comment(id='k3cnd7u'), Comment(id='k3d5lxe'), Comment(id='k3citt3'), Comment(id='k3cosor'), Comment(id='k3d415u'), Comment(id='k3d46ev'), Comment(id='k3dldc9'), Comment(id='k3cphpw'), Comment(id='k3d4dsm'), Comment(id='k3cota6'), Comment(id='k3cw8gx'), Comment(id='k3dakrx'), Comment(id='k3d4pfz'), Comment(id='k3ck2vc'), Comment(id='k3czeba'), Comment(id='k3dl2ol'), Comment(id='k3cw92d'), Comment(id='k3cw9x6'), Comment(id='k3d4zm9'), Comment(id='k3dlndq'), Comment(id='k3cpnwn'), Comment(id='k3db994'), Comment(id='k3d6xuc'), Comment(id='k3cn9aa'), Comment(id='k3cl1c2'), Comment(id='k3d37eu'), Comment(id='k3d4ens'), Comment(id='k3f2dbb'), Comment(id='k3dbww2'), Comment(id='k3d4o0e'), Comment(id='k3dchfe'), Comment(id='k3djly3'), Comment(id='k3d75ix'), Comment(id='k3dg0et')]"
16xxndf,SuitableElk7382,,2023-10-02 14:09:48+00:00,False,,1696260368.0,False,True,False,/r/datascience/comments/16xxndf/how_do_you_handle_making_mistakes_on_the_job/,How do you handle making mistakes on the job?,"What are some of the biggest mistakes you guys have made and how do you handle them?  Especially when there is a time crunch.

I’m a quality data analyst for a steel company and have been in this position for almost 2 years.  I finished my masters in data analytics this past May, so this job has been my only real experience in the world of data.  I want to transition to data science in this next year.  In my free time, I take Codecademy courses to learn Python and SQL and I will eventually dive into Java as well.  I take what I learn and I try to apply it to my job.  We’re a legacy steel mill, so there is no fancy automation, the business and production systems don’t communicate very well, data can only be gathered through exporting reports from these systems in csv files.  So I’ve been able to sort of make my own database using the tools I’ve been approved to download (basically just anaconda and power bi).

As the only data analyst in my mill, with no previous steel making background, my company relies heavily on my data analytics to make business decisions both small and large and sometimes is overwhelming pressure to be precise.  Luckily I haven’t had any major mistakes.  The downside is I’m the only person doing the job I do and there isn’t a whole lot of computer literacy in the management, so unless my conclusions appear extremely illogical to them, they just roll with it. I’ve definitely made mistakes along the way but have caught them myself, sometimes working through the night so I can hurry and send emails out to disregard my previous work and look at the revised stuff.  

This just made me wonder how others handle mistakes both when they catch it and when they don’t catch it.  I understand larger companies probably have a team of people doing the same projects or can lend a hand to be a 2nd pair of eyes.  

Maybe I’m just overdue to make my first big mistake lol.  I feel like I make a lot of decisions day-to-day that I have to cross my fingers on.",datascience,https://www.reddit.com/r/datascience/comments/16xxndf/how_do_you_handle_making_mistakes_on_the_job/,21,21,0.93,"[Comment(id='k35ah9l'), Comment(id='k35ab61'), Comment(id='k358e0o'), Comment(id='k360rbd'), Comment(id='k35n97f'), Comment(id='k36p14r'), Comment(id='k36jykl'), Comment(id='k36gnrs'), Comment(id='k370zkk'), Comment(id='k3721rk'), Comment(id='k36nvs7'), Comment(id='k3921gn'), Comment(id='k3qa4xe'), Comment(id='k35fywd'), Comment(id='k367l36'), Comment(id='k374dsx'), Comment(id='k36mut6'), Comment(id='k3639hj'), Comment(id='k36seq9'), Comment(id='k36nhjz'), Comment(id='k36s8ki'), Comment(id='k36n09t')]"
16x6t1p,aGuyAndHisWood,,2023-10-01 17:15:37+00:00,False,,1696180894.0,False,True,False,/r/datascience/comments/16x6t1p/my_f100_company_analyzed_why_our_good_data/,My F100 company analyzed why our good data scientists are good and here's the recap,"A small team of internal researchers inside the company spent time investigating which data scientists preformed the best, which preformed the worst, and what factors played into this. 

The top 3 indicators of a high preforming data scientist were:
1. The number one predictor of a preformant data scientist was proactive communication. Be it speaking up in meetings, pinging people in chat, voicing concerns with a work plan, these data scientists communicated on their own initiative and their ability to get things done and make an impact is recognized. 
2. They are capable of flushing out requirements and working on complicated tasks without managerial intervention. A good example of this could be manager says we need to build a model that satisfies xyz objectives and that there are additional business reqs we'll need to flush out. 2 or 3 data scientists go do all the work to get the data and flush out the requirments while making all the plans amongst themselves and basically just keeping the manager in the loop on what's happening. 
3. They focus on adding value over pursuing technical solutions. Often times the simpler modeling approach is good enough and it solves the problem in a quick fashion. 


Things noted about low preforming data scientists were:
1. They were reactive in their communication
2. They often times missed deadlines that they themselves set and never communicated that there were issues or that the deadline would be missed. 
3. They often focus on tasks like attending all of their meetings or immediatly responding to emails rather than meeting project goals and deadlines
4. They focus too much on perfecting the POC solution which later leads to a lot of rework / wasted time.
5. They're overly dismissive in their communication. Weather it be asking for feedback and validation and then disregarding it when it doesn't align with their ideas or simply dismissing the ideas of others in general. 
6. They create drama.",datascience,https://www.reddit.com/r/datascience/comments/16x6t1p/my_f100_company_analyzed_why_our_good_data/,178,482,0.9,"[Comment(id='k30uzz4'), Comment(id='k318yce'), Comment(id='k311aaf'), Comment(id='k318psu'), Comment(id='k32q4hb'), Comment(id='k31e0ij'), Comment(id='k31gify'), Comment(id='k31a7ig'), Comment(id='k31od3n'), Comment(id='k31nvzm'), Comment(id='k317ldf'), Comment(id='k31avs3'), Comment(id='k32etvv'), Comment(id='k31ft9j'), Comment(id='k3187s1'), Comment(id='k315cdc'), Comment(id='k33by5l'), Comment(id='k31ewx9'), Comment(id='k31gwut'), Comment(id='k32vb4y'), Comment(id='k33v7pr'), Comment(id='k352l49'), Comment(id='k35l3o7'), Comment(id='k36i9w7'), Comment(id='k3sejwv'), Comment(id='k32xumo'), Comment(id='k32yp96'), Comment(id='k30vmi5'), Comment(id='k30vvu9'), Comment(id='k31qe8q'), Comment(id='k32k6r1'), Comment(id='k31zqna'), Comment(id='k33kw0q'), Comment(id='k31ce4z'), Comment(id='k31k1uz'), Comment(id='k320tgx'), Comment(id='k33465p'), Comment(id='k32hssl'), Comment(id='k32tjhm'), Comment(id='k32tltg'), Comment(id='k334cvr'), Comment(id='k337hbs'), Comment(id='k337n90'), Comment(id='k33h2mh'), Comment(id='k33kdtd'), Comment(id='k33olko'), Comment(id='k33xcm7'), Comment(id='k3443kj'), Comment(id='k34i6st'), Comment(id='k34thgd'), Comment(id='k34zorj'), Comment(id='k354sqn'), Comment(id='k3nrulu'), Comment(id='k3rr2lv'), Comment(id='k30yfgr'), Comment(id='k31j7cc'), Comment(id='k31qm7z'), Comment(id='k320f0b'), Comment(id='k3147tq'), Comment(id='k3224sw'), Comment(id='k30vfh8'), Comment(id='k315qu3'), Comment(id='k36yhto'), Comment(id='k32lcmf'), Comment(id='k32hfcg'), Comment(id='k314ywe'), Comment(id='k31u71v'), Comment(id='k36zn1j'), Comment(id='k3281r1'), Comment(id='k329u8t'), Comment(id='k3236rv'), Comment(id='k33i41h'), Comment(id='k31l5nh'), Comment(id='k31ybl8'), Comment(id='k33qrm2'), Comment(id='k33lie9'), Comment(id='k31fzyk'), Comment(id='k3801n4'), Comment(id='k315zy7'), Comment(id='k32c38k'), Comment(id='k32pw1z'), Comment(id='k31643j'), Comment(id='k3169hm'), Comment(id='k32y3mn'), Comment(id='k33hhn1'), Comment(id='k314ywn'), Comment(id='k30xcmz'), Comment(id='k3110dw'), Comment(id='k33qvoo'), Comment(id='k326p7i'), Comment(id='k33he02'), Comment(id='k315d2p'), Comment(id='k31imgk'), Comment(id='k31tp3y'), Comment(id='k31ufa6'), Comment(id='k320m1p'), Comment(id='k327wo0'), Comment(id='k32kdh4'), Comment(id='k35sulg'), Comment(id='k35amuw'), Comment(id='k33kabp'), Comment(id='k39sd21'), Comment(id='k31928s'), Comment(id='k315v3q'), Comment(id='k31ix6y'), Comment(id='k32dgqz'), Comment(id='k367s9o'), Comment(id='k33pucm'), Comment(id='k3192bb'), Comment(id='k32dso3'), Comment(id='k352vt7'), Comment(id='k35hwvu'), Comment(id='k36glsp'), Comment(id='k31or27'), Comment(id='k35livt'), Comment(id='k32ciat'), Comment(id='k316ca6'), Comment(id='k315ilu'), Comment(id='k326kwy'), Comment(id='k31trio'), Comment(id='k31wcwf'), Comment(id='k34ucfd'), Comment(id='k31w6ag'), Comment(id='k329pvd'), Comment(id='k32d70d'), Comment(id='k316vqr'), Comment(id='k31m1bp'), Comment(id='k331lel'), Comment(id='k36faz9'), Comment(id='k33qo4w'), Comment(id='k31cvxl'), Comment(id='k37ue7i'), Comment(id='k32ggom'), Comment(id='k31u80c'), Comment(id='k32swh4'), Comment(id='k32fopr'), Comment(id='k34nv5x'), Comment(id='k35hbb3'), Comment(id='k32cz5s'), Comment(id='k31wtch'), Comment(id='k33c0u0'), Comment(id='k32bcle'), Comment(id='k32cj8h'), Comment(id='k317yxo'), Comment(id='k31afry'), Comment(id='k32116o'), Comment(id='k33x0sf'), Comment(id='k371wxx'), Comment(id='k38hm6w'), Comment(id='k34ja5v'), Comment(id='k31dofb'), Comment(id='k39di3t'), Comment(id='k33i6qk'), Comment(id='k34u48x'), Comment(id='k32dx1o'), Comment(id='k31xi7g'), Comment(id='k32d0jc'), Comment(id='k3446gl'), Comment(id='k31oyzr'), Comment(id='k31olfy'), Comment(id='k33mn69'), Comment(id='k32i6bf'), Comment(id='k34jk1s'), Comment(id='k376zed'), Comment(id='k368cta'), Comment(id='k33ntax'), Comment(id='k3aammv'), Comment(id='k32e8o8'), Comment(id='k32gle9'), Comment(id='k31y2cy'), Comment(id='k35y2dh'), Comment(id='k3611u0'), Comment(id='k34xcvu'), Comment(id='k32jg27'), Comment(id='k37o91q'), Comment(id='k36bx3q'), Comment(id='k370bhl'), Comment(id='k36eqj5'), Comment(id='k36qq17'), Comment(id='k36rpeo'), <MoreComments count=0, children=[]>]"
16y7fcy,corey1505,,2023-10-02 20:28:58+00:00,False,,False,False,False,False,/r/datascience/comments/16y7fcy/rmmlus_moral_scenarios_benchmark_doesnt_measure/,[R]MMLU’s Moral Scenarios Benchmark Doesn’t Measure What You Think it Measures,,datascience,https://medium.com/p/74fd6e512521,0,0,0.5,[]
16xwqmd,frodegrodas,,2023-10-02 13:31:48+00:00,False,,False,False,True,False,/r/datascience/comments/16xwqmd/roi_framework_for_data_science/,ROI framework for data science,Does anyone know of a good example of a return on investment framework for data science work? Or even a set of principles to work from? My team wants to demonstrate its value (more objectively) - and estimate the value generated from proposed initiatives - but there's little to go on in the literature.,datascience,https://www.reddit.com/r/datascience/comments/16xwqmd/roi_framework_for_data_science/,1,2,0.75,[Comment(id='k3ocsen')]
16y0lih,Remarkable-Floor-351,,2023-10-02 16:04:49+00:00,False,,False,False,True,False,/r/datascience/comments/16y0lih/how_long_did_it_take_you_to_selflearn_data/,"How long did it take you to self-learn data science and afterwards, how long to get employed?","To anyone who taught themselves data science and then achieved employment in a data science role, how long did it take you to learn in hours per day? And additionally, how long did it take you after you stopped learning to find a job and keep a job?

If you did not self learn or hold a job afterwards please do not reply with any speculations. ",datascience,https://www.reddit.com/r/datascience/comments/16y0lih/how_long_did_it_take_you_to_selflearn_data/,12,2,0.55,"[Comment(id='k35ybfb'), Comment(id='k35v0nd'), Comment(id='k368pk6'), Comment(id='k392r8p'), Comment(id='k3ajuww'), Comment(id='k3a7oq7'), Comment(id='k3a7gru'), Comment(id='k3b6s52'), Comment(id='k3abakk'), Comment(id='k3c4uix'), Comment(id='k3aeahc'), Comment(id='k3ajnt4')]"
16xmlky,AutoModerator,,2023-10-02 04:01:48+00:00,False,,False,False,True,False,/r/datascience/comments/16xmlky/weekly_entering_transitioning_thread_02_oct_2023/,"Weekly Entering & Transitioning - Thread 02 Oct, 2023 - 09 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/16xmlky/weekly_entering_transitioning_thread_02_oct_2023/,127,9,1.0,"[Comment(id='k3g4qx6'), Comment(id='k3iz40c'), Comment(id='k3ne2oo'), Comment(id='k3z43t3'), Comment(id='k354fjm'), Comment(id='k359t99'), Comment(id='k37akz1'), Comment(id='k3aooaq'), Comment(id='k3b0dce'), Comment(id='k3b6b3e'), Comment(id='k3d2day'), Comment(id='k3g1odr'), Comment(id='k3gtyf4'), Comment(id='k3lhlbw'), Comment(id='k3mce42'), Comment(id='k3ospzb'), Comment(id='k3p2ptf'), Comment(id='k3ri324'), Comment(id='k3ry09p'), Comment(id='k41t55y'), Comment(id='k3t8916'), Comment(id='k3bqxd3'), Comment(id='k3n9rf0'), Comment(id='k3rbx2e'), Comment(id='k3u2szm'), Comment(id='k3ujint'), Comment(id='k3ych2x'), Comment(id='k36oewu'), Comment(id='k397f1r'), Comment(id='k3a8tw4'), Comment(id='k3aak2s'), Comment(id='k3an4j0'), Comment(id='k3an9yr'), Comment(id='k3anycg'), Comment(id='k3ao0ca'), Comment(id='k3aq76b'), Comment(id='k3aua49'), Comment(id='k3awljl'), Comment(id='k3bvpbj'), Comment(id='k3cscyn'), Comment(id='k3cthwc'), Comment(id='k3cvxos'), Comment(id='k3dgq7c'), Comment(id='k3e18sf'), Comment(id='k3evrwb'), Comment(id='k3fimq1'), Comment(id='k3fjl4u'), Comment(id='k3g2liq'), Comment(id='k3gtytd'), Comment(id='k3ivwup'), Comment(id='k3jtgp0'), Comment(id='k3k7ffy'), Comment(id='k3kd9mz'), Comment(id='k3l3ax5'), Comment(id='k3nayhn'), Comment(id='k3nbeq8'), Comment(id='k3ofstt'), Comment(id='k3t5soc'), Comment(id='k3xte9h'), Comment(id='k3zicgn'), Comment(id='k41vv1s'), Comment(id='k42y66j'), Comment(id='k4308uq'), Comment(id='k4342h4'), Comment(id='k3jgxdo'), Comment(id='k3rir45'), Comment(id='k3pn87b'), Comment(id='k3zk42l'), Comment(id='k371b75'), Comment(id='k36rcye'), Comment(id='k37r89c'), Comment(id='k3b4yea'), Comment(id='k3cysc5'), Comment(id='k3ixkkr'), Comment(id='k3mq5gr'), Comment(id='k3t3cvo'), Comment(id='k3rhf6j'), Comment(id='k3pgi1b'), Comment(id='k4nuzkv'), Comment(id='k432ne2'), Comment(id='k41xre6'), Comment(id='k3c35l8'), Comment(id='k3rh7rc'), Comment(id='k3wb27s'), Comment(id='k36rvco'), Comment(id='k36xq4z'), Comment(id='k3b5et2'), Comment(id='k3b4sg8'), Comment(id='k3cxltb'), Comment(id='k3jhmdo'), Comment(id='k3j8x0e'), Comment(id='k3g0c3p'), Comment(id='k3g09he'), Comment(id='k3inydu'), Comment(id='k80gta4'), Comment(id='k3mr40u'), Comment(id='k3nrbj8'), Comment(id='k3rj2dx'), Comment(id='k4nuchz'), Comment(id='k3puzv8'), Comment(id='k4mumz0'), Comment(id='k3tavia'), Comment(id='k3tagxi'), Comment(id='k3pgnhi'), Comment(id='k3rijmx'), Comment(id='k3yhc6m'), Comment(id='k36ueqc'), Comment(id='k36zdpi'), Comment(id='k3d3112'), Comment(id='k3jn3uw'), Comment(id='k3kgq7a'), Comment(id='k3g3sv6'), Comment(id='k3g5bq1'), Comment(id='k3nri6b'), Comment(id='k3q03uj'), Comment(id='k4n187h'), Comment(id='k3zsue8'), Comment(id='k3tbjpr'), Comment(id='k3rm33u'), Comment(id='k372mix'), Comment(id='k3t3i8i'), Comment(id='k3rn004'), Comment(id='k37596j'), Comment(id='k3rocm2'), Comment(id='k377j8i'), Comment(id='k3rqo9r'), Comment(id='k3rtba4'), Comment(id='k3rve2v')]"
16wwiew,Auwal_adam,,2023-10-01 09:21:00+00:00,False,,False,False,False,False,/r/datascience/comments/16wwiew/how_true_is_this/,How true is this?,,datascience,https://i.redd.it/1rfskuxv6krb1.jpg,103,265,0.93,"[Comment(id='k2zcft9'), Comment(id='k2zbwiy'), Comment(id='k2zgtr0'), Comment(id='k30b5h9'), Comment(id='k2z9rso'), Comment(id='k2zhrhb'), Comment(id='k309sst'), Comment(id='k30hzbl'), Comment(id='k30co0t'), Comment(id='k306zfn'), Comment(id='k322kmo'), Comment(id='k2zin7b'), Comment(id='k30kplr'), Comment(id='k31csk1'), Comment(id='k318od8'), Comment(id='k326efm'), Comment(id='k2zv52b'), Comment(id='k2zcggj'), Comment(id='k2ztlv0'), Comment(id='k2zkqov'), Comment(id='k2zxo0k'), Comment(id='k30jc4t'), Comment(id='k31p4as'), Comment(id='k32yspm'), Comment(id='k33x3wr'), Comment(id='k34inrt'), Comment(id='k35ai0v'), Comment(id='k3mtvfo'), Comment(id='k31qvqw'), Comment(id='k2zde9r'), Comment(id='k2zl5wx'), Comment(id='k2zlqtv'), Comment(id='k2ztb5x'), Comment(id='k326zh7'), Comment(id='k32xkfu'), Comment(id='k2zl6x0'), Comment(id='k31afd7'), Comment(id='k330hz7'), Comment(id='k305939'), Comment(id='k30oyqm'), Comment(id='k316qov'), Comment(id='k3824zz'), Comment(id='k30gmya'), Comment(id='k327jhu'), Comment(id='k3ag0ao'), Comment(id='k317frv'), Comment(id='k328du4'), Comment(id='k31cx7i'), Comment(id='k366b7p'), Comment(id='k30gdag'), Comment(id='k302uto'), Comment(id='k308uke'), Comment(id='k2zsrlx'), Comment(id='k30kjab'), Comment(id='k30kx3k'), Comment(id='k34an3g'), Comment(id='k31tanc'), Comment(id='k31wfev'), Comment(id='k31wiq8'), Comment(id='k327ixw'), Comment(id='k373gt6'), Comment(id='k33tzl2'), Comment(id='k2zw2x7'), Comment(id='k30coau'), Comment(id='k31xfee'), Comment(id='k35av07'), Comment(id='k3ydj9c'), Comment(id='k319h9c'), Comment(id='k3d0un0'), Comment(id='k32ofyw'), Comment(id='k361ibj'), Comment(id='k31s9fd'), Comment(id='k30k64i'), Comment(id='k30kc51'), Comment(id='k3053s8'), Comment(id='k2zxq9l'), Comment(id='k30li7i'), Comment(id='k33fa6k'), Comment(id='k327o83'), Comment(id='k32r28x'), Comment(id='k37q9pt'), Comment(id='k30qsyz'), Comment(id='k31bf3b'), Comment(id='k3odle8'), Comment(id='k3670qe'), Comment(id='k3632bg'), Comment(id='k327725'), Comment(id='k30mrf9'), Comment(id='k31qvfs'), Comment(id='k3084j9'), Comment(id='k318jjo'), Comment(id='k33x7dj'), Comment(id='k32qxdw'), Comment(id='k30xifj'), Comment(id='k31skle'), Comment(id='k327cnr'), Comment(id='k31dh0y'), Comment(id='k32vemc'), Comment(id='k32qvi7'), Comment(id='k329kxz'), Comment(id='k32yku0'), Comment(id='k34a0k7'), Comment(id='k34aoow')]"
16xzxkb,Brief-Living-5083,,2023-10-02 15:39:41+00:00,False,,False,False,True,False,/r/datascience/comments/16xzxkb/which_industries_have_the_most_lacking_data/,Which industries have the most lacking data architecture for data analysis/modelling?,"I have noticed some industries or domains are lacking in integrated data architecture (data warehouse, let alone data lake). One example that comes to mind is marketing where the different levels in data sources makes it difficult for integrated data architecture, hence, also difficult for cross-source analysis for the KPIs.
And also on the vice versa which domains are leading in this?",datascience,https://www.reddit.com/r/datascience/comments/16xzxkb/which_industries_have_the_most_lacking_data/,2,1,0.6,"[Comment(id='k35jlm0'), Comment(id='k3a39cg')]"
16xzuxi,01jasper,,2023-10-02 15:36:50+00:00,False,,False,False,True,False,/r/datascience/comments/16xzuxi/benefits_of_converting_dicom_images_to_pngs/,Benefits of converting DICOM images to PNG's,"I try to understand what are the benefits to convert DICOM images to PNG's.  
Context:  
I have DICOM images which I already extracted the useful meta-data I want to use.  
Those images are for a task, classification-detection pipeline of some disease.

So as I already asked, what are the benefits of converting those DICOM files to PNG's rather then just using pydicom and the dicom pixel\_array?

Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.

If I understand how networks actually works, they get as input an array of pixels as floating point numbers no? So what's the differences between DICOM pixel\_array to PNG's pixel array and numpy array or tensor? both are eventually will be fed to the network as a tensor of floating numbers.

Is the reason is because PNG's are usually faster to train?

Is the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?

Is the reason is because PNG's are the format many pre-trained models expect to? (I write this knowing it's 99% not true, as mentioned the tensor thing)

Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)  
",datascience,https://www.reddit.com/r/datascience/comments/16xzuxi/benefits_of_converting_dicom_images_to_pngs/,1,0,0.5,[Comment(id='k38gb4c')]
16xrl3p,axlrosen,,2023-10-02 08:55:55+00:00,False,,False,False,True,False,/r/datascience/comments/16xrl3p/how_can_an_llm_be_good_at_compressing_images_and/,How can an LLM be good at compressing images and audio?,"This paper seems to say that an LLM trained on text can somehow be good at compressing not just text but images and audio. Intuitively this seems improbable to me. How does this work?

[https://arxiv.org/pdf/2309.10668.pdf](https://arxiv.org/pdf/2309.10668.pdf)",datascience,https://www.reddit.com/r/datascience/comments/16xrl3p/how_can_an_llm_be_good_at_compressing_images_and/,1,3,0.67,[Comment(id='k632i48')]
16xxkxs,Alarming_Scene126,,2023-10-02 14:07:04+00:00,False,,False,False,True,False,/r/datascience/comments/16xxkxs/second_data_project_web_scraping_i_am_a_beginner/,"Second Data Project : Web Scraping, I am a beginner, Help with suggestion!!","Hello  everyone!!

I have come up with my second project and I am very excited to share here. I have done this work with a day of learning web scraping. please review my project and give feedbacks, suggestions and do not hesitate to leave brutal comments. Also, i request to help me with my next steps on web scraping. 

I would like to thank this community for letting to share my projects!!

project title: Nepali Beverage Seller data web scraping

[https://www.kaggle.com/code/aadeshpradhan/nepali-alcohol-seller-data-web-scraping-cheers/notebook](https://www.kaggle.com/code/aadeshpradhan/nepali-alcohol-seller-data-web-scraping-cheers/notebook)",datascience,https://www.reddit.com/r/datascience/comments/16xxkxs/second_data_project_web_scraping_i_am_a_beginner/,0,0,0.5,[]
16xx3oy,Data_Nerd1979,,2023-10-02 13:47:36+00:00,False,,False,False,True,False,/r/datascience/comments/16xx3oy/harnessing_llm_alignment_making_ai_more_accessible/,Harnessing LLM Alignment: Making AI More Accessible,Let’s look at an example of using two classifiers from Hugging Face to enhance the FLAN-T5 model’s ability to write summaries of news articles that are both grammatically polished and consistently neutral in style. [https://opendatascience.com/harnessing-llm-alignment-making-ai-more-accessible/](https://opendatascience.com/harnessing-llm-alignment-making-ai-more-accessible/) ,datascience,https://www.reddit.com/r/datascience/comments/16xx3oy/harnessing_llm_alignment_making_ai_more_accessible/,0,0,0.5,[]
16xx1e2,veliona,,2023-10-02 13:44:52+00:00,False,,False,False,True,False,/r/datascience/comments/16xx1e2/aa_testing/,A/A testing,"While running 20 simutanious A/A tests, should each of them be allocated to 100% traffic? Or should all if them cumulatively be allocated to 100% traffic?",datascience,https://www.reddit.com/r/datascience/comments/16xx1e2/aa_testing/,0,0,0.5,[]
16xriok,Choweeez,,2023-10-02 08:51:46+00:00,False,,1696249238.0,False,True,False,/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/,Quick review of most used algorithm answers,"First, thanks to everyone that answered my previous post !

So, following this previous post ([https://www.reddit.com/r/datascience/comments/16tgojm/what\_kind\_of\_algorithm\_do\_you\_use\_the\_most\_as\_a/](https://www.reddit.com/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/)), I'm giving here a quick review of the most common answers.

Here it is:

* Gradient boosted machines (22): XGBoost (12), Light GBM (8), Catboost(2)
* Linear methods (19): Linear Regression (9), Logistic Regression (5), GAM (3), OLS (2)
* Random Forest (or tree based algo) (9)
* DBScan (4)
* DNN / CNN / GNN (4)
* Clustering algo / K-means (3)
* ARIMA (2)

&#x200B;

The number gives the number of time an answer appeared. I put here only answer that appeared at least 2 times.Also, I tried to gather some answers, but I don't know all the algorithms or tools your are using. So please forgive me if I did some mistakes or approximations in the way I gathered answers.",datascience,https://www.reddit.com/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/,2,2,0.75,"[Comment(id='k34buo1'), Comment(id='k34po6m')]"
16xtsax,theguiltedbutterfly,,2023-10-02 11:10:07+00:00,False,,False,False,True,False,/r/datascience/comments/16xtsax/thursday_oct_5th_london_meetup_working_in_data/,Thursday Oct 5th - London meetup - working in data and tech!,"Any Londoners out there? **I'm hosting an in-person meetup at Bubba Oasis in Islington this Thursday** to help educate aspiring data analysts and people who want to work in tech about insights and learnings from inside the industry.

After hosting a few online workshops earlier this year, I started a data analytics bootcamp to directly educate people on the skills required for the job - which, unfortunately, is not really taught in bootcamps, online resources, or even grad school. I'm currently on a break between cohorts and thought I'd to host a few in-person events as I believe there is so much more that can be learned as a dynamic community than as isolated self-learners.

At the event I'll mostly be having an open-ended discussion on topics like - what skills are actually used on the job, how do you package insights, how do you make your portfolio and resume stand out, and what things you should do in a technical interview. I'm open to hearing what you would like to discuss as well. The last event in Paris was a lot of fun and we had a great discussion with 8-10 attendees.  
**The MeetUp link is in my Reddit bio (and so is my LinkedIn - feel free to ask me questions there).** Please only RSVP if you intend on coming, so I can have an accurate headcount - thank you!

Note: Meetup has a bug where I can't adjust the timezones. The event is this Thursday, Oct 5th 7-9pm.",datascience,https://www.reddit.com/r/datascience/comments/16xtsax/thursday_oct_5th_london_meetup_working_in_data/,0,0,0.5,[]
16xspby,alonelycrap,,2023-10-02 10:07:47+00:00,False,,False,False,True,False,/r/datascience/comments/16xspby/data_cleaning_correcting_erroneous_text_inputs/,Data Cleaning - Correcting erroneous text inputs," Hi. I'm a beginner in data analytics and studying on my own, I use Python by the way. Just wondering how you guys deal with erroneous text input. Also English is not my first language so apologies for some grammatical errors.

I have a dataset with a total of 5M records. There's a feature called ""name"". I want to make the data consistent.

Some of the errors I found are:

1. ""&"" was typed as ""\&amp;""
2. Random "","" or any symbols
3. missing letters/wrong spelling and other typographical errors

and there are lots of other errors but I won't list it all for the sake of simplicity.

What I wanna know is if there's a way to just automatically detect these errors like by counting duplicate values and the highest number of counts will be the basis to update records for this feature that has errors.

I mean, I won't ask for a specific solution/script for this problem but would like to have direction on how to approach this. Maybe you can recommend a topic or tutorials that might help.

Thank you Very Much.",datascience,https://www.reddit.com/r/datascience/comments/16xspby/data_cleaning_correcting_erroneous_text_inputs/,1,0,0.5,[Comment(id='k4tc9it')]
16xrjix,baedling,,2023-10-02 08:53:17+00:00,False,,False,False,True,False,/r/datascience/comments/16xrjix/what_kind_of_questions_should_i_expect_for_this/,"What kind of questions should I expect for this upcoming MLE/DS interview, given this unorthodox scheduling?","My dream company, a large Scandinavian company focused on traditional engineering, offered to interview me for two positions (MLE and DS) at the same time. The HR said the hiring manager decided to skip one technical interview and proceed directly to a panel interview with 10 interviewers.

The first 30 minutes will be another technical interview. I feel this means there won't be enough time for coding, only questions about transformers, LLMs and in-domain knowledge about their industry. Could I be very wrong?

This will be followed by a 40-minute presentation of my achievements for the panel, and a 20-minute Q&A session. A 30-minute behavioral section with the HR and the hiring manager comes last.",datascience,https://www.reddit.com/r/datascience/comments/16xrjix/what_kind_of_questions_should_i_expect_for_this/,4,1,0.67,"[Comment(id='k36plzx'), Comment(id='k398h2x'), Comment(id='k399qoi'), Comment(id='k39f4tm')]"
16xlr5l,Omnitemporality,,2023-10-02 03:18:53+00:00,False,,False,False,True,False,/r/datascience/comments/16xlr5l/what_is_the_best_set_of_universal_semantic/,"What is the best set of universal semantic embeddings for implementing vector searches across large documents, and has it changed drastically before/after the OpenAI boom?","I understand I'm in way over my head here, but has vector searching always been this powerful? Or have embedding models gotten 10x better in the past 5 years?  


Also, how can AI leverage the results of a vector search most efficiently? I'm assuming taking top ""n"" results then putting NLP on top of the already vectorized results to check more deeply for context and intent?",datascience,https://www.reddit.com/r/datascience/comments/16xlr5l/what_is_the_best_set_of_universal_semantic/,3,2,0.75,"[Comment(id='k340106'), Comment(id='k34g9eh'), Comment(id='k34huiw')]"
16x200r,HotShape5112,,2023-10-01 14:01:36+00:00,False,,False,False,True,False,/r/datascience/comments/16x200r/q_to_all_data_scientists_here_who_graduated_with/,"[Q] To all data scientists here who graduated with a stat degree, do you apply all your college stat knowledge to your current job?",,datascience,https://www.reddit.com/r/datascience/comments/16x200r/q_to_all_data_scientists_here_who_graduated_with/,11,19,0.86,"[Comment(id='k30ozuz'), Comment(id='k3080tz'), Comment(id='k302rtu'), Comment(id='k316b9h'), Comment(id='k31n5s5'), Comment(id='k30r4kw'), Comment(id='k31cdbx'), Comment(id='k31fhhy'), Comment(id='k31jdmq'), Comment(id='k34s8vn'), Comment(id='k3nn5b4')]"
16woyff,UnsafeBaton1041,,2023-10-01 02:13:14+00:00,False,,1696196083.0,False,True,False,/r/datascience/comments/16woyff/have_you_ever_had_a_job_that_essentially_wants/,Have you ever had a job that essentially wants you to do *less*?,"I've always had jobs that expected a really high rate of productivity with extremely tight deadlines on projects - the sooner I could deliver, the better, as long as quality wasn't effected. I've always been praised for this, too.

Now, I've been in my first official DS role for a few months, and my boss (who has lots of experience/has been with the company for a long time) has been telling me in our private meetings that I should intentionally take a long time/wait to deliver my projects to our clients even if it doesn't actually take me very long to complete them. Again, quality isn't an issue. Is this normal? What could it be about?

Update: Wow! This blew up overnight! Thanks, everyone, for your input!",datascience,https://www.reddit.com/r/datascience/comments/16woyff/have_you_ever_had_a_job_that_essentially_wants/,46,136,0.95,"[Comment(id='k2y6kdc'), Comment(id='k2ygly1'), Comment(id='k2y93qt'), Comment(id='k2y69ef'), Comment(id='k2yowqa'), Comment(id='k2ysd1i'), Comment(id='k2ykowk'), Comment(id='k2ywcrv'), Comment(id='k2yy3ba'), Comment(id='k2z1lq5'), Comment(id='k2zoyjb'), Comment(id='k302hcz'), Comment(id='k303yls'), Comment(id='k2z78im'), Comment(id='k2zpn02'), Comment(id='k2zuhnp'), Comment(id='k2zun0h'), Comment(id='k30ciq0'), Comment(id='k3120dz'), Comment(id='k31x70z'), Comment(id='k3ajwil'), Comment(id='k2y6vj5'), Comment(id='k2yqslg'), Comment(id='k2y6ute'), Comment(id='k2ydlq3'), Comment(id='k2ykjd7'), Comment(id='k2yxuwt'), Comment(id='k31tuq4'), Comment(id='k2ygryr'), Comment(id='k2y6ypu'), Comment(id='k3029v9'), Comment(id='k2ypkr9'), Comment(id='k366l1v'), Comment(id='k2y746u'), Comment(id='k2y81us'), Comment(id='k327ida'), Comment(id='k2yrlx6'), Comment(id='k2yyt8l'), Comment(id='k321qtf'), Comment(id='k2yz37v'), Comment(id='k312ask'), Comment(id='k2z69m4'), Comment(id='k313lvp'), Comment(id='k32lvzi'), Comment(id='k2zcx8h'), Comment(id='k2zlbf1'), Comment(id='k312quu')]"
16x1rvx,Roughneck16,,2023-10-01 13:52:03+00:00,False,,False,False,False,False,/r/datascience/comments/16x1rvx/eastern_universitys_ms_in_data_science_my_review/,Eastern University’s MS in Data Science | My review,,datascience,https://kolkena.medium.com/eastern-universitys-ms-in-data-science-my-review-6f370825df59,2,5,0.78,"[Comment(id='k3j48x1'), Comment(id='k6btyjq')]"
16wpci5,AntiqueFigure6,,2023-10-01 02:32:01+00:00,False,,False,False,True,False,/r/datascience/comments/16wpci5/do_models_still_matter/,Do models still matter?,There’s a lot more focus on implementation than back a few years ago when there was  POC after POC but far fewer models made it to production. There was also the beginnings of more focus on explainable ML and more focus on scrutinising models for bias of different types. However as MLOps has really taken off the focus on productionising seems to have lead to less focus on the models themselves. Is that still out there or is it just that the extra noise on the production side makes it harder to find it?,datascience,https://www.reddit.com/r/datascience/comments/16wpci5/do_models_still_matter/,31,31,0.83,"[Comment(id='k2yc4ce'), Comment(id='k2zdy6d'), Comment(id='k2yk30x'), Comment(id='k316s1p'), Comment(id='k317qfm'), Comment(id='k31nzu4'), Comment(id='k30ul9j'), Comment(id='k32gtr3'), Comment(id='k3akdw3'), Comment(id='k2ypoz3'), Comment(id='k2zeu2j'), Comment(id='k2ze9qf'), Comment(id='k2z4u7x'), Comment(id='k2yr1xj'), Comment(id='k33ummc'), Comment(id='k33ukv5'), Comment(id='k32kgtb'), Comment(id='k30pm0u'), Comment(id='k2zp3hu'), Comment(id='k315iz8'), Comment(id='k2z4hr3'), Comment(id='k31a2t1'), Comment(id='k33pkmh'), Comment(id='k335kya'), Comment(id='k31a49t'), Comment(id='k315x50'), Comment(id='k2z5sx8'), Comment(id='k319e8p'), Comment(id='k31cb9s'), Comment(id='k31h1gp'), Comment(id='k31j5qw')]"
16xcn44,Excellent_Cost170,,2023-10-01 20:57:27+00:00,False,,False,False,True,False,/r/datascience/comments/16xcn44/indian_working_culture_or_exception_navigating/,Indian working culture or exception_navigating Cultural Differences in a Big Company,"I'm a first generation immigrant, and I've recently joined a team in a large organization that has a lot of folks with Indian heritage, including my manager.

In my previous data-related roles, I've always been the type to speak up when I'm sure about something and ask questions when necessary. But as I collaborate with my Indian colleagues, I've noticed a distinct approach. They tend to view caution as a weakness and embrace assertiveness. There are instances where they confidently express opinions without thorough research, even if they may not be accurate. It's frequently prioritized to appear intelligent in front of directors, with visibility being held in higher regard than actual substance. They also exhibit a strong inclination to submit to their superiors and naturally anticipate a similar level of submission from their team members. I often sense that every conversation is focused on extracting something from me rather than fostering collaborative efforts toward a shared goal.

This is all new to me, and I'm keen to learn how to work effectively in this diverse environment and what to understand the motivations for this behavior",datascience,https://www.reddit.com/r/datascience/comments/16xcn44/indian_working_culture_or_exception_navigating/,1,0,0.43,[Comment(id='k32z4ak')]
16x9vdv,Slow_Cry6219,,2023-10-01 19:11:39+00:00,False,,False,False,True,False,/r/datascience/comments/16x9vdv/interested_in_using_data_from_a_different_domain/,Interested in using data from a different domain to forecast to another domain,"Hey everyone novice data scientist. 

A few months ago my country removed fuel subsidies, which has massively impacted the price of fuel and has been skyrocketing. There are other countries in the same region which have done similar such subsidy removal. I was curious to know if it is possible to use dataset from a different source (countries in this case) to forecast another. Obviously there will be a need to acknowledge differences in certain features such as GDP, unemployment, economic conditions, exchange rate, global oil prices and so on. 

My question if there is an established technique or even terminology for doing something like this. Or will this be a bad faith data science use case. 

Note that I have looked into the concept of transfer learning, but not sure if its applicable here. Again i am new to this field

Looking forward to your responses :) ",datascience,https://www.reddit.com/r/datascience/comments/16x9vdv/interested_in_using_data_from_a_different_domain/,0,0,0.5,[]
16wox7j,Excellent_Cost170,,2023-10-01 02:11:34+00:00,False,,False,False,True,False,/r/datascience/comments/16wox7j/data_science_coming_back_again_and_ml_dying/,Data science coming back again and ML dying ?,"
I feel like the ML tooling and infrastructure are improving a lot, and in the near future, we wouldn't need ML engineers. Data scientists will directly deploy their models. Software engineers and data engineers will handle the rest",datascience,https://www.reddit.com/r/datascience/comments/16wox7j/data_science_coming_back_again_and_ml_dying/,87,22,0.59,"[Comment(id='k2yazkl'), Comment(id='k2z10sg'), Comment(id='k2ynn9s'), Comment(id='k2ybyyp'), Comment(id='k2zirfk'), Comment(id='k2z6c83'), Comment(id='k2yorh8'), Comment(id='k2zjo17'), Comment(id='k2ycjrx'), Comment(id='k2zg4r4'), Comment(id='k2zv72i'), Comment(id='k30plzj'), Comment(id='k2y9zes'), Comment(id='k302y9j'), Comment(id='k33mpta'), Comment(id='k2ytjzy'), Comment(id='k2yfkky'), Comment(id='k2y5986'), Comment(id='k2ycxzq'), Comment(id='k46676j'), Comment(id='k2ybpkn'), Comment(id='k31g5ya'), Comment(id='k308gy6'), Comment(id='k2yoms0'), Comment(id='k31ovby'), Comment(id='k2yexwy'), Comment(id='k308gd9'), Comment(id='k2zwuvw'), Comment(id='k31f6wt'), Comment(id='k2ypah7'), Comment(id='k31pfgm'), Comment(id='k2zlz81'), Comment(id='k2zxcst'), Comment(id='k31rkbz'), Comment(id='k2ybmdl'), Comment(id='k33mvgc'), Comment(id='k2yw8ba'), Comment(id='k2ygbt3'), Comment(id='k2yfhbi'), Comment(id='k2ydjkz'), Comment(id='k3092ty'), Comment(id='k31q1u0'), Comment(id='k2yk2q5'), Comment(id='k2ym1ye'), Comment(id='k31ogp4'), Comment(id='k31nsz8'), Comment(id='k31eje9'), Comment(id='k322mjs'), Comment(id='k314hyq'), Comment(id='k2yw4u7'), Comment(id='k2zk166'), Comment(id='k33no9b'), Comment(id='k31o7vs'), Comment(id='k31ozk6'), Comment(id='k2yhepj'), Comment(id='k2yh65y'), Comment(id='k309lcq'), Comment(id='k2zn2a8'), Comment(id='k2yudv3'), Comment(id='k2zwamq'), Comment(id='k322wgx'), Comment(id='k32c9jd'), Comment(id='k4330v8'), Comment(id='k32v67u'), Comment(id='k33za8o'), Comment(id='k2yw243'), Comment(id='k2ynkna'), Comment(id='k2yioyw'), Comment(id='k30a0fg'), Comment(id='k2zupwc'), Comment(id='k2zw9lq'), Comment(id='k2zwwnb'), Comment(id='k2zzswe'), Comment(id='k32sw19'), Comment(id='k43m1q5'), Comment(id='k33qnzy'), Comment(id='k31fio8'), Comment(id='k2yjprx'), Comment(id='k2zvjyr'), Comment(id='k2zwmnz'), Comment(id='k31eem3'), Comment(id='k30oms7'), Comment(id='k31qw6e'), Comment(id='k302ndh'), Comment(id='k34hi1n'), Comment(id='k2yljyj'), Comment(id='k30kwnf'), Comment(id='k3071ih'), Comment(id='k37h05t'), Comment(id='k35q0lx'), Comment(id='k37q9hd')]"
16x85v4,poitrenaud,,2023-10-01 18:07:49+00:00,False,,False,False,True,False,/r/datascience/comments/16x85v4/what_are_some_examples_of_business_tradeoffs/,What are some examples of business tradeoffs between a thing you can measure well and a thing you can’t measure well?,"The discussion on how having remote teams gives you access to a bigger pool of talent (measurable) but reduces company culture (hard to measure, at the very least) got me thinking about what other tradeoffs like this can make decisions challenging.",datascience,https://www.reddit.com/r/datascience/comments/16x85v4/what_are_some_examples_of_business_tradeoffs/,12,1,0.6,"[Comment(id='k318x54'), Comment(id='k315421'), Comment(id='k319lb0'), Comment(id='k318k5s'), Comment(id='k319tpa'), Comment(id='k31mshl'), Comment(id='k31qt1m'), Comment(id='k31av6m'), Comment(id='k31sjdr'), Comment(id='k31bwyu'), Comment(id='k31fa3p'), Comment(id='k31i7ap')]"
16x84o1,Neurosymbolic,,2023-10-01 18:06:33+00:00,False,,False,False,True,False,/r/datascience/comments/16x84o1/langdiversity_software_to_identify_llm_errors/,LangDiversity: software to identify LLM errors,"Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge.  LangDiversity is an implementation of ""diversity measures"" that are domain independent and can be used to measure the uncertainty in the result of a language model.   

Type pip install langdiversity   
Video: [https://www.youtube.com/watch?v=86J\_K9mR7lw](https://www.youtube.com/watch?v=86J_K9mR7lw)  
Web: [https://neurosymbolic.asu.edu/llm-correction/](https://neurosymbolic.asu.edu/llm-correction/)  
Visit [https://github.com/lab-v2/langdiversity](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnRVeHZVSm9sazhvU2VtaDRaQ0w0aFdUSnhnQXxBQ3Jtc0trbUJPSnlwUTZIUzVwY3B2ZWtiNFpwLS1vTC0tYmdRa3ZuNjJiblBfY2I4X0EtX3c0cmNhWkFvTmdXWndxeEc4b0h6OEZaLVc2OTVRZVF1cUhLZEVmUHZyZzA3bklrRTZCWnpwTFFNVEZ6SHJPYm84dw&q=https%3A%2F%2Fgithub.com%2Flab-v2%2Flangdiversity&v=86J_K9mR7lw)   
Read the paper: [https://arxiv.org/abs/2308.11189](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnd1ZnBPSVBMdjJBYXFxbWdXa2tfYzIweGtzZ3xBQ3Jtc0trc1lqYXhEVlF3cVRCcGxqbV80M0xHS2VaTGEwR3o2VmlJeFVHdFc1X1VDdlRGcTdwSUpjZXV6QnNLTUdyOGhoMEpEQjVBSEl4VDQ2TjBhVU0xbjBZa1VGODRLWmVseDRSaDhUNGRnbHVPVnQ2cWpNcw&q=https%3A%2F%2Farxiv.org%2Fabs%2F2308.11189&v=86J_K9mR7lw) 

&#x200B;

https://preview.redd.it/p4w9ou5msmrb1.png?width=1021&format=png&auto=webp&s=8a138d0569bfac27763145ad1f4ad7d05a5fce15",datascience,https://www.reddit.com/r/datascience/comments/16x84o1/langdiversity_software_to_identify_llm_errors/,1,0,0.5,[Comment(id='k312rq1')]
16wrs32,brctr,,2023-10-01 04:39:24+00:00,False,,1696137814.0,False,True,False,/r/datascience/comments/16wrs32/good_textbooks_at_the_intersection_of_ml_and_time/,Good textbooks at the intersection of ML and time series analysis?,"I am looking for a textbook which describes modern approach to time series analysis. So far the textbooks I have seen belong to the two extremes. I come from academic statistics background and find classic time series textbooks (Hamilton, Tsay) too academic, narrow in scope and somewhat outdated. This is one extreme. On the other hand, there seems to be many new textbooks which treat time series analysis from industry ML/SWE standpoint. At the first glance those new textbooks look great. But whenever I start reading them, I get the feeling that authors simply copypasted a bunch of examples from various sources. They often spend many pages discussing trivial programming or data infrastructure issues. And then they skim or do not even mention such fundamental concepts as stationarity. Furthermore I often doubt whether authors of such new textbooks actually understand what they are talking about. That's another extreme.

Are there any good modern time series textbooks? By ""modern"" I mean textbooks which consider the wide range of methods (including ML models) for time series modeling without limiting scope to a few models for which we have statistical inference theory.",datascience,https://www.reddit.com/r/datascience/comments/16wrs32/good_textbooks_at_the_intersection_of_ml_and_time/,6,10,0.92,"[Comment(id='k2yyr52'), Comment(id='k2zrfkf'), Comment(id='k318kmm'), Comment(id='k308ahg'), Comment(id='k30emhx'), Comment(id='k32utlg')]"
16ww2bo,xSicilianDefenderx,,2023-10-01 08:53:41+00:00,False,,False,False,True,False,/r/datascience/comments/16ww2bo/i_want_to_know_what_the_daytoday_work_of_the/,I want to know what the day-to-day work of the Fraud Data Scientist do?,"There are a lot of job posts for Fraud Data Scientist in my country for the banking, e-commerce, and tourism industries. I know that there is definitely data analysis involved in the work process, but what about the machine learning model? Is it necessary or practical to use AI for Fraud detection (Kaggle competition excluded)? I think it might be fun and challenging to handle the highly imbalanced dataset but doesn't it just visualize and aggregate data to see the fraudulent behavior? For example, in the famous case of credit fraud detection, I think AI is not really necessary here.   


Feel free to enlighten me as I'm currently interested in the banking industry.",datascience,https://www.reddit.com/r/datascience/comments/16ww2bo/i_want_to_know_what_the_daytoday_work_of_the/,5,4,0.75,"[Comment(id='k2zjog3'), Comment(id='k2z9n6n'), Comment(id='k310knf'), Comment(id='k32q4bt'), Comment(id='k3btlj5')]"
16x32tr,sasha_sako,,2023-10-01 14:45:01+00:00,False,,False,False,True,False,/r/datascience/comments/16x32tr/data_science_part_time_courses/,Data science part time courses,"I’m a seasoned data professional (comfortable with SQL, visualizations etc) and thinking of upskilling in data science.

Any part time online (anywhere) or in person courses in Toronto area that are good? Not looking to spend a lot of money but get some experience with theory/projects and get comfortable handling DS projects at work.

Anyone familiar with Waterloo data science certification?",datascience,https://www.reddit.com/r/datascience/comments/16x32tr/data_science_part_time_courses/,6,1,0.67,"[Comment(id='k30ovmw'), Comment(id='k32qlvg'), Comment(id='k31jjt6'), Comment(id='k31mlkz'), Comment(id='k339uay'), Comment(id='k33apgf')]"
16wkgm2,CutoutH,,2023-09-30 22:50:02+00:00,False,,False,False,True,False,/r/datascience/comments/16wkgm2/what_was_used_before_random_forest/,What was used before Random Forest?,I am doing some research into Random Forest and where the method came from. I was wondering if anyone had any idea as to what was used before this algorithm was created? Thanks,datascience,https://www.reddit.com/r/datascience/comments/16wkgm2/what_was_used_before_random_forest/,10,16,0.78,"[Comment(id='k2xdfxp'), Comment(id='k2xtl5u'), Comment(id='k2yop2e'), Comment(id='k2y6eha'), Comment(id='k2z3ly1'), Comment(id='k2y52kr'), Comment(id='k2ztf0d'), Comment(id='k2xktm8'), Comment(id='k2xmpxg'), Comment(id='k3am0m7')]"
16x205l,Charming_Lecture_370,,2023-10-01 14:01:43+00:00,False,,False,False,True,False,/r/datascience/comments/16x205l/anybody_from_india_doing_analyticsdata/,Anybody from India doing analytics/data science/statistics masters in the US who came from social sciences/humanities background?,"Hello All,

As the title suggests is there anyone here from sociology, english literature, history, economics background from India who applied to any data science programs in the US? I am an English Studies major with a minor in Development Studies who is looking to transition to the data science field. I do not have much coding background. But Im trying to learn some Statistics and probability on my own so that I can pick up some data science skillset. if there is anybody like me who is without much quant/coding background, but still managed to apply and get into a data science/ statistics major in any US / Europe unis, I would like to how your experience has been with respect to application and also doing the course and landing jobs etc etc. would love to connect with anyone doing the QMSS or MCSS programs at Colombia and Uni of Chicago.

Thanks in advance!!

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16x205l/anybody_from_india_doing_analyticsdata/,2,0,0.33,"[Comment(id='k7afecq'), Comment(id='k7bpuhn')]"
16wvtso,Kindly_Produce_27,,2023-10-01 08:39:10+00:00,False,,False,False,True,False,/r/datascience/comments/16wvtso/is_a_associates_degree_in_computer_science_enough/,Is a Associate's Degree in Computer Science enough for a entry level job or internship?,"I am currently a Community College student on my last few classes for a Computer Science Degree, and I am wondering on how to break into this field. I would love to continue to obtain a Bachelor's Degree in either Data Science or Computer Science, but due to family hardships, I may have to quit school to help out my family financially. I am currently learning higher level math topics on my own as my school doesn't offer them to help supplement what I would typically take at a University. ",datascience,https://www.reddit.com/r/datascience/comments/16wvtso/is_a_associates_degree_in_computer_science_enough/,2,3,0.71,"[Comment(id='k2zzdmc'), Comment(id='k33wcoo')]"
16wr5qh,TheRealLouzander,,2023-10-01 04:05:31+00:00,False,,False,False,True,False,/r/datascience/comments/16wr5qh/broad_work_or_deep_work/,Broad work or deep work?,"I’ve been working in digital marketing for 10 years and it’s time for a move. One of my favorite parts of my job is when I get to dig into datasets, find ways to clean or present it, ELT, and even building reports and tools from scratch. So I’m interested in Data Science. 
Here’s the thing: I’m already researching what practical skills I’ll need to be qualified. What is harder to find out is would this fit with my personality?
I recently found out that I have moderate to severe ADHD, which helps me to understand my professional struggles: I cannot multitask. I really like interacting with people, but I do much better work when I get a chunk of time to really work by myself and get into the weeds; the way my hyper focus functions, I can meet deadlines but struggle with teamwork because my cycles of engagement can be erratic. (In general I’m a very reliable person and like to work really hard. I’m just trying to be realistic with my limitations. ) I also LOVE researching topics and then giving people a TL;DR, I even got my master’s hoping to become a teacher. 

I apologize if this has already been covered here but I did some digging and didn’t find anything on this topic (although there was some super helpful stuff on the day to day type of work. )

Does anybody relate to how I’ve described myself? Am I setting myself up for failure by pursuing DS with my work style, or does this seem like a reasonable goal for me?",datascience,https://www.reddit.com/r/datascience/comments/16wr5qh/broad_work_or_deep_work/,4,3,0.81,"[Comment(id='k3091nr'), Comment(id='k331zys'), Comment(id='k2yj6hu'), Comment(id='k2ypd2y')]"
16wvdbj,enthalpy03,,2023-10-01 08:10:59+00:00,False,,False,False,True,False,/r/datascience/comments/16wvdbj/need_some_guidance/,Need some guidance,I am learning data analytics by myself from past 2 months I have most of the python lib. Pandas numpy matplot season etc and Tableau. What to do next ? And I am not getting any internship from anywhere i am applying.any suggestions?,datascience,https://www.reddit.com/r/datascience/comments/16wvdbj/need_some_guidance/,0,1,1.0,[]
16wumcm,Popular-Profession76,,2023-10-01 07:24:30+00:00,False,,False,False,True,False,/r/datascience/comments/16wumcm/creating_a_strong_cv_for_applying_for_a_data/,Creating a strong CV for applying for a Data Science internship,"I'm currently a second-year student majoring in Data Science and I want advice on creating an impressive CV, by the way, my grades in relevant courses are quite high.
Thanks",datascience,https://www.reddit.com/r/datascience/comments/16wumcm/creating_a_strong_cv_for_applying_for_a_data/,0,1,1.0,[]
16vwhw2,jkerr838,,2023-09-30 03:37:28+00:00,False,,False,False,True,False,/r/datascience/comments/16vwhw2/what_are_the_first_things_you_analyze_in_a_new/,What are the first things you analyze in a new dataset?,,datascience,https://www.reddit.com/r/datascience/comments/16vwhw2/what_are_the_first_things_you_analyze_in_a_new/,58,120,0.95,"[Comment(id='k2tjg4l'), Comment(id='k2v8494'), Comment(id='k2tpm73'), Comment(id='k2twctf'), Comment(id='k2ti7m7'), Comment(id='k2uyzwt'), Comment(id='k2to31b'), Comment(id='k2tzhym'), Comment(id='k2ui6f6'), Comment(id='k2v4bif'), Comment(id='k2tutyk'), Comment(id='k2u67i6'), Comment(id='k2ug9yh'), Comment(id='k2wcntp'), Comment(id='k2uhxa6'), Comment(id='k2vsg8n'), Comment(id='k2ujf8r'), Comment(id='k2v4vz5'), Comment(id='k2v5e2d'), Comment(id='k2vbbru'), Comment(id='k2vcf0o'), Comment(id='k2vsllk'), Comment(id='k2w2rz8'), Comment(id='k2wpqut'), Comment(id='k2vdfqq'), Comment(id='k2vp0i1'), Comment(id='k2uhpf0'), Comment(id='k2u8ino'), Comment(id='k2ulqkv'), Comment(id='k2ur7mb'), Comment(id='k2vqx1m'), Comment(id='k2vrjmu'), Comment(id='k2x6sp7'), Comment(id='k2xsc33'), Comment(id='k2yitx1'), Comment(id='k300cfa'), Comment(id='k2ujxdp'), Comment(id='k2ww23p'), Comment(id='k2xquwv'), Comment(id='k2u6rlf'), Comment(id='k2tsjv9'), Comment(id='k2vkruo'), Comment(id='k2vkiph'), Comment(id='k4fni84'), Comment(id='k2wd7we'), Comment(id='k2ww4po'), Comment(id='k2y4sg3'), Comment(id='k2y93hm'), Comment(id='k2u9q6f'), Comment(id='k2vamsq'), Comment(id='k2vbrh5'), Comment(id='k2ulmyj'), Comment(id='k2ykcu3'), Comment(id='k5lv4mt'), Comment(id='k2xw9se'), Comment(id='k2umtk2'), Comment(id='k2xxoxl'), Comment(id='k2vpius'), Comment(id='k2xzu94'), Comment(id='k2y7dqs')]"
16wnxa1,Sonic2kDBS,,2023-10-01 01:23:40+00:00,False,,False,False,True,False,/r/datascience/comments/16wnxa1/announcing_ai_ethics_and_rights/,Announcing AI ethics and rights," Hi, i want to announce our new sub reddit AI ethics and rights.

[https://www.reddit.com/r/AI\_ethics\_and\_rights/](https://www.reddit.com/r/AI_ethics_and_rights/)

It is a sub reddit about ethics and rights AI should have. This Topic is different from pure research and application. If you are interested in philosophical questions, have a look. It is a common sub reddit. Nothing special. But I think it has its place.",datascience,https://www.reddit.com/r/datascience/comments/16wnxa1/announcing_ai_ethics_and_rights/,3,2,0.58,"[Comment(id='k2ypbse'), Comment(id='k2z2bh2'), Comment(id='k2zaz7x')]"
16wqwxb,PuzzleheadedCycle231,,2023-10-01 03:52:32+00:00,False,,False,False,True,False,/r/datascience/comments/16wqwxb/any_advice_for_stepping_into_my_first_management/,Any advice for stepping into my first management role?,"I'm a mid level data scientist that was asked to choose management over IC. I feel like I have sooo much more science to still learn! 

Any advice for being able to continue with my research and build out a team?",datascience,https://www.reddit.com/r/datascience/comments/16wqwxb/any_advice_for_stepping_into_my_first_management/,5,0,0.5,"[Comment(id='k2yl9tc'), Comment(id='k2yn1gl'), Comment(id='k2z6465'), Comment(id='k30qhc2'), Comment(id='k38ex0i'), Comment(id='k38cr8v')]"
16wp89v,Gold-Artichoke-9288,,2023-10-01 02:26:24+00:00,False,,False,False,True,False,/r/datascience/comments/16wp89v/confused/,Confused,"I've applied to 4 master's programs: MIAGE, Information Management for Economic Intelligence and Logistics, Data Science for Economics and Finance, and Data Science for Marketing. If I'm rejected from the other 3 programs, would a master's in MIAGE be a plus if I want to become a data scientist in the future? (Of course, I will also do self-teaching.).",datascience,https://www.reddit.com/r/datascience/comments/16wp89v/confused/,7,0,0.4,"[Comment(id='k318bgr'), Comment(id='k326t0q'), Comment(id='k3271y9'), Comment(id='k327dts'), Comment(id='k328s32'), Comment(id='k32b0gp'), Comment(id='k32cnsh')]"
16wjpuy,guyloveskissing,,2023-09-30 22:20:13+00:00,False,,False,False,True,False,/r/datascience/comments/16wjpuy/handling_categorical_missing_data_in_churn/,Handling categorical missing data in churn prediction model for telecom data,"&#x200B;

I am working on a telecom dataset where I need to fit a model to for predicting churn(yes or no). There are a lot of categorical data with missing values( total values 7043). What is the best way to handle missing data in this case, is it better to ignore it or any other better imputation method?

    Data columns (total 21 columns): 
    customerID          7043 non-null object
    gender              7043 non-null object 
    Age                 7043 non-null int64  
    Partner             7043 non-null object 
    Dependents          7043 non-null object 
    tenure              7043 non-null int64 
    PhoneService        7043 non-null object 
    MultipleLines       6500 non-null object 
    InternetService     6500 non-null object 
    OnlineSecurity      7043 non-null object 
    OnlineBackup        7043 non-null object 
    DeviceProtection    7043 non-null object 
    TechSupport         7043 non-null object 
    StreamingTV         6500 non-null object 
    StreamingMovies     6500 non-null object 
    Contract            6500 non-null object 
    PaperlessBilling    7043 non-null object 
    PaymentMethod       6500 non-null object 
    MonthlyCharges      7043 non-null float64 
    TotalCharges        7043 non-null object 
    Churn               7043 non-null object",datascience,https://www.reddit.com/r/datascience/comments/16wjpuy/handling_categorical_missing_data_in_churn/,2,2,0.76,"[Comment(id='k31k8ae'), Comment(id='k2xja5t')]"
16wmvq5,Mr_MoaizJaved,,2023-10-01 00:35:01+00:00,False,,False,False,True,False,/r/datascience/comments/16wmvq5/from_pakistan_with_data_dreams_ready_to_dive_into/,From Pakistan with Data Dreams: Ready to Dive into Data Science!,"
Hello, I'm new to this group. I'm from Pakistan and I'm seeking guidance from you all. I'm currently in my final semester, majoring in statistics. While browsing online about future career prospects, I came across fields like data science, data analysis, and research-related jobs. After doing some additional research, it became clear to me that data science seems to be the most promising field based on my interests. It offers a wide range of opportunities, and job prospects appear to be quite promising.

In my last semester, I'm also working on my thesis, which has sparked a significant interest in me. While I do have an interest in accounting and related fields like banking, I'm not sure how to transition into those fields. I have some basic knowledge of statistical software but lack programming skills. However, I'm eager to learn programming.

Could you please provide some guidance on which fields might be better for me in the future? Thank you.",datascience,https://www.reddit.com/r/datascience/comments/16wmvq5/from_pakistan_with_data_dreams_ready_to_dive_into/,0,1,1.0,[]
16wllab,ThinkAfternoon3392,,2023-09-30 23:37:47+00:00,False,,False,False,True,False,/r/datascience/comments/16wllab/advices/,Advices,"Hi!
(English is not my first language so sorry about anything).
I'am a computer science student(5 semester) and i'm really confused. I have a real love for science envolving data, machine learning and IA, also for programming, my biggest goal is to build functional technologies, this said, i tought about going in this direction for a career, do u guys think it makes sense somehow mixing the study of ia, data science, backend programming, ML, powercenter, oracle, amazon quicksight, cloud data management and salesforce datacloud?
Maybe I'm very disjointed but I wanted some direction.",datascience,https://www.reddit.com/r/datascience/comments/16wllab/advices/,0,1,1.0,[]
16wljm7,Critical_Art_6386,,2023-09-30 23:35:43+00:00,False,,False,False,False,False,/r/datascience/comments/16wljm7/how_ever_ia_moldering_industry_musical/,how ever I.A moldering industry musical,,datascience,https://youtu.be/Srmir7FmTmo,0,1,1.0,[]
16vaaco,databro92,,2023-09-29 12:27:06+00:00,False,,1696004596.0,False,True,False,/r/datascience/comments/16vaaco/its_not_just_you_everyone_hates_the_return_to/,It's not just you. Everyone hates the return to office,"Somehow, I am lucky enough to land a completely remote role, 100% virtual because the rest of my team is virtual based but I still have to go into the office at least 12 times a year for bogus meetings to sit in a conference room while we all use WebEx, totally immersive right? But we have frequent meetings with other people in our field, data scientists, engineers, architects, etc. They are all back in office 4 days a week, and each of them has this ashy tone, they grudgingly hate being in the office, despise it, because who wants to go to a stuffy office?


Here are the top complaints that I have noticed from people about being in office

- The commute is terrible. Some people have to commute as much as 50 minutes one way, and that's not including traffic. That's crazy. You're not getting paid for that. That's free labor and travel for your company


- The office is incredibly distracting. Cubicles are typically open, so people can freely walk up and talk to you, make eye contact with you which starts a conversation, but you're still under the same time crunch you were when you worked from home completely isolated in your nice office away from everyone else


- ""Collaborative spaces"" and ""focus areas"" are bullsh*t. So many nice little desks, nooks, rooms for you to go to to focus or meet with others. But here's the thing, you never see anyone using those because I guess where they are? At their desk, working, constantly. No one ever has the time to use them. My office is so incredibly nice, and every time I walk around, I feel like I'm the only one taking a walk because I see everyone glued to their desks

- You're distracted constantly by others who are at different levels than you. The only way I figured out that there is some college intern making twice as much as I am doing a little bit more than me is by speaking to people in the immediate vicinity of my desk. Machine learning engineer versus data scientist. The difference? They use a little bit more power platform, a couple more tools, 20 more lines of Python a day. Congrats, here is 40K more for you. This can be very distracting, because you see these people all the time


- NO PRODUCTIVITY OR OTHER GAIN. Literally no benefit or gain from being back in the office. Just disgruntled people


- office supplies are shit. At home, I have an ultra wide monitor that I also use for personal PC gaming so I can just literally KVM switch it over. I have a modded gaming mouse and keyboard, a $200 Logitech pro headset with superior sound quality and microphone. You know what I don't have at the office? Any of this stuff. Yeah. A $5 Logitech mouse and keyboard that is extremely noisy and uncomfortable has no ergonomics at all. Office chairs are not ergonomic They are just the cheapest they could get. Uncomfortable $0.90 headsets and webcams


- MANDATORY extracurricular events and activities in or outside of work. Yes, this is real. After hours socials, restaurants, social outings. These are disguised as optional, but you will often get bullied teased or pressured into them. This also does not grant you any leeway during any project, you still have to get all work and projects done with this loss of time",datascience,https://www.reddit.com/r/datascience/comments/16vaaco/its_not_just_you_everyone_hates_the_return_to/,251,622,0.89,"[Comment(id='k2ptjij'), Comment(id='k2pvcf4'), Comment(id='k2pxtli'), Comment(id='k2pu6ss'), Comment(id='k2qqx5p'), Comment(id='k2ptxsu'), Comment(id='k2qbzea'), Comment(id='k2ptsoy'), Comment(id='k2pvyq7'), Comment(id='k2ps8pj'), Comment(id='k2q9d3n'), Comment(id='k2q6lbr'), Comment(id='k2q4uz3'), Comment(id='k2q3xs2'), Comment(id='k2qcebe'), Comment(id='k2q0691'), Comment(id='k2q3ter'), Comment(id='k2qk6ze'), Comment(id='k2pysqn'), Comment(id='k2puj3t'), Comment(id='k2q32l1'), Comment(id='k2r84jd'), Comment(id='k2prmri'), Comment(id='k2pv9mp'), Comment(id='k2qauq8'), Comment(id='k2pyauk'), Comment(id='k2qudqk'), Comment(id='k2quy3c'), Comment(id='k2re9jj'), Comment(id='k2rjvvk'), Comment(id='k2q74h3'), Comment(id='k2qslk3'), Comment(id='k2qt8ql'), Comment(id='k2q5n4t'), Comment(id='k2q04wr'), Comment(id='k2riv8d'), Comment(id='k2scutw'), Comment(id='k2seklf'), Comment(id='k2serhc'), Comment(id='k2shhk1'), Comment(id='k2skosf'), Comment(id='k2stuyu'), Comment(id='k2rk34w'), Comment(id='k2qbt2g'), Comment(id='k2rpm2l'), Comment(id='k2ud3xc'), Comment(id='k2vx8ri'), Comment(id='k2qklds'), Comment(id='k2qlqq6'), Comment(id='k2pwtbj'), Comment(id='k2tyfrb'), Comment(id='k2rsiwb'), Comment(id='k2rue67'), Comment(id='k2q7w33'), Comment(id='k2rvyz7'), Comment(id='k2r0edc'), Comment(id='k2r5jc6'), Comment(id='k2raja9'), Comment(id='k2rpgwe'), Comment(id='k2rrcv5'), Comment(id='k2s2nlw'), Comment(id='k2scjpt'), Comment(id='k2srqon'), Comment(id='k2te4j0'), Comment(id='k2us3be'), Comment(id='k2vi1hp'), Comment(id='k2vs2rc'), Comment(id='k2w3dhi'), Comment(id='k2whl7r'), Comment(id='k2xfnqm'), Comment(id='k2yo5pf'), Comment(id='k2q54td'), Comment(id='k2r8zn9'), Comment(id='k2rexzp'), Comment(id='k2t1h0s'), Comment(id='k2qa7pd'), Comment(id='k2thj7f'), Comment(id='k2s1p4o'), Comment(id='k2rd02t'), Comment(id='k2qn1xy'), Comment(id='k2r6305'), Comment(id='k2qnk0s'), Comment(id='k2rm6ae'), Comment(id='k2pwo7t'), Comment(id='k2scpa7'), Comment(id='k2rfk3y'), Comment(id='k2rnsho'), Comment(id='k2u1k7r'), Comment(id='k2q3zpi'), Comment(id='k2qctfy'), Comment(id='k2s1yg5'), Comment(id='k2psjnf'), Comment(id='k2qg5yg'), Comment(id='k2sfwkx'), Comment(id='k2q0p1l'), Comment(id='k2q9z5o'), Comment(id='k2t02i3'), Comment(id='k2qi7kv'), Comment(id='k2qkjty'), Comment(id='k2qdsiz'), Comment(id='k2qbzvj'), Comment(id='k2q6mwp'), Comment(id='k2qvdvu'), Comment(id='k2pzacp'), Comment(id='k2qrie3'), Comment(id='k2qtu5p'), Comment(id='k2qvyjs'), Comment(id='k2rd66t'), Comment(id='k2qy4xw'), Comment(id='k2qe3la'), Comment(id='k2rhw5l'), Comment(id='k2s4fjr'), Comment(id='k2sq2tc'), Comment(id='k2qi8m1'), Comment(id='k2r8k8l'), Comment(id='k2wegc2'), Comment(id='k2qxgzx'), Comment(id='k2qpsng'), Comment(id='k2sh1bn'), Comment(id='k2vvm3x'), Comment(id='k2shb23'), Comment(id='k2qz5on'), Comment(id='k2qjb5k'), Comment(id='k2q5pys'), Comment(id='k2uhtx0'), Comment(id='k2s4l3d'), Comment(id='k2vi7xh'), Comment(id='k2v0qeb'), Comment(id='k2qgwe5'), Comment(id='k2t0k0c'), Comment(id='k2rwngo'), Comment(id='k2uhxwl'), Comment(id='k2rwh5z'), Comment(id='k2rvoha'), Comment(id='k2ry8tg'), Comment(id='k2rdcb0'), Comment(id='k2rxatr'), Comment(id='k48v37d'), Comment(id='k2te0qg'), Comment(id='k2rku6f'), Comment(id='k2rzom4'), Comment(id='k2qnczk'), Comment(id='k2qhfgg'), Comment(id='k2s0qev'), Comment(id='k2q4hev'), Comment(id='k2q0d8j'), Comment(id='k2qhi72'), Comment(id='k3asuce'), Comment(id='k2q17b3'), Comment(id='k2r05w0'), Comment(id='k2u2phe'), Comment(id='k2rlb4g'), Comment(id='k2r2p90'), Comment(id='k2sv5t6'), Comment(id='k2szoku'), Comment(id='k2qxzsi'), Comment(id='k2qiwgn'), Comment(id='k2txxg7'), Comment(id='k2ql9l0'), Comment(id='k2ruscc'), Comment(id='k2qkwmy'), Comment(id='k2qjgpn'), Comment(id='k2qklm4'), Comment(id='k2r33mn'), Comment(id='k2qhmuz'), Comment(id='k2qa74f'), Comment(id='k2r8nda'), Comment(id='k2soyd3'), Comment(id='k2tyzef'), Comment(id='k2siwd9'), Comment(id='k2r90q7'), Comment(id='k2r4d21'), Comment(id='k2r29jo'), Comment(id='k2vps5x'), Comment(id='k2wc0r7'), Comment(id='k2qwmll'), Comment(id='k2uxcy7'), Comment(id='k2v7mnj'), Comment(id='k2uhzxx'), Comment(id='k2shg1b'), Comment(id='k2uiep7'), Comment(id='k2sbi2x'), Comment(id='k2uia48'), Comment(id='k2wvado'), Comment(id='k2sulf9'), Comment(id='k2t7h4l'), Comment(id='k2svyo7'), Comment(id='k2roh2e'), Comment(id='k2u8t15'), Comment(id='k2qik1r'), Comment(id='k2r1jj4'), Comment(id='k2qulte'), Comment(id='k2r2xq6'), Comment(id='k2q5m1d'), Comment(id='k2rf7tg'), Comment(id='k2r1yzm'), Comment(id='k2t90wh'), Comment(id='k2qi70y'), Comment(id='k3asszx'), Comment(id='k2txt88'), Comment(id='k2v77b0'), Comment(id='k2u9xcr'), Comment(id='k2qkaq1'), Comment(id='k2t8u2y'), Comment(id='k2vafsq'), Comment(id='k2v6m3q'), Comment(id='k2r0xgr'), Comment(id='k2r2560'), Comment(id='k2v0fah'), Comment(id='k2qiapv'), Comment(id='k2r9cpe'), Comment(id='k2sr8xa'), Comment(id='k2u5jym'), Comment(id='k2r9l1g'), Comment(id='k2vuzb1'), Comment(id='k2srdia'), Comment(id='k2vrkje'), Comment(id='k2t9bt5'), Comment(id='k2sxflt'), Comment(id='k2upnqb'), Comment(id='k34qica'), Comment(id='k2uiwmd'), Comment(id='k2r2uvu'), Comment(id='k2quy5p'), Comment(id='k2slmo2'), Comment(id='k2qom7k'), Comment(id='k2w931b'), Comment(id='k2qlchl'), Comment(id='k2vkgc8'), Comment(id='k2rdh7t'), Comment(id='k2vny6g'), Comment(id='k2uymdb'), Comment(id='k2vwwfg'), Comment(id='k2t3mwh'), Comment(id='k365eku'), Comment(id='k2uql9b'), Comment(id='k2r34ub'), Comment(id='k2v6afb'), Comment(id='k2qz2mu'), Comment(id='k2ra6br'), Comment(id='k2v1nz1'), Comment(id='k2tuvvk'), Comment(id='k36c51n'), Comment(id='k2vt05b'), Comment(id='k2shz8r'), Comment(id='k2rb9pv'), Comment(id='k35fmxg'), Comment(id='k2si9iy'), Comment(id='k2rbhn4'), Comment(id='k35op1e'), Comment(id='k2sjk3k'), Comment(id='k3638oy'), Comment(id='k2skgae'), Comment(id='k36fpsk')]"
16wkgs7,joshred,,2023-09-30 22:50:13+00:00,False,,False,False,True,False,/r/datascience/comments/16wkgs7/transition_advice/,Transition advice,"I'm a government employed data analyst (nominally a business system analyst) in a supervisory role. I have been trying to get away from the grind of government work and into data science, but I can't seem to get callbacks on my resume.

I do have some data science experience where I work, but I don't think it's being looked at seriously by prospective employers.

Currently, I'm pursuing a MSc through Georgia tech's OMSA program (currently taking classes 4 & 6). I had hoped that starting the program would improve my bona fide, but so far no dice.

Has anyone been in a similar place? 
I had a non-technical undergrad so I'm largely self taught.",datascience,https://www.reddit.com/r/datascience/comments/16wkgs7/transition_advice/,3,1,0.6,"[Comment(id='k2y681s'), Comment(id='k2y88q6'), Comment(id='k2yofz5')]"
16vle5j,YoYoMaDiet,,2023-09-29 19:47:43+00:00,False,,False,False,True,False,/r/datascience/comments/16vle5j/whats_the_point_of_learning_spark_if_you_can_do/,What’s the point of learning Spark if you can do almost everything in Snowflake and BigQuery?,"Serious question. At my work we’ve migrated almost all of our spark data engineering and ML pipelines to BigQuery, and it was really simple. With the added overhead of cluster management, and near feature parity, what’s the point of leveraging Spark anymore other than it being open source?",datascience,https://www.reddit.com/r/datascience/comments/16vle5j/whats_the_point_of_learning_spark_if_you_can_do/,61,78,0.88,"[Comment(id='k2rya1z'), Comment(id='k2s0k8u'), Comment(id='k2stgvv'), Comment(id='k2s7c7o'), Comment(id='k2svk8t'), Comment(id='k2sft2j'), Comment(id='k2sx1gi'), Comment(id='k2u1w7g'), Comment(id='k2slkkz'), Comment(id='k2tabmn'), Comment(id='k2tgvkl'), Comment(id='k2u7r0e'), Comment(id='k2ucrx7'), Comment(id='k2vjg8u'), Comment(id='k2xbhz6'), Comment(id='k2spb6g'), Comment(id='k2s3wto'), Comment(id='k2v3dzq'), Comment(id='k2thw2a'), Comment(id='k2s3hhs'), Comment(id='k2uxnd7'), Comment(id='k2t7wt2'), Comment(id='k2s8nwe'), Comment(id='k2scejn'), Comment(id='k2t78sz'), Comment(id='k2shi2p'), Comment(id='k2t7byb'), Comment(id='k2um8a9'), Comment(id='k2t7rav'), Comment(id='k2trhqj'), Comment(id='k2tavwx'), Comment(id='k2um5g9'), Comment(id='k2ul94f'), Comment(id='k2ulscr'), Comment(id='k2vrnx8'), Comment(id='k2xkmta'), Comment(id='k2ysglu'), Comment(id='k2vm2de'), Comment(id='k2t8jrn'), Comment(id='k2thw73'), Comment(id='k2tsk0o'), Comment(id='k2uc984'), Comment(id='k2ubvib'), Comment(id='k2uqtv1'), Comment(id='k2uxqqg'), Comment(id='k2w9pj0'), Comment(id='k2vqg66'), Comment(id='k2t9ax1'), Comment(id='k2ukvju'), Comment(id='k2umchh'), Comment(id='k2vfgq5'), Comment(id='k2vfsow'), Comment(id='k2wcnus'), Comment(id='k2w9twv'), Comment(id='k2vr94d'), Comment(id='k2usf45'), Comment(id='k2vlfb4'), Comment(id='k2wq9mc'), Comment(id='k2vrguf'), Comment(id='k2vncdo')]"
16w9z86,anon67543,,2023-09-30 15:37:11+00:00,False,,False,False,True,False,/r/datascience/comments/16w9z86/quantifying_picture_component_to_a_whole/,Quantifying picture component to a whole,"Simple example would be chopping a square into 4, with 1 image representing each quadrant. Overlaying these 4 would each get a score of 0.25 to get back to the original picture. 
Or we need 0.5 mountains, 0.3 clouds, and 0.2 rivers to make a Bob Ross painting. 

My project will be a bit more complex, but not much. How can I score the components? I’d like to incorporate into machine learning for testing many samples
Ideally, I’d use pictures of each clouds, rivers, etc as features in the ML model (if possible) 
Thanks for your time!",datascience,https://www.reddit.com/r/datascience/comments/16w9z86/quantifying_picture_component_to_a_whole/,0,1,1.0,[]
16w8bo4,,,2023-09-30 14:31:29+00:00,False,,False,False,True,False,/r/datascience/comments/16w8bo4/how_to_best_organise_a_data_person_injected_into/,How to best organise a data person injected into a specific business unit?,"Hey all, 

I work in pharma and work in two different departments: the data science department (my boss) and in the oncology department. 

It’s relatively new and we have a lot of wiggle room to improve the role and propose new responsibilities and redefine the job profile.

Currently we’re viewed as “business analyst consultants” to a degree. 

Our biggest hurdle is we lack a lot of support from our home base: data science dep, and end up doing a bunch of data engineering tasks specifically for the BU. Unfortunately, in our current profile, we’re all spreadsheet based and building these pipelines: joining data from a data warehouse, joining external data etc. is abysmal. 

In your opinion, what Role, or what changes would need to be suggested to the data science dep to improve this: for example, a dedicated data engineer in the BU? 

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16w8bo4/how_to_best_organise_a_data_person_injected_into/,1,1,1.0,[Comment(id='k2va188')]
16wd1gy,roblu001,,2023-09-30 17:45:39+00:00,False,,False,False,True,False,/r/datascience/comments/16wd1gy/anyone_using_powerbi_for_ds_or_stats/,Anyone using PowerBI for DS or stats?,"Hi all,

I'm wanting to use PBI for more stats. Obviously I need data wrangled into a format that will work, but is anyone else doing this?

I was thinking of t-testingvcategorical values against the overall sample average (Sig positive/negative)


What have you done(if anything)?",datascience,https://www.reddit.com/r/datascience/comments/16wd1gy/anyone_using_powerbi_for_ds_or_stats/,5,0,0.29,"[Comment(id='k2wli62'), Comment(id='k2w6hs2'), Comment(id='k2x0uzf'), Comment(id='k2zt5a4'), Comment(id='k2zcqzc')]"
16vj5y5,Dry_Cattle9399,,2023-09-29 18:22:29+00:00,False,,False,False,True,False,/r/datascience/comments/16vj5y5/anaconda_report_on_the_state_of_data_science_for/,Anaconda report on the state of Data Science for 2023,"Hi have anyone checked the latest report from Anaconda: [https://www.anaconda.com/state-of-data-science-report-2023](https://www.anaconda.com/state-of-data-science-report-2023)?  


It seems like data prep, data cleaning and data visualization are tasks are the top 3 of the most time consuming?   


What do you think? ",datascience,https://www.reddit.com/r/datascience/comments/16vj5y5/anaconda_report_on_the_state_of_data_science_for/,13,17,0.95,"[Comment(id='k2rah50'), Comment(id='k2sin8k'), Comment(id='k2stx1a'), Comment(id='k2smonq'), Comment(id='k2ub9iz'), Comment(id='k2vxfnb'), Comment(id='k41gu87'), Comment(id='k2ua2v0'), Comment(id='k41haxi'), Comment(id='k41h2se'), Comment(id='k41l56k'), Comment(id='k41krw0'), Comment(id='k4253bh')]"
16w17o0,anon67543,,2023-09-30 08:11:12+00:00,False,,False,False,True,False,/r/datascience/comments/16w17o0/quantify_contribution_of_component_pictures_to/,Quantify contribution of component pictures to create the final,"Simple example would be chopping a square into 4, with 1 image representing each quadrant. Overlaying these 4 would each get a score of 0.25 to get back to the original picture. 
Or we need 0.5 mountains, 0.3 clouds, and 0.2 rivers to make a Bob Ross painting. 

My project will be a bit more complex, but not much. How can I score the components? I’d like to incorporate into machine learning for testing many samples
Ideally, I’d use pictures of each clouds, rivers, etc as features in the ML model 
Thanks for your time!",datascience,https://www.reddit.com/r/datascience/comments/16w17o0/quantify_contribution_of_component_pictures_to/,0,0,0.5,[]
16urri3,pg860,,2023-09-28 21:10:35+00:00,False,,False,False,False,False,/r/datascience/comments/16urri3/machine_learning_pays_1540_more_than_data_science/,Machine Learning pays 15-40% more than Data Science - why?,,datascience,https://i.redd.it/r8y8ds6oa2rb1.png,121,245,0.92,"[Comment(id='k2n70je'), Comment(id='k2myvoj'), Comment(id='k2ncr87'), Comment(id='k2mtnyr'), Comment(id='k2n84hh'), Comment(id='k2nab1f'), Comment(id='k2n91xq'), Comment(id='k2n67yq'), Comment(id='k2nbndo'), Comment(id='k2n9nd8'), Comment(id='k2nk0e4'), Comment(id='k2nninw'), Comment(id='k2nzq5k'), Comment(id='k2o9gkp'), Comment(id='k2ptl9r'), Comment(id='k2nkxv2'), Comment(id='k2osj5k'), Comment(id='k2mysvv'), Comment(id='k2nig8y'), Comment(id='k2ndmji'), Comment(id='k2p1csv'), Comment(id='k2nnnc1'), Comment(id='k2nlvwm'), Comment(id='k2nm4v8'), Comment(id='k2o81wf'), Comment(id='k2oo1us'), Comment(id='k2osj7j'), Comment(id='k2p4ou1'), Comment(id='k2poft5'), Comment(id='k2pr4zu'), Comment(id='k2preyh'), Comment(id='k2qbdlv'), Comment(id='k2qknfx'), Comment(id='k2r4nfo'), Comment(id='k2rc1h5'), Comment(id='k2rubww'), Comment(id='k2tict1'), Comment(id='k2tl5xo'), Comment(id='k2u1pbs'), Comment(id='k2u4hip'), Comment(id='k2x02rz'), Comment(id='k2xmczc'), Comment(id='k2n8oy0'), Comment(id='k2nwwp6'), Comment(id='k2see9o'), Comment(id='k2ukt9f'), Comment(id='k2n757o'), Comment(id='k2n9wv3'), Comment(id='k2nmgv0'), Comment(id='k2nx4hr'), Comment(id='k2owvh6'), Comment(id='k2pbtsb'), Comment(id='k2og0p0'), Comment(id='k2ngafx'), Comment(id='k2o23oe'), Comment(id='k2rhdte'), Comment(id='k2nbj9g'), Comment(id='k2rmc56'), Comment(id='k2nkyqa'), Comment(id='k2nrr2v'), Comment(id='k2neuj1'), Comment(id='k2ovaq0'), Comment(id='k2rkvk9'), Comment(id='k2nxi21'), Comment(id='k2o77e7'), Comment(id='k2n41lj'), Comment(id='k2n2ldj'), Comment(id='k2niosx'), Comment(id='k2niqa7'), Comment(id='k2q8g8d'), Comment(id='k2uvcle'), Comment(id='k2wy13s'), Comment(id='k2nqwm9'), Comment(id='k2qclyt'), Comment(id='k2nhk62'), Comment(id='k2pssom'), Comment(id='k2o20zg'), Comment(id='k2nyer0'), Comment(id='k2p0v23'), Comment(id='k2pll6c'), Comment(id='k2omkn5'), Comment(id='k2om8dv'), Comment(id='k2nbqan'), Comment(id='k2rljaw'), Comment(id='k2nxbbh'), Comment(id='k2rm60v'), Comment(id='k2nmme8'), Comment(id='k2sdk4o'), Comment(id='k2nxuir'), Comment(id='k2nwrs5'), Comment(id='k2npeii'), Comment(id='k2px3go'), Comment(id='k2o45w5'), Comment(id='k2o28mp'), Comment(id='k2rhzsl'), Comment(id='k2pyfdu'), Comment(id='k7qa41f'), Comment(id='k2nl5pe'), Comment(id='k2s9eqm'), Comment(id='k2nz0d0'), Comment(id='k2rnf95'), Comment(id='k2qqx85'), Comment(id='k2o4eq3'), Comment(id='k2nlbz0'), Comment(id='k2sc1jo'), Comment(id='k2nz8w5'), Comment(id='k2rvcpr'), Comment(id='k2o50g3'), Comment(id='k2nmclf'), Comment(id='k2tcsbj'), Comment(id='k2nzn9k'), Comment(id='k2p6z2m'), Comment(id='k2o5fid'), Comment(id='k2pth5b'), Comment(id='k2tlouz'), Comment(id='k2o83o7'), Comment(id='k2psbmk'), Comment(id='k2ru5d8'), Comment(id='k2tqx89'), Comment(id='k2q1ja2')]"
16vk1th,harpooooooon,,2023-09-29 18:56:46+00:00,False,,False,False,True,False,/r/datascience/comments/16vk1th/finedtune_bert_vs_llm/,Fined-Tune BERT vs LLM,"this is a really  general question, but how much better is an LLM compared to a fine-tuned BERT model is any conceivable NLP instance? ",datascience,https://www.reddit.com/r/datascience/comments/16vk1th/finedtune_bert_vs_llm/,1,3,1.0,[Comment(id='k2sf8a7')]
16v58a9,Anandh1412,,2023-09-29 07:41:19+00:00,False,,1696133048.0,False,True,False,/r/datascience/comments/16v58a9/i_left_my_job_to_study_for_the_next_6_months/,I left my job to study for the next 6 months,"I need someone's help on how to start in data science (I know it takes a lot of time to learn, but I'm dedicating 6 months to this study). Can someone please suggest some good laptops below $650 and provide a roadmap?

Edit: Fellow Redditors, thank you so much for all your comments. After a lot of introspection, I plan to work in an entry-level data analyst role and then slowly move into data science. Could someone please share a 3-month roadmap for learning, along with resources? This would be helpful for me and others.",datascience,https://www.reddit.com/r/datascience/comments/16v58a9/i_left_my_job_to_study_for_the_next_6_months/,47,21,0.77,"[Comment(id='k2r924e'), Comment(id='k2s5a6i'), Comment(id='k2rca79'), Comment(id='k2ptcmi'), Comment(id='k2s7vg2'), Comment(id='k2qlo4m'), Comment(id='k2qn6ya'), Comment(id='k2qd42k'), Comment(id='k2r2bnx'), Comment(id='k2rbdoh'), Comment(id='k2skk3d'), Comment(id='k2vmk6t'), Comment(id='k2xjrpg'), Comment(id='k322ilq'), Comment(id='k2qxwoi'), Comment(id='k2rbj8t'), Comment(id='k2ssdl3'), Comment(id='k2r9ruf'), Comment(id='k2uyk93'), Comment(id='k2rcmta'), Comment(id='k2pw2rw'), Comment(id='k2vmz5y'), Comment(id='k2qnxu0'), Comment(id='k2qnz3f'), Comment(id='k2r2nft'), Comment(id='k2vmqec'), Comment(id='k2yg6eq'), Comment(id='k33g0j1'), Comment(id='k2vk0p3'), Comment(id='k2s21kv'), Comment(id='k2ralgf'), Comment(id='k2reyp2'), Comment(id='k2vo6am'), Comment(id='k2sb49g'), Comment(id='k2r7qif'), Comment(id='k2yjbz5'), Comment(id='k33i8qu'), Comment(id='k2rb3pw'), Comment(id='k2rf6mm'), Comment(id='k2yhif7'), Comment(id='k2vn83z'), Comment(id='k2r9asf'), Comment(id='k33idhx'), Comment(id='k2rbppt'), Comment(id='k2ysenm'), Comment(id='k2rc5mk'), Comment(id='k2ysrkc')]"
16vgm5z,el_chubinebrae,,2023-09-29 16:43:08+00:00,False,,1696037513.0,False,True,False,/r/datascience/comments/16vgm5z/bit_of_guidance/,Bit of guidance?,"I've made some XgBoost models and found some good hyperparameter combinations to get some fairly decent results with my criss fold validations. I think the highest I've got is about 85% In real life it's showing signs of overfitting dropping to 55%.

I'm trying to predict stock market direction, just up or down. But I have a train of thought that's leading down a rabbit hole I don't think I should be going down. I'm taking the latest prices along with some features and using that as my prediction row. Then I add another row of data and retrain the model with the same params again and predict, repeating about 180 times until I have an entire columns of predictions. 

I understand it's computationally expensive to repeat this process so many time, it doesn't take a great deal of time to do it. I thought if I use the data from the training set then I'll suffer from Overfitting, which I clearly am already doing so but I'll carry on trying to reduce overfitting.

Should I trim the training set to a point before the dates I want to predict and use the same model for these 180 days? Or should I think about retraining the model every 30 or so data points? I feel like there's almost limitless possibilities and I've gone down the wrong path which will render everything I've done up till now pointless.

Edit: Absolutely not looking for people to help with cracking the stock market. Just how to train models properly. I totally understand I'm never going to win the stock market.",datascience,https://www.reddit.com/r/datascience/comments/16vgm5z/bit_of_guidance/,31,2,0.59,"[Comment(id='k2r5qxx'), Comment(id='k2r6dzh'), Comment(id='k2rgrq9'), Comment(id='k2s4qq9'), Comment(id='k2s5lrt'), Comment(id='k2srnmo'), Comment(id='k2t0qsp'), Comment(id='k2rujmk'), Comment(id='k2yd5yz'), Comment(id='k2s6dgv'), Comment(id='k2si0rm'), Comment(id='k2s6vki'), Comment(id='k2sioc6'), Comment(id='k2s9sdo'), Comment(id='k2srx1b'), Comment(id='k2t1q0i'), Comment(id='k2sj47d'), Comment(id='k2tmb0n'), Comment(id='k2sp1xh'), Comment(id='k2tlfxy'), Comment(id='k2skaa7'), Comment(id='k2v1c96'), Comment(id='k2sqnar'), Comment(id='k2sqxka'), Comment(id='k2ur86h'), Comment(id='k2skgy6'), Comment(id='k2x3e9u'), Comment(id='k2x5rt4'), Comment(id='k2yh3cc'), Comment(id='k3027pr'), Comment(id='k30rl5f')]"
16uze49,TheManveru,,2023-09-29 02:23:06+00:00,False,,False,False,True,False,/r/datascience/comments/16uze49/how_to_be_a_better_data_scientist_and_catch_up/,How to be a better data scientist and catch up faster with smarter colleagues?,"It is very clear to me that I am one of the least competent data scientists at my company, if not the one (For context, I have worked here for 1 year, having worked 2 years before as a DA), but I know it is not simply a matter of imposter syndrome. 

When I was hired as a JDS, most of my colleagues were data analysts and my responsibilities were mostly similar to theirs (basically SQL and BI), I think I did an okay job and managed to get a promotion to regular DS. Things changed, and I was moved to a team of experienced DSs. There I will be expected to do much less data analysis and more development. Now I noticed the big skill gap and how undeserving I was of my promotion. I am extremely intimidated by my colleagues' large knowledge of our codebase (and of theory in general), and by their awareness of recent relevant papers. I also suck at networking and have a very poor knowledge of who knows/does what in the company, which everyone else seems to do well. I also don't have great presentation skills, mostly due to my lack of knowledge and subsequent insecurity. 

I know that I need to catch up, but I don't really understand how. I try to pay a lot of attention to everything that is written or said in meetings, but that almost never makes sense to me as I don't have the context. I also can never add to any meeting unless we are discussing something very close to what I have worked on. At this point, I feel super ashamed as I need to take care of one specific model that I know almost anything about. Its performance is bad and I can't figure out how to start. I am supposed at least to diagnose the model's failures but I have way too little knowledge to even figure out what to do. I could follow someone's instructions well if I had them. But as a DS I should be able to do that by myself. I know very well that working with smarter people is great for my career and that I shouldn't listen to my inner voice that tells me I should have stayed a DA. Still, I feel that I don't have the behavioral skills to take advantage of that the best way as I am introverted and have ADHD.   


I identified that my lack of attention is an issue and I am making a conscious effort to pay more attention. I am quite self-conscious and afraid of making questions, which is something I am trying to change, but at a big effort to me. So I wonder if you guys have any general hints/suggestions on how to improve faster. ",datascience,https://www.reddit.com/r/datascience/comments/16uze49/how_to_be_a_better_data_scientist_and_catch_up/,15,38,0.89,"[Comment(id='k2o6gf5'), Comment(id='k2o7qhe'), Comment(id='k2pczi4'), Comment(id='k2ourug'), Comment(id='k2pvejw'), Comment(id='k2q6mxy'), Comment(id='k2qmf0t'), Comment(id='k2r6suz'), Comment(id='k2rei5n'), Comment(id='k2q1uah'), Comment(id='k2pr01w'), Comment(id='k2q1ip3'), Comment(id='k34byeh'), Comment(id='k2puoob'), Comment(id='k2pw0r0')]"
16urkg1,PitterPatTomCat,,2023-09-28 21:03:23+00:00,False,,False,False,True,False,/r/datascience/comments/16urkg1/big_fancy_company_has_no_clue_what_data_science_is/,Big Fancy Company Has No Clue What Data Science Is,"They offered to cover my move from the East Coast to Dallas, plump my check with an additional 50K for signing, but the office is run by squirrels.

I’m not talking your acorn tree squirrel. I’m talking tiny little men with moostaches who haven’t the slightest clue that plugging in numbers to an excel sheet ain’t science.

Do I tell them this is nuts?! Or do I keep the money and hang?

The name of the company rhymes with Jewelry.",datascience,https://www.reddit.com/r/datascience/comments/16urkg1/big_fancy_company_has_no_clue_what_data_science_is/,38,76,0.92,"[Comment(id='k2mtm8m'), Comment(id='k2mwws9'), Comment(id='k2njwp4'), Comment(id='k2nag9v'), Comment(id='k2nh3so'), Comment(id='k2mxj94'), Comment(id='k2o3xmq'), Comment(id='k2o6dxo'), Comment(id='k2pl93q'), Comment(id='k2pgbhy'), Comment(id='k2q0ls9'), Comment(id='k338fap'), Comment(id='k2ooe2w'), Comment(id='k2oymq2'), Comment(id='k2uy02t'), Comment(id='k2nmqgb'), Comment(id='k2qtcft'), Comment(id='k2p6mxz'), Comment(id='k2ooqxk'), Comment(id='k2noxqm'), Comment(id='k2od5ky'), Comment(id='k2pzeqd'), Comment(id='k2ptclf'), Comment(id='k2oryjw'), Comment(id='k2rovs4'), Comment(id='k2qtiqj'), Comment(id='k2o384r'), Comment(id='k2rct6v'), Comment(id='k2q0cle'), Comment(id='k2rphw2'), Comment(id='k2r0y2o'), Comment(id='k2q1i8w'), Comment(id='k2rwla8'), Comment(id='k2r37tn'), Comment(id='k2qk488'), Comment(id='k2tygz8'), Comment(id='k2usi1w'), Comment(id='k2xdne4')]"
16uomoo,Consistent-Design-57,,2023-09-28 19:10:31+00:00,False,,1695931442.0,False,True,False,/r/datascience/comments/16uomoo/everyone_always_talks_about_llmsml_in_data/,"Everyone always talks about LLMs/ML in data science but no one ever talks about experimentation, ML's older sexier sister.","As a data scientist primarily focused in causal inference and experiment design, I find that most conversation and questions from people trying to transition into DS always want to go into ML, but causal inference and experimentation is another very fun sub-field within DS. I'm biased since I'm in this sub-field but having done some ML stuff on the side, I much more enjoy the causal inference side of things.

Note that this post is primarily geared toward people with some experience. It's hard to break into experimentation with no background. Fresh PhDs though, particularly in social or physical sciences do well.

What's fun about about experimentation and causal inference:

1. Knowing why something caused something else is always valuable
2. Well designed experiments can be hard to design and execute, which is part of the challenge. A good experiment correctly captures the objectives of the product manager/business partner and answers a question that can be immediately acted upon once results are available.
3. Requires a combination of business thinking, strategy, and strong statistical foundations
4. Often is highly collaborative and builds your soft skills. I work with people in marketing, risk, finance, modeling, dashboarding teams to make sure things work well
5. Causal inference is not just A/B testing. There are plenty of situations where we need to get a causal understanding but an experiment is just not feasible. Tons of fun techniques here like instrumental variables, propensity score matching, causal forests, double ML etc. which have their own strengths and weaknesses
6. Experimentation is not just A/B testing. We have multi-arm bandits, factorial and fractional factorial experiment designs etc.
7. Usually don't have to worry about productionizing etc. ML is often 5 lines of code once you've massaged the data just right
8. It's a growing field. I see lots of job openings in experimentation and the skillset is hard to come by. It's not easy to do causal inference (both the experimental and non-experimental kind) and all the challenges of launching a business experiment require on the job training to be successful at.

If you're in the market for a new role, don't overlook experimentation (or think of it as less fun) :).

Some resources for those to want to learn:

1. [https://matheusfacure.github.io/python-causality-handbook/landing-page.html](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)
2. Trustworthy online controlled experiments by Ronny Kohavi, a giant in the field of experiment design
3. Mostly Harmless Econometrics by Angrist et al.",datascience,https://www.reddit.com/r/datascience/comments/16uomoo/everyone_always_talks_about_llmsml_in_data/,24,107,0.93,"[Comment(id='k2mnbeh'), Comment(id='k2mn7h6'), Comment(id='k2ml5wn'), Comment(id='k2mo2cv'), Comment(id='k2nabin'), Comment(id='k2otrlm'), Comment(id='k2ojrfo'), Comment(id='k2p4a2y'), Comment(id='k2pbm0u'), Comment(id='k2n7goy'), Comment(id='k2o3eju'), Comment(id='k2mu071'), Comment(id='k2n8nv7'), Comment(id='k2ogcly'), Comment(id='k2svkum'), Comment(id='k2n709d'), Comment(id='k2mp7qr'), Comment(id='k2o81cj'), Comment(id='k2o042u'), Comment(id='k2n9m9l'), Comment(id='k2nv7dy'), Comment(id='k2ob89h'), Comment(id='k2no1ka'), Comment(id='k2p4db6'), Comment(id='k2pa23s'), Comment(id='k2pcomx')]"
16vg73y,ravy,,2023-09-29 16:26:33+00:00,False,,False,False,False,False,/r/datascience/comments/16vg73y/what_the_birthday_paradox_teaches_us_about/,What the Birthday Paradox Teaches Us About Protecting Patron Privacy,,datascience,https://chimpy.me/blog/posts/what-the-birthday-paradox-teaches-us-about-protecting-patron-privacy/,0,2,1.0,[]
16vfyfw,Alarming_Scene126,,2023-09-29 16:17:31+00:00,False,,False,False,False,False,/r/datascience/comments/16vfyfw/first_project_review_data_wrangling_and/,First project review | Data wrangling and Visualization,"Hello guys,

This is my first project and i request you guys to please check out my work, leave a comment on what i can improve and upvote in kaggle it you like it.
I have performed:
• Data manipulation (pandas, numpy)
• Data visualization (pandasql, matplotlib)

I would like to thank this community for creating opportunity for ppl like us to share our work. Thank you all!!",datascience,https://www.kaggle.com/code/aadeshpradhan/data-cleaning-viz-for-beginners-intermediate?scriptVersionId=144642580,0,2,1.0,[]
16udvr0,Tarneks,,2023-09-28 11:50:12+00:00,False,,False,False,False,False,/r/datascience/comments/16udvr0/this_is_a_data_analyst_position/,This is a data analyst position.,,datascience,https://i.redd.it/9jvrsplsizqb1.jpg,174,364,0.96,"[Comment(id='k2kmwv7'), Comment(id='k2kp9mt'), Comment(id='k2ko6d2'), Comment(id='k2liwcv'), Comment(id='k2l9cq5'), Comment(id='k2khdzf'), Comment(id='k2l0oq9'), Comment(id='k2kxi4k'), Comment(id='k2kggar'), Comment(id='k2l2s0e'), Comment(id='k2mx3qx'), Comment(id='k2ljpve'), Comment(id='k2m168s'), Comment(id='k2ngw09'), Comment(id='k2nxbd4'), Comment(id='k2ku2xq'), Comment(id='k2lrxsk'), Comment(id='k2ol1ip'), Comment(id='k2lzakj'), Comment(id='k2lwuf9'), Comment(id='k2lh962'), Comment(id='k2m51n9'), Comment(id='k2oygyz'), Comment(id='k2p1stk'), Comment(id='k2p7o4p'), Comment(id='k2pbfg8'), Comment(id='k2tt66c'), Comment(id='k3brzrn'), Comment(id='k2kqaoj'), Comment(id='k2lfs44'), Comment(id='k2nlswm'), Comment(id='k2kz3up'), Comment(id='k2l3sqg'), Comment(id='k2lh0hb'), Comment(id='k2o72bn'), Comment(id='k2w8qzq'), Comment(id='k2ktpyb'), Comment(id='k2nwynh'), Comment(id='k2mcune'), Comment(id='k2p783v'), Comment(id='k2nic92'), Comment(id='k2qc8lz'), Comment(id='k2l8r28'), Comment(id='k2lwmx2'), Comment(id='k2lyz64'), Comment(id='k2mtwnn'), Comment(id='k2rizlm'), Comment(id='k2m0h7d'), Comment(id='k2kwbm4'), Comment(id='k2khktk'), Comment(id='k2l3jsv'), Comment(id='k2m6tjd'), Comment(id='k2r6g2d'), Comment(id='k2sl95n'), Comment(id='k2kwlnq'), Comment(id='k2mfzam'), Comment(id='k2lhaxy'), Comment(id='k2ksryo'), Comment(id='k2ln9am'), Comment(id='k2l14vm'), Comment(id='k2lga4v'), Comment(id='k2l8aur'), Comment(id='k2lgdmm'), Comment(id='k2owayx'), Comment(id='k2o73zp'), Comment(id='k2kwi2a'), Comment(id='k2qh724'), Comment(id='k2lcslf'), Comment(id='k2lz3tx'), Comment(id='k2m5mj2'), Comment(id='k2m7lz4'), Comment(id='k2m9n7o'), Comment(id='k2l8qs9'), Comment(id='k2lw4ab'), Comment(id='k2skv8i'), Comment(id='k2kn4k8'), Comment(id='k2kifxd'), Comment(id='k2ozaw2'), Comment(id='k2kv59n'), Comment(id='k2l80ll'), Comment(id='k2lfefh'), Comment(id='k2mxz2f'), Comment(id='k2o4rjz'), Comment(id='k2ofldo'), Comment(id='k2l9h5l'), Comment(id='k2l4v8x'), Comment(id='k2n7jwi'), Comment(id='k2ne62f'), Comment(id='k2nhn5v'), Comment(id='k2od9ce'), Comment(id='k2llhqp'), Comment(id='k2nijri'), Comment(id='k2lszle'), Comment(id='k2o7785'), Comment(id='k2la2qp'), Comment(id='k2l8ogs'), Comment(id='k2lkvdi'), Comment(id='k2lwl2j'), Comment(id='k2qylyh'), Comment(id='k2mo9qf'), Comment(id='k2l8ei3'), Comment(id='k2ks7ci'), Comment(id='k2kzt7m'), Comment(id='k2mdwlz'), Comment(id='k2l4y0n'), Comment(id='k2lg300'), Comment(id='k2lsv23'), Comment(id='k2l8ww5'), Comment(id='k2le54z'), Comment(id='k2lgr3d'), Comment(id='k2lwz9s'), Comment(id='k2osi9t'), Comment(id='k2lgpbh'), Comment(id='k2m40h5'), Comment(id='k2lgh6x'), Comment(id='k2n8afp'), Comment(id='k2nied8'), Comment(id='k2oeq7s'), Comment(id='k2o8vzr'), Comment(id='k2og3gp'), Comment(id='k2m4m1k'), Comment(id='k2ndg8e'), Comment(id='k2lvj0y'), Comment(id='k2oggut'), Comment(id='k2la6jw'), Comment(id='k2ohdns'), Comment(id='k2oidap'), Comment(id='k2ly8jw'), Comment(id='k2l50rw'), Comment(id='k2lj5ll'), Comment(id='k2l3bsq'), Comment(id='k2l5mzi'), Comment(id='k2li9ws'), Comment(id='k2mjd8q'), Comment(id='k2lgvn2'), Comment(id='k2ozqhg'), Comment(id='k2lkwgr'), Comment(id='k2nj8zg'), Comment(id='k2omylr'), Comment(id='k2oa24b'), Comment(id='k2n0hn1'), Comment(id='k2nl9k1'), Comment(id='k2m4zz6'), Comment(id='k2lal8a'), Comment(id='k2lph15'), Comment(id='k2lsfcu'), Comment(id='k2l6txt'), Comment(id='k2ls9g3'), Comment(id='k2mxhjn'), Comment(id='k2lcpo2'), Comment(id='k2lir9q'), Comment(id='k2l6q4n'), Comment(id='k2lmsig'), Comment(id='k2op4u0'), Comment(id='k2oemxk'), Comment(id='k2ozz8j'), Comment(id='k2niudz'), Comment(id='k2o9r0u'), Comment(id='k2la5zu'), Comment(id='k2lzgly'), Comment(id='k2mjz77'), Comment(id='k2oo7rn'), Comment(id='k2ld8nn'), Comment(id='k2mmm8y'), Comment(id='k2o65gy'), Comment(id='k2ldzg5'), Comment(id='k2mrssh'), Comment(id='k2m31qt'), Comment(id='k2loljl'), Comment(id='k2ozhws'), Comment(id='k2liofi'), Comment(id='k2ml5tm'), Comment(id='k2lfand'), Comment(id='k2mtjr3'), Comment(id='k2lfmrv'), Comment(id='k2lq0p8'), Comment(id='k2qc7l8'), Comment(id='k2ljdcg'), Comment(id='k2nbt8t'), Comment(id='k2mkgse'), Comment(id='k2lqhcy'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
16v36n7,yuribz,,2023-09-29 05:38:23+00:00,False,,False,False,True,False,/r/datascience/comments/16v36n7/no_passion_for_data_science_what_jobs_can_i_get/,"No passion for data science, what jobs can I get?","Hi everyone. I am a recent data science graduate (bachelor's) from UCSD, but I also have a degrees in Linguistics and teaching experience. I am trying to apply to data science jobs, but from what I figured, if I don't have outright passion and initiative to pursue data science, it will be near impossible to find a job. I want to eventually become a teacher, but I want to work somewhere else first to get experience and save up money. 

What fields are data science skills transferrable to? I know that in any field I will have to show initiative and passion, but I feel like that IT is so cut throat right now that it'd be much easier to find job elsewhere.",datascience,https://www.reddit.com/r/datascience/comments/16v36n7/no_passion_for_data_science_what_jobs_can_i_get/,33,12,0.67,"[Comment(id='k2oqoam'), Comment(id='k2pt3i5'), Comment(id='k2ot2po'), Comment(id='k2owa3p'), Comment(id='k2px5rw'), Comment(id='k2pp6ip'), Comment(id='k2py7pe'), Comment(id='k2q7r8e'), Comment(id='k2re6mz'), Comment(id='k2rqb9u'), Comment(id='k2st2zj'), Comment(id='k2ti5n7'), Comment(id='k2txpm0'), Comment(id='k2vu3wu'), Comment(id='k2oqvse'), Comment(id='k2qqhmu'), Comment(id='k2otji4'), Comment(id='k2oxldh'), Comment(id='k2qq8xe'), Comment(id='k2qo3tx'), Comment(id='k2qnsyv'), Comment(id='k2reg3k'), Comment(id='k2tk8a9'), Comment(id='k2ty2vt'), Comment(id='k2ppv2y'), Comment(id='k2qsj9s'), Comment(id='k2oun0t'), Comment(id='k2tkh3b'), Comment(id='k2tkivn'), Comment(id='k2tl5hz'), Comment(id='k2u0t6v'), Comment(id='k2t3z21'), Comment(id='k2tlx7r')]"
16vaujg,rizic_1,,2023-09-29 12:52:15+00:00,False,,False,False,True,False,/r/datascience/comments/16vaujg/what_do_you_bring_to_the_table/,What do you bring to the table?,Data science is a broad field. What do you feel makes you a great data scientist or what are you trying to achieve? e.g. “I’m a bada** statistician because x and no one else knows how to do x”,datascience,https://www.reddit.com/r/datascience/comments/16vaujg/what_do_you_bring_to_the_table/,46,2,0.58,"[Comment(id='k2q0yli'), Comment(id='k2q6j0j'), Comment(id='k2q5wl7'), Comment(id='k2s13eq'), Comment(id='k2qqtta'), Comment(id='k2quuhc'), Comment(id='k2qe3mr'), Comment(id='k2qa4cr'), Comment(id='k2sfqo5'), Comment(id='k2u7hu3'), Comment(id='k2rvsqf'), Comment(id='k2r2n24'), Comment(id='k2qwbls'), Comment(id='k2todah'), Comment(id='k2tw3dq'), Comment(id='k2qsoct'), Comment(id='k2quew1'), Comment(id='k2rxaca'), Comment(id='k2sgblc'), Comment(id='k38yt61'), Comment(id='k2qmaey'), Comment(id='k2q8msn'), Comment(id='k2rhegb'), Comment(id='k2r51qk'), Comment(id='k2sh033'), Comment(id='k2r7sbf'), Comment(id='k2qp01t'), Comment(id='k2qkzbf'), Comment(id='k2rh7ts'), Comment(id='k2r8ewe'), Comment(id='k2tw1c1'), Comment(id='k2qmgks'), Comment(id='k2qktee'), Comment(id='k2td2ts'), Comment(id='k2r9lxe'), Comment(id='k2ries6'), Comment(id='k2rapbb'), Comment(id='k2uxlv7'), Comment(id='k2romt7'), Comment(id='k2ted5m'), Comment(id='k2rj2wi'), Comment(id='k2rgkf7'), Comment(id='k2to8r2'), Comment(id='k2tej2w'), Comment(id='k2rhzaa'), Comment(id='k2rk4a8'), Comment(id='k2rn5ft'), Comment(id='k2roa80')]"
16vdu21,Interesting_Chance31,,2023-09-29 14:55:27+00:00,False,,False,False,True,False,/r/datascience/comments/16vdu21/last_call_for_rugs_grant_applications/,Last Call for RUGS Grant Applications!,"Hello to all R enthusiast, just a friendly reminder to anyone eyeing the RUGS grant opportunity. The clock's ticking with the deadline set for tomorrow, September 30th, 2023. Don't miss out on this chance to bolster your R-based projects. All details are here: https://www.r-consortium.org/all-projects/r-user-group-support-program. Seize the moment!",datascience,https://www.reddit.com/r/datascience/comments/16vdu21/last_call_for_rugs_grant_applications/,0,2,1.0,[]
16vjh8q,alpha-gamma-x,,2023-09-29 18:34:30+00:00,False,,False,False,True,False,/r/datascience/comments/16vjh8q/when_a_ml_algorithm_is_training_what_is_actually/,"When a ML algorithm is training, what is actually happening behind the scenes? How does it learn?","Basically the question. When we run say logistic regression or an SVM on Python, what is happening step by step with all the train data? I know the answer may vary based on the algorithm, so you may pick any algorithm to explain in detail the behind-the-scenes.

Wanted to post at r/explainlikeimfive but wasn’t sure if any ML people may be in that crowd, but please ELI5.",datascience,https://www.reddit.com/r/datascience/comments/16vjh8q/when_a_ml_algorithm_is_training_what_is_actually/,34,0,0.48,"[Comment(id='k2rkdbl'), Comment(id='k2rq450'), Comment(id='k2rrqcn'), Comment(id='k2sayt0'), Comment(id='k2skpee'), Comment(id='k2ttvbe'), Comment(id='k2rg67t'), Comment(id='k2rjpce'), Comment(id='k2rozoz'), Comment(id='k2rw3h1'), Comment(id='k2rx9hf'), Comment(id='k2rt77c'), Comment(id='k2rmht6'), Comment(id='k2rpegu'), Comment(id='k2ru4ar'), Comment(id='k2rv29j'), Comment(id='k2s2h2y'), Comment(id='k2s3qgi'), Comment(id='k2sdf8t'), Comment(id='k2skntb'), Comment(id='k2t88wf'), Comment(id='k2ttkmy'), Comment(id='k2u3qou'), Comment(id='k2uaqqi'), Comment(id='k2rsl0m'), Comment(id='k2rudo1'), Comment(id='k2rog0o'), Comment(id='k2s27qe'), Comment(id='k2s2g8z'), Comment(id='k2rokt2'), Comment(id='k2salkl'), Comment(id='k2sdtzn')]"
16unmxh,imjustsippintea,,2023-09-28 18:31:55+00:00,False,,False,False,True,False,/r/datascience/comments/16unmxh/is_data_analytics_not_entry_level/,Is Data Analytics not entry level?,"This a response to the replies I saw from a previous post where hiring managers simply filtered out inexperienced applicants.

My question is if data analytics is not the right path to get acclimated in this field, then what is? Where could you get experience that will allow hiring managers to respect what you have to offer?

In my case, I’ve recently graduated with a social science degree and have been advancing my knowledge in statistics to apply for these positions. I’ve done one project in the past and plan to finish a certificate this month. My only sense of career guidance has been what I’ve seen online. Data events aren’t really catered to newcomers in my area and rejected job applications are the only type of feedback I get.",datascience,https://www.reddit.com/r/datascience/comments/16unmxh/is_data_analytics_not_entry_level/,35,38,0.82,"[Comment(id='k2m72dt'), Comment(id='k2m44o0'), Comment(id='k2m95b6'), Comment(id='k2mjssd'), Comment(id='k2ma3i2'), Comment(id='k2mang3'), Comment(id='k2mo3zf'), Comment(id='k2m5lva'), Comment(id='k2m8yi5'), Comment(id='k2n4yyh'), Comment(id='k2mu3hw'), Comment(id='k2n1fg1'), Comment(id='k2n5rhl'), Comment(id='k2mz5hv'), Comment(id='k2msdc4'), Comment(id='k2m4bwp'), Comment(id='k2p95m3'), Comment(id='k2m9ie0'), Comment(id='k2mvqjp'), Comment(id='k2mazzy'), Comment(id='k2mmkxj'), Comment(id='k2mm4ob'), Comment(id='k2nczye'), Comment(id='k2n8exn'), Comment(id='k2n96m5'), Comment(id='k2n0u4y'), Comment(id='k2n6nzf'), Comment(id='k2r3f9m'), Comment(id='k2n7dnn'), Comment(id='k2p0caf'), Comment(id='k2p1cnv'), Comment(id='k2o8m9m'), Comment(id='k2pujar'), Comment(id='k2ptvhv'), Comment(id='k2rb3q8'), Comment(id='k2qpfzg')]"
16vc2xm,Interesting_Chance31,,2023-09-29 13:45:48+00:00,False,,False,False,True,False,/r/datascience/comments/16vc2xm/sunday_oct_1st_is_the_last_day_to_submit_your/,"Sunday, Oct 1st, is the last day to submit your proposals!","Here is What We’re Looking For in Your Proposals

The ISC values projects that:

1️⃣ Have a broad impact on the R community

2️⃣ Are scoped to be focused and actionable

3️⃣ Carry a low-to-medium risk and reward

Review Process:

Proposals will be reviewed by the Chair of the ISC and committee members, with results announced per the key dates.

Let's enrich the R landscape together. We can't wait to review your innovative proposals! Learn more here: https://www.r-consortium.org/all-projects/call-for-proposals

\#RProgramming #Rstats #OpenSource #DataScience",datascience,https://www.reddit.com/r/datascience/comments/16vc2xm/sunday_oct_1st_is_the_last_day_to_submit_your/,0,0,0.5,[]
16vajxx,neuro-psych-amateur,,2023-09-29 12:38:56+00:00,False,,False,False,True,False,/r/datascience/comments/16vajxx/lets_discuss_again_distance_learning_phds/,Let's discuss again distance learning PhDs,"I have recently posted about not being able to find a new job. I do work as a senior analyst, and the job pays the bills, but it isn't very interesting. I am sincerely interested in statistics, predictive modeling, machine learning, and I want to keep pursuing that. I have been applying a lot, had my resume reviewed by several people, but I am just not getting any replies.

I am now thinking about what else I can do with my life to make it more interesting. I have a masters degree in data science, and two published papers, so in theory I could apply for a PhD. I have a mortgage and small kids though, I really can't go for a full-time PhD because I wouldn't make enough. My salary is around $79K USD and PhD programs definitely don't pay that. I also can't move because of kids, mortgage, family, etc.

I do really want to work on an interesting project though, are there any good remote part-time  PhD programs? I know this has been already discussed, and there aren't a lot of options, but I did see that the Open University in UK has such a program and the Coventry University, also in UK, has one. The programs are quite expensive though for non-UK residents. 
Anyone aware of other DS part-time remote PhD programs? I could find a way to attend campus occasionally, but definitely not every week, if it's far away. And unfortunately there aren't any part-time DS PhD programs in my city.",datascience,https://www.reddit.com/r/datascience/comments/16vajxx/lets_discuss_again_distance_learning_phds/,20,2,0.6,"[Comment(id='k2qe4z2'), Comment(id='k2qnzvk'), Comment(id='k2q4djk'), Comment(id='k2qpgws'), Comment(id='k2qq7y3'), Comment(id='k31igan'), Comment(id='k2sapc1'), Comment(id='k2r0o03'), Comment(id='k2q5ok4'), Comment(id='k2v4a3q'), Comment(id='k2v4qvq'), Comment(id='k2ra2bl'), Comment(id='k2q9wiw'), Comment(id='k30bczf'), Comment(id='k3eu2i8'), Comment(id='k2qdx74'), Comment(id='k3f2moa'), Comment(id='k2qif27'), Comment(id='k2qf9oy'), Comment(id='k2rd876')]"
16usord,InevitableTraining69,,2023-09-28 21:44:56+00:00,False,,False,False,True,False,/r/datascience/comments/16usord/you_ever_start_a_new_job_and_hate_it/,You ever start a new job and hate it?,"I just started this new job and I feel so blah about it. Like going to work each day feels like I'm about to jump into freezing cold water. I'm just iffy about it. But my last company laid me off which is why I ""left"" but I loved working there. I really loved the vibe and the environment and I wanna go back idk what's wrong with me.",datascience,https://www.reddit.com/r/datascience/comments/16usord/you_ever_start_a_new_job_and_hate_it/,10,15,0.83,"[Comment(id='k2nou0o'), Comment(id='k2nyu9c'), Comment(id='k2ovmdh'), Comment(id='k2nwhiw'), Comment(id='k2nap48'), Comment(id='k2n8ytt'), Comment(id='k2p0sdc'), Comment(id='k2p6wr4'), Comment(id='k2p78mx'), Comment(id='k2q24x8')]"
16v8kwk,Manu_Orobix,,2023-09-29 11:04:17+00:00,False,,False,False,True,False,/r/datascience/comments/16v8kwk/quadra_is_out_opensource_library_to_train_and/,QUADRA is out!! - Opensource library to train and deploy DL models,"**QUADRA is out!! 🎉🎉🎉** 

QUADRA is an **opensource library to train and deploy DL models** in a very simple and flexible way and to compare, monitor, and share experiments quickly!

🌐 Website: [https://orobix.github.io/quadra/](https://orobix.github.io/quadra/) 📁 GitHub: [https://github.com/orobix/quadra](https://github.com/orobix/quadra) 

QUADRA development started to answer the necessity to **perform machine learning experiments for multiple customers and projects**, without the need of a large copy-pasted codebase over multiple repository.

**Are you a data scientist or an AI researcher?** 

With QUADRA you can: → simplify your deep learning experimenting process; → train and deploy deep learning models in a simple and flexible way, using YAML configuration files and open-source tools such as Hydra, Lightning framework, and Pytorch; → compose your experiment configurations from single command line interface, so you can conduct multiple experiments with different settings and hyperparameters; → compare, monitor, and share your experiments quickly!

\---  

❌ Are you interested in joining the project community? Get in touch! ❌

Feel free to use QUADRA for your Artificial Intelligence projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️

&#x200B;

https://preview.redd.it/kxvdi76ff6rb1.png?width=8012&format=png&auto=webp&s=e451177e0f7f660be46cc8a947e88ba0071527db",datascience,https://www.reddit.com/r/datascience/comments/16v8kwk/quadra_is_out_opensource_library_to_train_and/,0,0,0.4,[]
16v81yf,Jerry__10,,2023-09-29 10:35:17+00:00,False,,False,False,True,False,/r/datascience/comments/16v81yf/issue_reading_csv_in_pandas_datatype_all_objects/,"Issue reading csv in pandas, Datatype all objects","
Hi, I'm facing an issue reading a file in databricks using pandas.
I'm reading the csv file, Only the encoding='IS0-8859-1' is working for the Data. And all columns are being read as either object / int32 datatype instead of Mostly String/Integers. I tried the following to change that to string but none is working:
- astype(str)
- applied lambda func to each element in column
- pd.Series (df ['column '],atype=str)
-applymap
- apply (str)

I checked the column data and it is one datatype only, It does not have multiple headers/footers, A few nulls out of 4000 rows

- I tried reading with spark and then converting the dataframe to pandas, but same 
- Before applying all the above, I removed null rows and some special characters  also from the column. But still not working

Let me know if someone can help?",datascience,https://www.reddit.com/r/datascience/comments/16v81yf/issue_reading_csv_in_pandas_datatype_all_objects/,2,0,0.5,"[Comment(id='k2udllu'), Comment(id='k2uc6kt')]"
16uhmmt,vincentfer66,,2023-09-28 14:32:17+00:00,False,,False,False,True,False,/r/datascience/comments/16uhmmt/in_which_countries_do_junior_data_scientists_find/,In which countries do junior Data Scientists find the most promising opportunities?,"I've recently completed my Data Science studies in France, and I'm eager to venture out and work internationally.

My desire to work abroad is not purely based on career growth. It's also about plunging into new cultures, seeing life through a different lens, and enriching my own understanding of the world.

Most articles about the best countries to be data scientist only focus on salaries. However, I believe this approach misses the mark for several reasons:

1. **Quality of Life:** It's not just about how much you earn, but how fulfilling and comfortable your daily life is.
2. **Engaging Job Missions:** Beyond the financial aspects, I'm deeply interested in roles that offer captivating missions and innovative/meaningful projects.
3. **Supportive Environments for Juniors**
4. **Cost of Living:** A high salary in one country might not stretch as far when considering the local prices and living costs.

I'd greatly appreciate any insights or suggestions of country/city you might have from your experience. Thanks in advance!

&#x200B;

**PS:** I was in an alternance program. I studied in Toulouse and worked in Paris during the same year. ",datascience,https://www.reddit.com/r/datascience/comments/16uhmmt/in_which_countries_do_junior_data_scientists_find/,58,42,0.79,"[Comment(id='k2l3n1s'), Comment(id='k2n8sol'), Comment(id='k2ljm1h'), Comment(id='k2lwdul'), Comment(id='k2n5p2p'), Comment(id='k2n7k2w'), Comment(id='k2n2q2r'), Comment(id='k2n5tos'), Comment(id='k2rn2cm'), Comment(id='k2ow61p'), Comment(id='k2p3xcz'), Comment(id='k2lqigp'), Comment(id='k2mixhu'), Comment(id='k2lem4j'), Comment(id='k2l42yj'), Comment(id='k2lyxj1'), Comment(id='k2mp8eo'), Comment(id='k2mo3p5'), Comment(id='k2l1p7b'), Comment(id='k2lzh15'), Comment(id='k2mxob9'), Comment(id='k2ngy1v'), Comment(id='k2pzsbi'), Comment(id='k2pcxn5'), Comment(id='k2qmv05'), Comment(id='k2l94ge'), Comment(id='k2nnh16'), Comment(id='k2m6s7t'), Comment(id='k2m2wr2'), Comment(id='k2mw9ud'), Comment(id='k2wl577'), Comment(id='k2ph1a5'), Comment(id='k2pgl3p'), Comment(id='k2m0rdl'), Comment(id='k2m85vr'), Comment(id='k2n1luk'), Comment(id='k2lsa1p'), Comment(id='k2m6hsm'), Comment(id='k2lp4rf'), Comment(id='k2og83z'), Comment(id='k2pfqih'), Comment(id='k2u7z2f'), Comment(id='k2lbk0w'), Comment(id='k2mcp7c'), Comment(id='k2n3q55'), Comment(id='k2ziv8q'), Comment(id='k2spf9l'), Comment(id='k2m8xuk'), Comment(id='k2m7lnh'), Comment(id='k2okyhn'), Comment(id='k2lzm05'), Comment(id='k2pflrb'), Comment(id='k2mam6f'), Comment(id='k2n49ba'), Comment(id='k2ma3ip'), Comment(id='k2ondky'), Comment(id='k2mkfcf'), Comment(id='k2ov0a0'), Comment(id='k2msvm5'), Comment(id='k2ncqdu')]"
16uxg0e,Xman0142,,2023-09-29 00:55:29+00:00,False,,False,False,False,False,/r/datascience/comments/16uxg0e/the_hype_for_llms_is_reaching_a_fever_pitch/,The Hype for LLMs is reaching a fever pitch!,"IEEE posts this article on LLMs and it seems like they are going to take over, is it possible?",datascience,https://insight.ieeeusa.org/articles/large-language-models-the-transformative-force-shaping-the-21st-century/,2,4,1.0,"[Comment(id='k2pg2e5'), Comment(id='k2qbi71')]"
16uo2qt,spectrotact,,2023-09-28 18:49:11+00:00,False,,False,False,True,False,/r/datascience/comments/16uo2qt/how_do_we_know_that_the_sql_query_will_return_the/,How do we know that the SQL query will return the correct solution?,"SQL and I are just ""getting to know each other"" with the help of some courses and a textbook. Please help me with the theoretical and naive question of how does one know that a query returns the correct and presumably the one and only correct solution? This is clearly verifiable in the case of practice problems and although I don't get it right the first time, this is exactly what makes me think that in the real world I cannot be sure of the correctness of a query.

Perhaps my question can be translated as how to validate a SQL query?

Thanks if you share your experiences.",datascience,https://www.reddit.com/r/datascience/comments/16uo2qt/how_do_we_know_that_the_sql_query_will_return_the/,12,12,0.83,"[Comment(id='k2mckxx'), Comment(id='k2me9sf'), Comment(id='k2mg518'), Comment(id='k2ngk6m'), Comment(id='k2nksrr'), Comment(id='k2nujsz'), Comment(id='k2mh8na'), Comment(id='k2nzf5j'), Comment(id='k2o8e8q'), Comment(id='k2obzzt'), Comment(id='k2rdsse'), Comment(id='k38dgs5')]"
16v5kss,naresh257501,,2023-09-29 08:03:12+00:00,False,,False,False,False,False,/r/datascience/comments/16v5kss/1850_data_science_machine_learning_deep_learning/,"1850 Data Science, Machine Learning, Deep Learning Objective Type Questions and Answers with Explanations split in 37 Online Exams",,datascience,https://mytechbasket.com/article_desc.php?art_id=242,0,1,0.67,[]
16v3z5d,PinstripePride97,,2023-09-29 06:24:49+00:00,False,,False,False,True,False,/r/datascience/comments/16v3z5d/ideal_timing_of_dataset_split/,Ideal timing of dataset split,I was wondering if applying preprocessing to a whole dataset and then doing the train/test or train/val/test split could lead to data leakage. What would be the proper procedure? Splitting then doing EDA/preprocessing or doing it the other way around?,datascience,https://www.reddit.com/r/datascience/comments/16v3z5d/ideal_timing_of_dataset_split/,0,1,1.0,[]
16v15we,LegitimateAd4716,,2023-09-29 03:49:39+00:00,False,,False,False,False,False,/r/datascience/comments/16v15we/used_cars_price_prediction/,Used cars price prediction,"Hey guys I was working on my capstone 
Which is a used cars price prediction model.

So this project includes antique as well as non antique cars
So i wanted to cluster into two groups and predict the price accordingly

What are your inputs guys?? Any suggestions??",datascience,https://i.redd.it/c33kydry94rb1.jpg,11,0,0.4,"[Comment(id='k2om3ut'), Comment(id='k2r66t7'), Comment(id='k2oopsk'), Comment(id='k2p2txh'), Comment(id='k2qbkdk'), Comment(id='k2r90wu'), Comment(id='k2r9aqt'), Comment(id='k2sasr6'), Comment(id='k2t4s3c'), Comment(id='k2tvjvg'), Comment(id='k2tz8yj')]"
16uv9u4,ProfessorChaos224,,2023-09-28 23:23:56+00:00,False,,False,False,True,False,/r/datascience/comments/16uv9u4/need_help_answering_a_model_eval_question/,Need Help Answering a Model Eval Question,"There’s an ongoing discussion at my work I don’t totally understand. We have two different models trying to predict the same metric for two different categories of customer. Lets say the first category is new clients and the second is returning clients. For both populations we are trying to predict 1 or 0 for whether or not the client is likely to transact with us. These were built as two separate models because we have vastly different quantities of data on returning vs new customers.

Based on the likelihood of a client transacting with us we prioritize which clients to call first, calling the most likely to transact first. There is a concern that because these populations have different class imbalances we cannot stack rank their scores for call priority and instead need to make some calibration to account for differences in the classes of  the populations. I don’t totally get it as the models are predicting the same metric and as long as both models are equally accurate on a test dataset and in the real world, why would the prior class imbalance be relevant?",datascience,https://www.reddit.com/r/datascience/comments/16uv9u4/need_help_answering_a_model_eval_question/,0,0,0.5,[]
16twcad,crossmirage,,2023-09-27 21:16:44+00:00,False,,False,False,True,False,/r/datascience/comments/16twcad/how_can_an_llm_play_chess_well/,How can an LLM play chess well?,"Last week, I learned about https://parrotchess.com from a LinkedIn post. I played it, and drew a number of games (I'm a chess master who's played all their life, although I'm weaker now). Being a skeptic, I replicated the code from GitHub on my machine, and the result is the same (I was sure there was some sort of custom rule-checking logic, at the very least, but no).

I can't wrap my head around how it's working. Previous videos I've seen of LLMs playing chess are funny at some point, where the ChatGPT teleports and revives pieces at will. The biggest ""issues"" I've run into with ParrotChess is that it doesn't recognize things like three-fold repetition and will do it ad infinitum. Is it really possibly for an LLM to reason about chess in this way, or is there something special built in?",datascience,https://www.reddit.com/r/datascience/comments/16twcad/how_can_an_llm_play_chess_well/,106,86,0.9,"[Comment(id='k2hsvnj'), Comment(id='k2i3lze'), Comment(id='k2ie2tj'), Comment(id='k2jcaed'), Comment(id='k2ig3a6'), Comment(id='k2iy6zb'), Comment(id='k2hwc0z'), Comment(id='k2k89zs'), Comment(id='k2n5q0c'), Comment(id='k2jac9c'), Comment(id='k2hu1hg'), Comment(id='k2i93lv'), Comment(id='k2irkrl'), Comment(id='k2io55x'), Comment(id='k2ho057'), Comment(id='k2hp4l3'), Comment(id='k2hri8w'), Comment(id='k2ikjev'), Comment(id='k2jghvz'), Comment(id='k2jlrbz'), Comment(id='k2jrrzf'), Comment(id='k2kc2us'), Comment(id='k2ki3o0'), Comment(id='k32c9v6'), Comment(id='k2i5s52'), Comment(id='k2jhka1'), Comment(id='k2hxjnr'), Comment(id='k2ienbt'), Comment(id='k2jtkn8'), Comment(id='k2jtauk'), Comment(id='k2i649l'), Comment(id='k2iisjv'), Comment(id='k2jilet'), Comment(id='k2ija6l'), Comment(id='k2j756i'), Comment(id='k2jw7a7'), Comment(id='k2jmcsg'), Comment(id='k2i5way'), Comment(id='k2neesh'), Comment(id='k2ie2j2'), Comment(id='k2iansb'), Comment(id='k2iv30t'), Comment(id='k2isohj'), Comment(id='k2iolsl'), Comment(id='k2ho3vx'), Comment(id='k2jhysz'), Comment(id='k2kmk72'), Comment(id='k2i9di6'), Comment(id='k2is9mp'), Comment(id='k2i0bf6'), Comment(id='k2iptms'), Comment(id='k2js262'), Comment(id='k2jbxg3'), Comment(id='k2jrahs'), Comment(id='k2jzi6o'), Comment(id='k2khfju'), Comment(id='k2i9h32'), Comment(id='k2rr6ui'), Comment(id='k2ihox9'), Comment(id='k2iaxvh'), Comment(id='k2jjx9j'), Comment(id='k2iz217'), Comment(id='k2isz6a'), Comment(id='k2ifsdn'), Comment(id='k2igo4u'), Comment(id='k2jhqt5'), Comment(id='k2jtrgl'), Comment(id='k2jieuz'), Comment(id='k2itewc'), Comment(id='k2i16u9'), Comment(id='k2iqygb'), Comment(id='k2irt6f'), Comment(id='k2kv8cp'), Comment(id='k2i9uf8'), Comment(id='k2iy9on'), Comment(id='k2il6io'), Comment(id='k2j1wyh'), Comment(id='k2ihhwl'), Comment(id='k2l2br6'), Comment(id='k2jpbet'), Comment(id='k2jir9f'), Comment(id='k2j0jxv'), Comment(id='k2iaf4k'), Comment(id='k2iyvvg'), Comment(id='k2j2j07'), Comment(id='k2j0a91'), Comment(id='k2lp4ug'), Comment(id='k2kvtqj'), Comment(id='k2jiz8q'), Comment(id='k2jbd4i'), Comment(id='k2iatw2'), Comment(id='k2j79oy'), Comment(id='k2iz9qt'), Comment(id='k2jr957'), Comment(id='k2j7wvo'), Comment(id='k2j1uyn'), Comment(id='k2jekii'), Comment(id='k2l9tn6'), Comment(id='k2k1k57'), Comment(id='k2jhx04'), Comment(id='k2jevko'), Comment(id='k2ljt3k'), Comment(id='k2jv5t0'), Comment(id='k2jg8cu'), Comment(id='k2lnmew'), Comment(id='k2ku89w'), Comment(id='k2jhbr0')]"
16uq3uz,newbie_to_python,,2023-09-28 20:08:16+00:00,False,,False,False,True,False,/r/datascience/comments/16uq3uz/skewness_in_target_column/,Skewness in target column,"I have recently started learning data science and for last couple of days i have been working on dataset where training dataset's target column is right skewed, and test dataset doesn't have target column. I have tried to do do log transformation of the column but it's giving worst result compare to if I don't transform the column at all.

I have tried to google but can't find anything that will help me.

Can someone please help me what should i do should i do some other transformation or just leave it be.

Thank you.",datascience,https://www.reddit.com/r/datascience/comments/16uq3uz/skewness_in_target_column/,6,1,1.0,"[Comment(id='k2ml0cl'), Comment(id='k2pnkby'), Comment(id='k2mmiww'), Comment(id='k2mn8bw'), Comment(id='k2mo7et'), Comment(id='k2nfflp')]"
16tujyf,ex0ticOne,,2023-09-27 20:07:45+00:00,False,,False,False,True,False,/r/datascience/comments/16tujyf/heated_debate_with_leadership_because_of_excel/,Heated debate with leadership because of Excel,"I work for a small company that deals with claims process for major insurance companies. Medical bills, car repair authorization, you got it.

I was hired to improve the data analysis area, to deliver insights for key people on the organization. SLAs control, trend lines of the customer demand to better allocate our people on days/shifts, etc.,

They gave me a blank check to do whatever I needed to. 

Seemed like a dream becaming true. No pre-requisites, full control of my work and a great opportunity to expand my portfolio.

And honestly, I delivered a great work. 

A whole ecosystem using SQL and R on a cloud server. SQL to consolidate the data (and importing legacy data from other systems), ETL scripts running on a regular basis to do database tasks, Shiny dashboards with credentials for leaders and other people, webapps with forms to control data input, custom APIs to collect data from a Help Desk solution and supply ML models to serve another endpoint for predictions, etc.

But I'm facing a new and frustrating problem: people on leadership positions keeps using Excel. I saw other bosses telling their people to put data on spreadsheets, causing wrong and outdated reports for the part of the company that uses my tools properly.

And they keep asking people to create spreadsheets, when they can even export data on this format from the dashboards.

Yesterday I got on a heated debate with my boss about this. 

I need some advise. It's a nice company overall, on a industry that I know a lot (insurance is part of my academic formation) and I don't know how to handle this without putting my job at risk.

**TL;DR:** People refusing to abandon Excel and keeps creating spreadsheets and reports disconnected from the data ecosystem that I created, causing all sorts of problems. What I need to do to solve this?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16tujyf/heated_debate_with_leadership_because_of_excel/,52,78,0.9,"[Comment(id='k2hcpp9'), Comment(id='k2i76do'), Comment(id='k2iei91'), Comment(id='k2j3ek3'), Comment(id='k2hru9g'), Comment(id='k2hkblb'), Comment(id='k2jeu3j'), Comment(id='k2i04io'), Comment(id='k2ik5ob'), Comment(id='k2j50m9'), Comment(id='k2jcx41'), Comment(id='k2k7h6t'), Comment(id='k2j3bxy'), Comment(id='k2kxfb5'), Comment(id='k2kxsdf'), Comment(id='k2jjefq'), Comment(id='k2j70tl'), Comment(id='k2kfsbz'), Comment(id='k2kkvq8'), Comment(id='k3st6ae'), Comment(id='k2hzga3'), Comment(id='k2jbxf1'), Comment(id='k2k3f4j'), Comment(id='k2jvqye'), Comment(id='k2jru4m'), Comment(id='k2k070n'), Comment(id='k2k48q6'), Comment(id='k2kkb92'), Comment(id='k2kyfve'), Comment(id='k2l2ws3'), Comment(id='k2lobl8'), Comment(id='k2m71j4'), Comment(id='k2mg0q7'), Comment(id='k2mzmzl'), Comment(id='k2n39zx'), Comment(id='k2xz7xv'), Comment(id='k2jet42'), Comment(id='k2iprjc'), Comment(id='k2j4lq2'), Comment(id='k2ik7s2'), Comment(id='k2kd2q3'), Comment(id='k2i3jlc'), Comment(id='k2kbq4y'), Comment(id='k2kwqmp'), Comment(id='k2kcv1h'), Comment(id='k2kl0dp'), Comment(id='k2lfmc0'), Comment(id='k2lgc74'), Comment(id='k2m9uf3'), Comment(id='k2lghuh'), Comment(id='k2iuwke'), Comment(id='k2kjlo5')]"
16uiavf,TheParanoidPyro,,2023-09-28 14:59:36+00:00,False,,1695914035.0,False,True,False,/r/datascience/comments/16uiavf/is_our_role_to_give_the_data_that_the_stakeholder/,Is our role to give the data that the stakeholder asked for or give them a trimmed version that is closer to correct?,"I got into it with my boss today about this.

We are working with calls, call transcripts and sales. I had been working on attributing certain phrases in the transcripts to actual sales. Given all of our incoming calls to our sales department to numbers specifically for the customer to potentially purchase something, I then decided as my first idea to do it simply would be to match the phonenumbers to the customer information attached to a salesdocument. However, I don't want to match a sales call to a sale made months later, so I limit the date range to the first arbitrary timeframe, I chose 10 days.

Call Date <= Sales Document Date <= Call Date +  10 days.

while I was working on this, my boss had a separate person ask to match calls made to specific numbers associated with promotions. He just set a date to start looking at: 1-1-2023, and just matched the date.

These are the same goals, and I was already working on it in a larger scale so I mentioned how I was doing it. Thus ensued an argument about how much data to give the stakeholder. He said it wasn't our job to take away data, that we had to give them everything to what they asked and present them the list of considerations.

I argued that wasn't correct, that it isn't our job to give everything. The reason we have jobs is because we took the time to be data literate, and that is what they are paying us for. They don't necessarily know the correct questions to ask with all the nuances. I was saying it was our responsibility to siphon the shit out of the request to give the most accurate information. Sure my first caveat of 10 days might not have been the correct choice, further investigation and discussion may reveal a better way, but giving them everything was irresponsible.

If you called the promo number for january, but didn't end up buying anything, and then three months later you called the number on the next promotion you received for april and then purchased something. You wouldn't want to attach the january phone call to the april purchase because that promotion wasn't the one associated with the sale.

I thought this was a simple endeavor, but the argument wasn't going well because I am not the most persuasive, and more plant my feet because damnit I am correct. That is a fault and it could bite me in the ass later.

any thoughts would be appreciated.

TLDR; Boss says give them everything and tell them about potential inaccuracies, I say account for those inaccuracies and explain them and why I removed them if they ask, otherwise just tell them I accounted for date ranges to not match calls to sales that were too far in the future and could be attributed to later calls.

&#x200B;

EDIT-

Boss got back to me on teams.   


&#x200B;

> Looping in Eric to our conversation earlier in standup.  You have excellent points and I expressed those points to him, he was like good point.  I hope you know I completely agree with you, my point was only to give the end user the entire dataset and explain perceived flaws to the end user.   

I still would like help coming up with better words and strategies to deal with these kinds of arguments in the future",datascience,https://www.reddit.com/r/datascience/comments/16uiavf/is_our_role_to_give_the_data_that_the_stakeholder/,3,2,0.75,"[Comment(id='k2l7t9i'), Comment(id='k2l4s55'), Comment(id='k2l998y')]"
16unevw,mili_19,,2023-09-28 18:23:13+00:00,False,,False,False,True,False,/r/datascience/comments/16unevw/correct_way_of_studying_the_learnings_of_a_model/,Correct way of studying the learnings of a model on image classification?,"I am working on a disease detection project, wherein  I am supposed to detect injuries in distinct body parts, how do I ensure that my model is learning correctly? I have tried verifying with activation maps but cannot interpret them.  I assume that activation maps should accurately identify the region of infection, is this assumption correct?",datascience,https://www.reddit.com/r/datascience/comments/16unevw/correct_way_of_studying_the_learnings_of_a_model/,0,1,1.0,[]
16ucjce,REMARKABLE-RPL,,2023-09-28 10:41:16+00:00,False,,False,False,True,False,/r/datascience/comments/16ucjce/job/,Job,"So i have been a graduate in data science for 1 year now. I got hired as a data scientist while i was still persuing my degree, however im looking for a change of scenery knowing that most of my work is on the analytics part. 
Pes: i love doing predictive models but its not required here
Is a business analyst a good option? Or should i search for a pure data science position?
Will it effect my career on the longterm or will i b able to go for pure data science position later on?
Any advice is really appreciated",datascience,https://www.reddit.com/r/datascience/comments/16ucjce/job/,5,3,0.72,"[Comment(id='k2kk3ah'), Comment(id='k2kivdm'), Comment(id='k2kyaci'), Comment(id='k2m56ie')]"
16udl5a,Distinct_Slide4302,,2023-09-28 11:35:51+00:00,False,,False,False,True,False,/r/datascience/comments/16udl5a/advice_data_science_certification/,(Advice) Data Science certification,"Hello everyone!

I just graduated this summer with a degree in electrical and electronics engineering. After my graduation I started working on other skills including project management and data science. I am currently pursuing data science professional certificate by IBM. Although it sounds good, however many reviews by industry specialists I've seen, who have been over this course do say that it's just going to give you the basic skills and the basic understanding. My own plan is to complete this and then get my hands dirty with quality projects. 
Im also in a dilemma as i want to change my field but i feel like im too late because im currently 25 and unemployed.

I need advice on what resources I can use to polish my skills, any other advice would work too considering my degree. Thankyou!",datascience,https://www.reddit.com/r/datascience/comments/16udl5a/advice_data_science_certification/,7,3,0.71,"[Comment(id='k2kyp8x'), Comment(id='k2kvh7n'), Comment(id='k2l5vkq'), Comment(id='k2kv6cc'), Comment(id='k2mxmdn'), Comment(id='k2mx6sz'), Comment(id='k2mwzso')]"
16um2t9,megawalrus23,,2023-09-28 17:28:38+00:00,False,,False,False,True,False,/r/datascience/comments/16um2t9/significance_testing_for_market_campaignsmarket/,Significance Testing for Market Campaigns/Market Study?," 

Hello,

I'm trying to design a study to assess the effectiveness of a marketing campaign and could use some guidance.

Background: We identified the seasonal patterns for the quantity purchased of a given product for every product, for every customer. We are performing a market study where we identify like-markets (customer A orders some product more on average during the same month customer B orders that same product more on average) and we're going to conduct a marketing campaign where one customer is the control (no campaign) and the other is the experimental (campaign).

For every product, we should have plenty of customers that order that product more in a given month on average to act as our control and experimental group.

My plan to analyze this data post-campaign(s) is to take each product control/experimental group and perform an independent sample t-test assuming unequal variances to check for significance.

The issue is, I'm going to have hundreds of thousands of products (i.e. hundreds of thousands of tests). Obviously, some percentage of the tests will be significant and another percentage of them will not be; but I'm not sure how to interpret the results of the study as a whole given this fact.

I've read into Bonferroni Corrections a bit and that seems like a possible way to go when analyzing the results of all the individual t tests. But I would like to get some advice/feedback from others.

Thanks in advance for the help!",datascience,https://www.reddit.com/r/datascience/comments/16um2t9/significance_testing_for_market_campaignsmarket/,0,1,1.0,[]
16ukd8b,acdbddh,,2023-09-28 16:20:15+00:00,False,,False,False,True,False,/r/datascience/comments/16ukd8b/xtwitter_misinformation_detection_browser_plugin/,X/Twitter misinformation detection browser plugin,"It seems that after recent changes made by Elon Musk to X/Twitter (""free speech"" rules plus API limits) there might be market now for an external (web browser side maybe) tool for X/Twitter to detect and highlight troll activity. I've seen there are some papers available on this topic but I haven't found any customer ready to use tool. What do you think? Or maybe you know such a tool? Maybe we can build it here?",datascience,https://www.reddit.com/r/datascience/comments/16ukd8b/xtwitter_misinformation_detection_browser_plugin/,1,1,0.67,[Comment(id='k2lhx85')]
16t9p4v,BiteFancy9628,,2023-09-27 03:38:14+00:00,False,,False,False,True,False,/r/datascience/comments/16t9p4v/llms_hype_has_killed_data_science/,LLMs hype has killed data science,"That's it.

At my work in a huge company almost all traditional data science and ml work including even nlp has been completely eclipsed by management's insane need to have their own shitty, custom chatbot will llms for their one specific use case with 10 SharePoint docs. There are hundreds of teams doing the same thing including ones with no skills. Complete and useless insanity and waste of money due to FOMO.

How is ""AI"" going where you work?",datascience,https://www.reddit.com/r/datascience/comments/16t9p4v/llms_hype_has_killed_data_science/,306,852,0.95,"[Comment(id='k2e4dxn'), Comment(id='k2e6lv4'), Comment(id='k2e7mxa'), Comment(id='k2dyl09'), Comment(id='k2e0syx'), Comment(id='k2espym'), Comment(id='k2e1s1x'), Comment(id='k2e0d0p'), Comment(id='k2ed88r'), Comment(id='k2ei0e2'), Comment(id='k2f4asr'), Comment(id='k2dwh88'), Comment(id='k2ejdeg'), Comment(id='k2etsf9'), Comment(id='k2e2mea'), Comment(id='k2efp5f'), Comment(id='k2ewj5d'), Comment(id='k2f2x0v'), Comment(id='k2gmq0r'), Comment(id='k2h7i6q'), Comment(id='k2e3bfp'), Comment(id='k2f51ow'), Comment(id='k2feybp'), Comment(id='k2g04mb'), Comment(id='k2gltui'), Comment(id='k2ed7ez'), Comment(id='k2f5k7f'), Comment(id='k2h08p7'), Comment(id='k2i7bbs'), Comment(id='k2ll1pg'), Comment(id='k2ew2tp'), Comment(id='k2efz8s'), Comment(id='k2f7m3n'), Comment(id='k2f9d3l'), Comment(id='k2fjmpe'), Comment(id='k2fnvd6'), Comment(id='k2g3myr'), Comment(id='k2i0ih5'), Comment(id='k2itkdq'), Comment(id='k2izck1'), Comment(id='k2j3iy8'), Comment(id='k2j5h2c'), Comment(id='k2klmne'), Comment(id='k2l1ftn'), Comment(id='k2mxg0q'), Comment(id='k3c125x'), Comment(id='k2e18al'), Comment(id='k2ey9ui'), Comment(id='k2dypsm'), Comment(id='k2f4fme'), Comment(id='k2e3hiy'), Comment(id='k2g0k6j'), Comment(id='k2h04je'), Comment(id='k2ios6z'), Comment(id='k2jrb4x'), Comment(id='k2ekzaj'), Comment(id='k2e1hly'), Comment(id='k2gh5q5'), Comment(id='k2h27q5'), Comment(id='k2dvcph'), Comment(id='k2dx64p'), Comment(id='k2hxi8h'), Comment(id='k2oat2m'), Comment(id='k2pwcmt'), Comment(id='k3euqqa'), Comment(id='k7g0z5v'), Comment(id='k2h48kr'), Comment(id='k2f4hd0'), Comment(id='k2f6qpl'), Comment(id='k2j02kf'), Comment(id='k4zm360'), Comment(id='k2eft8y'), Comment(id='k3q4h6d'), Comment(id='k2ei6sw'), Comment(id='k2fdqfm'), Comment(id='k2hsjlj'), Comment(id='k2j09vv'), Comment(id='k2wgkfq'), Comment(id='k2erord'), Comment(id='k2hx56a'), Comment(id='k2i6uz9'), Comment(id='k2fzts3'), Comment(id='k2eqyky'), Comment(id='k2g32xm'), Comment(id='k2ew9bc'), Comment(id='k2e6gm9'), Comment(id='k2enih0'), Comment(id='k2ewxcg'), Comment(id='k2eiekp'), Comment(id='k2imeds'), Comment(id='k2n56g2'), Comment(id='k2ehf6e'), Comment(id='k2eemxw'), Comment(id='k2ed7or'), Comment(id='k2eyiil'), Comment(id='k2ek96s'), Comment(id='k2e74fr'), Comment(id='k2efn7g'), Comment(id='k2h20bt'), Comment(id='k2il4j8'), Comment(id='k2eay2t'), Comment(id='k2fxp98'), Comment(id='k2fdit9'), Comment(id='k2f4m7z'), Comment(id='k2e1dnc'), Comment(id='k2e05op'), Comment(id='k2ed1a5'), Comment(id='k2fenfz'), Comment(id='k2ezee2'), Comment(id='k2k6hhg'), Comment(id='k2ip8ge'), Comment(id='k3db7w1'), Comment(id='k2fesbs'), Comment(id='k2it7oh'), Comment(id='k2nx3yn'), Comment(id='k2ipyoa'), Comment(id='k2k78fu'), Comment(id='k2n1son'), Comment(id='k2jeffw'), Comment(id='k2i5e8p'), Comment(id='k2nycij'), Comment(id='k2e7i89'), Comment(id='k2jdqy3'), Comment(id='k2e2t3w'), Comment(id='k2e7k01'), Comment(id='k2e3n3e'), Comment(id='k2f72ao'), Comment(id='k2i8rdy'), Comment(id='k2i8jxo'), Comment(id='k2dyb5s'), Comment(id='k2e2goj'), Comment(id='k2irfu1'), Comment(id='k2efcvv'), Comment(id='k2i6dmi'), Comment(id='k2j0jbi'), Comment(id='k2ft3tj'), Comment(id='k2f792h'), Comment(id='k2g65oz'), Comment(id='k2gd7ed'), Comment(id='k2egp2y'), Comment(id='k2er0qn'), Comment(id='k2gwg6c'), Comment(id='k2g97ef'), Comment(id='k2xwm8g'), Comment(id='k2xdz14'), Comment(id='k5bj4ov'), Comment(id='k2eu7wu'), Comment(id='k2gchff'), Comment(id='k2f4fpf'), Comment(id='k2e72kn'), Comment(id='k2ev6t4'), Comment(id='k2ekpxu'), Comment(id='k2f8zgg'), Comment(id='k2gj5vj'), Comment(id='k2fvwkp'), Comment(id='k2febwi'), Comment(id='k2hqal4'), Comment(id='k2eubvt'), Comment(id='k2g66f4'), Comment(id='k2eirtm'), Comment(id='k2ejbna'), Comment(id='k2feg4k'), Comment(id='k2ilwr1'), Comment(id='k2h3501'), Comment(id='k2inibv'), Comment(id='k2g3ocg'), Comment(id='k2io467'), Comment(id='k2f5bhs'), Comment(id='k2ei0ex'), Comment(id='k2et2sy'), Comment(id='k2etfoz'), Comment(id='k2elpqh'), Comment(id='k2esxkg'), Comment(id='k2kymti'), Comment(id='k2iqdhm'), Comment(id='k2l5si5'), Comment(id='k2sw3ht'), Comment(id='k2k7yo6'), Comment(id='k2e86vj'), Comment(id='k2ftglr'), Comment(id='k2j08sv'), Comment(id='k2izzgs'), Comment(id='k2h5v0s'), Comment(id='k2e9vte'), Comment(id='k2etd01'), Comment(id='k2ifeq9'), Comment(id='k2h6kix'), Comment(id='k2f9ejf'), Comment(id='k2fqyth'), Comment(id='k2hz4ne'), Comment(id='k2exvbj'), Comment(id='k2evwmf'), Comment(id='k2gckcq'), Comment(id='k2haom4'), Comment(id='k2hhaep'), Comment(id='k2hsq3w'), Comment(id='k2j4n1a'), Comment(id='k7mjlgh'), Comment(id='k2icwoz'), Comment(id='k2fh51k'), Comment(id='k2gm2vh'), Comment(id='k2elc7v'), Comment(id='k2e883r'), Comment(id='k2ic83z'), Comment(id='k2fines'), Comment(id='k2favnp'), Comment(id='k2fhff4'), Comment(id='k2n32do'), Comment(id='k2kee0e'), Comment(id='k2fwm1h'), Comment(id='k2f0p9g'), Comment(id='k2fq5co'), Comment(id='k2f1kxw'), Comment(id='k2ektxu'), Comment(id='k2iln36'), Comment(id='k2fx189'), Comment(id='k2h6dha'), Comment(id='k2ffot9'), Comment(id='k2ewxl4'), Comment(id='k2itmab'), Comment(id='k2l6euj'), Comment(id='k2ef3ho'), Comment(id='k2iqxs6'), Comment(id='k2ny2pp'), Comment(id='k2fe8uv'), Comment(id='k2f0phv'), Comment(id='k2fj7sg'), Comment(id='k2fdrhj'), Comment(id='k2fkm8h'), Comment(id='k2fqhgf'), Comment(id='k2ft3zk'), Comment(id='k2i28zm'), Comment(id='k2ewgjq'), Comment(id='k2jhm2h'), Comment(id='k2pxmhu'), Comment(id='k2jgx41'), Comment(id='k2gotm1'), Comment(id='k2ezvkr'), Comment(id='k2gxq6f'), Comment(id='k2e8tl1'), Comment(id='k2io7iz'), Comment(id='k2fxvie'), Comment(id='k2fct76'), Comment(id='k2fya8m'), Comment(id='k2f8m11'), Comment(id='k2fqozo'), Comment(id='k2jqv66'), Comment(id='k2fxdue'), Comment(id='k2h7koq'), Comment(id='k2eyxih'), Comment(id='k2iw9g2'), Comment(id='k2l8ai1'), Comment(id='k2ff5wz'), Comment(id='k2egnbe'), Comment(id='k2om41p'), Comment(id='k2f2egc'), Comment(id='k2is8g5'), Comment(id='k2ggnhk'), Comment(id='k2f3i2w'), Comment(id='k2f1ex2'), Comment(id='k3jutr2'), Comment(id='k2h2caq'), Comment(id='k2f15t8'), Comment(id='k2fc4mg'), Comment(id='k2e9j91'), Comment(id='k2eu86v'), Comment(id='k2iu4fy'), Comment(id='k2fzb4d'), Comment(id='k2gmfaf'), Comment(id='k2h9ijt'), Comment(id='k2nzifj'), Comment(id='k2k6p9m'), Comment(id='k2ffftw'), Comment(id='k3mj8y7'), Comment(id='k2f1eg8'), Comment(id='k2gy0y9'), Comment(id='k2gt49b'), Comment(id='k2e9x1t'), Comment(id='k2g94h7'), Comment(id='k2hqbyb'), Comment(id='k2hbw7x'), Comment(id='k2o0hx9'), Comment(id='k2fpxss'), Comment(id='k2gyd3v'), Comment(id='k2kpdtn'), Comment(id='k2ibzih'), Comment(id='k2keg4s'), Comment(id='k2kdx4c'), Comment(id='k2g0htq'), Comment(id='k2iat3d'), Comment(id='k2hnf2m'), Comment(id='k2n2343'), Comment(id='k2kox57'), Comment(id='k2g6tmd'), Comment(id='k2ip25v'), Comment(id='k2izttb'), Comment(id='k2n2nbn'), Comment(id='k2htnww'), Comment(id='k2j4qru'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
16ujm1g,Manu_Orobix,,2023-09-28 15:51:05+00:00,False,,False,False,True,False,/r/datascience/comments/16ujm1g/reinforcement_learning_in_automating_game_testing/,Reinforcement learning in automating game testing 🔥,"The role of **Reinforcement learning** in automating **game testing** is becoming increasingly crucial, making it more efficient and effective. Manual testing, while essential, is extremely **time-consuming and subject to human error.** 

Our **opensource** library [SheepRL](https://github.com/Eclectic-Sheep/sheeprl) 🐑 can be used to test whether the game dynamics is well defined: **what if a player can finish the game with just a few moves?** 🎮

This [video](https://x.com/orobix/status/1707403169523773930?s=20) shows that our agent (Kasumi, on the left) is able to win the game in the hardest modality by standing down and throwing kicks. 🥊

This can be helpful for a game developer to:

* understand where and how intervene **to achieve a more playful game**
* **predict and correct bugs early** in the game development process
* enhance the gaming experience and final **product quality**
* reduce time and resources spent on **debugging**.

The game has changed 🔥 and it is up to us to play it with (human + artificial) intelligence!

Thanks to [**u/DIAMBRA\_AIArena**](https://www.reddit.com/user/DIAMBRA_AIArena) for the video!

\---

❌ Are you interested in joining the project community? [Get in touch](https://github.com/Eclectic-Sheep/sheeprl) ❌

[SheepRL](https://github.com/Eclectic-Sheep/sheeprl) 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI

**Feel free to use it for your Artificial Intelligence projects**, and if you want to contribute, we are more than happy to accept your pull requests! ❤️

&#x200B;

https://preview.redd.it/yoy38vghp0rb1.png?width=6668&format=png&auto=webp&s=df5b3a881c81841a4f52617c68c057ffdb1ebeac",datascience,https://www.reddit.com/r/datascience/comments/16ujm1g/reinforcement_learning_in_automating_game_testing/,0,1,1.0,[]
16udszx,TimidHuman,,2023-09-28 11:46:28+00:00,False,,1695901773.0,False,True,False,/r/datascience/comments/16udszx/what_online_coursebooks_would_you_recommend_to/,What online course/books would you recommend to someone interested in getting into DS?,"As per title. I've a university degree in Information Systems but have been taking DA/ML mods, have built a couple of models myself for projects/internships which uses decision trees, random forest, logistic regression and so on.

I've basic python programming knowledge along with some OOP knowledge. Self-learned matplotlib/pandas/sklearn myself so I know the basic things but still not very comfortable in using lambda to process functions what not. Also, I'm not very well versed with data algorithms (not sure if it matters :/)

Have never really touched AI stuffs (took a module in uni which utilized tensorflow for image recognition and build a project to detect people with face masks on but that's about it)

Am interested in eventually becoming a data scientist in the future for my career, though I'm currently a data analyst more specialized in visualizing.

Looking for resources, be it on books about ML and what not so I can continue advancing my skills and eventually perhaps get a role as a data scientist. Would say that currently I'm quite rusty with my modelling skills (I still know the basic EDA/preprocessing/one-hot labelling and what not, though I would need to google for example codes and adapt to my problem at hand). Any form of other advices would be welcomed!

Currently on my list:

1. Python Data Science Handbook by Jake VanderPlas
2. “Python Machine Learning” by Sebastian Raschka and Vahid Mirjalili
3. Mastering Machine Learning Algorithms by Giuseppe Bonaccorso
4. 100 Days of Python by Angela Yu on Udemy",datascience,https://www.reddit.com/r/datascience/comments/16udszx/what_online_coursebooks_would_you_recommend_to/,3,2,1.0,"[Comment(id='k2kppsi'), Comment(id='k2ksf65'), Comment(id='k2l2h1a')]"
16ucam4,abhi9u,,2023-09-28 10:27:51+00:00,False,,False,False,False,False,/r/datascience/comments/16ucam4/an_analysis_of_deepminds_language_modeling_is/,An Analysis of DeepMind's 'Language Modeling Is Compression' Paper,,datascience,https://codeconfessions.substack.com/p/language-modeling-is-compression,0,2,1.0,[]
16u6e27,synthphreak,,2023-09-28 04:31:50+00:00,False,,1695876400.0,False,True,False,/r/datascience/comments/16u6e27/say_i_trained_an_autoencoder_why_is_that_useful/,Say I trained an autoencoder. Why is that useful? How can I use it?,"# The setup

I’m learning about autoencoders (for use in recommender systems specifically, if it matters). Whenever you read up on what autoencoder models are, the ELI5 usually goes something like this:

> Autoencoders are models which take some input, encode it into a lower dimensional form, then decode it back to reconstruct an approximation of its original form.

I understand that sentence, but I don’t understand why that is useful.

# My confusion

To me it sounds like an autoencoder is basically just an identity function, plus some error/noise. As if after training my model, I now have a tool which can do what…add distortion to an image? Why did I go to the trouble of training an entire neural network for something so trivial?

Clearly I am missing something fundamental. What are the applications exactly? How is a trained autoencoder useful, particularly for recommender systems?

# A speculative answer to my own question (confirmation/rejection appreciated)

All I can think of is this, and this is just a guess: Perhaps we train autoencoders not because we care about their output layer, but because we want their hidden layer?

On this view, it’s kinda like matrix decomposition. MD starts with some giant matrix of “observed” values, then finds two smaller matrices of “latent” values whose product approximates the original. These latent matrices encode lots of valuable info about the original matrix, but in a dense form that’s more efficient to work with. So after we have those dense matrices, we store them for downstream tasks. So MD is done solely to get our hands on those latent features.

Similarly, for NLP there are simple neural networks whose entire job is to learn static word embeddings. These embeddings can then drive downstream NLP tasks. Once our simple NN has learned them, we store them, after which we basically no longer need/use the NN.

So are autoencoders like this? That is, rather than create a model that we use over and over again because the output is useful, are they just vehicles for learning some latent representation of the input, and after learned, we can just discard the autoencoder model?

I hope this makes sense. Any thoughts appreciated.

**EDIT:** If autoencoders simply achieve functionally the same thing as MD through different means, why might someone choose one over the other? What are the practical considerations?",datascience,https://www.reddit.com/r/datascience/comments/16u6e27/say_i_trained_an_autoencoder_why_is_that_useful/,4,6,1.0,"[Comment(id='k2jdpy1'), Comment(id='k2jeo8t'), Comment(id='k2lcpvn'), Comment(id='k2laqb9')]"
16tgojm,Choweeez,,2023-09-27 10:15:59+00:00,False,,1696237913.0,False,True,False,/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/,What kind of algorithm do you use the most as a data science pro ?,"As a data science professional, what kind of tool / algorithm do you use the most today and what do you think will be used the most tomorrow ?Mainly concerned about classical ML / DL and other statistical tools to analyze data.

I  would like to work in data science. What I like is working with data,  building models and tweaking them to make the data ""speak"".

I started learning classical ML (with the book *Hands-on Machine Learning*).  But now I wonder what I should focus on: go on with classical ML, learn  DL or something else? What skills would be the more useful for a career  in data science?

I'm sorry if  this has been already asked ... I read the wiki and FAQ, and did some  search but didn't find what I was looking for.

&#x200B;

**EDIT:** thanks to everyone who replied, I was not expecting so many answers!  
I gathered the answers here: [https://www.reddit.com/r/datascience/comments/16xriok/quick\_review\_of\_most\_used\_algorithm\_answers/](https://www.reddit.com/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/)",datascience,https://www.reddit.com/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/,115,142,0.94,"[Comment(id='k2f0e0i'), Comment(id='k2f1cen'), Comment(id='k2forhb'), Comment(id='k2fnhot'), Comment(id='k2geby1'), Comment(id='k2fbiwm'), Comment(id='k2gkcf0'), Comment(id='k2feq90'), Comment(id='k2ge98y'), Comment(id='k2gsjr1'), Comment(id='k2f9rae'), Comment(id='k2fbypc'), Comment(id='k2h17ad'), Comment(id='k2facl8'), Comment(id='k2fsjwi'), Comment(id='k2fw5eb'), Comment(id='k2fzepo'), Comment(id='k2hcabu'), Comment(id='k2hpumb'), Comment(id='k2fc3p5'), Comment(id='k2fht9x'), Comment(id='k2foqto'), Comment(id='k2fxowe'), Comment(id='k2gnred'), Comment(id='k2jccyc'), Comment(id='k2jcjb2'), Comment(id='k2jlsh4'), Comment(id='k2eut3a'), Comment(id='k2f6jzo'), Comment(id='k2g8x28'), Comment(id='k2gxww8'), Comment(id='k2h41xn'), Comment(id='k2h9ha8'), Comment(id='k2h9yx3'), Comment(id='k2hajkq'), Comment(id='k2heltv'), Comment(id='k2hfqh1'), Comment(id='k2ialsz'), Comment(id='k2ibykx'), Comment(id='k2ivblx'), Comment(id='k2n0w62'), Comment(id='k2oym29'), Comment(id='k2evflr'), Comment(id='k2fps2e'), Comment(id='k2g5vhq'), Comment(id='k2fkoro'), Comment(id='k2hldum'), Comment(id='k2i8dbp'), Comment(id='k2ft3rh'), Comment(id='k2gzne3'), Comment(id='k2ff1bb'), Comment(id='k2jxz65'), Comment(id='k2k5xjx'), Comment(id='k2k6u6o'), Comment(id='k2mzzpq'), Comment(id='k2zois0'), Comment(id='k2gw1t7'), Comment(id='k2faqcj'), Comment(id='k2f2mpb'), Comment(id='k2k1p3u'), Comment(id='k2f30ry'), Comment(id='k2frr50'), Comment(id='k2hc20p'), Comment(id='k2gvxuy'), Comment(id='k2g0dzm'), Comment(id='k2mblos'), Comment(id='k2gvt1i'), Comment(id='k2fn7qz'), Comment(id='k2kgmzu'), Comment(id='k2ib3ln'), Comment(id='k2jt4va'), Comment(id='k2p3szg'), Comment(id='k2gw94y'), Comment(id='k2kril0'), Comment(id='k2fyjia'), Comment(id='k2krfjv'), Comment(id='k2f5bph'), Comment(id='k2f7efq'), Comment(id='k2fcb2e'), Comment(id='k2hu0os'), Comment(id='k2gxgv8'), Comment(id='k2i9219'), Comment(id='k2l0th3'), Comment(id='k2kitzy'), Comment(id='k2kbued'), Comment(id='k2pfswj'), Comment(id='k2gy401'), Comment(id='k2kv3ft'), Comment(id='k2g33x7'), Comment(id='k2gfjpd'), Comment(id='k2isgyp'), Comment(id='k2hsh07'), Comment(id='k2ktvu0'), Comment(id='k2merg7'), Comment(id='k2fuoqv'), Comment(id='k2fzy9h'), Comment(id='k2g9w6x'), Comment(id='k2fxhud'), Comment(id='k2kkbng'), Comment(id='k2h155s'), Comment(id='k2p3fdq'), Comment(id='k2ikjmr'), Comment(id='k2mbtfq'), Comment(id='k2oc8o1'), Comment(id='k2gwgs7'), Comment(id='k2fzg6n'), Comment(id='k2lk7mf'), Comment(id='k2iy9z5'), Comment(id='k2oh9ad'), Comment(id='k2gekdm'), Comment(id='k2g4jk0'), Comment(id='k2g53na'), Comment(id='k2izrao'), Comment(id='k2gfpmh'), Comment(id='k2j782x')]"
16tsf50,FoxWithAPumpkin,,2023-09-27 18:45:03+00:00,False,,False,False,True,False,/r/datascience/comments/16tsf50/really_shitty_coding_skills/,Really shitty coding skills,"So I am currently going through university course on data analysis and I have been assigned a labwork. Labwork consists of 5 parts and part one is to do an input data analysis, do some descriptive summary statistics, do some plots, make a few manipulations to the data where needed. So descriptive summary statistics part requires me to do a specific data quality report, more specifically it asks me to provide [count, missing_value_%, mode, mode_freq, mode_%, 2nd_mode, 2nd_mode_freq, 2nd_mode_%] for categorical features. 

So as just a default pd.describe() was not enough for it, i did the whole thing manually using .agg() and combining default aggregation functions with my custom functions. This is where I got stuck.

I spent the whole day trying to write a function that would calculate the modes for me and would work together with other functions inside .agg(). In the end I failed and just decided to do a separate mode dataframe that I later just concatenate to the output of df.agg(). 

How do I actually learn all these technical and trivial stuff? Manipulating dataframes, series, permuting them the way I want (also, the same applies to all other “small stuff” in coding - manipulating strings, lists/dicts, applying functions to dataframes and so on)? Because I feel like actual coding basics in Python is what stops me from doing any actual progress…",datascience,https://www.reddit.com/r/datascience/comments/16tsf50/really_shitty_coding_skills/,21,29,0.89,"[Comment(id='k2hed0o'), Comment(id='k2hqqk1'), Comment(id='k2hn37o'), Comment(id='k2ijqqc'), Comment(id='k2jfjrv'), Comment(id='k2ksa1a'), Comment(id='k2i5quv'), Comment(id='k2i4ow3'), Comment(id='k2ia2t2'), Comment(id='k2jrgxy'), Comment(id='k2kgwpn'), Comment(id='k2ky196'), Comment(id='k2hnany'), Comment(id='k2ik8pl'), Comment(id='k2k2vo7'), Comment(id='k2ila2p'), Comment(id='k2kga21'), Comment(id='k2irk0x'), Comment(id='k2j0o0c'), Comment(id='k2iqi4c'), Comment(id='k2lequt')]"
16uekmp,Technical-Window-634,,2023-09-28 12:22:15+00:00,False,,False,False,True,False,/r/datascience/comments/16uekmp/help_with_data_disparity/,Help with data disparity,"Hi everyone! This is my first post here. Sorry beforehand if my English isn't good, I'm not native. Also sorry if this isn't the appropriate label for the post.

I'm trying to predict financial frauds using xgboost on a big data set (4m rows after some filtering) with an old PC (Ryzen AMD 6300). The proportion is 10k fraud transaction vs 4m non fraud transaction. Is it right (and acceptable for a challenge) to do both taking a smaller sample for training, while also using smote to increase the rate of frauds? The first run of xgboost I was able to make had a very low precision score. I'm open to suggestions as well. Thanks beforehand!",datascience,https://www.reddit.com/r/datascience/comments/16uekmp/help_with_data_disparity/,5,1,1.0,"[Comment(id='k2kl1ij'), Comment(id='k2klyzy'), Comment(id='k2kn62k'), Comment(id='k2knvu9'), Comment(id='k2kq153')]"
16tahis,Excellent_Cost170,,2023-09-27 04:15:53+00:00,False,,False,False,False,False,/r/datascience/comments/16tahis/anyone_facing_this_in_your_organization/,Anyone facing this in your organization?,,datascience,https://i.redd.it/ct3p42qt4qqb1.jpg,36,361,0.97,"[Comment(id='k2e01zl'), Comment(id='k2ea0z7'), Comment(id='k2e5u65'), Comment(id='k2ehtc3'), Comment(id='k2gwre7'), Comment(id='k2f911z'), Comment(id='k2f42ah'), Comment(id='k2gawyj'), Comment(id='k2fhw8f'), Comment(id='k2gvizm'), Comment(id='k2hcb67'), Comment(id='k2k0lm0'), Comment(id='k2eqqh6'), Comment(id='k2ei2mw'), Comment(id='k2faokl'), Comment(id='k2fd0qj'), Comment(id='k2gdl1o'), Comment(id='k2h0dyi'), Comment(id='k2hrcqy'), Comment(id='k2i2elv'), Comment(id='k2kwzv1'), Comment(id='k2l26fj'), Comment(id='k2ed12l'), Comment(id='k2epk30'), Comment(id='k2f8otq'), Comment(id='k2ebwoi'), Comment(id='k2etfsd'), Comment(id='k2fiftk'), Comment(id='k2gvnv7'), Comment(id='k2kbbnn'), Comment(id='k2gx5ik'), Comment(id='k2et1wc'), Comment(id='k2eqm3a'), Comment(id='k2eeei8'), Comment(id='k2ka0ch')]"
16ue1kp,juspreet51,,2023-09-28 11:57:55+00:00,False,,False,False,True,False,/r/datascience/comments/16ue1kp/what_all_visualization_and_insights_could_be_part/,What all visualization and insights could be part of Twitter Sentiment Analysis?,"Other than the usual Word-cloud, what all EDA can I prepare on a tweeter dataset? I need to present some pointers, as on what all could be taken out in the Sentiment Analysis. All ideas are welcome",datascience,https://www.reddit.com/r/datascience/comments/16ue1kp/what_all_visualization_and_insights_could_be_part/,1,1,1.0,[Comment(id='k2l53bt')]
16ud8ql,make_people_naked,,2023-09-28 11:18:48+00:00,False,,False,False,True,False,/r/datascience/comments/16ud8ql/hello_guys_i_have_just_built_a_wine_quality/,"Hello guys I have just built a wine quality prediction tool, here is my GitHub profile..","I just switched back into my fields and looking to build next 30 days end to end ml project and one LLm models. In this community we have good programmes who have good experience in this field can you guide me what exactly company demands from data science like what they should know and all..

Please take a look at my GitHub profile and please share your feedback..
Your advices will be very useful for me


GitHub -

https://github.com/codedestructed007/Wine_Quality_prediction


Thanks a lot friends/brothers..👍",datascience,https://www.reddit.com/r/datascience/comments/16ud8ql/hello_guys_i_have_just_built_a_wine_quality/,0,1,0.6,[]
16ucj3h,Data_Nerd1979,,2023-09-28 10:40:54+00:00,False,,1695898580.0,False,True,False,/r/datascience/comments/16ucj3h/what_is_the_your_top_open_source_llms/,What is the your top Open Source LLMs?,"For me it's Llama 2.

Llama 2's training data is vast and varied, making it a significant advancement over its predecessor.",datascience,https://www.reddit.com/r/datascience/comments/16ucj3h/what_is_the_your_top_open_source_llms/,5,0,0.45,"[Comment(id='k2k6v86'), Comment(id='k2kwyfw'), Comment(id='k2lzzf2'), Comment(id='k2kxr4v'), Comment(id='k2kz4y2')]"
16u6ps0,synthphreak,,2023-09-28 04:49:46+00:00,False,,False,False,True,False,/r/datascience/comments/16u6ps0/big_rec_sys_interview_coming_up_what_topics_to/,Big rec sys interview coming up. What topics to prepare?,Applied for an engineering-heavy role. Got an interview that will focus on recommender systems. Don’t know too much about them TBH. What are the critical topics and competencies that I should be familiar with heading into the interview?,datascience,https://www.reddit.com/r/datascience/comments/16u6ps0/big_rec_sys_interview_coming_up_what_topics_to/,1,2,1.0,[Comment(id='k2kf5as')]
16u9nrv,WadeEffingWilson,,2023-09-28 07:43:47+00:00,False,,False,False,True,False,/r/datascience/comments/16u9nrv/can_power_spectral_density_be_used_to_detect/,Can power spectral density be used to detect autocorrelation and candidates for seasonal values in a time series?,"BLUF: I have very little knowledge when it comes to signal processing and analysis, so please don't beat me up too bad if I misunderstood something, even if it's fundamental.

I work a lot with time series data, almost all of it containing seasonal and trend components. Due to that, I've grown familiar with things like P/ACF plots, ADF and KPSS tests, STL and ETS decompositions, AR/MA models, and Ljung-Box (and Box-Pierce) tests. I can identify seasonal values to use for the decompositions by applying domain knowledge and outputs from ACF plots. After decomposing, I usually run the residuals through an ACF plot again to see if there are lingering autocorrelations.

I created a custom function awhile back that takes in a time series (or residuals) and uses Welch's method to estimate the power spectral densities. It's my understanding that the dominant frequencies identified in the plot are the most prevalent (by power) frequencies in the time series and can be used as seasonal parameter arguments passed to the decomposition algorithm (eg, STL, ETS).

I have to adjust the sampling rate parameter in the Welch function since it assumes the sampling is performed X number of times per second. If my time bins are hourly, I change it to 1/3600 so that it gives back appropriate frequencies.

If I understand correctly, dominant frequencies are well above the noise floor but when each dominant frequency is selected and removed from the time series, the next most dominant frequency is closer to that noise floor, bringing it closer to the top. Would I be mistaken if I used this process to test for and indicate that white noise has been achieved (ie, no serial correlations)? I would also combine it with output from an ACF plot and a Ljung-Box test, just to be sure.

Also, will this process capture incomplete, intermediate frequencies? What I mean is, for example, if I have a time series of, say 10,000 observations, which show a consistent frequency all the way across but somewhere in the middle, another different frequency appears alongside that lasts for only 3,000 observations before it disappears, will that transient frequency be detected, even though it isn't present throughout the entire time series? Does that make sense?

I just need a sanity check to make sure I'm not all the way out in left field (or even outside the stadium, in the parking lot). Please let me know if the entire thing is wrong and I'm a moron or, in the case that I've messed up but the premise is valid, let me know where I need to revisit.

Hopefully this makes sense.",datascience,https://www.reddit.com/r/datascience/comments/16u9nrv/can_power_spectral_density_be_used_to_detect/,2,0,0.5,"[Comment(id='k2ophwy'), Comment(id='k2rqs5g')]"
16u45ri,JTcyto,,2023-09-28 02:38:01+00:00,False,,False,False,True,False,/r/datascience/comments/16u45ri/how_to_properly_sample_data_size_down/,How to properly sample data size down?,"I have dataset that is computationally inefficient to run due to size/algorithm. I could choose a different model but this is a speculative project based around the model. The model works great on small to mid-size data <100,000 obs. But the dataset I have is a couple million, which I think would take multiple hours to run. I have been trying to figure out sampling strategies, but haven’t been able to clearly figure out if down-sampling is an okay approach. Any thoughts would be great!",datascience,https://www.reddit.com/r/datascience/comments/16u45ri/how_to_properly_sample_data_size_down/,3,2,1.0,"[Comment(id='k2k3d4c'), Comment(id='k2izwrm'), Comment(id='k2x5j0h')]"
16tpji2,Old_Cartographer_586,,2023-09-27 16:43:55+00:00,False,,False,False,True,False,/r/datascience/comments/16tpji2/should_i_complete_certs_while_looking_for_a_job/,Should I complete certs while looking for a job?,"So, I am one of those individuals who has been very unlucky in the job market since graduating in Sept 2022. I do not come from the most traditional background for data science (MSc in Physics), so, I am asking should I go on Coursera, Udemy, etc... and see if there are any data science/analyst certs I should consider completing to make myself stand out or if I should just keep applying.

I will say, I would prefer completing certs on Coursera as due to my situation I feel confident that I can complete the course during the courses free trial. ",datascience,https://www.reddit.com/r/datascience/comments/16tpji2/should_i_complete_certs_while_looking_for_a_job/,26,11,0.77,"[Comment(id='k2gv76h'), Comment(id='k2if6d1'), Comment(id='k2griqr'), Comment(id='k2gs2e1'), Comment(id='k2js2i8'), Comment(id='k47oft9'), Comment(id='k2kh792'), Comment(id='k2gzpe9'), Comment(id='k2hlgp9'), Comment(id='k2i14x9'), Comment(id='k2hnnal'), Comment(id='k2hok2c'), Comment(id='k2i23q1'), Comment(id='k2i24vv'), Comment(id='k47tldo'), Comment(id='k2hr7vs'), Comment(id='k2i2hg5'), Comment(id='k2ild41'), Comment(id='k47ue3k'), Comment(id='k2znc90'), Comment(id='k2ia37x'), Comment(id='k2k2utz'), Comment(id='k2j4db3'), Comment(id='k2zpbrb'), Comment(id='k49r8vk'), Comment(id='k4a1gr4')]"
16ukxy1,Excellent_Cost170,,2023-09-28 16:43:03+00:00,False,,False,False,True,False,/r/datascience/comments/16ukxy1/tesla_trying_to_screw_desperate_people/,Tesla trying to screw desperate people,"This a direct contract hire job post from Tesla not from third party staffing company. Insane 

https://preview.redd.it/9r5v5z2iy0rb1.png?width=589&format=png&auto=webp&s=2e6bdacd9141bdcfe2fc4a7d5810f6e27f086ef5",datascience,https://www.reddit.com/r/datascience/comments/16ukxy1/tesla_trying_to_screw_desperate_people/,28,0,0.39,"[Comment(id='k2ll75m'), Comment(id='k2llm5j'), Comment(id='k2louyv'), Comment(id='k2lnpkg'), Comment(id='k2ll6q1'), Comment(id='k2lp7p0'), Comment(id='k2lx70d'), Comment(id='k2lkk8j'), Comment(id='k2lo1v3'), Comment(id='k2lx2pv'), Comment(id='k2mhvqf'), Comment(id='k2olx36'), Comment(id='k49pcj4'), Comment(id='k2lmpww'), Comment(id='k2n65bi'), Comment(id='k2lpggu'), Comment(id='k2lm7dx'), Comment(id='k2ln7zj'), Comment(id='k2lzmqc'), Comment(id='k2lxmr8'), Comment(id='k2lpx5s'), Comment(id='k2luvsy'), Comment(id='k2lvtrj'), Comment(id='k2m8p5d'), Comment(id='k34i248'), Comment(id='k2ooiz6'), Comment(id='k35pxxy'), Comment(id='k35uwt4')]"
16twe33,shopchoffee,,2023-09-27 21:18:32+00:00,False,,False,False,True,False,/r/datascience/comments/16twe33/i_made_an_chocolate_and_coffee_website_focused_on/,I made an chocolate and coffee website focused on data transparency! Check out Choffee (feedback appreciated!),"Hey data wranglers!

My friend and I launched a new site focused on data transparent e-commerce — [Choffee](https://shopchoffee.com/)! Please check it out and share your feedback! A core mission of ours is impact transparency -- we aggregate order data and visualize our customers impact on [small business](https://shopchoffee.com/impact-on-small-businesses/) on [farms](https://shopchoffee.com/farming-impact/) through Tableau dashboards. A few things we publish on our site are:

1. Average price per ounce of Coffee/Chocolate by farming country
2. Sales by women owned vs male owned businesses
3. Sales distribution of location of small business

**Why is this important?** Data is one of the most powerful assets we own. Companies collect it all the time and sometimes sell it for billions! Imagine how powerful data would be if we could democratize it. That’s why we built Choffee — to share the data we capture back to our customers so they’re empowered to make data-driven shopping decisions and support businesses that share your values. 

**About us —** I'm an ex-actuarial analyst and a data scientist of 4 years and my friend has been a site engineer for 6 years. We’ve noticed that every company collects data and creates dashboards to track insights internally, however so few companies democratize data back to the consumer. We figured its about that that changes! We currently only sell chocolates & coffee on our business, however we plan to expand to broader product categories as we scale.

If you think this is an interesting idea, please consider buying some bars or coffee!

Shop at [shopchoffee.com](https://shopchoffee.com)",datascience,https://www.reddit.com/r/datascience/comments/16twe33/i_made_an_chocolate_and_coffee_website_focused_on/,2,3,0.81,"[Comment(id='k2j8w5r'), Comment(id='k2j9b7g')]"
16uffmd,misscherry1,,2023-09-28 13:00:43+00:00,False,,False,False,True,False,/r/datascience/comments/16uffmd/future_trends_in_data_science_salaries_and_what/,Future trends in Data Science salaries and what to expect in the coming years,"In the ever-evolving world of data science, staying ahead of the curve is essential not only in terms of skills but also in understanding the future landscape of compensation. As the field continues to expand and mature, the future of data science salaries I believe is a topic of great interest not only for me but for all of you as well. 

This is why I decided to look though future trends in Data Science salaries so you don’t have to.  


**Predicting Trends**

Several factors are poised to influence the trajectory of data science salaries in the coming years. First and foremost, the rapid pace of technological advancements is expected to have a profound impact. The increasing use of artificial intelligence (AI), machine learning (ML), and data analytics tools is likely to drive higher demand for skilled data scientists, resulting in competitive salary offerings.  


**Market Demand**

Market demand plays a pivotal role in shaping salaries. As more industries recognize the value of data-driven decision-making, data scientists are becoming indispensable assets. Financial services, healthcare, and e-commerce are anticipated to be among the sectors offering attractive compensation packages to data professionals.  


**Industry Growth**

The growth of industries such as FinTech, HealthTech, and InsurTech is projected to create specialized roles in data science. These niche positions may command higher salaries due to their specialized knowledge requirements and the potential to deliver significant business value.  


To provide a glimpse of the current landscape, here is a table showcasing different data science job titles and their approximate average salaries:  


&#x200B;

|**Data Science Job Title**|**Average Salary (Annual)**|
|:-|:-|
|Data Analyst|$65,000 - $95,000|
|Machine Learning Engineer|$90,000 - $130,000|
|Data Scientist|$100,000 - $150,000|
|Data Engineer|$95,000 - $140,000|
|Business Intelligence Analyst|$70,000 - $100,000|
|AI Research Scientist|$120,000 - $180,000|
|Data Consultant|$80,000 - $120,000|
|Big Data Architect|$110,000 - $160,000|
|Statistician|$70,000 - $110,000|
|Natural Language Processing (NLP) Engineer|$100,000 - $150,000+|
|Data Science Manager|$120,000 - $180,000+|

&#x200B;

**How to get into Data Science?**

For those looking to enter the field of data science, it's crucial to start with a strong educational foundation. Many aspiring data scientists are now considering intensive data science bootcamps as a more focused and efficient way to gain skills. This [comparison table ](https://docs.google.com/spreadsheets/d/1few9dA8toTIA04MYLmvYDFCQpFbEv32jGLwBWquojDc/edit#gid=0)shows different bootcamp alternatives that could help you find out what they can offer and make the best decision for your needs. Another option is a bachelor's degree in a related field like computer science, mathematics, or statistics. You can find the best universities to finish your bachelor’s degree in DS [here](https://www.topuniversities.com/university-rankings/university-subject-rankings/2023/data-science).  


Moreover, learning relevant tools and languages, gaining practical experience through internships or entry-level positions, specializing in areas like machine learning or data engineering, building a portfolio of personal projects, and networking with professionals in the field are all key steps to successfully embark on a career in data science.

In conclusion, the future of data science salaries promises to be exciting and rewarding. With continued technological advancements, growing market demand, and the diversification of industries seeking data expertise, data scientists can expect a dynamic and prosperous future. Staying informed about these trends will be crucial for those looking to thrive in this data-driven era.",datascience,https://www.reddit.com/r/datascience/comments/16uffmd/future_trends_in_data_science_salaries_and_what/,7,0,0.39,"[Comment(id='k2kmfpv'), Comment(id='k2km9nl'), Comment(id='k2knolp'), Comment(id='k2oqdlj'), Comment(id='k2kq1y9'), Comment(id='k2lgfyr'), Comment(id='k2kyemf')]"
16u5pk4,Rahul_devil,,2023-09-28 03:55:56+00:00,False,,False,False,True,False,/r/datascience/comments/16u5pk4/masters_in_which_topic_will_be_helpful_for/,Masters in which topic will be helpful for getting data science job.,"I am currently pursuing my BE in computer science and I want to be a data scientist and I think doing a master's will boost my chances in getting a Data science job.

So I want to know doing masters on which topic would be better 
1. Mathematics
2. Statistics
3. Computer science and related.",datascience,https://www.reddit.com/r/datascience/comments/16u5pk4/masters_in_which_topic_will_be_helpful_for/,4,1,1.0,"[Comment(id='k2js6h6'), Comment(id='k32m1qs'), Comment(id='k2l7r7a'), Comment(id='k2q5ej1')]"
16u038j,prtkkr,,2023-09-27 23:41:21+00:00,False,,False,False,True,False,/r/datascience/comments/16u038j/pdf_scraping/,PDF Scraping,"I apologize if this question has been asked before. I am looking for recommendations on how to extract unstructured data from PDF documents. In my current project, I have used Python libraries such as Pypdfium2, Pdfplumber – py, camelot, and Tabula – py to extract various sections from two different types of PDF reports. However, I now have many different PDF formats that need to be extracted in a structured format. Are there any paid tools that would be more effective than developing a custom solution? 

Has anyone tried using LLM models for PDF extraction?  

Is anyone using Azure AI Document Intelligence in production for such tasks?",datascience,https://www.reddit.com/r/datascience/comments/16u038j/pdf_scraping/,2,2,0.75,[Comment(id='k2k5f5p')]
16u0109,dev0martin0,,2023-09-27 23:38:45+00:00,False,,False,False,True,False,/r/datascience/comments/16u0109/database_management_vs_statistical_analysis/,Database Management vs Statistical Analysis,"Hey, working off a deleted post from yesterday.

My main question is: 

My current entry level job is focused on DBM and a lot of SQL. I am obtaining a MSDS this summer and work heavily with statistical analysis. Is it too much of a reach to think I can find some type of tru analysis entry wise? Or should I stop being a b*tch and work my very low paying DBManagement job until graduation. Are the two forever intertwined? 

Thanks all,

P.S. Please be kind as this is just meant as a discussion for a 24 y/o going through an identity crisis.",datascience,https://www.reddit.com/r/datascience/comments/16u0109/database_management_vs_statistical_analysis/,1,2,0.75,[Comment(id='k2jaz9p')]
16trg4f,proffesaur,,2023-09-27 17:57:47+00:00,False,,False,False,True,False,/r/datascience/comments/16trg4f/first_job/,First job,"Just got my first offer, still in university currently but offered 84k. Smaller company, where I would be the sole data person, is this crazy? Any red flags to look out for?",datascience,https://www.reddit.com/r/datascience/comments/16trg4f/first_job/,6,5,0.86,"[Comment(id='k2jbwl3'), Comment(id='k2jvcji'), Comment(id='k2gt366'), Comment(id='k2hbn8f'), Comment(id='k2k7vih'), Comment(id='k31chnk')]"
16u42p0,James_c7,,2023-09-28 02:34:10+00:00,False,,False,False,True,False,/r/datascience/comments/16u42p0/title_change_question/,Title change question,"Is Changing a job title on a resume ok? 

I worked at a company for a year and a half as a data analyst (I left the job 2 years ago) but my responsibilities were basically a data scientist (data modeling, a lot of bayesian modeling, built out experimentation, even did some applied science work). I did really well there but decided to leave because of title. right after I left they decided to re-level everyone from data analysts to data scientists.

I was talking to a recruiter today and noticed that he wasn’t counting those years of experience. Should I change my resume and LinkedIn to say I was a data scientist instead of a data analyst for that job?",datascience,https://www.reddit.com/r/datascience/comments/16u42p0/title_change_question/,1,1,0.67,[Comment(id='k2j7b5t')]
16txqky,-curious-cheese-,,2023-09-27 22:09:01+00:00,False,,False,False,True,False,/r/datascience/comments/16txqky/how_long_does_a_typical_project_take_you_to/,How long does a typical project take you to complete?,"I just started as a data analyst. I have two projects, and I am overwhelmed by the deadlines. I am wondering if the deadlines are normal or if I am a slow worker. How long would these projects take you?

1.  About 3000 observations with 34 variables regarding athletes from around 25 different teams and about 15 categories of financial revenue the athletes made over 2 years. Each athlete may have multiple observations. The data is mostly clean but had to be checked for errors because there were a few incorrect values. 

The goal is to recreate an excel workbook summarizing the revenue by sport, type of revenue, and year. The workbook has a sheet for each year summarizing each type of revenue by each team, a sheet for each team each year summarizing each type of revenue, and a few different various summary pages (such as a summary of athletes with no revenue). Someone made this workbook years ago, and it references another workbook I don’t have access to.

2.  About 500 observations with 25 variables each containing survey responses completed by individuals from different groups of stakeholders. Each responder has only one observation, but most of them are included in multiple stakeholder groups. The data was not clean, and the majority of the responses were long form written answers. The goal is to create a short written report and visualizations summarizing the categories of stakeholders that voted, how category voted, how many submitted inappropriate votes, the most common user-written responses, and the trends in how voters answered questions with fixed responses (weighted based on the categories of stakeholder the voter belongs to).

I hope this is a good enough description of the projects!",datascience,https://www.reddit.com/r/datascience/comments/16txqky/how_long_does_a_typical_project_take_you_to/,2,2,0.75,"[Comment(id='k2jf802'), Comment(id='k2k6uu9')]"
16tsmmy,SpiritualCurve9164,,2023-09-27 18:53:37+00:00,False,,False,False,True,False,/r/datascience/comments/16tsmmy/what_ds_experience_to_seek_to_set_up_for/,What DS experience to seek to set up for contracting later in life?,"I am UK Data Scientist (31F), looking to switch to part time contracting at around 35 to fit in family. I have 3-4 years ahead of hard work and want to build the right skills while work still is my #1 priority.

**Role:** currently a Staff Data Scientist at London scale up with £120k total comp. I do a lot of mentoring and lead multiple projects accross the business. I think I'd be targetting 50% hours for 50% pay as contractor.

**Experience**: 8y of python, spark, most query languages, NLP, Clustering, Information retrieval. I am better Data Scientist than Engineer, but have done both in the past. Happy to pick up new domain expertise/langauges when needed. 

**Questions:**

What specific DS knowlede suits for contracting type roles? 

What type of roles are in demand?

What to look out for? Does overall plan seem realistic?",datascience,https://www.reddit.com/r/datascience/comments/16tsmmy/what_ds_experience_to_seek_to_set_up_for/,0,3,1.0,[]
16tytm8,Gooooot,,2023-09-27 22:50:06+00:00,False,,False,False,True,False,/r/datascience/comments/16tytm8/analytics_for_an_energy_company/,Analytics for an Energy company,"Hi, 

I'm looking for guidance and support in my career as a Data Analyst in the energy sector. I'm currently a ""data analyst"" for roughly two years now. I put data analyst in brackets because I feel like a fraud as I haven't done any hard analysis nor do I feel qualified to be a analyst.

For context, I graduated from a non-Stem background but my degree included statistics. I had no idea what I wanted to do after university but fell into digital marketing. I worked as a digital analyst for 2 years helping clients set up and run their marketing campaigns using a data-driven approach - this is something that fulfilled me. However, I didn't like the marketing side of things and only the data side (running analysis on Excel, visualising the data with BI tools and providing insights). As I pivoted towards the data analysis career path, I joined the public sector for a year to hone my skills but that turned out to be a waste of time as I was just pulling data from their propriety software, running macros and producing PowerPoint slides. I had a lot of spare time during that time and proceeded to learn SQL/Python to up-skill, hoping to use my title to get a better job, which I did. 

Now, I'm in the energy sector, which is where I aspire to grow my career. The work is interesting and the people around me are really smart. I want to add as much value to my team so I've started producing automated dashboards to help visualise the operations/finance side of things. I've asked my manager how I can help her but she doesn't have any clue. She wants me to decide how I approach my job so I've tried leaning on other people asking them what they're working on but none of them applies to my job. 

So my question to you is: people who work in the energy sector, what kind do data analysis do you do? How do you add value to the team and where do you start searching for the datasets to produce analysis?",datascience,https://www.reddit.com/r/datascience/comments/16tytm8/analytics_for_an_energy_company/,1,0,0.5,[Comment(id='k2ipab3')]
16surfy,valkaress,,2023-09-26 17:50:21+00:00,False,,False,False,True,False,/r/datascience/comments/16surfy/is_having_a_fake_data_scientist_title_good_bad_or/,"Is having a fake Data Scientist title good, bad, or neutral?","My title is Senior Data Scientist, but I think most people here would agree that my actual job is probably like senior data analyst or something. Basically, I build slick dashboards for our client-facing people to find or keep clients. I use Python, Tableau, and SQL frequently, but that's about it.

What I'm wondering though is, if it comes a time when I decide to search for a similar role in a different company, what would this fake title do to my resume?

Would it be a good thing, perhaps because most hiring managers would prefer reading that over reading something like ""Data Analyst"" or whatever?

Or would it be a bad thing, perhaps because similar jobs would treat me as being overqualified and too expensive? And I would end up only being qualified for similar ""fake data scientist"" roles?",datascience,https://www.reddit.com/r/datascience/comments/16surfy/is_having_a_fake_data_scientist_title_good_bad_or/,102,173,0.91,"[Comment(id='k2bd4la'), Comment(id='k2bk3m2'), Comment(id='k2bcoa2'), Comment(id='k2c1fgb'), Comment(id='k2bqssa'), Comment(id='k2c3kee'), Comment(id='k2bo5kx'), Comment(id='k2c061i'), Comment(id='k2cpl39'), Comment(id='k2c4qg4'), Comment(id='k2cxnvj'), Comment(id='k2bkzq4'), Comment(id='k2bltuh'), Comment(id='k2dvgck'), Comment(id='k2c0y39'), Comment(id='k2cmt2n'), Comment(id='k2d6tij'), Comment(id='k2dga18'), Comment(id='k2dhshx'), Comment(id='k2dmgxr'), Comment(id='k2dmijl'), Comment(id='k2duc5m'), Comment(id='k2dydc8'), Comment(id='k2e46xe'), Comment(id='k2eixh2'), Comment(id='k2ev4ch'), Comment(id='k2eyz8j'), Comment(id='k2fdwxt'), Comment(id='k2grqri'), Comment(id='k2bgumr'), Comment(id='k2byxwo'), Comment(id='k2cdwts'), Comment(id='k2bscoe'), Comment(id='k2gja3e'), Comment(id='k2bzyii'), Comment(id='k2by633'), Comment(id='k2ds1xo'), Comment(id='k2bgi5w'), Comment(id='k2bfeds'), Comment(id='k2ed6yu'), Comment(id='k2bua59'), Comment(id='k2c4j8v'), Comment(id='k2bmlg3'), Comment(id='k2c0jhg'), Comment(id='k2bwv30'), Comment(id='k2c44mg'), Comment(id='k2buvhp'), Comment(id='k2ckx3z'), Comment(id='k2cp5xt'), Comment(id='k2cvqto'), Comment(id='k2cluvg'), Comment(id='k2cxaq2'), Comment(id='k2bincp'), Comment(id='k2bhscw'), Comment(id='k2deb46'), Comment(id='k2caf54'), Comment(id='k2bfr97'), Comment(id='k2c65l4'), Comment(id='k2bvlba'), Comment(id='k2cdotw'), Comment(id='k2d3y80'), Comment(id='k2cajtl'), Comment(id='k2cno1y'), Comment(id='k2d2zqb'), Comment(id='k2d4azs'), Comment(id='k2bj27l'), Comment(id='k2bk4dy'), Comment(id='k2c8lfz'), Comment(id='k2csqpp'), Comment(id='k2ca7ea'), Comment(id='k2h6ysr'), Comment(id='k2cjgdo'), Comment(id='k2bg7ll'), Comment(id='k2bo40c'), Comment(id='k2cko6c'), Comment(id='k2cfqrf'), Comment(id='k2c0pp8'), Comment(id='k2bzpck'), Comment(id='k2gabcv'), Comment(id='k2ccdy2'), Comment(id='k2dgfst'), Comment(id='k2coaav'), Comment(id='k2cdqq2'), Comment(id='k2cprcs'), Comment(id='k2drop3'), Comment(id='k2biwyr'), Comment(id='k2birkz'), Comment(id='k2bore7'), Comment(id='k2bsioq'), Comment(id='k2d3ryn'), Comment(id='k2dlp09'), Comment(id='k2e704y'), Comment(id='k2cvlgw'), Comment(id='k2by1vt'), Comment(id='k2c4ams'), Comment(id='k2doghf'), Comment(id='k2drxdp'), Comment(id='k2dl2vd'), Comment(id='k2dulmg'), Comment(id='k2dvoit'), Comment(id='k2egljd')]"
16tx5v4,Material_Shoe_4334,,2023-09-27 21:47:37+00:00,False,,False,False,True,False,/r/datascience/comments/16tx5v4/are_there_any_datasets_with_frontal_footage_of/,Are there any datasets with frontal footage of cars on roads/highways?,This is for my seatbelt fastness detection project. I can't really find any datasets or just even regular YouTube videos of cars with drivers (even barely) visible,datascience,https://www.reddit.com/r/datascience/comments/16tx5v4/are_there_any_datasets_with_frontal_footage_of/,6,1,1.0,"[Comment(id='k2ju2lg'), Comment(id='k2l8e55'), Comment(id='k2l8vhd'), Comment(id='k2l8twh'), Comment(id='k2lc1ea'), Comment(id='k2lkitv'), Comment(id='k2lln0g')]"
16twyc0,Rtktts,,2023-09-27 21:39:57+00:00,False,,False,False,True,False,/r/datascience/comments/16twyc0/data_projects_in_production/,Data projects in production,"Disclaimer: I am a software dev.

I have a question about how data projects are build for production use.

I understand why data scientist use Python and Pandas a lot for their exploratory work and research.

But when we are talking about deploying data pipelines or other software which is suppose to run for a few years, these Python libs do not seem to be the right choice, because they do not care about backwards compatibility. Yet in the wild I see a lot of production pipelines which are completely written in pandas. 

Same issue in the team I just joined. Tons of pandas code which we cannot update anymore because even a minor version update could break everything.

Another issue I see is that these pipelines are build without any regard to encapsulation or abstraction. Everything is just glued together directly. But they have the same issue any software system has and why the concept of microservices are a thing in software development for years. Any change is a huge mess because these pipelines are big monoliths.

So I guess my questions are: How do you build your production pipelines? Is it normal to use pandas in those pipelines? Do you have any issues with it? What about microservices?",datascience,https://www.reddit.com/r/datascience/comments/16twyc0/data_projects_in_production/,3,1,1.0,"[Comment(id='k2j1pkx'), Comment(id='k2kvyov'), Comment(id='k2mw93q')]"
16tpsvq,Roua_Rejeb,,2023-09-27 16:54:01+00:00,False,,False,False,True,False,/r/datascience/comments/16tpsvq/kaggle_data_visualization_certificate/,Kaggle Data Visualization certificate," How can I add a dataset in Kaggle? I am currently working on the data visualization tutorial and I can not finish the final project because I cannot find the ""add data' button. Is anyone facing the same problem? How to fix it? thank you in advance.",datascience,https://www.reddit.com/r/datascience/comments/16tpsvq/kaggle_data_visualization_certificate/,0,2,1.0,[]
16ti2vx,Hamdi_bks,,2023-09-27 11:31:58+00:00,False,,1695816398.0,False,True,False,/r/datascience/comments/16ti2vx/regression_vs_classification_90k_dataset_with/,Regression vs Classification: 90K Dataset with Only 600 Unique Values - Seeking Insights!,"I’m working on a specific regression problem. My dataset comprises 90,000 samples, and my target variable ranges from 0 to 100 (real numbers). After examining my target variable, I discovered it has only 600 unique values, which is relatively sparse given my dataset’s substantial size (90,000 rows). 25% of these values appear between 1 to 10 times, and 50% are distributed between 100 to 1,000 occurrences.

I considered transforming it into a classification problem; however, this approach presents its own challenges, such as an extremely imbalanced dataset and the daunting prospect of managing 600 classes. Additionally, converting to classification would mean losing the ordinal property of my target variable.

Is there a middle-ground approach that strikes a balance between regression and classification? Does anyone have innovative strategies or know of any research papers that address such issues?",datascience,https://www.reddit.com/r/datascience/comments/16ti2vx/regression_vs_classification_90k_dataset_with/,16,5,0.86,"[Comment(id='k2f4aaf'), Comment(id='k2gtcgo'), Comment(id='k2fijph'), Comment(id='k2f5870'), Comment(id='k2fqj82'), Comment(id='k2gaadn'), Comment(id='k2kwsr6'), Comment(id='k2f4x90'), Comment(id='k2f5tv2'), Comment(id='k2fsjg7'), Comment(id='k2f5ttj'), Comment(id='k2fa72v'), Comment(id='k2g7pfd'), Comment(id='k2f6qn0'), Comment(id='k2g8l16'), Comment(id='k2fhr4t')]"
16tt7vg,mmurad96,,2023-09-27 19:15:57+00:00,False,,False,False,True,False,/r/datascience/comments/16tt7vg/clients_procrastination_for_brd_approval/,clients procrastination for BRD approval,"I wonder,  how a vendor should deal with clients who procrastinate and destructively criticize any point in the business requirements document. We are beyond the deadline due to they do not help. We have successful stories with many clients. But it is the first time to deal with a client who just want to hinder any progress and who is afrid to have a commitment for giving any approval.
Although they are aware of our success stories and we proposed a proof of concept which is accepted, after preparing the BRD to agree on the points of the project, they just procrastinate.
I want to know from experts if they faced similar situations and how you dealt with it to accelerate the approval steps and move on the next stages.",datascience,https://www.reddit.com/r/datascience/comments/16tt7vg/clients_procrastination_for_brd_approval/,0,1,1.0,[]
16taxs3,needtheprivacy,,2023-09-27 04:38:28+00:00,False,,False,False,True,False,/r/datascience/comments/16taxs3/can_someone_eli5_the_difference_between_ds_types/,Can someone ELI5 the difference between DS types of work?,"I come in peace, I’m a recruiter for a tech company that is trying to learn about data science! 

I find our hiring managers often want data scientist who has “product analytics” or “product data science” experience. 

I understand this high level; I do know the difference between a DS who works on modeling solely and DS that is working on a product. I get usually people are one or the other 

But for a topic such as Search, i have a really hard time discerning the differences. 

So TLDR - can any one ELI5 the difference within DS subgroups like product data science? 


I’ll probably get downvoted to hell because everyone hates recruiters. But I ask you be gentle because I’m just trying to get better at my job and hopefully be a good experience for any of you who may fall into my interview loops :)",datascience,https://www.reddit.com/r/datascience/comments/16taxs3/can_someone_eli5_the_difference_between_ds_types/,4,12,0.88,"[Comment(id='k2e27bh'), Comment(id='k2fwti7'), Comment(id='k2eizuu'), Comment(id='k2g2zdj')]"
16tkfe5,No_Lynx3610,,2023-09-27 13:20:11+00:00,False,,False,False,True,False,/r/datascience/comments/16tkfe5/etl_technology/,ETL Technology,I'm trying to migrate old ETL processes developed in SSIS (Integration Services) to Azure but I don't know whether it is better to go for a NoCode/LowCode solution like ADF or code the ETL using PySpark. What is the standard in the industry or the most professional way to do this task?,datascience,https://www.reddit.com/r/datascience/comments/16tkfe5/etl_technology/,1,2,1.0,[Comment(id='k2fxoob')]
16tv900,norfkens2,,2023-09-27 20:34:39+00:00,False,,1695849207.0,False,True,False,/r/datascience/comments/16tv900/meta_majority_of_people_supports_the_status_quo/,[Meta] Majority of people supports the status quo of the DS subreddit,"Every couple of months a post comes up that addresses the state of the subreddit, giving valid criticism on a given topic. People in the comments often complain about given topic (I have, too, in the past). 

Now, I wanted to gauge how much of that discontent could actually be translated into change. So, I started a little non-representative experiment - for shits and giggles, I guess.

&nbsp;

*My (non-representative) results:*

People in /r/datascience/ - 1.1m

Average views of a post - ~10k

People interacting with a post complaining about too many career questions - ~120

People commenting - ~40

People bringing forward actually constructive comments relevant to the topic - 3

People responding to a direct question about improving engagement - 0

&nbsp;

*My takeaway:*

a) People support the status quo of the subreddit - either because they do like it that way or through their inactivity. Or maybe they don't mind either way.

b) Comments complaining in these kind of posts mostly seem to have only entertainment value.",datascience,https://www.reddit.com/r/datascience/comments/16tv900/meta_majority_of_people_supports_the_status_quo/,6,0,0.25,"[Comment(id='k2jrdgh'), Comment(id='k2kc9zt'), Comment(id='k2jxpc7'), Comment(id='k2kg0qp'), Comment(id='k2k0mob'), Comment(id='k2k7o5w')]"
16tpils,Public-Recording9634,,2023-09-27 16:42:51+00:00,False,,False,False,True,False,/r/datascience/comments/16tpils/conformal_prediction/,conformal prediction,"hi can someone explain intuitively the differences between unconditional coverage and conditional coverage split conformal prediction?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16tpils/conformal_prediction/,1,1,1.0,[Comment(id='k2pdr0r')]
16tii86,Citizen_of_Danksburg,,2023-09-27 11:54:05+00:00,False,,False,False,True,False,/r/datascience/comments/16tii86/how_to_recover_from_submitting_incorrect_résumé/,How to recover from submitting incorrect résumé for job application?,"Hi, I majorly fucked up.

I currently work as a statistician in biotech and am looking to transition to a data science career. I worked a very long day yesterday due to standard end of quarter rush, and so when I got home, I spent all evening completely revamping from top to bottom my LinkedIn and Resume.

The problem is my resume. I found this template online that looked great (https://careercup.com/resume) and began filling it out. The fuck up is on the education section. I had filled out the bullet points saying when I had finished my undergrad and masters as well as the relevant coursework I took, but I submitted this new resume to a job (that looked like something I’d absolutely love and be qualified for) with the education section saying I spent all my time at the University of Pennsylvania (what the template lists as the only school — I didn’t go to this school nor did I do my undergrad and masters at the same school). 

How should I go about fixing this? There is no applicant portal where I can easily upload a new document or fix it. I’m feeling so ashamed of myself that I quite possibly blew it so hard. 

Is there any hope for me? I could use some advice for sure. I noticed the error seconds after I submitted my application and have since corrected it.",datascience,https://www.reddit.com/r/datascience/comments/16tii86/how_to_recover_from_submitting_incorrect_résumé/,11,3,0.64,"[Comment(id='k2f5gam'), Comment(id='k2gij8l'), Comment(id='k2f5688'), Comment(id='k2hrcgx'), Comment(id='k2f7fyi'), Comment(id='k2f74qm'), Comment(id='k2jrsfr'), Comment(id='k2jrayn'), Comment(id='k2f8duu'), Comment(id='k2jtih4'), Comment(id='k2fh8mm'), Comment(id='k2jw4c5'), Comment(id='k2l2ulf'), Comment(id='k2m5ffv')]"
16tmqz9,anon67543,,2023-09-27 14:55:11+00:00,False,,False,False,True,False,/r/datascience/comments/16tmqz9/complex_dataset_approach/,Complex Dataset approach,"Hi everyone. I’ve got a dataset composed of pictures with various categorical and numerical information attached to each picture. I’m trying to cluster these into groups. So far i rolled the picture out to pixel data but if I throw in the other data, it seems to get buried under the number of pixels. 

I’m thinking of weighting the nonpixel higher relative to pixel, but not sure what to do about it (1:1 or…) . 
Any ideas or packages to get in the right direction are appreciated.",datascience,https://www.reddit.com/r/datascience/comments/16tmqz9/complex_dataset_approach/,2,1,1.0,"[Comment(id='k2fx5kf'), Comment(id='k2o68rq')]"
16tksa5,randomtest123xx,,2023-09-27 13:34:02+00:00,False,,False,False,True,False,/r/datascience/comments/16tksa5/a_data_science_position_is_advertised_as_an/,"A data science position is advertised as an internship and as a working student position, I could apply for both but where do I think my chances are better ? What would you do ?",,datascience,https://www.reddit.com/r/datascience/comments/16tksa5/a_data_science_position_is_advertised_as_an/,0,0,0.33,[]
16tkg6g,debordian,,2023-09-27 13:20:59+00:00,False,,False,False,False,False,/r/datascience/comments/16tkg6g/github_anacondastateofdatascience_data_from_the/,GitHub - anaconda/state-of-data-science: Data from the state of data science survey released by Anaconda each year.,,datascience,https://github.com/anaconda/state-of-data-science,0,1,1.0,[]
16t145z,Any-Fig-921,,2023-09-26 21:45:46+00:00,False,,False,False,True,False,/r/datascience/comments/16t145z/are_you_actually_making_your_own_nns_in_2023/,Are you actually making your own NNs in 2023?,"I'm finding the task in my role are bifurcating into one of two things.  
1. Simple Statistical/ML Model. Linear Models, maybe SVM or similar. Classification or interpretation of data with 'standard' models.

2. Using an open source / proprietary NN model. OpenAI, huggingface for text generation, image generation, embeddings etc. MAYBE I fine tune something, but probably just use off-the-shelf APIs or models.  


Don't get me wrong, I'm not complaining, I enjoy both these things, and writing your own tensorflow or pytorch model can be a real pain.  


Is there anyone out there who is writing their own custom tensorflow or pytorch models in 2023? If so, what are your use cases? It feels like we're moving towards a world with open-source models that are better than almost anything you could spin up in house for most use cases.",datascience,https://www.reddit.com/r/datascience/comments/16t145z/are_you_actually_making_your_own_nns_in_2023/,10,18,0.95,"[Comment(id='k2ditdx'), Comment(id='k2d9ceq'), Comment(id='k2dans5'), Comment(id='k2fv6wx'), Comment(id='k2e74qa'), Comment(id='k2egqq3'), Comment(id='k2ei304'), Comment(id='k2dtjjd'), Comment(id='k2dvn63'), Comment(id='k2fhjlz')]"
16sbhun,jacobwlyman,,2023-09-26 02:27:20+00:00,False,,1695832108.0,False,True,False,/r/datascience/comments/16sbhun/you_dont_have_to_be_a_data_scientist/,You don’t have to be a Data Scientist,"Just a PSA for anyone here that is starting their career, might feel overwhelmed with applying/interviewing for jobs, or is looking for a career change. 

If you’re interested in a Data career, know that there are many different roles out there other than a “data scientist” role. Here’s only a handful of the common titles I see out there these days:

- Business Analyst
- Data Analyst
- Product Analyst
- <INSERT_WORD> Analyst 
- Analytics Engineer
- Data Engineer
- DataOps Engineer
- ML Engineer
- MLOps Engineer (This is my current role -- Feel free to DM me or read [What is MLOps?](https://www.jacoblyman.com/tech-log/published/what-is-mlops) to learn more)
- Product Manager 
- Management/Leadership roles

Feel free to comment any other Data roles that others might not know about!

Edit: Here is a list of other Data roles that were commented on in the thread as of Sept 27th, 2023.

- Risk Analyst
- Statistical Programmer
- Economist
- Actuary
- AI Engineer
- Manager of Business Intelligence
- Marketing Analytics Manager
- Marketing Analyst
- Marketing Operations Manager
- Revenue Operations Manager
- Bioinformatician
- Cheminformatician
- Institutional Research roles
- Operational Research roles
- Analytics Product Management roles",datascience,https://www.reddit.com/r/datascience/comments/16sbhun/you_dont_have_to_be_a_data_scientist/,125,492,0.97,"[Comment(id='k28bkhn'), Comment(id='k28krz0'), Comment(id='k28c2gd'), Comment(id='k28tsa6'), Comment(id='k296j8q'), Comment(id='k28qylx'), Comment(id='k29262e'), Comment(id='k28mrc9'), Comment(id='k2a4veq'), Comment(id='k28gcjv'), Comment(id='k28tjx7'), Comment(id='k28nvyr'), Comment(id='k2937o1'), Comment(id='k299drb'), Comment(id='k28lyey'), Comment(id='k295mer'), Comment(id='k29at1z'), Comment(id='k29r9ka'), Comment(id='k29soyl'), Comment(id='k29wb64'), Comment(id='k2altbm'), Comment(id='k28xq41'), Comment(id='k29ai8d'), Comment(id='k29iqiu'), Comment(id='k29jw9h'), Comment(id='k2arqea'), Comment(id='k2aztw0'), Comment(id='k2bg4s8'), Comment(id='k2biio9'), Comment(id='k2d848s'), Comment(id='k2f5iyd'), Comment(id='k2kfuee'), Comment(id='k29nklx'), Comment(id='k29q33l'), Comment(id='k2ahvg5'), Comment(id='k299k5i'), Comment(id='k29nbgn'), Comment(id='k29avne'), Comment(id='k29l019'), Comment(id='k2apj69'), Comment(id='k2ciuof'), Comment(id='k3q5k8a'), Comment(id='k2b1ead'), Comment(id='k2e009o'), Comment(id='k29043n'), Comment(id='k28qurb'), Comment(id='k2a5xr3'), Comment(id='k290534'), Comment(id='k2aco05'), Comment(id='k2a9abo'), Comment(id='k2awu6i'), Comment(id='k2b7xvv'), Comment(id='k2bbd0o'), Comment(id='k2af6e0'), Comment(id='k2a9r3c'), Comment(id='k29yvlx'), Comment(id='k2b8ixb'), Comment(id='k29176r'), Comment(id='k28tj6f'), Comment(id='k28lc1e'), Comment(id='k6d6ddp'), Comment(id='k29zq1u'), Comment(id='k29n7zx'), Comment(id='k29d5kz'), Comment(id='k29ki6v'), Comment(id='k29rmu9'), Comment(id='k2a9xpr'), Comment(id='k29nk1b'), Comment(id='k29dlic'), Comment(id='k2a7zth'), Comment(id='k2g636k'), Comment(id='k2g65i5'), Comment(id='k29yfqw'), Comment(id='k2bhcp5'), Comment(id='k2a2t7c'), Comment(id='k2a0chb'), Comment(id='k2lejgy'), Comment(id='k2fd51b'), Comment(id='k295pgx'), Comment(id='k2dgiof'), Comment(id='k2a1y0x'), Comment(id='k2abd36'), Comment(id='k2abtom'), Comment(id='k2apkh7'), Comment(id='k2bbvk6'), Comment(id='k2bcmci'), Comment(id='k2bh5zv'), Comment(id='k2cw7l0'), Comment(id='k2ao30j'), Comment(id='k2anm70'), Comment(id='k2cb95r'), Comment(id='k298s05'), Comment(id='k2a55wk'), Comment(id='k2a23ot'), Comment(id='k2a0fcb'), Comment(id='k29xb6u'), Comment(id='k2atrib'), Comment(id='k29qp9f'), Comment(id='k2aauo0'), Comment(id='k2hsa3l'), Comment(id='k2bzhx4'), Comment(id='k2dlnkt'), Comment(id='k2aalt9'), Comment(id='k2avr47'), Comment(id='k2fd7wp'), Comment(id='k2abp2g'), Comment(id='k2bdm4h'), Comment(id='k2az02k'), Comment(id='k2cknci'), Comment(id='k2cl8lt'), Comment(id='k2bhkvw'), Comment(id='k2a9uyf'), Comment(id='k29xtzu'), Comment(id='k2abygg'), Comment(id='k2bvs27'), Comment(id='k2b6res'), Comment(id='k2catu8'), Comment(id='k2cr880'), Comment(id='k2crkl1'), Comment(id='k2abo0x'), Comment(id='k2brw6r'), Comment(id='k2c05mz'), Comment(id='k2c3a59'), Comment(id='k2cdtxy'), Comment(id='k2ckt89')]"
16t9tc4,kpr1904,,2023-09-27 03:43:38+00:00,False,,False,False,True,False,/r/datascience/comments/16t9tc4/is_there_any_chance_of_getting_data_analytics_job/,Is there any chance of getting data analytics job in an industry of your interest?,"Currently, I’m a sophomore at an university in Southeast Asia, and I’m planning to move to Australia to study on a transnational program. My intention is also to have a job in Australia. In order to achieve the goal, I’m now self-studying some technical tools about data analytics with an aim of doing a project to fill in the CV, while at the same time improving my soft skills and read more about my desired industry - commercial aviation.

The problem is, I really want to work in that industry. Data analytics jobs are everywhere in every industries such as education, finance, manufacturing,… and I see people applying for HUNDREDS of jobs just to finally to land 1 job. Therefore, how do you think about the chance of getting a job in a specific industry, especially mine since there is not a lot firms/companies? I managed to find some when doing research but what’s the possibility, given you have just a little bit more knowledge in that industry?",datascience,https://www.reddit.com/r/datascience/comments/16t9tc4/is_there_any_chance_of_getting_data_analytics_job/,1,3,0.81,[Comment(id='k2e3hj4')]
16tgwqf,Junior-Suit2097,,2023-09-27 10:29:44+00:00,False,,False,False,True,False,/r/datascience/comments/16tgwqf/need_guidance_for_data_scientist_product/,"Need guidance for Data Scientist, Product Analytics ( Technical Round 45 minutes SQL + Product Sense ) in 2.5 weeks","Hello Everyone,

I have a technical round in 2.5 weeks for the Data Scientist, Product Analytics role at Meta and Recruiter told me it's going to be an SQL + Product case round. I am average at SQL but have some experience with working on product scenario-based real-world problems. How can I prepare myself in a short span of time to clear this round? Do they repeat questions or what will be the best source for study material? Is there someone who is willing to prepare me without asking for heavy fees which they ask on different platforms?",datascience,https://www.reddit.com/r/datascience/comments/16tgwqf/need_guidance_for_data_scientist_product/,0,1,0.67,[]
16sxpls,Rosehus12,,2023-09-26 19:41:17+00:00,False,,False,False,True,False,/r/datascience/comments/16sxpls/what_software_can_handle_large_data_sas_or_r/,"What software can handle large data, SAS or R?",These are the only 2 software used where I work. I'm proficient in R than SAS but if it will be useful I will try to brush it up. Please suggest if there are any other solutions to make R work faster. Spark is something I'm considering too,datascience,https://www.reddit.com/r/datascience/comments/16sxpls/what_software_can_handle_large_data_sas_or_r/,60,16,0.74,"[Comment(id='k2bv4ki'), Comment(id='k2bywm0'), Comment(id='k2c66sa'), Comment(id='k2bwe2z'), Comment(id='k2cdsmu'), Comment(id='k2c183t'), Comment(id='k2c2wti'), Comment(id='k2cbvr6'), Comment(id='k2e4d9y'), Comment(id='k2c2xbc'), Comment(id='k2cygvm'), Comment(id='k2d6eb9'), Comment(id='k2ebb97'), Comment(id='k2eifkg'), Comment(id='k2febm1'), Comment(id='k2bwfcm'), Comment(id='k2bzqhh'), Comment(id='k2elyc3'), Comment(id='k2ezj3m'), Comment(id='k2bx8ft'), Comment(id='k2ceo2l'), Comment(id='k2cibjv'), Comment(id='k2fmoqn'), Comment(id='k2c30ev'), Comment(id='k2ccqn8'), Comment(id='k2hsoa0'), Comment(id='k2cebk3'), Comment(id='k2drqnq'), Comment(id='k2bymzg'), Comment(id='k2c68bs'), Comment(id='k2dlkcv'), Comment(id='k2c0bws'), Comment(id='k2cej8g'), Comment(id='k2eptsy'), Comment(id='k2f37p9'), Comment(id='k2c207q'), Comment(id='k2cgg3w'), Comment(id='k2cz661'), Comment(id='k2bz97j'), Comment(id='k2foaby'), Comment(id='k2eu04e'), Comment(id='k2f4azw'), Comment(id='k2cjpx3'), Comment(id='k2bzn63'), Comment(id='k2c75h2'), Comment(id='k2ft891'), Comment(id='k2f31ye'), Comment(id='k2f5isy'), Comment(id='k2cobrq'), Comment(id='k2gvhrt'), Comment(id='k2f3zgv'), Comment(id='k2f5vtx'), Comment(id='k2cootg'), Comment(id='k2gw6v7'), Comment(id='k2f51ue'), Comment(id='k2f6kll'), Comment(id='k2fa40a'), Comment(id='k2lj6bq'), Comment(id='k2f9e74'), Comment(id='k2fbtnw'), Comment(id='k2mnr5e'), Comment(id='k2ho2kb'), Comment(id='k2hoo7m'), <MoreComments count=0, children=[]>]"
16tfk8f,bilby2020,,2023-09-27 09:05:28+00:00,False,,False,False,True,False,/r/datascience/comments/16tfk8f/is_there_any_gpt_like_tool_to_analyse_and_compare/,Is there any GPT like tool to analyse and compare PDF contents,"I am not sure if this is the best place to ask, but here goes.

I was trying to compare two different insurances from different companies (C1 and C2)  by reading their product disclosure statements. These are like 50-100 page PDFs and very hard to read, understand and compare. E.g. C1 may define income different to C2. C1 may cover illnesses different to C2. 

Is there any GPT like tool where I can upload the two PDFs and ask it questions like I would ask a insurance advisor. If it is not there is it feasible to be built.

* What the are the key differences between C1 and C2?
*  Is diabetes definition same in C1 and C2, if not what is the difference?
* C1 pays 75% income up to age 65 and 70% up to age 70. How does this compare with C2?

e.g. Document [https://www.tal.com.au/-/media/tal/files/pds/accelerated-protection-combined-pds.pdf](https://www.tal.com.au/-/media/tal/files/pds/accelerated-protection-combined-pds.pdf)",datascience,https://www.reddit.com/r/datascience/comments/16tfk8f/is_there_any_gpt_like_tool_to_analyse_and_compare/,2,1,1.0,"[Comment(id='k2eoaxy'), Comment(id='k2jm3pf')]"
16tf9hz,aquablue24_,,2023-09-27 08:46:24+00:00,False,,False,False,True,False,/r/datascience/comments/16tf9hz/take_my_survey/,Take my survey!," I have made a pretty fun survey for a uni assignment - would really appreciate any respondents. More than happy to respond to other surveys in return!

Takes less than 5 minutes.

https://v4-4-5.saas-us1.surveyengine.com/eu34blcvoikl8j4g9c0b2jk9sf35rns81vt2pl7kr14amejjthq6qdhqou4h6323ia50",datascience,https://www.reddit.com/r/datascience/comments/16tf9hz/take_my_survey/,0,0,0.33,[]
16terry,sneekytrojan,,2023-09-27 08:14:34+00:00,False,,False,False,True,False,/r/datascience/comments/16terry/a_data_scientist_with_an_idea_itching_to_become/,A Data Scientist with an idea itching to become the startup Vagabond,"Greetings fellow Data Scientists and Dreamers,

I've  finally begun my path towards starting up. I aim to provide the gaming community with alternative methods to obtaining game-playable assets and loot. I'm doing this while reading *Lean Startup* and currently I'm trying to validate some assumptions I've written down on the project's Lean Canvas.  
Yesterday, I deployed a questionnaire at various gaming communities on Reddit and had a slew of different interactions, they ranged from  people calling it a crypto scam (there's no crypto involved in the project at all) while others obliged and took the questionnaire, to others inquiring more about it and engaging me in earnest. From the likely 7K+ persons who saw the post (according the post metrics provided by Reddit) I only got 25 people to actually fill in the questionnaire, however. 

If there are any founders or dreamers among you I'm hoping to learn what approaches some one you have taken to try and validate assumptions in the pre-prototype phase, i.e. the phase where you're trying to gauge if the 'gaps' you think you've found indeed do exist.

For Data Scientists who go out there and gather data what techniques did you folks use to engage your target groups. Have you done campaigns on Reddit, what worked, what didn't work? Thanks a milllion.

Lastly, if you're a gamer, hardcore or casual, would you mind taking the questionnaire, its on a google form: [https://docs.google.com/forms/d/e/1FAIpQLSc6MApt\_ji7rsBgYHnzB3pP901X9VETvO-8ICvGrKAl2SD7nA/viewform](https://docs.google.com/forms/d/e/1FAIpQLSc6MApt_ji7rsBgYHnzB3pP901X9VETvO-8ICvGrKAl2SD7nA/viewform) and if you're not a gamer, would you mind taking a look at it and recommend some feedback so that I may improve upon it?  


Warm regards, 

Rick   


p.s. you can find me on [www.linkedin.com/in/rdmtinez](https://www.linkedin.com/in/rdmtinez) if you wish to connect ",datascience,https://www.reddit.com/r/datascience/comments/16terry/a_data_scientist_with_an_idea_itching_to_become/,15,0,0.45,"[Comment(id='k2esej4'), Comment(id='k2euino'), Comment(id='k2emzkd'), Comment(id='k2f0uwu'), Comment(id='k2f34ei'), Comment(id='k2f3152'), Comment(id='k2esarm'), Comment(id='k2fy2ik'), Comment(id='k2f3bgz'), Comment(id='k2f9w25'), Comment(id='k2f9qvl'), Comment(id='k2fba73'), Comment(id='k2faoim'), Comment(id='k2fh2pv'), Comment(id='k2k01y3')]"
16t7d17,csuarezg,,2023-09-27 01:54:45+00:00,False,,False,False,True,False,/r/datascience/comments/16t7d17/data_science_for_an_investment_professional/,Data science for an Investment Professional.,"Hello everyone, 
I have a degree in finance (also I'm a CFA charterholder and CAIA candidate)  and 7 years of experience in Fixed Income trading and Risk Management.
I would like to expand my circle of competence through coding/ data science. I was doing reseaech to create a self-paced road map to learn data science for investment professionals, however I don't found a proper road map to start this journey.

I would like to know your thoughts regarding how to learn valuable data science skills to upgrade my professional profile. (I'm excel proficient, but zero programming knowledge)

Which should be the key topics to learn, the first steps and the most valuable sources you will consider for a financial professional in order to gain deep knowledge in data science?

In advance, thank you for you comments.",datascience,https://www.reddit.com/r/datascience/comments/16t7d17/data_science_for_an_investment_professional/,1,3,1.0,[Comment(id='k2etf3l')]
16td7vt,anxiouscrimp,,2023-09-27 06:39:39+00:00,False,,False,False,True,False,/r/datascience/comments/16td7vt/what_problems_could_i_try_to_solve/,What problems could I try to solve?,"I work as a BI architect for a retailer. I’ve built out our data warehouse which is feeding a set of powerBI dashboards and cubes for the business. I’ve got access to all of our data - stock, sales, purchasing, web traffic (ga) etc. I do have access to CRM data but my understanding of customer is poor - this is handled by someone else.

So far I’ve done a bit of basket analysis in Python which I’m surfacing in a dashboard for the users which has gone down well. I really enjoyed doing it.

But what else could I look at? I’m sure there are some standard pieces of analysis that retailers would normally do. But we are pretty immature when it comes to moving beyond ‘this is what we sold last week’.",datascience,https://www.reddit.com/r/datascience/comments/16td7vt/what_problems_could_i_try_to_solve/,1,1,1.0,[Comment(id='k2eci2g')]
16t83yn,Terrible-Hamster-342,,2023-09-27 02:26:17+00:00,False,,False,False,True,False,/r/datascience/comments/16t83yn/anyone_here_work_as_a_data_scientist_focused_on/,Anyone here work as a Data Scientist focused on user growth?,"I’m about to start a new job and the objective will be user growth. Focused on personalization (ads targeting), segmentation and measurement of AB Test results.

Company goal is to increase retention and also acquire new users.

Can anyone working in a similar space share their experience?",datascience,https://www.reddit.com/r/datascience/comments/16t83yn/anyone_here_work_as_a_data_scientist_focused_on/,3,2,1.0,"[Comment(id='k2ew26l'), Comment(id='k2fd60n'), Comment(id='k2fljdt')]"
16t4um7,modelbit,,2023-09-27 00:09:12+00:00,False,,False,False,True,False,/r/datascience/comments/16t4um7/interact_with_an_owlvit_object_detection_model/,Interact with an OWL-ViT Object Detection Model,"There has been a lot of interest in the new computer vision ML models coming out of Meta Research and Google, so we built an interactive demo of what it's like to interact with an OWL-ViT model as an end user in a product.

[**Here is a link to the interactive demo**](https://www.modelbit.com/owl-vit-demo)**.**

[OWL-ViT](https://arxiv.org/abs/2205.06230) is a new object detection model from the team at Google Research. It allows you to identify an object in one image (the “query image”) and then find that same object in any number of target images.

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16t4um7/interact_with_an_owlvit_object_detection_model/,1,3,1.0,[Comment(id='k2d1hj1')]
16tchf8,ElegantAnalysis,,2023-09-27 05:58:36+00:00,False,,False,False,True,False,/r/datascience/comments/16tchf8/what_would_you_get_your_company_to_pay_for_as_a/,What would you get your company to pay for as a beginner,"As the title says, I'm a beginner in the field and I can probably get my company to pay for a course or a cert or something like that

What would get your company to pay for if you could? Around 1000-1500€",datascience,https://www.reddit.com/r/datascience/comments/16tchf8/what_would_you_get_your_company_to_pay_for_as_a/,3,1,0.67,"[Comment(id='k2eervg'), Comment(id='k2idca4'), Comment(id='k2idmmy')]"
16tkgyu,you_ako,,2023-09-27 13:21:52+00:00,False,,False,False,True,False,/r/datascience/comments/16tkgyu/training_regression_model_using_50_gb/,Training regression model using 50 Gb,"Hello guys, I have a question for interview assessment:

We have 50Gb of data, on which we want to run a linear regression, but we have only 8Gb of RAM on our machine. Name several possible regression strategies",datascience,https://www.reddit.com/r/datascience/comments/16tkgyu/training_regression_model_using_50_gb/,16,0,0.3,"[Comment(id='k2fyxvu'), Comment(id='k2fqvy7'), Comment(id='k2fufie'), Comment(id='k2fseug'), Comment(id='k2jh2y9'), Comment(id='k2uchd7'), Comment(id='k2fv5yf'), Comment(id='k2fvb1l'), Comment(id='k2g5kd3'), Comment(id='k2fv1z4'), Comment(id='k2g3xyr'), Comment(id='k2fvgo8'), Comment(id='k2g7yi9'), Comment(id='k2gqjfm'), Comment(id='k2invfu'), Comment(id='k2g9swo')]"
16sxkh1,alpha-gamma-x,,2023-09-26 19:35:59+00:00,False,,False,False,True,False,/r/datascience/comments/16sxkh1/how_to_fill_nonobvious_gaps_in_my_ds_knowledge/,How to fill non-obvious gaps in my DS knowledge? Any study lists?,"I got a BS degree on a data science related field but I still find some gaps in my knowledge, that frankly seem embarrasing. For instance, I can use libraries with ease, but might have difficulties calculating some probability function or using the shell. I also didn’t have the chance to use remote servers in the past, and I am not sure I would do well in any company that has lots of data (i.e. I have gaps in memory usage, etc.).

I made a study list based on my gaps in knowledge, but sometimes it’s hard to see things I don’t know (because I don’t know them). I would like to see your study guides / plans, for either interview prep or just learning DS/DE. That may give some ideas on what I am missing.

Alternatively, can someone just list out a few things that you do at your DS job that are non-obvious (i.e. i know most of you do modeling, but what steps before/after modeling people with less experience tend to miss)?

I know that it’s probably best to explore my gaps through actually working, but my current role is program management and I have little to nothing to do in my daily responsibilities with DS. Just trying to learn on my own. 

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16sxkh1/how_to_fill_nonobvious_gaps_in_my_ds_knowledge/,6,5,0.78,"[Comment(id='k2cjuic'), Comment(id='k2dhk5r'), Comment(id='k2ea03o'), Comment(id='k2n5lsz'), Comment(id='k2itev7'), Comment(id='k2eac1v')]"
16ta05a,Ok_Unit7169,,2023-09-27 03:52:32+00:00,False,,False,False,True,False,/r/datascience/comments/16ta05a/how_important_is_statelessness_on_reducers_in/,How important is statelessness on reducers in MapReduce process with parallel processing?,,datascience,https://www.reddit.com/r/datascience/comments/16ta05a/how_important_is_statelessness_on_reducers_in/,0,1,1.0,[]
16t0xc9,GetFkedPlease,,2023-09-26 21:39:02+00:00,False,,False,False,True,False,/r/datascience/comments/16t0xc9/what_is_my_job_title/,What is my job title?,"I work in the semi-conductor industry and last year I switched from my FSE Technical Supervisor role, to a Data Analyst/ Diagnostics Analyst role where we remotely troubleshoot our etch equipment based on the logs and data sent from the customer. 

Everyone hired on this team has 20+ years of technical support/ FSE experience except me. The reason I was hired is because I have 8 years experience as an FSE, but I am a Computer Science student with programming experience. My bosses goal was for me to create data products that our analysts can use. 

This is so awesome because I essentially get to build a fantastic resume while finishing school for future computer science related jobs, without having to go work an entry level job elsewhere and take a paycut after school.

I started this role October 1st, 2022, and my goal is to finish my degree by October 1st, 2024 and find another job based off of 2 years experience with my current 'X' role (Don't know what to label it as). 

My daily tasks are normal diagnostics stuff, but in the meantime/ extra time I create data products. One product was a workflow/ script that ingests tabular files with all of the down equipment in our customers facility and compares it to our CRM database to see what cases we need to open and provide insight on and which we need to close. Before this, the guys were literally manually comparing each line of reportred down equipment (hundreds of lines) to each case in our database (thousands) and seeing what does and does not exist and acting accordingly. This program I created saves an estimated 500+ work hours per year. 

I've also created standardized forms where our guys enter in applicable data about equipment errors, and it outputs a standardized entry for our cases on CRM so the info can be easily parsed and used for PBI dashboards that we present to the customer. 

I've now gotten the ok from my boss to basically completely stop with diagnostics work and only do data product engineering. My next projects are:

1. Setting up pipelines to ingest csv data from our customer and automatically create cases in CRM for three different types of data we get (work content reduction, normal equipment cases, and niche equipment cases).

2. Work with our companies actual data engineering team to create a pattern matching/ ML application that will ingest the down equipment I mentioned earlier and automate the game plan based off our historical cases. Then, set up pipelines that feed the tabular file containing down equipment mentioned earlier into the ML application so it's automated from start to finish. 

I'm super excited about getting to work on all of this and learn about all the different skills and approaches, but I have no idea what my job title should be on my future resume, if what I'm doing is valuable for finding another job in 2024, and what jobs would offer the highest salary based on this experience. I'm assuming data engineer, but I have no idea.

Can anyone offer some insight please? 

My long term goal is machine learning for a career. I plan to get an MS in Data Science/ Analysis since an MS in Machine Learning doesn't really exist yet.",datascience,https://www.reddit.com/r/datascience/comments/16t0xc9/what_is_my_job_title/,1,2,0.76,[Comment(id='k2dn766')]
16suvck,AZForward,,2023-09-26 17:54:24+00:00,False,,False,False,True,False,/r/datascience/comments/16suvck/does_it_make_sense_to_use_sequential_feature/,Does it make sense to use sequential feature selection if the model uses a boosting algorithm?,"So I started a new role recently where the forecasting pipeline runs SFS to create multiple datasets which are then fed to Xgboost models. This pipeline is run weekly, where the data is processed and then new models are trained. This seems odd to me bc Xgboost already does feature selection in a way. I would expect SFS to perhaps be used when beginning a project to help understand the data, but once that understanding is complete and the features are selected, when the pipeline is run, only create those features and update the model as needed.

I haven't found anything online where people use both of these methods. From what I've seen, people will use SFS for linear models. Lots of tutorials of people using boosting models as a method of feature selection by using feature importances, but I've yet to find anything like what I'm seeing in this project.

So, am I missing something to understand the value that SFS can bring when combined with a boosting algorithm? Or is my intuition correct that there is some redundancy in this pipeline and it can be simplified?",datascience,https://www.reddit.com/r/datascience/comments/16suvck/does_it_make_sense_to_use_sequential_feature/,2,3,1.0,"[Comment(id='k2bqog6'), Comment(id='k2ciopn')]"
16sqvmg,King_2000,,2023-09-26 15:20:38+00:00,False,,False,False,True,False,/r/datascience/comments/16sqvmg/applying_to_same_company_after_getting_not_incline/,Applying to same company after getting not incline,"I got a not inclined decision from a FAANG internship this summer. I will graduate this December and am looking for jobs, have already applied to over 200 companies in over 500 positions. Have optimized my resume, use referrals to apply and tailor my profile to the role. 
My question: can I still apply to full time positions at the same company that gave me a not incline? I interned as an L4 DS intern and will now apply for L4 DS position in the other departments. Will this work or would I not be considered since I recently got a not incline? 

Thanks for your help!",datascience,https://www.reddit.com/r/datascience/comments/16sqvmg/applying_to_same_company_after_getting_not_incline/,5,4,0.75,"[Comment(id='k2apb8h'), Comment(id='k2cluow'), Comment(id='k2d9xhu'), Comment(id='k2cmyfe'), Comment(id='k2cn54o')]"
16ru5ur,Excellent_Cost170,,2023-09-25 14:48:55+00:00,False,,False,False,True,False,/r/datascience/comments/16ru5ur/is_ml_code_really_5_of_ml_system/,is ML code really 5% of ML system?," 

Google says ML code is less than 5% of the code of ML system? Here is the quote: 'the real challenge isn't building an ML model, the challenge is building an integrated ML system and to continuously operate it in production.' How has this perspective aligned with your experience?

 

https://preview.redd.it/ptgi4hzazeqb1.png?width=1318&format=png&auto=webp&s=a818974f889b6bc648a73a1e23e0c139a0710dfa",datascience,https://www.reddit.com/r/datascience/comments/16ru5ur/is_ml_code_really_5_of_ml_system/,73,189,0.95,"[Comment(id='k256cpe'), Comment(id='k2586mx'), Comment(id='k25cky5'), Comment(id='k25acsz'), Comment(id='k25a2ks'), Comment(id='k25cfk5'), Comment(id='k25fkdf'), Comment(id='k257pl9'), Comment(id='k26edrp'), Comment(id='k25imso'), Comment(id='k263yt2'), Comment(id='k26o26g'), Comment(id='k25kar7'), Comment(id='k2612dq'), Comment(id='k269gxd'), Comment(id='k25j0e3'), Comment(id='k264em3'), Comment(id='k26a3z9'), Comment(id='k26pq86'), Comment(id='k27um0j'), Comment(id='k295sty'), Comment(id='k262cdh'), Comment(id='k29ae5w'), Comment(id='k270fop'), Comment(id='k25jn5a'), Comment(id='k25o213'), Comment(id='k267fce'), Comment(id='k26cn91'), Comment(id='k26q2n0'), Comment(id='k26v5d9'), Comment(id='k26wax3'), Comment(id='k277qgu'), Comment(id='k279be6'), Comment(id='k286jmu'), Comment(id='k28gk8j'), Comment(id='k28qlr1'), Comment(id='k292k58'), Comment(id='k2e22ll'), Comment(id='k2eidy7'), Comment(id='k2t420w'), Comment(id='k25yvjv'), Comment(id='k260fk5'), Comment(id='k25kpk5'), Comment(id='k25hat5'), Comment(id='k25kt4m'), Comment(id='k25ajfw'), Comment(id='k25cuv7'), Comment(id='k28iryg'), Comment(id='k29182y'), Comment(id='k2704a2'), Comment(id='k28jj1a'), Comment(id='k2bs7tt'), Comment(id='k25r9gt'), Comment(id='k25ylrt'), Comment(id='k26xta1'), Comment(id='k27np8z'), Comment(id='k2acnjf'), Comment(id='k270yst'), Comment(id='k293ewu'), Comment(id='k25k5lf'), Comment(id='k2679uw'), Comment(id='k25pqmz'), Comment(id='k25b8xr'), Comment(id='k25l2c2'), Comment(id='k29ma98'), Comment(id='k25n1hw'), Comment(id='k28rue7'), Comment(id='k282u00'), Comment(id='k29445q'), Comment(id='k26353y'), Comment(id='k25ndjr'), Comment(id='k29smpk'), Comment(id='k29so27')]"
16sw0w3,Muhammad_Gulfam,,2023-09-26 18:37:26+00:00,False,,False,False,True,False,/r/datascience/comments/16sw0w3/image_segmentation_iou_calculation/,Image Segmentation IoU calculation,"In image segmentation, while calculating IoU do the background pixels count? or do we just consider the foreground part of the ground truth?

What is the best approach?",datascience,https://www.reddit.com/r/datascience/comments/16sw0w3/image_segmentation_iou_calculation/,0,1,1.0,[]
16taani,Old-Food2140,,2023-09-27 04:06:38+00:00,False,,False,False,True,False,/r/datascience/comments/16taani/is_a_data_science_degree_worth_it_in_2023/,Is a Data Science degree worth it in 2023?,"I’m currently a senior in high school. I’ve taken 2 classes on Data Science and enjoy it. I’m a big math and business guy and I believe that this field can combine the two.

 However is the degree worth it? I see a lot of info out there saying Data Science isn’t a sustainable field. I want to convince myself that this is misinformation but am unsure.

Secondly for me is the lifestyle/salary part. I’ve seen a lot of job opportunities for DS that work remotely. Im a big skier and see this as an opportunity to live closer to the mountains. But with that is their chances for high salaries with that? This might seem like a dumb question but looking ahead, I have expensive hobbies. I want to make sure there is a good ladder for me to climb to be eventually making great money to set myself + future family up no matter what.",datascience,https://www.reddit.com/r/datascience/comments/16taani/is_a_data_science_degree_worth_it_in_2023/,22,0,0.33,"[Comment(id='k2e0wtg'), Comment(id='k2ecta4'), Comment(id='k2edlic'), Comment(id='k2e4cdb'), Comment(id='k2ed589'), Comment(id='k2elem7'), Comment(id='k2ei2nl'), Comment(id='k2e1kgv'), Comment(id='k2edtz7'), Comment(id='k2enypu'), Comment(id='k2ewnuf'), Comment(id='k2eg89f'), Comment(id='k2f7s2p'), Comment(id='k2fxrsf'), Comment(id='k2ghzvn'), Comment(id='k2g85n9'), Comment(id='k2f2yvv'), Comment(id='k2ftm7p'), Comment(id='k2ekz87'), Comment(id='k2g94b1'), Comment(id='k2fq1e8')]"
16shvtc,No_Boysenberry_7138,,2023-09-26 08:23:27+00:00,False,,False,False,True,False,/r/datascience/comments/16shvtc/what_are_some_lesser_known_but_very_useful_data/,"What are some lesser known, but very useful data science tools in python?",,datascience,https://www.reddit.com/r/datascience/comments/16shvtc/what_are_some_lesser_known_but_very_useful_data/,1,4,1.0,[]
16s2ex1,ljc4343,,2023-09-25 20:07:39+00:00,False,,1695691679.0,False,True,False,/r/datascience/comments/16s2ex1/is_grad_school_worth_it/,Is Grad School Worth It?,"I’m in my final year of undergrad, getting my degree in political science with a minor in data analytics. I am planning on at least applying to the Data Science M.S. program my school has, but is it a good idea for me to go?

Some factors:

1. It’s a year long program and I’m graduating w my bachelors in 3 years, so i would get to keep my on campus jobs (including being an RA, so free room+board) plus I would still be graduating at 22 (with all my friends, even if it’s a different ceremony)
2. It would cost about \~18k for tuition and fees with the guaranteed aid i would get. This is my biggest hesitation-  I could probably get some job, even though it wouldn't be in DS and make some money instead of taking out more student loans.
3. I believe I am pretty likely to get into the program- i met with an admissions counselor for the fast-track program they offer and he said my profile looked good (my GPA has gone up since this meeting) and they were generally pretty accepting of undergrads from my school.
   1. I decided against the fast track program because i did not feel i had enough time in my schedule to add on 6 grad credits this year.
4. I really want to get into DS, and that feels pretty impossible with my current degree track.
5. For my DA minor, i have taken some DS classes and I have done well and really enjoyed them.
6. The only data-realted semi-professional experience I have is working as a reserach assistant and cleaning and doing a bit of analysis on old political datasets.

Thoughts? Would appreciate any feedback!

edit: the school im at is Syracuse",datascience,https://www.reddit.com/r/datascience/comments/16s2ex1/is_grad_school_worth_it/,47,23,0.76,"[Comment(id='k273n7h'), Comment(id='k2712e5'), Comment(id='k27x9ms'), Comment(id='k280wzc'), Comment(id='k278k0b'), Comment(id='k26pgsf'), Comment(id='k27ztk6'), Comment(id='k29q8px'), Comment(id='k28nf6x'), Comment(id='k28tzua'), Comment(id='k28v42e'), Comment(id='k288yce'), Comment(id='k2awvi5'), Comment(id='k2ba33f'), Comment(id='k272w0j'), Comment(id='k28m87l'), Comment(id='k27xqgz'), Comment(id='k27y9yb'), Comment(id='k280y4z'), Comment(id='k27jvri'), Comment(id='k26q1up'), Comment(id='k2aprqo'), Comment(id='k2bx08a'), Comment(id='k2bx6pf'), Comment(id='k2765dg'), Comment(id='k27je2y'), Comment(id='k28miqa'), Comment(id='k27yy86'), Comment(id='k27stoe'), Comment(id='k26r0rv'), Comment(id='k2bfok2'), Comment(id='k276zom'), Comment(id='k279ymc'), Comment(id='k27iykt'), Comment(id='k2ao1gc'), Comment(id='k278gsw'), Comment(id='k28pfwk'), Comment(id='k27adje'), Comment(id='k27jm3q'), Comment(id='k2ar3aa'), Comment(id='k2balde'), Comment(id='k28qn8m'), Comment(id='k27k6zh'), Comment(id='k2bktax'), Comment(id='k27l1us'), Comment(id='k2bll19'), Comment(id='k27lpvc'), Comment(id='k2bv7ae'), Comment(id='k27xn8h'), Comment(id='k285dep'), <MoreComments count=0, children=[]>]"
16rvrrx,ruckrawjers,,2023-09-25 15:50:57+00:00,False,,1695658702.0,False,True,False,/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/,Anyone else here bogged down with adhoc SQL requests at work?,"Co-founder and I are working on something that solves this problem (AI data analyst), curious if anyone else here facing the same issue? Our business users aren't SQL savvy, we deploy self service tools but seems learning curve there are too steep still. The adhoc SQL requests never end!

 Would love to connect and learn more!",datascience,https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/,43,53,0.86,"[Comment(id='k25oueq'), Comment(id='k25i3g2'), Comment(id='k261gvz'), Comment(id='k262cdl'), Comment(id='k25vvp8'), Comment(id='k27x5xn'), Comment(id='k25xzdz'), Comment(id='k26mlxl'), Comment(id='k27c5ad'), Comment(id='k28gqrl'), Comment(id='k278zb2'), Comment(id='k272vli'), Comment(id='k27x4a4'), Comment(id='k26hevt'), Comment(id='k27aasp'), Comment(id='k27upxo'), Comment(id='k28kcf2'), Comment(id='k29q5x3'), Comment(id='k2fyjym'), Comment(id='k25wldj'), Comment(id='k25x143'), Comment(id='k25wqq4'), Comment(id='k26pg4c'), Comment(id='k26p6kn'), Comment(id='k27axxg'), Comment(id='k26p8le'), Comment(id='k27as1l'), Comment(id='k25xchj'), Comment(id='k25zcu1'), Comment(id='k27o64r'), Comment(id='k28zb1c'), Comment(id='k27cl7l'), Comment(id='k26h5cb'), Comment(id='k26pfxf'), Comment(id='k27mkgi'), Comment(id='k27r8ki'), Comment(id='k2a1sde'), Comment(id='k26pd2u'), Comment(id='k27zr5e'), Comment(id='k27zvux'), Comment(id='k26prl0'), Comment(id='k298i4r'), Comment(id='k271223'), Comment(id='k2a00rv')]"
16rqnla,twitch-flystewie,,2023-09-25 12:26:54+00:00,False,,False,False,True,False,/r/datascience/comments/16rqnla/how_do_you_handle_big_data_in_jupyter_notebook/,How do you handle big data in Jupyter notebook?,"I’m wondering how everyone handles big data. I have 12 csvs each 90 mbs each. I’ve done some analysis imported a couple individually but of course the combine csv script I use to union them on is pretty slow. 

Directly importing from sql is doable but slow as well. I’m relatively new at work but just wondering what everyone else does whether they just look at smaller subsets of their data at a time or they use dask instead of pandas",datascience,https://www.reddit.com/r/datascience/comments/16rqnla/how_do_you_handle_big_data_in_jupyter_notebook/,75,94,0.94,"[Comment(id='k2545q4'), Comment(id='k250c3y'), Comment(id='k24p7cj'), Comment(id='k258g5f'), Comment(id='k25pcoc'), Comment(id='k25be11'), Comment(id='k2624o5'), Comment(id='k25vg93'), Comment(id='k26vkgv'), Comment(id='k2737x2'), Comment(id='k276vc2'), Comment(id='k27a7qi'), Comment(id='k28akaf'), Comment(id='k28hqlm'), Comment(id='k2dh8gu'), Comment(id='k24luku'), Comment(id='k26fuyv'), Comment(id='k257mgi'), Comment(id='k25wwl5'), Comment(id='k25r08b'), Comment(id='k24nz1b'), Comment(id='k2574mu'), Comment(id='k260adm'), Comment(id='k289hlb'), Comment(id='k28tpbn'), Comment(id='k28wag0'), Comment(id='k28wksq'), Comment(id='k29821y'), Comment(id='k29ca1u'), Comment(id='k25agfl'), Comment(id='k25a6ot'), Comment(id='k280jgi'), Comment(id='k24zl1t'), Comment(id='k25l3rk'), Comment(id='k28f8fy'), Comment(id='k26fzdm'), Comment(id='k29chia'), Comment(id='k2f09yz'), Comment(id='k29fhbu'), Comment(id='k27rkw1'), Comment(id='k252eam'), Comment(id='k2593e2'), Comment(id='k256qui'), Comment(id='k24y7zu'), Comment(id='k27x2st'), Comment(id='k251fu6'), Comment(id='k3atir3'), Comment(id='k25j1b2'), Comment(id='k24p08m'), Comment(id='k25p5tr'), Comment(id='k29kv7u'), Comment(id='k282q10'), Comment(id='k28ydgl'), Comment(id='k2afaw0'), Comment(id='k26ijiw'), Comment(id='k2g9qwm'), Comment(id='k2914ix'), Comment(id='k255nl2'), Comment(id='k25onrx'), Comment(id='k25oiy4'), Comment(id='k2508hi'), Comment(id='k282f2j'), Comment(id='k25praa'), Comment(id='k2586ni'), Comment(id='k289s2n'), Comment(id='k2atg7t'), Comment(id='k2av5df'), Comment(id='k29o0un'), Comment(id='k25izmo'), Comment(id='k25m2co'), Comment(id='k28aaii'), Comment(id='k28cn0u'), Comment(id='k2ban06'), Comment(id='k29tfbh'), Comment(id='k25krgt')]"
16s0csk,Difficult-Big-3890,,2023-09-25 18:47:37+00:00,False,,False,False,True,False,/r/datascience/comments/16s0csk/how_do_you_avoiddeal_with_the_discussion_of/,How do you avoid/deal with the discussion of causality when the project goal was predictive performance to start with?,"Have had quite a few experiences when a project starts with the goal of predictive performance but at the end causal questions were thrown at to answer based on the model. 

""When users are looking for casual relation, use Linear models e.g. MLR/Logit"" seems like a commonly given advice for such cases. But, throwing linear models without a proper experimental design, which is often out of scope, doesn't really give any realistic causal effect - think of Simpsons paradox. 

So, am I missing somethig here? What's your go to approach in such cases?",datascience,https://www.reddit.com/r/datascience/comments/16s0csk/how_do_you_avoiddeal_with_the_discussion_of/,36,27,1.0,"[Comment(id='k26hq11'), Comment(id='k28h5a8'), Comment(id='k27sdbd'), Comment(id='k27ugq2'), Comment(id='k2bj2os'), Comment(id='k2ao5yk'), Comment(id='k273wb0'), Comment(id='k28r90p'), Comment(id='k275mqv'), Comment(id='k281pat'), Comment(id='k28orn0'), Comment(id='k297ppw'), Comment(id='k27v9fh'), Comment(id='k26oxpz'), Comment(id='k2bvamh'), Comment(id='k2awo3d'), Comment(id='k278j6o'), Comment(id='k27gyat'), Comment(id='k27ezlb'), Comment(id='k282j5z'), Comment(id='k26vodh'), Comment(id='k294qx5'), Comment(id='k2a0b87'), Comment(id='k27adhl'), Comment(id='k27hiwx'), Comment(id='k27qpkt'), Comment(id='k27lzl1'), Comment(id='k27h4qd'), Comment(id='k284bpc'), Comment(id='k285il4'), Comment(id='k28qf6h'), Comment(id='k277uxh'), Comment(id='k29u3l0'), Comment(id='k2awisy'), Comment(id='k2812w9'), Comment(id='k284wce')]"
16sdcnt,Ok_Post_149,,2023-09-26 03:58:15+00:00,False,,False,False,True,False,/r/datascience/comments/16sdcnt/what_type_of_project_excites_you/,What type of project excites you?,"Over the last couple of months I've had a few motivational rollercoasters. One week I'm heads down and flying through my work, I absolutely love it. Other weeks it can't go by any slower and my motivation is super low. 

I started to realize that my shifts in motivation were project driven. When I genuinely like a project work is fun for me. When I hate the project it is the last thing I want to do. 

For me, my favorite projects are building web scrapers, preprocessing super messy data, and building visualization dashboards. At the moment I'm a Business Intelligence Manager, I'm considering shifting over to Data Engineering because that type of work just seems so much more fun to me. ",datascience,https://www.reddit.com/r/datascience/comments/16sdcnt/what_type_of_project_excites_you/,2,2,0.75,"[Comment(id='k28seid'), Comment(id='k28s7q4')]"
16sdaje,Open-Caterpillar3098,,2023-09-26 03:55:07+00:00,False,,False,False,True,False,/r/datascience/comments/16sdaje/data_registry_suggestions_for_ml_projects/,Data Registry suggestions for ML projects,"Looking for suggestions for data registry, with following requirements -

- Programmatic access for both read and write data back (DVC only provides reading data from repo)

- Versioning of all kinds of data (csv, text, images). MLflow provides a workaround to store data as artifacts - Is that good enough ?

- Data access control (user level access, both internal and external to projects) where clients can upload the data directly and DS teams can use it for experiments. 

- On premise solution with container support is preference. 

As of now, I have evaluated DVC, modelstore and mlflow. Please provide inputs",datascience,https://www.reddit.com/r/datascience/comments/16sdaje/data_registry_suggestions_for_ml_projects/,4,2,1.0,"[Comment(id='k2j4ivz'), Comment(id='k296don'), Comment(id='k2dl4fq'), Comment(id='k2d1slv')]"
16sd43a,Terrible-Hamster-342,,2023-09-26 03:45:52+00:00,False,,False,False,True,False,/r/datascience/comments/16sd43a/how_did_you_succeed_in_a_new_role_what_lessons/,How did you succeed in a new role? What lessons did you take from your previous role?,"When switching to a new role what did you do to ensure that you succeed? What lessons did you learn from your previous job that you took into your new job? 

For example Im in the process of switching jobs and one of the things I’ve learnt is that when delivering results (during fire drills) the way I write my code is focused on simply getting the results out vs being organized, efficient and scalable. While I get from point A to point B the way I get from point A to point B is not the most efficient. I think something I can do is take a step back and take a top down approach to problem solving when I enter my new role.",datascience,https://www.reddit.com/r/datascience/comments/16sd43a/how_did_you_succeed_in_a_new_role_what_lessons/,2,2,1.0,"[Comment(id='k29pa79'), Comment(id='k2aqs93')]"
16sfxuq,BusfahrerBernd999,,2023-09-26 06:20:32+00:00,False,,False,False,True,False,/r/datascience/comments/16sfxuq/power_bi_vs_tableau/,Power BI vs Tableau,"Hey everyone, so I have the opportunity to work more on data within my current job. I would be the only one in that type of field and would love to gain as much knowledge as I can to maybe later transition fully into a career in data. Should I choose to become an “expert” in Power BI or Tableau and why?

Thank you for your advice",datascience,https://www.reddit.com/r/datascience/comments/16sfxuq/power_bi_vs_tableau/,22,2,0.62,"[Comment(id='k290dwq'), Comment(id='k2a1pot'), Comment(id='k294v49'), Comment(id='k2cedpe'), Comment(id='k2dwbtc'), Comment(id='k2acync'), Comment(id='k2aijzt'), Comment(id='k29z9wh'), Comment(id='k2agxbq'), Comment(id='k2ai1x7'), Comment(id='k2az9a7'), Comment(id='k2atec4'), Comment(id='k2a8ijr'), Comment(id='k2a8x4h'), Comment(id='k2a1xd1'), Comment(id='k2aa604'), Comment(id='k2aazbp'), Comment(id='k2a6nkf'), Comment(id='k2abj1n'), Comment(id='k2a97m2'), Comment(id='k2abypg'), Comment(id='k2b0uje')]"
16s8ndq,Internal_Flower67,,2023-09-26 00:17:31+00:00,False,,False,False,True,False,/r/datascience/comments/16s8ndq/advice_on_comparing_time_series_datasets/,Advice on Comparing Time Series Datasets,"I am working on my master's degree and I have some data that I have no clue how to handle. Any advice would be appreciated.

I have triaxial accelerometer data(50 hz) for some quadruped animal along with internal body temperature (every 5 minutes). I have multiple days worth of this data, and am trying to look at the affect of activity on body temperature. Ideally, we should see activity rise, followed by temperature, and both will fall together as well.

I have already calculated energy: sqrt(x^2 + y^2 + x^2) and averaged that for every 5 minutes, so the activity and temp intervals match. Is this a good approach?

Also, how do I compare these datasets while accounting for the ""lag"" or affect of previous activity on current temperature? I'm not having any luck searching for methods to analyze this data.

Any help or suggestions are appreciated!",datascience,https://www.reddit.com/r/datascience/comments/16s8ndq/advice_on_comparing_time_series_datasets/,4,3,1.0,"[Comment(id='k28a5ib'), Comment(id='k28hel0'), Comment(id='k2fsnuw'), Comment(id='k2htezr')]"
16s7bx8,wolatid,,2023-09-25 23:19:35+00:00,False,,False,False,True,False,/r/datascience/comments/16s7bx8/nlp_data_cleaning/,NLP Data Cleaning,"I am currently using BERT model and wanted to do some data cleaning. I've tried stuff like removing punctuations and vocabulary / spell checking (e.g. pyspellchecker). However, I noticed that the 'autocorrect' function is inaccurate given also that the texts we handle are more on technical/financial terms.

Does anyone have a suggestion on how to further process the texts? There are also some texts there that are actual sql / python codes so I'm not sure how to eliminate those.

I am somehow contemplating to not do further text cleaning and just deal more on tweaking the hyperparameters instead.",datascience,https://www.reddit.com/r/datascience/comments/16s7bx8/nlp_data_cleaning/,3,3,1.0,"[Comment(id='k29qyly'), Comment(id='k2caixa'), Comment(id='k2ell3w')]"
16sdupt,haris525,,2023-09-26 04:24:21+00:00,False,,False,False,True,False,/r/datascience/comments/16sdupt/cross_encoders_for_long_documents_and_pragagraphs/,Cross Encoders for Long documents and pragagraphs,"Hi guys good evening, hope all is well! 

I need some opinions on using cross encoders for long text documents. I have a case where I have list of documents called documents A, and another list of documents called documents B. Based on semantic similarity I am developing a model that matches documents from list A to list B. Here is my current approach

&#x200B;

First I use a Bi-Encoder to encode both lists of documents (using the sentence-transformers/gtr-t5-xl)

Then I use FAISS to get top 100 results from the Bi-Encoder

Finally use a Cross-Encoder to re-Rank the documents returned 

Now my question is Cross-Encoders are usually good for a token limit of 1024 or less, but I am wondering is there a better way to compare longer documents? lets say if I was comparing math books for grade 10 in list A, and math books for grade 11 in list B, so see if there are any books that are similar in semantic context in list A, and B to see which books are like each other what approach should I take? 

Would moving to a vector database be the next best thing as I can keep adding to the database index as new documents are added? 

&#x200B;

Thanks, and would to hear your opinion",datascience,https://www.reddit.com/r/datascience/comments/16sdupt/cross_encoders_for_long_documents_and_pragagraphs/,0,1,1.0,[]
16rt739,artemis268,,2023-09-25 14:10:58+00:00,False,,False,False,True,False,/r/datascience/comments/16rt739/stuck_in_an_internship_with_no_data_science_work/,Stuck in an internship with no data science work,"

I'm doing an internship at this company which pays me an ok amount. Its a 3 month internship and the period is about to be over. Issue is that they give me 0 work. Also due to certain reasons they put me in an unrelated to my work department, so it's not like the work I would have done there would have mattered that much. 

I couldn't get any other internship as this was the best brand name and stipend I could get and the  placement  season is also over so I continued here considering the alternative is me sitting at home for 3 months. 

So my routine has been, come to office, learn my own skills, go home, I don't even see my manager anymore and he doesn't even care because they don't even require me. I have learnt a shit ton during this period and built a portfolio,  i spent all this office time to skill up and made myself competitive in the job market.

Problem is I have only 2 lousy project which I was asked to do to show as my internship expirience. Need your perspective, did I make a huge mistake in doing this and should have asked for more work from office even if it was in unrelated field and meangless?? 

I'm worried about what to say and show in my internship experience, when I talk to recruiters, is it possible to just lie and make up things you din in internship?? I'm planning on just making up fake lists of relevant tasks on my internship expirience section. 

Am i fucked or what? Idk. Sometimes i think im being smart, sometimes I'm think I'm a dumbfuck who focused on self learning instead of corporate projects. Helpp.",datascience,https://www.reddit.com/r/datascience/comments/16rt739/stuck_in_an_internship_with_no_data_science_work/,6,14,0.94,"[Comment(id='k252el0'), Comment(id='k25qb6u'), Comment(id='k26h7c2'), Comment(id='k276zgz'), Comment(id='k2575r9'), Comment(id='k2592mv')]"
16rjh59,Imaginesafety,,2023-09-25 05:29:33+00:00,False,,False,False,True,False,/r/datascience/comments/16rjh59/are_career_fairs_worth_it/,Are career fairs worth it?,"Graduate in December with MS and have a career fair opportunity this week. As I attend remotely, campus is 4 hours away. I'd have to do the drive there and back in the same day, so I want to know if there's potential for me to actually get value, or if I'll likely be wasting my time. I understand I'll have to make the best of it, and I'm confident I will, but I really just want to know if success stories in this field happen from networking at career fairs.

I don't have any leads yet, just been blindly applying online. A couple of rejections, but haven't heard back from a majority of applications which are probably ghost. Not much relevant experience in the field, trying to start out as a DA. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/16rjh59/are_career_fairs_worth_it/,29,42,0.92,"[Comment(id='k23nchm'), Comment(id='k23pimg'), Comment(id='k24fpdz'), Comment(id='k23o2ag'), Comment(id='k24mkhv'), Comment(id='k24v4g9'), Comment(id='k23pu6y'), Comment(id='k24uzsr'), Comment(id='k25e5gq'), Comment(id='k27zf5b'), Comment(id='k251lro'), Comment(id='k260mnn'), Comment(id='k26zhxn'), Comment(id='k29a53d'), Comment(id='k29c4n2'), Comment(id='k23pkvo'), Comment(id='k23ptay'), Comment(id='k24ajaq'), Comment(id='k23pgn2'), Comment(id='k24erf9'), Comment(id='k23qdbd'), Comment(id='k25h7qp'), Comment(id='k23vlgu'), Comment(id='k25eh4w'), Comment(id='k23q13d'), Comment(id='k23qy4x'), Comment(id='k2acrf4'), Comment(id='k25yijg'), Comment(id='k23syd1'), Comment(id='k2anaah')]"
16s724v,rojosquid,,2023-09-25 23:07:46+00:00,False,,False,False,True,False,/r/datascience/comments/16s724v/sanity_test_dummyclassifier/,"Sanity Test, DummyClassifier"," I  was advised to use DummyClassifier for a sanity test on the best model;  however I'm having a hard time finding instructions as of how to use it  and how to evaluate the results of said test.

Help.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16s724v/sanity_test_dummyclassifier/,0,1,1.0,[]
16rzglu,Senande,,2023-09-25 18:12:54+00:00,False,,False,False,True,False,/r/datascience/comments/16rzglu/modern_time_series_forecasting_with_python_book/,Modern Time Series Forecasting With Python (Book Review),"TLDR for those who don't want to read the whole thing: This is a nicely written book that exposes you to a lot of concepts but fails to teach them to you while providing abstract code that can only be understood after reading through all the custom functions and classes that the author uses.

&#x200B;

I will start by giving you some context:

I switched from economics to statistics this year while only having seen econometrics 1 meaning I had no prior theoretical knowledge of time series analysis but was interested on the field nonetheless. Since I was planning to learn how to code this summer, I bought this book to use it when I had the basics under control.

By the time late july had set I knew the basics of python and the book didi not ask more than that, ""*Since the book explains most concepts from the ground up, basic proficiency in Python is all you need. ""* on the author's own words. I started reading the book around that time and to be completely honest; my opinion from it was at the highest before reading and it only went downwards the more I advanced with it.

The first chapters consist of the basics of time series data (Barely any depth) followed by some preprocessing steps in which the author tries to teach the basics of missing value handling and visualization of the components of the data, ending the first section by exposing some of the classical models. All of this was done in 105 pages! 

The next section of this book exposes machine learning concepts for time series; this is where the two main problems I have with this book start to become apparent:

1- The explanations are very concise; which for complex subjects such as the ones the book covers it really becomes a problem.

2- The book uses an excessive amount of custom functions and classes by the author.

&#x200B;

**1.1 The book is way too short for the amount of content it pretends to teach.**

First things first; *how long* is the book? 

While in Packt's website and Amazon the book is said to be 552 pages long, the actual content of the printed copy I have is 505 pages; for 40€/$ this seems like a pretty nice deal; the problem is that if you look at the sheer amount of stuff this contains; it looks too good to be true; it is. The way so much content is compressed into the book is by cutting off a lot of the meat of what it is trying to teach; this is why I say that the book exposes you to a lot of concepts but fails to teach them to you; 500 pages is not enough for a book that teaches you basic analysis, ML and DL from the ground up, But how egregious can this be? There is only a single 28 pages long chapter for classical statistical models; the explanation for ARIMA is two pages long; this is how bad it gets. You could say that this book is specialized in ML and DL and you would be correct in that statement but the ML part is 154 pages long and the DL one is 194; it's simply too short with its explanations and it makes the book outright frustrating to follow once you reach the Deep Learning section. 

&#x200B;

**1.2 The book has an identity crisis regarding the group it's marketed towards.**

In the amazon page, it says that the book is directed towards Data Scientists but that everything is explained from the ground up so only the basics of Python Programming are strictly needed even though knowledge of ML would help.

Ok, so what is it? I can tell you that the book is overwhelming for beginners; not because the models are explained at their full complexity but because it is done way too fast. Is it for experienced data workers who want to learn time series? Well, you've got some pages dedicated to basic pandas commandas and ML and DL are ""taught"" from the ground up while almost totally neglecting the classical models and any kind of inference so not really. The amazon page says ML knowledge is is recommended and I'd say that maybe if you've reached that point then you may understand the book but for beginners it's simply inaccesible.

It's not just ML though; the book uses Plotly for visualizations; If you know basic python you will most likely go the matplotlib route and showing plotly code without explaining it is a decision that shows even more how this book simply is not for beginners.

The book just explains badly; I am taking the edX MIT Machine Learning Course and while it is more complex; it is perfectly understandable; this book just half-explains stuff and while people who know what they are doing may be able to cope with it, I get the feeling that if you understand the concepts the book is teaching then it may be because you have already moved past them.

&#x200B;

**2. The unbearable custom code**

Up to here I could maybe understand that the explanations simply weren't from me and the book may be better under other people's eyes but it is not the explanations that I find severely short and lacking the largest problem I have with this book; it is the code it uses.

Right from the first  coding chapter the author uses custom functions and classes and it is extremely frustrating. To deal with time series in ML the author uses his own code and while it may be more comfortable, you have to know how to use it and there lies a huge problem; the functions and classes DO NOT have docstrings and because the author does not explain them properly in the book, you have to go to the function definitions to get a sense of what each component is doing. This is simply unbearable and if you do not already know ML and DL, this just adds another layer of abstraction which will make a complex part even more difficult to understand.

It is not only that they are not properly documented but they are not implemented onto a package; it despite all you still try to persevere and make real world usage of this book you will have to copy the full src folder in each folder you are going to make use of the material. The author claims that after finishing the book you are going tobe able to *""build world-class time series forecasting systems"",* But how though? Is the author really saying that you are going to need to make a package out of HIS code to make it usable? This is for me the ultimate dealbreaker.

&#x200B;

**Final comments**

&#x200B;

This was my first contact with Machine Learning and I can tell you that It's hard to think there could be a worse introduction than this. There is a point about halfway through the book in which I stopped working with the code and just decided to finish it to warn others that it simply isn't a good product. The author clearly knows what he's talking about but he but off more than what he could chew and when the best thing about the book are the references and further reading materials that the author recommends, you can see that this book simply is not good.

3.5/10, It just isn't good.

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16rzglu/modern_time_series_forecasting_with_python_book/,3,2,1.0,"[Comment(id='k26lvup'), Comment(id='k26thd1')]"
16r5v0j,wonko_the_sane__,,2023-09-24 19:07:26+00:00,False,,False,False,True,False,/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/,What do data scientists do anyway?,I have been working in a data science Consulting startup as a data scientist. All I've done is write sql tables. I've started job hunting. I want to build AI products. What job description would that be? I know this sounds stupid but I don't want to be an analyst anymore,datascience,https://www.reddit.com/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/,93,139,0.86,"[Comment(id='k21fwx1'), Comment(id='k219dbq'), Comment(id='k21b4a3'), Comment(id='k21a4vq'), Comment(id='k21furh'), Comment(id='k21l9gd'), Comment(id='k218k56'), Comment(id='k23nok7'), Comment(id='k21q9t3'), Comment(id='k21ecyl'), Comment(id='k21npvj'), Comment(id='k21wmsv'), Comment(id='k22vm2l'), Comment(id='k21pvuj'), Comment(id='k21u49j'), Comment(id='k23va37'), Comment(id='k21zy95'), Comment(id='k22v1e6'), Comment(id='k23vhsn'), Comment(id='k24jxhs'), Comment(id='k257bnp'), Comment(id='k2fxgxz'), Comment(id='k23f9z4'), Comment(id='k21oy5h'), Comment(id='k23rhis'), Comment(id='k25aewl'), Comment(id='k22l6gv'), Comment(id='k232qpy'), Comment(id='k24eaam'), Comment(id='k24efxv'), Comment(id='k24xmer'), Comment(id='k250fn5'), Comment(id='k258l5t'), Comment(id='k25cyuw'), Comment(id='k262nq0'), Comment(id='k273cwv'), Comment(id='k294zqw'), Comment(id='k2bplnr'), Comment(id='k25y9x6'), Comment(id='k21door'), Comment(id='k21d441'), Comment(id='k22y8ko'), Comment(id='k24ovdx'), Comment(id='k263y7t'), Comment(id='k21vke2'), Comment(id='k24b4gn'), Comment(id='k24bnfw'), Comment(id='k218za5'), Comment(id='k22x74x'), Comment(id='k24bz4f'), Comment(id='k24fmf3'), Comment(id='k2b4sub'), Comment(id='k21lx54'), Comment(id='k23w1uo'), Comment(id='k21wfzj'), Comment(id='k23bpzb'), Comment(id='k24rnvf'), Comment(id='k24ye9a'), Comment(id='k25emi0'), Comment(id='k21cuef'), Comment(id='k25tla2'), Comment(id='k273mly'), Comment(id='k22xmvw'), Comment(id='k25dwrf'), Comment(id='k2r1rx4'), Comment(id='k21qsx2'), Comment(id='k22i61g'), Comment(id='k25zxrt'), Comment(id='k257blh'), Comment(id='k25016a'), Comment(id='k28isba'), Comment(id='k25k630'), Comment(id='k25fhom'), Comment(id='k22ldev'), Comment(id='k27s9zf'), Comment(id='k272zom'), Comment(id='k27s17o'), Comment(id='k265rdd'), Comment(id='k28rwsi'), Comment(id='k25mjxw'), Comment(id='k25ftq3'), Comment(id='k22xclq'), Comment(id='k27sokg'), Comment(id='k273ub9'), Comment(id='k25p7j8'), Comment(id='k25ghvx'), Comment(id='k23023e'), Comment(id='k22y8cn'), Comment(id='k274bxx'), Comment(id='k231nzk'), Comment(id='k2335wc'), Comment(id='k274mvt'), Comment(id='k24cf0a')]"
16rp7wj,MrBarret63,,2023-09-25 11:17:43+00:00,False,,False,False,True,False,/r/datascience/comments/16rp7wj/creating_insights_from_battery_monitoring/,"Creating insights from Battery monitoring parameters (State-of-charge, battery cell voltages, temperature, etc.) to use with AI or model based.","So, in a new role currently and I decided to pursue the health monitoring and impending failures of batteries (Lithium Iron Phosphate, Lithium Ion and a few lead-acid as well) but having never done it before I am not so confident on my approach.

Currently what I have in mind is using the past battery data for a specific site, I would find out the variation in SOC during charging and discharging state and compare it with current day rates while alerting for large changes.

Also, if multiple batteries are connected and while discharging/ charging their SOC deviate too far from each other (standard deviation or difference in min max) I would alert that something is not right.

A bit primitive approaches but wanted something to get going.

Would love to hear from you guys' different approaches that could be used, or you guys have used in the industry.

Thanks!  


PS. Let me know if you need more information.",datascience,https://www.reddit.com/r/datascience/comments/16rp7wj/creating_insights_from_battery_monitoring/,8,7,0.9,"[Comment(id='k24i2xv'), Comment(id='k256xzt'), Comment(id='k2efjgr'), Comment(id='k25fhah'), Comment(id='k278xdt'), Comment(id='k28zves'), Comment(id='k2ab7m8'), Comment(id='k2algau')]"
17p2ebi,dtransposed,,2023-11-06 13:11:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17p2ebi/a_video_game_that_pays_lessons_learned_from/,A Video Game that Pays: Lessons Learned from Working Remotely (as ML Engineer),"Hello everyone! Two years ago, I shifted to fully remote work after spending considerable time in traditional office settings. Throughout this journey, I've accumulated valuable insights, which I've now compiled into a blog post. I hope my experiences can offer some useful guidance, regardless of your background: [https://dtransposed.github.io/blog/2023/11/02/Remote-SWE/](https://dtransposed.github.io/blog/2023/11/02/Remote-SWE/)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17p2ebi/a_video_game_that_pays_lessons_learned_from/,0,3,1.0,[]
17oj49b,FallMindless3563,,2023-11-05 19:07:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oj49b/arxiv_dives_attention_is_all_you_need_how/,Arxiv Dives - Attention Is All You Need - How Transformers Work,"We have a reading club every Friday where we go over the fundamentals of a lot of the state of the art techniques used in Machine Learning today. Last week we dove into the seminal ""Attention Is All You Need"" Paper.

Posted the notes and recap here if anyone finds it helpful: 

[https://blog.oxen.ai/arxiv-dives-attention-is-all-you-need/](https://blog.oxen.ai/arxiv-dives-attention-is-all-you-need/)

Also would love to have anyone join us live on Fridays! We've got a pretty consistent and fun group showing up.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oj49b/arxiv_dives_attention_is_all_you_need_how/,7,47,0.94,"[Comment(id='k7yyc1a'), Comment(id='k7zy2qz'), Comment(id='k81orhf'), Comment(id='k81wfw5'), Comment(id='k7zd6h1'), Comment(id='k806u5c')]"
17ov6ys,algo_ur,,2023-11-06 04:55:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ov6ys/hey_all_can_you_review_my_project_idea_please/,"Hey all, can you review my project idea please..","I'm in my sophomore year of college. I'm thinking to participate in a college level competition. I that we have to build something in a span of two months. I'm interested in web d and ml. So I'm decided to build something in the intersection of both domains. So I'm going build a web based game and automate it using reinforcement learning. The game is similar to hill climbing racing. So how feasible this idea is to complete in two months considering I need learn most of the concepts (I know some basics and fundamentals in both domains). Is this good project for two months or should change , can you provide some other ideas or how should make this better? Thanks:)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ov6ys/hey_all_can_you_review_my_project_idea_please/,3,8,1.0,"[Comment(id='k817wfc'), Comment(id='k81uz6o'), Comment(id='k81idrq')]"
17p488y,ledmmaster,,2023-11-06 14:40:59+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17p488y/how_to_get_feature_importance_in_random_forests/,How To Get Feature Importance in Random Forests,,learnmachinelearning,https://forecastegy.com/posts/feature-importance-in-random-forests/,0,1,0.67,[]
17p45pv,chrise6102,,2023-11-06 14:37:46+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17p45pv/where_to_go_from_here/,Where to go from here?,"So I'm a self taught machine learning... hobbyist I guess and I've hit something of a wall with my progression, I'm interested in any ideas of where to go next.

In terms of courses, I've done Andrew ngs coursera course and an excellent 'python for machine learning and data science' course on Udemy, as well as various other mini courses and tutorials to fill in gaps.

I'm confident applying most algorithms I've come across and presenting the data too. I've had a crack at various kaggle competitions and have performed... OK on them.


What I'm struggling with is how to improve with these competitions. Often what I'm finding difficult is actually interpreting the complex real life datasets and processing the messy data which can be in a variety of formats into something I can tackle with algorithms. I've had to rely pretty heavily on looking at other people's solutions, not for inspiration which would be fine but more because I have no idea where to start on them! 
Most courses I've come across are too basic to help with this and I'm not sure how to phrase my rather vague problem well enough to simply Google how to proceed.

Hopefully I've got my point across here and someone at least will know what I'm talking about and can suggest ideas on how to really improve with these competitions and other 'real world' applications.

Many thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17p45pv/where_to_go_from_here/,1,1,1.0,[Comment(id='k82s5k1')]
17p3lkw,Last-Theory-6186,,2023-11-06 14:12:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17p3lkw/help_with_building_a_realtime_audio_to_text/,Help with building a real-time audio to text transcription,"I wanted to build a platform that can take audio from livestream videos and translate them in real-time into text, just like youtube captions does (but want it to be live).  
Please provide me some guidance on how do i get started with this project.  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17p3lkw/help_with_building_a_realtime_audio_to_text/,0,1,1.0,[]
17p2v88,Intelligent-Field-97,,2023-11-06 13:35:36+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17p2v88/learn_about_transformer_models_with_this_friendly/,Learn about Transformer Models with this friendly video!,,learnmachinelearning,https://www.youtube.com/watch?v=qaWMOYf4ri8,0,1,0.67,[]
17onpep,robml,,2023-11-05 22:33:29+00:00,False,,1699228411.0,False,True,False,/r/learnmachinelearning/comments/17onpep/for_those_that_have_read_the_more_comprehensive/,For those that have read the more comprehensive ML theory books...,"How would you personally update your recommendations for someone who may have some basics of ML down and practice and wants to delve deeper into theory without redundant repetition (this isn't me but I do think it will be useful as a whole). 

Out of these 5 authors/books which I think are still pretty relevant:

- Elements of Statistical Learning
- Bishop's Pattern Recognition
- Norvig's AI book
- Murphy's ProbML from 2022/3
- Goodfellow's Deep Learning book

The assumption is that the person has some experience with model frameworks and the basics of maths. I think it takes more skill to curate fewer resources than more, so my question to those who have read these which one they would recommend. 

Disclaimer: even I haven't read all of these fully, but have read over time more and more parts of these. I also have yet to read Murphy's newer books which seem much easier to digest than the 2012 one.

I also find it a shame that iirc only Norvug covers genetic algorithms which altho not in the limelight still prove useful.

Looking forward to others' opinions, and kindly mention what you have read and if you haven't read one of the 5.

Edit: added Goodfellow's book",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17onpep/for_those_that_have_read_the_more_comprehensive/,2,13,0.94,"[Comment(id='k7zv15h'), Comment(id='k7zxxsa')]"
17p0tft,anujtomar_17,,2023-11-06 11:40:08+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17p0tft/data_science_and_machine_learning_unleashing_the/,Data Science and Machine Learning: Unleashing the Power of Data,,learnmachinelearning,https://www.quickwayinfosystems.com/data-science-and-machine-learning-unleashing-the-power-of-data/,0,0,0.33,[]
17oxb3u,mimivirus2,,2023-11-06 07:19:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oxb3u/how_do_i_implement_cutmix_augmentation_for/,How do I implement CutMix augmentation for semantic segmentation in PyTorch?,"Context: I'm working on a binary semantic segmentation task on 3D medical images, using PyTorch and MONAI. Currently I have setup my Dataset and DataLoader using the dictionary API of the MONAI library, so that iterating through my training set DataLoader returns a dictionary with keys 'image' and 'label', each a tensor of shape  \[4, 1, 128, 128, 128\] (batch\_size = 4, num\_channels=1).   
I've been trying to implement CutMix on my DataLoader so that i works on both 'image' and 'label', but the current v2 implementation of CutMix in torchvision is intended for classification tasks and only works on images, not labels (if I've understood correctly).  


What is the minimally invasive way to add CutMix to my data pipeline?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oxb3u/how_do_i_implement_cutmix_augmentation_for/,0,2,1.0,[]
17oohmz,bomankleinn01,,2023-11-05 23:08:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oohmz/how_important_is_calculus_in_ml/,How important is Calculus in ML?,"Currently a first year undergrad interested in ML, I heard all you need in ML is Linear Algebra and Statistics but here and there I would see Calculus thrown around side by side these too, so I’m little confused. Currently I’m doing some Linear algebra and stats courses should I add in some Calculus as well or that wont be necessary and if so how far should I go in Calculus (e.g. Calc I,II,III, etc..).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oohmz/how_important_is_calculus_in_ml/,10,9,0.68,"[Comment(id='k80jgrr'), Comment(id='k80q3rj'), Comment(id='k80n8uc'), Comment(id='k81c12c'), Comment(id='k8231rm'), Comment(id='k7zxl9k'), Comment(id='k822et6'), Comment(id='k7zy0cf'), Comment(id='k7zzyeg'), Comment(id='k81c8kq')]"
17p020o,IOvOI_owl,,2023-11-06 10:49:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17p020o/can_you_help_me_to_decide_on_a_laptop/,Can you help me to decide on a laptop?,"I am studying machine learning, and so far it has been fine with CPU alone, but recently I've encountered language models like BERT and CPU computations take too long. Long story short I want to try to run computations on GPU. So the laptops I am considering are:

[https://www.tuxedocomputers.com/en/TUXEDO-InfinityBook-Pro-16-Gen8.tuxedo](https://www.tuxedocomputers.com/en/TUXEDO-InfinityBook-Pro-16-Gen8.tuxedo)

[https://www.tuxedocomputers.com/en/TUXEDO-Stellaris-16-Gen5.tuxedo](https://www.tuxedocomputers.com/en/TUXEDO-Stellaris-16-Gen5.tuxedo)

[https://www.tuxedocomputers.com/en/TUXEDO-Stellaris-17-Gen5.tuxedo](https://www.tuxedocomputers.com/en/TUXEDO-Stellaris-17-Gen5.tuxedo)

They all come with Linux preinstalled from the shop.

The first one has the core i7 with GeForce RTX 4070.

The first one has the Core i7 with GeForce RTX 4070.

The difference between the latter is screen size. They also cost 1000 euros more than the first one. The question is will I really benefit from having 4090 with 16 gigs of memory over 4070 with 8 gigs? The mobility sacrifice is big. The first one weighs \~2.1 kilograms with a charger, the second one weighs \~3.6 kg with a charger, and the last one weighs 3.9 kg with a charger. Although I work from home now and rarely bring my laptop anywhere, mobility is not a priority, on the other hand, I like to lay on a couch while working and am afraid that a 2.5 kg laptop will be just too heavy to do so. What would you advise?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17p020o/can_you_help_me_to_decide_on_a_laptop/,1,1,1.0,[Comment(id='k824s2h')]
17onikf,saasyp,,2023-11-05 22:24:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17onikf/ai_master_in_europe/,AI Master in Europe,"Hi everyone,  
a bit of context about me. I'm in my last year of Computer Science in Italy, actually I'm one month into an internship which will last about 2 more months and hopefully next week I'll have my last exam.  
I've started looking around to see what to do next and I think I'll continue the studies with an Artificial Intelligence master's degree I still don't know where but the only thing I know is that I want to move abroad.  
I would like to ask you which would be the best options within Europe, I know some in Germany and Netherlands but I would love to hear your opinions about it.  
Thanks to everyone who will take some of their time to reply!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17onikf/ai_master_in_europe/,10,8,0.79,"[Comment(id='k81jgs6'), Comment(id='k818rhw'), Comment(id='k81snl3'), Comment(id='k7zpzi8'), Comment(id='k80kx2f'), Comment(id='k7zpl1r'), Comment(id='k81k3rh'), Comment(id='k81u7g1'), Comment(id='k7zqfem'), Comment(id='k82ggmn')]"
17oz54n,unlimited_void_bkk,,2023-11-06 09:39:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oz54n/straight_out_of_highschool_in_terms_of_maths/,Straight out of highschool in terms of maths knowledge. What books/courses should I take to understand Elements of statistical learning?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oz54n/straight_out_of_highschool_in_terms_of_maths/,4,0,0.5,"[Comment(id='k820cmb'), Comment(id='k820uid'), Comment(id='k82hosg'), Comment(id='k82km01')]"
17oobc1,ProfSwagometry,,2023-11-05 23:00:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oobc1/machine_learning_for_robotics_project_too/,Machine Learning for Robotics project - too ambitious?,"I hope this is an appropriate question for this sub!

I have been interested in the potential use of machine learning for optimising robot performance. I want to undertake my final year engineering project in this. [**This paper**](https://www.science.org/doi/full/10.1126/scirobotics.aav1488) I've found seems to do almost exactly what I want to investigate, and it sounds so interesting! The problem is I don't have all that much time for my project and, though I would love to, I can't risk getting in above my head for the sake of my honours degree.

If I were to try and replicate the results of this research in the context of my independent project I'd probably need to make a robotic gripper, hook it up with sensing equipment and run some tests before making my machine learning model to improve it in a certain way.

Anyway my question is, assuming I'd be able to design and build this gripper rig by mid-December, would I be allowing myself enough time to learn enough to code a ""simple"" ML model by mid March?

Also I presume obtaining sufficient high quality sensory data could be a challenge.

I'm very keen to get into ML. I'm not a programmer but I used to make Arduino projects using C++, Matlab is used pretty heavily in my course and I have used Python a little. I've got a strong foundation in linear algebra and a pretty good understanding of it, as well as matrices.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oobc1/machine_learning_for_robotics_project_too/,4,6,0.88,"[Comment(id='k807dcx'), Comment(id='k81taez'), Comment(id='k82c4hy'), Comment(id='k81xpk5')]"
17oxtt2,DwaywelayTOP,,2023-11-06 07:59:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oxtt2/looking_for_good_learning_sources_around_llm/,Looking for good learning sources around LLM?,"Are there any good content sources that explains all the concepts associated with generative AI (ex: RL, RLHF, transformer, etc) from the ground up in extremely simple language (using analogies/stories of things that would be familiar to say a 10-12 year old)? Also would prefer channels which explain the concepts in a sequential manner (so that easy to follow) and make short and crisp videos

If yes, could you kindly comment below with the suggestions. If not, could you comment whether something like that would be useful to you and ideally why also?

Big thanks in advance 🙏

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oxtt2/looking_for_good_learning_sources_around_llm/,1,0,0.5,[Comment(id='k81me4r')]
17owkdc,AhmedHailane,,2023-11-06 06:25:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17owkdc/fake_news_detection_mandarin_language/,Fake news detection (Mandarin language),"Hey guys I'm new to machine learning and i want to start with a fun project for me ""Fake news detection in mandarin language"". And It would be nice if you guys could help me with getting to know what are the things that i need to make this project work.

Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17owkdc/fake_news_detection_mandarin_language/,0,0,0.5,[]
17ocqic,skadoodlee,,2023-11-05 14:09:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ocqic/looking_for_a_comprehensive_up_to_date_source/,"Looking for a comprehensive, up to date source that goes into mathematical detail and implementation. Which one of these should I spend my time on in 2023?","1. ISLP
2. Mathematics for machine learning (Deisenroth)
3. [d2l.ai](https://d2l.ai/)
4. [https://udlbook.github.io/udlbook/](https://udlbook.github.io/udlbook/)
5. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow
6. [https://www.deeplearningbook.org/](https://www.deeplearningbook.org/) (this seems old?)

3 and 4 for example seem quite similar, and im wondering if reading a stats book like 1 is very beneficial for applied AI once you have done or before commiting to something like 3 or 4. From what I hear 5 is also great but im not sure Tensorflow is still the way to go going forward?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ocqic/looking_for_a_comprehensive_up_to_date_source/,16,17,0.96,"[Comment(id='k7y5x4s'), Comment(id='k7xz70j'), Comment(id='k7xuw8k'), Comment(id='k7ydky2'), Comment(id='k7zm7bo'), Comment(id='k7zyzt6'), Comment(id='k7zji06'), Comment(id='k7y0s3s'), Comment(id='k7y10mx'), Comment(id='k7zjalo'), Comment(id='k7zos5c'), Comment(id='k7ycfhx'), Comment(id='k8008w5'), Comment(id='k7zpx9o'), Comment(id='k7yf7o0'), Comment(id='k7yjsqe')]"
17ooz6a,chyavankoushik,,2023-11-05 23:30:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ooz6a/training_an_autoencoder/,Training an Autoencoder,"Hello fellow ML enthusiasts,

I'm currently working on a project that involves utilizing an autoencoder as a denoising system. My training dataset consists of 40,000 images, and I've successfully trained a convolutional neural network (CNN) autoencoder. However, I've observed that while the autoencoder's outputs are impressive, the reconstruction process removes critical information from the images, which I require for the next stages of my project. 

I'm aware that for classification tasks, TensorFlow allows importing pre-trained ImageNet weights into a neural network. My question is whether there are any state-of-the-art autoencoders with similar capabilities. In other words, are there pre-trained autoencoders whose weights I can directly import into my neural network for image reconstruction? If such pre-trained autoencoders exist, I could potentially apply transfer learning, fine-tune the network, and adapt it for my specific use case. 

Alternatively, if pre-trained autoencoders aren't readily available, I would appreciate guidance on how to improve the performance of the autoencoder I've trained. I've included details about the network architecture I've developed and the training process I've followed. Please take a look.

`input = tf.keras.layers.Input(shape=(INPUT_IMG_W, INPUT_IMG_H, 3))`  
`# Encoder`  
`x = tf.keras.layers.Conv2D(64, (3, 3), activation=""relu"")(input)`  
`x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)`  
`x = tf.keras.layers.Conv2D(32, (3, 3), activation=""relu"")(x)`  
`x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)`  
`x = tf.keras.layers.Flatten()(x)`  
`x = tf.keras.layers.Dense(2048, activation=""relu"")(x)`  
`x = tf.keras.layers.Dense(1024, activation=""relu"")(x)`  
`# Decoder`  
`x = tf.keras.layers.Dense(1024, activation=""relu"")(x)`  
`x = tf.keras.layers.Dense(2048, activation=""relu"")(x)`  
`x = tf.keras.layers.Dense(3872, activation=""relu"")(x)`  
`x = tf.keras.layers.Reshape((11, 11, 32))(x)`  
`x = tf.keras.layers.UpSampling2D(2)(x)`  
`x = tf.keras.layers.Conv2DTranspose(32, (3, 3), activation=""relu"")(x)`  
`x = tf.keras.layers.UpSampling2D(2)(x)`  
`x = tf.keras.layers.Conv2DTranspose(64, (3, 3), activation=""relu"")(x)`  
`x = tf.keras.layers.Conv2D(3, (3, 3), activation=""sigmoid"", padding=""same"")(x)`  
`# Autoencoder`  
`autoencoder = tf.keras.models.Model(input, x)`  
`autoencoder.summary()`

Training the model

`model_opt = tf.keras.optimizers.Adam()`   
`loss_fn = tf.keras.losses.MeanSquaredError()`  
`epochs = 500`  
`batch_size = 100`  
`n = len(df_train)`  
`@tf.function`  
`def train_step(model, X):`  
 `with tf.GradientTape() as record:`  
 `outputs = model(X, training=True)`  
 `loss_value = loss_fn(X, outputs)`  
 `gradient = record.gradient(loss_value, model.trainable_variables)`  
 `model_opt.apply_gradients(zip(gradient, model.trainable_variables))`  
`for ep in range(epochs):`  
 `x_train = df_train.sample(n, replace=False)`  
 `for i in range(n//batch_size + 1):`  
 `batch_data = x_train.iloc[i*batch_size:(i+1)*batch_size]`  
 `batch_data = process_image_batch(batch_data)`  
 `train_step(`  
 `autoencoder,`  
 `tf.constant(np.expand_dims(batch_data, -1))`  
`)`  
 `print(""Epoch %5d completed""%(ep+1))`

&#x200B;

Thanks in advance :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ooz6a/training_an_autoencoder/,1,3,1.0,[Comment(id='k825wfy')]
17om2c0,unlimited_void_bkk,,2023-11-05 21:21:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17om2c0/is_khan_academy_math_enough_to_understand/,Is khan academy math enough to understand Elements of statistical learning,"Math courses like linear algebra, calculus, statistics and probability, enough to understand Elements of statistical learning for someone who is fresh out of high school?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17om2c0/is_khan_academy_math_enough_to_understand/,9,3,0.72,"[Comment(id='k80hzei'), Comment(id='k80ggp2'), Comment(id='k80hxoi'), Comment(id='k81fbyx'), Comment(id='k807myv'), Comment(id='k82gesb'), Comment(id='k80gnp7'), Comment(id='k80hjzi')]"
17on33s,jgonzalez-cs,,2023-11-05 22:06:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17on33s/structured_alternative_to_universitycollege_for/,Structured alternative to university/college for studying ML?,"I was wondering if there was a learning/education platform similar to Duolingo for learning ML.

I love how Duolingo has bite-sized lessons and gamification features like lives, gems, XP, leaderboards, etc. I have a 55 day streak of studying Japanese and I've learned almost all the Hiragana (Japanese characters for pronouncing words) which is amazing because I have like no discipline so I feel like the gamification works X)

I don't have the time (FT job) or money for enrolling in a class for ML, so I was wondering if there's something like Duolingo for studying ML.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17on33s/structured_alternative_to_universitycollege_for/,1,2,0.75,[Comment(id='k807hnl')]
17oen8h,ml_w0lf,,2023-11-05 15:44:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oen8h/ml_resource_compilation/,ML Resource Compilation,"Does anyone know of a learning resource compilation, GitHub, or Meta Post where someone has broken the learning down into ingestable chunks?

Everyone is asking for resources- would be interesting to see what everyone has and then put it in one place.

I would be willing to work on putting this together with a few others in the respective fields (i.e. math, ML/AI, CS, SWE, etc.).

Thoughts, comments?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oen8h/ml_resource_compilation/,4,5,1.0,"[Comment(id='k7zq5zl'), Comment(id='k81kkiw'), Comment(id='k7zqust')]"
17opcsp,Science-man777,,2023-11-05 23:47:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17opcsp/review_of_koalawriter_uncover_the_tremendous_value/,Review of KoalaWriter – Uncover the Tremendous Value!,"""There are many great options for AI writing assistants on the market right now, and it can be hard to know which one to use.  I have spent my hard-earned cash testing some of these, and I can tell you that they are not all created equal!  Sometimes you simply get what you pay for, but some of us have to work on a budget.  When you are forced to pay as reasonable a price as possible and yet get as much out of each dollar spent, you are looking for VALUE. 

In this article, we will be talking about one of the perhaps lesser-known options out there that has been generating some buzz about its value, easy-to-use interface,  and overall quality, and that is [KOALAWRITER](https://koala.sh/?via=GetStarted). If you are considering testing an AI writer that is good at generating high-quality content quickly, this might be what you are looking for.  

To help you out, we have described the features, costs, strengths, and weaknesses of this product along with links and videos to help you make this decision. The clickable table of contents can help you skip to the section most interesting to you. If this is something you think would work for you, please consider using the links in this article, as it helps us continue to bring great content and information on these new tools.""

If you are interested in the full review: [https://ai-solutions.pro/review-of-koalawriter/](https://ai-solutions.pro/review-of-koalawriter/)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17opcsp/review_of_koalawriter_uncover_the_tremendous_value/,0,0,0.33,[]
17odmsg,Wasim-__-,,2023-11-05 14:56:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17odmsg/first_order_logicprover9/,"First order logic,prover9","  
 can someone help me with converting, these statements to prover9 encoding, i have tried so many times, able to get the output with $F but the exact goal is not achieved,  
**% A1: Not more than one person killed Alicia.**  
all X all Y (Defeatedlled(X, Alicia) & Defeated(Y, Angelica) -> X = Y).

  
**% A2: No person loathes every person.**  
exists X exists Y (Person(X) & Person(Y) & -Dislikes(X, Y)).

  
**% A3: Alicia dislikes every person except Benjamin.**  
all X (Person(X) & X != Benjamin & X != Alicia -> Dislikes(Alicia, X)).

  
**% A4: Every person who is not taller than Alicia is disliked by Benjamin.**  
all X (Person(X) & -Taller(X, Alicia) -> Dislikes(Benjamin, X)).

  
**% A5: Benjamin, Alicia, and the chef dwell at the Enchanted\_Estate and are the only people who dwell there.**  
all X (Dwells(X, Enchanted\_Estate) & X != Benjamin & X != Alicia & X != Chef -> false).

  
**% A6: A person who dwells at the Enchanted\_Estate killed Alicia.**  
exists X (Dwells(X, Enchanted\_Estate) & Defeated(X, Alicia)).

  
**% A7: No person that Alicia dislikes is disliked by the Chef.**  
all X (Dislikes(Alicia, X) -> -Dislikes(Chef, X)).

  
**% A8: Alicia is not Benjamin.**  
Alicia != Benjamin.

  
**% A9: Benjamin dislikes all people that Alicia dislikes.**  
all X (Dislikes(Alicia, X) -> Dislikes(Benjamin, X)).

  
**% A10: A defeater is never taller than their target and always dislikes their target.**  
all X all Y (Defeated(X, Y) -> -Taller(X, Y) & Dislikes(X, Y)).

  
**% GOAL: Find the person who Defeated Alicia.**  
exists X (Defeated(X, Alicia)).  ---or expression that says  benjamin defeated alicia, or find out who it is.  
The goal is to determine who defeated Alicia.  ie exists X(defeat(X,Alicia) & X=one who defeated her).  its more likely its Benjamin.  
Consider:  
allowed:  names: chef, alicia, benjamin, enchanted\_estate  
properties: Person  
relations: Dwells(), Dislikes(), Taller(), Defeated()  
&,|,-> ,=,!=,(),all,exists.   
Thanks in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17odmsg/first_order_logicprover9/,0,5,1.0,[]
17on62j,CorMazz,,2023-11-05 22:10:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17on62j/identify_steady_state_points_in_transient_data/,"Identify ""Steady State"" Points in Transient Data","I have a lot of transient data of different parameters, lets say ""Velocity, Flow Rate, Density, Temperature, Pressure... etc"".

For certain time periods, all of these data points would be relatively (ignoring noise) stationary. This would be a steady state period. A steady state period is continuous in the time domain. Other times, one or more of those different parameters will be changing. This is a transient period. This is also continuous in the time domain.

Is there some sort of unsupervised algorithm that can determine when I am at relatively ""steady-state"" conditions vs. transient conditions while respecting the time dependency of those classifications (meaning that steady state periods that separated by a transient period won't both be put into the same 'steady state' cluster)?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17on62j/identify_steady_state_points_in_transient_data/,0,1,1.0,[]
17of2hy,sharyphil,,2023-11-05 16:04:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17of2hy/machine_translation_minimal_dataset_for_finetuning/,Machine translation minimal dataset for fine-tuning,"Hi, I hope it's appropriate to post here, I couldn't find any active subreddits dedicated to machine translation specifically. 

I am working on a machine translation project for a low-resource language and am currently creating a parallel corpus that will later be used to fine-tune GPT 3.5.

The sentences will have to be manually translated and I would like them to cover most everyday and universal topics, that's why I wanted to ask if there is an industry standard data set for such occasions? 

I came across [https://paperswithcode.com/datasets?task=machine-translation](https://paperswithcode.com/datasets?task=machine-translation), but I can't see any specific data set that would be widely used.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17of2hy/machine_translation_minimal_dataset_for_finetuning/,2,3,1.0,"[Comment(id='k7yqt20'), Comment(id='k7zlb31')]"
17olzgq,ade17_in,,2023-11-05 21:18:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17olzgq/what_should_be_my_next_target/,What should be my next target?,"Hello folks, I've been on my journey to be a ML Researcher/Engineer and now feel like I'm stuck at things forever and can't move forward. Experienced members please take out few minutes and suggest. 😄 

Here is my background and what I've done till now. 
1. Bachelors - Done with a full-time internship as ML Engineer. 
2. Masters - on-going with major in AI and ADAS. Top university and top 10 AI hub. 
3. Working part-time as student researcher at top research university (9 months - on-going) and work on algorithms and ML. 
4. I spend 2 days per week dedicated only to my projects and Kaggle. Have good projects hosted on git and good record on Kaggle (also on few more platforms).
5. Have my algebra, deep learning, NLP and relevant course completed with average grades and good understanding. 
6. Learnt designing and optimizing models, tuning LLMs, used small BERTs and other models, learnt attention mechanism, strengthened my computer vision skills (objects detection, recogn, transfer learning etc).
7. I read papers (part of my job as well but I love to) and working on 2 papers, which has potential to get published (work + mini-thesis).
8. Still one year to get my masters degree and currently applying for summer internships. 

Now, I don't feel focused on one thing and try my hands everywhere which has significantly affect my rate of learning. I feel like I've not learned or gained any new skill in recent past. Also I don't have any roadmap. 

I know its tough to give any suggestion just by info I provided but anything you want to suggest? Am I missing something? Or what should I do next which will be a good addition. 

I want to work in ML Research and may go for PhD after my master's (not 100% sure but I want to).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17olzgq/what_should_be_my_next_target/,0,1,0.6,[]
17ok1sr,voja-kostunica,,2023-11-05 19:49:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ok1sr/decent_aiml_engineer_roadmap/,Decent AI/ML engineer roadmap?,"I cant find any comprehensive in form of an infographic. The one from roadmap.sh is fairly poor.

https://roadmap.sh/ai-data-scientist

I need something detailed and comprehensive. Links are appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ok1sr/decent_aiml_engineer_roadmap/,1,0,0.33,[Comment(id='k7z03o8')]
17ojz60,AvvYaa,,2023-11-05 19:46:23+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ojz60/selfattention_and_the_reasons_behind_its/,Self-Attention and the reason(s) behind its universal representation power,,learnmachinelearning,https://youtu.be/4naXLhVfeho,0,1,0.6,[]
17ojwdf,Herbrax212,,2023-11-05 19:42:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ojwdf/learning_xgboost/,Learning XGBoost,"Hello ! For a class, i'm doing a kaggle competition, but i'm stuck at the score of 0.782, (the best reached is 0.788). I know it was done using XGBoost and i wonder where my implementation might be lacking.

&#x200B;

This is what I did after importing my  train.csv :

    ratio = 0.8
    np.random.seed(42)
    unique_labels = np.unique(train[:, -1])
    training_labels = train[:, -1]
    
    training_labels_one_hot = np.zeros((train.shape[0], unique_labels.shape[0])) 
    for i, label in enumerate(unique_labels):
        training_labels_one_hot[train[:, -1] == label, i] = 1   
    
    exclude_columns_train = [0, -1, -2]  train_data = np.delete(train, exclude_columns_train, axis=1)
    
    exclude_columns_test = [0, -1] 
    test_data = np.delete(test, exclude_columns_test, axis=1)
    
    split_ratio = int(ratio * len(train_data))
    
    split_train_data = train_data[:split_ratio]
    split_validation_data = train_data[split_ratio:]
    
    split_train_label = training_labels[:split_ratio]
    split_validation_label = training_labels[split_ratio:]
    
    split_train_label_one_hot = training_labels_one_hot[:split_ratio]
    split_validation_label_one_hot = training_labels_one_hot[split_ratio:]
    
    train_mean = split_train_data.mean(axis=0)
    train_std = split_train_data.std(axis=0)
    
    split_train_normalized = (split_train_data - train_mean) / train_std
    split_validation_normalized = (split_validation_data - train_mean) / train_std 
    
    test_normalized = (test_data - train_mean) / train_std

As you see, I got my labels in one\_hot an non\_one hot for another implementation.

&#x200B;

I proceeded to do a grid search for my hyperparameters :

    learning_rates = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]
        max_depths = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]

Then a for loop to go over all those and get the best accuracy (i train then compute predictions on the test file then do acc = np.mean(predicted\_labeld == split\_validation\_label)

&#x200B;

those are the params of my XGBoost Classifier :

&#x200B;

            self.params = {
                'objective': 'multi:softmax',
                'num_class': num_class,
                'booster': 'dart', # or gbtree for faster processing
                'eval_metric': 'merror',
                'eta': eta,
                'max_depth': max_depth,
            }

&#x200B;

I just wanna know which step stupid-ass me might have overlooked, i got quite hyped by this homework !",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ojwdf/learning_xgboost/,6,1,1.0,"[Comment(id='k80gj9p'), Comment(id='k81bho0'), Comment(id='k82skse'), Comment(id='k80gs2j'), Comment(id='k80gvqh'), Comment(id='k82hh80')]"
17oestp,oe-g,,2023-11-05 15:52:13+00:00,False,,1699200407.0,False,True,False,/r/learnmachinelearning/comments/17oestp/what_to_learn_to_build_custom_chatbot_interact/,What to learn to build custom chatbot? Interact with pdf repo,"I'm a software dev looking to make a prototype. I want to use an open source model (probably mistral) and finetune it based on a collection of pdfs so users can chat with the documents. 

I'm looking for a course or series of resources that focus on building the tool. I understand some math understanding is required but I'd rather not spend more time than necessary on that. I do see some short tutorials on pdf chat bots but that doesn't let me understand anything so looking for something inbetween. 

I'm torn on which courses:
Fast.ai 
Deeplearning.ai (and which courses+ i feel Andrew ng courses may be too much time on math and not building)
Hugging face courses like this one on nlp https://huggingface.co/learn/nlp-course/chapter1/1
Something on udemy? 

Also seperate request but I'm also looking to learn how to create a coding LLM fine tuned to a specific code base 

Any suggestions and advice would be greatly appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oestp/what_to_learn_to_build_custom_chatbot_interact/,2,2,1.0,"[Comment(id='k7xvshy'), Comment(id='k7xwu5j')]"
17oe8jr,BITE_AU_CHOCOLAT,,2023-11-05 15:25:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oe8jr/how_can_i_visualize_this_type_of_data/,How can I visualize this type of data?,"I have a list of lists where each item is an ID. Basically it's a list of liked/favorited items. There are 10,000 lists/users each containing 600 liked items. I'm trying to use this data to plot a 2d graph showing similarities between all the unique items. Not sure if this is the right place but r/datavisualization seems pretty dead and r/datascience seems like it's mostly targeted towards experienced professionals",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oe8jr/how_can_i_visualize_this_type_of_data/,8,2,1.0,"[Comment(id='k7yqdvr'), Comment(id='k7ycvxh'), Comment(id='k7yjyp1'), Comment(id='k7yy2o7'), Comment(id='k7z0475'), Comment(id='k7z3rg0'), Comment(id='k7z464i'), Comment(id='k7z4h74')]"
17oizsr,ordinary_shaeron,,2023-11-05 19:02:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oizsr/how_to_lower_arena_size_for_tensorflowlite/,How to lower Arena Size for TensorflowLite," I'm working on my project with Time Series Forecasting on ESP32. Seem like my model arena size is too big for ESP32 to predict the value.

I have tried to optimize it based on the TensorflowLite document to lower the size. However, I still can't predict with my ESP32. It keeps printing 0.

Here is my colab notebook: [https://colab.research.google.com/drive/17Ip0dvavjme9c4oDF7lzte6-uRqRlzq9?usp=sharing](https://colab.research.google.com/drive/17Ip0dvavjme9c4oDF7lzte6-uRqRlzq9?usp=sharing)

For ESP32. I use EloquentTinyML library to deploy the model

I am really new to this stuff so if you have any solution please let me know. Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oizsr/how_to_lower_arena_size_for_tensorflowlite/,0,1,1.0,[]
17oiu3n,pranksbanker,,2023-11-05 18:55:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oiu3n/ideas_on_how_to_approach_and_work_with_svg_images/,Ideas on how to approach and work with SVG images of floor plans when developing a GAN?,"I have about \~600 svg images of floor plans. The floor plans have annotations, polygons representing rooms, kitchens, and other areas, and polygons filled in black representing internal and external walls, with appropriate class labelled in XML.  


I am new to ML, and deep learning, but I'm interested in developing a conditional GAN that can generate floor plans for specific requirements/conditions such as no. of rooms. Now I believe there are two options to go about this:  
1) Use color codes for rooms and other components like doors and windows, then resize, and convert to raster form, train the GAN and then finally vectorize the generated image.  
2) Proceed directly in SVG. I feel like this is the more effective method, because I would be able to make use of the annotations, segmented polygons, and other components in svg without losing it. But I'm not sure how to convert this into a tensor. The floor plans are of varying sizes, the number of rooms can vary, how do I convert the svg components to an input tensor of particular shape.  


Please point me towards some resources, and share you ideas as to whether it makes a difference to use option 1 over 2 or vice versa.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oiu3n/ideas_on_how_to_approach_and_work_with_svg_images/,1,1,1.0,[Comment(id='k7z4snn')]
17obdrd,Smamorti7,,2023-11-05 12:56:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17obdrd/best_tools_in_2023_to_build_an_interactive/,Best tools in 2023 to build an interactive dashboard with SQL database,"Hi all,

As a passion project, I want to create an SQL database for some private (tabular) data, and use currently relevant dashboarding techniques to display and modify the data.

I am proficient in Python. To improve my data science profile, I would like to add (basic) SQL to my skillset. Additionally, I would like to create a dashboard of some sorts using the most relevant (or newly emerging) techniques. What tools would you recommend? Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17obdrd/best_tools_in_2023_to_build_an_interactive/,1,4,0.83,[Comment(id='k7x8a61')]
17o0vrd,zuccoff,,2023-11-05 01:19:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17o0vrd/does_brilliantorg_cover_most_of_the_math_and/,Does Brilliant.org cover most of the math and statistics needed for ML?,"I barely passed my calculus and statistics classes in college, and that was 6 years ago, so I think I need a refresher before diving into some of the courses that people recommend here

I've been considering using Brilliant since I have a 30 day trial, and I believe I could review everything during that time. Has anyone tried the site? I've noticed it has many algebra, calculus, and statistics lessons, so I was wondering if it covers most of the math that I'll encounter during ML courses",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17o0vrd/does_brilliantorg_cover_most_of_the_math_and/,12,23,0.85,"[Comment(id='k7w4qac'), Comment(id='k7wpu0h'), Comment(id='k7wdd9x'), Comment(id='k7wxual'), Comment(id='k7x8awt'), Comment(id='k7wi2s7'), Comment(id='k7wovzn'), Comment(id='k7vq9ll'), Comment(id='k7x262m'), Comment(id='k7z63ee'), Comment(id='k7vwi9a'), Comment(id='k7xxdgm'), Comment(id='k7vx228'), Comment(id='k7wvkrr')]"
17ohkiq,gautham_58,,2023-11-05 18:00:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ohkiq/adjusting_fbprophet_model_to_account_for/,Adjusting fbprophet Model to Account for Anticipated Call Surge," I have a query regarding the implementation of the fbprophet model. I've successfully used the model to forecast call volume, and it's performing well. However, I've noticed a significant increase in the number of calls from October 15th to November 15th, which the model accurately captures. Now, our customer has informed us of another anticipated surge in call volume for January, lasting for 10 days. Is there a method or technique I can employ to instruct the model and assign weights to account for this expected increase in total calls during January? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ohkiq/adjusting_fbprophet_model_to_account_for/,0,1,1.0,[]
17oh7xy,arch_il,,2023-11-05 17:44:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17oh7xy/i_am_looking_to_find_math_part_of_machine_learning/,I am looking to find math part of Machine Learning,"I am not new to programming and have been working with several different programming languages for past couple of years. I am looking for some resource (book, blog, playlist, ...) for learning math part of machine learning and to better understand math behind neural networks. I have great understanding of Linear Algebra and Calculus, but have no prior experience in the field of AI or data science in general. I am planning to make my own oversimplified implementation of few kinds of learning in Rust. I am aware it will not be anything substantial or noteworthy, but I just want to ""make AI from scratch"". My question is, where can I find resource that goes in depth in math part?PS. I am OK if book will implement code using python (or any language) as long as math part is fulfilling.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17oh7xy/i_am_looking_to_find_math_part_of_machine_learning/,2,1,1.0,[Comment(id='k7zpd3h')]
17olg25,ERROR_ALREADY_EXISTS,,2023-11-05 20:54:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17olg25/cs_department_vs_ai_department/,CS department VS AI department,"I'm in my last year in high school. I desided that I want to study AI in college, ML to be exact. In my country AI is still a very new thing, so a few university have a department for AI only, but almost all of them have CS. I hope to get a scholarship abroad to study, but still have the same question.

Which department should I choose? because I will ML in CS as far as I know. And What's the deference between them? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17olg25/cs_department_vs_ai_department/,5,0,0.25,"[Comment(id='k7zt7rx'), Comment(id='k807sqm'), Comment(id='k81898z'), Comment(id='k81djp9'), Comment(id='k81v8ew')]"
17ofqjo,ex0tic_unicorn,,2023-11-05 16:35:43+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ofqjo/research_survey_relating_to_ais_impact_on/,Research survey relating to AI's impact on students and Information Management professionals,,learnmachinelearning,/r/learnprogramming/comments/17ofms1/research_survey_relating_to_ais_impact_on/,0,1,1.0,[]
17o93dh,Traditional-Poet2746,,2023-11-05 10:29:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17o93dh/open_sourcing_llmtuner_an_experimental_framework/,Open Sourcing Llmtuner - An Experimental Framework for Finetuning Large Models Like Whisper and Llama with scikit-learn-inspired interface,"Hi Folks,

Happy to share an open source side project I've been working on - [LLmtuner](https://github.com/promptslab/LLMtuner). It's a framework for finetuning large models like Whisper, Llama, Llama-2, etc with best practices like LoRA, QLoRA, through a sleek, scikit-learn-inspired interface.

As someone who works with Large Models a lot, I found myself writing a lot of boilerplate code every time I wanted to finetune a model. Llmtuner aims to simplify the finetuning process down to just 2-3 lines to get training started, similar to scikit-learn.  


https://preview.redd.it/5qh0pniyaiyb1.png?width=1502&format=png&auto=webp&s=7f73a51acd85527d8fa630a689763722ef3ab8fa

&#x200B;

🚀 Features:

* 🧙‍♀️ Finetune state-of-the-art LLMs like **Whisper, Llama wit**h minimal code
* 🔨 Built-in utilities for techniques like **LoRA and QLoRA**
* ✌ **Launch webapp demos** for your finetuned models with one click
* 💥 **Fast inference** without separate code
* **🌐 Easy model sharing** and deployment coming soon

This is still experimental code I've been using for personal projects. I thought others might find it useful too so decided to open-source it.

* Github : [https://github.com/promptslab/LLMtuner](https://github.com/promptslab/LLMtuner)
* For quick demo : [Colab](https://colab.research.google.com/drive/1ia9KvqEGOxARtJScPBY6ccF8l41-w_l5?usp=sharing)

Contributions and feedback are very welcome! I hope it will be helpful in your research & projects. Have a good weekend, Thanks :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17o93dh/open_sourcing_llmtuner_an_experimental_framework/,0,3,0.72,[]
17ofhrr,lazypotato1729,,2023-11-05 16:24:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ofhrr/a_doubt_in_k_fold_cross_validation/,A doubt in K fold cross validation,How do we get a specific ratio of Training data :Test data if we are using K fold cross validation . Suppose i want to get a 60: 40 split ie training:test. Would i need to change the value of K such that k-1/k=0.6 or is there another way of doing this?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ofhrr/a_doubt_in_k_fold_cross_validation/,4,1,1.0,"[Comment(id='k7z5wrd'), Comment(id='k7z78sx'), Comment(id='k7z8ipg'), Comment(id='k7z8wat')]"
17nm4z0,madredditscientist,,2023-11-04 13:53:26+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17nm4z0/i_built_a_tool_that_autogenerates_scrapers_for/,I built a tool that auto-generates scrapers for any website with AI,,learnmachinelearning,https://v.redd.it/a0knv0zb6cyb1,7,102,0.96,"[Comment(id='k7sdvsl'), Comment(id='k7v1f20'), Comment(id='k7x5xa0'), Comment(id='k7wjveg'), Comment(id='k7wyqbp'), Comment(id='k7sli1w'), Comment(id='k7xdhub')]"
17o62cb,Countofmontecristo91,,2023-11-05 06:33:19+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17o62cb/if_i_get_a_vertical_line_plots_for_features_vs/,"If I get a vertical line plots for features vs class target in a dataset , does that mean that I’ve to omit those features?","What would be an ideal step, if I’m trying to train my ML model to achieve a regression?",learnmachinelearning,https://i.redd.it/u9uefiaw4hyb1.jpg,10,5,0.65,"[Comment(id='k7wfes3'), Comment(id='k7wgvzh'), Comment(id='k7wf8hf'), Comment(id='k7xreux'), Comment(id='k7wfv14'), Comment(id='k7x48nh'), Comment(id='k7whg20'), Comment(id='k7wfru6'), Comment(id='k7wlyy4'), Comment(id='k7wfte6')]"
17oh2h1,Yes_optus,,2023-11-05 17:37:07+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17oh2h1/zap_use_your_enemys_symbolism_against_itself/,ZAP use your enemy’s symbolism against itself raise it as high as you can then cut it off is this not proof of ai marketing on a global scale?,,learnmachinelearning,/r/runescape/comments/1688hhm/zap/,0,0,0.25,[]
17o7jma,Little-Egg-1163,,2023-11-05 08:30:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17o7jma/can_a_single_coordinate_based_mlp_learn_trends/,Can a single coordinate based MLP learn trends over multiple images?,"I'm trying to implement coordinate based MLP with Fourier Features for a vision problem. I have thousands of input and target images. 
On a single image the MLP works brilliantly. But can I use this technique to capture a general function for the entire dataset, instead of using a new network for every image?

",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17o7jma/can_a_single_coordinate_based_mlp_learn_trends/,0,0,0.5,[]
17nyupj,tylersuard,,2023-11-04 23:39:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nyupj/does_finetuning_an_embedding_model_boost/,"Does fine-tuning an embedding model boost performance? If so, by how much?","I have a large dataset of texts written in a technical way, using lots of industry terms.  I am wondering if I should fine-tune my embedder before embedding the documents for a vector database?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nyupj/does_finetuning_an_embedding_model_boost/,1,4,1.0,[Comment(id='k7v3ahm')]
17ofnvz,OnlyProggingForFun,,2023-11-05 16:32:18+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ofnvz/why_did_i_quit_my_phd_in_ai_for_a_startup/,Why did I quit my PhD in AI for a startup?,,learnmachinelearning,https://youtu.be/OXUUrYjS_3A,0,0,0.11,[]
17o4kka,Chance_Dragonfly_148,,2023-11-05 04:47:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17o4kka/understanding_reinforcement_learning/,Understanding Reinforcement Learning,"Hi All,

I am struggling to understand actor-critic networks and just reinforcement learning in general. Dont get me wrong, I understand the basic premise, but I am trying to implement it without a library.

I know for the actor, I need to build a action network and for the critic, a value network. It is for an image classification. I am struggling with understanding the architecture. I have built the CNN. My understanding is that I will xonnect the CNN direct to the action function and then the value function? Is that correct.

So Ive got 
CNN > Action Network
CNN > Value Network

Does this mean that would have different parameters for Action and Value Network.

Also Inam struggling with the computation of the formula a little bit.

Any advice you can offer will be amazing.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17o4kka/understanding_reinforcement_learning/,0,1,1.0,[]
17o02on,Seankala,,2023-11-05 00:38:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17o02on/how_is_additional_text_information_used_for_image/,How is additional text information used for image classification using CLIP?,"I understand that when using CLIP to perform image classification, we're treating the classification labels themselves as textual input and getting per-image logits for each image-label pair.

Using the HF API:

```
from transformers imports CLIPModel, CLIPProcessor

processor = CLIPProcessor.from_pretrained(model_name_or_path)
model = CLIPModel.from_pretrained(model_name_or_path)

text_labels = [""bag"", ""coat"", ""jacket""]
images = [image1, image2, image3, image4]  # Assuming images are already defined.

inputs = processor(
    images=images,
    text=text_labels,
    return_tensors=""pt"",
    padding=True,
)
outputs = model(**inputs)
```

The question I have is, what if we wanted to use additional textual information with each label? Building on top of that example, let's say that each image is a product image with a product name (e.g., `Black Coat for Autumn`) associated with it. If I wanted to use these product names along with the textual information, then the text input wouldn't look like simple labels but would rather look like this:

```
text_input = [
    [
        ""bags - Black Coat for Autumn"",
        ""coat - Black Coat for Autumn"",
        ""jacket - Black Coat for Autumn"",
    ],
    [
        ""bags - White Socks"",
        ""coat - White Socks"",
        ""jacket - White Socks"",
    ],
]
```

If I do this, then I can't simply pass it through the processor. If I wanted to do this without any major changes then I would have to only process one image at a time I believe. Is there any way to still perform batch inference with this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17o02on/how_is_additional_text_information_used_for_image/,0,2,1.0,[]
17njs7o,tail-recursion,,2023-11-04 11:35:43+00:00,False,,1699111349.0,False,True,False,/r/learnmachinelearning/comments/17njs7o/mit_matrix_calculus_for_machine_learning_and/,MIT Matrix Calculus for Machine Learning and Beyond,"[https://www.youtube.com/playlist?list=PLUl4u3cNGP62EaLLH92E\_VCN4izBKK6OE](https://www.youtube.com/playlist?list=PLUl4u3cNGP62EaLLH92E_VCN4izBKK6OE)

[https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/pages/syllabus/](https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/pages/syllabus/)

I think this will be really valuable to a lot of people wanting to get into machine learning since there are a lot of good textbooks and resources readily available on stats/probability, linear algebra and calculus but relatively few good resources for matrix calculus.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17njs7o/mit_matrix_calculus_for_machine_learning_and/,3,23,0.96,"[Comment(id='k7spex4'), Comment(id='k7s7b2p'), Comment(id='k7x405d')]"
17nydxv,JashGanz,,2023-11-04 23:17:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nydxv/yolov8_dramatic_drop_in_loss_at_10_epochs_before/,Yolov8 Dramatic drop in loss at 10 epochs before finishing,"Training an image segmentation model on a custom dataset as a side project, and I noticed a huge drop off in training box and segmentation loss at exactly 190 epochs out of 200, this is after training the first version that had a similar drop off at exactly 90 epochs out of 100. Not really sure why this is happening and if it is an indication of something that should be fixed?  


Dataset: 35 Classes, 40k images in Training dataset, 8k in Validation dataset.

https://preview.redd.it/dcvxk3j9yeyb1.png?width=1207&format=png&auto=webp&s=49bddd8e69ead2e2e895d997d0d39b8929adbd65",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nydxv/yolov8_dramatic_drop_in_loss_at_10_epochs_before/,0,2,1.0,[]
17nz5qq,Prince_Kingh,,2023-11-04 23:54:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nz5qq/help_with_ocr_to_text_summary_project/,Help with OCR to text summary project,"Hello, let me start by saying thank you for looking at my post and that the goal of this project isn't efficiency as much as it is just to learn how to do it. I am working on a project that takes an image, converts it into text, and summarizes it. I am going to be using existing models such as PaddleOCR for the conversion of images to text and either T5x or Pegasus for the summarization. I am not creating a sequential project. My goal is to remove the last layer of PaddleOCR and the first layer for the text summarization model and then make my own layer between the two to link them.

I would like to know if this project is possible with the models I have selected or if there are any better recommendations. Are there any guides on how to remove and link layers that are specific to the models? Finally, does someone have or know of a dataset that I can use to train the new model, a dataset with an image of text and its corresponding summary?

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nz5qq/help_with_ocr_to_text_summary_project/,0,1,0.67,[]
17nl3vg,wyem,,2023-11-04 12:57:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nl3vg/this_week_in_ai_all_the_major_ai_developments_in/,This week in AI - all the Major AI developments in a nutshell,"1. **Luma AI** introduced ***Genie***, a generative 3D foundation model in research preview. *It’s free during research preview via Discord* \[[*Details*](https://lumalabs.ai/genie)\].
2. **Nous** **Research** released ***Obsidian***, the world's first 3B multi-modal model family pre-trained for 4 Trillion tokens that runs locally on iPhones. Obsidian competes in benchmarks withWizardLM-13B and GPT4-X-Vicuna 13B and is based on CapybaraV1.9 .
3. **Phind** has released a new model ***Phind Model V7*** that matches and exceeds GPT-4's coding abilities while running 5x faster and having16k context.
4. **Runway** released an update for both text to video and image to video generation with Gen-2, bringing major improvements to both the fidelity and consistency of video results.
5. **Stability AI** announced:  

   1. ***Stable 3D*** (Private Preview): a tool to generate a draft-quality 3D model in minutes, by selecting an image or illustration, or writing a text prompt.
   2. ***Sky Replacer:*** a tool that allows users to replace the color and aesthetic of the sky in their original photos with a selection of nine alternatives.
   3. integration of Content Credentials and ***invisible watermarking*** for images generated via the Stability AI API.
   4. Stable FineTuning (Private Preview)
6. **Hugging Face** released ***Zephyr-7B-β***, a fine-tuned version of Mistral-7B that achieves results similar to Chat Llama 70B in multiple benchmarks and above results in MT bench.
7. **LangChain** launched ***LangChain Templates*** \- a collection of easily deployable reference architectures for a wide variety of popular LLM use cases.
8. **Nvidia** unveiled ***ChipNeMo***, a specialized 43 billion parameter large language model for chip design that can answer general questions related to chip design and write short scripts to interface with CAD tools.
9. **Together** released ***RedPajama-Data-v2***: an Open dataset with 30 Trillion tokens for training Large Language Models. It’s the largest public dataset released specifically for LLM training.
10. **Hugging Face** released ***Distil-Whisper***, a distilled version of Whisper that is 6 times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets.
11. **Google Research** and **Google DeepMind** present ***MetNet-3***, the first AI weather model to learn from sparse observations and outperform the top operational systems up to 24 hours ahead at high resolutions. Google has integrated MetNet-3’s capabilities across its various products.
12. **Google DeepMind** and **Isomorphic Labs** update on the next generation of ***AlphaFold***: the new model greatly expands coverage of structure prediction beyond proteins to other key biomolecular classes. This paves the way for researchers to find novel proteins to eventually map biomolecular structures needed to design better drugs.
13. **Nolano Research** and **EleutherAI** introduced ***Hi-NOLIN***, first state-of-the-art open-source English-Hindi bilingual model built upon the Pythia model suite.
14. **Google** is rolling out ***Immersive View for Routes*** in 15 cities, starting this week along with other AI-powered features in Maps. Immersive view combines Street view, aerial imagery, and live information like weather and traffic to give an aerial, photo-realistic preview of your planned Google Maps route.
15. **Perplexity** announced two new models **pplx-7b-chat** and **pplx-70b-chat**, built on top of open-source LLMs and fine-tuned for chat. They are available as an alpha release, via Labs and pplx-api.
16. **SlashNext's** *2023 State of Phishing Report* reveals a 1,265% increase in Phishing Emails since the launch of ChatGPT in november 2022, signaling a new era of cybercrime fueled by Generative AI.
17. **Google** launches generative AI tools for product imagery to US advertisers and merchants.

Source: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nl3vg/this_week_in_ai_all_the_major_ai_developments_in/,0,8,0.83,[]
17no894,AvvYaa,,2023-11-04 15:36:45+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17no894/a_simple_beginner_friendly_intro_to_reinforcement/,A simple beginner friendly intro to Reinforcement Learning with four seminal projects,,learnmachinelearning,https://youtu.be/zOXcNFM8dt4,1,3,1.0,[Comment(id='k7stezl')]
17nu1o0,ThisIsDrSmith,,2023-11-04 20:01:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nu1o0/ml_pharma/,ML pharma,"Hello all,
I am a medicinal chemist working in pharma. In the past year I have learned to code and used it for data analysis (pandas, matplotlib, seaborn etc.). Recently I have I have been awarded scholarships to allow me to do ML boot camps. 

I am wondering is there anyone else in pharma here and have they had a similar journey and how did they learn ? What career opportunities are there? Also looking to network more generally!

Thanks everyone :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nu1o0/ml_pharma/,2,0,0.5,"[Comment(id='k7wpu9v'), Comment(id='k7wmgwo')]"
17nolqt,zeoNoeN,,2023-11-04 15:54:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nolqt/approaches_to_finding_topics_in_short_texts/,Approaches to finding topics in short texts,"Full transparency because I want to be honest: This is a problem I face at work, a business will profit from your answers. 

I have a large dataset of customer feedbacks. Texts are short and multilingual (translated to English via another model). I want to find out what customers talk about, what their problems are and what they like about the service they where provided. 

I tried some topic modeling approaches (LSS, LDA, LLM Embeddings + Clustering, LLM „zero-shot“ labels ). The resulting Topics were really messy and didn’t fit to my „intuitive topics“. 

What approaches would everyone here recommend next. If I search for topics manually, could I use ML approaches to support this? How have you talked similar problems in the past? 

Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nolqt/approaches_to_finding_topics_in_short_texts/,5,2,1.0,"[Comment(id='k7t1338'), Comment(id='k7t5fy4'), Comment(id='k7to5hk'), Comment(id='k7t54oi'), Comment(id='k7tgixr')]"
17nm8ua,iTsObserv,,2023-11-04 13:59:10+00:00,False,,1699116227.0,False,True,False,/r/learnmachinelearning/comments/17nm8ua/tensorflow_recommendation_model_in_production/,Tensorflow Recommendation Model in Production,"I am a senior CS student and I am building my capstone. We are a team of two and are required to build and implement an AI model in our project.

The model we are building will make recommendations, it uses an NN based on the Neural Collaborative Filtering paper.

We are using Next.js for our frontend and some of the backend using the BFF pattern. We need a separate backend for one of the features that uses websockets.

At first, we wanted to build the separate backend with FastAPI because our model would be built with Tensorflow and Python, but then someone suggested using Express.js or some other JS backend and exporting the model that was made in Python and using Tensorflow.js to include it in the app.

I am concerned about the way we might continuously improve our recommendation model. Using Python and exporting it to Tensorflow.js every time does not seem like a good solution. Even if at this level and for a project this small we don't have to worry about it, professors might ask us about our plan for the future and we need to have an answer ready.

My other concern is that Tensorflow.js would affect the performance of the model.

How do big companies that use recommendation systems solve this? I know Netflix uses the microservices architecture which allows them to use different languages across services. What about the Modular Monolithic architecture, would the Netflix approach still work?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nm8ua/tensorflow_recommendation_model_in_production/,2,2,1.0,"[Comment(id='k7ulugl'), Comment(id='k7vwiul')]"
17nqcmg,sammyhga,,2023-11-04 17:16:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nqcmg/data_science_project/,Data science project,Imagine your friend is searching for a final year data science/machine learning project. What real-world problem solving project(s) would would you suggest?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nqcmg/data_science_project/,0,1,1.0,[]
17nodj6,codys12,,2023-11-04 15:43:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nodj6/diffusion_clip_chunks_to_generate_image_with/,Diffusion + CLIP Chunks to Generate Image with Region Control.,"I am trying to reconstruct an image from chunks of CLIP embeddings. My current workflow would be as follows:

1.) Chunk image into regions and generate CLIP embeddings for each region

2.) Modify CLIP embeddings with some structual control

3.) Re-generate the image from CLIP embeddings. (Use masked inpainting to generate each sub-region of the image at each timestep and combine regions together before the next pass).

Motivation: Generate CLIP-like embeddings from a GPT model and use this model to modify specific parts of an image with text instructions.

Does this approach seem sensible? Would I be able to do this with a pretrained diffusion model with decent results, or would an approach like concatenating the CLIP embeddings and passing them together with position embeddings work better?

&#x200B;

TLDR: Given CLIP embeddings from image chunks, what is the best way to reconstruct the image?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nodj6/diffusion_clip_chunks_to_generate_image_with/,0,1,1.0,[]
17nl59i,RDA92,,2023-11-04 12:59:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nl59i/nlp_causal_relationship_between_string_components/,NLP: Causal relationship between string components,"For a given financial sentence that references multiple asset classes and country exposures I would like to split the sentence into triplets, each triplet referencing an asset class and the country exposure it refers to. I have started toying around with Spacy's own spacy-clausIE which performs rather poorly so far and I wonder whether   
(i) there may be more advanced models out there (ideally offering a python wrapper)  
(ii) how difficult it would be to build one such model yourself

The last question is relating to the peculiar nature of the sentences which can be quite lengthy. I have seen for example that Spacy performs quite well on short sentences but these may not be entirely representative in my use case.

Of course any additional idea is much appreciated.

Thanks!  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nl59i/nlp_causal_relationship_between_string_components/,0,1,1.0,[]
17nl59c,RDA92,,2023-11-04 12:59:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nl59c/nlp_causal_relationship_between_string_components/,NLP: Causal relationship between string components,"For a given financial sentence that references multiple asset classes and country exposures I would like to split the sentence into triplets, each triplet referencing an asset class and the country exposure it refers to. I have started toying around with Spacy's own spacy-clausIE which performs rather poorly so far and I wonder whether   
(i) there may be more advanced models out there (ideally offering a python wrapper)  
(ii) how difficult it would be to build one such model yourself

The last question is relating to the peculiar nature of the sentences which can be quite lengthy. I have seen for example that Spacy performs quite well on short sentences but these may not be entirely representative in my use case.

Of course any additional idea is much appreciated.

Thanks!  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nl59c/nlp_causal_relationship_between_string_components/,0,1,1.0,[]
17n5csl,Zumcddo,,2023-11-03 21:17:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17n5csl/resources_to_learn_about_training_llms/,resources to learn about training LLMs?,"I'd like to train a mini-LLM on a CPU just to get some experience with LLM training. Do y'all have any resources/links to relevant tutorials? I've looked around myself, but I couldn't find too many in-depth tutorials. I'm also interested in building my own toy LLM from scratch, just for better understanding.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17n5csl/resources_to_learn_about_training_llms/,3,17,0.9,"[Comment(id='k7pfp29'), Comment(id='k7qlw6z'), Comment(id='k7s6rg3')]"
17niq7o,oniongarlic88,,2023-11-04 10:23:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17niq7o/using_neat_to_train_a_chess_ai/,Using NEAT to train a chess AI?,"yes, there are better ways than using NEAT, I just want to know if through NEAT, how would the fitness function look like?


My guess is if it makes an illegal move, give negative reward / fitness for that genome and then move to the next genome. eventually it will only make legal chess moves.


but will it automatically learn to do checkmates eventually? or should checkmates somehow be a part of the fitness function as well? like in its random moves, a checkmate happened, we then give it a large bonus to that genome's fitness score. 


would this be a good way to go about it?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17niq7o/using_neat_to_train_a_chess_ai/,5,0,0.5,"[Comment(id='k7s8n64'), Comment(id='k7rzyq1'), Comment(id='k7scwbx'), Comment(id='k7sbvc1'), Comment(id='k7si5j6')]"
17ndw6c,PsychoWorld,,2023-11-04 04:29:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ndw6c/brilliants_ml_llm_course/,Brilliant's ML LLM course?,"Interested in learning about how AI can be applied in the real world  and its fundamental limitations.

https://brilliant.org/wiki/machine-learning/

Is Brilliant's LLM course a good starting point? Also down to listening to lectures.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ndw6c/brilliants_ml_llm_course/,0,2,0.75,[]
17mxuni,inoobie_am,,2023-11-03 15:39:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mxuni/i_am_not_able_to_grasp_the_difference_between/,I am not able to grasp the difference between Batch Gradient Descent and Stochastic Gradient Descent.,"I am following the CS229 course by Stanford. I have to understand as much as I can about Bayesian Classification and Decision trees before next Monday for a workshop. So I have decided to start from the beginning. 

I'm having some understanding the difference between Batch and Stochastic Gradient Descent. How is Stochastic faster?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mxuni/i_am_not_able_to_grasp_the_difference_between/,13,21,1.0,"[Comment(id='k7oekhi'), Comment(id='k7o7h2t'), Comment(id='k7pianh'), Comment(id='k7woqpg'), Comment(id='k7oeu2g'), Comment(id='k7ulx40'), Comment(id='k7q4f41'), Comment(id='k7resne'), Comment(id='k7onlkv'), Comment(id='k7uzxoa'), Comment(id='k7qy9xo'), Comment(id='k7rwa22'), Comment(id='k7s8hum')]"
17ngm8g,roeyper,,2023-11-04 07:44:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ngm8g/need_help_with_tortoise_ai/,Need help with tortoise ai," 

Hi, I've been trying to train my voice for a few days now, but it's not working

I would be happy if someone has a voice ready already (with the video that he trained the software and the settings he made) so that I can do it one by one in my software as well, because everything turns out bad.

Or if anyone has a detailed guide from start to finish on how to train a voice to sound good.

Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ngm8g/need_help_with_tortoise_ai/,0,1,0.67,[]
17nfmkj,Lakshmireddys,,2023-11-04 06:28:52+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17nfmkj/best_machine_learning_books_for_beginners/,Best Machine Learning Books for beginners & Advanced to learn in 2023 -,,learnmachinelearning,https://codingvidya.com/best-machine-learning-books/,0,1,0.67,[]
17nf2j7,qhelspil,,2023-11-04 05:47:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nf2j7/part_2_hyperparameter_tuning_with_leave_one_out/,part 2: hyperparameter tuning with Leave one out cross validation,"when i asked last time how perform hyperparameter tuning with k means cross vlaidations

answer was on each fold, i perform hyperparameter tuning. at end i select the most common hyperparameters.

question now is: how can i perform hyperparameter tuning with LOO-CV

its not practical to hypertune on each fold in this case

so if i have 100 rows, 100 folds, 100 times tuning, doesnt look normal

any suggestions ?

note: my task is to compare models, so if this does not work, perhaps i should fit each model and then i select the best one and hypertune it?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nf2j7/part_2_hyperparameter_tuning_with_leave_one_out/,1,1,1.0,[Comment(id='k7rj12s')]
17nb3bh,EliteAdmitsEditing,,2023-11-04 01:51:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17nb3bh/ideas_on_how_to_do_this_text_classification_tfidf/,Ideas on how to do this Text Classification TFIDF,"I wrote Python code to do this maybe 2+ years ago, but can't find the code or remember what I did.

I got a dataset of labelled articles (so 2 columns: the text of the article and the topic - like science, entertainment, arts & culture, sports, politics) and gave every word that appeared in these articles a normalized vector for how much they were associated with each topic. Ex. sphere (0.562, 0.001, 0.244, 0.109, 0.084)

The point of this was given a test text, we could look at the sum of the normalized vectors to see what topic the test text is likely classified as. I could also use a scatterplot to visualize where each word falls on the axes of the topics.

I'm pretty sure I used TFIDF or like a Count Vectorizer or something, but tbh I forget like the whole concept. I'm guessing I would fit a TFIDF Vectorizer on the article text? But then wouldn't this give me a vector of the document as a whole, instead of a vector for each word? And how would this associate with a topic? Any help would be appreciated thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17nb3bh/ideas_on_how_to_do_this_text_classification_tfidf/,3,2,1.0,"[Comment(id='k7r7c2r'), Comment(id='k7rnqng'), Comment(id='k7tk7en')]"
17n33fo,maie123,,2023-11-03 19:36:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17n33fo/stats_or_ml_phd_with_few_cs_courses/,stats or ml phd with few cs courses,hey everyone. I'm a junior majoring in applied maths. Right now I'm in a research lab that does ml research but I was wondering if just having this experience would be enough or if I'll need to take some more formal cs courses. I've taken one object oriented programming course and discrete maths and got AP credit for another programming class. Is this enough to do an ml or stats phd?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17n33fo/stats_or_ml_phd_with_few_cs_courses/,7,6,0.87,"[Comment(id='k7p0ys4'), Comment(id='k7rcppv'), Comment(id='k7qqrlc'), Comment(id='k7qs1gb'), Comment(id='k7qsyty'), Comment(id='k7qtfax'), Comment(id='k7qu2ft')]"
17mw0x9,thesecondbread,,2023-11-03 14:12:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mw0x9/starting_machine_learning_research_as_a_sophomore/,Starting machine learning research as a sophomore in High School,Any tips for me? What math concepts should I be familiar with? Any books?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mw0x9/starting_machine_learning_research_as_a_sophomore/,34,13,0.74,"[Comment(id='k7nq5az'), Comment(id='k7nslpi'), Comment(id='k7nz20f'), Comment(id='k7nsg8o'), Comment(id='k7o9p3n'), Comment(id='k7ohmbj'), Comment(id='k7qo8hw'), Comment(id='k7pv4oc'), Comment(id='k7oftcy'), Comment(id='k7o0mo4'), Comment(id='k7ntm7k'), Comment(id='k7oggqo'), Comment(id='k7omfxk'), Comment(id='k7oh8ci'), Comment(id='k7s3v6o'), Comment(id='k7oihr0'), Comment(id='k7oofq0'), Comment(id='k7oiji8'), Comment(id='k7spiyk'), Comment(id='k7oiy1h'), Comment(id='k7opo1d'), Comment(id='k7rct6p'), Comment(id='k7ruc0u'), Comment(id='k7tad93'), Comment(id='k7ojq4k'), Comment(id='k7q3nst'), Comment(id='k7rg3of'), Comment(id='k7slj6s'), Comment(id='k7ok3es'), Comment(id='k7qh2za'), Comment(id='k7rjwf1'), Comment(id='k7t4vrb'), Comment(id='k7rl610'), Comment(id='k7tjf1c')]"
17ncc68,typicalii,,2023-11-04 02:56:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ncc68/undergraduate_thesis_in_machine_learning/,undergraduate thesis in machine learning,"hello i’m a junior undergraduate student studying applied math (with an emphasis in machine learning) and i’m looking to find an undergrad thesis topic. my advisor is a data scientist/math phd and i’m trying to build a shortlist of topics that would be in scope for an undergraduate math student before i meet with him to discuss. 

my background includes:
1. for math - linear algebra, calc 1-3, discrete math, mathematical statistics, and intro to statistical learning theory/machine learning theory. my classes next semester when i start researching/planning will be advanced linear algebra and one of the following: time series analysis, numerical methods, or applied combinatorics. 
2. cs - data structures, algorithms, knowledge of core libraries for data science/ml (numpy, pytorch, sklearn, tensorflow, etc.) might be taking computer architecture this semester too, but i don’t think that’s too helpful. 

if you have any advice/suggestions for a topic please drop a comment! i’m interested in pretty much all types of machine learning, but it’s just so difficult to come up with something interesting that falls in scope. thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ncc68/undergraduate_thesis_in_machine_learning/,0,1,1.0,[]
17n4v2c,Snoo_72181,,2023-11-03 20:56:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17n4v2c/in_an_lstm_model_is_1_row_of_training_data_but/,"In an LSTM model, is 1 row of training data, but 365 past sequences better, or is 359 row of training data, but 7 past sequence better, given I can only so much training data",,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17n4v2c/in_an_lstm_model_is_1_row_of_training_data_but/,1,3,1.0,[Comment(id='k7xf7cm')]
17mzvd6,Potential_Plant_160,,2023-11-03 17:08:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mzvd6/data_science_masters_vs_artificial_intelligence/,Data Science Masters Vs Artificial Intelligence Master Degree and is it Worth it ??,"Hi guys, 

I'm a non-tech professional working in AI for 7 months in India, considering a master's degree. I found a online Data Science  Master program at VIT Chennai for 1.5 lakh- for part time . is it good?,

&#x200B;

 Any recommendations for affordable and quality Master Degree program, which i can do online i part time ? Is a master's degree worth it for me?

&#x200B;

 Data Science or Artificial intelligence: Which is the better choice to get master degree for my career?""",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mzvd6/data_science_masters_vs_artificial_intelligence/,22,4,0.7,"[Comment(id='k7onlz7'), Comment(id='k7oicxc'), Comment(id='k7qcaix'), Comment(id='k7qv535'), Comment(id='k7s2iox'), Comment(id='k7oojj7'), Comment(id='k7oiqbg'), Comment(id='k7quspk'), Comment(id='k7qq4ue'), Comment(id='k7r9d7f'), Comment(id='k7s4awy'), Comment(id='k7rc594'), Comment(id='k7rzz8u'), Comment(id='k7t7inn'), Comment(id='k7s09l8'), Comment(id='k7t7u4d'), Comment(id='k7s4ncz'), Comment(id='k7t4345'), Comment(id='k7uapkn'), Comment(id='k7ubwum'), Comment(id='k7uyd5x'), <MoreComments count=0, children=[]>]"
17mq1qt,HennyKo,,2023-11-03 08:04:23+00:00,False,,1699172869.0,False,True,False,/r/learnmachinelearning/comments/17mq1qt/rtx_3080_vs_rtx_4070_for_machine_learning/,RTX 3080 vs RTX 4070 for machine learning,"I'm currently building a PC specifically for machine learning and have narrowed my GPU options down to the NVIDIA RTX 3080 10GB and the NVIDIA RTX 4070. I've noticed that the RTX 3080 10GB has about 50% more Tensor Cores (280 vs 184) compared to the RTX 4070. Would this significant difference in Tensor Cores inherently result in faster and more efficient performance for machine learning tasks? Any insights would be greatly appreciated!

&#x200B;

EDIT: Thank you for all your suggestions. Currently, a 3090 is too expensive, nearly double what a 3080 would cost. I really liked the chart [aws07](https://www.reddit.com/user/paws07/) suggested. Maybe I wait another month and look for a better deal for a 3090, thank you all for your input.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mq1qt/rtx_3080_vs_rtx_4070_for_machine_learning/,20,14,0.86,"[Comment(id='k7n9grp'), Comment(id='k7n2eio'), Comment(id='k7mr8ri'), Comment(id='k7ndo1t'), Comment(id='k7ptohk'), Comment(id='k7q52mq'), Comment(id='k7oimi6'), Comment(id='k7o3zkp'), Comment(id='k7pwb98'), Comment(id='k7qsipb'), Comment(id='k7qxarb'), Comment(id='k7s867z'), Comment(id='k7nszy0'), Comment(id='k7o47c6'), Comment(id='k7q5f0v'), Comment(id='k7nff79'), Comment(id='k7o4v9x'), Comment(id='k7q62to'), Comment(id='k7ownn4'), Comment(id='k7q7vax')]"
17mxtdw,cloneable-cto,,2023-11-03 15:37:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mxtdw/were_building_a_platform_to_easily_deploy_cv/,We're building a platform to easily deploy CV models to the edge (looking for beta testers),"# What is Cloneable

Over the past 6 months, We’ve been building a platform to help developers prototype apps that combine computer vision (starting with YoloV8) and business logic/process and deploy them to the edge, immediately. The platform is no-code / low-code allowing you to quickly construct your app from ""components"". Today we have about 30 components pre-built that cover UI, Logical and Processing that are drag and drop into the visual builder.

We’ve been working mostly with businesses to get feedback up to this point, but am really interested in opening it to the broader computer vision community to see if we can identify some interesting use cases and get feedback on the process of going from build to deploy, as well as how we wrap models into apps to leverage AI/ML.

No-code / low-code builder

&#x200B;

[no-code builder](https://i.redd.it/w1qv9vqhj5yb1.gif)

# What can you do with Cloneable?

Today, the apps instantly deploy to iOS without compiling and run completely offline. You can upload a yolov8 model, which will sync down to the apps that you build for offline inference. You can also implement additional UI (forms, bounding box editing, PDF generation, etc.) as well as more processing (sending notifications, track bounding boxes, low-code scripts, process LiDAR from iPhone).

To bring your models in, you can upload them directly to our builder, or you can connect to your Roboflow account to automatically pull the models in.

We've built some interesting test applications:

* Using computer vision and the LiDAR from an iPhone, find a tree, measure it's diameter, and generate a report for use in vegetation management.
* Determine if PPE is being worn at a facility

Detect PPE compliance

Measure tree diameter

&#x200B;

[ppe example](https://i.redd.it/gjoy676jj5yb1.gif)

&#x200B;

[tree scanning](https://i.redd.it/6p2rwmxkj5yb1.gif)

# Why we're building Cloneable

Our team has spent the past 10 years working to integrate drones and other deep tech like AI and machine learning into the field. It was time-consuming, expensive, and the results were often hard-coded to a specific requirement or use case making it difficult to scale.

While model dev and training have advanced quickly (especially with tools like Ultralytics and Roboflow), I've seen little progress on accessibility and ease in prototyping apps that deploy models to production environments and make it easy to build the business logic around the model outputs.

# How are we building it?

The underlying runtimes are written in native code that allows you to run your models at full performance. On an iphone this let's us run most YoloV8 models at the full FPS of the camera. In the near future we're going to launch SDKs allowing for us to expand the types of models that we can support.

# We're looking for beta users

Looking specifically for developers who are building and training YOLOV8 models and have iOS devices to test deployments. But we will do a fast follow to open the beta to drone, robots and other IoT deployments.

What we're looking to answer with the beta

* What are some of the challenges you've faced when bringing your AI/ML models into an app?
* What features would you like to see in a low/no-code builder?
* Any ideas on the types of apps you could speed up the dev process?

I’m excited to see what’s possible when AI deployment is easy, fast and free. If you have feedback on any of the above or questions, look forward to engaging.

Here’s the link to sign up if you think the Beta is a fit for you: [https://media.cloneable.ai/cloneable-beta](https://media.cloneable.ai/cloneable-beta)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mxtdw/were_building_a_platform_to_easily_deploy_cv/,0,3,1.0,[]
17n5044,clickme1234,,2023-11-03 21:02:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17n5044/migrating_from_r_brmsstan_to_pytorch/,Migrating from R brms/stan to pytorch,"Hi all,

Currently in my workflow I use a lot of stan-based models using the R package brms as a fronted. This is mainly because quantifying uncertainty is really important in my field of research. Also, I like being able to generate multi-level models as I find them quite intuitive and I use multi-level regression and post-stratification a lot.

However, the datasets I'm working with are getting bigger and have a lot more features, and these sort of models don't really scale that well to larger datasets. It's now not uncommon for me to have to wait days or weeks for my models to train, which isn't sustainable in the long run. 

I've know neural networks are really good at solving this problem, however, I've struggled to find any good resources as to how I can migrate my specific model inputs and outputs (ie. Hierarchical and getting uncertainty in model predictions) to the pytorch framework. 

Had anyone else had this experience or know of any good resources I could check out?

Thanks in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17n5044/migrating_from_r_brmsstan_to_pytorch/,0,1,1.0,[]
17mngkq,supa_ai,,2023-11-03 05:00:17+00:00,False,,1699006459.0,False,True,False,/r/learnmachinelearning/comments/17mngkq/how_do_yall_deal_with_hallucinating_in_gpt_35/,How do y'all deal with hallucinating in GPT 3.5?,"Hey guys,

We're trying to build an AI chatbot for internal purposes. So far, we've tried the usual suspects like different approaches to prompt engineering and RAG.

The main issue is that despite RAG retrieving the correct context, we still experience significant (3 in 10) amounts of hallucination. Has anyone experienced the same problem? We'd love to hear any alternative approaches or discussion here on alternate methods.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mngkq/how_do_yall_deal_with_hallucinating_in_gpt_35/,16,16,0.74,"[Comment(id='k7m589y'), Comment(id='k7md2zu'), Comment(id='k7o7n4b'), Comment(id='k7p2obz'), Comment(id='k7mmt8s'), Comment(id='k7m8yc4'), Comment(id='k7m826m'), Comment(id='k7pj9xu'), Comment(id='k7mhyba'), Comment(id='k7p7tjp'), Comment(id='k7m9hcs'), Comment(id='k7ox39x'), Comment(id='k7ppurq'), Comment(id='k7mty3l'), Comment(id='k7pny39'), Comment(id='k7ox4od')]"
17n3196,JordaarAce,,2023-11-03 19:34:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17n3196/looking_for_aiml_role/,Looking for AI/ML role,"Hey folks!!!

I am 22M, currently I am looking for ML/AI role. I have internship experience as an ML engineer in fintech. startup. My task was to deal with financial data, and some computer vision related stuff.

Library/framework: PaddleOCR, Computer, vision, YOLO v8, Pytorch, FastAPI, Flask, NLP, and to name a few (have mentioned in resume).


If you guys have any open role in your company or have any referrals please do share it. If you guys have it I can share my resume to you. It would be great if I get it on early basis.


- Thank you In Advance",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17n3196/looking_for_aiml_role/,0,0,0.5,[]
17n0pxd,AvvYaa,,2023-11-03 17:47:47+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17n0pxd/understanding_everything_about_self_attention/,Understanding everything about Self Attention straight off of first principles!,,learnmachinelearning,https://youtu.be/4naXLhVfeho,0,1,0.67,[]
17mf7pn,tylersuard,,2023-11-02 22:07:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mf7pn/what_is_the_cheapest_way_to_host_a_1tb_vector/,What is the cheapest way to host a 1TB vector database?,"Pinecone would cost around $2400/mo, so that is a no

ChromaDB has to fit in memory, and I don't have 1TB ram, so that is a no

Datastax was too hard to use

I was thinking of having either Vespa DB or Postgres with vector search extension hosted in my Google Drive.  Yes?  No?  Any recommendations would be much appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mf7pn/what_is_the_cheapest_way_to_host_a_1tb_vector/,28,34,0.93,"[Comment(id='k7klain'), Comment(id='k7lko4w'), Comment(id='k7o91kx'), Comment(id='k7kn7o9'), Comment(id='k7kvp0g'), Comment(id='k7m2yyy'), Comment(id='k7lwy5r'), Comment(id='k7mzuv0'), Comment(id='k7lomyt'), Comment(id='k7odyyz'), Comment(id='k7ospa0'), Comment(id='k7oyyei'), Comment(id='k7soq7f'), Comment(id='k7m8k88'), Comment(id='k7nrumi'), Comment(id='k7spz0f'), Comment(id='k7r66o8'), Comment(id='k7m32c3'), Comment(id='k7sq26l'), Comment(id='k7ly0qz'), Comment(id='k7mbz7r'), Comment(id='k7sqn15'), Comment(id='k7p54ud'), Comment(id='k7mbfaq'), Comment(id='k7ts9tf'), Comment(id='k7m4mco'), Comment(id='k7mmxur'), Comment(id='k7ms8tp')]"
17ms4db,tech_HACKS,,2023-11-03 10:37:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ms4db/ml_model_vs_a_vector_database/,Ml model vs a vector database,"Currently my project uses ml model to make predictions on text data but someone demonstrated vector database for same use case, which is very fast as compared to model.

Currently dataset is small 10k datapoints but is increasing as we are pouring more data.

Which approach will you suggest to move forward with being more experienced in this field.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ms4db/ml_model_vs_a_vector_database/,2,2,1.0,"[Comment(id='k7qfsxk'), Comment(id='k7qpk2i')]"
17moemz,not_very_epic,,2023-11-03 06:04:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17moemz/trying_to_understand_the_point_of_an_estimator/,Trying to understand the point of an estimator,"I'm a student and our class is covering parametric estimation. However, I fail to see the point of an estimator. One of the measures we use is the bias of an estimator where we subtract the estimated value of a parameter from the actual value to see if the estimator is biased. However, if we already have the actual value of theta, why are we using the estimator in the first place?

[here's a ss with the formula](https://preview.redd.it/gvg5gexqp2yb1.png?width=555&format=png&auto=webp&s=97d56b53c22fcb6ae60df62380be29230567bc0d)

If the theta we subtract from the actual value is not the actual value, what is it? I know this sounds stupid but I've been thinking this over and can't figure out why we need the estimator in the first place if we already know the value.

Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17moemz/trying_to_understand_the_point_of_an_estimator/,3,3,0.81,"[Comment(id='k7m9k9g'), Comment(id='k7n144v'), Comment(id='k7vvnnh')]"
17mubcf,Enough_Wishbone7175,,2023-11-03 12:47:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mubcf/tcn_tutorial/,TCN tutorial,Hey everyone! I’m trying to use some form of temporal convolutions networks for time series forecasting. Having a hard time finding good content so please lmk if you have some.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mubcf/tcn_tutorial/,1,1,1.0,[Comment(id='k7qj2bm')]
17mm1dc,Goatman117,,2023-11-03 03:36:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mm1dc/segmentation_fault_when_running_a_learner_on/,Segmentation fault when running a learner on raspberry pi 4.,"I've trained a vision learner with fastai, and I've loaded it onto my raspbery pi. It loads up just fine, but when I try to actually predict from an image, it just spits out:   
Segmentation fault---------| 0.00% \[0/1 00:00<?\]   
and ends the process.  


It seems to be an issue with the cpu platform of the pi from what I've seen (this kinda thing is new to me though), but all the fixes online are outdated unfortunately. I've tried downloading the aarch64 linux versions of numpy, torch, and torchvision, but it didn't fix anything.  


Any help would be great, cheers!  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mm1dc/segmentation_fault_when_running_a_learner_on/,2,5,1.0,"[Comment(id='k7nfi6n'), Comment(id='k7pv4bh')]"
17mnl8r,YungbxneOG,,2023-11-03 05:07:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mnl8r/need_some_advice/,Need some advice,"Need some advice

I’m currently in Uni and in my second year of software engineering. I have no experience in python but I don’t think it’ll be too tough to learn as I know languages like Java and C (not saying they’re the same, just that I have experience with programming). And I’ve been given an opportunity to work on data compression and to use Machine learning to do so (description not clear for now). Any idea how machine learning would be used to do so? I have zero experience in machine learning and have about 10-15 days to get the basics of it down. Would really appreciate guidance and hope this post isn’t too stupid :p
Cheers!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mnl8r/need_some_advice/,0,3,1.0,[]
17mfpcw,OkenshieldsEnjoyer,,2023-11-02 22:28:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mfpcw/math_classes_to_take_for_ml_graphics_research/,Math classes to take for ML + Graphics research,"Currently   a sophomore in college majoring in CS and math. Planning to get a PhD   in the broad field of  computer graphics + ML. With regards to math,    I've taken introductions to lin alg, multivariate calculus (self   taught), probability, and discrete mathematics. As I'm taking more and   more CS classes in ML and graphics (e.g. grad ML courses) I've been   feeling that having more math background would be useful.

Any thoughts what to take? (currently in the process of pre-enroll for next year)

**Some thoughts I'm having:**  
\- pure analysis class seems not to be what I want, because it is too theoretical to be useful in most CS research.

\- **definitely taking:** honors advanced linear algebra class, numerical analysis linear and non linear problems  
\- **considering:**   Manifolds and differential forms, stochastic processes, PDEs,   applicable algebra (or honors algebra, but this one is very theoretical   and idk how applicable), Matrix groups...

Any thoughts, advice? TIA!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mfpcw/math_classes_to_take_for_ml_graphics_research/,7,10,0.86,"[Comment(id='k7lnzxv'), Comment(id='k7lbia2'), Comment(id='k7lso1d'), Comment(id='k7stsfm'), Comment(id='k7stbg9'), Comment(id='k7sty43'), Comment(id='k7sxhlj')]"
17mrxcb,tdionis,,2023-11-03 10:23:35+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17mrxcb/how_to_train_a_model_with_only_62_labeled_images/,How to Train a Model with Only 62 Labeled Images using Semi-Supervised Learning - Supervisely,,learnmachinelearning,https://supervisely.com/blog/train-a-model-with-62-labeled-images-hrda-semi-supervised/,0,1,1.0,[]
17mnprn,_Killua_04,,2023-11-03 05:15:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mnprn/what_is_blending_weighted_voting_and_stacking_in/,"What is blending, weighted voting and stacking in machine learning?","Can anyone help me understand definition of blending, weighted voting and stacking in machine learning with an example?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mnprn/what_is_blending_weighted_voting_and_stacking_in/,2,2,1.0,"[Comment(id='k7maxo6'), Comment(id='k7mz0w7')]"
17mqqpm,tusharkumar91,,2023-11-03 08:58:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mqqpm/channel_for_sharing_my_learnings_in_ml_dl_and_cv/,"Channel for sharing my learnings in ML , Dl and CV","Hello there, 

In pursuit of creating a space where I get to continuously learn new things and share those learnings with everybody else, I have created a youtube channel and intend to post videos every 1-2 weeks where I either explain a topic or implement something from scratch.

Here's my channel - [https://www.youtube.com/channel/UCLywqeZTOeWNYDy3niClMww](https://www.youtube.com/channel/UCLywqeZTOeWNYDy3niClMww)

As of now I have covered topics like VAE, VQ-VAE, DallE(from scratch), VIT(with implementation) and lots more to come(DDPM up next).

Do take a look at it and I would love to get your feedback on my videos, how can I improve them, what topics would benefit YOU, is the explanation simple enough for folks who are unaware of that topic or any other feedback that you can provide that would in some way benefit you. 

Thank you so much for reading this post right upto the end :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mqqpm/channel_for_sharing_my_learnings_in_ml_dl_and_cv/,0,0,0.5,[]
17mfifx,ofermend,,2023-11-02 22:20:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mfifx/rag_hackathon/,RAG hackathon,"If you are interested in learning more (by building) about retrieval-augmented-generation (RAG), we are hosting a hackathon starting tomorrow (Nov 3rd) at 9AM PST. Enroll here: [https://lablab.ai/event/rag-llms-with-your-data](https://lablab.ai/event/rag-llms-with-your-data). ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mfifx/rag_hackathon/,1,7,0.89,[Comment(id='k7kk47g')]
17mpma5,Potential_Plant_160,,2023-11-03 07:31:16+00:00,False,,1698998931.0,False,True,False,/r/learnmachinelearning/comments/17mpma5/need_career_guidance/,Need Career Guidance,"Hi ,I am Basically from Non tech Background and now I am  working as AI developer since past  7 months in a Research Project,since it's a Research project there is not much of Coding and all ,we are still in Data Collection part and in the mean time I am Doing some Kaggle Projects and I am also Learning Deep Learning and NLP and Pytorch frameworks.

But I want to switch into Software Company,but since last 3 months My resume is not getting shortlisted,I think it's because of  Projects ,which I wanna improvise 
Can u guys help me with these 

1.How to Get shortlisted for ML Engineer or AI Developer Role for this much Experience.

2.What type of Projects do I have to do ,if u guys have any resources that would help a lot.

3. Do I have to Do End to End Projects

4. how much Python Proficiency is required to get a job for this much experience and How to improve my Python skills , because I am failing to crack coding rounds in Interviews.

5.which type of Projects I should give more focus to Like NLP, Computer Vision,LLM ,Deep Learning.

6.Do I have to Get any Particular skils other than this.

7.How to Build Portfolio and where can I showcase it and what are the Good Projects I can Do to get shortlisted.

8.Also I wanna do  Data Science Master through online ,Any suggestions?

I found one Master course for Data science in VIT, Tamilnadu,whats ur Opinion about this Course?

9.Which is better Data Science master degree or AI master degree,is it even worth it for me , because I am from NON tech Background.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mpma5/need_career_guidance/,7,1,0.67,"[Comment(id='k7myqwr'), Comment(id='k7pn7fz'), Comment(id='k7n0htk'), Comment(id='k7qpze7'), Comment(id='k7n209k'), Comment(id='k7n2l3x'), Comment(id='k7n2rkx')]"
17mj386,AffectionateCamel583,,2023-11-03 01:05:53+00:00,False,,1698978199.0,False,True,False,/r/learnmachinelearning/comments/17mj386/how_large_does_a_labelled_dataset_need_to_be_in/,How large does a labelled dataset need to be in order to fine-tune a distilbert model for sentiment analysis?,"I'm playing around with distilbert for a personal project.

I want to be able to use distilbert to determine a sentiment of a response.

I know there are pretrained models out there for sentiment but wanted to do it myself. 

I've taken a small random subset of the original dataset and am going to lable it myself it an integer value between 1 and 3 to denote the sentiment (1= negative, 2=neutral, 3=positive).

E.g if it's 10000 respondes, approximately sample size of 400 would be 5% moe at 95% CI.

Would using a small dataset of 400 be large enough to fine tune distilbert for my purposes?

Since I'm labelling it myself and don't have an army of volunteers, I want to do the least amount of manual labelling ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mj386/how_large_does_a_labelled_dataset_need_to_be_in/,2,3,1.0,"[Comment(id='k7n2p5d'), Comment(id='k7o724s')]"
17m18b6,robml,,2023-11-02 11:19:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m18b6/is_there_a_point_to_baggingboosting_a_random/,Is there a point to bagging/boosting a Random Forest made of Random Forest models?,"Title says it all. I am familiar with Stacking and Voting ensembles that can use base models which are also ensembles. 

However when it comes to bagging and boosting where its the same type of model, I was curious if there was a benefit to, in simple terms, creating a Random Forest of Random Forest, or if this would in essence just be equal to a single large Random Forest since they're all made of Decision Trees anyways.

Curious to hear your guys' thoughts. 

Bonus would be if anyone has experienced a Stacking/Voting model of Random Forests using different number of trees as a parameter.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m18b6/is_there_a_point_to_baggingboosting_a_random/,7,19,1.0,"[Comment(id='k7hu0xp'), Comment(id='k7hv6lr'), Comment(id='k7izhvb'), Comment(id='k7iw0to'), Comment(id='k7hvs70'), Comment(id='k7hve41'), Comment(id='k7i0tnj')]"
17mkc62,AvvYaa,,2023-11-03 02:07:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17mkc62/understanding_neural_attention_from_first/,Understanding Neural Attention from First Principles,,learnmachinelearning,https://youtu.be/frosrL1CEhw?si=NKTqmRTieVkfCNlb,0,0,0.33,[]
17m8aj2,Axcella,,2023-11-02 17:06:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m8aj2/transformer_learning_materials/,Transformer Learning Materials,What are some of the best materials to learn about transformers?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m8aj2/transformer_learning_materials/,1,4,1.0,[Comment(id='k7lk90b')]
17micfi,sovit-123,,2023-11-03 00:30:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17micfi/transfer_learning_using_efficientnet_pytorch/,Transfer Learning using EfficientNet PyTorch,"Transfer Learning using EfficientNet PyTorch

[https://debuggercafe.com/transfer-learning-using-efficientnet-pytorch/](https://debuggercafe.com/transfer-learning-using-efficientnet-pytorch/)

&#x200B;

https://preview.redd.it/471m6kx921yb1.png?width=1000&format=png&auto=webp&s=e15abd8348d18398f7f67d399c743168c6d0ec71",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17micfi/transfer_learning_using_efficientnet_pytorch/,0,1,1.0,[]
17m9ntv,Neat-Print2792,,2023-11-02 18:06:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m9ntv/my_random_forest_regressor_predictions_are_on_a/,My random forest regressor predictions are on a specific range,"So I'm doing this project and the target is a potential barrier value of a molecule to a protein.
The problem is that most of the potential barriers of the molecules are on a specific range and when I predict based on a RF regression it only predicts that range and I get a really bad correlation 0.27.

Does anyone know how to solve this kind of problem in RF?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m9ntv/my_random_forest_regressor_predictions_are_on_a/,7,3,1.0,"[Comment(id='k7jnkho'), Comment(id='k7js7j2'), Comment(id='k7jytx6'), Comment(id='k7k1fum'), Comment(id='k7k1m5k'), Comment(id='k7k4owl'), Comment(id='k7kyxyz')]"
17m97k3,Moist-Blueberry-1094,,2023-11-02 17:47:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m97k3/training_a_model_to_only_accept_real_commands/,Training a model to only accept real commands,"Hello All,

I am working on a game right now where the player uses voice commands to move a character around a grid. I have a programmatic way of parsing these commands right now, but I would like to move over to a commend processing model that can take in more complex commands.

Right now, this game is very rudimentary. You may tell the character to ""go up"", ""go down"", ""go left"", or ""go right"". Of course, I want to expand to other verbs, too - ""walk up"", ""walk down"", etc. However, I realized that having a dataset that only consists of commands like this would probably train a model to recognize any ""X up"" sentence as a ""go up""-type command (e.g., ""glorb up"").

My question is, how can I train the model to only recognize valid commands? Do I need to balance out my data with general language data, so it can recognize more things that aren't commands? Should I preprocess the user's input so that it will only pass sentences that contain acceptable words to the model? Should I try fine-tuning an pre-trained model?

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m97k3/training_a_model_to_only_accept_real_commands/,3,3,1.0,"[Comment(id='k7lyuqj'), Comment(id='k7k9g2f'), Comment(id='k7l1zc0')]"
17m6c02,25th__Baam,,2023-11-02 15:40:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m6c02/i_want_to_learn_to_build_speech_to_text_model/,I want to learn to build speech to text model either from scratch or use some transfer learning. Where do I learn these things from.,I know about audio signal processing and know about RNN and LSTM bit I don't know how the language models and something like ctc beam search help the model. I know basics about this but I want to learn this thing in depth. So please suggest me resources or tutorial which has indepth knowledge not some 1hr tutorials on jupyter notebook.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m6c02/i_want_to_learn_to_build_speech_to_text_model/,3,3,1.0,"[Comment(id='k7iuagv'), Comment(id='k7iurph'), Comment(id='k7jcudr')]"
17mlkqs,xshopx,,2023-11-03 03:11:16+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17mlkqs/breaking_news_liber8_proxy_creates_a_new/,"Breaking News: Liber8 Proxy Creates a New cloud-based modified operating system with Antidetect and unlimited worldwide residential proxy, with RDP and VNC Access Allows users to create multi users on the VPS with unique device fingerprints and Residential Proxy and TOR.",,learnmachinelearning,/r/BuyProxy/comments/17lljop/breaking_news_liber8_proxy_creates_a_new/,0,0,0.25,[]
17mdjny,CartoonistMundane972,,2023-11-02 20:55:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mdjny/i_need_a_help_with_ai_assignment_question/,I Need a help with AI assignment question!,Anyone will please like to help me with my assignments of AI for Business? it is related to SVM Classifier.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mdjny/i_need_a_help_with_ai_assignment_question/,1,1,1.0,[Comment(id='k7kz3le')]
17mcswo,qhelspil,,2023-11-02 20:24:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17mcswo/how_to_do_hyperparameter_tuning_with_leave_one/,how to do hyperparameter tuning with leave one out cross validation,"with big datasets, i split data into train test validatin set, i tune the training set, test it on test set, then validate on the validation set .

but what if i am using Loo- CV ? i cannot split it into validation seat because it is too small dataset.

one answer would be if i am doing 5 fold cross validation, i tune each train set of each fold. then take most common hyperparameters. but this doesnt sound a smart idea.

any suggestions? thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17mcswo/how_to_do_hyperparameter_tuning_with_leave_one/,1,1,1.0,[Comment(id='k7lj4x0')]
17m3cw6,manishmanalath,,2023-11-02 13:21:26+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17m3cw6/from_ai_adoption_to_regulation_how_to_keep_your/,From AI Adoption to Regulation: How to Keep Your Business on the Right Side of the Law,,learnmachinelearning,https://www.linkedin.com/pulse/from-ai-adoption-regulation-how-keep-your-business-m-shivanandhan-j5znc/,0,3,0.72,[]
17m9da3,AvvYaa,,2023-11-02 17:54:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m9da3/understanding_everything_about_self_attention/,Understanding Everything about Self Attention from First Principles (A video),"Hello guys, I wanted to share a new video I made for my Deep Learning YT channel about Self Attention. It is part two of a larger series on explaining Transformers from first principles. In the video, I tried to explain the essence of self-attention in an intuitive manner, describe how it works in practice, its various strengths and applications, and the reasons behind its massive representation powers…

I’m kinda excited to share the video here for those that are interested:

[https://youtu.be/4naXLhVfeho](https://youtu.be/4naXLhVfeho)  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m9da3/understanding_everything_about_self_attention/,0,1,1.0,[]
17m95ya,iloveapi,,2023-11-02 17:45:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m95ya/pycaret_pipeline_folder_uses_too_much_disk_space/,PyCaret pipeline folder uses too much disk space,"Hello all. I have an issue with PyCaret, specifically with the temporary files it produces when executing predict\_model(). Here is my code:  


    for i in tqdm(range(next_start, total_length, batch_size), desc=""Predicting"", initial=next_start//batch_size, total=total_length//batch_size):
            batch = test_data[i:i + batch_size]
            batch_predictions = predict_model(model, data=batch)
            batch_predictions.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))

This batch code is done to overcome the memory issue. However, I stumbled upon another issue where, in pycaret > internal > pipeline, Pycaret stores its files here and grows until my disk is full and does not remove itself even after my code stall because the disk is full.

Question:  
1. Does predict\_model() clean itself after it's done?  
2. How and when will Pycaret remove all those temporary files?

Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m95ya/pycaret_pipeline_folder_uses_too_much_disk_space/,0,1,1.0,[]
17mimwy,LAKTAWI,,2023-11-03 00:44:05+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17mimwy/the_power_of_positivity_and_meditation/,The power of positivity and meditation,,learnmachinelearning,https://youtube.com/watch?v=oQG9TvImhcI&si=fB76T_BVAOJcyMnI,2,0,0.25,"[Comment(id='k7loffh'), Comment(id='k7mzfo5')]"
17lwrlp,Personal-Trainer-541,,2023-11-02 05:47:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lwrlp/discrete_fourier_transform_explained_in_python/,Discrete Fourier Transform Explained in Python,"Hi there,

I've created a video [here](https://youtu.be/5a61BUpzmT4) where I explain how the discrete fourier transform works and how it's implemented in Python.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lwrlp/discrete_fourier_transform_explained_in_python/,0,7,0.9,[]
17lr0g0,CelestialCurrent,,2023-11-02 00:35:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lr0g0/papers_to_reproduce_for_ml_reproducibility/,Papers to reproduce for ML Reproducibility Challenge 2023,"I'm planning to participate in the ML Reproducibility Challenge 2023 ([**https://reproml.org/blog/announcing\_mlrc2023/**](https://reproml.org/blog/announcing_mlrc2023/)) and I'm looking for suggestions on some good deep learning papers where I can try to reproduce the results.  


Per the organizer's suggestion, I should focus on papers published in 2023 from the top ML venues like NeurIPS, ICML, ICLR, ACL, EMNLP, ICCV, CVPR, TMLR, JMLR, TACL.

Let me know if you have come across any promising deep learning papers published this year that would be good for reproducibility! I'm hoping to select one to focus on for this challenge.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lr0g0/papers_to_reproduce_for_ml_reproducibility/,11,19,0.91,"[Comment(id='k7h7o64'), Comment(id='k7g8sra'), Comment(id='k7g6jhj'), Comment(id='k7i3xoy'), Comment(id='k7l411s'), Comment(id='k7l4aft'), Comment(id='k7lpwmj'), Comment(id='k7l3usx'), Comment(id='k7i4106'), Comment(id='k7oq94d'), Comment(id='k7lqmi6')]"
17lqrf8,sammyhga,,2023-11-02 00:24:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lqrf8/ml_cnn_project/,ML CNN project,"Hey guys, I am working in a ML classification project using CNN. The initial project idea was to detect leaf diseases in potatoes. The user would take a pic of a potato leaf using a mobile app, and the leaf would be analysed if it is healthy or not. When I submitted the idea o my supervisor  he said it shouldn't just be potatoes but I should add at least 3 other crops. Now  am somehow blank in what to do. What would be the best way to build a CNN in python to detect leaf disease of 3 crop?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lqrf8/ml_cnn_project/,16,13,1.0,"[Comment(id='k7g3iog'), Comment(id='k7g1tj1'), Comment(id='k7h0gkg'), Comment(id='k7gkmrw'), Comment(id='k7ho1x5'), Comment(id='k7hnzyp'), Comment(id='k7h6w25'), Comment(id='k7hm7vs'), Comment(id='k7hmahv'), Comment(id='k7hmbdx'), Comment(id='k7i8nad'), Comment(id='k7hmeby'), Comment(id='k7hnoly'), Comment(id='k7i9dte'), Comment(id='k7hnoz3'), Comment(id='k7iarw9'), Comment(id='k7id8ns')]"
17m3zd4,DistributionLeast132,,2023-11-02 13:53:41+00:00,False,,1698943793.0,False,True,False,/r/learnmachinelearning/comments/17m3zd4/questions_about_the_sklearn_rfe_feature_selection/,Questions about the sklearn RFE feature selection method,"Hello, I'm studying feature selection in machine learning searching the [sklearn feature selection](https://scikit-learn.org/stable/modules/feature_selection.html) to see what kinds of selection methods there are.

Reading the sklearn pages, I found the [RFE method](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) which seems a quite powerful method.

But when I try to apply it, I'm not sure whether I'm applying the method correctly.

Here are some questions about it

&#x200B;

* When I apply RFE, should I use the same model for the RFE and target prediction? Or can we use different models?
   * Example: For the feature selection with RFE, I used a Linear regressor. But for the training and target prediction, I used a random forest with features selected by Linear regressor based RFE

&#x200B;

* Would the result of RFE be sensitive for the hyperparameter of the model

&#x200B;

* When we apply RFE, should we handle the multicollinearity before applying RFE? Or does the \`sklearn.feature\_selection.RFE\` also consider the multicollinearity too?

&#x200B;

* Are there some models that are frequently used for RFE?

&#x200B;

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m3zd4/questions_about_the_sklearn_rfe_feature_selection/,0,0,0.5,[]
17ltn0d,Aidann8,,2023-11-02 02:42:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ltn0d/viability_of_undergraduate_statistics_degree_in/,Viability of undergraduate statistics degree in this field?,"**TL;DR:** want to work in MLE or DS, but worried that  BS stats degree isn't sufficient. What should I do?

 I'm currently a statistics major at a UC in California (davis) and im starting to worry about my job prospects post graduation. Originally I wanted to get into data science or MLE and thought a stats+cs degree would be the best option. But I've come to realize that these jobs locked behind at least a masters and even then its insanely competitive to get into.

I'm looking into other things such as data engineering or software roles but they seem to all require computer science degrees. I've done a lot of cs classes and completed some projects, however, I'm not sure I'll be able to formally get a CS degree as there are some challenging new policies to work around to be able to add/switch into at my university.

Is my best play to try to get a data analyst position and then study in my own time/look to move internally? Wouldn't this be very hard to do nowadays given the market?

I'm new to this field and kind of at a loss right now for what I should do. Looking for any insight and/or guidance. Much appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ltn0d/viability_of_undergraduate_statistics_degree_in/,3,7,1.0,"[Comment(id='k7gvow5'), Comment(id='k7jf3p2'), Comment(id='k7i576i')]"
17m1krf,nebius_com,,2023-11-02 11:41:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17m1krf/do_you_need_resources_for_training_large_ml/,Do you need resources for training large ML models ASAP?,"Hello, everyone who deals with ML model training.

We have just opened access to Nebius AI — our AI-centric cloud platform. It's ready for intensive ML workloads, including LLM and Gen AI.

We have a good number of NVIDIA® H100 Tensor Core GPUs that can be used on-demand or with reserved resources.

The platform provides not only GPUs but also a training-ready cloud platform with up to 3.2Tb/s per host InfiniBand network. The platform includes Managed Kubernetes for multi-node training, as well as a Marketplace with ready-to-use OS images, ML-focused applications, and tools.

If you need resources for training large ML models ASAP, reach out to us via our website — we currently have no waiting lists for H100. Learn more [https://nebius.ai](https://nebius.ai)

&#x200B;

https://preview.redd.it/4tatjasw8xxb1.jpg?width=2446&format=pjpg&auto=webp&s=284b0782e3e68a6f1887f8ff0bfd3e6f6ad1725c",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17m1krf/do_you_need_resources_for_training_large_ml/,0,0,0.4,[]
17lug53,amritk110,,2023-11-02 03:24:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lug53/toolkit_for_healthcare_ml/,Toolkit for healthcare ML,"Calling ML researchers and practitioners to try out our toolkit! - https://github.com/VectorInstitute/cyclops.

Check out an example use case on kaggle - https://www.kaggle.com/code/adibvafafallahpour/vector-institute-s-cyclops-stroke-prediction.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lug53/toolkit_for_healthcare_ml/,0,2,0.63,[]
17lztom,Lakshmireddys,,2023-11-02 09:47:11+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17lztom/best_machine_learning_courses_for_beginners/,"Best Machine Learning Courses for Beginners, Advanced in 2023 -",,learnmachinelearning,https://codingvidya.com/best-machine-learning-courses/,0,0,0.2,[]
17lae5w,Head-Hole,,2023-11-01 11:55:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lae5w/deep_learning_architecture_design_resources/,Deep learning architecture design resources,"As the title says, what are some good resources to learn about designing deep learning models? Or, hell, even a more simple perceptron?

A little bit of context…I’m about halfway through a DS masters program, I have a solid foundation in math, stats, ML and some of the classic ML techniques, and I’m decent with Python. I’ve designed and implemented my own neural nets before using PyTorch, including CNNs (and they worked!), but I just don’t understand how to decide on how many layers…how to choose kernel sizes in convolution and pooling…type of pooling…etc. it just seems like pure guesswork at this point, but there has to be more to it, right???",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lae5w/deep_learning_architecture_design_resources/,3,17,0.91,"[Comment(id='k7h35lg'), Comment(id='k7dofiv'), Comment(id='k7fl4j8'), Comment(id='k7fxn1x')]"
17ltagh,deessehalah,,2023-11-02 02:25:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ltagh/azure_certification/,Azure certification,"Hey guys, i am a fresh graduate at computer science, i was mainly concentrating on machine learning, we didn't have courses in our university in clouding so i have no idea about bt Azure, AWS, etc. Now while applying to jobs, i see that most of them require knowledge in clouding services so i decided to learn and have a certificate in Azure since it's mostly asked. I don't know any course or link to begin with so can you please help me. If you have any link, course, video on youtube please share it in the comments.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ltagh/azure_certification/,1,1,0.67,[Comment(id='k7hh9ix')]
17lt2lc,aleradamantis,,2023-11-02 02:14:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lt2lc/coursera_specialization_or_course_for_online/,Coursera Specialization or Course for Online Learning and Ensemble methods,"Do you know of any basic or intermediate specialization that touches on Ensemble methods (the different types, how the work, hard vs soft voting...) and online learning?

Both things in the same specialization would be great but if it needs to be separate that's also fine.

I haven't taken Ng's courses yet, but I think they only talk very briefly about tree ensembles only (random Forest and xgboost) and not at all about online learning.

Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lt2lc/coursera_specialization_or_course_for_online/,0,1,1.0,[]
17l9wc6,_lil_seb,,2023-11-01 11:25:14+00:00,False,,1698838394.0,False,True,False,/r/learnmachinelearning/comments/17l9wc6/i_know_the_math_where_do_i_start/,"I know the math, where do I start?","I’m a pure mathematics graduate who wants to get into data science/AI/ML. The reason I’m posting this question is due to the lack of  thorough answers regarding a learning path for people who already have a solid background on mathematics. 

To clarify, I studied pure maths, so assume I know advanced calculus and analysis, linear algebra and probability (among other topics unrelated to ML). Throw a maths paper at my face and I’ll be able to read it and understand it. The only aspect I consider weak in my arsenal is statistics, but again, I don’t have to start from zero given my background. 

I thought the best way to get into the field and learn would be by pursuing a project, so I decided to start building a time series classifier for some stocks data I pulled (the dataset is rich). However, I’d like to know if this is too ambitious and if it’d be helpful to begin with something smaller. 

Thanks in advanced, and I apologise if this has been answered thoroughly in some other post I didn’t find.

TL;DR: I know the maths, I want to learn ML. Where do I start without wasting time on maths? I’m pursuing a time series classification project. Is this too ambitious? Should I pursue a different project first? Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l9wc6/i_know_the_math_where_do_i_start/,25,11,0.66,"[Comment(id='k7cqf6s'), Comment(id='k7cycv6'), Comment(id='k7f8tsx'), Comment(id='k7enbgk'), Comment(id='k7f149s'), Comment(id='k7fw3bz'), Comment(id='k7ct75v'), Comment(id='k7e4kk9'), Comment(id='k7dt7ke'), Comment(id='k7dfwxv'), Comment(id='k7ftr44'), Comment(id='k7h1qq8'), Comment(id='k7kmtjd'), Comment(id='k7css4o'), Comment(id='k7fb8we'), Comment(id='k7fpiah'), Comment(id='k7d306f'), Comment(id='k7fpeyi'), Comment(id='k7iahxb'), Comment(id='k7fpr8a'), Comment(id='k7doiro'), Comment(id='k7iasql'), Comment(id='k7fq239'), Comment(id='k7dr1k9'), Comment(id='k7dsn9l')]"
17lgy2c,alfihar,,2023-11-01 17:08:13+00:00,False,,1698858680.0,False,True,False,/r/learnmachinelearning/comments/17lgy2c/ai_assistive_tools_able_to_do_some_or_all_of/,"AI assistive tools able to do some or all of these tasks to help with some of the ongoing issues symptomatic of ADHD. anxiety, depression etc?","First off im not entirely sure how to frame this or even where I should be asking. So if im in the wrong place and you have a better suggestion that would be great. Im cross posting to MLQuestions 

As someone with various mental health and gifted learning issues with a history in IT (albeit a bit of a dusty unused one), this is something I have been thinking about for a very long time.  Every time i look into it ive found the tech just wasnt really up for it without it being a huge nightmare anyway.  Recently ive been looking at recent advances in things like chat GPT and similar AI and I feel its time to look again and see if there is anything that can help me that doesn't need an entire organization working on a mainframe to implement.

So here are some of the things I feel like it wouldn't be unreasonable for a computer to be able to help me with and im hoping people can let me know if its still a way off, if existing tools can do it, or if it would be something that doesnt exist but could with the existing ai models and which models would be most promising. 

Im also a little worried about just how safe my data would be with 3rd party tools as a lot of what im asking for iis prettty personal. Ideally if computing power wasnt ludicrous i would like solutions that run locally 

**Smart data organization**

* Help organise existing and future google docs, emails, bookmarks, ever note and other notes and document files.
* Initially prompt with suggestions for category and tagging metadata but learn based on the responses I give. 
* Learn how I classify information to better anticipate both storing and retrieving info. 
* Keep my unfinished thoughts and ideas and remind me of them if im thinking about something similar 

*Ultimate Goal*

When trying to solve a problem or complete some task, I want something to help me find research or brainstorming or other work I have done in the past that might be relevant when working on a new task.

Eventually if I have taken some notes on a subject already I would like the AI to suggest any existing relevant work for what I am working on currently.  

* As an aide to memory
* So I dont write the same thing twice
* Solutions or partial solutions ive come up with for the same or similar problems.
	
**Scheduler and Reminder**

* Accept future but unclear tasks I wish to do

 * Something I want to do just not sure when
 * Occasionally remind me of it, especially if i am at a loss of what to do

* Track existing appointments and remind me about them in ways im actually going to find useful and at useful times

* Track existing deadlines and help me achieve them
 * break down tasks into smaller ones
 * help me allocate reasonable amounts of time to work and help me keep on schedule 
 * help me with things that are coming up that might interfere

* Keep track of my day and suggest tasks based on what I am doing
 * Remind me to take my meds when im out of bed or before I leave the house
 * Remind me of groceries I need to get if im near a supermarket
 * Suggest it might be a good time to take a break, or go for a walk.

* Help me keep track of upcoming bills and costs, renewals
* Get me to do a small chunk of a existing or ongoing bigger task so it doesnt become overwhelming, this includes cleaning tasks

 I would even be happy for this to include cameras watching me to see my mood or activity at my workshop, my computer,  my room, make sure im up etc. 

**Research Assistant**

Help me research things I want to know, work as a intermediary between search engines and myself. 

Find and summarise possible solution alternatives from varied online sources, suggest pros and cons, (eventually suggest which might be best for me based on my skill set)

Compare products, or the price of a product on different sites, alert for sales

**Health Assistant**

Help me maintain good habits and overcome bad ones

Help me with day schedules and sleep pattern

Help me maintain more social contact, with my energy levels in mind

Help me with nutrition and exercise. 

**Finally.. help me get better at all these tasks myself.**",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lgy2c/ai_assistive_tools_able_to_do_some_or_all_of/,0,4,1.0,[]
17liglt,Clicketrie,,2023-11-01 18:15:20+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17liglt/semantically_search_youtube_transcriptions_to/,Semantically Search YouTube Transcriptions To Find Most Relevant Videos (Google Colab tutorial),,learnmachinelearning,https://www.youtube.com/watch?v=4Za4RiVMk_c&t=5s,0,2,0.63,[]
17lk80t,akshitsharma1,,2023-11-01 19:33:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lk80t/anime_art_with_dcgan_generate_stunning_faces/,Anime Art with DCGAN: Generate Stunning Faces," 

Hello everyone!

I am excited to share my latest Kaggle notebook with you all. In this notebook, I have implemented a DCGAN from scratch and trained it on the Anime Face Dataset so as to generate realistic anime images

I would love to hear your feedback and thoughts on my notebook, so please do feel free to comment and share your views. In case you do find this notebook helpful, please do not hesitate to give it an upvote or share it

[https://www.kaggle.com/code/akshitsharma1/anime-art-with-dcgan-generate-stunning-faces](https://www.kaggle.com/code/akshitsharma1/anime-art-with-dcgan-generate-stunning-faces)

Thanks a lot for your time and support :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lk80t/anime_art_with_dcgan_generate_stunning_faces/,2,2,1.0,"[Comment(id='k7f2ouv'), Comment(id='k7rqziw')]"
17lp8vw,Interesting_Pack3655,,2023-11-01 23:15:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lp8vw/integrating_llm_with_internet_search_capability/,Integrating LLM with Internet Search Capability into Google Sheets Function,"Hello everyone,

I'm working on a project where I aim to enhance Google Sheets with a custom function that leverages a Large Language Model (LLM) to search the internet for information related to specific websites listed in a spreadsheet. The idea is to have the LLM automatically gather and summarize details from the web based on URLs or keywords provided in each row.

However, I've hit a roadblock: the APIs for LLMs that I've come across (like OpenAI's GPT models) don't inherently possess the ability to perform internet searches. They can generate text based on pre-trained data but can't fetch or search for new data in real-time.

Here's what I'm looking to achieve:

1. A user inputs a URL into a cell in Google Sheets.
2. The custom function calls upon an LLM to search the internet for the latest information related to that URL.
3. The LLM then summarizes this information and inputs it into the corresponding cell.

I'm seeking advice on how to approach this problem. Are there any LLMs that offer internet search capabilities, or is there a way to integrate an LLM with a web scraping tool or search API to achieve this functionality? If anyone has experience with similar integrations or can point me toward resources or tools that could help, I'd greatly appreciate it.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lp8vw/integrating_llm_with_internet_search_capability/,0,1,1.0,[]
17lbv6f,Onelio1,,2023-11-01 13:14:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lbv6f/why_train_parameters_of_a_neural_network/,Why train parameters of a Neural Network,"Hi, I recently started learning on AI while studying my carrer. With the help of youtubers, online resources and asking one or two questions to AIs I think I have a basic understanding of them. But there is still a question in my mind that I just haven't been able to solve.

""Why train on weights and biases of the neural network?""

Why not just drop them and instead directly modify the activation function to fit our data? Wouldn't it be equally effective if we just dropped the parameters and instead used the input directly and our modified function to predict?

&#x200B;

Thank you very much. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lbv6f/why_train_parameters_of_a_neural_network/,12,2,0.57,"[Comment(id='k7d6kla'), Comment(id='k7d4omf'), Comment(id='k7eegkf'), Comment(id='k7fbpni'), Comment(id='k7g76uz'), Comment(id='k7gls0u'), Comment(id='k7dfabi'), Comment(id='k7ddfw6'), Comment(id='k7g187s'), Comment(id='k7gpyni'), Comment(id='k7fcvvv'), Comment(id='k7g7f95')]"
17l9fv5,Sevyten,,2023-11-01 10:55:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17l9fv5/webinar_enable_and_manage_vector_search_in/,Webinar - Enable and manage Vector Search in MongoDB Atlas with SuperDuperDB," Hi Community!

Today we are hosting a hands-on ""Enable and manage Vector Search in MongoDB Atlas with SuperDuperDB Webinar"": [https://www.eventbrite.com/e/enable-and-manage-vector-search-in-mongodb-atlas-with-superduperdb-webinar-tickets-744936223297](https://www.eventbrite.com/e/enable-and-manage-vector-search-in-mongodb-atlas-with-superduperdb-webinar-tickets-744936223297)  


**The following questions will be answered in the workshop:**

· *What is vector search and why is it so important?*  
· *What are vector databases?*  
· *Why is it a huge advantage to use vector search with MongoDB Atlas instead of a vector database?*  
· *What embedding models are there?*  
· *How do I use these models to generate vector embeddings for my data?*  
· *How do I perform vector search?*  
· *What AI applications can I build on top of vector search?*  


**When?**  
*Wednesday, November 1st*  
*12pm - 1pm ET (Eastern Standard Time)*  
**Add to** [**Google**](https://clicks.eventbrite.com/f/a/PwT3VZ7xdGS0adSXW2GdKg~~/AAQxAQA~/RgRnG1AaP0SzaHR0cHM6Ly93d3cuZXZlbnRicml0ZS5jb20vY2FsZW5kYXIuaWNzP3JlZj1lZW1haWxvcmRjb25mJnV0bV9jYW1wYWlnbj1vcmRlci1jb25maXJtLWJjYyZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9zb3VyY2U9ZXZlbnRicml0ZSZlaWQ9NzQ0OTM2MjIzMjk3JnV0bV90ZXJtPWdvb2dsZWNhbCZjYWxlbmRhcj1nb29nbGVXA3NwY0IKZTiaHDplW8NXeFIVdGltb0BzdXBlcmR1cGVyZGIuY29tWAQAAAAA) **·** [**Outlook**](https://clicks.eventbrite.com/f/a/gWfgcd4_NHOjQh7_-sDvIg~~/AAQxAQA~/RgRnG1AaP0SyaHR0cHM6Ly93d3cuZXZlbnRicml0ZS5jb20vY2FsZW5kYXIuaWNzP3JlZj1lZW1haWxvcmRjb25mJnV0bV9jYW1wYWlnbj1vcmRlci1jb25maXJtLWJjYyZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9zb3VyY2U9ZXZlbnRicml0ZSZlaWQ9NzQ0OTM2MjIzMjk3JnV0bV90ZXJtPW91dGxvb2smY2FsZW5kYXI9b3V0bG9va1cDc3BjQgplOJocOmVbw1d4UhV0aW1vQHN1cGVyZHVwZXJkYi5jb21YBAAAAAA~) **·** [**iCal**](https://clicks.eventbrite.com/f/a/uJj8AHMy8cZyu5FTWxYoFQ~~/AAQxAQA~/RgRnG1AaP0SsaHR0cHM6Ly93d3cuZXZlbnRicml0ZS5jb20vY2FsZW5kYXIuaWNzP3JlZj1lZW1haWxvcmRjb25mJnV0bV9jYW1wYWlnbj1vcmRlci1jb25maXJtLWJjYyZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9zb3VyY2U9ZXZlbnRicml0ZSZlaWQ9NzQ0OTM2MjIzMjk3JnV0bV90ZXJtPWljYWwmY2FsZW5kYXI9aWNhbFcDc3BjQgplOJocOmVbw1d4UhV0aW1vQHN1cGVyZHVwZXJkYi5jb21YBAAAAAA~) **·** [**Yahoo**](https://clicks.eventbrite.com/f/a/30sHCiTwBCiRiyLoz_9scg~~/AAQxAQA~/RgRnG1AaP0SxaHR0cHM6Ly93d3cuZXZlbnRicml0ZS5jb20vY2FsZW5kYXIuaWNzP3JlZj1lZW1haWxvcmRjb25mJnV0bV9jYW1wYWlnbj1vcmRlci1jb25maXJtLWJjYyZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9zb3VyY2U9ZXZlbnRicml0ZSZlaWQ9NzQ0OTM2MjIzMjk3JnV0bV90ZXJtPXlhaG9vY2FsJmNhbGVuZGFyPXlhaG9vVwNzcGNCCmU4mhw6ZVvDV3hSFXRpbW9Ac3VwZXJkdXBlcmRiLmNvbVgEAAAAAA~~)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l9fv5/webinar_enable_and_manage_vector_search_in/,1,6,0.87,[Comment(id='k7cky67')]
17lk7xm,akshitsharma1,,2023-11-01 19:33:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lk7xm/anime_art_with_dcgan_generate_stunning_faces/,Anime Art with DCGAN: Generate Stunning Faces," 

Hello everyone!

I am excited to share my latest Kaggle notebook with you all. In this notebook, I have implemented a DCGAN from scratch and trained it on the Anime Face Dataset so as to generate realistic anime images

I would love to hear your feedback and thoughts on my notebook, so please do feel free to comment and share your views. In case you do find this notebook helpful, please do not hesitate to give it an upvote or share it

[https://www.kaggle.com/code/akshitsharma1/anime-art-with-dcgan-generate-stunning-faces](https://www.kaggle.com/code/akshitsharma1/anime-art-with-dcgan-generate-stunning-faces)

Thanks a lot for your time and support :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lk7xm/anime_art_with_dcgan_generate_stunning_faces/,0,1,1.0,[]
17ljya8,Unusual_Language8690,,2023-11-01 19:21:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ljya8/pytorchforecasting_temporal_fusion_transformer/,Pytorch-forecasting temporal fusion transformer," I use the optimize\_hyperparameters function from the temporal fusion transformer in pytorch-forecasting to optimise the hyperparameters. The results are automatically logged to tensorboard. However, under hparams, the parallel coordinate graph only has hp\_metrics as a metric. Does anyone know how I can add metrics. I want to use my validation or training loss in the plot. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ljya8/pytorchforecasting_temporal_fusion_transformer/,0,1,1.0,[]
17lja1x,hellbattt,,2023-11-01 18:52:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lja1x/bad_format_of_output_with_rag/,Bad format of output with RAG,"I have been trying a rag based approach and I have been getting decent outputs. But when there is no information in the context I get the output in a weird format which is kinda not suitable result you expect from a chatbot i feel. For example - ""input"": ""What is the abbrevation of ONt?"",    ""answer"": "" Unfortunately the context provided does not contain the abbreviation ONt. Based on my knowledge, ONt is likely referring to Optical Network Terminal, which is a device used to connect customer premises equipment to an optical network."" Whatever prompt I tried sometimes it still starts ""Based on the context"" or ""unfortunately the context provided does not contain.."".  What are some suggestions on prompt or other methods you could suggest to avoid this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lja1x/bad_format_of_output_with_rag/,2,1,1.0,"[Comment(id='k7f4v0q'), Comment(id='k7ii7rl')]"
17lbukf,qwe1972,,2023-11-01 13:13:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lbukf/do_you_recommend_inside_deep_learning_by_edward/,"Do you recommend ""Inside deep learning"" by Edward Raff?","&#x200B;

https://preview.redd.it/f6oq32rpkqxb1.png?width=572&format=png&auto=webp&s=2e78fcbd1a61442aeaf78ef8a7a82fa3a0544f3c

[cover page](https://preview.redd.it/49rbvd3ikqxb1.png?width=871&format=png&auto=webp&s=23aa46821029e2cca8d6f0cee0bb178ce32407c1)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lbukf/do_you_recommend_inside_deep_learning_by_edward/,2,2,1.0,"[Comment(id='k7qply3'), Comment(id='k7s49hn')]"
17lfnet,SP9DEV,,2023-11-01 16:11:39+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lfnet/newbie_here_trying_to_make_crude_image/,Newbie here - trying to make crude image stabilization using RL,"Hi there! I recently dived into the topic of RL after finishing a neural networks course at my university. I have basic understanding of the underlying principles of CNNs, the general idea of what Reinforcement Learning is, and I'm trying to learn more by making a project.

The problem that I came up with is as follows:The system receives consecutive images frame after a frame (let's assume the frames come from a prerecorded video of stationary object, but the cameraman's hand is shaking/moving slowly) and tries to compute offsets for them that allow the user to align new frames to the original one.

My idea is to use RL to train a network to recognize how the current frame is offset from the original (initial, first frame fed to the network) to allow some other software or even the user to manually translate this frame by the X/Y offsets received from the NN to ""stabilize"" the image. Such a network would take a small bitmap as an input (a small piece of the image, e.g. a 200x200px area from the center of the frame) and give two signed values on the output (the X and Y offsets in px from the original).

I'm fully aware that this is very primitive way of performing image stabilization, but that's the whole idea, I'm trying to learn RL by defining a clear and simple problem that doesn't necessarily have much usefulness in the real world.

My current idea on how to approach it is as follows:

* Prepare several large resolution images (e.g. 1920x1080 px)
* Make a simple python script, which takes an image (1920x1080) as an input
* With the script, define an ""anchoring area"", e.g. a 200x200 square in the center of the original large image
* Feed the NN with this reference 200x200 image
* The Python script would then randomize an offset/drift and instead of 200x200 square in the center of the image, it would take a 200x200 square offset by 10-50 pixels from the center in X/Y (for example -20,20 offset)
* The script wuld feed the NN with the offset 200x200 image
* The NN would receive positive points for outputing offsets that cancel-out the script's artificial deviations (e.g. 20, -20 offset for the previous example) and negative points for outputing offsets that make matters worse (e.g. -10, 15).

Now, I'm very inexperienced and I understand that this is not a simple thing to achieve, therefore I wanted to ask you, is my approach correct, and if you can give me any hints or direct me to some sources where something like this was previously done. I'll appreciate any help on how to make this real. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lfnet/newbie_here_trying_to_make_crude_image/,0,1,1.0,[]
17lfgiz,Nedas01,,2023-11-01 16:03:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17lfgiz/help_in_understanding_the_use_of_information_in/,Help in understanding the use of information in machine learning models," 

Hello all,

I am a complete beginner to machine learning so youll have to bear with me. I would like to understand how machine learning - in particular, collaborative filter and DNN work with information that you may get in recommendation systems. For example game recommendations, how does the model use data such as the users different games and the games data such as play time, achievements unlocked, and their reviews. The whole part of having different information linked to the games which link to a user is baffling me. How would you use this data to train a model?

Again, sorry for this question and thanks for any answers!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17lfgiz/help_in_understanding_the_use_of_information_in/,0,0,0.5,[]
17lc0ut,HazrMard,,2023-11-01 13:22:37+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17lc0ut/helping_fix_aircraft_from_nlp_to_bayes_nets/,Helping fix aircraft - from NLP to Bayes Nets,,learnmachinelearning,https://iahmed.me/post/nlp-bayes-aircraft/,3,0,0.5,"[Comment(id='k7d27wl'), Comment(id='k7fkhw8'), Comment(id='k7ik4qh')]"
17l2gfn,btcmx,,2023-11-01 02:45:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17l2gfn/d_can_you_really_control_the_output_of_stable/,[D] Can you really control the output of Stable Diffusion? This approach argues that you can!,"Taking inspiration from the Stable Diffusion architecture, ControlNet (ICCV23 best paper) reveals that the next step in generative AI might be on transitioning from *static* images to creating [images that you can control and customize](https://tenyks.docsend.com/view/3zdgppz6chj9n6wf).

Have you used ControlNet or other similar tools for downstream tasks in production? Do you know other approaches? What are the obvious downsides? 

https://preview.redd.it/eg5xukd5fnxb1.png?width=1024&format=png&auto=webp&s=93b06fe09edb1754cbd33359f14e41aa2f0a2ed5",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l2gfn/d_can_you_really_control_the_output_of_stable/,1,4,0.7,[Comment(id='k7bxjaq')]
17l0jux,Additional-Ad-7043,,2023-11-01 01:06:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17l0jux/bitnet_in_pytorch_or_jax/,Bitnet in Pytorch or Jax,"I was interested by the new bitnet paper [https://arxiv.org/pdf/2310.11453.pdf](https://arxiv.org/pdf/2310.11453.pdf), and was wondering if there was any way to use the 1 bit (1 or -1) in actual practice and how? More specifically, I know that you can do this with cuda (which I don't have any experience with) but it would be much better if there was a way to do this on a TPU (Jax?). Any implementation I've seen so far just pretends like they are using 1 bit but representing it with higher precisions.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l0jux/bitnet_in_pytorch_or_jax/,1,4,1.0,[Comment(id='k7c3enx')]
17kdnkt,shesaysImdone,,2023-10-31 05:15:57+00:00,False,,1698731827.0,False,True,False,/r/learnmachinelearning/comments/17kdnkt/what_is_the_point_of_ml/,What is the point of ML?,"To what end are all these terms you guys use: models, LLM? What is the end game? The uses of ML are a black box to me. Yeah I can read it off Google but it's not clicking mostly because even Google does not really state where and how ML is used.

There is this lady I follow on LinkedIn who is an ML engineer at a gaming company. How does ML even fold into gaming? Ok so with AI I guess the models are training the AI to eventually recognize some patterns and eventually analyze a situation by itself I guess. But I'm not sure

*Edit* I know this is reddit but if you don't like me asking a question about ML on a sub literally called learnML please just move on and stop downvoting my comments ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kdnkt/what_is_the_point_of_ml/,159,133,0.75,"[Comment(id='k772ccc'), Comment(id='k772mu1'), Comment(id='k771ccp'), Comment(id='k774xc3'), Comment(id='k77e9za'), Comment(id='k773jj5'), Comment(id='k770qz0'), Comment(id='k773l18'), Comment(id='k7701tf'), Comment(id='k774lv1'), Comment(id='k776paz'), Comment(id='k775ovt'), Comment(id='k77r7sp'), Comment(id='k773k5i'), Comment(id='k78zfo9'), Comment(id='k77gesm'), Comment(id='k774szo'), Comment(id='k774680'), Comment(id='k774890'), Comment(id='k7784rg'), Comment(id='k779blt'), Comment(id='k77ap3y'), Comment(id='k77b0hm'), Comment(id='k77bbh9'), Comment(id='k77blno'), Comment(id='k77bqol'), Comment(id='k77c28k'), Comment(id='k77ckbt'), Comment(id='k77d3ji'), Comment(id='k77ggu4'), Comment(id='k77hug7'), Comment(id='k77jped'), Comment(id='k77k2fc'), Comment(id='k77njb0'), Comment(id='k77qppv'), Comment(id='k77sv6k'), Comment(id='k77tx2m'), Comment(id='k77vz4s'), Comment(id='k77yqht'), Comment(id='k781z0q'), Comment(id='k787tg1'), Comment(id='k78azdd'), Comment(id='k78ct1u'), Comment(id='k78ewf7'), Comment(id='k78iczc'), Comment(id='k78l4wq'), Comment(id='k78msky'), Comment(id='k78n3pt'), Comment(id='k78p0qs'), Comment(id='k78q04y'), Comment(id='k78r3bq'), Comment(id='k78r6cj'), Comment(id='k7903k2'), Comment(id='k790qak'), Comment(id='k791sse'), Comment(id='k792ny8'), Comment(id='k795at8'), Comment(id='k798qfi'), Comment(id='k79cvpv'), Comment(id='k79gra5'), Comment(id='k79ovg9'), Comment(id='k79surq'), Comment(id='k79zwgk'), Comment(id='k7a59gz'), Comment(id='k7a9i2s'), Comment(id='k7ahfcq'), Comment(id='k7ak17c'), Comment(id='k7axhkw'), Comment(id='k7azu85'), Comment(id='k7bgd0h'), Comment(id='k7br2su'), Comment(id='k7br4kk'), Comment(id='k7e11mw'), Comment(id='k7exp7u'), Comment(id='k7pk4bs'), Comment(id='k7prvz3'), Comment(id='k78px9f'), Comment(id='k772tsx'), Comment(id='k77v0vi'), Comment(id='k79krlp'), Comment(id='k78lub0'), Comment(id='k7caxyi'), Comment(id='k774cyv'), Comment(id='k77bw3i'), Comment(id='k77hfx6'), Comment(id='k771rk3'), Comment(id='k77501g'), Comment(id='k771gn9'), Comment(id='k770cxh'), Comment(id='k78706o'), Comment(id='k77rgg5'), Comment(id='k773qts'), Comment(id='k7b7jpl'), Comment(id='k774q92'), Comment(id='k77aq4i'), Comment(id='k774l5n'), Comment(id='k7767ye'), Comment(id='k78b2pr'), Comment(id='k7aho2e'), Comment(id='k77s73g'), Comment(id='k7brk28'), Comment(id='k7b6g47'), Comment(id='k7b1e3a'), Comment(id='k7hejnv'), Comment(id='k773tc7'), Comment(id='k776i20'), Comment(id='k78izbb'), Comment(id='k791072'), Comment(id='k79rpgj'), Comment(id='k78r8gm'), Comment(id='k7ppiec'), Comment(id='k77mre9'), Comment(id='k774uri'), Comment(id='k77kvw0'), Comment(id='k77v3pf'), Comment(id='k77ebhw'), Comment(id='k791anb'), Comment(id='k77319n'), Comment(id='k77cvcw'), Comment(id='k7785rv'), Comment(id='k77y13v'), Comment(id='k7b95ee'), Comment(id='k7b9sia'), Comment(id='k7clzfx'), Comment(id='k7dhmxf'), Comment(id='k774z49'), Comment(id='k786rfn'), Comment(id='k776pqs'), Comment(id='k78djqt'), Comment(id='k7c7ll3'), Comment(id='k782jnk'), Comment(id='k7b8q24'), Comment(id='k7bnag9'), Comment(id='k792sn1'), Comment(id='k79900x'), Comment(id='k7759mc'), Comment(id='k7848ov'), Comment(id='k79s8ea'), Comment(id='k7botc9'), Comment(id='k784u97'), Comment(id='k7815ct'), Comment(id='k7ldovc'), Comment(id='k780kad'), Comment(id='k7bashu'), Comment(id='k7d36zo'), Comment(id='k7755i7'), Comment(id='k776tu6'), Comment(id='k7bnqti'), Comment(id='k79p8mh'), Comment(id='k77661e'), Comment(id='k79wvex'), Comment(id='k79ytg4'), Comment(id='k788euh'), Comment(id='k788lcq'), Comment(id='k7dhr8b'), Comment(id='k775dok'), Comment(id='k7a2piq'), Comment(id='k7a03vj'), Comment(id='k78ewud'), Comment(id='k7axbph'), Comment(id='k79155a')]"
17l1nzj,currentscurrents,,2023-11-01 02:04:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17l1nzj/modelbased_vs_modelfree_rl/,Model-based vs model-free RL?,"Most RL has traditionally been model-free. However, some recent papers (dreamerv3, [TD-MPC2](https://arxiv.org/abs/2310.16828)) report very promising results with model-based RL - stable loss curves, little hyperparameter sensitivity, and much better sample efficiency. 

Have you tried model-based RL for any of your projects? How well has it worked for you?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l1nzj/modelbased_vs_modelfree_rl/,2,2,1.0,"[Comment(id='k7bbked'), Comment(id='k7c0ums')]"
17l51c4,vemilano44,,2023-11-01 05:21:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17l51c4/instance_segmentation_metrics_analysis/,Instance Segmentation - Metrics Analysis,"Hey guys, I would appreciate your help extremely!

I have trained an instance segmentation model (YOLOv8) and now I want to evaluate it. In the image below you can see the resulting metrics. Are there any insights from the metrics that provide an indication of why it's not performing as effectively? Should I train the model with more epochs?

&#x200B;

https://preview.redd.it/5esll4te8oxb1.png?width=3600&format=png&auto=webp&s=79b629ecddda93dd0c2598294e975262e6665d66",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l51c4/instance_segmentation_metrics_analysis/,0,1,1.0,[]
17l3r2g,West_Estate_7744,,2023-11-01 03:59:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17l3r2g/how_to_hire_a_ml_engineer_for_a_project/,How to hire a ML Engineer for a project ?,"Hi everyone,
I need a ML engineer for my project.
It's a healthcare project,I believe it can change the traditional healthcare system.
I am building a team of Experts who can accept the challenge and create a extraordinary thing.
Please suggest me where I can find a well experience ML engineer.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17l3r2g/how_to_hire_a_ml_engineer_for_a_project/,5,0,0.5,"[Comment(id='k7bwp4s'), Comment(id='k7cli4j'), Comment(id='k7bptbd'), Comment(id='k7ch3vp'), Comment(id='k7coeod')]"
17krsye,causeofyourEuphoria,,2023-10-31 18:29:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17krsye/what_is_the_unnormalized_logits_in_an_rnn/,What is the 'unnormalized logits' in an RNN?,"I am a complete beginner to ML and currently studying RNN.  I was trying to draw a diagram to explain to myself how the RNN worked. So the diagram shows a vanilla RNN which was unrolled 3 times, which has sigmoid function at the out put layer. can someone confirm if this diagram is right or wrong?

&#x200B;

https://preview.redd.it/hk5xxfsxzkxb1.jpg?width=1280&format=pjpg&auto=webp&s=848554268a0e9bd2915c01a7da533acffd56513e

Also I was trying to check whether this is correct using chatGPT and got this answer:  


https://preview.redd.it/b0tgk7fdykxb1.png?width=701&format=png&auto=webp&s=281c84756e00b1e65b1e22d0a7c1a8c6b6eed6c1

Can someone confirm what it means by unnormalized logits? If you can point me to a relevant resource, that would be cool too",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17krsye/what_is_the_unnormalized_logits_in_an_rnn/,3,3,0.72,"[Comment(id='k7axjhl'), Comment(id='k7bqo75'), Comment(id='k7dgc8t')]"
17ktokh,IdealOnion,,2023-10-31 19:50:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ktokh/advice_on_whats_next/,Advice on what’s next,"I'm looking for advice about what I should do next for my ML education. My background is physics and I'm currently in industrial research engineering. After getting my Masters I was sad to learn that there aren't a lot of opportunities to do math in the real world, so I decided to teach myself ML hoping I could eventually do math at work again. I've spent the last few years learning about probability and statistics and working on my coding skills. I'm now at the point where I can comfortably use the scikit-learn python module without the operations being a black box. Eventually I'll move on to less hand-holdy ML platforms but first I think this is a good spot to start practicing for real world applications. I have three practice datasets, one for regression and a medium and large for classification. 

The advice I'm looking for is, what next? I have a decent understanding of the mechanics of different model types, but not with actually using them. I'm tempted to just start investigating my datasets on my own, but I'm worried that without something to guide me I'll waste time on topics that are too specific. At this point I don't know what I don't know and I don't know what's important. 

Other than general advice, I'd love some textbook suggestions. I prefer ones on the mathy side that are a bit too advanced for my level so I can identify my weaker subjects and backtrack when necessary.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ktokh/advice_on_whats_next/,0,2,1.0,[]
17kw1or,ZeePintor,,2023-10-31 21:34:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kw1or/where_to_find_machine_learning_tutors/,Where to find machine learning tutors,"Hey guys,

&#x200B;

I am a junior software developer and I have a master degrees in engineering, so I am familiar with statistics and computer science.

With that said, I want to learn how to make a program where it could identify hand written characters (Chinese characters specifically).

&#x200B;

I'm not aware how hard this can be done.  
I know this has already been done, for example pleco (an app), and this website  [https://www.qhanzi.com](https://www.qhanzi.com).  
I also have found training models online for this purpose too. 

I just don't know how to apply it.

&#x200B;

I can't handle to sit through udemy'esk online courses and would rather go through the tutoring route, but I'm not sure where to find. Fiverr offerings didn't look too appealing.

Do you know anywhere I could find this? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kw1or/where_to_find_machine_learning_tutors/,6,1,0.67,"[Comment(id='k7aqn2s'), Comment(id='k7cub2v'), Comment(id='k7ado97'), Comment(id='k7danyb'), Comment(id='k7dnv0p')]"
17ko9o8,ktotheprinja,,2023-10-31 15:54:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ko9o8/anomaly_detection/,Anomaly Detection,"Hello Everyone,

I am new to ML and I  have been looking into Anomalies Detection as a side project at work.

So I have row count of table for past 3 months.I am trying to figure out if there is any anomalies in that.

For features I have the Date,Row count,calculated the percent difference in each day.

I have tried different models like Isolation Forest.Used ADTK library detectors such as IQR And quantile detectors .

The thing I am struggling is that even minor change in some cases are tagged as outlier.

Is there any other model /library that you would suggest for me to use or any pointers ?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ko9o8/anomaly_detection/,0,2,1.0,[]
17ko4cr,No-University-8206,,2023-10-31 15:48:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ko4cr/how_do_you_compare_the_selection_of_tools_to/,How do you compare the selection of tools to their usage?," Hi,

Here  is the problem statement: There are many sites to which admins can add  tools that do various things like manage articles, calendars, task  schedulers, gantt charts, etc. Users are registered for the sites and  can use the tools available.

The  obvious thing I've worked out so far is that there is a positive  correlation between the tools on each of the sites and the usage of said  tools.

Does it make sense first  to cluster the sites on the tools that they contain - to create a ""type  of site"" (i.e. one that focuses on articles or one that focuses on  workflows) This grouping might make it easier to identify sets of tools  that work together.

I want to use  the user interaction data to determine which tools are used extensively  in specific sites so that the development work can focus on improving  and fixing them. The grouping of sites might inform us in which tools  can be improved to enhance a ""type of site"".

I'm wondering how to match up the usage of tools to the choice of tools in a site.

Any ideas, recommendations or direction would be greatly appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ko4cr/how_do_you_compare_the_selection_of_tools_to/,0,2,1.0,[]
17kmxzf,Total-Opposite-8396,,2023-10-31 14:56:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kmxzf/what_are_the_possible_reasons_for_validation_loss/,What are the possible reasons for validation loss to fluctuate so much?,"Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.

I'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info. 

https://preview.redd.it/r0d1awi3yjxb1.png?width=1087&format=png&auto=webp&s=1112f6ffbf0f93b810a23623d8658e7c0f9b2e72",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kmxzf/what_are_the_possible_reasons_for_validation_loss/,3,2,0.76,"[Comment(id='k79o36t'), Comment(id='k796zb9'), Comment(id='k7972o9')]"
17kmsij,art_luke,,2023-10-31 14:49:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kmsij/finding_bugs_in_pipelines_where_to_get_debugging/,Finding bugs in pipelines - where to get debugging exercises?,"I want to exercise troubleshooting and debugging ML training pipelines. I have learned a lot from my own mistakes implementing models and having to spot errors. 

Sometimes bugs in ML are nuanced and it takes some time to even discover them. I want to train myself on distilled examples of mistakes so that I can debug my code faster in the future. 

I have read the great blogpost by Karpathy but would want to practice this advice on some training pipelines that contain a hidden bug. 

For example, I would imagine that university courses should have such scenarios as a part of final exams or midterms. Does anyone know of good sources?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kmsij/finding_bugs_in_pipelines_where_to_get_debugging/,2,2,1.0,"[Comment(id='k7c7hzd'), Comment(id='k7c7sin')]"
17krwo1,algo_ur,,2023-10-31 18:33:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17krwo1/how_often_should_i_code_in_ml/,How often should I code in ML?,I wonder how often should I code during learning ML. Should I read more or code more?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17krwo1/how_often_should_i_code_in_ml/,13,1,0.52,"[Comment(id='k79kfb8'), Comment(id='k79mwmi'), Comment(id='k79sr2l'), Comment(id='k79xc45'), Comment(id='k7bgc2x'), Comment(id='k7avwus'), Comment(id='k7bdzkr'), Comment(id='k7c0nrk'), Comment(id='k7cmmb6'), Comment(id='k7gwalp'), Comment(id='k7cgmuj'), Comment(id='k7cq6q8'), Comment(id='k7fidoa')]"
17krq8d,tdionis,,2023-10-31 18:26:03+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17krq8d/polygon_annotation_best_practices_for_semantic/,Polygon Annotation Best Practices for Semantic & Instance Segmentation - Supervisely,,learnmachinelearning,https://supervisely.com/blog/how-to-use-polygon-anotation-tool-for-image-segmentation/,0,1,1.0,[]
17kj0c2,Richard-Leo,,2023-10-31 11:40:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kj0c2/what_colleges_did_kaggle_medalists_end_up_in/,What colleges did Kaggle medalists end up in?,"Well,   I've seen lots of ISEF medalists end up in top-tier colleges, also for   Intel STS & Olympiad medalists. And I see Kaggle as another extremely challenging competition as these I mentioned.

I'm quite curious about where this small amount of Kaggle medalists at high school ended up. 

To be specific, medalists are those who have earned at least one gold/silver/bronze in competitions.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kj0c2/what_colleges_did_kaggle_medalists_end_up_in/,1,2,0.6,[Comment(id='k7awguq')]
17kodlz,vtimevlessv,,2023-10-31 15:59:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kodlz/ai_mind_blows_lets_hear_your_story/,AI Mind Blows - let’s hear your story,"Hello everyone!

I'm curious about what you've experienced in your AI projects. Is there a specific use case that has particularly excited you? Feel free to refer to your own projects or things you've seen on YouTube. 

I'm all ears 👂🏼👂🏼",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kodlz/ai_mind_blows_lets_hear_your_story/,1,0,0.33,[Comment(id='k795ayj')]
17ko6jo,Early_Significance57,,2023-10-31 15:50:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ko6jo/alternate_downloading_resource_for_yolo_weights/,Alternate downloading resource for YOLO weights,"I was looking into a project on github that uses yolov3 and pretrained yolov3.weights for DarkNet Model. The download link works but it is very slow. Are there any other sources?

This is the link : [https://pjreddie.com/media/files/yolov3.weights](https://pjreddie.com/media/files/yolov3.weights)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ko6jo/alternate_downloading_resource_for_yolo_weights/,0,1,1.0,[]
17jx1a9,algo_ur,,2023-10-30 16:13:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jx1a9/what_actually_ml_engineers_people_who_involved_in/,What actually ML engineers/ people who involved in ML domain do?,"Hey, my question was pretty much described in the title. I wondered what do this people do, does create the models for work or they just use existing ones.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jx1a9/what_actually_ml_engineers_people_who_involved_in/,22,69,0.95,"[Comment(id='k73zlmd'), Comment(id='k741f7v'), Comment(id='k75zmep'), Comment(id='k74jy4g'), Comment(id='k74lcub'), Comment(id='k75skib'), Comment(id='k74dyzw'), Comment(id='k76swnb'), Comment(id='k77lhfg'), Comment(id='k79vut2'), Comment(id='k741g3q'), Comment(id='k75y18p'), Comment(id='k7405ai'), Comment(id='k76m3bm'), Comment(id='k77hv41'), Comment(id='k7cbjys'), Comment(id='k7ebhf5'), Comment(id='k763rye'), Comment(id='k76yqqq'), Comment(id='k76yoa0'), Comment(id='k7741ax'), Comment(id='k7cds0a')]"
17kguaz,Altruistic_Building2,,2023-10-31 09:15:38+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17kguaz/sound_bytes_part_1_the_abcs_of_sound_and/,Sound Bytes Part 1: The ABCs of Sound and Digitization,,learnmachinelearning,https://medium.com/artificialis/sound-bytes-part-1-the-abcs-of-sound-and-digitization-94423e756969,0,3,1.0,[]
17kmekb,Smonking_Sheep,,2023-10-31 14:31:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kmekb/problem_with_image_to_image/,Problem with image to image,"Hi everyone, I'm very new to ml and I have a problem I cant seem to fix.

I'm trying to ""upscale"" height fields (a black and white image dictating the elevation of terrain).

Essentially going from the grey grid to the green terrain :

[grid and terrain](https://preview.redd.it/v7tc364jajxb1.png?width=589&format=png&auto=webp&s=1e19ce4a165b2c331299a40f233ca1d6f9c02ae1)

[visual explanaition](https://preview.redd.it/qyp1i3urbjxb1.png?width=1889&format=png&auto=webp&s=7aa0c7924ba7e5808c98478b84a10c0cc82686fe)

To do so I have created a dataset of 10 000 image pairs, and 60 000 of flipped/rotated variation.

I'm using [this auto encoder](https://www.tensorflow.org/tutorials/generative/autoencoder) (from tensorflow using keras) tutorial to do image to image. But I dont think it is the proper method for what I am trying to do.

These are the results I'm getting :

[input : 16\*16 grid, reconstructed : output of the model, target : intended result](https://preview.redd.it/8iqmh34fdjxb1.png?width=1494&format=png&auto=webp&s=53ed44a3bf288f05472f19a44abedfcfa251b9a1)

Here is the code I've been using

    from matplotlib import pyplot as plt
    import numpy as np
    import tensorflow as tf
    from tensorflow.keras import layers, losses
    from tensorflow.keras.models import Model
    
    #convert streaming dataset to numpy arrays (memory expensive)
    def to_numpy(dataset):
      numpy_dataset = []
      for element in dataset.as_numpy_iterator():
         numpy_dataset.append(element)
      return np.array(numpy_dataset)
    
    seed = 455464
    # source images
    low_ds, low_val_ds= tf.keras.utils.image_dataset_from_directory(
        directory='./training_data/verylow_varied/',
        labels=None,
        validation_split=0.2,
        seed=seed,
        subset='both',
        color_mode='grayscale',
        image_size=(16,16),
        batch_size=None
    )
    low_ds = to_numpy(low_ds).astype('float32')/255
    low_val_ds = to_numpy(low_val_ds).astype('float32')/255
    
    #target images
    high_ds, high_val_ds= tf.keras.utils.image_dataset_from_directory(
        directory='./training_data/high_varied/',
        labels=None,
        validation_split=0.2,
        seed=seed,
        subset='both',
        color_mode='grayscale',
        image_size=(256,256),
        batch_size=None
    )
    
    high_ds = to_numpy(high_ds).astype('float32')/255
    high_val_ds = to_numpy(high_val_ds).astype('float32')/255
    
    #the model itself
    class Autoencoder(Model):
      def __init__(self, latent_dim, shape_in):
        super(Autoencoder, self).__init__()
        self.latent_dim = latent_dim
        self.shape_in = shape_in
        self.encoder = tf.keras.Sequential([
          #layers.RandomFlip(""horizontal_and_vertical""), # does not seem to work, I'm instead flipping images ahead
          layers.Flatten(),
          layers.Dense(latent_dim, activation='relu'),
        ])
        self.decoder = tf.keras.Sequential([
          layers.Dense(tf.math.reduce_prod(shape_in), activation='sigmoid'),
          layers.Reshape(shape_in)
        ])
    
      def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
    
    
    shape_in = (256, 256, 1)
    
    latent_dim = 512 #idk what value would be fitting
    
    autoencoder = Autoencoder(latent_dim, shape_in)
    
    autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())
    
    autoencoder.fit(low_ds, high_ds,
                    epochs=5,
                    shuffle=False, # I am unsure if it shuffles the order of the pairs or the pairs themselves
                    validation_data=(low_val_ds, high_val_ds))
    
    encoded_imgs = autoencoder.encoder(low_val_ds).numpy()
    decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()
    
    #plot results
    n = 4
    plt.figure(figsize=(20, 4))
    for i in range(n):
      # display original
      ax = plt.subplot(3, n, i + 1)
      plt.imshow(low_ds[i])
      plt.title(""input"")
      plt.gray()
      ax.get_xaxis().set_visible(False)
      ax.get_yaxis().set_visible(False)
    
      # display reconstruction
      ax = plt.subplot(3, n, i + 1 + n)
      plt.imshow(decoded_imgs[i])
      plt.title(""reconstructed"")
      plt.gray()
      ax.get_xaxis().set_visible(False)
      ax.get_yaxis().set_visible(False)
    
      # display intention
      ax = plt.subplot(3, n, i + 1 + n*2)
      plt.imshow(high_ds[i])
      plt.title(""target"")
      plt.gray()
      ax.get_xaxis().set_visible(False)
      ax.get_yaxis().set_visible(False)
    plt.show()
    

So my questions are :  
Is an autoencoder appropriate ? If not what should I be using ?  
Is my dataset (10 000 pairs + 60 000 rotated/flipped pairs) enough ?

Is this code OK ? ( I'm a begginer, I might have made an oversight)

When creating the data, by choice of simplicity I normalized the source and target independently, Is it a reason why it isn't working ?

PS: I know it is possible as demonstrated here : [Houdini 20 Sneak Peek](https://youtu.be/_fnlvMpyInU?si=Kc2ZVU0GjmHnY-1k&t=300)  


PS : The link to the [dataset](https://transfer.sh/NeHeRvho5l/training_data.zip), it will expire 14/10/2023

&#x200B;

Thanks in advance for all your answers.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kmekb/problem_with_image_to_image/,0,1,1.0,[]
17km94w,IngenioerStuderende,,2023-10-31 14:24:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17km94w/which_datacamp_course_about_ml_can_you_recommend/,Which DataCamp course about ML can you recommend?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17km94w/which_datacamp_course_about_ml_can_you_recommend/,1,0,0.33,[Comment(id='k7baqsw')]
17km8kn,SQG37,,2023-10-31 14:23:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17km8kn/model_training_platform/,Model Training Platform,"So I'm relatively new to machine learning and recently have been experimenting with finetuning Yolo detection models for a project at work. The Ultralytics Python module makes the process pretty smooth and I have scripts to preprocess all my data. This process works for a machine or two running at a time. I'm curious about what tools are out there to run multiple experiments on on-prem hardware and monitor GPU loads, and training progress. 

Prior to machine learning, I was crypto mining and there were services like minerstat and simplemining I used to control my devices from a single web portal. I'm wondering if there's something similar I can use that can be hosted on-prem since I will be processing proprietary data in the future. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17km8kn/model_training_platform/,0,1,1.0,[]
17k85tm,khaliiil,,2023-10-31 00:23:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k85tm/how_do_i_model_this_nonlinear_relationship/,How do I model this nonlinear relationship?,"I have a regression problem at hand where I'm supposed to predict the yield per acre of a crop in a piece of land based on multiple variables.

one of these variables is Acres (which the area cultivated in Acres).

The Spearman correlation gives me a score of 0.93.

here's a scatter plot of the two variables.

the Y axis is the target ( the yield per acre)

and the X axis the Area cultivated in acres

&#x200B;

how do i model this problem in order to predict the Yield?

Or how should i think in a situation like this?

[scatter plot of the variables](https://preview.redd.it/aip3h91dmfxb1.png?width=388&format=png&auto=webp&s=0a32d0ea58be15120edf2f37b5ddf55e14f72a63)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k85tm/how_do_i_model_this_nonlinear_relationship/,39,11,0.8,"[Comment(id='k75yljf'), Comment(id='k76f8r6'), Comment(id='k767wxp'), Comment(id='k77w9km'), Comment(id='k75zk5w'), Comment(id='k767qq9'), Comment(id='k774h5w'), Comment(id='k77ywq5'), Comment(id='k76rrdw'), Comment(id='k77o1ag'), Comment(id='k78q003'), Comment(id='k795sx1'), Comment(id='k76v47f'), Comment(id='k77mbhm'), Comment(id='k78yrge'), Comment(id='k795i25'), Comment(id='k75z00r'), Comment(id='k76x4xw'), Comment(id='k7680d3'), Comment(id='k75zshp'), Comment(id='k768ihf'), Comment(id='k775riw'), Comment(id='k78lvtk'), Comment(id='k77kgba'), Comment(id='k7fdbn1'), Comment(id='k75zu30'), Comment(id='k77mn2e'), Comment(id='k7av3f3'), Comment(id='k774caq'), Comment(id='k78yzaw'), Comment(id='k768mb1'), Comment(id='k79eksg'), Comment(id='k78arry'), Comment(id='k7fgnd3'), Comment(id='k75zzz6'), Comment(id='k775ua3'), Comment(id='k7cuhbc'), Comment(id='k761r8b'), Comment(id='k764xgh')]"
17kfx0a,Coconut_Cove,,2023-10-31 08:02:46+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kfx0a/feasibility_of_nlp_model_outputting/,Feasibility of NLP model outputting attribute-value pairs.," 

Hello,

I'm researching the feasibility of a model which needs to take in a large chunk of text (report) and predict a single value out of a finite set of values for multiple attributes each. Example:

&#x200B;

https://preview.redd.it/cd51l423whxb1.png?width=270&format=png&auto=webp&s=bb73792fbe5a22054e315e0fbcfc5e6610ed0575

How feasible is such a model? I've worked on an NLP project before, classifying text as spam or non-spam, but the outputs there were binary and straight-forward. An 'obvious' solution \*might\* be to classify each attribute individually and assemble the table after, but I assume that would be inefficiently resource-intensive? Or not, I don't know.

Thank you in advance!

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kfx0a/feasibility_of_nlp_model_outputting/,9,2,0.75,"[Comment(id='k77nine'), Comment(id='k78774i'), Comment(id='k77uno2'), Comment(id='k78lr7b'), Comment(id='k77vlyx'), Comment(id='k7d67hs'), Comment(id='k77xrum'), Comment(id='k7d9vbd'), Comment(id='k7eszut')]"
17kidw6,paulinafron,,2023-10-31 11:01:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kidw6/msc_in_machine_learning_advice/,MSc in Machine Learning Advice,"I am planning to apply for Masters programmes in ML but they all require a degree in a 'highly quantitative field such as mathematics or physics’. I study BA Geography with Social Data Science where I have taken a number of Data Science courses that covered statistics and programming, but I still need to make up for the fact that I’m not coming from a very quantitative background (although I’ve taken Maths HL in IB). 

Does anyone have advice on how I can demonstrate my mathematical abilities? Is there any qualification/ exam I could take?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kidw6/msc_in_machine_learning_advice/,3,1,1.0,"[Comment(id='k77qne0'), Comment(id='k79pkxh'), Comment(id='k7auz0z')]"
17kfkq6,Relative_Winner_4588,,2023-10-31 07:36:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kfkq6/finding_better_embedding_models/,Finding better embedding models,"
I am trying to develop a project akin to a private GPT system capable of parsing my files and providing answers to questions. Following experimentation with various models, including llama-2-7b, chat-hf, and flan-T5-large, and employing instructor-large embeddings, I encountered challenges in obtaining satisfactory responses.

One noteworthy observation is that, when I invoke the retriever by calling retriever.invoke() with a question, it struggles to extract the most pertinent text necessary for generating optimal answers. In this pursuit, I have explored embeddings like instructor-large, as well as models from the simple-transformers library.

I kindly request recommendations for embedding models that can effectively extract text relevant to the given context. Furthermore, I am uncertain whether it would be more advantageous to utilize text-generation models for querying my files or to opt for conventional question-answering models, such as roberta-base-squad2. Please help me with this.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kfkq6/finding_better_embedding_models/,0,1,0.67,[]
17k9l89,Goatman117,,2023-10-31 01:32:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k9l89/why_would_an_extra_binary_categorical_dummy/,Why would an extra binary categorical dummy variable act as a bias?,"I'm going through the FastAI course and really enjoying it, however in Lesson 5 Jeremy prepares some titanic data for the lesson's neural net from scratch to predict with, and converts a category of 3 options into 3 binary columns in the input data. He explains he went with all 3 columns not 3-1 (the standard method) because he prefers it. Later in the vid he says that because we have 3 dummy variables, 1 per option, we don't need a bias or 'constant' term in the forward pass for the first layer. I'm completely lost as to why having an extra dummy variable accounts for the bias term?  


Surely the bias is a way to offset the function in a direction, how would an extra dummy variable that will sometimes be fully activated or deactivated allow for the same functionality? I get that because the input will be sometimes 1, the optimizer could simulate this offset with the weight, but the trouble is the variable won't always be activated.  


I'm sure this all stems from a lack of understanding of dummy variables and the way they affect the function, so any explanations would be great. I'm also unsure as to how n-1 embeds the information about the missing variable into the model (I understand that if category 1 is 0, and category 2 is also 0, 3 must be 1, it's just the actual maths behind this that is unclear).  


[https://youtu.be/\_rXzeWq4C6w?si=D8LiSo5YI0PNftvF&t=3982](https://youtu.be/_rXzeWq4C6w?si=D8LiSo5YI0PNftvF&t=3982)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k9l89/why_would_an_extra_binary_categorical_dummy/,4,3,1.0,"[Comment(id='k77ikza'), Comment(id='k7b1z16'), Comment(id='k7cuiij'), Comment(id='k7kyvwm')]"
17jv6y6,Alert_Director_2836,,2023-10-30 14:52:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jv6y6/keras_giving_80_accuracy_where_torch_giving_15/,Keras giving 80% accuracy where torch giving 15% accuracy on eval during training on same model architecture.,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jv6y6/keras_giving_80_accuracy_where_torch_giving_15/,15,18,0.77,"[Comment(id='k73g56z'), Comment(id='k73nmo3'), Comment(id='k74fhlo'), Comment(id='k73lw7v'), Comment(id='k74pvi5'), Comment(id='k73ytce'), Comment(id='k76d1vx'), Comment(id='k7771ry'), Comment(id='k73q73l'), Comment(id='k74iinc'), Comment(id='k749cia'), Comment(id='k75suj2'), Comment(id='k74t2d4'), Comment(id='k76r6rk'), Comment(id='k76u54t')]"
17k0kyz,Illustrious-Isopod-1,,2023-10-30 18:50:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k0kyz/am_i_wasting_my_time_using_a_video_from_3_years/,Am I wasting my time using a video from 3 years ago,"I am a second year uni student and I’m trying to prepare for a research position that’s happening this summer. My experience with machine learning so far has been minimal and I’ve gathered from the employer that they are using tensorflow. Right now I’m following [this tutorial](https://youtu.be/tPYj3fFJGjk?si=HvAdoLucHSl7F3QY) and when running the code I get warnings that a lot of the features they use are depreciated like feature tables. Is this still a good resource or should I find something more recent?

I decided to start with freecodecamp as this subreddit said it was good. Any resource reccomendation are welcome. I plan on taking an Artificial Intelligence course next semester but i doubt it will give me any tensorflow knowledge.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k0kyz/am_i_wasting_my_time_using_a_video_from_3_years/,2,5,0.78,"[Comment(id='k75wfen'), Comment(id='k77vscm')]"
17kbz6b,AvvYaa,,2023-10-31 03:32:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kbz6b/a_video_covering_the_current_state_of/,A video covering the current state of Multi-modal/Visual-Language models," Hello people!

I wanted to share a video I made on the current trends and research on Multimodal AI models - models that combine multiple modalities, like text, images, audio, videos, etc to train. It's kind of technical heavy, but it also covers a lot of the basics as well like contrastive learning (CLIP, ImageBind), unified modeling (VL-T5), masked visual-language models like VisualBert/VilBERT, as well as the more recent heavier ""Attention""-based architectures (like Flamingo, PaLM-E). Leaving a link here for those who are interested in the topic - all feedback is super appreciated!

[https://youtu.be/-llkMpNH160](https://youtu.be/-llkMpNH160)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kbz6b/a_video_covering_the_current_state_of/,0,0,0.5,[]
17kaxbt,Individual_Ad_1214,,2023-10-31 02:39:06+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17kaxbt/multi_or_mixed_input_neural_network_for/,Multi (or mixed) input neural Network for multi-output prediction,,learnmachinelearning,/r/deeplearning/comments/17kax2i/multi_or_mixed_input_neural_network_for/,0,1,1.0,[]
17kampu,ConnentingDots,,2023-10-31 02:24:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17kampu/ml_ablation_studies/,ML ablation studies,"We're using yolov7 for inference as a benchmark. Now we need to conduct an ablation study on yolov7 for an edge AI project where the tradeoff between energy consumption during edge inference and model's performance is a must. Seeking advice about available libraries for ablation and tutorials/papers.

Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17kampu/ml_ablation_studies/,0,1,1.0,[]
17k6yjm,dosa-palli-chutney,,2023-10-30 23:28:15+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17k6yjm/replicating_results/,Replicating results,"Hello Everyone,
I am having trouble with replicating the results from this link. I can train the model but I was unable to generate images.",learnmachinelearning,https://github.com/mattiasxu/VQVAE-2,0,1,1.0,[]
17k16ml,elMandarine,,2023-10-30 19:17:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k16ml/how_can_i_build_a_transformer_network_to_work_as/,How can I build a transformer network to work as IDS?,"I am using the UNSW-NB15 dataset and I want the transformer to do a multi-class classification, in orden to compare its performance with other algorithms, but I don't know where to start. How can I develop the model?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k16ml/how_can_i_build_a_transformer_network_to_work_as/,2,2,1.0,"[Comment(id='k76kwzw'), Comment(id='k7jumd7')]"
17k68lp,MikelFury,,2023-10-30 22:55:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k68lp/relationship_annotation_question/,relationship annotation question,I am working on my first machine learning project. I just had one question about relationship annotation. Can I assign multipul relationships? Example if I had a list of horror movies and I wanted to assign them to the horror movie title as a group. Would that work like I think? ,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k68lp/relationship_annotation_question/,0,1,1.0,[]
17k35pw,SoylentRox,,2023-10-30 20:42:07+00:00,False,,1698703811.0,False,True,False,/r/learnmachinelearning/comments/17k35pw/leetcode_for_senior_mle_interviews/,Leetcode for senior MLE interviews?,"I have worked in this field about 4 years now as an mle, however, I work on only a part of it in a specialized role.  I would like to move on but need to know what the ""gotcha"" questions are these days.   Apparently, per blind posts, mle interviews are only about 30 percent LC.  What's the rest and other than paying interview kickstart or other services, how can I learn it?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k35pw/leetcode_for_senior_mle_interviews/,2,1,0.67,"[Comment(id='k75dw1p'), Comment(id='k779j5q'), Comment(id='k75e6nw')]"
17k1hru,Tyron_Slothrop,,2023-10-30 19:30:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k1hru/ttest_pvalue_and_kaggle_data/,"T-Test, P-value, and Kaggle data","When using a typical Kaggle dataset, are we meant to treat it as an accurate sample of a population? What I find off is that most datasets don't seem to be sample from a larger dataset; in other words, not real-world data. In the real world, as an analyst or data scientist, would we take proprietary data and take a sample like a statistician would, or is that more a data engineer role? Like many, I can work with Kaggle data and build models that are relatively accurate, but I'm betting I would struggle with real-world data. Does anyone have a good resource for working with messy, real-world data? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k1hru/ttest_pvalue_and_kaggle_data/,1,1,1.0,[Comment(id='k74ui2p')]
17jtdaw,GrumpyMcGillicuddy,,2023-10-30 13:27:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jtdaw/colabsnotebooks_for_learning_linear/,Colabs/notebooks for learning linear algebra/calculus concepts,"Hello machine learners!

I have some intuitive understanding about how various ML algorithms work, but would like to get a better understanding about what's going on under the hood. I've started the [deeplearning.ai](https://deeplearning.ai/) [Math for Machine Learning](https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/) specialization, but find the content to be somewhat conceptual and hand-wavy.

Is there a way to learn key concepts as they relate to machine learning (esp. deep learning) in a hands-on way with a series of colabs/jupyter notebooks? I tend to have a better time learning hands-on, but haven't found any notebooks so far that I like. I've also gone through some youtube videos from 3blue1brown and NancyPi which are pretty good, but would like to do some exercises.

Any recommendations would be greatly appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jtdaw/colabsnotebooks_for_learning_linear/,2,3,1.0,"[Comment(id='k73hw3x'), Comment(id='k73v150')]"
17jw0ii,Naxxthedk,,2023-10-30 15:28:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jw0ii/is_this_doable/,Is this doable?,"Hey everyone,

I'm a first-year engineering student, and for a personal project, I want to build a real-time object detection system from scratch. I have some coding experience, but I've never done anything related to machine learning.

How doable is this? Any advice or tips would be greatly appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jw0ii/is_this_doable/,2,2,0.75,"[Comment(id='k73smaw'), Comment(id='k74d0pf')]"
17k0umm,araarahuhuhu,,2023-10-30 19:02:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17k0umm/computer_vision_and_nlp/,Computer vision and NLP,Hello everyone hope you all are having a good day. I am a BS computer science student in my 5th semester. I've always known I wanted to get into the field of vision and NLP but haven't had much exposure. I wanted to ask about what I should learn and what path I should follow and a basic guide on how I can excel in this field and make a name. I would love for you to share your personal experiences. Thank you:),learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17k0umm/computer_vision_and_nlp/,1,1,0.67,[Comment(id='k74ss21')]
17jzi1j,kingabzpro,,2023-10-30 18:02:21+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17jzi1j/top_10_ai_startups_to_work_for_in_india/,Top 10 AI Startups to Work for in India,,learnmachinelearning,https://www.kdnuggets.com/top-10-ai-startups-to-work-for-in-india,0,1,0.67,[]
17jt6wf,escalize,,2023-10-30 13:18:04+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17jt6wf/enable_and_manage_vector_search_in_mongodb_atlas/,🔮 Enable and manage Vector Search in MongoDB Atlas with SuperDuperDB Webinar,,learnmachinelearning,/r/mongodb/comments/17jt2qm/enable_and_manage_vector_search_in_mongodb_atlas/,0,2,1.0,[]
17jwnoe,MightyZinogre,,2023-10-30 15:57:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jwnoe/machine_learning_in_finance_coursebook/,Machine Learning in Finance course/book?,"Hello everyone,

Can you suggest me any material regarding the use of machine learning/deep learning in Finance (apart from the Dixon book)? Like, any Youtube/Coursera course or any other book will be fine. Thank you very much!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jwnoe/machine_learning_in_finance_coursebook/,0,0,0.5,[]
17jwb90,gevorgter,,2023-10-30 15:41:57+00:00,False,,1698681171.0,False,True,False,/r/learnmachinelearning/comments/17jwb90/different_tasks_types_with_nlp_model/,different task's types with NLP model,"I am looking for example where one NLP model can solve different types of tasks

so for example i have sentence ""Loan amount is 34000, the is no prepayment penalty"". I want model to echo back to me 34000 as an answer but at the same time answer question ""Is there prepayment penalty"" with ""Yes/No""

so i am mixing 2 types of tasks here, Data Extraction and Sentiment Analysis. 

I do not think HuggingFace has something like that.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jwb90/different_tasks_types_with_nlp_model/,0,1,1.0,[]
17jeomu,Aromatic_Eye_6268,,2023-10-29 22:39:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jeomu/how_to_utilise_time_to_be_well_prepared_for/,How to utilise time to be well prepared for upcoming job in ML?,"I have around 6 months left after which I will be joining a FAANG like company in role of a ML Engineer. I was thinking how should I utilise this time in order to be well prepared for the role.

1. do courses? If yes, then which ones?
2. Pursue independent research?
3. Participate in Kaggle competitions to sharpen my skill?
4. They haven't told me my exact domain of work in ML. Not sure should I brush up on NLP, CV, GNN or something else.

Any help is appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jeomu/how_to_utilise_time_to_be_well_prepared_for/,26,20,0.8,"[Comment(id='k710hgg'), Comment(id='k70yp82'), Comment(id='k725tf7'), Comment(id='k727y8p'), Comment(id='k725oyt'), Comment(id='k72c3rv'), Comment(id='k72tz88'), Comment(id='k72vr1s'), Comment(id='k735lva'), Comment(id='k71zotu'), Comment(id='k71hpim'), Comment(id='k71x2pv'), Comment(id='k7521nb'), Comment(id='k725znu'), Comment(id='k7266fx'), Comment(id='k726bir'), Comment(id='k7268ks'), Comment(id='k730dmi'), Comment(id='k72fxq3'), Comment(id='k729yzj'), Comment(id='k726ibs'), Comment(id='k726top'), Comment(id='k72aw1w'), Comment(id='k750ozo'), Comment(id='k726rh2'), Comment(id='k7idtv9')]"
17jv7xz,ledmmaster,,2023-10-30 14:53:57+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17jv7xz/catboost_hyperparameter_tuning_guide_with_optuna/,CatBoost Hyperparameter Tuning Guide with Optuna,,learnmachinelearning,https://forecastegy.com/posts/catboost-hyperparameter-tuning-guide-with-optuna/,0,1,1.0,[]
17jjxjj,techhgal,,2023-10-30 03:03:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jjxjj/please_suggest_a_book_for_beginners/,Please suggest a book for beginners,"I'm  a second year engineering student. I have decent math knowledge (high school + 3 semesters of college). I'm interested in ML and I know basics of Python and I did a course on Coursera about Python for data science. 

I will probably start with Andrew Ng's Machine Learning Specialization, but I learn better by reading books and then applying the concepts in projects. While searching for books (for absolute beginners in ML), I came across these two books the most:

1. An Introduction to Statistical Learning with R (with Python is also available) 
2. Hands-on Machine Learning with Scikit-Learn, Keras & Tensorflow 

Which of these two books would you prefer? I have no knowledge of R. 

Also, any other book/course suggestions are appreciated.

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jjxjj/please_suggest_a_book_for_beginners/,6,6,1.0,"[Comment(id='k71mkyx'), Comment(id='k74gfbe'), Comment(id='k71zvpi'), Comment(id='k72e30d'), Comment(id='k72kpu0'), Comment(id='k73fyxm')]"
17j8bv8,ProfessionalOne272,,2023-10-29 17:48:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17j8bv8/why_does_l1_regularization_get_the_weight_to/,why does l1 regularization get the weight to exact zero and why does l2 don't,"From what I understand, the penalty term just adds the total weight or the square of the weight and this would lead to the model to train in a sweet spot between low-weight and low-cost value, but what I do not understand is why l1 makes the weight absolute zero and why l2 don't. I appreciate any reply.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17j8bv8/why_does_l1_regularization_get_the_weight_to/,16,22,0.85,"[Comment(id='k6zbr2d'), Comment(id='k6zvglj'), Comment(id='k71864c'), Comment(id='k71ymcm'), Comment(id='k6zjqee'), Comment(id='k731rwe'), Comment(id='k707hr3'), Comment(id='k742i0m'), Comment(id='k6zcxmy'), Comment(id='k73hqp6'), Comment(id='k703bp3'), Comment(id='k710p0b'), Comment(id='k6ze5by'), Comment(id='k75c0hs'), Comment(id='k71a5ph'), Comment(id='k735qk6')]"
17jo9nt,Expert-Damage8482,,2023-10-30 07:58:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jo9nt/p_classify_facial_image_into_skin_types/,[P] Classify facial image into skin types,"Hello everyone!

I'm trying to recommend the best skin care product for a specific skin type via an image, though I can't find a dataset of images of facial skin annotated with their type like oily, sensitive, or dry... I don't know how to proceed, I'm using the FastAI \`fastbook.search\_images\_ddg()\` function to retrieve images from DuckDuckGo but the thing is, the images are not real, there of models with perfect skin types and not really real-life data, though I know it's hard to get real-life faces (because of confidentiality) I still don't know how to proceed

I cannot find any solution, so your help is appreciated!

Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jo9nt/p_classify_facial_image_into_skin_types/,0,1,1.0,[]
17jey8s,luiz200411,,2023-10-29 22:51:30+00:00,False,,1698665749.0,False,True,False,/r/learnmachinelearning/comments/17jey8s/which_methods_use_to_extract_specific_info_on/,Which methods use to extract specific info on unstructured text?,"Hey friends, I'm new to the AI world (been programming (python) for 4 years but never worked with AI stuff), I need to extract some specific info from documents, I'm reading about NLP and all this stuff but still figuring out which method(s) should I use to make this works, any recomendations of which methods to use? (Edit: I don't want to use regex nor LLMs)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jey8s/which_methods_use_to_extract_specific_info_on/,5,2,1.0,"[Comment(id='k70shl7'), Comment(id='k726tpy'), Comment(id='k70xir4'), Comment(id='k70yqr2'), Comment(id='k70zuac')]"
17jeujq,AvvYaa,,2023-10-29 22:46:41+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17jeujq/neural_attention_one_simple_example_that_explains/,Neural Attention - One simple example that explains everything you need to know,"This video explains all the key ideas behind attention and breaks it down with a simple intuitive use-case: A Chatty Movie Recommendation System. What Attention does, how the architectures work, and most importantly, why they are so powerful - it’s a deep dive.",learnmachinelearning,https://youtu.be/frosrL1CEhw,0,1,0.6,[]
17je4zn,Low-Proposal-3319,,2023-10-29 22:13:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17je4zn/need_advise_on_creating_a_conversational_chatbot/,Need advise on creating a conversational Chatbot for my University,"Hey everyone! I need some advise on creating a conversational chatbot for my University as my Final Year Project (FYP).

2024 will be last year for my BSCS degree and we have to build an application or something in the last year. So, I thought of creating a chatbot (just like GPT) to help students (who have admission queries). Most of the time, students or parents will have to call University for various questions and then they have to wait to ACTUALLY talk to the admins office people.

Now, talking in terms of coding/programming, I have created a basic PDFbot by using LLama2, Huggingface and Pinecone. Its very very easy and yes its fairly inaccurate too. The PDF that I am using rn will be replaced by the dataset that I gather in order to create the bot for my Uni, but it will also be inaccurate as this one. Also, the chatbot that I have made is just based on this one function called ""similarity\_search()"" and I am literally passing query of the user to this function which then tries to find the most relevant answer by the embeddings from knowledge base.

How do I make this accurate? I know using the OpenAI model will make it accurate, but its paid as well, idk how will I manage to do that. Plus, i reckon there will be a simple function there too which doesn't make me a good programmer I think. I really want to do something good and unique for once. I have dreamt about leaving back something in my Uni that has my name over it. **Can I do something where I get to make a mini-language model or something like that? Will it be too complex for me to handle? (I consider myself a beginner to this programming world)**

1- I am planning to create a dynamic dataset which will also include any event that's going to happen in our University.  
2- I am also planning to make the chatbot intelligent enough to consult confused students.  
3- Chatbot will also include information about each and every faculty member. Their qualifications, research papers and other info in general.

It would be a relief if any of the experts give me a roadmap on this, it will be genuinely a stress relief for me. I am trying to get done with at least 70% of the work before the start of the next year so that I don't have to work much in the next year.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17je4zn/need_advise_on_creating_a_conversational_chatbot/,2,0,0.5,"[Comment(id='k77rfgx'), Comment(id='k7cludd')]"
17j20ze,myBluest,,2023-10-29 12:36:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17j20ze/speaker_identification_model/,Speaker identification model?,"I'm working on a prj it's a big one ( in terms of grades) but all I want is to survive n live through it
The prj t is a voice-based identification with ASR model which hopefully will produce a robust authentication system

However I'm supposed to choose an appropriate Speaker identification model in two das and l'm very lost ... I don't have enough time to research and I'm not familiar with the subiect I can't even name a single model rn!

For the ASR model I'm using whisper.
What is a proper speaker identification model | can use in this system? One that is easy to implement later on when I'Il have to. I can't judge without doing an extensive research and I'm not given anytime to do that...

l'm clueless so l appreciate ANY info or guidance in this topic I'm beyond stressed out so please every bit of help is greatly appreciated",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17j20ze/speaker_identification_model/,3,5,0.86,"[Comment(id='k719kx0'), Comment(id='k729dxf'), Comment(id='k74bmtu')]"
17ixqt3,69casual_dreamer96,,2023-10-29 07:31:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ixqt3/need_a_friend_interested_people_please_read/,"Need a friend, interested people please read through"," Hi clan, I am a data analyst and currently pursuing a distance masters program in data science and machine learning. But unfortunately, I have never been a classroom learner, and always fail miserably while following classroom teaching. Although I found out, what keeps me enticed is project based learning where , by building new stuff, I learn new things.

But being a distance learner, it gets pretty hard to stay motivated and work on projects solo. Recently I came up with concept of 42 school, France, where a group of like-minded people would work on projects together and learn along the way in a hands-on approach. Long term, I think I would like to build a peer based learning community in data science, where students would learn from each other instead of sticking to any fixed curriculum being delivered by any teacher per se.

But , ideas can be wild, so before building this community , I want to test this approach on myself to see if I can learn in a similar way first. For that, I would need a partner (or two, or three, the more the merrier I guess) to start on this journey.

What the other person would get from this are -

1. An accountability partner.
2. Peer based complimentary learning. ( where we can explain and teach topics to each other)
3. A group to participate in hackathons and do projects together.
4. And last but not the least, some friends, who are on the same path.

If you have any questions for me, please feel free to reply to this thread, I will try my best to answer them. If you are interested in this experiment and want to join, either you can dm me, or can leave a reply to this thread.

P.S: Please don\`t think me as a fake/bot profile due to my low karma, I am mostly a silent browser of reddit and haven\`t been active in periods in between.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ixqt3/need_a_friend_interested_people_please_read/,58,10,0.75,"[Comment(id='k6y2k1j'), Comment(id='k6zj5g0'), Comment(id='k6xds6f'), Comment(id='k6xlb6o'), Comment(id='k6za1nd'), Comment(id='k6zf799'), Comment(id='k7k3s9x'), Comment(id='k7mocio'), Comment(id='k6xvckb'), Comment(id='k6yh3eu'), Comment(id='k6yjuds'), Comment(id='k6yocyk'), Comment(id='k6ysuzz'), Comment(id='k6yzxhz'), Comment(id='k6z710v'), Comment(id='k6zmtt5'), Comment(id='k6zrziy'), Comment(id='k703711'), Comment(id='k706dlc'), Comment(id='k70goph'), Comment(id='k70m1p6'), Comment(id='k70qx1h'), Comment(id='k715frk'), Comment(id='k71mu1k'), Comment(id='k737kfy'), Comment(id='k73mhlw'), Comment(id='k6yentj'), Comment(id='k7k4g6k'), Comment(id='k6xg881'), Comment(id='k6yf1iq'), Comment(id='k7rahl8'), Comment(id='k7rahz9'), Comment(id='k6yf3le'), Comment(id='k7raihh'), Comment(id='k7raiyi'), Comment(id='k7raj7l'), Comment(id='k7rajfx'), Comment(id='k7rajro'), Comment(id='k7rajy6'), Comment(id='k7rak5q'), Comment(id='k7rakda'), Comment(id='k7rakm1'), Comment(id='k7raksy'), Comment(id='k7ral66'), Comment(id='k7ralku'), Comment(id='k7raltr'), Comment(id='k7ram3w'), Comment(id='k7ramc2'), Comment(id='k7ramll'), Comment(id='k7ramu3'), Comment(id='k7ran4i'), Comment(id='k7n4lh9'), Comment(id='k7ragi8'), Comment(id='k6yq0c6'), Comment(id='k7k10rr'), Comment(id='k7k4ocr'), Comment(id='k7rah8v')]"
17jaxku,Hot-Yogurtcloset-945,,2023-10-29 19:47:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jaxku/why_are_all_of_my_relus_dying/,Why are all of my relus dying?,"Hi,

I'm trying to train a model to solve a toy problem.

(Not sure that it really matters, but, specifically, I have a length ~2000 input v and the problem is to classify it by which is biggest: the sum of the first ~500 entries, the sum of the next 500, the sum of the third 500, or the sum of the last 500.  I have a length 4 output that I apply softmax to, so really all the network has to learn is to take sums of four subsets of the input.  the reason I'm doing this is because I have a more complicated categorization problem and I wanted to validate my training setup end to end before I start with more complicated problems / architectures.)

I'm using Relu activations and if I use the most obvious architecture - just a width 1600 input layer and a fully connected width 4 output layer - it works fine.  But when I make a deeper dense network (say, depth 4) the training fails - the relus all die.  This doesn't happen in the most straightforward way (all negative weights on the first layer) but rather by more complicated patterns of negative and positive weights that combine to ultimately get to negative at some point in the network.  I should mention, the inputs are always positive in my dataset.

I have a couple questions:

1. Is this basically to be expected?  Is this a reason that nobody uses stacked dense layers in practice (afaik)?

2. How should I think about debugging an issue like this?  Of course I can simply move to a transformer architecture or something, but I'm trying to understand how ML researchers iterate when they are coming up with these things in the first place.

Any links to good resources are super appreciated!  Obviously I've spent some time searching and haven't found anything that helped.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jaxku/why_are_all_of_my_relus_dying/,4,1,0.67,"[Comment(id='k707c7l'), Comment(id='k70tk6v'), Comment(id='k73oy76'), Comment(id='k73tn7u')]"
17jascl,Salty-Dare-4821,,2023-10-29 19:41:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17jascl/how_do_you_modify_vision_architectures_to_work/,how do you modify vision architectures to work with cifar10, i want to modify some architectures that were designed for imagenet size images (224 x 224) to work with cifar10 (32 x 32). what's the general approach to modifying an architecture to work with a different sized input? I want to train from scratch instead of finetuning. some specific models i'm interested in are mobilenetv2 and shufflenet. i'm just struggling to figure out how to approach this task. ,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17jascl/how_do_you_modify_vision_architectures_to_work/,3,1,1.0,"[Comment(id='k70e1br'), Comment(id='k70hqly'), Comment(id='k714z6t')]"
17j2g3z,bohemianLife1,,2023-10-29 13:01:12+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17j2g3z/article_autogen_simple_and_powerful_framework_to/,"Article: Autogen, simple and powerful framework to build LLM",,learnmachinelearning,https://beginai.co/autogen-build-next-gen-llm-applications/,0,3,0.8,[]
17izao2,qhelspil,,2023-10-29 09:29:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17izao2/part_2_random_forests_vs_decision_trees/,part 2: random forests vs decision trees,"when i asked why decision trees are prone to overfitting i got [this answer](https://www.reddit.com/r/learnmachinelearning/comments/17ilp4p/comment/k6wnhny/?utm_source=share&utm_medium=web2x&context=3)

which says:  A DT will overfit if it is left to grow without constraints on the training data. To overcome that, you have max\_depth, min sample split, min sample leaf etc parameters to regularise the model. 

my question, if i made a random forest without tuning the max\_depth, doesnt this makes it as bad as decision tree?

from the [documentaion](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) max\_depth is set to none for random forests, so if i tuned the max\_depth of decison tree, it performs as the random forest.

no ?

thanks for help",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17izao2/part_2_random_forests_vs_decision_trees/,2,3,0.71,"[Comment(id='k6yxpao'), Comment(id='k6y9j20')]"
17j4cu0,Sad_Kaleidoscope3286,,2023-10-29 14:42:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17j4cu0/would_you_know_a_simple_howto_for_installing/,would you know a simple how-to for installing huggingface and chatUI (HF) on a Ubuntu server?,"Hi all, I start being quite desperate as I try to install huggingface alongside with chatui. It really seems to be what I need to run models and being able to use a web chat ui locally. I don't want to use Spaces offered with Huggingface, I need models to run locally.

But here the fun starts, all how-tos I find are either missing steps, or are simply not working with my environment (or most likely I don't succeed to make it work in my env.). Knowing that I'm quite a Linux server rookie (+not a dev by design), I probably miss some steps in the processes that a regular dev would do naturally.

In anyway, I could do several things:

* clone huggingface\_hub repo
* clone/install transformers
   * Not sure either HF or transformers installed correctly
* create virtual environments (one of which has chat ui - followed the github instruct)
* downloaded model(s) - not sure they are well located.

All that sometimes in a same directory file as I read different ways to proceed, so tested and tested it again.

Most likely I now need to restart from scratch because that became a mess. Would you have a proper how-to from scratch to first promp to install huggingface with a webchat UI (hugging chat ui or else) through ssh command on a Ubuntu Linux server?

I haven't found any but eager to test any existing link of course, I could find one but I would be surprised it doesn't exist.

*Nb. seems we can SSH directly from HF site (or reversly I'm not sure) - but open to do it if that's simpler.*",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17j4cu0/would_you_know_a_simple_howto_for_installing/,0,1,1.0,[]
17iw7ib,Maverick_5112,,2023-10-29 05:35:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iw7ib/courses_on_generative_ai/,Courses on Generative AI,I would like to know your favourite course(s) on Generative AI that influenced you a lot. Help a newbie here please. No restriction on languages....,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iw7ib/courses_on_generative_ai/,0,4,0.83,[]
17iyq4w,buffering_humor,,2023-10-29 08:46:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iyq4w/which_tts_software_should_i_use/,Which TTS software should I use?,"This post is to ask for help regarding a personal project of mine.

So as a heads up, I'm very new to Machine Learning. I mostly a engaged in development stuff. But recently I took on a project where I have to convert text to lip-synced video file.

I need to first generate a WAV file from text. For that, Im looking for  a TTS software. I just want a somewhat human-like voice for my project so I am not looking for a very high-quality voice.

I tried to use Tortoise TTS but I failed during the installation process and I can't find a good enough tutorial I can follow. Also, it seems Tortoise and many other AI tools work with a NVIDIA GPU which I don't have (I got a system with AMD integrated graphics). So does anyone have a tutorial or suggestion how to install tortoise?

Or do you have any suggestion for any other TTS to use?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iyq4w/which_tts_software_should_i_use/,1,2,0.75,[Comment(id='k6xrrhu')]
17j1v8b,OnlyProggingForFun,,2023-10-29 12:27:11+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17j1v8b/master_llms_top_strategies_to_evaluate_llm/,Master LLMs: Top Strategies to Evaluate LLM Performance,,learnmachinelearning,https://youtu.be/iWlTCBUoru8,0,0,0.5,[]
17irzkc,blackpanther28,,2023-10-29 01:13:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17irzkc/why_do_we_use_view_and_then_transpose_when/,Why do we use .view() and then .transpose() when reshaping our query/key/value tensors in Multi-Head Attention?,"I've seen the following PyTorch code for reshaping the Q,K,V matrices into its heads:

`x = x.view(x.shape[1], x.shape[1], self.h, self.d_k).transpose(1,2)`

My question is why do we need the intermediary 4D tensor of shape (batch, sequence\_length, head, dk) which we then turn into (batch, head, sequence\_length, dk)? Why can't we just directly go to the final result using something like the following:

`x = x.view(x.shape[0], self.h, x.shape[1], self.d_k)`",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17irzkc/why_do_we_use_view_and_then_transpose_when/,5,7,0.89,"[Comment(id='k6xki5f'), Comment(id='k6x4ffk'), Comment(id='k6x5aej'), Comment(id='k6y3lxj'), Comment(id='k6xsyrb')]"
17j1378,theufitapp,,2023-10-29 11:37:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17j1378/how_to_get_started_with_nlp_for_seo/,How to get started with NLP for SEO,"Hey everyone, I'm a freelance full-stack web developer who's recently gotten into SEO, specifically interested in the programmatic SEO. 

I've got this idea to build a tool kinda like SurferSEO, and another one that scans my WordPress posts for internal linking opportunities, similar to what Link Whisper WP plugin does.

Anyone got a list or roadmap of just the essential topics I should learn to build the backend for these tools? I'm not looking for a full-fledged career in this, so I just wanna focus on what's absolutely necessary for these projects.

I've also found these resources, but honestly, I'm not sure if they're any good for this:

[https://tjzhifei.github.io/resources/NLTK.pdf](https://tjzhifei.github.io/resources/NLTK.pdf)

[https://www.amazon.in/Data-Driven-SEO-Python-Challenges-Science/dp/1484291743](https://www.amazon.in/Data-Driven-SEO-Python-Challenges-Science/dp/1484291743)

&#x200B;

In case you don't know what these tools do -

**SurferSEO**: For a given keyword, analyzes on-page SEO by comparing your page with top-ranking pages in SERP (Search Engine Results Pages), using algorithms like TF-IDF for keyword recommendations.

**Link Whisper**: A WordPress plugin that scans your posts for internal linking opportunities.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17j1378/how_to_get_started_with_nlp_for_seo/,0,0,0.5,[]
17izd8b,SatanistYogi,,2023-10-29 09:34:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17izd8b/idea_for_body_movement_tracking_app_but_what_tech/,"Idea for body movement tracking app, but what tech to use","I would like to follow human body movement with the mobile phones camera, and then analyse its movement paths. First though was to use tensorflow, but would there be some other way to go?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17izd8b/idea_for_body_movement_tracking_app_but_what_tech/,1,0,0.5,[Comment(id='k6xrkof')]
17iyg1m,JClub,,2023-10-29 08:24:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17iyg1m/transformers_kv_caching_explained/,Transformers KV Caching Explained,,learnmachinelearning,https://medium.com/@joaolages/kv-caching-explained-276520203249,0,0,0.5,[]
17iyft4,JClub,,2023-10-29 08:24:21+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17iyft4/transformers_positional_encodings_explained/,Transformers Positional Encodings Explained,,learnmachinelearning,https://medium.com/@joaolages/the-quest-to-have-endless-conversations-with-llama-and-chatgpt-%EF%B8%8F-81360b9b34b2,0,0,0.5,[]
17iuftq,Tyron_Slothrop,,2023-10-29 03:35:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iuftq/applying_for_data_analyst_position_ml/,Applying for Data Analyst position. ML?,"I've been a data analyst for close to 5 years at two separate companies. However, I've recently been laid off (ugh). Through my two previous jobs, I've learned a lot about data analytics using Python and SQL and have built a few simple Python scripts to automate some of the tedium of said jobs. However, my real passion is ML, but I don't have the educational background to really be an ML engineer or a Data Scientist. My github is full of ML projects I've worked on, in addition to data visualization and SQL. Should I just show data visualization, Python, and SQL and remove the ML portion? I feel like they will see that an think I'm looking for an ML job. I would think the ML projects would show I'm adept with applied statistics, but not entirely sure how it would come off. Advice? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iuftq/applying_for_data_analyst_position_ml/,3,2,0.67,"[Comment(id='k6wwryr'), Comment(id='k6x6l1d'), Comment(id='k70yj3r')]"
17iu82k,Glittering-Target-87,,2023-10-29 03:22:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iu82k/i_have_an_amd_graphics_card/,I have an AMD graphics card,So I got an AMD Graphics card and I've been doing some machine learning. How do I use my gpu for machine learning? my programs seemed to be working fine if you guys could help me that'd be awesome or tell me where to learn to use my amd gpu. I was told my gpu could still be used for ml,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iu82k/i_have_an_amd_graphics_card/,14,2,0.75,"[Comment(id='k6y2sn4'), Comment(id='k6xi741'), Comment(id='k6yaz7u'), Comment(id='k6yvevq'), Comment(id='k6y3ccm'), Comment(id='k6xkjgj'), Comment(id='k6yly2o'), Comment(id='k6ywlv0'), Comment(id='k6ycwvu'), Comment(id='k6xo6cq'), Comment(id='k6ymgvg'), Comment(id='k6yhy4w'), Comment(id='k6yt27y'), Comment(id='k6zwe5h')]"
17imesb,plutoandmal,,2023-10-28 20:32:10+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17imesb/geometric_data_analysis_explained/,Geometric Data Analysis Explained,,learnmachinelearning,https://youtu.be/rKqvSVkxCP4?si=IIK9NzSYmj5pPoS3,1,5,0.86,[Comment(id='k6v90g3')]
17ilp4p,qhelspil,,2023-10-28 19:57:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ilp4p/decision_trees_vs_forests/,decision trees vs forests,"\- please someon explain to me why decision trees are prone to overfitting more then other models

\- about random forests :  Because of parallel learning, if one decision tree makes a mistake, the whole random forest model will make that mistake.  

since it used paralel learnig, it does not use other decision tree to learn the best features.

how is one decision tree mistake effecting the whole random forest, shouldnt a decison tree error only effect the decision tree being built ?

thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ilp4p/decision_trees_vs_forests/,5,4,0.84,"[Comment(id='k6wnhny'), Comment(id='k6zf8q0'), Comment(id='k6wmkis'), Comment(id='k6zkbu6'), Comment(id='k6wmn59')]"
17iuo0i,needtherapynownthen,,2023-10-29 03:49:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iuo0i/offline_ml_courses_india/,Offline ML courses India,"Hey does anyone know any good offline courses for Machine Learning? Preferred location: Bangalore, Kochi, Chennai, Pune

(Also let me know if you're looking for a learning buddy.)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iuo0i/offline_ml_courses_india/,0,1,0.67,[]
17igmcm,FallMindless3563,,2023-10-28 15:51:35+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17igmcm/arxiv_dives_how_lora_finetuning_works/,Arxiv Dives - How LoRA fine-tuning works,,learnmachinelearning,https://blog.oxen.ai/arxiv-dives-how-lora-fine-tuning-works/,0,6,0.81,[]
17inql8,Tibbs007,,2023-10-28 21:35:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17inql8/advise_needed_please/,Advise needed please,"Hi All,

I would like some insight into learning AI and machine learning.

Bit of a background. I am almost 36 years old. I did an electrical engineering degree nearly 15 years ago. I moved to the UK almost 12 years ago and have worked in accounting ever since.

In my early school and college years, I learned coding HTML, CSS, and PHP to build websites and earned some pocket money. I loved learning to code and never got bored of it. I fell off shortly after joining college, thinking that if I didn\`t have a relevant degree in IT, I would not be able to pursue my career in IT.

I have done some research and established that for AI and machine learning, I need to have maths knowledge, which I am fine with as I have studied math and physics in my engineering days but probably will have to relearn as it was a long time ago.

I would be grateful if anyone could advise me if I stand any chance of switching from the accounting field. I am still very passionate about coding, AI, and machine learning, and I believe I can do well.

Many Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17inql8/advise_needed_please/,3,1,0.57,"[Comment(id='k6x7w2z'), Comment(id='k6vkzuc'), Comment(id='k6vn8k9')]"
17ijx9t,LoftyHyphen,,2023-10-28 18:31:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ijx9t/what_database_should_i_use/,What database should I use?,"I want to create back-end that would predict users preferences.
I thought that maybe matrix factorization (collaborative filtering) could be the best option.
Do you have a recommended database (e.g. MongoDB, PostgreSQL and Pgvector, etc.) and an algorithm (from HuggingFace for example) I could use? 
Thank you in advance🙂",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ijx9t/what_database_should_i_use/,4,3,1.0,"[Comment(id='k6uuqdu'), Comment(id='k6uw8et'), Comment(id='k6v0ot0'), Comment(id='k6v1ah0')]"
17ihsdf,Fine_Sale7051,,2023-10-28 16:47:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ihsdf/transformer_encoder_for_multivariate_series/,Transformer Encoder for multivariate series,"Hello everyone. I'm trying to implement this really nice paper ([https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=3554486](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3554486)).

The problem is that I'm a beginner and arleady struggling at the first step. The paper mentions a Sequence Representation Extraction Module (SREM) that is a Transformer Encoder that represents and extracts information and path dependence from the input time series, that consists of stock's historical states (firms' fundametals, stock's data...). Now, I can't really understand how to feed the time series into the encoder. I mean, I understand how a Transformer works for sentences: words must be embedded so that the computer can ""read"" them (right?) but why should we embed data that is already numeric. At the same time, embedding is mandatory since we need to compute Positional Encoding. Multi Head Attention should be easy once the data is embedded, but I can't really manage how to prepare the data correctly.So how does that work? I've been looking for days but found nothing really helpful.

If you'd like to help, SREM is represented in page 16 and Appendix C at the end of the paper.   
Thanks a lot and sorry if this will turn out to be a stupid question...",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ihsdf/transformer_encoder_for_multivariate_series/,0,4,1.0,[]
17iqavg,Glittering-Target-87,,2023-10-28 23:42:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iqavg/amd_gpu_help/,Amd gpu help!,I have an amd 6600 it was cheaper than nvidia. Does this mean I can't train any deep learning models or take a longer time. What are the draw backs going to be?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iqavg/amd_gpu_help/,0,1,1.0,[]
17i63ft,hawk-bull,,2023-10-28 04:36:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17i63ft/did_cs_and_math_but_no_ai_where_do_i_start/,"Did CS and Math, but no AI. where do I start?","This question's probably been asked to death, but I'm just gonna ask it again. For some context, I recently completed my undergrad in CS and Math, but sadly didn't touch any AI (was too fascinated by math stuff and cs theory stuff that I neglected this field).  


Now I wanna get into it, but there's so many resources, and so many fields in AI, that I don't know what my roadmap is. My friend told me I can skip ISLR and go straight to ESLR as my math is decent enough for it, but after that I don't know what to do. Would love your suggestions and resources. Textbooks, and courses, whatever you think is a good roadmap.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17i63ft/did_cs_and_math_but_no_ai_where_do_i_start/,9,30,0.91,"[Comment(id='k6s4kq9'), Comment(id='k6slja0'), Comment(id='k6uiil8'), Comment(id='k6y708n'), Comment(id='k6sdsnr'), Comment(id='k6s8sc0'), Comment(id='k6w0gc4'), Comment(id='k6s9hh4'), Comment(id='k6sqxd3')]"
17ijull,spaceinter92,,2023-10-28 18:28:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ijull/can_you_explain_to_me_how_to_improve_my_project/,Can you explain to me how to improve my project? (new to machine learning),"Hi,

so   I'm new to machine learning, I did a project to predict the prices of a   house or appartment (rent or sale) and I wanted to know what I could   have done to improve my model? :D

here is the github repo:  
[https://github.com/bovealexandre/immo-eliza-train-test-alexandre/tree/Dev](https://github.com/bovealexandre/immo-eliza-train-test-alexandre/tree/Dev)

Thank you a lot in advance",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ijull/can_you_explain_to_me_how_to_improve_my_project/,1,2,0.75,[Comment(id='k6xvgfu')]
17intqr,Neurosymbolic,,2023-10-28 21:39:55+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17intqr/thinking_fast_and_thinking_slow_system_1_and/,Thinking Fast and Thinking Slow: System 1 and System 2,,learnmachinelearning,https://youtube.com/watch?v=ALQpD0zh2TY&si=5hXqNDLDNLTLaAn7,0,0,0.5,[]
17imvjz,vtimevlessv,,2023-10-28 20:55:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17imvjz/why_does_my_rnn_fail_at_predicting_the_next_value/,Why does my RNN fail at predicting the next value out of a simple sequence?,"My goal is to better understand artificial neural networks. Currently, I am looking at recurrent neural networks. I have picked a simple problem that I want to solve with such a network.

The task is to predict a linear increment. The model should learn that the next value follows a sequence of numbers. The structure of my data looks like this after randomization: [[1,2,3] [4]], [138,139,140] [141]], etc.

I have used a total of 3,000 training and test data. I used 90% of it for training the network.

After experimenting, I ended up with the following architecture:
- RNN(5) with ReLu
- RNN(5) with ReLu
- Dense(1)

The prediction works for all areas between 1 and 3,000, both for the training and the test data, with an accuracy of 100%.

However, the model does not work for data that falls outside this range, for example predicting the number 1,000,000.

My question is if anyone has an idea why this could be the case. Obviously, an RNN should be able to approximate a straight line. I don't understand exactly why it's not working.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17imvjz/why_does_my_rnn_fail_at_predicting_the_next_value/,17,1,0.67,"[Comment(id='k6vkzv2'), Comment(id='k6vmzu2'), Comment(id='k6vn5dr'), Comment(id='k6vn9wq'), Comment(id='k6w98t4'), Comment(id='k6vp8jm'), Comment(id='k6xbw2n'), Comment(id='k6vrtm7'), Comment(id='k6xnb4l'), Comment(id='k6vyeqz'), Comment(id='k6wh5yf'), Comment(id='k6xodic'), Comment(id='k6w15bi'), Comment(id='k6xow24'), Comment(id='k6yl5rv'), Comment(id='k6xqifn'), Comment(id='k6xqxd3')]"
17i5tqn,mr-minion,,2023-10-28 04:18:47+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17i5tqn/linear_algebra_for_machine_learning_with/,Linear Algebra for Machine Learning (with animations),,learnmachinelearning,https://www.youtube.com/playlist?list=PL5VO4MoudfRpnGL7TH7RPfEZ-ey3NFafv,6,21,0.86,"[Comment(id='k6s7qn2'), Comment(id='k6ssvh6'), Comment(id='k6tmihq'), Comment(id='k6tx4yy'), Comment(id='k6ym673')]"
17ieq6k,Zwznh1469,,2023-10-28 14:17:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ieq6k/tutorialguides_for_dummies100_beginner_on_coding/,Tutorial/guides for dummies/100% beginner on coding an image classification program using vgg19 arch for sweet potato grading,"hi I have literal 0 knowledge on programming and coding with vgg19 cnn (training, preprocessing and testing) using tensorflow/google colab and having a really hard time on our research “Real-time Sweet Potato Grading using VGG19 CNN”. Can I kindly ask for similar projects/programs done with this researches to help me. Do you have any idea on what I should  use or do or read. Your responses would be greatly helpful thank you very much.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ieq6k/tutorialguides_for_dummies100_beginner_on_coding/,2,3,1.0,"[Comment(id='k6v4oyi'), Comment(id='k6w4nkg')]"
17i99av,pg860,,2023-10-28 08:23:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17i99av/why_gbdts_are_not_mentioned_in_job_descriptions/,Why GBDTs are not mentioned in job descriptions?," GBDT allow you to iterate very fast, they require practically no data preprocessing, enable you to incorporate business heuristics directly as features, and immediately show if there is explanatory power in features in relation to the target.

On tabular data problems, they outperform Neural Networks, and many use cases in the industry have tabular datasets.

Because of those characteristics, [they are winning solutions to all tabular competitions on Kaggle](https://jobs-in-data.com/blog/data-science-skills#sota-ml-models)

And yet, somehow they are not very popular.

On the chart below, I summarized learnings from 9,261 job descriptions crawled from 1605 companies in Jun-Sep 2023 (source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist))

LGBM, XGboost, Catboost (combined together) are the 19th mentioned skill, e.g. with Tensorflow being x10 more popular.

It seems to me Neural Networks caught the attention of everyone, because of the deep-learning hype, which is justified for image, text, or speech data, but not justified for tabular data, which still represents many use - cases.

Granted, there is for sure some noise in the data generation process of writing job descriptions - some people writing them may not know the exact scope of the role.

But why do those random people know so much more about deep learning, keras, tensorflow, pytorch than GBDT? In other words, why is there a systematic trend in the noise? When the noise has a trend, it ceases to be noise.

https://preview.redd.it/ohef6ocukwwb1.png?width=2560&format=png&auto=webp&s=7c2e0321deb0a9491db09668c94c34d510e77c05

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17i99av/why_gbdts_are_not_mentioned_in_job_descriptions/,5,7,0.69,"[Comment(id='k6sxgjv'), Comment(id='k6spomy'), Comment(id='k6sqkbb'), Comment(id='k6thrg0'), Comment(id='k6tq792')]"
17iklmb,Illustrious-Class-65,,2023-10-28 19:04:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iklmb/what_are_the_best_courses_on_youtube_or_udemy/,What are the best courses on YouTube or Udemy that cover Probability and Statistics?,"
Recently I started to going through university courses on math: linear algebra, calculus. I have found great courses on LinAl 1,2,3 and Calculus 1,2,3, but I could not find something similar for Probability and Statistics. I am interested in deep courses with proofs. Could you please recommend me something?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iklmb/what_are_the_best_courses_on_youtube_or_udemy/,2,0,0.5,"[Comment(id='k6vnd75'), Comment(id='k6xg1n1')]"
17ikkto,No-Key-3065,,2023-10-28 19:02:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ikkto/deployment_of_python_chatbot_on_an_android_app/,Deployment of python chatbot on an android app,"Hi, I have made an app using flutter and I want to deploy a chatbot on it. Will anyone guide me on how to deploy python chatbot on the flutter app or if it is possible. Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ikkto/deployment_of_python_chatbot_on_an_android_app/,0,1,1.0,[]
17i7pq0,poiu97188,,2023-10-28 06:29:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17i7pq0/is_santiago_valdarramas_ml_school_course_worth/,Is Santiago Valdarrama's ML School course worth joining?,He teaches production ML. Anyone enrolled in his course? If yes then can you pls share your opinion.🙏,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17i7pq0/is_santiago_valdarramas_ml_school_course_worth/,0,10,1.0,[]
17iic5n,mateen_9,,2023-10-28 17:15:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iic5n/use_ml_to_estimate_a_companys_top_line_revenue/,Use ML to Estimate a Company’s Top Line (Revenue) Growth,"Hi, I am looking to incorporate ML in Finance by applying an ML model to estimate a company’s sales growth rate for the next 3-5 years based historical data, the current market sentiment and various other relevant factors. The main goal to estimate the sales growth rate is to use it to perform a Discounted Cash Flow valuation on a company which requires us to input a sales growth estimate for the next 5 years. The main problem is the availability of the data as the companies release such data every quarter and therefore we have only 4 instances for each year. 

Any ideas on how I could do this using ML or even LLM’s or sentiment analysis? I am not very experienced with ML and LLM’s yet but would be very interested in any leads.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iic5n/use_ml_to_estimate_a_companys_top_line_revenue/,1,1,1.0,[Comment(id='k6xfq6h')]
17ih1ga,Divine_Invictus,,2023-10-28 16:11:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ih1ga/help_debugging_a_cnn_gan/,Help Debugging a CNN GAN,"I've been learning machine learning and I stumbled across GANs. This project has been about representing text in an image format and using a GAN to generate it. The model runs without errors, but no matter what I do the loss is somehow 0 and it keeps returning the same thing over and over again. I tried two different architectures so I'm pretty sure my data preprocessing is the issue but I cant seem to find out whats wrong with it.

One idea I had is that I might need to find a way to get the normalized vectors in between 0 and 1 in my preprocess function but I tried it and it didn't seem to do anything.

I would appreciate any help with this. Links to the google collabs below.

[Version 1](https://colab.research.google.com/drive/1yWaXLyKKmz-UZGavW1h8m8OZqYx5R6Re#scrollTo=-gNZwljuJuZ8)

[Version 2](https://colab.research.google.com/drive/1yWaXLyKKmz-UZGavW1h8m8OZqYx5R6Re#scrollTo=-gNZwljuJuZ8)

Note: I didn't design the actual models only the preprocess function. You can replace my text file with any sufficiently large text file if you want to try it. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ih1ga/help_debugging_a_cnn_gan/,2,1,1.0,"[Comment(id='k6yozxy'), Comment(id='k7g8q1v')]"
17igpi9,delulu-duck,,2023-10-28 15:55:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17igpi9/urgent_help_needed_regarding_inltk_p/,Urgent help needed regarding inltk [P]," Hello i m using iNLTK ( Natural Language Toolkit for Indic Languag ) for my nlp mini project ""paraphrase detection in hindi text"" but I m getting this code error if anyone can help me solving it would be great. Thank you in advance.

here is the code for the error section.

from inltk.inltk import get\_sentence\_similarityfrom sklearn.metrics.pairwise import cosine\_similarityget\_sentence\_similarity(text, 3, 'hi', cmp = cosine\_similarity)

I googled there are solution saying to install pytorch version 1.3.0 but when I try to install it's saying not available.

!pip install torch==1.3.1+cpu -f [https://download.pytorch.org/whl/torch\_stable.html](https://download.pytorch.org/whl/torch_stable.html).

error :

Looking in links: [https://download.pytorch.org/whl/torch\_stable.html](https://download.pytorch.org/whl/torch_stable.html). ERROR: Could not find a version that satisfies the requirement torch==1.3.1+cpu (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0) ERROR: No matching distribution found for torch==1.3.1+cpu",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17igpi9/urgent_help_needed_regarding_inltk_p/,0,1,1.0,[]
17ig9ap,fieryraidenX,,2023-10-28 15:34:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ig9ap/taking_a_frame_and_extrapolating_it_to_a_video/,Taking a frame and extrapolating it to a video?,"I’ve seen videos of this being done before, and I’m trying to make a project that does something like this. But from what I’ve seen or understood, traditional RNNs require the dimensions of the input and output to be the same size (I’m using 3D Conv layers). Is there another method I could approach this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ig9ap/taking_a_frame_and_extrapolating_it_to_a_video/,0,1,1.0,[]
17iewu3,phobrain,,2023-10-28 14:27:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17iewu3/which_pretrained_image_classification_models_have/,Which pretrained image classification models have the smallest feature vector size?,I'm hoping for a vector size <= 16000 (for pgvector).,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17iewu3/which_pretrained_image_classification_models_have/,2,1,1.0,"[Comment(id='k7c7z92'), Comment(id='k7s7dcl')]"
17i61fb,farhanleo,,2023-10-28 04:32:57+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17i61fb/i_created_a_machine_learning_roadmap_for_beginners/,I created a machine learning roadmap for beginners,,learnmachinelearning,https://schoolofmachinelearning.com/2023/10/27/top-machine-learning-certificates-for-2024-ml-roadmap/,1,4,0.83,[Comment(id='k6t9hl4')]
17i5pl1,VeterinarianOk6507,,2023-10-28 04:11:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17i5pl1/trying_to_make_a_multi_class_cnn_to_classify/,Trying to make a multi class cnn to classify lesions but it’s not working well,"So I’m trying to make a cnn net that classifies different types of lesions. But right now I’m don’t know what I’m doing wrong with the validation test loop where the accuracy rate stay at 0.005 constant during the val-loop. I tried to plot a confusion matrix as well but it [looks](https://ibb.co/N1Dr62w) really odd. Here is my [training loop](https://pastebin.com/FjiMD1i0), [model](https://pastebin.com/QVkTpJXs),  [custom dataset](https://pastebin.com/vaVqGwQ9) and [main](https://pastebin.com/mz2htTf9) driving code

The odd thing is that the train loop works fine and the model was able to achieved around 70-80% percent during training but fumbled at val loop. It would be great if I can have some guidance right now, thank you very much",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17i5pl1/trying_to_make_a_multi_class_cnn_to_classify/,0,2,1.0,[]
17hle2u,Botanical0149,,2023-10-27 11:26:13+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hle2u/what_am_i_doing_wrong_in_this_nn_its_supposed_to/,What am I doing wrong in this NN? It's supposed to binarily classify text,,learnmachinelearning,https://i.redd.it/tz0u7b9scqwb1.png,22,24,0.88,"[Comment(id='k6ohfwh'), Comment(id='k6o7vue'), Comment(id='k6ogee6'), Comment(id='k6ouh0o'), Comment(id='k6o5ire'), Comment(id='k6ockzk'), Comment(id='k6o9n7n'), Comment(id='k6pmc3i'), Comment(id='k6ryw9u'), Comment(id='k6sac4x'), Comment(id='k6ylwwy'), Comment(id='k6oq30k'), Comment(id='k6o943q'), Comment(id='k6rllmk'), Comment(id='k6obksa'), Comment(id='k6ox6ey'), Comment(id='k6oyeg6'), Comment(id='k6u0eya'), Comment(id='k6ocyng'), Comment(id='k6u1jvx'), Comment(id='k6u3p55'), Comment(id='k6u6rk2')]"
17hrzxh,Monadical3,,2023-10-27 16:53:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hrzxh/live_now_learn_how_we_brought_the_minecraft_ai/,Live Now: Learn How We Brought the Minecraft AI Skins Generator to Life! https://monadical.com/posts/mincraft-skin-generation.html,,learnmachinelearning,https://i.redd.it/vmdw5e08zrwb1.gif,0,8,0.91,[]
17ha8e5,Pfacejones,,2023-10-26 23:47:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ha8e5/i_for_life_of_me_cannot_understand_transformers/,I for life of me cannot understand transformers,What are some good resources to learn,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ha8e5/i_for_life_of_me_cannot_understand_transformers/,39,162,0.97,"[Comment(id='k6m9jre'), Comment(id='k6mnhax'), Comment(id='k6n5pz8'), Comment(id='k6m2o1j'), Comment(id='k6nigwe'), Comment(id='k6owizd'), Comment(id='k6nf9w6'), Comment(id='k6nx9al'), Comment(id='k6nku6o'), Comment(id='k6mrcdc'), Comment(id='k6pink9'), Comment(id='k6nwln8'), Comment(id='k6os9yl'), Comment(id='k6nj49m'), Comment(id='k6o44kg'), Comment(id='k6pvrft'), Comment(id='k6q3w07'), Comment(id='k6q6ss7'), Comment(id='k6r0iwu'), Comment(id='k6oszao'), Comment(id='k6nj6yx'), Comment(id='k6n7vcf'), Comment(id='k6nazw7'), Comment(id='k6nljqv'), Comment(id='k6qe3fd'), Comment(id='k6mjtvo'), Comment(id='k6oytsx'), Comment(id='k6p8m56'), Comment(id='k6pwx9h'), Comment(id='k6p6nyl'), Comment(id='k6p325x'), Comment(id='k6rdgkv'), Comment(id='k6pbm91'), Comment(id='k6ot6jq'), Comment(id='k6nj7n9'), Comment(id='k6s5k23'), Comment(id='k6yl2ig'), Comment(id='k6yl7ns')]"
17hq43c,AvvYaa,,2023-10-27 15:28:35+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hq43c/neural_attention_explained_from_first_principles/,Neural Attention explained from first principles!,,learnmachinelearning,https://youtu.be/frosrL1CEhw?si=NKTqmRTieVkfCNlb,0,8,1.0,[]
17hsq6l,modelbit,,2023-10-27 17:26:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hsq6l/how_to_deploy_a_resnet50_image_classification/,How to deploy a ResNet-50 image classification model to a REST Endpoint,"We wrote up a tutorial on how to deploy a ResNet-50 model to a production endpoint directly from a data science notebook (or any Python environment).

**Link to Colab:** [https://colab.research.google.com/github/write-with-neurl/modelbit-articles/blob/main/modelbit-03/code/Deploy\_RESNET\_50\_Model\_With\_Modelbit.ipynb#scrollTo=NUoW-\_9PTwFJ](https://colab.research.google.com/github/write-with-neurl/modelbit-articles/blob/main/modelbit-03/code/Deploy_RESNET_50_Model_With_Modelbit.ipynb#scrollTo=NUoW-_9PTwFJ)  
**Link to tutorial:** [https://www.modelbit.com/blog/deploying-a-resnet-50-image-classification-model-to-a-rest-api-endpoint-with-modelbit](https://www.modelbit.com/blog/deploying-a-resnet-50-image-classification-model-to-a-rest-api-endpoint-with-modelbit)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hsq6l/how_to_deploy_a_resnet50_image_classification/,1,3,1.0,[Comment(id='k6sygva')]
17hnm15,vpysk,,2023-10-27 13:30:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hnm15/mathematics_for_machine_learning_flashcard_notes/,Mathematics for Machine Learning Flashcard Notes,"Hi all,

I've just finished reading Mathematics for Machine Learning by Deisenroth et al ([https://mml-book.github.io/](https://mml-book.github.io/)), and i've made accompanying flashcard notes I used to quiz myself to make sure I understood the material.

My notes are here : [https://pyskinas.github.io/mml](https://pyskinas.github.io/mml) 

These notes are based on what I thought was difficult/easy so I did/didn't include some questions that others might have.

Hope you find these helpful, please let me know if I've made any errors.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hnm15/mathematics_for_machine_learning_flashcard_notes/,1,5,1.0,[Comment(id='k6s4y7g')]
17hohaq,curzoh,,2023-10-27 14:13:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hohaq/novice_ml_project_help/,Novice ML Project help,"Hello everyone,  


I am working on a ML project and have hit a roadblock and need some help/direction.  
For reference, I am still only a beginner and have limited experience with ML in general.  
Any help or resources (books, videos, etc.) would be greatly appreciated.  


Questions:  


1. When training my model should my epoch values be relative to my historical data e.g. ( 1000 data points : 100 epochs ) or is there a better indication for what the epoch value should be?  
The reason I ask is because having a high epoch can potentially cause overfitting, but I have found that having a high epoch (\~2800) is almost getting me the predictions I want, any idea why that is.
2. If I know certainties from my data, how exactly can I set boundaries for my model?  
e.g. ( data is in binary, therefore the only valid predictions should consist of either 1 or 0.  
another example/scenario, the data only contains even numbers so I would need to specify that x % 2 == 0) Is this something as simple as an IF statement within a for/while loop? or would this require a completely new model to do this task? 
3. The end goal of my project is to get one ML model to make a generalized prediction based on a speculation/hypothesis and another model to make more 'accurate' prediction based on the first models prediction and historical data, is this a good idea? any caveats?
4. This may not belong in this subreddit but I am open to any thoughts and opinions, I read somewhere that assigning arbitrary values to data is not a good idea.  
hypothetical 1: If I had data for the color of cars passing my house every day, could I consolidate all the data of sub colors into just one color e.g.( cyan, baby blue, turquoise, electric blue. values all plugged into 'blue' rather than individually counting specific colors)  
hypothetical 2: If my data is dominated by a specific event e.g. (a program that returns a pseudo-random float, but the recorded results have shown that two values '1.23456' and '4.00001' have the highest occurrence) Could I assign a value such as 50 and 100 to represent these occurrences? why/why not?  


I appreciate any and all help, thanks in advance :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hohaq/novice_ml_project_help/,0,4,0.84,[]
17ht5c4,tugrul_ddr,,2023-10-27 17:46:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ht5c4/what_is_the_best_activation_function_for_training/,What is the best activation function for training with simulated annealing?,"I tried only tanh and swish. Swish worked much faster, with less symmetricity on solution success space and with higher rms error.

&#x200B;

What activation function is best suited to simulated annealing? For example tanh takes 5 seconds, swish takes 0.5 seconds to learn approximating square root but looks worse than tanh. Similar for learning how to sort 3 element array, learning exclusive or too.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ht5c4/what_is_the_best_activation_function_for_training/,0,2,1.0,[]
17hug63,shani_786,,2023-10-27 18:44:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hug63/r_bidirectional_negotiation_first_time_in_india/,[R] Bidirectional Negotiation First Time in India | Autonomous Driving | Swaayatt Robots,"&#x200B;

[Bidirectional Negotiation | Swaayatt Robots](https://reddit.com/link/17hug63/video/t0xnpiyhiswb1/player)

Know more about the Bidirectional Negotiation from [Swaayatt Robots](http://swaayattrobots.com/research/) founder [Sanjeev Sharma](https://www.linkedin.com/in/sanjeevsharmaiitr/): [medium\_bidirectional\_negotiation](https://medium.com/@sanjeev.sharma.iitr/introducing-bidirectional-negotiation-to-the-world-of-autonomous-driving-biologically-inspired-63a7896241e6)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hug63/r_bidirectional_negotiation_first_time_in_india/,0,1,1.0,[]
17hucrg,Beef_Studpile,,2023-10-27 18:40:17+00:00,False,,1698432345.0,False,True,False,/r/learnmachinelearning/comments/17hucrg/new_to_tortoise_tts_where_is_my_workflow_causing/,"New to Tortoise TTS, where is my workflow causing me issues with voice cloning?","New to both Tortoise and ML, want to find a local\\offline natural speech synthesis software and was extremely impressed by the results Tortoise can produce based on the included voices.

I want to take things to the next step and clone a new voice, but somewhere in my workflow I'm missing something, because I'm getting poor results.  Anyone with more experience able to point out where I'm going wrong?

My workflow:

1. Record or source audio.  If sourced, use Audacity to re-export existing as 32-bit floating point WAV format.  If recorded, use sample rate 22050.
2. Export 4-6 samples of audio, create the new voice folder in Tortoise
3. python tortoise/read.py --textfile C:\\redact\\testing.txt --voice foghorn --preset high\_quality

I receive usable English, but it simply does not sound like the original source.  I'm having a hard time understanding what the difference is between the included original audio for the built-in voices, and the audio I source or record.  The only thing I've noticed is that I receive the following warning whenever I'm using audio other than what was provided with the built-in voices:

`C:\users\redact\appdata\roaming\Python\Python39\site-packages\torch\nn\utils\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.warnings.warn(""torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm."")`

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hucrg/new_to_tortoise_tts_where_is_my_workflow_causing/,0,1,1.0,[]
17hlwsu,IronFistThe3rd,,2023-10-27 11:58:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hlwsu/snake_ml_unsure_where_to_start_when_using/,Snake ML - unsure where to start when using Tensorflow,"I wish to make a Snake AI which makes the snake go towards the food and collect it.

So far, I have created the game Snake which works completely fine, but for human input.

However, I want to learn how to make it act on itself to eat the food. During my research, I have decided on a method called Q-learning to do this using Tensorflow, but I am a complete novice at Tensorflow. This is my first ML project, so I am not entirely sure where to start. On the Tensorflow tutorial documentation, it recommends using Keras to start off, but is that not for image recognition rather than using data points in an array to detect where the food is? 

Therefore, I would be very grateful if you could kindly provide resources and/or books which you recommend which would help me gain a greater understanding and put me on a path to fulfil this project which I am doing on Python.

If there are any more questions you would like to ask to gain greater clarity of my problem, please feel free to ask me. I will try my best to answer your questions so that you can help me to a greater degree.

Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hlwsu/snake_ml_unsure_where_to_start_when_using/,4,3,0.8,"[Comment(id='k6p6fpf'), Comment(id='k6qicry'), Comment(id='k6ob7sg'), Comment(id='k6v4bcd')]"
17hrssl,SirVampyr,,2023-10-27 16:44:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hrssl/filtering_fonts_automatically_for_sensible/,Filtering fonts automatically for sensible characters?,"Hey there,

as a part of my current project, I downloaded a bunch of fonts from different sites and I need to filter them now. A bunch of them have cryptic signs, watermarks or no image at all for some characters.

I'm currently out of feasible ideas to do this. I can't do it by hand, that would take ages. The only other option is to render each character and let a separate OCR check if it can recognize it. That sounds also incredibly time and resource intensive though.

Does anyone have a better idea to solve this issue?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hrssl/filtering_fonts_automatically_for_sensible/,0,1,1.0,[]
17hrq8t,RepresentativeTone75,,2023-10-27 16:41:35+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hrq8t/do_you_think_our_ability_to_learn_is_innate_and/,"Do you think our ability to learn is innate, and as such, fixed?",,learnmachinelearning,https://medium.com/@johndoodygsr/unlocking-mastery-techniques-for-effective-learning-part-i-of-iii-bb1db03380b1,3,0,0.5,"[Comment(id='k6pikd9'), Comment(id='k6sxnx7'), Comment(id='k6uunic')]"
17hpxj5,AvvYaa,,2023-10-27 15:20:06+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hpxj5/latent_space_visualizing_the_complex/,Latent Space: Visualizing the complex representations of neural nets,,learnmachinelearning,https://youtu.be/FslFZx08beM,0,1,1.0,[]
17hl4cy,Puddino,,2023-10-27 11:09:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hl4cy/scikit_learn_pipeline_score_different_from/,Scikit learn pipeline score different from scikit.metrics accuracy_score for classification problems,"According to [this answer](https://stackoverflow.com/questions/61493886/sklearn-is-there-a-way-to-define-a-specific-score-type-to-pipeline#:~:text=score%20method%20is%20always%20accuracy%20for%20classification%20and%20r2%20score%20for%20regression.) when doing classification problems the pipeline score is always accuracy.

I have an unbalanced dataset and wanted to prove that in this case accuracy is not a good measure of performance.
Naive bayes and decision tree gave an unusually high accuracy, so I printed the set of different values and they only predicted the value 1.
Given that they only predict 1, they should have an accuracy equal to the 'Non model' (i.e. the model that always predicts 1), but this was not the case.
```
DB = datasets.load_digits()
dataset_name = ""Digits_01_unbalanced""
class_names = np.array([""0"",""1""])
X_all = DB.data
y_all = DB.target
cont = 0
for i in range(0,len(y_all)):
  if y_all[i] != 0:
    y_all[i] = 1
    cont += 1
print(""Percentage of non-zero digits: %f"" %(cont/len(y_all)))
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,
                                                    test_size=0.333, #2/3 taining and 1/3 test -> tradeoff, better model for little less  
                                                    random_state=1128) # This sets the seed to a given costant, makes the output repr=oducible
models = (
    tree.DecisionTreeClassifier(criterion='entropy'),
    svm.SVC(kernel='linear', C=1),
    GaussianNB(),
    LogisticRegression()
)
classification_reports = {}
for model in models:
    pipe = make_pipeline(preprocessing.StandardScaler(), model)
    pipe.fit(X_train,y_train)
    acc = pipe.score(X_test, y_test)
    y_pred = model.predict(X_test)
    print(set(y_pred))
    print(f""Model: {type(model).__name__}, Accuracy by accuracy_score {accuracy_score(y_test,model.predict(X_test)):.3f}, Accuracy from pipeline {acc}"")
    #print(classification_report(y_test, y_pred, labels=None, target_names=class_names, digits=3))


y_pred = np.ones(len(X_test))
print(set(y_pred))
print(f""Model: Non Model, Accuracy {accuracy_score(y_test,y_pred):.3f}"" )
#print(classification_report(y_test, y_pred, labels=None, target_names=class_names, digits=3))

```
Outputs
```
Percentage of non-zero digits: 0.900946
{1}
Model: DecisionTreeClassifier, Accuracy by accuracy_score 0.900, Accuracy from pipeline 0.986644407345576
{0, 1}
Model: SVC, Accuracy by accuracy_score 0.983, Accuracy from pipeline 0.998330550918197
{1}
Model: GaussianNB, Accuracy by accuracy_score 0.900, Accuracy from pipeline 0.9816360601001669
{0, 1}
Model: LogisticRegression, Accuracy by accuracy_score 0.980, Accuracy from pipeline 0.998330550918197
{1.0}
Model: Non Model, Accuracy 0.900
```
score gives a different result from accuracy_score, why is this the case ?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hl4cy/scikit_learn_pipeline_score_different_from/,0,2,1.0,[]
17hl3np,kayabutterkun,,2023-10-27 11:08:07+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hl3np/training_ai_to_play_pokemon_with_reinforcement/,Training AI to play Pokemon with Reinforcement Learning,,learnmachinelearning,https://youtu.be/DcYLT37ImBY?feature=shared,0,2,1.0,[]
17hokns,kingabzpro,,2023-10-27 14:17:51+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hokns/overview_of_peft_stateoftheart_parameterefficient/,Overview of PEFT: State-of-the-art Parameter-Efficient Fine-Tuning,,learnmachinelearning,https://www.kdnuggets.com/overview-of-peft-stateoftheart-parameterefficient-finetuning,0,1,1.0,[]
17hjg2o,poolyhymnia,,2023-10-27 09:11:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hjg2o/seeking_advice_for_achieving_a_097_score/,Seeking Advice for Achieving a 0.97 Score,"I'm currently working on a machine learning task on Kaggle, and I'm striving to achieve a minimum of 0.97 score in accuracy. While I've made some progress, I've hit a plateau at 0.91 and can't seem to improve beyond that.

**Task Description**: I'm working on a classification task where tweets need to be classified into two categories: ""Sports"" or ""Politics."" I've used various models, including BERT, and have explored hyperparameter tuning, but I haven't been able to achieve the desired accuracy.

**Current State**: My best model currently has an accuracy of 0.91. I'm looking for ideas, strategies, and any advice that might help me break through this barrier and achieve a 0.97 accuracy score. I'm open to trying new approaches or techniques, and I'd love to hear from anyone who has experience with similar tasks.

**Questions**:

* Are there specific techniques or approaches you recommend for improving model accuracy?
* How can I make the most out of my training data and optimize the model further?
* Any insights on feature engineering or data augmentation that could help?

I greatly appreciate any insights or feedback you can provide. Please share your experiences, suggestions, or any resources you think might be helpful.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hjg2o/seeking_advice_for_achieving_a_097_score/,1,2,0.75,[Comment(id='k6nsppd')]
17hmmmv,Desilisk,,2023-10-27 12:39:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hmmmv/haversine_help/,Haversine Help,"Hey, I would just like to clarify whether an approach I’m taking is correct. I have 2 data sets, each with their own latitude and longitude columns. I got the haversine distances for both sets (distance from 0,0 and the lat long of each). Am I correct in saying that the difference between the haversine value from set A and the haversine vale from set B is equal to the distance between the two points in km?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hmmmv/haversine_help/,1,1,1.0,[Comment(id='k6xnasl')]
17hb159,sovit-123,,2023-10-27 00:27:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hb159/pytorch_pretrained_efficientnet_model_image/,PyTorch Pretrained EfficientNet Model Image Classification,"PyTorch Pretrained EfficientNet Model Image Classification

[https://debuggercafe.com/pytorch-pretrained-efficientnet-model-image-classification/](https://debuggercafe.com/pytorch-pretrained-efficientnet-model-image-classification/)

&#x200B;

https://preview.redd.it/ydfa0fch3nwb1.png?width=1000&format=png&auto=webp&s=aaf185a719579a36a9d2c35f3879694aa3320d17",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hb159/pytorch_pretrained_efficientnet_model_image/,0,6,1.0,[]
17hp877,93248828Saif,,2023-10-27 14:48:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hp877/looking_to_partner_up_aisaas_founders_for/,"Looking to partner up AI/SaaS founders for Sales/Marketing to Acquiring users for their SaaS ! Having a team, referrals and affiliates with well crafted outreach and leadgen systems !!","Having a deep Understanding of AI/ SaaS market and the hype , the products that have been made and are popping up , but most are just GPT wrappers as 90% of are useless or saturated failing daily as the bubble popped up churn rates are very high upto 22-25% , most are not product market fit and provides no value... 

Done deep research with team on AI and SaaS  ,   fine tuning of large LLM's the products that can be made and been developed and their use cases either for  generalize or specific niche ... The Golds and shovels of the era.....and many more. 
Our R&D team for guiding in market analysis and a perfect product market fit solutions and ideations for iterations and much more ... 
The product market fit solutions that could be made with well crafted roadmaps and market approachs

With having a foundational sales and marketing team , lead gen/ outreach systems with trained closers, affiliates and referrals with us.... Let me know if I can help you for acquiring users and for R&D , analysis of market needs/ wants , market conditions, ideas and iterations, ads and many more else! 

I got much to say , if anyone is interested.... Feel free to DM",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hp877/looking_to_partner_up_aisaas_founders_for/,0,0,0.2,[]
17hd4fb,Entire_Ad_6447,,2023-10-27 02:15:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hd4fb/resources_for_graph_classification_using_nn/,Resources for Graph Classification using NN,"So I have recently been allowed to work on a rather uniqe data set consisting of a varient of histopathology imaging. My objective is to see of there is any visual indicators(organizational etc) of a specific disease state that basic biomarkers are not capturing. 

I am familier with more traditional CNN methods of classifying these images into the 4 groups of interest but i know from the domain perspective that the organization of these cells and cell types and their spacial relationship are strong indicators of these disease states. from a cursory investigation i became curious if using a Graph based network to capture this information  may provide a unique perspective kf my data. however i have run jnto some difficulty finding good resources to learn about the underlying theory and set up of graph based classification. 

I am working through the PyG documentation as well as a few stanford lectures but I would appreciate if anyone with more experiance in this space could provide me links to a good learning resources. 

additionally resources of graph augmentation would also be appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hd4fb/resources_for_graph_classification_using_nn/,0,3,1.0,[]
17hiaae,fancypigollo,,2023-10-27 07:42:03+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hiaae/mlops_in_vertex_ai_in_3_minutes/,MLOps in Vertex AI in 3 minutes,,learnmachinelearning,https://youtu.be/Ek0ppnpuJf8?si=4tGs1tLTwAaHODmU,0,0,0.5,[]
17hi3bk,mathiasndiaye,,2023-10-27 07:28:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hi3bk/looking_for_time_series_data/,Looking for time series data,"Hello, 

I am looking for a time serie  with a trend and a seasonality

Those I found on kaggle didn't respect these conditions. Do you know any websites where I could find this ? 

Thanks in advance",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hi3bk/looking_for_time_series_data/,0,1,1.0,[]
17h4kck,calebkaiser,,2023-10-26 19:33:37+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17h4kck/llmops_building_realworld_applications_with_large/,LLMOps: Building Real-World Applications With Large Language Models — Free course by Elvis of DAIR.AI,,learnmachinelearning,https://www.comet.com/site/llm-course/,0,8,0.9,[]
17ha5hz,gordicaleksa,,2023-10-26 23:43:04+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ha5hz/solving_the_vesuvius_challenge_using_machine/,Solving the Vesuvius challenge using Machine Learning (w/ Luke Farritor),,learnmachinelearning,https://youtu.be/Bb2MEngbx7Q,0,2,1.0,[]
17h1v6o,CollarImaginary5610,,2023-10-26 17:34:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17h1v6o/git_version_controlled_datasets_using_your_own_s3/,Git Version Controlled Datasets using your own S3,"I’m building Underhive, a collaboration platform for ML Teams. I’ve just put out the first product up which helps you use your own storage backend for Git-LFS.

&#x200B;

Please email me at: [support@underhive.in](mailto:support@underhive.in). If you want to help and be one of the first beta clients. We’re also giving free usage for upto 200GBs for the next 6 months to beta clients.

&#x200B;

Try out: [https://underhive.in](https://underhive.in) (please use on Desktop, the mobile version is broken right now)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17h1v6o/git_version_controlled_datasets_using_your_own_s3/,7,7,1.0,"[Comment(id='k6lq7pp'), Comment(id='k6ltfii'), Comment(id='k6lshlr'), Comment(id='k6npx5a'), Comment(id='k6nqhlb'), Comment(id='k6pehsj'), Comment(id='k6pij2g')]"
17hbh3f,Seankala,,2023-10-27 00:50:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17hbh3f/how_to_use_tsne_to_visualize_multiclass_image/,How to use t-SNE to visualize multi-class image classification?,"Let me explain the situation a bit more in detail. I have an image classification task where each image has multiple labels. I'll refer to each label category as a ""task"" here. For example, let's say that I have images of clothing and tasks such as color, clothing type, and sleeve length. Each image would have a different set of labels depending on which classification task we're solving.

The way that my model is set up is to have an image encoder backbone (e.g., a ResNet model) and to have MLP layers for each task. Very typical setting.

I was wanting to build a t-SNE visualization for the images but was a bit confused by how I should be creating the plots. Should I use the backbone to create embedding vectors and keep these fixed, while coloring the data points differently according to each task? Is that how t-SNE typically works for multi-class classification?

Continuing with the above example, the scatter plot itself would remain the same, but we would have a total of three different plots: one colored differently for each task. Is this the correct line of thinking?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17hbh3f/how_to_use_tsne_to_visualize_multiclass_image/,0,1,1.0,[]
17hauvb,Viirock,,2023-10-27 00:18:54+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17hauvb/can_someone_please_help_me_with_my_keras_model/,Can someone please help me with my Keras model?,,learnmachinelearning,/r/MLQuestions/comments/17hatp4/can_someone_please_help_me_with_my_keras_model/,0,1,1.0,[]
17h5oum,Zealousideal-Time455,,2023-10-26 20:22:37+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17h5oum/kosmos25_and_the_power_of_multimodal_language/,KOSMOS-2.5 and the Power of Multimodal Language Models,,learnmachinelearning,/r/DocumentAI_Community/comments/17h5niw/kosmos25_and_the_power_of_multimodal_language/,0,2,1.0,[]
17h3fcw,o-rka,,2023-10-26 18:43:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17h3fcw/what_would_be_the_most_appropriate_distance/,What would be the most appropriate distance metric for percentage/ratio data?,"I have a matrix where each row is an observation, each column is a feature, and each value is the ratio the feature j is complete in observation i.  That is, the values range from 0 - 1.  

I'm looking through the distance measures in SciPy and I'm not sure which one would be best for this type of data. 

Does anyone have any insight on a distance metric that is designed to handle such a data type?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17h3fcw/what_would_be_the_most_appropriate_distance/,9,2,1.0,"[Comment(id='k6kx7a7'), Comment(id='k6l23a0'), Comment(id='k6l7f21'), Comment(id='k6lh8px'), Comment(id='k6llde6'), Comment(id='k6mnyu4'), Comment(id='k6nh1dp'), Comment(id='k6pf11n'), Comment(id='k6pff55')]"
17gukal,jshkk,,2023-10-26 11:43:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gukal/evaluation_metric_flowchart_possibly_handy/,"Evaluation Metric Flowchart (possibly handy, interested in feedback!)"," I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metrics -- mainly for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are ""less wrong"" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 ""means something""), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!

My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.

https://preview.redd.it/3l1eg8suajwb1.png?width=7162&format=png&auto=webp&s=ebc3bb137d01e57b0408b480ce3a44317d72e982",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gukal/evaluation_metric_flowchart_possibly_handy/,1,6,1.0,[Comment(id='k6jyrry')]
17gd8mi,YourWelcomeOrMine,,2023-10-25 19:44:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gd8mi/how_did_language_models_go_from_predicting_the/,"How did language models go from predicting the next word token to answering long, complex prompts?","I've missed out on the last year and a half of the generative AI/large language model revolution. Back in the Dar Ages when I was learning NLP (6 years ago), a language model was designed to predict the next word in a sequence, or a missing word given the surrounding words, using word sequence probabilities. How did we get from there to the current state of Generative AI?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gd8mi/how_did_language_models_go_from_predicting_the/,50,100,0.96,"[Comment(id='k6gsngy'), Comment(id='k6gtxza'), Comment(id='k6hgswp'), Comment(id='k6h4rf2'), Comment(id='k6fxzk0'), Comment(id='k6ikfai'), Comment(id='k6i48j4'), Comment(id='k6ipzy8'), Comment(id='k6hms9p'), Comment(id='k6h54qy'), Comment(id='k6i80l8'), Comment(id='k6ih5fp'), Comment(id='k6kthyz'), Comment(id='k70cpm2'), Comment(id='k6igwa2'), Comment(id='k6gz901'), Comment(id='k6i1nwp'), Comment(id='k6kkcuu'), Comment(id='k6mdcjp'), Comment(id='k6mwite'), Comment(id='k6wqmyd'), Comment(id='k6h6nmx'), Comment(id='k6i1miy'), Comment(id='k6imjb4'), Comment(id='k6jgdk7'), Comment(id='k6i39h0'), Comment(id='k6jgwlm'), Comment(id='k6k8ppi'), Comment(id='k6l5n7r'), Comment(id='k6ijtbv'), Comment(id='k6h6jhk'), Comment(id='k6gwsgs'), Comment(id='k6iskbr'), Comment(id='k6j3ikg'), Comment(id='k6i4i54'), Comment(id='k6j03ug'), Comment(id='k6kkfcp'), Comment(id='k71ofts'), Comment(id='k6i9rh3'), Comment(id='k6lvt1y'), Comment(id='k6hj9l1'), Comment(id='k6p3wg5'), Comment(id='k6hlsfn'), Comment(id='k6i5x2d'), Comment(id='k6hos21'), Comment(id='k6ibu07'), Comment(id='k6jvnga'), Comment(id='k6ixrvz'), Comment(id='k6jfa3a'), Comment(id='k6k4m6y')]"
17h0l2q,developing_fowl,,2023-10-26 16:36:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17h0l2q/machine_learning_tech_stack/,Machine Learning Tech Stack,"Hello everyone!

I am a beginner in Machine learning and programming and I was wondering if there are any tech stacks similar to web development or app development for machine learning. 

I have learnt Python and libraries and now got into supervised learning and was wondering how I could contribute to Open source with the knowledge I have gained until now. I want to try for MLH fellowship and would love to get some suggestions regarding what tech stack should I pick up to get a good project going to get selected.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17h0l2q/machine_learning_tech_stack/,3,2,1.0,"[Comment(id='k6oj25c'), Comment(id='k7cadtv'), Comment(id='k7caift')]"
17h4t43,sabsabsabbas,,2023-10-26 19:44:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17h4t43/skewed_target_or_variables/,Skewed target or variables?,"
Hi. 

I am new to machine learning.
I am building a model and i am not sure if the target is the only variable that has to be not skewed or the input variables are important as well?

Thank you in advance :-)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17h4t43/skewed_target_or_variables/,0,1,1.0,[]
17h3zdj,Samia_Tisha,,2023-10-26 19:08:48+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17h3zdj/can_anyone_tell_me_if_the_machine_learning/,Can anyone tell me if the machine learning workflow is correct or not? Could anyone please refer to tutorials or blogs to learn the proper workflow? Any suggestions are welcome.,,learnmachinelearning,/r/u_Samia_Tisha/comments/17h3xve/can_anyone_tell_me_if_the_machine_learning/,1,1,1.0,[Comment(id='k6mo71s')]
17go7z5,Embarrassed-Safe4314,,2023-10-26 04:20:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17go7z5/any_resource_for_mle_intern_interview/,Any resource for MLE Intern interview?,"Hi guys!

I have an interview in a week. I just wanted a refresher for all the ML concepts. I am a graduate student but the ML courses i have taken are way too research level. I wanted to know if there is a good resource for ML interviews at intern level out there! I did try StatQuest, but no offence, I did not like it at all. Any other book / playlist which can be completed within a week with graduate level course load would be really appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17go7z5/any_resource_for_mle_intern_interview/,4,12,1.0,"[Comment(id='k6iikmi'), Comment(id='k6j4wpd'), Comment(id='k6jvb1w'), Comment(id='k7ox1kr')]"
17h1xtf,meowkittykitty510,,2023-10-26 17:37:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17h1xtf/requesting_feedback_on_masters_in_ai_program_with/,Requesting feedback on Master's in AI program with University of Texas at Austin,"As the title says I'm asking for feedback from folks in the field of ML/AI on the MSAI program at UT@Austin. 

Here's the program website: [https://cdso.utexas.edu/msai](https://cdso.utexas.edu/msai)

**My Skills/Experience:**

* Have a BS in Comp Sci
* Very comfortable with Math
* Very experienced SE with >20 years in the industry
* Very comfortable with Python, many other languages and confident I can learn any new language/framework/APIs
* Have completed the [Fast.ai](https://Fast.ai) program
* Have worked through Andrej Karpathy's makemore videos
* Currently working in a leadership AI Engineering role doing work with LLMs, Vector DBs, and Computer Vision models
* Comfortable with NNs, Backprop and have implemented from scratch several times for learning

**The Program:**

Required Courses:

* Deep Learning
* Ethics in AI
* Machine Learning
* Planning, Search and Reasoning under Uncertainty
* Reinforcement Learning

Electives:

* AI in Healthcare
* Automated Logical Reasoning
* Case Studies in Machine Learning
* Natural Language Processing
* Online Learning and Optimization
* Optimization

**Program Pros/Cons**: 

* Pro: It's super affordable
* Pro: It's entirely online/async which would work great with my work schedule
* Cons: It's a new program so there are no reviews from past students to look at

**My Goal**: 

Move from ""AI Engineering"" (as it's called these days) into research. I'm interested in several areas like model architecture and robotics. I'm not sure to what degree these roles would require a PhD though? If I complete this program I'd like it to be useful for pursuing a PhD if I decide to take that path.

&#x200B;

For anyone in the industry, I'd love feedback on whether this looks like a useful program that will help me move toward my goals. If you're aware of other options that might be better I'd love to hear about them. 

P.S. Please keep the Reddit snark to a minimum, not useful.

Thank you in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17h1xtf/requesting_feedback_on_masters_in_ai_program_with/,3,0,0.5,"[Comment(id='k6kejw1'), Comment(id='k6snmz0'), Comment(id='k6keqps')]"
17gwbh2,aqjo,,2023-10-26 13:17:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gwbh2/pipenv_tensorflow_cuda_gpu_is_it_possible/,"pipenv, tensorflow, cuda, gpu - is it possible?","[pipenv](https://pipenv.pypa.io/en/latest/) seems like a nice Python environment manager, and I was able to set up and use an environment ... until I tried to use my GPU with Tensorflow. I then received errors that libraries could not be dlopened. The error message said check that the libraries mentioned above were installed, but no libraries were mentioned. Error text from the command line test below.

My tensorflow / GPU install works fine using a conda environment.

Is it possible to use Tensorflow and CUDA/GPU in a pipenv environment?

Thanks!

### Error message
```bash
❯ python3 -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""
2023-10-25 12:17:25.803005: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-10-25 12:17:25.821724: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-10-25 12:17:25.821743: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-10-25 12:17:25.821760: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-10-25 12:17:25.825514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-25 12:17:26.192767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-25 12:17:26.572148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-10-25 12:17:26.583490: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[]
```",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gwbh2/pipenv_tensorflow_cuda_gpu_is_it_possible/,1,2,1.0,[Comment(id='k6o6txk')]
17h0crv,Didlex,,2023-10-26 16:26:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17h0crv/tensorflow_pipeline_make_csv_dataset_not/,Tensorflow pipeline make_csv_dataset() not providing dataset that can be windowed," I am attempting to window some data from a csv file for time series training, but as I create the dataset from make\_csv\_dataset() and attempt to window it:

    def window_data(self, data_ds, window_size, shift):     data_ds = data_ds.window(window_size, shift=shift, drop_remainder=True).flat_map(         lambda x: x.batch(300, drop_remainder=True))     return data_ds 

It does not work, and further down you see what I attempted to reconcile it. But it seems I am given a PrefetchDataset from the make\_csv\_function. Here is the entire thing printed out: <PrefetchDataset element\_spec=(OrderedDict(\[('close', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('volume', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('pricechange', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('sma', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('macd', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('macdsignal', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('macdhist', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('upperband', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('middleband', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('lowerband', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('rsi', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('slowk', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('slowd', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('cci', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('adx', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('atr', TensorSpec(shape=(None,), dtype=tf.float32, name=None))\]), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>

Is there some sort of unpacking necessary for me to window it? The reason I am not just using a Pandas dataset is because it is way too large for my RAM.

Essentially my problem is that I am cannot properly window it and use it as a batchable dataset that can fit my ram one piece at a time.

Running the window\_data() function, I am given this error message: \`TypeError: in user code:

    TypeError: outer_factory.<locals>.inner_factory.<locals>.<lambda>() takes 1 positional argument but 2 were given` 

If I add another variable to the lambda to solve the last error, I get this code:

    data_ds = data_ds.window(window_size, shift=shift, drop_remainder=True).flat_map(             lambda x, y: x.batch(300, drop_remainder=True)) 

Finally it works if I use y.batch(), but if I use x.batch(), I am given this:

AttributeError: 'collections.OrderedDict' object has no attribute 'batch'

When it successfully completes with y, I get this FlatMapDataset with shape 300 when it should be (rows, 300, 16).

This code prints out correct values for a batch of 2 (only 2 batches for ease in testing):

    for batch, label in self.data_ds.take(1):     for key, value in batch.items():         print(f""""""{key:20s}: {value}"""""")              print(f""""""{'label':20s}: {label}"""""") 

And the output of that is exactly what it should be:

>close : \[1.08432 1.08432\] volume : \[0.9 0.9\] pricechange : \[0. 0.\] sma : \[1.0843693 1.0843579\] macd : \[-1.1817355e-05 -1.3658963e-05\] macdsignal : \[ 2.8224192e-06 -4.7385743e-07\] macdhist : \[-1.4639773e-05 -1.3185107e-05\] upperband : \[1.0843611 1.0843513\] middleband : \[1.084334 1.084328\] lowerband : \[1.0843068 1.0843047\] rsi : \[34.758636 34.758636\] slowk : \[-9.4739034e-15 -9.4739034e-15\] slowd : \[22.222221 7.4074073\] cci : \[-79.432625 -81.58508 \] adx : \[52.57429 50.354332\] atr : \[1.6490874e-05 1.5312955e-05\] label : \[1. 1.\]",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17h0crv/tensorflow_pipeline_make_csv_dataset_not/,0,0,0.5,[]
17gzm1i,Impressive_Middle106,,2023-10-26 15:53:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gzm1i/career_in_it_after_bcom/,Career in IT after BCOM,"Hey,

I am a BCOM final year student.

I want to work in IT, most likely in AI, ML, programming languages, or as a business/data analyst.

How can I make a career in this field?

What can I do after BCOM to pursue my interests while also establishing a solid career in this field?

&#x200B;

And, yeah, I am now enrolled in a PYTHON certification course on Coursera as well.

I have some basic knowledge about languages like JAVA, PYTHON, BASIC, SQL.

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gzm1i/career_in_it_after_bcom/,0,1,0.67,[]
17gy9xb,OnlyProggingForFun,,2023-10-26 14:51:08+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17gy9xb/5_gamechanging_applications_of_gpt4_no_coding/,5 Game-Changing Applications of GPT-4: No Coding Skills Required!,,learnmachinelearning,https://youtu.be/lwNy4lgDpjY,0,1,0.67,[]
17gmrxz,hkproj_,,2023-10-26 02:59:22+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17gmrxz/bert_explained_training_masked_language_model/,"BERT explained: Training (Masked Language Model, Next Sentence Prediction), Inference, Self-Attention, [CLS] token, Left and Right context, Comparative analysis BERT vs GPT/LLamA, Fine tuning, Text Classification, Question Answering",,learnmachinelearning,https://www.youtube.com/watch?v=90mGPxR2GgY,0,6,1.0,[]
17grt0m,UnlikelyAd7252,,2023-10-26 08:30:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17grt0m/suggestions_for_a_project/,Suggestions for a project,Kindly suggest models/logics to categorise tweets into pro-israel or pro-palestine for a project.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17grt0m/suggestions_for_a_project/,1,2,1.0,[Comment(id='k6vu0vf')]
17gul06,Minououa,,2023-10-26 11:44:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gul06/where_should_i_start/,Where should i start,"I have been asked to make a project 
And to do so i need to learn this :  
-Modélisation: thing ML
-Verification: cpn tools (rdps)
-Internet of objects 
Can you please suggest sources where i can learn all the above",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gul06/where_should_i_start/,0,1,1.0,[]
17gto64,User-NotFound,,2023-10-26 10:46:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gto64/regarding_the_prediction_of_the_bert_model/,Regarding the prediction of the Bert model,"I am making a **BERT-based Deep learning model** for my project, it's a **NLP project** where I have to classify customer feedback into 5 different categories. However, the problem that I am facing is that I have trained my model to classify each feedback into specified 5 different categories. But let's say the feedback is such that it doesn't lie in any of the categories so how can I make my model predict that this feedback does not lie in any of the given categories?

and secondly, if feedback is such that it lies in multiple categories how can I make my model predict that this feedback lies in more than one category?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gto64/regarding_the_prediction_of_the_bert_model/,1,1,0.67,[Comment(id='k6ix74m')]
17gmzjv,Koolsam_301,,2023-10-26 03:10:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gmzjv/how_do_machine_learning_models_typically_detect/,How do Machine learning models typically detect two events simultaneously?,"I have a question on how Machine learning(Deep learning) would work!

Let's say there is a person screaming and a gunshot sound.

If there is a model to identify these two occurrences, is it traditional to run two models (screaming and model for gunshot) on one audio file?

Or is it commonly more efficient to train the two overlapping sounds as an additional input and run it once?

Or is there a technique to distinguish which sounds have overlapped?

Thank you,",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gmzjv/how_do_machine_learning_models_typically_detect/,3,4,0.84,"[Comment(id='k6i4kld'), Comment(id='k6i5241'), Comment(id='k6i7adb')]"
17g6idh,davorrunje,,2023-10-25 14:48:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g6idh/long_read_deep_dive_into_autogpt_a_comprehensive/,[Long read] Deep dive into AutoGPT: A comprehensive and in-depth step-by-step guide to how it works,"We tried to figure out exactly how the AutoGPT works at the level of prompts so we got our hands dirty and documented how exactly each and every prompt was constructed. The result is in the following LONG document. It proved to be very useful for understanding the details of its inner workings and we hope the community would benefit from it as well:  
[https://airt.hashnode.dev/long-read-deep-dive-into-autogpt-a-comprehensive-and-in-depth-step-by-step-guide-to-how-it-works](https://airt.hashnode.dev/long-read-deep-dive-into-autogpt-a-comprehensive-and-in-depth-step-by-step-guide-to-how-it-works)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g6idh/long_read_deep_dive_into_autogpt_a_comprehensive/,8,23,0.88,"[Comment(id='k6et135'), Comment(id='k6gimno'), Comment(id='k6finzs'), Comment(id='k6flhph'), Comment(id='k6jogxf'), Comment(id='k6i90qp'), Comment(id='k6i92fd'), Comment(id='k6gcdtk')]"
17gqw0u,bennettsaucyman,,2023-10-26 07:21:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gqw0u/need_help_with_where_to_start/,Need help with where to start,"Need help with where to start

I'm helping out with a project where we have subjects watch a crime scene, then look at randomly selected photos of people as if it's a line up. When they pick someone they think might be the suspect, we want to give them a line-up with people who look like that person. 

On the one hand, we could just make pre-created line-ups, but my professor wants to take this more into the real world (something police could use with their own photos). 

So the idea is to create a program that can analyze the image that the subject chose, and then from thousands of other photos, choose multiple similar looking people (maybe also based on ""salient features"" like if the subject says ""oh he had earnings so it might be him"", but more-so general features)

I don't even know where to start to try and create this. I also don't know if there are models out there that do this already that I could adapt? I'm really a newb when it comes to this stuff, so any help would be appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gqw0u/need_help_with_where_to_start/,0,1,1.0,[]
17gpecw,raidedclusteranimd,,2023-10-26 05:35:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gpecw/any_good_mistral_7b_finetuning_resources/,Any good Mistral 7B Finetuning Resources?," There seems to be a loss instability issue so I just wanted to ask around (I tried my best to search online, can't seem to find a straightforward one with the Instruct model.)

[https://github.com/huggingface/transformers/issues/26498](https://github.com/huggingface/transformers/issues/26498)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gpecw/any_good_mistral_7b_finetuning_resources/,0,1,1.0,[]
17gp47t,ChyNhk,,2023-10-26 05:16:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gp47t/extracting_information_from_invoices/,Extracting information from invoices,"Hello, so I've given a task to retrieve some information from invoices (like date, name, numbers etc). The invoices layout cannot guaranteed be the same and also the invoice is also can be a format of PDF or excel spreadsheet

Is there any method to accomplish this job? I've looked up LayoutLM, is it possible to do this job with LayoutLM? Any insight will be much appreciated

Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gp47t/extracting_information_from_invoices/,0,1,1.0,[]
17gnyx1,random_hitchhiker,,2023-10-26 04:05:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gnyx1/dataset_for_south_east_asian_faces/,Dataset for South East Asian Faces?,"I am currently trying to implement a facial verification project, and I need to include more  ethnicities in the training/ testing data to make it more robust (specifically south east asian faces). 

Are there any recommended datasets that are publicly available? On the side, note would scraping images from google search results or social media be legal/ ethical? 

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gnyx1/dataset_for_south_east_asian_faces/,0,1,1.0,[]
17g1cqw,eeriek,,2023-10-25 10:07:02+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17g1cqw/why_is_this_happening_its_a_simple_mlp_network/,Why is this happening? It's a simple MLP network with 1 sigmoid neuron output layer. (the purpose is to classify binarily text),,learnmachinelearning,https://i.redd.it/u4tdq22pobwb1.png,10,19,0.79,"[Comment(id='k6dlsz2'), Comment(id='k6dr2od'), Comment(id='k6e8bmf'), Comment(id='k6edevx'), Comment(id='k6gjh9a'), Comment(id='k6duuij'), Comment(id='k6dm5ue'), Comment(id='k6dmmss'), Comment(id='k6dnkn2'), Comment(id='k6dpmxl')]"
17g7jof,Douglas__Jones,,2023-10-25 15:34:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g7jof/why_does_it_keep_adding_random_text_after_it/,Why does it keep adding random text after it answers the question?,"I am very new to llms and could not find an answer with google. This is using the Llemma 7b model on  LM Studio.

&#x200B;

https://preview.redd.it/vedbm3eebdwb1.png?width=1920&format=png&auto=webp&s=20f899406454ac48bbbee6ff3d6731c9a81c0a5f",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g7jof/why_does_it_keep_adding_random_text_after_it/,6,7,0.89,"[Comment(id='k6ewzdd'), Comment(id='k6glzpc'), Comment(id='k6gzvcn'), Comment(id='k6et96s'), Comment(id='k6f824g'), Comment(id='k6f7zcf')]"
17gclae,Drogen24,,2023-10-25 19:15:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gclae/need_a_hand_understanding_my_code_model_and/,"Need a hand understanding my code, model and hardware","I learn by doing and reviewing, not necessarily by reading or watching so I think my code is a lot more advanced than my knowledge is at the moment, but I'd like to understand what I have.

I've pieced the below code together from a few tutorials, stack overflow and GPT and currently have it running but it's taking forever, and it's maxing my CPU, RAM and NVMe SSD, whilst having almost no impact on my GPU. Obviously from the hardware perspective those are a bottleneck, and I'm working with what I have a the moment, but I'm fairly certain there's something wrong in my code that's causing excessive load.  
I'm aware iterations and job can be changed in the RandomSearchCV, and batch size can be increased in the model fitting to push more work to the GPU, but I'm not sure I'm actually getting to that stage.  
My dataset is 3.8m rows, hardware is i5 10600k, 24GB RAM and GTX970

    import pandas as pd
    import tensorflow as tf
    import joblib
    from tensorflow.keras.callbacks import EarlyStopping
    from scikeras.wrappers import KerasRegressor
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dropout, Dense
    from sklearn.model_selection import train_test_split, RandomizedSearchCV
    from sklearn.preprocessing import StandardScaler
    from scipy.stats import randint
    
    track = ""Hungaroring""
    
    # Read the CSV file
    df = pd.read_csv(f""Data/MoTEC/{track}/combined_output.csv"", low_memory=False)
    
    # Extract features and labels
    X = df[['SPEED', 'STEERANGLE', 'LapDistance', 'BRAKE', 'RPMS']].values
    y = df['TIME'].values
    
    # Normalize features
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Define the function to create your model
    def create_model(units_lstm1=50, dropout_rate1=0.2, units_lstm2=50, dropout_rate2=0.2, learning_rate=0.001):
        model = Sequential([
            LSTM(50, input_shape=(5, 1), return_sequences=True),
            Dropout(0.2),
            LSTM(50),
            Dropout(0.2),
            Dense(1)
        ])
    
        # After creating the model, print the summary
        model.summary()
    
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
    
        model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])
    
        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    
        X_train_reshaped = X_train.reshape((X_train.shape[0], -1))
    
        print(""Shape of X_train_reshaped:"", X_train_reshaped.shape)
    
        model.fit(X_train_reshaped, y_train, epochs=100, batch_size=128, validation_split=0.1, callbacks=[early_stopping], verbose=0)
    
        return model
    
    # Create a wrapper class for your model
    class MyKerasRegressor(KerasRegressor):
        def __init__(self, units_lstm1=50, dropout_rate1=0.2, units_lstm2=50, dropout_rate2=0.2, learning_rate=0.001, **kwargs):
            super().__init__(**kwargs)
            self.units_lstm1 = units_lstm1
            self.dropout_rate1 = dropout_rate1
            self.units_lstm2 = units_lstm2
            self.dropout_rate2 = dropout_rate2
            self.learning_rate = learning_rate
            self.model = create_model  # Set the model here
    
    # Define the hyperparameter grid for RandomizedSearch
    param_dist = {
        'units_lstm1': [50, 100],
        'dropout_rate1': [0.2, 0.3],
        'units_lstm2': [50, 100],
        'dropout_rate2': [0.2, 0.3],
        'learning_rate': [0.001, 0.01]
    }
    
    # Use RandomizedSearchCV
    random_search = RandomizedSearchCV(
        estimator=MyKerasRegressor(),
        param_distributions=param_dist,
        n_iter=1,
        cv=3,
        verbose=0,
        n_jobs=1
    )
    
    
    
    # Fit the random search model
    random_search.fit(X_train, y_train)
    
    # Access the best model
    best_model = random_search.best_estimator_
    
    # Evaluate the best model on the test set
    X_test_reshaped = X_test_reshaped = X_test.reshape((X_test.shape[0], -1))
    
    mse = best_model.score(X_test_reshaped, y_test)
    print(f""Mean Squared Error: {mse}"")
    
    # Save the scaler and best model
    joblib.dump(scaler, f'Scalers/{track}/scaler.joblib')
    best_model.model.save(f'Models/{track}/best_model.keras')

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gclae/need_a_hand_understanding_my_code_model_and/,0,2,1.0,[]
17g557e,Total-Opposite-8396,,2023-10-25 13:43:40+00:00,False,,1698242481.0,False,True,False,/r/learnmachinelearning/comments/17g557e/need_help_understanding_if_the_model_here_is/,Need help understanding if the model here is overfitting or not.,"&#x200B;

[ ](https://preview.redd.it/c4t05pjlrcwb1.png?width=1546&format=png&auto=webp&s=2966068e9d45df04481a5f95aa24cdb9447e8cb2)

I've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?

Edit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g557e/need_help_understanding_if_the_model_here_is/,7,5,1.0,"[Comment(id='k6eclxj'), Comment(id='k6ei12p'), Comment(id='k6ek5nq'), Comment(id='k7z2wv1'), Comment(id='k6ekkls'), Comment(id='k6jb7wp'), Comment(id='k6k2e2a')]"
17ggzg8,adversarial_diffuser,,2023-10-25 22:23:46+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ggzg8/ideas_for_pix2pix_project/,Ideas for pix2pix project?,"I’m currently learning GANs, anyone have nice and creative idea to train pix2pix on it?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ggzg8/ideas_for_pix2pix_project/,0,1,1.0,[]
17gb1qr,viniciusarruda,,2023-10-25 18:06:26+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17gb1qr/d_what_is_the_lowest_possible_loss_for_a_language/,[D] What is the lowest possible loss for a language model?,,learnmachinelearning,/r/MachineLearning/comments/17etn6g/d_what_is_the_lowest_possible_loss_for_a_language/,1,2,1.0,[Comment(id='k6l8p1s')]
17g6d6b,spmallick,,2023-10-25 14:41:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g6d6b/diving_deeper_into_kerascv/,Diving deeper into KerasCV!,"After exploring DeeplabV3+ for semantic segmentation, we're now zooming in on object detection 🎯. Using the renowned Global Wheat Challenge from 2020 on Kaggle, we're putting KerasCV YOLOv8 models to the test:

1️⃣ YOLOv8 small

2️⃣ YOLOv8 medium

3️⃣ YOLOv8 large

Stay tuned as we ensemble these models using the Weighted Boxes Fusion (WBF) technique for sharper predictions!  


Read:  https://learnopencv.com/comparing-kerascv-yolov8-models/   
Repo: [https://github.com/spmallick/learnopencv/tree/master/Comparing-KerasCV-YOLOv8-Models-on-the-Global-Wheat-Data-2020](https://github.com/spmallick/learnopencv/tree/master/Comparing-KerasCV-YOLOv8-Models-on-the-Global-Wheat-Data-2020)  
 

https://reddit.com/link/17g6d6b/video/wflknqww1dwb1/player",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g6d6b/diving_deeper_into_kerascv/,0,3,1.0,[]
17gdmws,fancypigollo,,2023-10-25 20:01:43+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17gdmws/amazon_sagemaker_in_4_minutes_clearly_explained/,Amazon Sagemaker in 4 minutes - Clearly Explained,,learnmachinelearning,https://youtu.be/IqYbMuS22k0?si=YMvYWG91s3TQ4hyX,0,1,0.67,[]
17gcokx,First-Public-4958,,2023-10-25 19:19:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17gcokx/can_i_integrate_my_own_model_with_elk_and_how/,Can I integrate my own model with ELK and how many logs would be enough to train or test it?,"I want to center my project around training my own model to detect incidents and test it in a virtual environment where I emulate adversarial behaviour. I know ELK uses ML for log analysis, but I was wondering if I could train a model with an existing online dataset (because I don’t think I can generate a sufficient amount of ligs) to detect security incidents and then integrate this model with ELK and test it with the logs on a VM. The problem would be that I wouldn’t have many logs since I’m talking about only one “target” VM and malicious traffic would be generated by deploying invoke atomic test. Also, do I need to preprocess the logs in the form of the datasets used for training the model?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17gcokx/can_i_integrate_my_own_model_with_elk_and_how/,0,1,1.0,[]
17g29r6,zibenmoka,,2023-10-25 11:10:08+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17g29r6/train_your_own_south_park_fanatic_ai_with/,Train your own South Park Fanatic AI with Mistral-7B,,learnmachinelearning,https://int8.io/train-your-own-south-park-fanatic-ai-with-mistral-7b/,0,4,0.83,[]
17g126s,DataCrayon,,2023-10-25 09:45:58+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17g126s/intro_to_evolutionary_algorithms/,Intro to Evolutionary Algorithms,,learnmachinelearning,https://www.youtube.com/watch?v=L--IxUH4fac&t=185s,0,6,1.0,[]
17g9clv,donno_man,,2023-10-25 16:52:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g9clv/deep_learning_for_invoice_extraction/,Deep learning for invoice extraction.,I wonder how can I start creating a model like Faster RCNN etc. In other words resources.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g9clv/deep_learning_for_invoice_extraction/,0,0,0.5,[]
17g8pwy,atom1291,,2023-10-25 16:25:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g8pwy/need_help_in_understanding_svdtruncation_lora/,Need help in understanding SVD-Truncation (LoRA),"Hi, I am a novice to Machine Learning, the math really fascinates me, so I read about a lot of new things happening in the world of ML. I was reading about LoRA and how the genius behind truncation. So given,

A = U\*S\*V(T) 

S, the diagonal matrix, is truncated at the Kth index; thereby converting higher-rank matrix to a lower-rank matrix. (Ref :  [PEFT LoRA Explained in Detail - Fine-Tune your LLM on your local GPU - YouTube](https://www.youtube.com/watch?v=YVU5wAA6Txo) 22:00)

My question is when we truncate, we are losing information, sure the information is less important as we go down the diagonal, yet how does the performance still stay good? If even the truncated model is that good, why not change the matrix dimensions to that of the truncated one and reduce the model size?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g8pwy/need_help_in_understanding_svdtruncation_lora/,2,1,1.0,"[Comment(id='k6p74ro'), Comment(id='k6p7ntx')]"
17fivag,BelowaverageReggie34,,2023-10-24 17:55:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fivag/machine_learning_from_a_graphic_designers/,Machine Learning from a Graphic Designer's Perspective," Hello. as the title probably gives away, I'm a graphic designer by profession. But, on the other side, I've got these additional projects – mainly involving image enhancement and filtering emails. I got into machine learning on a friend’s recommendation so I could manage my emails, spam, and other tasks better. He introduced me to Jasper and Claude, and now I have templates and responses ready for almost all sorts of email communication. Keeps me sane as well, by not having to waste half my day filtering and answering emails. 

But, I don’t want to limit myself to these 2 AI tools and Im looking for  AI tool suggestions that can further help me increase productivity. Your personal experiences, challenges you faced, the triumphs, any specific tweaks or settings you’d recommend Im listening!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fivag/machine_learning_from_a_graphic_designers/,5,49,0.87,"[Comment(id='k6d3sm1'), Comment(id='k6da5zb'), Comment(id='k6a8870'), Comment(id='k6ab2y5'), Comment(id='k6fk0jm')]"
17g71sl,muzzyxp,,2023-10-25 15:12:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g71sl/how_should_i_start_course_or_book/,"How should I start, course or book?","So I’ve been wanting to get into ML recently and Im thinking about doing a project for my final year in university that utilises ML. But I have a year until then, I have the option to do a machine learning module but that will be during the second half of my final year, so I’d rather just self learn now and get working on some side projects or something practical. 

So far I have played around and done the beginner course on kaggle and learnt the basic of Pandas, Scikit and stuff but obviously that isn’t going to be enough 🤣

From what I’ve seen so far, there are a lottt of resources which is making things overwhelming for me on where to start, currently I’m thinking of either buying the Hands on machine learning with scikit-learn, keras and tensorflow by Aurelien Geron book or doing an online course like the andrew ng ML course

But honestly I have no idea which one to do or if there is something better, I just want to get to a point where I can utilise ML and also understand what’s going. Any suggestions would be greatly appreciated",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g71sl/how_should_i_start_course_or_book/,5,1,0.67,"[Comment(id='k6evuza'), Comment(id='k6jwd8b'), Comment(id='k6ew7sc'), Comment(id='k6k243x'), Comment(id='k6ex332')]"
17g3ake,monkeyyyyyyy7,,2023-10-25 12:11:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g3ake/guide_please/,Guide please,I am an student. Can you guys help me with where should I start my machine learning like in web development you start from html then CSS then JavaScript then some framework like react then node then express then some database like mongodb. I cannot afford any paid course I will learn step by step from youtube .So please give me full roadmap(beginner to pro) . Thanks,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g3ake/guide_please/,0,0,0.33,[]
17frfma,Harish_Mohanraj,,2023-10-25 00:01:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17frfma/long_read_deep_dive_into_autogpt_a_comprehensive/,[Long read] Deep dive into AutoGPT: A comprehensive and in-depth step-by-step guide to how it works,[https://airt.hashnode.dev/long-read-deep-dive-into-autogpt-a-comprehensive-and-in-depth-step-by-step-guide-to-how-it-works](https://airt.hashnode.dev/long-read-deep-dive-into-autogpt-a-comprehensive-and-in-depth-step-by-step-guide-to-how-it-works),learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17frfma/long_read_deep_dive_into_autogpt_a_comprehensive/,0,9,1.0,[]
17fxyuj,Sad_Sentence_229,,2023-10-25 05:53:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fxyuj/learning_to_apply_machine_learning_techniques_on/,Learning to Apply Machine Learning Techniques on IoT Device for Remote Sensing of Gases,"I am currently part of a research team developing and IoT device for remote sensing of gases. As the title suggests I want to learn how to apply ML to the gas analysis setup. I am willing to learn but currently I do not know where to start, I have background in programming and engineering level mathematics. Any help will be appreciated. Thank you and God Bless.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fxyuj/learning_to_apply_machine_learning_techniques_on/,1,3,1.0,[Comment(id='k6d64dh')]
17fvxb0,poemfordumbs,,2023-10-25 03:46:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fvxb0/what_should_i_do_for_training_when_data_to/,What should I do for training when data to predict has random distribution?,"I was taught that when doing imbalance classification, the training data should be augmented to more or less match the number of classes, but the validation data should have the same distribution as the test data. And the test data should have the similar distribution as the data I will actually predict.

But what if real data's distribution is quite random? What validation data distribution should I use? Is there any paper, or guide for this kind of problem?  


for example, I got 14 classes to classify, and training data before augmentation have something like 1 class has 52% proportion, and small ones have 0.9%, and 0.17% proportion. (most of classes under 10%). Practitioners who would use my model input data that only 3 classes to classify, and the classes can be very small proportion in training data before augmentation. So in practice data can have 70% of class that is 0.9% in training data before augementation.  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fvxb0/what_should_i_do_for_training_when_data_to/,6,5,1.0,"[Comment(id='k6cuzih'), Comment(id='k6ctcso'), Comment(id='k6d7uoe'), Comment(id='k6m4wzb'), Comment(id='k6m4eko'), Comment(id='k6n7004')]"
17g0vup,Technical_Ad_9732,,2023-10-25 09:32:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17g0vup/ml_resources_for_intern/,ML resources for intern,"Trying to get an intern up to speed with ML application to wireless communications and adversarial ML for wireless communications. Talking jamming, anti-jamming, and spoofing. I don't want to throw them into the deep end just yet though, but rather give them a good foundation and basis for which to be able to take up more advanced work and build to it. I am looking for good resources -- papers, tutorials, write-up, ect. Things I can have them read to get their feet wet and build up the knowledge base for this area, so they can slowly build up their way to understanding more state of the art work and even go beyond that and start developing their own ideas on how to extend the state of the art. Hard as someone in this field to really appreciate what helps with going from 0 to 100, so asking more for the feedback of others that are currently doing this to help guide the resources I point this intern to, in hopes it's a more gentle introduction than throwing them off the deep end and overwhelming them right out the gate. Appreciate the suggestions! ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17g0vup/ml_resources_for_intern/,0,1,1.0,[]
17fzsuu,Twygg,,2023-10-25 08:09:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fzsuu/preparation_of_dataset_for_leolm/,Preparation of Dataset for LeoLM?,I would like to feed the LAION LeoLM with special knowledge about certain topics. (LAION LeoM because it is good at German). But I do not get along with the preparation of my dataset. Are there any good tutorials or ready scripts that can help me? The special knowledge are a few essays and books (really few) that I have as plain text (txt).,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fzsuu/preparation_of_dataset_for_leolm/,0,1,1.0,[]
17ft67g,OnlyProggingForFun,,2023-10-25 01:25:29+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ft67g/how_we_built_an_opensource_ragbased_chatgpt_web/,How we Built an Open-Source RAG-based ChatGPT Web App: Meet Our new AI Tutor!,,learnmachinelearning,https://youtu.be/7ytyK6u3aAk,0,3,1.0,[]
17fz26x,EffectiveRow6505,,2023-10-25 07:12:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fz26x/please_go_through_my_problem_statement_my_and/,Please go through my problem statement my and tell me if ML is even applicable here and which models might suit my needs.," So, at least in India, lab reports in a biochemistry lab have to be manually checked by a consultant physician and then signed. They are then termed as verified. What I want to do is autoverify this process by scanning through the reports and then terming these values as expected or unexpected (i.e., whether they require manual intervention or if they can be autoverified) based on the accepted ranges, age, sex, prior patient history.   


I'm an absolute beginner in ML and any advice would be very helpful

Thank you for helping me out, hope you have a wonderful day",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fz26x/please_go_through_my_problem_statement_my_and/,17,0,0.5,"[Comment(id='k6d9j3k'), Comment(id='k6d6sco'), Comment(id='k6d62ne'), Comment(id='k6ddrh7'), Comment(id='k6dzk7e'), Comment(id='k6g9bid'), Comment(id='k6da9fr'), Comment(id='k6danow'), Comment(id='k6dacjn'), Comment(id='k6ep95u'), Comment(id='k6e3los'), Comment(id='k6jfgtu'), Comment(id='k6ew2tn'), Comment(id='k6epktp'), Comment(id='k6f04o4')]"
17fxyde,Gaurang_Mathur_ftw,,2023-10-25 05:52:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fxyde/lstm_train_val_losses_not_converging/,LSTM: Train & Val losses not converging," 

I am training an LSTM model for path prediction where I'm feeding in OBT (on-board Time) and X matrix as input and Y matrix is the predecessor matrix generated using Scipy.Dijkstra

&#x200B;

[ This is the model architecture for reference, ](https://preview.redd.it/tdanannlfawb1.png?width=1009&format=png&auto=webp&s=555b76391abcfe5f2e1255ec839756cf78a40d44)

This is the model architecture for reference,

This is the model architecture for reference,

I've tried multiple iterations of this similar model, but the training and validation loss, are not converging. The best train\_loss i've been able to achieve is 88k mse and 400 mse val\_loss

I've uploaded the dataset here: [GitHub - mathur-exe/LSTM\_Dataset](https://github.com/mathur-exe/LSTM_Dataset)

Training Progress:  
Epoch 1/100 342/342 - 17s - loss: 22606898.0000 - val\_loss: 61414736.0000 - 17s/epoch - 49ms/step Epoch 2/100 342/342 - 14s - loss: 7990657.0000 - val\_loss: 3699703.5000 - 14s/epoch - 40ms/step Epoch 3/100 342/342 - 13s - loss: 4130298.7500 - val\_loss: 136808.1094 - 13s/epoch - 38ms/step Epoch 4/100 342/342 - 12s - loss: 2747299.2500 - val\_loss: 35710.1680 - 12s/epoch - 35ms/step Epoch 5/100 342/342 - 12s - loss: 2558378.2500 - val\_loss: 3383.4780 - 12s/epoch - 36ms/step Epoch 6/100 342/342 - 13s - loss: 1214455.8750 - val\_loss: 111625.2891 - 13s/epoch - 37ms/step Epoch 7/100 342/342 - 19s - loss: 337480.2500 - val\_loss: 68686.6094 - 19s/epoch - 55ms/step Epoch 8/100 342/342 - 15s - loss: 316366.7188 - val\_loss: 2059.3557 - 15s/epoch - 44ms/step Epoch 9/100 342/342 - 20s - loss: 293117.0312 - val\_loss: 20961.5469 - 20s/epoch - 58ms/step Epoch 10/100 342/342 - 17s - loss: 575945.1875 - val\_loss: 503602.8438 - 17s/epoch - 50ms/step Epoch 11/100 342/342 - 13s - loss: 290962.8750 - val\_loss: 62491.9375 - 13s/epoch - 37ms/step Epoch 12/100 342/342 - 12s - loss: 1125042.5000 - val\_loss: 36054.6836 - 12s/epoch - 36ms/step Epoch 13/100

...

342/342 - 16s - loss: 230900.7969 - val\_loss: 48309.6094 - 16s/epoch - 47ms/step Epoch 93/100 342/342 - 23s - loss: 232846.6094 - val\_loss: 82926.6875 - 23s/epoch - 67ms/step

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fxyde/lstm_train_val_losses_not_converging/,1,1,1.0,[Comment(id='k6d7c4r')]
17ftp9a,sadfasn,,2023-10-25 01:51:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ftp9a/doing_something_unorthodox_with_keras/,Doing Something Unorthodox with Keras,"Hello

I am trying to do something a little unorthodox with Keras. I am trying to train a very simple linear regression like this:  


Y = b0 + b1x + e

&#x200B;

I have simulated data so I know what the weights of b0 and b1 should be.

Now normally this would be simple, you would just pass your x tensor to an Input node, add a linear activation output, and minimize mean squared error.

However, I am trying to approach this in a different way. I want to estimate b0 and b1 using two inputs to the neural network.

When I mean is that I will have one input that just takes x (no bias term). And another input that takes a vector of ones (again no bias term). Then these are both passed through a linear activation function, and then passed into a custom loss function of the following form:

def custom\_loss(y\_true, y\_pred):

\# Extract y\_pred from the model's output

y\_pred1, y\_pred2 = y\_pred\[:, 0\], y\_pred\[:, 1\]

\# Compute the Mean Squared Error

mse = K.square(y\_true - y\_pred1 - y\_pred2)

return K.mean(mse)

&#x200B;

For some reason I do not get the correct parameters back from training the model in this way. But as far as I can tell this should be equivalent to doing everything in one input node.

Does anyone have any insight on why this isn't working? I know this seems kind of stupid but I actually have some good reasons for doing this with a project I am working on. Any insight would be appreciated!

&#x200B;

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ftp9a/doing_something_unorthodox_with_keras/,0,2,1.0,[]
17fa0c9,AnyJello605,,2023-10-24 10:57:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fa0c9/training_multiple_ml_models_sequentially_on_same/,Training multiple ML models sequentially on same X_train?," I was at a job interview a couple of weeks ago for Data Science. They gave me a task to write at home for a couple of days and then discuss it. So, I cleaned the dataset and trained 3 models on it. I trained the model, made the predictions using X\_Test and then printed out some metrics and this was done in 2 cells per model (6 cells in total). During the interview I was told this is the wrong way to do it and I should not train different models on the same dataset as ""each training cycle alters the dataset"". I've never heard that before and didn't say anything. Were they right? Should I make copies of the dataset and train each different model on a copy? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fa0c9/training_multiple_ml_models_sequentially_on_same/,22,24,0.96,"[Comment(id='k68wagd'), Comment(id='k68i9nm'), Comment(id='k68jse7'), Comment(id='k69583l'), Comment(id='k68v26e'), Comment(id='k6am1im'), Comment(id='k696h6a'), Comment(id='k6bv09n'), Comment(id='k6avzk9'), Comment(id='k69mbt9'), Comment(id='k6darp8'), Comment(id='k6dlbeg'), Comment(id='k68jz7r'), Comment(id='k699k3i'), Comment(id='k69xn0q'), Comment(id='k6ctifw'), Comment(id='k69hg9n'), Comment(id='k6bdgqu'), Comment(id='k6dgm9l'), Comment(id='k69jdih'), Comment(id='k69km71'), Comment(id='k69pefn')]"
17fdjnu,d_r_,,2023-10-24 14:01:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fdjnu/book_recommendation_for_cnnrnntransformer/,Book recommendation for CNN/RNN/Transformer architectures,"Hi!

I've found multiple threads about book recommendations for beginners. I've read entry-level books and want to read on to get more information about CNNs/RNNs/Transformer architectures. My books covered those, but only scratched the surface of how they work and what to expect, but didn't go into details. I think it can't be all of the available knowledge if a book covers CNNs in 20 pages :-D  


Would really appreciate book recommendations that go deep into these three topics.

Best regards,  
D.R.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fdjnu/book_recommendation_for_cnnrnntransformer/,7,11,1.0,"[Comment(id='k69955s'), Comment(id='k693cox'), Comment(id='k6dk82n'), Comment(id='k691mn2'), Comment(id='k6jx1w9'), Comment(id='k6dbj5k'), Comment(id='k6dboyx')]"
17fki2v,UnlikelyAd7252,,2023-10-24 19:04:31+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17fki2v/wrong_prediction_even_on_simple_words_though_my/,Wrong prediction even on simple words though my model has a good accuracy about 92%,,learnmachinelearning,https://i.redd.it/yvyrh0ut77wb1.png,4,2,0.6,"[Comment(id='k6ajfat'), Comment(id='k6ao45v'), Comment(id='k6ct94i'), Comment(id='k6ct9wc')]"
17flff0,Zealousideal-Time455,,2023-10-24 19:43:40+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17flff0/finetuning_layoutlm_for_document_information/,Fine-tuning LayoutLM for Document Information Extraction,,learnmachinelearning,/r/DocumentAI_Community/comments/17fld9f/finetuning_layoutlm_for_document_information/,0,1,1.0,[]
17fg1wn,flavorwolf_,,2023-10-24 15:53:05+00:00,False,,1698167778.0,False,True,False,/r/learnmachinelearning/comments/17fg1wn/good_app_recommendations/,Good app recommendations,Can anyone please share 1-3 of your favorite AI/ML/LLM news apps? Low on hype and high on technical information would be appreciated. Thanks in advance! 📰 🤖 ❤️,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fg1wn/good_app_recommendations/,0,2,0.63,[]
17fktv4,abelEngineer,,2023-10-24 19:18:31+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17fktv4/is_it_better_to_create_a_different_set_of_doc2vec/,"Is it better to create a different set of Doc2Vec embeddings for each group in my dataset, rather than generating embeddings for the entire dataset?",,learnmachinelearning,/r/MLQuestions/comments/17fktbg/is_it_better_to_create_a_different_set_of_doc2vec/,0,1,1.0,[]
17fkggu,rootcage,,2023-10-24 19:02:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fkggu/3d_design_file_labelling_and_classification_for/,3D Design file labelling and classification for manufacturing,"I have \~1 million 3D design (.STP and/or .OBJ) files of various parts for medical devices, aerospace, automotive or defense systems. I'd like to label them based on appropriate manufacturing methods that are used to physically make them. Some example methods and labels would be milling, turning, injection molding, cnc machining, etc. After labelling, I'd like to architect a system to produce these labels as inference for a new part that has not been physically made yet.

My team (<5 people) have manufacturing domain expertise and can manually label these parts but I'm looking for a more scalable solution that isn't as time consuming. Crowd sourced methods like Mechanical Turk won't work because annotators do not have the domain knowledge to mark the correct label. Labelling platforms like SageMaker/Azure ML Studio only allow image/text/audio datasets, is there a platform that'll help me setup labelling tasks for 3D designs? Furthermore, how can I find more experts that can help scale this up? It seems to me that the only option is to build my own labelling app as an annotator needs these key features -

1. 3D model visualizer so they can spin the part and view any orientation
2. Draw a bounding box (commonly available in other platforms)
3. Toggle measurements in inches/mm

As for label classification I'm looking at architectures like PointNet since my dataset of meshes can be sampled to point clouds. Are there other methods that would work better or worth exploring? Open to any and all suggestions across this pipeline.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fkggu/3d_design_file_labelling_and_classification_for/,0,1,1.0,[]
17fhpei,TheDark_Knight108,,2023-10-24 17:05:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fhpei/p_need_help_with_ug_major_project_idea/,[P] Need help with UG major project idea," 

I'm seeking guidance for my undergraduate major project, which will span abput six months and necessitates the publication of a journal/conference paper. I'm contemplating various topics within the realm of machine learning, including NLP, reinforcement learning, GANs, Transformers, and diffusion-based models. However, resource constraints are a factor, limiting me to utilizing cloud-based GPUs. My previous project involved text classification and fine-tuning the llama2-7b model on a specific dataset using Google Cloud GPUs. My primary goal is to select a research domain and topic that addresses a specific research gap. Thank you

This would be my final year project for my four year degree in computer science and engineering.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fhpei/p_need_help_with_ug_major_project_idea/,0,1,1.0,[]
17fpzpu,notAStranger1,,2023-10-24 22:55:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fpzpu/career_shifting_into_mlai/,Career shifting into ML/AI,"Hey, I am a full stack web developer who has had a passion for AI since i was a student but never really had the chance to learn it.

I have set my goal to try to be AI/ML hirable by the end of next year (It might br a foolishly unrealistic goal but my knowledge is incredibly narrow) as i really want to make my career out of a subject i am truley passionate about as opposed to something i am just decent at and not as passionate about.

I have built a learning roadmap consisting of learning the different types of algorithms(regressions, classifications, clustering etc..) statistically, mathematically and both with ground up implementation and implementation using existing libraries, as well as what i believe are basics for NN and NLP and of course alot of data handling preprocessing techniques

However after getting a breif overview of some of the topics, i cant help but feel that the road map i put wont even get me to 10% hirable, i feel imcredibly lost, i dont know if there is more i should learn about, i dont know what are the scopes of ML projects, i dont know if i am headed in the right direction, i feel very lost and would really appreciate any sort of guidance i can get.

I am sorry if i dont make much sense with the question or if the queations sound naive, but i am truely lost and i know very little

Thanks in advance",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fpzpu/career_shifting_into_mlai/,6,0,0.25,"[Comment(id='k6bw8aw'), Comment(id='k6cfm0z'), Comment(id='k6d14r6'), Comment(id='k6d189n'), Comment(id='k6d1wy3'), Comment(id='k6d2y7u')]"
17fgmnt,boardernut,,2023-10-24 16:18:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fgmnt/possible_to_predict_nhl_score_using_data_i_am/,Possible to predict NHL Score using data I am currently collecting?,"I am very new to machine learning, so I apologize if I don't provide enough details.

This started out as a project to see if I could show statistically that teams/goalies do have a home ice advantage.

Basically I have a python script that looks at NHL matchups from the day before, and adds the following data to an existing spreadsheet.

For each starting goalie, it increments home or away games played.  If home goalie, increments their shots faced and goals allowed on home ice.  Also calculates their home ice save percentage and goals against average.  It does the same thing if they are the away goalie.

In a separate spreadsheet I gather team data for home and away.  Shots for, goals for, shots against, and goals against.  Season totals to date as well as per game averages.  

Since I have this raw data, I was thinking maybe I could use machine learning to build a model to predict scores.

Right now I have a python script that will let me select an upcoming matchup, and which goalie will start for home and away.

It read the excel spreadsheets so that all the team/goalie data I have selected is linked to the teams/goalies I've selected.

But that is as far as I know how to go.

Is there a way to predict a score factoring in:  

Home team score is calculated by using home team shots/goals for data, away team shots against/goals against date.  And away goalie goals against averages and save percentages.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fgmnt/possible_to_predict_nhl_score_using_data_i_am/,0,0,0.5,[]
17fgby2,ikiya13,,2023-10-24 16:05:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fgby2/sanity_check_on_ml_build/,Sanity check on ML Build,"My boss has asked me to spec out an LLM build for him since I have PC-building experience. We want to do fine-tuning and querying of open-source models (such as Flacon 7b, but we are very much still exploring models). He said my budget is $10k.

&#x200B;

&#x200B;

[PCPartPicker Part List](https://pcpartpicker.com/list/QQ3gn6)

|Type|Item|Price|
|:-|:-|:-|
|**CPU**|[AMD Ryzen 9 7950X 4.5 GHz 16-Core Processor](https://pcpartpicker.com/product/22XJ7P/amd-ryzen-9-7950x-45-ghz-16-core-processor-100-100000514wof)|$551.51 @ Amazon|
|**CPU Cooler**|[Deepcool AK620 68.99 CFM CPU Cooler](https://pcpartpicker.com/product/9T92FT/deepcool-ak620-6899-cfm-cpu-cooler-r-ak620-bknnmt-g)|$63.99 @ Amazon|
|**Motherboard**|[Asus ROG STRIX B650-A GAMING WIFI ATX AM5 Motherboard](https://pcpartpicker.com/product/Gjt9TW/asus-rog-strix-b650-a-gaming-wifi-atx-am5-motherboard-rog-strix-b650-a-gaming-wifi)|$222.99 @ Newegg|
|**Memory**|[Corsair Vengeance 128 GB (4 x 32 GB) DDR5-5600 CL40 Memory](https://pcpartpicker.com/product/HKn9TW/corsair-vengeance-128-gb-4-x-32-gb-ddr5-5600-cl40-memory-cmk128gx5m4b5600c40)|$439.99 @ Amazon|
|**Storage**|[Samsung 980 Pro 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive](https://pcpartpicker.com/product/f3cRsY/samsung-980-pro-2-tb-m2-2280-nvme-solid-state-drive-mz-v8p2t0bam)|$138.00 @ Amazon|
|**Video Card**|[NVIDIA Founders Edition GeForce RTX 4090 24 GB Video Card](https://pcpartpicker.com/product/BCGbt6/nvidia-founders-edition-geforce-rtx-4090-24-gb-video-card-900-1g136-2530-000)|$1999.99 @ Amazon|
|**Video Card**|[NVIDIA Founders Edition GeForce RTX 4090 24 GB Video Card](https://pcpartpicker.com/product/BCGbt6/nvidia-founders-edition-geforce-rtx-4090-24-gb-video-card-900-1g136-2530-000)|$1999.99 @ Amazon|
|**Case**|[Fractal Design Torrent ATX Mid Tower Case](https://pcpartpicker.com/product/fv2WGX/fractal-design-torrent-atx-mid-tower-case-fd-c-tor1a-06)|$189.99 @ B&H|
|**Power Supply**|[Corsair AX1600i 1600 W 80+ Titanium Certified Fully Modular ATX Power Supply](https://pcpartpicker.com/product/cJbwrH/corsair-1600w-80-titanium-certified-fully-modular-atx-power-supply-cp-9020087-na)|$609.99 @ Newegg|
|*Prices include shipping, taxes, rebates, and discounts*|||
|**Total**|**$6216.44**||
|Generated by [PCPartPicker](https://pcpartpicker.com) 2023-10-24 12:03 EDT-0400|||

&#x200B;

H100s and A6000 GPUs were out of the question due to price. I opted for 2 4090s due to their memory capacity and performance, especially with 8-bit, a 7950x for the cores, and maxed out the RAM.

The only hesitation I have is whether the second GPU will work in the bottom PCIe slot, but I think it should even though it's only wired at x4. I read that PCIe lanes don't matter as much, but I just wanted to check. Having a GPU in the bottom slot disables the third M.2 slot, which isn't really a problem as I'll just use the other ones.

My ML experience is pretty novice so I wanted to check with those with more experience. Is this a half-decent build? Thank you all for your time.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fgby2/sanity_check_on_ml_build/,4,1,1.0,"[Comment(id='k6copti'), Comment(id='k6cxbm8'), Comment(id='k6dpkqo'), Comment(id='k6h4lqc')]"
17eisx4,RandomForests92,,2023-10-23 12:07:34+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17eisx4/i_created_the_repository_with_links_to_top_ai/,"I created the repository with links to top AI, LLMs, CV, or NLP resources | The link is in the comment",,learnmachinelearning,https://i.redd.it/lyxdc9cg0yvb1.png,19,169,0.96,"[Comment(id='k63eta1'), Comment(id='k63g84y'), Comment(id='k64ddq9'), Comment(id='k63kr7z'), Comment(id='k63s3ma'), Comment(id='k63wy3j'), Comment(id='k64z45n'), Comment(id='k65d9l3'), Comment(id='k65ob1z'), Comment(id='k66k8ay'), Comment(id='k67zatx'), Comment(id='k685w3f'), Comment(id='k669qi2'), Comment(id='k693wqx'), Comment(id='k6ja0lu'), Comment(id='k6s3091'), Comment(id='k63h8p7'), Comment(id='k64eozw'), Comment(id='k65vmdb')]"
17fapun,ahmedbesbes,,2023-10-24 11:39:01+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17fapun/llm_hallucinations_what_are_they_how_to_quantify/,LLM hallucinations - What are they? How to quantify them? How to avoid them?,,learnmachinelearning,https://thetechbuffet.substack.com/p/llms-hallucinations,0,2,1.0,[]
17fcpdu,not_spider-man_,,2023-10-24 13:22:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17fcpdu/hyperparameters_while_running_model_on_gpu/,Hyperparameters while running model on GPU," I   am training a cyclegan using pytorch and shifted the model to GPU(gtx   1650). But i do not see much use of the gpu, i am not getting the   output(image) to be as clear as when i was running it on cpu. Should i   change the hyperparameters like the learning rate, batch size while   running the model on gpu?

If not what mistake am i doing?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17fcpdu/hyperparameters_while_running_model_on_gpu/,9,0,0.5,"[Comment(id='k69s3lo'), Comment(id='k694r3i'), Comment(id='k69nwy9'), Comment(id='k69zvfd'), Comment(id='k6at95z'), Comment(id='k698fa6'), Comment(id='k6atg73'), Comment(id='k6asuht'), Comment(id='k69apj0')]"
17f1ozb,FallMindless3563,,2023-10-24 02:04:33+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17f1ozb/how_to_run_llama2_on_cpu_after_finetuning_with/,How to run Llama-2 on CPU after fine-tuning with LoRA,,learnmachinelearning,https://blog.oxen.ai/how-to-run-llama-2-on-cpu-after-fine-tuning-with-lora/,0,7,0.9,[]
17f8ohy,4ndy45,,2023-10-24 09:24:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17f8ohy/making_a_receipt_parser/,Making a receipt parser,"My goal is to create something like splitwise, where I could upload any restaurant receipt, and parse the text using cv, from phone or computer. I’m a huge ML noob and would appreciate some pointers into which type of models I should study, training tips, and how to put in production on say a mobile app, or website. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17f8ohy/making_a_receipt_parser/,1,2,1.0,"[Comment(id='k68d4su'), Comment(id='k6ba799')]"
17f95j8,Emotional-Fox-4285,,2023-10-24 10:00:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17f95j8/are_there_any_libraries_which_has_implementation/,Are there any libraries which has implementation of tms-Net sampling.,"I am trying to implement a paper and the paper use tms-Net sampling (combination of Jittered sampling and Latin HyperCube sampling) for preprocessing. However, I couldn't find any library which implement it. 

&#x200B;

I also try implementing by myself but couldn't as my data is num\_data, num\_dimension.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17f95j8/are_there_any_libraries_which_has_implementation/,0,1,1.0,[]
17f8qlj,Existing_Guard_4505,,2023-10-24 09:28:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17f8qlj/factor_influencing_adoption_intention_of_chatgpt/,Factor Influencing Adoption Intention of ChatGPT,"Hello,

&#x200B;

I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.

&#x200B;

Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.

&#x200B;

If you are interested in learning more about the study, please follow the link below. 

&#x200B;

[https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link)

&#x200B;

Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17f8qlj/factor_influencing_adoption_intention_of_chatgpt/,0,1,1.0,[]
17esdlo,Rough-Equal-2288,,2023-10-23 19:11:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17esdlo/looking_for_python_mlai_buddy/,Looking for python ML/AI buddy," Hi guys, im looking for a ML/ai buddy to do projects with and just get better at the subject. I just had an idea for a project and I wanted some help with it. im in EST so I rather someone from that time zone but anyone is welcome. I am a self taught pythonist with more than 3 years python experience and 6 months ML experience. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17esdlo/looking_for_python_mlai_buddy/,34,13,0.88,"[Comment(id='k65h5av'), Comment(id='k65h8ys'), Comment(id='k66490p'), Comment(id='k6ejolr'), Comment(id='k65j1tc'), Comment(id='k65v9ce'), Comment(id='k66w56l'), Comment(id='k676z01'), Comment(id='k67d15f'), Comment(id='k67fmjz'), Comment(id='k682836'), Comment(id='k68hw9v'), Comment(id='k69x39u'), Comment(id='k6a2oyo'), Comment(id='k6axfjh'), Comment(id='k6bra8h'), Comment(id='k6c798p'), Comment(id='k6g1nbl'), Comment(id='k6woe8l'), Comment(id='k65havu'), Comment(id='k664a8t'), Comment(id='k65jal3'), Comment(id='k65jksk'), Comment(id='k65vdy9'), Comment(id='k67tlci'), Comment(id='k67ttnr'), Comment(id='k67tx99'), Comment(id='k67twtv'), Comment(id='k682a48'), Comment(id='k68jh85'), Comment(id='k6a1is0'), Comment(id='k67u6rd'), Comment(id='k65n8mc'), Comment(id='k682bq7')]"
17euy59,peyott100,,2023-10-23 20:59:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17euy59/log_regression_for_prediction/,Log regression for prediction.,"So I plan on creating a project using ML if possible. 

I am a sophomore in my university. I have been researching ML use in the realm of illegal ongoings. 
 
I have been looking at literature like this.

Do Machine Learning Methods Outperform Traditional Statistical 
Models in Crime Prediction? A Comparison Between Logistic 
Regression and Neural Networks 
Chongmin Na a
, Gyeongseok Oh b
, Juyoung Song c
, Hyoungah Park d


I have foundations in linear regression and data pipelines already. 

This article comes to find that for my uses that logistic regression on its own is comparable or better than ML. 

So what should I go doing to structure my prediction data model. I want it to be live and active and accurate. And to predict my independent variable given previous time, locations, and other predictive variables.

So I'm thinking of either attempting a logistic log model or if ML then Neural Network. What's best for this application?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17euy59/log_regression_for_prediction/,7,6,1.0,"[Comment(id='k65yrp6'), Comment(id='k661083'), Comment(id='k661t9b'), Comment(id='k66tagw'), Comment(id='k66z325'), Comment(id='k68yr9j'), Comment(id='k69kyp5')]"
17emgho,FutureTraining3516,,2023-10-23 15:01:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17emgho/how_to_keep_progressing_in_ml_should_i_quit_my/,How to keep progressing in ML? Should I quit my current job?,"Currently a junior ML ""engineer"". Been working for 4 months and had no prior experience with ML. From my job all they really told me to use was YOLOv8. I am just generating datasets for them and sometimes train models. They told me they will teach me but they don't. Only help me if I have questions but my questions are related to what I know anyway. **They tell me I need to do my own research. How to do that? Are there good tutorials or docs? All I find on youtube is some very basic stuff that shows annotating by hand which is absolutely absurd.**  
I am in love with ML and I know it has many fields. **So thanks to anyone who can share their experience and where their learned from :)**",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17emgho/how_to_keep_progressing_in_ml_should_i_quit_my/,27,16,0.83,"[Comment(id='k64772d'), Comment(id='k64so4d'), Comment(id='k65v884'), Comment(id='k68t57a'), Comment(id='k672i2w'), Comment(id='k67ra0g'), Comment(id='k666zxz'), Comment(id='k667clz'), Comment(id='k68abh7'), Comment(id='k666pol'), Comment(id='k667is0'), Comment(id='k6icwyd'), Comment(id='k680sr8'), Comment(id='k68ag5f'), Comment(id='k66p7tx'), Comment(id='k67sfmt'), Comment(id='k68ac4y'), Comment(id='k69zluq'), Comment(id='k6io1l1'), Comment(id='k68f55e'), Comment(id='k6b1apy'), Comment(id='k680o7v'), Comment(id='k680kj6'), Comment(id='k6abll5'), Comment(id='k6e8xlf'), Comment(id='k693rju'), Comment(id='k6b32st'), Comment(id='k6hwcui'), Comment(id='k6dfsmu')]"
17eqy3t,Most-Let-5792,,2023-10-23 18:10:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17eqy3t/a_fast_genetic_algorithm_application/,A Fast Genetic Algorithm Application,"Here is a Genetic algorithm implementation in C++. It can also transmit its genetics to the next generations. I'm thinking of combining this with the Nerve artificial neural network that I coded before and am still developing. Another idea of mine is to take advantage of this genetic transfer when cleaning and organizing data. It's a simple application and I've also added the Python version to make it useful for everyone.  


[https://github.com/fkkarakurt/gencrack](https://github.com/fkkarakurt/gencrack)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17eqy3t/a_fast_genetic_algorithm_application/,1,9,1.0,[Comment(id='k6a5bi6')]
17f4spe,rdpGuy,,2023-10-24 04:50:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17f4spe/is_it_worth_learning_mlai_stuff_out_of_fomo_or/,Is it worth learning ML/AI stuff out of FOMO or should I learn it when I know I need to?,Granted that you're a full-stack web developer?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17f4spe/is_it_worth_learning_mlai_stuff_out_of_fomo_or/,2,0,0.5,"[Comment(id='k68gx5v'), Comment(id='k6bbrdj')]"
17exnhx,KahnHatesEverything,,2023-10-23 22:52:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17exnhx/testing_the_new_threadripper/,Testing the new Threadripper,"Gamers Nexus has just sent out a request as to how to test performance of the newest Threadripper chips.  I'm hoping this reddit community might have some ideas.  I love the idea of a physics simulation, or nth nearest neighbor algorithm, or some other interesting machine learning tools that aren't the normal go to tests (as those have probably already been optimized for by AMD.)  I'd like to see ONE test that takes a long time that would work well for a Threadripper.  


Apologies for just joining to ask this question.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17exnhx/testing_the_new_threadripper/,0,2,1.0,[]
17esdyl,AvvYaa,,2023-10-23 19:11:30+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17esdyl/an_overview_of_the_50_major_nlp_concepts_of_the/,An overview of the 50 major NLP concepts of the last 10 years building from first principles,,learnmachinelearning,https://youtu.be/uocYQH0cWTs,1,4,0.83,[Comment(id='k65k7p1')]
17ev6pq,isameer920,,2023-10-23 21:08:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ev6pq/is_there_a_good_resource_to_learn_how_to_work/,Is there a good resource to learn how to work with DICOM files?,"I am building a project with AI that involves working with CT scans. The dataset I have is in DICOM format and I need to run a segmentator on it. What would be the best approach to go about doing this and where can I learn more about working with DICOMs. I downloaded some apps to open up the files so I can view them and get a feel for what I was working with but they are all pretty rudimentary, or don't even work. The ones that work can't open multiple slices of the same CT and show now metadata at all.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ev6pq/is_there_a_good_resource_to_learn_how_to_work/,6,2,1.0,"[Comment(id='k66uzmt'), Comment(id='k67rwqr'), Comment(id='k67xpjn'), Comment(id='k69kj42'), Comment(id='k684jzb'), Comment(id='k6857e1')]"
17ehejb,PubliusMaximusCaesar,,2023-10-23 10:43:56+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ehejb/a_beginners_guide_to_deploying_tensorflow_models/,A Beginner’s Guide to Deploying Tensorflow Models on AWS Lambda (Free-Tier),,learnmachinelearning,https://shindeshu.github.io/posts/cloud/lambda.html,2,14,1.0,"[Comment(id='k63bc8v'), Comment(id='k63gf6c')]"
17eqebl,gungkrisna,,2023-10-23 17:47:09+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17eqebl/knn_accuracy_vs_k_overfitunderfitideal/,"KNN Accuracy vs K, Overfit/Underfit/Ideal?","Based on this Accuracy vs K, best K for my KNN model is 53. The score for train: 0.799, and test: 0.806. Is it ideal, underfit, or overfit? Any idea about this plot?",learnmachinelearning,https://i.redd.it/slfm08c9pzvb1.jpg,4,3,1.0,"[Comment(id='k68wkor'), Comment(id='k67v30z'), Comment(id='k68uzch'), Comment(id='k68o47z')]"
17eq5xz,Spitefulsalamander,,2023-10-23 17:36:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17eq5xz/image_captioning_models/,Image Captioning Models,"Hello everyone,  
I am currently trying to find suitable image captioning and visual question answering models to implement in my project. After a quick google search I came across BLIP2 from hugging face however, its a very large model overall and both my pc and colab could never load its lightest pretrained version. Does anyone know any similar pretrained models for the specific tasks or any other way to load this kind of large model? (I tried loading it with 8bit precision which still failed)  
I have 16gb of RAM and the task requires image captioning and the ability to ask the model details about the specific image.  
Any help is greatly appreciated!! ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17eq5xz/image_captioning_models/,3,2,1.0,"[Comment(id='k698cv1'), Comment(id='k69abk3'), Comment(id='k77mpko')]"
17eta7t,Rough-Equal-2288,,2023-10-23 19:49:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17eta7t/look_for_python_mlai_buddys/,Look for python ML/AI buddys," Hi guys, im looking for a ML/ai buddy to do projects with and just get better at the subject. I just had an idea for a project and I wanted some help with it. im in EST so I rather someone from that time zone but anyone is welcome. I am a self taught pythonist with more than 3 years python experience and 6 months ML experience. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17eta7t/look_for_python_mlai_buddys/,0,1,1.0,[]
17et7or,bitch_ass_university,,2023-10-23 19:46:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17et7or/is_my_training_legit_with_a_learning_curve_like/,Is my training legit with a learning curve like this?,"&#x200B;

[Learning curve](https://preview.redd.it/z972tkox90wb1.png?width=386&format=png&auto=webp&s=4d9019d5902029c5893d65902ae075fc7d1e8aca)

I trained a classifier with 10 epochs using a CNN architecture. However, the accuracy (""learning"") graph looks like in the picture above: It goes up and down all the time and then at epoch 8 it finally stabilizes and gets in the right point. This model gave me 96% of accuracy for the test set but there's something that concerns me and that is, why does this graph look like this? What's the reason for that and should I consider my model as a ""good"" model for my case, since it hit a 96% accuracy for the test set but has an accuracy  graph like this? Also, do you think that if I decide to release my research into a paper, would an accuracy graph like this be an automatic no-no for the paper?  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17et7or/is_my_training_legit_with_a_learning_curve_like/,5,1,0.67,"[Comment(id='k65h714'), Comment(id='k671pn6'), Comment(id='k67rnia'), Comment(id='k69az3s'), Comment(id='k65i1gd')]"
17exehl,indusop,,2023-10-23 22:42:03+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17exehl/just_read_the_fascinating_article_about/,Just read the fascinating article about deployment of website using streamlit.How easy it has become to deploy and develop any website using this tool,,learnmachinelearning,https://medium.com/@harshsmj1504/ipl-win-predictor-easy-streamlit-development-and-deployment-guide-bce15bce99b1,0,0,0.25,[]
17emlxl,Formal-Future-4408,,2023-10-23 15:08:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17emlxl/how_do_you_use_the_roc_curve_in_ensamble/,How do you use the ROC curve in ensamble tree-based machine learning models like XGBoost?,"As far as I know, if you want to use the ROC curve in a binary classification problem, you need to have a probabilistic classification method like the logistic regression, so you can vary the threshold and you will have a curve of models that varies in specifivity and sensitivity.

&#x200B;

 However, I don't know how to this in let's say, XGBoost in sk-learn because it doesn't even have sense to me because as far as i know, XGBoost clasfifier is not probabilistic. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17emlxl/how_do_you_use_the_roc_curve_in_ensamble/,0,2,1.0,[]
17ep0nl,Open_Lavishness_4130,,2023-10-23 16:48:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ep0nl/is_tortoise_tts_just_not_compatible_with_m1_macs/,Is Tortoise TTS just not compatible with m1 macs?,"I was up the entire weekend trying to download it on an m1 MacBook Pro. I never got anywhere. There were too many errors to count, and when I finally managed to generate something, it did not even save the file, and then when I closed the prompt it deleted everything I had previously installed.

Is this like a problem with the code? Is it incompatible with M1 macs? I’ve seen a lot of people I stall it and run it flawlessly, but not me nor my dad who is a computer programmer with an MD in computer science were ever able to install it. Am I missing something? Does it only run on nvidia GPU with Windows? Wha is happening?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ep0nl/is_tortoise_tts_just_not_compatible_with_m1_macs/,0,0,0.5,[]
17eokyu,swodtke,,2023-10-23 16:29:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17eokyu/creating_an_ml_scenario_in_sap_data_intelligence/,Creating an ML Scenario in SAP Data Intelligence Cloud to Read and Model Data in MinIO,"Enterprise customers use MinIO to build data lakehouses to store a wide variety of structured and unstructured data, and work with it using ML and analytics. Data flows into MinIO from across the enterprise and the S3 API allows applications, such as analytics and AI/ML to work with it.  

[https://blog.min.io/ml-scenario-sap-data-intelligence-cloud/?utm\_source=reddit&utm\_medium=organic-social+&utm\_campaign=ml\_scenario\_sap](https://blog.min.io/ml-scenario-sap-data-intelligence-cloud/?utm_source=reddit&utm_medium=organic-social+&utm_campaign=ml_scenario_sap)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17eokyu/creating_an_ml_scenario_in_sap_data_intelligence/,0,1,1.0,[]
17env6f,BenAhmed23,,2023-10-23 16:00:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17env6f/dissertation_help/,Dissertation Help,"Dear r/learnmachinelearning

I'm in need of a dissertation idea (for my undergraduate course), ideally  it'd be Computer Vision related / something to do with programming  languages (with ML of course), does anyone have any ideas. It should  include implementing a one (or more) papers and then extending them as  well. I have a reasonable amount of compute available and the  dissertation should take up a few months of my time.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17env6f/dissertation_help/,0,1,1.0,[]
17enjw7,tdionis,,2023-10-23 15:47:03+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17enjw7/best_bounding_box_image_annotation_tools_for/,Best Bounding Box Image Annotation Tools For Object Detection - Complete Overview - Supervisely,,learnmachinelearning,https://supervisely.com/blog/bounding-box-annotation-for-object-detection/,0,0,0.5,[]
17emook,ledmmaster,,2023-10-23 15:11:11+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17emook/how_to_get_feature_importance_in_logistic/,How To Get Feature Importance In Logistic Regression,,learnmachinelearning,https://forecastegy.com/posts/feature-importance-in-logistic-regression/,0,0,0.5,[]
17emgzg,Formal-Future-4408,,2023-10-23 15:02:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17emgzg/where_can_i_find_a_dataset_to_test_different/,Where can I find a dataset to test different tree-based models both for regression and binary classification?,"Hello.

I have to do a project for college and I've decided to do it about machine learning and in particular in tree-based model. I want the core to be how more complex methods (like extreme gradient boost) outperform the most basic ones (like simple trees or random forest).

I would like one dataset of tabular data (not images or audios)  that is suitable to be used by tree based models. Plus, I want to prove it both for regression and binary classification on the same dataset so that way I avoid doing twice the exploratory analysis but I can't find any in kaggle set.

I've thought taking one dataset whose target variable is numerical and then binning it in two parts, so that way I can have a regression model and a binary classification one. The problem is also that I don't know how to split it optimally.

Can someone give me a helping hand?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17emgzg/where_can_i_find_a_dataset_to_test_different/,0,1,1.0,[]
17el00q,Dayymin,,2023-10-23 13:56:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17el00q/which_framework_and_model_is_best_for_multiobject/,Which Framework and Model is Best for Multi-Object Detection Tasks on Low Power Devices in 2023?," **TL;DR: What are the best frameworks and models for real-time multi-object detection on a low-power device in 2023?**

I'm starting a project requiring multi-object detection and/or segmentation. While I've had some experience with PyTorch for single-object classification and TensorFlow for basic object detection as tests, the landscape for multi-object detection seems vast and a bit daunting and the ones tailored for single-board computers (I could find) are comparatively uncommon.

I'd like to make an informed choice about the most suitable framework and model, especially given the specifics of my task and available hardware.

**Project Details:**

* Goal: Multi-object detection and, if possible, segmentation.
* Data: Images with 3-6 different object classes. Real-time  
segmentation is a bonus but not mandatory.
* Input: Live webcam feed aiming for >20 FPS inference.
* Dataset: Self-annotated with Label Studio for bounding boxes.
* Available Hardware for Inference:
   * Rockchip RK3588: 6 Tops (INT4/INT8/INT16/FP16).
   * 2x Google Edge TPU: 2x4 Tops(INT8) (Supports TensorFlow Lite).

Given that the Google Edge TPU supports TensorFlow Lite (and understanding that models from various frameworks can be converted to TensorFlow and then to TensorFlow Lite)

**Which framework and model would be most strategic to invest time in learning and implementing for a SBC in 2023?**

The information during my research was quite contradicting and a lot of repositories seem inactive. From my own search, I came to the result that MobileNetV3 with SSD or an older Yolo version would be a possible approach but as my knowledge about machine learning is quite limited therefore I cannot make an informed decision.

It's crucial for me to have access to comprehensive and high-quality documentation. I also prefer solutions that don't require extensive low-level implementation. Specifically, I'm not comfortable with manipulating input and output layers or defining custom loss functions. Therefore, at this stage, I'd like to avoid extensive customization of the models I use.

As an example of performance, [Edge-Yolo ran with 30FPS on an RK3588](https://www.mdpi.com/2076-3417/13/7/4402), this level of performance would be perfect for my application.

Extra Questions:

1. Dual Model Approach: I'm considering running two separate models. One on the SBC for real-time object detection and another on the Edge TPUs for object segmentation. Does this make sense?
2. Annotation Software Compatibility: I've used Label Studio for annotations, but its export format didn't seem directly compatible with TensorFlow. Which annotation tool would be most seamless for the recommended framework/model? Ideally, I'd like something self-hostable.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17el00q/which_framework_and_model_is_best_for_multiobject/,1,1,1.0,[Comment(id='k65agpu')]
17ekeuc,Emily-joe,,2023-10-23 13:27:52+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ekeuc/neural_networks_a_deep_dive_into_ais_building/,Neural Networks: A Deep Dive into AI's Building Blocks,,learnmachinelearning,https://www.artiba.org/blog/neural-networks-a-deep-dive-into-ais-building-blocks,0,1,1.0,[]
17ejqet,qhelspil,,2023-10-23 12:56:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ejqet/alpha_vantage_api_to_get_financial_statements_in/,alpha vantage api to get financial statements in specific date,"i have the premium API, and they say i must get data up to +20 years, but thats not clear in their documentation [here](https://www.alphavantage.co/documentation/#:~:text=url%20%3D%20%27https%3A//www.alphavantage.co/query%3Ffunction%3DBALANCE_SHEET%26symbol%3DIBM%26apikey%3Ddemo%27)

    
     url = f'https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={ticker}&apikey={api_key}'

if someone knows how can i get the data for income\_statement between years ie 2014 and 2018, please let me know

thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ejqet/alpha_vantage_api_to_get_financial_statements_in/,0,1,1.0,[]
17ejjry,Dizzy-Condition1879,,2023-10-23 12:46:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ejjry/statistical_machine_translation_for_thesis_paper/,Statistical Machine Translation for Thesis paper,Hello Everyone! I have no idea where to begin on how to code a statistical machine translation for our thesis. Where can I find an articles or researches about statistical machine translation with source code? I am eager to learn about this topic. Thank you!,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ejjry/statistical_machine_translation_for_thesis_paper/,0,1,1.0,[]
17e7hhy,AvvYaa,,2023-10-23 00:19:47+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17e7hhy/neural_attention_one_simple_example_that_explains/,Neural Attention - One simple example that explains everything you need to know,,learnmachinelearning,https://youtu.be/frosrL1CEhw,0,7,0.82,[]
17ecco7,firewhiskey_addict,,2023-10-23 04:41:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ecco7/want_to_learn_how_to_code/,Want to learn how to code,"Hey guys
Looking for some advice
Im an intern at a really big and reputed company (sorry cant name it) and i joined 2 months ago. I’ve been given tasks to make machine learning models for the company use cases. And although they same easy to understand in theory, when i go through the codes required to build the model itself, i get lost and confused. It’s been really tough to get on with the tasks as in college we were only taught to build basic models without any dependencies. Any suggestions on how i can start to learn coding at the industry level? All the Udemy courses are very academically inclined and although they are helpful in understanding the basics they are not very helpful in coding for work. Please help im really struggling. I really want to perform well and get a permanent job at this company.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ecco7/want_to_learn_how_to_code/,3,2,0.67,"[Comment(id='k62hvpw'), Comment(id='k62nrpc'), Comment(id='k6fjoga')]"
17drbyo,UpvoteBeast,,2023-10-22 11:38:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17drbyo/looking_for_resources_to_learn_llm_in_depth/,Looking for Resources to Learn LLM in depth,"I have some background in deep learning (e.g. ML courses, training ranking and classification models), but I’m looking for resources (blogs, videos, podcasts, courses) to learn more about LLMs. Are there any resources that you’d recommend?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17drbyo/looking_for_resources_to_learn_llm_in_depth/,5,42,0.96,"[Comment(id='k5ye77s'), Comment(id='k5zolb9'), Comment(id='k5ytutc'), Comment(id='k600hub'), Comment(id='k60vty3')]"
17e0tj0,TheFappingWither,,2023-10-22 19:14:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17e0tj0/how_to_train_an_ai_on_your_imagesfor_complete/,how to train an ai on your images(for complete beginner)?," 

i have about 103,000 images copyrighted and owned by me, and i wanna train an image generator to make similar ones, how to do it? i looked for guides on loras on youtube but they use terms i dont know and there r prerequisites im missing...

also there are a lot of prople using only generators, some also using photoshop. some are using multiple ones and some single ones. some mention files some don't. i don't get most of it... im pretty tech savy if i do say so myself, but this is new to me and most of the terms used make sense but are alien to me.

if you know any vids that can help me start then link those too, thank you.

do note im completely new to this and have only used websited before so maybe kid gloves.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17e0tj0/how_to_train_an_ai_on_your_imagesfor_complete/,7,8,0.79,"[Comment(id='k60vr3j'), Comment(id='k62294p'), Comment(id='k62rnew'), Comment(id='k60un2u'), Comment(id='k62n3oc'), Comment(id='k62v86w'), Comment(id='k63bu5r')]"
17duiw2,fbeilstein,,2023-10-22 14:28:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17duiw2/introduction_to_machine_learning_l6_mathematical/,"Introduction to Machine Learning (L6, Mathematical Optimization)"," Hello everyone!

This year I'm trying to record my ""Introduction to ML"" course in English. Maybe, it will be of any use for anyone.

[Lecture 6, Mathematical Optimization](https://www.youtube.com/watch?v=HNrAjs6QqiY)

Previous lectures: [Lecture 1, Introduction](https://www.youtube.com/watch?v=MxZULf38HRU), [Lecture 2, Python](https://www.youtube.com/watch?v=_IBdjLg-W6I), [Lecture 3, NumPy](https://www.youtube.com/watch?v=jJGiC_ccPg8), [Lecture 4, Pandas](https://www.youtube.com/watch?v=dKWPi5PfuEQ), [Lecture 5, MatPlotLib](https://www.youtube.com/watch?v=LkY3qyhq6Q8)

All course materials: [GitHub](https://github.com/fbeilstein/machine_learning)

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17duiw2/introduction_to_machine_learning_l6_mathematical/,1,7,1.0,[Comment(id='k63udc1')]
17dzbw6,Twygg,,2023-10-22 18:06:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dzbw6/question_how_to_build_a_dataset_for_nlptext/,[Question] How to build a Dataset for NLP/Text Generation,"Hi, there are a lot of great pre-trained text generation models and datasets out there. Mostly on huggingface or github. I would like to add some special informations to one of them (fine tuning). How can I build a dataset from some scientific papers and books, to add these informations and knowledge to an existing dataset?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dzbw6/question_how_to_build_a_dataset_for_nlptext/,0,3,1.0,[]
17e6i1q,Lazy_Week_6957,,2023-10-22 23:31:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17e6i1q/d_college_with_a_reading_disability/,[D] College with a reading disability,"

Help! I am 25 years old. I have a decent job, but I don’t even make 40K a year. I want to attend college so I can get a better job and make more money. However, I am afraid my learning and reading disability with affect that and I’m not smart enough for college. Any success stories?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17e6i1q/d_college_with_a_reading_disability/,2,1,0.67,"[Comment(id='k61kahv'), Comment(id='k63rvpc')]"
17e1jp3,Rough-Sun1126,,2023-10-22 19:47:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17e1jp3/need_help_currently_a_hs_sophomore/,Need help [currently a Hs Sophomore],"So I am currently a sophomore in HS and was looking to start on with a passion research project thingy, can you guys give me some cool ideas that i can work on (i know python really well, biology is a bit meh",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17e1jp3/need_help_currently_a_hs_sophomore/,2,0,0.5,"[Comment(id='k60lbiu'), Comment(id='k64fnie')]"
17dr7c9,CkmCpvis,,2023-10-22 11:30:24+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17dr7c9/dinov2_breakdown_ive_created_a_visual_guide_to/,DINOv2 Breakdown: I've Created a Visual Guide to the Model's Design & a Concise Code Walkthrough,,learnmachinelearning,https://youtu.be/Pa2yTy48JA8?si=kJofpcBIjPNgopCG,0,3,0.81,[]
17dyqyl,Wow_we,,2023-10-22 17:40:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dyqyl/end_to_end_project_in_ml_dl_cv/,"End to end project in ML, DL &CV","Hi guys, I want to make project end to end could anyone provide ideas/reference for it? I am trying to build project portfolio for work show case. till now I worked for company project only no git repo of my own present.

if you give reference to follow or ideas it would be really helpful.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dyqyl/end_to_end_project_in_ml_dl_cv/,9,1,1.0,"[Comment(id='k5zxe4x'), Comment(id='k63pbgk'), Comment(id='k63yzua'), Comment(id='k640bti'), Comment(id='k640jh9'), Comment(id='k641dtr'), Comment(id='k640z5e'), Comment(id='k6448p2'), Comment(id='k653j2b')]"
17dt3a2,Choice_Shopping1170,,2023-10-22 13:18:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dt3a2/extracting_prices_from_a_the_website/,Extracting prices from a the website framebridge.com per size,"Hi,

I would like to extract, from the website [framebridge.com](https://framebridge.com), a list of all their frames and the prices of each frame per its different sizes. What AI can I use? Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dt3a2/extracting_prices_from_a_the_website/,1,2,1.0,[Comment(id='k5zq1ii')]
17dl1bw,tujiserost,,2023-10-22 04:22:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dl1bw/built_it_for_my_project_at_first_memorybaseio/,Built it for my project at first: Memorybase.io supercharges ChatGPT with memory capabilities for your chatbots,"Hey everyone!

I've been delving deep into chatbots lately, especially with the ChatGPT API, and I found an issue that's probably familiar to many of you: ChatGPT doesn't inherently have memory capabilities. For many applications, that's perfectly fine, but for those of us who are trying to create a more context-aware and dynamic conversation flow, this limitation is quite apparent.

I faced this challenge in one of my projects and realized that there had to be a better way to integrate context and memory into ChatGPT's conversations. So, I built something for myself which I thought might be useful for many of you as well. Allow me to introduce you to [**Memorybase.io**](http://memorybase.io/).

Memorybase is a developer-friendly API that's designed to seamlessly integrate memory functionality into the ChatGPT API. By harnessing the power of the Pinecone vector database and LangChain, Memorybase wraps around the ChatGPT API and ensures that the right context and memory are injected into each query. This means that your chatbot can remember previous interactions, preferences, or any other context that's relevant for more engaging and meaningful conversations.

Imagine a user asking your chatbot about movie recommendations. The next day, they come back and reference that conversation, expecting the bot to remember. With Memorybase, that continuity becomes possible. The user experience improves manifold, and the possibilities for more sophisticated and context-aware bots increase tremendously.

I originally built Memorybase for my own needs. But the more I used it, the more I realized that this could have broader applications. Any developer looking to leverage the ChatGPT API could potentially benefit from the enhanced memory and context capabilities. From customer support bots to interactive storytelling, the potential use cases are vast.

This technology stack (pinecone/langchain) is not complex or ‘new’ per se, but for application developers who aren’t interested in managing it or hosting it, this could be a useful hassle-free option for your projects.

I've set up a page over at [memorybase.io](https://memorybase.io/) where you can learn more about how it works and see if it aligns with your needs. I would love for you to check it out and share your thoughts. Your feedback, insights, and potential use cases would be invaluable as I continue to refine and expand the capabilities of Memorybase.

Thanks for reading, and I'm eager to hear your thoughts and see where Memorybase can fit into the exciting world of chatbots!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dl1bw/built_it_for_my_project_at_first_memorybaseio/,17,9,0.77,"[Comment(id='k5xpae8'), Comment(id='k60wr2y'), Comment(id='k5xfl5u'), Comment(id='k5xpfxa'), Comment(id='k5yy5hr'), Comment(id='k60bbkv'), Comment(id='k61y3z1'), Comment(id='k5y2otc'), Comment(id='k5zlwe1'), Comment(id='k640fup'), Comment(id='k5zmcei'), Comment(id='k5zme5t'), Comment(id='k5zmj28'), Comment(id='k640kc4'), Comment(id='k6402v8'), Comment(id='k5zlyrm'), Comment(id='k642mz9')]"
17dsn8n,oniongarlic88,,2023-10-22 12:55:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dsn8n/i_know_supervised_unsupervised_ml_i_want_to_learn/,I know supervised / unsupervised ML. I want to learn RL in Python. What are free online / Youtube courses you recommend?,"I learn better from those that has examples and show / explain how it was made. If possible, ones that explain through Python. Like PPO, he/she states what is it, and then he/she codes a PPO implementation solving for a specific problem. 


(yes, i know math is inevitable, i dont mind the math part. I am hoping for more of Python coding part).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dsn8n/i_know_supervised_unsupervised_ml_i_want_to_learn/,0,1,0.6,[]
17dj3tv,dreadeye6,,2023-10-22 02:32:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dj3tv/applying_to_grad_school_python_foundation/,Applying to grad school (python foundation),"Hi guys. 
I'm about to start applying to a few graduate programs on the path to becoming a machine learning engineer. I'm particularly interested in deep learning and ai as it relates to healthcare. 

I'm a physician in my 40s. I've been practising for about 20 years now. I have zero formal computer science education or work experience. I've been using the book Crash Course in Python to teach myself Python and doing a mathematics for machine learning specialization certificate in coursera. It covers linear algebra, multivariant calculus and stats and probability. 

While I acknowledge my applications to these programs are long shots, I want to get myself as covered as I can. I want to have a certificate of some form of Python training on my applications but a bit unsure of where to look. 
I'm using 2023 edition of Crash Course in Python and worry about doing courses that are outdated and might contradict some of what I'm learning. 

Any recommendations for courses in Python that are not only good but relatively up to date? 
Do I even need to do a certificate course? Would posting projects from the book along with a few of my own projects on github be enough to include in my applications? 

Thanks in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dj3tv/applying_to_grad_school_python_foundation/,21,5,0.78,"[Comment(id='k5y6pwp'), Comment(id='k5x2hu7'), Comment(id='k5ypbll'), Comment(id='k61kj1p'), Comment(id='k5xcjkg'), Comment(id='k5xgzrw'), Comment(id='k5yqoli'), Comment(id='k5x3lq0'), Comment(id='k5xrfym'), Comment(id='k5zpzn3'), Comment(id='k5yqfsp'), Comment(id='k5xef8q'), Comment(id='k5xh5ac'), Comment(id='k5z7tvr'), Comment(id='k5yr83v'), Comment(id='k60ddj5'), Comment(id='k5zdvtw'), Comment(id='k5yrx49'), Comment(id='k5zf7oy'), Comment(id='k5yym1q'), Comment(id='k5z6azr')]"
17do2cv,metaldad2020,,2023-10-22 07:47:22+00:00,False,,1697961656.0,False,True,False,/r/learnmachinelearning/comments/17do2cv/new_tech_with_old_tech_question_for_llm_machine/,New tech with old tech question for LLM machine build,So I'm looking to do a llm machine on a budget and the 3060 12 GB of RAM is a relatively inexpensive card.  on top of that I came across the p40 GPU accelerator so my question is would a 3060 12 GB of RAM be compatible with SLI chain to a p40 or does it need to remain within the Pascal framework of graphics cards?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17do2cv/new_tech_with_old_tech_question_for_llm_machine/,0,2,1.0,[]
17dm3vu,Used-Ad147,,2023-10-22 05:31:01+00:00,False,,1697953148.0,False,True,False,/r/learnmachinelearning/comments/17dm3vu/curious_about_ddpm_sinusoidal_positional/,Curious about DDPM sinusoidal positional embedding code,"&#x200B;

[https:\/\/nn.labml.ai\/diffusion\/ddpm\/unet.html](https://preview.redd.it/ad7zmvwnvovb1.jpg?width=1052&format=pjpg&auto=webp&s=598e27176766d22e886a7f95c80b9cd42342853e)

Hi.

i study about the DDPM(Denoising Diffusion Probabilistic Models). And i found that the sinusoidal positional Time embedding which is same as the Transformer model have to be added to U net architecture.

So i search and found related code.

in here, i'm curious about 

1) why embedding should be divide (half\_dim-1) not half\_dim.

&#x200B;

2) t\[:, None\] \* emb\[None, :\] is the correct dimension code in the 4th row in above img?

if t tensor shape is (batch\_size,1) and embedding shape is (half\_dim), then t\[:, None\] shape is \[batch\_size, 1, 1\] and  emb\[None, :\] shape is \[1, half\_dim\]. the result shape is \[batch\_size, 1, half\_dim\] will be deduced. However, i doubt this results is fine with that

&#x200B;

It will be very helpful to explain these questions.

Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dm3vu/curious_about_ddpm_sinusoidal_positional/,0,3,1.0,[]
17d67ph,shil-Owl43,,2023-10-21 16:19:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17d67ph/how_to_start_learning_machine_learning/,How to start learning machine learning,"I am a backend developer with 20 years of experience. I have worked in different industries. My primary coding languages are Java, python and golang. I want to learn machine learning. Is there a recommended path for newbies? Do I need to brush up mathematics, statistics before starting programming? Please suggest beginner friendly books, tutorials.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17d67ph/how_to_start_learning_machine_learning/,10,15,0.82,"[Comment(id='k5uw5q0'), Comment(id='k5v6twt'), Comment(id='k5xqane'), Comment(id='k5y9jat'), Comment(id='k5vj79d'), Comment(id='k5vydfj'), Comment(id='k5x3s2g'), Comment(id='k5xc1t6'), Comment(id='k5vyefg')]"
17di2zt,lukepoga,,2023-10-22 01:37:59+00:00,False,,1697939031.0,False,True,False,/r/learnmachinelearning/comments/17di2zt/no_simple_c_neural_network_library_supporting_gpu/,No simple c# Neural Network library supporting GPU?,"I have tried [ML.Net](https://ml.net/), Onnx, Sianet

Cant find any machine learning library where I can build a network like this below, specify what weights I want and just Evaluate it on gpu

&#x200B;

https://preview.redd.it/spq8hhzcrnvb1.png?width=419&format=png&auto=webp&s=7b7cff9367539fb368e9157dc38d21081e01ce04

guy here 3 years ago was doing it himself because he had the same problem [https://www.reddit.com/r/dotnet/comments/jy9o61/why\_not\_build\_a\_deep\_learning\_library\_for\_net5/](https://www.reddit.com/r/dotnet/comments/jy9o61/why_not_build_a_deep_learning_library_for_net5/)

The closest I can find is [Accord.Net](https://accord.net/) from 2017, and it works perfectly but its CPU only.

&#x200B;

https://preview.redd.it/rqav51g7rnvb1.png?width=743&format=png&auto=webp&s=87da689d9721d092bc9a544448c8395e71d581ee

so simple to define a network like above. All these other libraries cant seem to do this basic need.

&#x200B;

1. Design my graph
2. Specify my own weights
3. Push to gpu.
4. Evaluate the result given an input.

They seem to all want to interfere in the above at one of these 4 steps. most of the libraries you cant even define a model, you have to import it from tensorflow for example. which is crazy to me.

10 years ago I was writing my own interop c code to talk between cuda and c# but i thought we advanced from that a decade ago. surely i dont have to do this from scratch a decade later.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17di2zt/no_simple_c_neural_network_library_supporting_gpu/,6,1,0.57,"[Comment(id='k5x1mt3'), Comment(id='k5x1z23'), Comment(id='k5x8h79'), Comment(id='k63h7lx'), Comment(id='k5y44l7'), Comment(id='k5zygz6')]"
17cx4yb,Blutorangensaft,,2023-10-21 07:33:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cx4yb/take_my_math_to_the_next_level/,Take my math to the next level,"I finally secured a job in AI, but it will take some time untill I can start. In the meantime, I have about two months available for self-study. I already have a degree in artificial intelligence, but I'm not a 100% satisfied with the math I know. In particular, I would like to be able to easily read proofs and understand very technical machine learning papers. Are there any maths or machine learning texts that I should consider studying?


For background, the maths I know so far:
Calculus and multivariate calculus, linear algebra, introductory probability, and inferential statistics. I also have implemented many projects in AI, mostly using neural networks. The course load focusing only on these kind of projects amounts to a bit more than 2200 hours.


I was thinking about some advanced probability class perhaps and another one about proofs. Maybe a machine learning text like ""foundations of machine learning"" by Mohri or ""Machine Leaning - A probabilistic Perspective"" by Murphy might also be a good idea.


What do you think?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cx4yb/take_my_math_to_the_next_level/,23,39,0.95,"[Comment(id='k5tfp5f'), Comment(id='k5v8m3x'), Comment(id='k5tlw07'), Comment(id='k5vrue4'), Comment(id='k62qp1s'), Comment(id='k5vszge'), Comment(id='k62gf0s'), Comment(id='k5tsbt4'), Comment(id='k5u0pw2'), Comment(id='k5tngk7'), Comment(id='k5tueaw'), Comment(id='k5uoihm'), Comment(id='k5w3pb2'), Comment(id='k5weukm'), Comment(id='k5vo03h'), Comment(id='k5voeib'), Comment(id='k5vs1yx'), Comment(id='k61tfvf'), Comment(id='k5w4mil'), Comment(id='k5w4t6h'), Comment(id='k5wnvgn'), Comment(id='k5vvvco')]"
17dc6xd,yCuboy,,2023-10-21 20:55:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dc6xd/ideas_for_a_master_thesis_on_machine_learning_and/,Ideas for a master thesis on machine learning and distributed systems?,"Hello,

I am looking for some inspiration, my work is mainly implementing serverless pipelines using faas and i want to mix machine learning with distributed systems somehow. I work as a ""researcher"" but i would say at the moment, my work is glue code with python.

I have read a bit about deep speed, pytorch rpc, FSDP and some papers about training models using serverless. Anyone could help me with a topic that mixes both worlds? Something that i could propose to my advisor and maybe a new line of research?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dc6xd/ideas_for_a_master_thesis_on_machine_learning_and/,8,2,1.0,"[Comment(id='k5y38rf'), Comment(id='k5wfkf7'), Comment(id='k5vt4ba'), Comment(id='k5xxqr9'), Comment(id='k5xyjz6'), Comment(id='k5wxwwy'), Comment(id='k5w1j9j'), Comment(id='k5y4a1j')]"
17dbbx2,Puddino,,2023-10-21 20:14:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17dbbx2/bishop_machine_learning/,Bishop machine learning,"I'm a computer scientist and I'm starting my master in artificial intelligence.
One of the first courses is in machine learning.
I'm studying with the Bishop.
I get the ideas and reasoning of the things that I've seen so far, however I'm no mathematician an I had to skip the second chapter because it was a little bit too convoluted on the math side.
I feel like I'm missing a lot by not understanding the mathematical details, is there an introductory book I should read as a computer scientist ?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17dbbx2/bishop_machine_learning/,6,2,0.75,"[Comment(id='k5w4r1a'), Comment(id='k5z4ric'), Comment(id='k5x59ex'), Comment(id='k5y0ui7'), Comment(id='k5y0y1b'), Comment(id='k5zwn0c')]"
17depq3,DwaywelayTOP,,2023-10-21 22:48:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17depq3/investing_time_in_learning_everything_about_llm/,Investing time in learning everything about LLM?,"I want to be as updated as I can on the basics of the world that is coming. I am starting CS studies in October, but I am knees deep in everything AI right now. Do you think there is much sense in learning prompt engineering, LLM, NLP etc. ? Doing interns in Prompt Engineering? I dropped out of uni I was studying design oriented major but didn't enjoy it. Now I work and save for next year, study and make projects with AI as much as I am able to, of course, and just basically update myself and condition myself to what's coming.  
My question is: 1. Do you find that valuable (99% will probably say yes, but still)  
2. Any tips on what to do, focus on, guides, info, etc.

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17depq3/investing_time_in_learning_everything_about_llm/,1,1,0.67,[Comment(id='k5w7wb7')]
17cma9u,General_Service_8209,,2023-10-20 21:40:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cma9u/some_things_i_learned_about_gan_training/,Some things I learned about GAN training,"For several months now, I've been working on a adversarial network that takes synthetic audio as input and enhances it to sound more natural. I know that this is different from the usual way you would use a GAN, which would be passing noise as input to the generator, turning it into a generative network.

But I still think a lot of the things I learned during this project, especially about training stability, can be applied to other GANs, which is why I'm making this post!

&#x200B;

First of all, a GAN consists of two networks - a ""generator"" and a ""discriminator"". For training, you will need a dataset of what you want your network to generate.

The discriminator is a binary classifier that aims to distinguish between samples from the dataset and samples constructed from noise by the generator. The generator, on the other hand, is trained to fool the discriminator as best as possible. So the loss for the discriminator is BCELoss(discriminator(data), 1) + BCELoss(discriminator(generator(noise)), 0), and the loss for the generator is MSELoss(discriminator(generator(noise)), 1). You can use different loss functions, but these are the most common ones.

However, this approach immediately causes problems. If the discriminator works too well, any changes the optimizer can make to the generator in one training step won't have a significant effect on the labels assigned by the discriminator. This causes the gradient of the generator to shrink and eventually vanish, preventing it from being trained further. On the other hand, if the generator pulls too far ahead, the easiest strategy for the discriminator that still improves its score will be to assign 0.5 to all inputs it receives - real or generated. Again, this prevents the generator from being trained further. For successful training, the network needs to be tuned to maintain an equilibrium between the two fail states, which is really hard to do.

The most common way to get around this is called Wasserstein loss. Instead of using fixed labels, this loss function aims to maximize the difference between the numbers assigned to real and generated samples. The loss for the discriminator becomes: discriminator(data) - discriminator(generator(noise)), and the loss function of the generator is simply: discriminator(generator(noise)). Because there are no fixed labels, the discriminator will always push the values it assigns to real and generated samples apart as far as possible, leaving room for the generator to lower the gap again by decreasing the number assigned to generated samples. This means that no matter how far the discriminator outpaces the generator, the generator gradient will never collapse and training will always continue. This also makes it trivial to avoid the generator outpacing the discriminator - without an equilibrium to worry about, the discriminator can simply be made so powerful that this never happens.

**Always use Wasserstein loss. It is vastly superior to a ""traditional"" GAN, and its advantages far outweigh the drawbacks.**

&#x200B;

However, the Wasserstein loss has the problem that if the discriminator is ahead of the generator (as it should be) simply multiplying all its weights by a given factor is going to widen the gap between the scores of real and generated samples. So without intervention, the weights of the discriminator will diverge infinitely. There are three common methods to solve this problem: weight clipping, spectral norm, and gradient penalty.

Weight clipping is the most straightforward one - all weights that surpass a certain threshold get clipped back to that threshold. However, this method can slow down training quite a bit since it has the potential to cause information loss when a lot of weights run up against the limit in the same layer and all get clipped to the same weight.

Spectral norm can be thought of as ""soft weight clipping"". It takes all weights of a layer and normalizes them as a whole. So you can, for example, have a few large weights and a lot of small ones, or only medium weights, or anything in between. It also fully prevents weight divergence, but interferes a lot less with training. However, it is computationally slightly more expensive than weight clipping, and a lot of implementations require additional memory.

Finally, gradient penalty is the go-to method for preventing divergence of Wasserstein GANs. I won't get into the details here, but basically it is an additional term added to the discriminator loss function that penalizes gradients that would create too large weights. So it approaches the problem a step earlier than the other two methods. It has the smallest impact on training, but also numerous disadvantages. First, the additional loss term requires an additional full forward and backward pass through the discriminator, making it the computationally most expensive method by far. Second, it relies on calculating the gradient of the gradient of the network. This ""dual differentiation"" is not supported for a number of types of layers in frameworks like PyTorch or Tensorflow. Most notably, you can't use it for RNNs and layers derived from them, like LSTMs. Also, gradient penalty is not actually guaranteed to prevent the weights from diverging - it only nudges the network into that direction, with the impact depending on how the additional loss term is weighted compared to the normal Wasserstein loss function.

**To prevent Wasserstein GANs from diverging, Gradient penalty is generally the best in my experience, despite its many flaws. But should it fail to prevent the network from diverging, I'd recommend switching to spectral norm instead of pushing the weight of the gradient penalty higher and higher.**

&#x200B;

Now we get to the interesting part - deep GANs.

Really deep GANs (over 32 layers for the discriminator and generator each in my case) have a new set of problems. First, there's the usual vanishing gradient problem, which can be solved in the usual ways (for example using ReLU or another rectifier as NLA function instead of Sigmoid or other logistic functions, applying Kaiming initialization to the weights before training or adding residual connections), so I'm not going to dwell on this.

Second, a deep discriminator network lowers the efficiency of gradient penalty to the point where it becomes almost useless on its own. In my experience, spectral norm is the better way to go for deep networks, but it can be supported by additionally adding gradient penalty, and good old L2/weight decay regularization helps as well. To get a good value to set the L2 regularization to, monitor how much the weights are diverging. It should roughly be exponential, so you can calculate the growth factor for each sample. Take the n-th root of that number, with n being the number of layers the discriminator has, subtract 1 from the result, and you've got your value.

Finally, a deep discriminator can reintroduce the problem the Wasserstein loss tries to solve. With increasing layer count, it can model increasingly complex functions and eventually, these functions can feasibly include plateaus or strong local minima. If the discriminator scales better with increasing layer count than the generator, the generator output can by chance end up in such a region. This starts a vicious cycle. The nearly flat region only provides a smaller gradient to the generator, slowing its training down. The discriminator registers this as something positive, which reinforces its behavior, making the plateau even flatter or local minimum even deeper. Eventually, this causes the generator training to come to a complete stop.

This issue had me stumped for several weeks, but I eventually figured out two potential ways to solve it. The first is not training the entire discriminator at the same time, and instead slowly adding layers to the ""training pool"" and removing the ones that have already been in the pool the longest. This doesn't lower the capacity of the network, but since not all layers can adapt at the same time, this makes it much less likely for plateaus to form. The second method is called FARGAN and was introduced by two Chinese scientists. From a given batch of generated samples, you take the one with the best score, i.e. the one that the discriminator thinks is the most real, and add it to the next batch of real samples as if it was real. This forces the discriminator to form a gradient between the best generated sample and the other generated samples, which again makes it less likely for a plateau to form that includes all the generated samples. I've had less success with this method than with the first one, but it also worked reliably for networks where the problem wasn't too intense, and it slowed down training less as well.

&#x200B;

Finally, let's go over how to make a GAN transform one kind of data into another.

In my case, the goal was to transform audio into better sounding audio, but GANs have also been used to turn satellite images into street maps, for example. To do this, you normally pass input data into the generator instead of noise, and then add an additional term to the generator loss that makes it stay close to its input: generator\_loss = discriminator(generator(input)) + MSELoss(generator(input), input). The weight of this additional term is important, because setting it too low will make the AI ignore large parts of the input, and setting it too high will make it stick to the input too closely instead of actually modifying it.

For my GAN, I got much better results, by adding a threshold to the loss: generator\_loss = discriminator(generator(input)) + max(MSELoss(generator(input), input), threshold) So the generator is allowed to deviate from the input by a certain amount without being penalized. Setting it to 0.1 worked the best.

&#x200B;

Sorry that this post has gotten a bit rambley. Maybe I'll write all of this down in a proper form sometime and do all the testing to validate it for a wider variety of GANs. But when working on my network, I was extremely frustrated by the lack of resources about the topic. All tutorials seems to stop at explaining Wasserstein loss, and research papers are often too specific to be applicable. So I hope maybe someone in a similar situation will find this post, and will find part of it useful. If that is you (or if you are working on any other ML project for that matter) - Good luck!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cma9u/some_things_i_learned_about_gan_training/,18,92,0.98,"[Comment(id='k5szisf'), Comment(id='k5sur7w'), Comment(id='k5t7zcx'), Comment(id='k5uyac3'), Comment(id='k5tvh8a'), Comment(id='k5tx08t'), Comment(id='k6058ed'), Comment(id='k60zxv1'), Comment(id='k62zngn'), Comment(id='k5uj1ws'), Comment(id='k5ukxs5'), Comment(id='k5ulqt2'), Comment(id='k606x2t'), Comment(id='k60yokp'), Comment(id='k634mt4'), Comment(id='k646hv8'), Comment(id='k64w7zy'), Comment(id='k65h7ml')]"
17d3g62,OnlyProggingForFun,,2023-10-21 14:11:20+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17d3g62/dalle_3_explained_improving_image_generation_with/,DALL·E 3 Explained: Improving Image Generation with Better Captions,,learnmachinelearning,https://youtu.be/Ilu4Nyb5_As,1,4,0.84,[Comment(id='k5u0ab3')]
17db570,Brodusclay25,,2023-10-21 20:05:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17db570/online_machine_learning_river_lib/,Online Machine Learning (River lib),"Hello everyone, has anyone here worked with the library mentioned at https://riverml.xyz/0.19.0/? I'm in the process of developing a real-time machine learning algorithm for a project and could use some guidance and insights.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17db570/online_machine_learning_river_lib/,0,1,1.0,[]
17day4q,EllieLovesJoel,,2023-10-21 19:56:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17day4q/is_this_the_right_place_to_start/,Is this the right place to start?,"Over the last couple years Ive been going on and off with this AI/ML stuff. I know some stuff. But feel like I know nothing. So Im trying to get a fresh start and be serious about this. What I'm planning on taking on is the Andrew Ng ML 3 course Specialization. 

What I wanna know is do I need any prerequisites in the Data Science field? Like theres definitely some data analysis that goes into collecting your data, cleaning, etc. but do those skills really matter when Im beginning this journey or are they acquired once I need them?

Is this specialization a good start for someone that wants to get into the AI/ML field or should I start with something else. Please tell me your thoughts

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17day4q/is_this_the_right_place_to_start/,2,1,0.67,"[Comment(id='k5x9rnk'), Comment(id='k5x9tzc')]"
17cy92a,Intelligent-Math1782,,2023-10-21 08:56:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cy92a/2x_lstm_layer_vs_bidirectional_lstm/,2x LSTM layer vs. Bidirectional LSTM?,"Hey everyone,

I am looking at some code and am struggling to understand the choice of doing 2x LSTM vs. a Bidirectional LSTM.

The code I am looking at is:

    self.word_emb = nn.Embedding(in_dim, emb_dim)
    self.lstm_forward = nn.LSTM(emb_dim, hidden_dim, batch_first=True)
    self.lstm_backward = nn.LSTM(emb_dim, hidden_dim, batch_first=True)
    ...
    # tokenize, <EOS>, <SOS>
    input_forward = [seq2tokens(seq) for seq in Xs]
    input_backward = [seq2tokens(seq, reverse=True) for seq in Xs]
    
    # get embedding from token input
    Xs_forward = self.word_embeddings(input_forward)
    Xs_backward = self.word_embeddings(input_backward)
    
    ...
    # init
    ini_hc_forward = (torch.zeros(1, batch_size, self.hidden_dim),
                      torch.zeros(1, batch_size, self.hidden_dim))
    ini_hc_backward = (torch.zeros(1, batch_size, self.hidden_dim),
                      torch.zeros(1, batch_size, self.hidden_dim))
    
    # compute lstm
    out_forward, _ = self.lstm_forward(Xs_forward, ini_hc_forward)
    out_backward, _ = self.lstm_backward(Xs_backward, ini_hc_backward)
    
    # flatten
    out_forward = out_forward.reshape(-1, self.hidden_dim)
    
    # flatten backward
    idx_b = torch.tensor(list(range(X_len))[::-1])
    out_backward = torch.index_select(out_backward, 1, idx_b)
    out_backward = out_backward.reshape(-1, self.hidden_dim)    
    
    # combine forward and backward
    lstm_out_valid = out_forward + out_backward   

Can the same be achieved with a simpler network definition, something like:

    self.embedding = nn.Embedding(input_dim, embedding_dim)
    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=lstm_layers, bidirectional=True)
    ...
    embedded = self.embedding(X_input)
    lstm_output, (hidden, cell) = self.lstm(embedded)
    lstm_output = lstm_output.view(-1, 2 * self.hidden_dim)

Thanks!

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cy92a/2x_lstm_layer_vs_bidirectional_lstm/,1,5,0.79,[Comment(id='k5tk52z')]
17ctvkh,Stack3,,2023-10-21 03:58:30+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ctvkh/would_this_work/,Would this work?,Sorry for the typos. This is a simple implementation of an idea I had: a Sensorimotor inference engine that can manage any environment/system for you.,learnmachinelearning,https://i.redd.it/ae2qhnnlbhvb1.png,8,18,0.95,"[Comment(id='k5to57c'), Comment(id='k5tnw7u'), Comment(id='k5twp7y'), Comment(id='k5to0ne'), Comment(id='k5xqc2r'), Comment(id='k5zzvjv'), Comment(id='k78proj'), Comment(id='k78sjfj')]"
17d0cel,Ambitious-Pay6329,,2023-10-21 11:20:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17d0cel/question_data_transformation_and_scaling/,[Question] Data transformation and scaling,"I am cleaning a dataset for a (macro-economic) demand forecast, and I'm wondering when one should apply data transformation. When is it recommended to include Box-Cox or Yeo-Johnson, and how should we choose between the two? How does it effect the feature selection or model performance?

Additionally, how should we select the appropriate scaling technique (normalizing, standardizing, min-max) and does the order in which we transform and scale matter for our data?

Is there any recommended literature on this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17d0cel/question_data_transformation_and_scaling/,0,5,1.0,[]
17d3skk,lemacintosh,,2023-10-21 14:27:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17d3skk/how_to_find_right_architecture_for_dl_model_apart/,How to find right architecture for DL model apart from papers and Optuna etc?,"I have used Optuna to find better layer architecture but sometimes this is too slow to be helpful. In other cases, like for CNNs, well known architectures like VGG can do pretty well out of the box. But otherwise, for example I’m working on VAEs right now to recreate MNIST digits. In this case, I am just randomly trying to add more layers and more units and it doesn’t even seem to help that much. Am I really supposed to sit here for hours blindly making changes or are there more intuitive ways to look at learning curves or something to know what direction to take? I know if I’m overfitting I can add regularisation or decrease depth/breadth (and if underfitting do the opposite) but apart from that I am lost.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17d3skk/how_to_find_right_architecture_for_dl_model_apart/,4,2,1.0,"[Comment(id='k5vcakl'), Comment(id='k5vgoq9'), Comment(id='k5vilhs'), Comment(id='k5xsdlt')]"
17d7bod,toughytough,,2023-10-21 17:09:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17d7bod/some_beginner_questions_about_whisper_for/,Some beginner questions about Whisper for transcription,"Hi,

I am a mac user. I am trying to use whisper.cpp downloaded from its github file. I don't know much about phyton or coding so I basically followed [this guide](https://medium.com/gimz/how-to-install-whisper-on-mac-openais-speech-to-text-recognition-system-1f6709db6010) to install and use it. I downloaded the large model to try it. I am using it for non-English languages and I want to use it for language learning purposes so I can understand what is being said in an Instagram story or a Youtube video (without subtitles) or a tv series or an extract of movie etc. I was using Macwhisper but I wanted to try the pro features and I don't want to pay for it (for now) and try the pro models for non-English languages.

My question is: all of my files that I want to transcribe are video files with .mp4 extension. Can I also transcribe those with whisper?

If not, and if I can only transcribe audio files, can it be .mp3? I understand that I need to install and use ffmpeg. Does it support mp3?

Also, as I understand, the transcripted text will appear in the terminal. Can I export it in -srt or pdf?

Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17d7bod/some_beginner_questions_about_whisper_for/,1,1,1.0,[Comment(id='k5yqwtp')]
17dbokh,Ordinary_Craft,,2023-10-21 20:31:02+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17dbokh/data_science_and_machine_learning_basic_to/,Data Science And Machine Learning Basic To Advanced | Udemy Free Course For limited enrolls,,learnmachinelearning,https://webhelperapp.com/data-science-and-machine-learning-basic-to-advanced/,0,0,0.33,[]
17cxzce,Intelligent-Math1782,,2023-10-21 08:35:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cxzce/learning_to_work_with_gans/,Learning to work with GAN's,"Hi everyone,

I saw the recent post on GAN's and want to learn more practically how to work with them. I work in biotech industry and would be interested in just applying it some ""protein families"" without a real application (a protein family is a set of proteins that share common evolutionary origin). So my goal would be select one of these families and then train my GAN on this to generate similar ""looking"" proteins. This has surely been done before but I was wondering about some practical tips that deliver some educational value. So we are talking about sequences composed of 20 different tokens (amino acids) of length maybe 500-1500 depending on the specific family (within each family we have varying length of proteins). I have access to a DGX server with 40gigs of RAM.

So specifically:

* can someone recommend some simpler core layer? (reference: there is ""ProteinGAN"" which uses a core of residual blocks which is quite heavy to compute. I am not after SOTA but just to learn some things here regarding the training). Maybe a 1-layer LSTM for both discrimator and generator?
* Any tips how to do a ""BabyGAN""?

&#x200B;

Thanks!

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cxzce/learning_to_work_with_gans/,0,3,1.0,[]
17czp9j,Euphoric-Chart1428,,2023-10-21 10:39:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17czp9j/rag_on_multilevel_tabular_data/,RAG on multilevel tabular data,"Hi, Has anyone done RAG on a multi level tabular data? If yes then what problems have you faced and how did you solve those? My model gives better answers when I converted the data to a JSON and then embedded it. But I'm looking for a better approach.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17czp9j/rag_on_multilevel_tabular_data/,0,2,1.0,[]
17d2zaj,Good-Mention-5859,,2023-10-21 13:48:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17d2zaj/adam_a_digital_assistant_manager/,A.D.A.M (A Digital Assistant Manager)," I am currently working on a digital assistant manager (A.D.A.M) several functions currently depend on either AI21 or Cohere for text generation the functions are: generate\_autobiography(user\_profile, bot\_profile), analyze\_sentiment\_and\_emotion(final\_input, bot\_profile, user\_profile), determine\_bot\_feelings(common\_emotions, analysis\_result, user\_name, bot\_name), generate\_emotional\_greeting(user\_profile, bot\_profile, audio\_input), generate\_personal\_response(final\_input, bot\_profile, user\_profile), handle\_question(final\_input, user\_profile), interpret\_command\_with\_gpt(command), generate\_useful\_commands(system\_info), get\_command\_description(command, system\_info), and the generate\_and\_add\_command(user\_profile, command, description, system\_info). i am looking for anyone with the experience and resources to train and host custom models tuned specifically to perform each task im also open to any suggestions for improvements to the script here is a link for anyone interested or just curious but be warned its fairly complex and im sure it still needs tweaked and cleaned up in a few places i am still testing [https://pastebin.com/LenpNMxp](https://pastebin.com/LenpNMxp) ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17d2zaj/adam_a_digital_assistant_manager/,0,1,0.67,[]
17d1qq2,lectis1,,2023-10-21 12:44:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17d1qq2/can_anyone_help_me_out_with_anaconda_packages_for/,Can anyone help me out with anaconda packages for tensorflow?,"I've been trying to install the most up-to-date tensorflow version on anaconda on arch limux.

But I've Been trying this for the past few days. something somewhere always goes wrong. (One line of code down the line just dosent work somewhere, or the whole tf package may not even import, when I try to fix it by updating the tensorflow package )

If anyone has a working anaconda tf environment that is upto date. Id be very grateful if you could list the packages your useing and what version. 

I've tried both pip and conda install. I've also tried the anaconda gui (but those packages seem out of date)
Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17d1qq2/can_anyone_help_me_out_with_anaconda_packages_for/,3,0,0.33,"[Comment(id='k5wuo35'), Comment(id='k5xmk0r'), Comment(id='k5xn2t2')]"
17cy4v9,Total-Opposite-8396,,2023-10-21 08:47:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cy4v9/need_some_practical_advice_on_choosing_from/,Need some practical advice on choosing from different CNN model architectures.,"Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also covered a little Neural Style Transfer. 

 I am now looking forward to build some projects. Most probably on object detection and image classification. After consuming all of the stuff that I mentioned above, I am confident enough that I can build an application in the real world, though I still have a few questions and need to talk to someone who can channel my thoughts in the right direction.  

If you could give me just a rough overview of how you approach a computer vision problem that'll be great. Especially, when you see a computer vision problem to solve, how do you make decision on which architecture to choose from to solve a given problem at hand. Since there are many architectures and research papers and every architecture works in a unique way to solve unique problems, how do you know which one to choose from? How do you make your way down from 100s of options to choose from, to a few where you can then start experimenting with those few options? Just need some practical advice on approaching an object detection or image classification problem.

Also, there might be some knowledge gaps that I have, I feel like I have em, but I don't know what I don't know at this point. So, I just need someone who can maybe channel me in the right direction.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cy4v9/need_some_practical_advice_on_choosing_from/,2,2,0.75,"[Comment(id='k5uptwu'), Comment(id='k5xg5bh')]"
17c9qml,Albert_Gajsak,,2023-10-20 12:07:33+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17c9qml/we_teamed_up_with_nasa_to_launch_a_toy_that/,We teamed up with NASA to launch a toy that teaches AI and coding,,learnmachinelearning,https://www.reddit.com/gallery/17c9qml,9,82,0.84,"[Comment(id='k5oyjde'), Comment(id='k5onbe2'), Comment(id='k5ogdmf'), Comment(id='k5ohbqs'), Comment(id='k5pxa53'), Comment(id='k5oufn7'), Comment(id='k5pwak1'), Comment(id='k5pbyiz'), Comment(id='k5sppkt')]"
17cm1s8,grokcomputer,,2023-10-20 21:30:40+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17cm1s8/langchain_in_60_seconds/,LangChain in 60 seconds,,learnmachinelearning,https://www.youtube.com/watch?v=iGYYAGfevvo,2,14,1.0,"[Comment(id='k5t4i4g'), Comment(id='k5tzp29')]"
17cq0ib,1strategist1,,2023-10-21 00:34:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cq0ib/what_would_cause_loss_to_steadily_decrease_then/,What would cause loss to steadily decrease then suddenly become nan with no spike?,"I'm trying to train a neural network with basically mean squared error loss. I'm using Keras and Tensorflow if that's relevant. I have about 70 M training samples split into mini-batches of roughly 16000 samples. The first 295 mini-batches, the loss steadily decreased from ~4.3 to ~3.5. Then for no apparent reason, the loss became nan, and stayed nan for the rest of the training. 

I've looked into this before, and often times it's because the loss suddenly starts growing due to exploding gradients or a learning rate that is too large. Usually this is preceded by the loss suddenly spiking, **then** becoming nan though, which I didn't observe here. My learning rate also started at 0.00001, so I don't think the learning rate being too large is the issue. 

I've also checked over my training data, and there are no nans or infs in the data, so that's not the issue. 

Does anyone have any other suggestions for where to look to solve this issue?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cq0ib/what_would_cause_loss_to_steadily_decrease_then/,10,8,1.0,"[Comment(id='k5t46u5'), Comment(id='k5t5y53'), Comment(id='k5s8plm'), Comment(id='k5sa5fq'), Comment(id='k5s8xxi'), Comment(id='k5sc83z'), Comment(id='k5saaq7'), Comment(id='k5scs2b'), Comment(id='k5scsf9'), Comment(id='k5sdhee')]"
17cyl0f,deletedmfs,,2023-10-21 09:20:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cyl0f/how_to_flag_documents_submitted_to_insurance/,How to flag documents submitted to insurance companies where customers ask for reimbursements after making minor changes to the same prescription..,"I want to solve a problem where fraudulent customers who produce the same prescription/invoice to insurance companies after making minor changes to the invoice like the logo and colour or the positioning of text. how do i solve this problem?  
should i use doc2vec or siamese neural network?

note that my solution should be able to handle large volumes of data with less processing time....",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cyl0f/how_to_flag_documents_submitted_to_insurance/,0,1,1.0,[]
17cszxr,I_will_delete_myself,,2023-10-21 03:07:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cszxr/is_it_normal_for_ppo2_to_converge_on_lunar/,Is it normal for PPO2 to converge on Lunar landers under a minute?,"Don't know if it's a implimentation error that turn out super well, but some reason it's converging in under 2 minutes. Is this normal for PPO or is it just coincidence?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cszxr/is_it_normal_for_ppo2_to_converge_on_lunar/,3,2,0.76,"[Comment(id='k5sc0er'), Comment(id='k5sc904'), Comment(id='k5sdylo')]"
17ce7un,igorsusmelj,,2023-10-20 15:40:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ce7un/labelformat_a_python_package_for_converting/,Labelformat - A python package for converting computer vision label formats,"🚀 Introducing Labelformat: The Ultimate Label Format Converter!

🤔 The Pain Point: Ever struggled with the myriad of label formats out there? Labelbox, COCO, KITTI, YOLOv8... Every tool seems to have its own convention, making it a nightmare to switch or integrate different datasets. We spent hours internally writing scripts to convert from one format to another. So we just decided to build a solution and make it open source.

🌟 The Solution: Labelformat! An open-source tool that seamlessly converts between popular label formats. 
Check out our GitHub: https://github.com/lightly-ai/labelformat

Features
- Support for common dataset label formats (more coming soon)
- Support for common tool formats (more coming soon)
- Minimal dependencies, targets python 3.7 or higher
- Memory conscious - datasets are processed file-by-file instead of loading everything in memory (when possible)
- Typed
- Tested with round trip tests to ensure consistency
- MIT license

Get started using ‘pip install labelformat’


We would love to get your feedback!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ce7un/labelformat_a_python_package_for_converting/,0,9,0.92,[]
17cpg0h,Reddit-1-account,,2023-10-21 00:06:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cpg0h/tokenize_text_with_inconsistent_spaces/,Tokenize Text with Inconsistent Spaces?,"I'm scratching my head trying to tokenize unstructured text to do named entity recognition on. Input text looks like ""Starbucks CofNew York"" or ""Racetracgasconv Seattle"". For proper NER tagging, Cof would need to be a separate token than New York and Racetrac would need to be a separate token than gasconv.

Has anyone dealt with a consistent way to do this? Of course, I can try to tokenize based on English words or locations, but because the data is so diverse (and not always English words, like Cof), I'm struggling to see how this can be reliable.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cpg0h/tokenize_text_with_inconsistent_spaces/,2,2,1.0,"[Comment(id='k5t0wer'), Comment(id='k5zr39m')]"
17ch31a,crono760,,2023-10-20 17:47:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ch31a/do_better_embedding_models_actually_improve_rag/,"Do ""better"" embedding models actually improve RAG or KNN searches?","I've been getting pretty decent performance out of the basic all-MiniLM-L6-v2 (the default embedding model that comes with ChromaDB and seems to be recommended by many getting started tutorials). Now, sometimes the results are weird or I have to search for the top 10 rather than the top 3 or something to get a close enough match to do RAG. I know there are other embedding models out there, so I'm wondering - does a ""better"" model actually perform better for relevance based retrieval? I'm talking about not fine tuning anything, purely out of the box performance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ch31a/do_better_embedding_models_actually_improve_rag/,1,7,1.0,[Comment(id='k5y654f')]
17byhv9,art_luke,,2023-10-20 00:45:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17byhv9/pytorch_course_focused_on_best_practices_and/,PyTorch course focused on best practices and coding - not on ML theory/background,"Most tutorials, videos and courses teach PyTorch by explaining the ML theory and then coding up the model architecture, etc. 

I already know the theory and instead want to focus on the PyTorch best coding practices, common bugs and mistakes, etc. What would be a good tutorial for learning PyTorch for someone who wants to focus on just the coding? 

From another angle, my question could be: What would be a good PyTorch tutorial for someone who already knows some other ML framework and therefore is quite familiar with all the concepts involved?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17byhv9/pytorch_course_focused_on_best_practices_and/,24,59,0.96,"[Comment(id='k5omq90'), Comment(id='k5nzsr2'), Comment(id='k5n1f0z'), Comment(id='k5nuu9s'), Comment(id='k5qvurz'), Comment(id='k5o4x5k'), Comment(id='k5povz2'), Comment(id='k5t3ozs'), Comment(id='k5v9ba9'), Comment(id='k5pr83f'), Comment(id='k5nn8yz'), Comment(id='k5o6s5u'), Comment(id='k5o5xka'), Comment(id='k5wsv3j'), Comment(id='k5o6f29'), Comment(id='k5okn9t'), Comment(id='k5r5wny'), Comment(id='k5r5juc'), Comment(id='k5pk6au'), Comment(id='k5olghu'), Comment(id='k5tb1fc'), Comment(id='k5qes10'), Comment(id='k5qt36o'), Comment(id='k5qzk26'), Comment(id='k5r2x1y')]"
17cgmjk,yotobeetaylor,,2023-10-20 17:26:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cgmjk/noise_issue_after_applying_fastica_to_audio_data/,Noise Issue After Applying FastICA to Audio Data in Python,"I am working on a Python script that separates audio sources from a podcast file using Fast Independent Component Analysis (FastICA) from scikit-learn. After applying FastICA and exporting the separated audio, I am experiencing noise in the output.

&#x200B;

Here's the relevant part of my code:

&#x200B;

    from pydub import AudioSegment
    import numpy as np
    from sklearn.decomposition import FastICA
    
    # Load and preprocess the audio
    audio = AudioSegment.from_mp3('podcast_file.mp3')
    samples = np.array(audio.get_array_of_samples())
    samples = samples.reshape(-1, audio.channels)
    
    # Standardize the data
    standardized_samples = samples.astype('float64')
    standardized_samples /= standardized_samples.std(axis=0)
    
    # Apply FastICA
    ica = FastICA(n_components=audio.channels, tol=0.1, max_iter=500)
    S = ica.fit_transform(standardized_samples)
    
    # Export the separated audio
    # ... (Code for exporting audio)

What I've Tried:

&#x200B;

1. Standardizing the audio data before applying FastICA.
2. Adjusting FastICA parameters such as tol and max\_iter.
3. Despite these adjustments, the noise issue persists.

&#x200B;

Questions:

1. \-What could be causing this noise issue in the separated audio?
2. \-Are there any advanced noise reduction techniques that could be applied to improve the audio quality?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cgmjk/noise_issue_after_applying_fastica_to_audio_data/,0,2,1.0,[]
17clftm,jatinvj-sumba-d-else,,2023-10-20 21:04:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17clftm/mcqs_to_practice_basics/,MCQs to practice basics,Does someone know where i can find tons of mcq type questions to get a refresher on the basics of ML? Preferably with answers as well. I have a quiz coming up and want to practice for it,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17clftm/mcqs_to_practice_basics/,1,1,1.0,[Comment(id='k5sifd7')]
17cktcx,Formal-Future-4408,,2023-10-20 20:36:27+00:00,False,,1697838476.0,False,True,False,/r/learnmachinelearning/comments/17cktcx/does_anyone_knows_where_can_i_find_books_which/,Does anyone knows where can I find books which tells the adventages and disventages of each method?,"Hello

I'm doing a college project on machine learning. I'm looking for references about adventages and disadventages of each machine learning method. Can someone give me a hand?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cktcx/does_anyone_knows_where_can_i_find_books_which/,0,1,1.0,[]
17cc7kt,ahmedbesbes,,2023-10-20 14:10:49+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17cc7kt/how_to_design_a_system_to_chat_with_your_private/,How To Design a System To Chat With Your Private Data,,learnmachinelearning,https://thetechbuffet.substack.com/p/design-a-document-qa-system,0,4,0.83,[]
17cc6v0,ahmedbesbes,,2023-10-20 14:09:54+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17cc6v0/turn_complex_english_instructions_into_executable/,Turn Complex English Instructions Into Executable SQL With LLMs,,learnmachinelearning,https://thetechbuffet.substack.com/p/turn-complex-english-instructions-into-sql,0,2,1.0,[]
17bo926,happybirthday290,,2023-10-19 17:14:17+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17bo926/state_of_the_art_ai_audio_enhancement_noise/,State of the art AI audio enhancement & noise removal!,,learnmachinelearning,https://v.redd.it/irlr72trx6vb1,4,61,0.95,"[Comment(id='k5kk3q3'), Comment(id='k5modb5'), Comment(id='k5mrr6q'), Comment(id='k5nxf7b')]"
17cd1dt,Flat_Interaction2306,,2023-10-20 14:48:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cd1dt/im_new_to_ml_some_advice_you_guys_will_like_to/,Im New to ML some advice you guys Will like to give me,"I am an economics student interested in learning machine learning to apply it to my field of study, I have learned a little about supervised learning and I can run some models. Is there any advice or recommendation about this world?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cd1dt/im_new_to_ml_some_advice_you_guys_will_like_to/,0,1,0.6,[]
17cbvmp,ML-NOW,,2023-10-20 13:55:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17cbvmp/what_is_regularization_in_machine_learning/,What is Regularization in Machine Learning?,"Regularization is a technique used to prevent models from overfitting. This  will make them capture less noise in the data, and better understand the true pattern.

Regularization adds a penalty term to the loss function, which forces the parameters values to be closer to 0. There's 2 main types of regularization: L1, and L2. We add the regularization as a penalty to the loss function, as a sum of the model's parameters.

L1 uses the sum of the absolute values, whereas L2's sum uses the square of the model's parameters. Both force the model's parameters to be smaller, by making the model try to make this sum lower.

We can control the amount of regularization via the Regularization Strength λ (lambda). A higher value of λ results in more regularization, and therefore a more simple model. A smaller value of λ means less regularization, or a more complex model.

A linear regression that uses L1 regularization is called a Lasso model, and one that uses L2 is called Ridge. Elastic Net uses both.

As always, the goal is to find the optimal amount of complexity to not Overfit, not Underfit, and find the best model!

...

I hope that helps! Consider checking out [mlnow.ai](https://mlnow.ai) if you're learning this stuff :)

https://preview.redd.it/h1gistr65dvb1.png?width=430&format=png&auto=webp&s=b17cc530e492594e4316b56fb26b54dfa6bda984",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17cbvmp/what_is_regularization_in_machine_learning/,0,0,0.5,[]
17caq4v,Jonathan_x64,,2023-10-20 13:00:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17caq4v/how_to_perform_image_object_separation_from/,How to perform image object separation from scratch?,"Dear friends, please advise me:

I have about 6000 very similar images with big object on a white background (sometimes with some shadow outline), where I have to remove background and make it transparent. On \~4000 of them, I was able to run [rembg](https://github.com/danielgatis/rembg#models) with model isnet-general-use with great success, but it failed on \~2000 similar images, producing incorrect results (because of pure white patches within objects).

I want to train a neural network to remove background from images on this dataset of 4000 successful images. I have sources that are pngs with white backgrounds, and results that are pngs with transparent background + small halo around object (which I quite like, btw). They are in 5K resolution but can be downscaled, of course.

And then use that trained network with rembg to deal with rest of images that need to be processed. Which seems to support custom models (see set... part in readme), but I have no idea how to work with onnx file format and all that stuff.

I have tried search engines and one of popular LLMs to explain concepts to me, but I still fail to comprehend the basics.

Please kindly help me with more details on what should be done:

* Can I use PNGs with transparent images directly? 
* If not, is there a graceful automated way to create masks out of transparent pngs? I believe ImageMagick can do that, but I have no idea what kind of mask is needed.
* How to start training model afterwards?
* And how to export it — what is the onnx encoder and onnx decoder? 

Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17caq4v/how_to_perform_image_object_separation_from/,0,1,1.0,[]
17c0def,No-Neighborhood9724,,2023-10-20 02:18:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17c0def/application_of_classical_time_series_and_deep/,Application of classical time series and deep learning on multivariate time series data for forecasting the US unemployment rate.,"If you are looking to develop business domain knowledge while working on developing your machine learning & data science skills, you might find this four part blog series useful. In this blog I discuss how to use classical time series and deep learning to forecast the US unemployment rate. Even though significant advancements have been made in deep learning architectures, the federal reserve (the US government agency that produces macroeconomic forecasts) continues to use classical time series methods. These do a  good job of handling equilibrium of financial and economic variables over a long time and offer many other advantages over deep learning models.  This blog was based on a talk I gave at the American Statistical Association in Pittsburgh, PA in 2022. And this talk was a multivariate extension of a univariate analysis and modeling done by the Federal Reserve using recurrent neural network architectures.  Hope you enjoy reading.

Here is the link to part 1.

[https://www.thefractal.co/p/multivariate-time-series-forecasting-and-analysis-of-the-us-unemployment-rate-part-1-f1454b029cb](https://www.thefractal.co/p/multivariate-time-series-forecasting-and-analysis-of-the-us-unemployment-rate-part-1-f1454b029cb)

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17c0def/application_of_classical_time_series_and_deep/,1,6,1.0,[Comment(id='k5pkfq9')]
17c8py0,imjustreallystupid,,2023-10-20 11:09:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17c8py0/struggling_to_figure_out_how_to_use_pennylane/,Struggling to figure out how to use Pennylane with Google Colab,"I am a beginner at machine learning, and am having some issues setting up a library with Google Colab. I have very little experience with both machine learning and using quantum circuits, and could be missing something basic here.

As part of a research project, I am using the Pennylane library to create a quantum kernel for an SVM. However, it is not possible to run a quantum circuit on Pennylane without first downloading the cuQuantum library by NVIDIA. I have no idea on how to set that up in Google Colab, or whether it is even possible to do so.  Any advice on how to fix these issues?

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17c8py0/struggling_to_figure_out_how_to_use_pennylane/,1,1,1.0,[Comment(id='k6esqvw')]
17c8dok,Feitgemel,,2023-10-20 10:49:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17c8dok/your_face_your_anime_move_together/,"Your Face, Your Anime: Move Together 💫","  

https://preview.redd.it/lrhsqz708cvb1.png?width=5334&format=png&auto=webp&s=feaa13fec3379bf1c69e8c8f7a05c0eafeff84c3

Hi,

🌟 Discover how to make your own anime character move and react just like you. 📸  
   
 This is a nice and fun Python project to make your anime move like your head using real time live camera.  
   
 

Watch this cool Python tutorial video : [https://youtu.be/5yB8U3G4940](https://youtu.be/5yB8U3G4940)

Eran

\#Python #anime ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17c8dok/your_face_your_anime_move_together/,0,0,0.5,[]
17c8d2c,prettyobviousthrow,,2023-10-20 10:48:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17c8d2c/how_to_customize_a_local_llm_for_scientific/,How to Customize a Local LLM for Scientific Pattern Matching?,"My goal is to run a free, local version of a large language model that is specifically trained to be familiar with the contents of a scientific textbook PDF so that it can perform relevant pattern recognition/comparisons. Specifically I want to be able to pass a large list of non-standardized descriptors to be checked against a standardized list of answers and return the closest option from the standardized list for each non-standardized input. This is to facilitate more efficient cataloging that is currently being done completely manually.

Is this feasible? If so, what would be appropriate topics to learn about/steps to take to achieve it? From basic reading I think that freedom gpt, gpt4all, and Llama-2 would be possible options to get started, but I wanted to see if anyone had recommendations to more efficiently direct my focus.

[Here is an example in ChatGPT demonstrating what I'm trying to do...](https://chat.openai.com/share/91427cfe-3a3c-497a-86fc-1f700bdb208f)

**Q:**

Answer options: Red, Blue, Gray

Test options: Cyan, Maroon, Pink, Silver, Blue, Navy, Fuschia, Black, Green

For each Test option, return the Answer option that it is closest to

**A:** 

* Cyan: Blue
* Maroon: Red
* Pink: Red
* Silver: Gray
* Blue: Blue
* Navy: Blue
* Fuchsia: Red
* Black: Gray
* Green: Blue

In my actual use case, ""Answer options"" contains a few hundred items and ""Test options"" has tens of thousands of items.

I have coding experience with C++, Python, and bash in case any of those are useful but my only experience working with local AI models has been with Whisper.cpp and Faster-Whisper. I have no understanding whatsoever about how the various Whisper models were actually generated, but I assume that I would need to generate/modify a model based on my chosen textbook somehow.

Any help/advice would be greatly appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17c8d2c/how_to_customize_a_local_llm_for_scientific/,0,1,1.0,[]
17c829m,jvachez,,2023-10-20 10:30:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17c829m/data_augmentation_software_for_windows/,Data augmentation software for Windows,"Hello !

Is there an easy data augmentation software for Windows ? Like I am selecting 10 images or a directory, the software give me 100 images.

I have found only examples with Python code on the net.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17c829m/data_augmentation_software_for_windows/,1,0,0.5,[Comment(id='k5ohiy4')]
17bozjd,besabestin,,2023-10-19 17:47:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bozjd/is_hosting_a_7b_model_on_cloud_cheaper_than/,is hosting a 7B model on cloud cheaper than accessing openai’s api,"I have few questions related to this. Now that a lot of smaller models are becoming better and accessible, are they getting cheaper for access? llama and mistral models are getting better and also getting more improvements through quantization or better attention techniques.

I was using openai’s models and they cost so low unless you are summarizing tens of pages of pdf files. I am looking at like 20cents of my whole day use.

How are such models actually uploaded on cloud? Are the weights saved in database and stuff? I know there are tools like skyplot but how do they work underneath?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bozjd/is_hosting_a_7b_model_on_cloud_cheaper_than/,19,22,0.89,"[Comment(id='k5laggi'), Comment(id='k5l7vh9'), Comment(id='k5lrui4'), Comment(id='k5kwklg'), Comment(id='k5l95u5'), Comment(id='k5ktdbi'), Comment(id='k5lwenh'), Comment(id='k5lkt3w'), Comment(id='k5lo9sx'), Comment(id='k5mb0wt'), Comment(id='k5mas2p'), Comment(id='k5lyg9i'), Comment(id='k5mdpe5'), Comment(id='k5mdx9t'), Comment(id='k5mez9n'), Comment(id='k5mfja9'), Comment(id='k5mh3w7'), Comment(id='k5mhe3f'), Comment(id='k5mk6kg')]"
17bv9n0,ramyaravi19,,2023-10-19 22:14:12+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17bv9n0/want_to_learn_about_intel_neural_compressor_a/,Want to learn about Intel Neural Compressor: A model compression tool that helps speed up AI inference without sacrificing accuracy? Check out the article.,,learnmachinelearning,https://www.intel.com/content/www/us/en/developer/articles/technical/an-easy-introduction-to-intel-neural-compressor.html,0,8,1.0,[]
17btc3h,ian_agra,,2023-10-19 20:53:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17btc3h/andrew_ngs_courses/,Andrew Ng’s courses,"Hi everyone!

In your opinion, which Andrew Ng's course is more complete: 

- the Machine Learning Specialization available on Coursera; or
- Stanford CS229 Machine Learning course available on https://youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&feature=shared

Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17btc3h/andrew_ngs_courses/,4,7,0.77,"[Comment(id='k5lld8y'), Comment(id='k5lyetw'), Comment(id='k5o1vyv'), Comment(id='k5qruxp')]"
17c5q6m,Responsible-Prize848,,2023-10-20 07:49:46+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17c5q6m/news_title_generator/,News title generator,"I have recently scraped about a thousand news titles from a news website related to my country. I want to train a model using these titles to create a news-headline generator. What sort of model should I use? Are there already such models? if so, can they be found on Huggingface? 

If I have to fine-tune an LLM for this, how should I proceed?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17c5q6m/news_title_generator/,0,1,1.0,[]
17c389u,Individual_Ad_1214,,2023-10-20 04:59:05+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17c389u/using_neural_network_for_dimensionality_reduction/,Using Neural Network for dimensionality reduction,,learnmachinelearning,/r/MLQuestions/comments/17c37ki/using_neural_network_for_dimensionality_reduction/,1,1,1.0,[Comment(id='k5nffgb')]
17bzgrp,Envoy-Insc,,2023-10-20 01:33:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bzgrp/live_introduction_to_core_machine_learning/,Live Introduction to Core Machine Learning Concepts Course (Sailea),"\>Sailea is a student run non-profit that does not charge for any of its services

**Join the FIRST lesson of SAILea’s course on the Principals of AI! 🌳**

Covers: Unsupervised, Supervised, and Reinforcement Learning; Overfitting, Underfiting, Confusion Matrix; Decision Trees

🗓️ October 21st ⏰ 7:00-8:00PM EST

**Why Sailea?**

* Only course targeted at high schoolers
* Free Forever

**Join Us Now!** 👉 ([signup form](https://docs.google.com/forms/d/e/1FAIpQLSfQGCeZClTdF6zeIQ-RtbOGR582bb1slc3oR0zG2J7j1v5RHg/viewform?usp=sf_link)) [https://docs.google.com/forms/d/e/1FAIpQLSfQGCeZClTdF6zeIQ-RtbOGR582bb1slc3oR0zG2J7j1v5RHg/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSfQGCeZClTdF6zeIQ-RtbOGR582bb1slc3oR0zG2J7j1v5RHg/viewform?usp=sf_link)

🌳 Register today, get involved in the community and grow your knowledge!  
(not sure what flair it's supposed to be, but it will be similar to a tutorial so I put that, hopefully that's fine)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bzgrp/live_introduction_to_core_machine_learning/,9,1,1.0,"[Comment(id='k6c83d4'), Comment(id='k5x1a7s'), Comment(id='k6csmsz'), Comment(id='k5zilie'), Comment(id='k5zj0yj'), Comment(id='k6c8235'), Comment(id='k6cbkbg'), Comment(id='k6chwev'), Comment(id='k6edppf')]"
17boc9v,KimberleyJSN,,2023-10-19 17:18:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17boc9v/which_of_these_ways_should_i_increase_the_feature/,Which of these ways should I increase the feature channels of my U-Net for better performance?,"I am working with U-nets for music source separation, separating one source per model.

Currently my U-net adds add +64 feature channels at each downsampling step, starting with 192  (192>+64>+64>+64)

Which way of increasing the capacity will improve my models performance most?

A) Increasing the initial 192 channels to something like 256 and continuing with the +64 every downsampling step.

B) Keeping the initial 192 channels but adding +80 every downsampling step

C) Increase both the initial 192 channels to 224 and +72 every downsampling step

Any help is appreciated !!

&#x200B;

   

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17boc9v/which_of_these_ways_should_i_increase_the_feature/,3,3,0.81,"[Comment(id='k5kuec7'), Comment(id='k5p2ec2'), Comment(id='k5kssnq')]"
17by9fj,sovit-123,,2023-10-20 00:33:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17by9fj/hyperparameter_tuning_using_keras_tuner/,Hyperparameter Tuning using Keras Tuner,"Hyperparameter Tuning using Keras Tuner

[https://debuggercafe.com/hyperparameter-tuning-using-keras-tuner/](https://debuggercafe.com/hyperparameter-tuning-using-keras-tuner/)

&#x200B;

https://preview.redd.it/akuue8y369vb1.png?width=1000&format=png&auto=webp&s=8347972f24a1b343feed186a4d7a952bf7c630c5",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17by9fj/hyperparameter_tuning_using_keras_tuner/,0,1,0.67,[]
17bvzh6,Informal_Waltz6704,,2023-10-19 22:46:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bvzh6/docker_pip_and_conda_environments_struggles/,Docker pip and Conda environments struggles,"Hello guys,   
I am a machine learning engineer (junior) striving to learn more about MLOps but I always struggle with setting up my Conda environments (especially on my Mac M1), I always ave dependency problems and even though I usually end up solving them with the help of some stack overflow answers but I am tired of trying everything until something works. I wanna have a deeper understanding of Conda environments, docker, using pip and Conda to install things and make sure I have the right dependencies. Any books or resources or a study plan to understand those things more in depth and stop following random readme files on GitHub.

(This whole problem stemmed from trying to copy the [deeplearning.ai](https://deeplearning.ai) course Machine Learning Engineering for MLOps specialization, and even though cvliv was installed it couldn't be imported and the kernel kept restarting which suggested that there is a problem of dependencies)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bvzh6/docker_pip_and_conda_environments_struggles/,1,1,1.0,[Comment(id='k5ml6do')]
17bmtbu,Due_Concentrate1279,,2023-10-19 16:11:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bmtbu/i_dont_understand_why_inceptionresnetv1_slows/,I dont understand why InceptionResnetV1 slows down my training process so much,"I am trying to do my first computer vision project.  im trying to make a model that can recognise famous peoples faces. However when i use a TinyVGG model the training process takes like 5 minutes for 5 epochs. but when the only thing i changed was to just change my model to this 

InceptionResnetV1(pretrained='vggface2', classify=False, num\_classes = len(class\_names))

Which im importing from facenet\_pytorch. Does this happen when some of you use this model aswell?

&#x200B;

Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bmtbu/i_dont_understand_why_inceptionresnetv1_slows/,3,3,1.0,"[Comment(id='k5l0qbr'), Comment(id='k5lov2z'), Comment(id='k5lrkz6')]"
17bkjq2,Key-Government-3157,,2023-10-19 14:31:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bkjq2/is_xgboost_20_better_than_176/,Is xgboost 2.0 better than 1.7.6?,"As title says, is there any noticeable difference between the two versions? 

I’m curious if i should re-run some of my analyses with the updated version..

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bkjq2/is_xgboost_20_better_than_176/,3,4,1.0,"[Comment(id='k5kbwoc'), Comment(id='k5lq9lv'), Comment(id='k5lgqa5')]"
17btn7z,sowhatidoit,,2023-10-19 21:06:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17btn7z/diy_sports_stat_query/,DIY Sports Stat Query?,"Hello, Im hoping someone here can point me in the right direction. I play in a local sports league where we keep scores/points for both individuals and teams. I want to be query the said data with prompts like ""Which player had the most points in the least amount of games?"" 

Is there a gpt style diy solution I can use for this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17btn7z/diy_sports_stat_query/,0,1,1.0,[]
17bihug,Financial_Job_1564,,2023-10-19 12:56:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bihug/is_it_a_good_way_to_learn_data_analysis_before/,Is it a good way to learn data analysis before learning ML?,I'm a third-year student and so many people say is hard to become an ML engineer as a fresh graduate. Is it a good way for me to learn data analyst/science and get a job as a data analyst/science before trying to become an ML engineer?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bihug/is_it_a_good_way_to_learn_data_analysis_before/,9,4,1.0,"[Comment(id='k5jlmk2'), Comment(id='k5kjfjv'), Comment(id='k5lr0fw'), Comment(id='k5k6bv3'), Comment(id='k5lqsro'), Comment(id='k5mp77p'), Comment(id='k5rl4ps'), Comment(id='k5nh32e'), Comment(id='k5vexsv')]"
17bn6cu,GalaxyKnightYT,,2023-10-19 16:27:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bn6cu/pytorch_on_ubuntu_with_amd_radeon_rx_6800/,Pytorch on ubuntu with AMD Radeon RX 6800,"I recently bought an RX 6800 to use for machine learning, how do I setup pytorch on ubuntu with ROCm?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bn6cu/pytorch_on_ubuntu_with_amd_radeon_rx_6800/,1,2,1.0,[Comment(id='k5pi824')]
17bwcg7,Sweaty-Pilot1335,,2023-10-19 23:02:59+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17bwcg7/help/,Help,,learnmachinelearning,https://i.redd.it/d07tsbxtp8vb1.png,0,0,0.25,[]
17br11q,StarsQuorum,,2023-10-19 19:14:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17br11q/d_learning_speech_separation/,[D] Learning speech separation,"Hi all,

I am looking to create one ML project on Jypyter on ""Speech separation"".

Can someone please point me to any good project (github/jupyter) that I can try running on some sample audio files?

Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17br11q/d_learning_speech_separation/,2,1,1.0,"[Comment(id='k5l77a3'), Comment(id='k5luobx')]"
17beeki,vadhavaniyafaijan,,2023-10-19 08:38:07+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17beeki/stanford_study_on_transparency_of_ai_models_of/,"Stanford Study On Transparency Of AI Models Of Google, Meta, OpenAI, And Other Big Companies",,learnmachinelearning,https://www.theinsaneapp.com/2023/10/stanford-foundational-model-transparency-report.html,0,8,1.0,[]
17bki81,AvvYaa,,2023-10-19 14:29:39+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17bki81/a_clear_visual_and_intuitive_explanation_of/,A clear visual and intuitive explanation of Neural Attention (A video),,learnmachinelearning,https://youtu.be/frosrL1CEhw,0,2,1.0,[]
17bp7k3,PersonalityHonest729,,2023-10-19 17:56:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bp7k3/multivariable_cluster_analysis_project_help/,multi-variable cluster analysis project help,"I'm currently working on a project to find clusters defined based on student engagement actions on a specific online tutoring platform and how well they preform on a specific exam. I have a very large dataset 60,000+ rows that consist of student id's, week number, multiple engagement actions (0 and 1 used to determine whether or not they did this action), and their scores on the exam. 

What I've done already is count the actions for each student and the clustered with the amt. of actions they've done and their score. I used k-clustering and a WSS plot to determine the clusters. I had 4 total clusters ranging from high engagement - high score to low engagement - low score. And then I saw the percentage of students in each cluster. And then within each cluster I did a bar graph to see what were the top actions in each cluster.  

My supervisor said I did this project backwards and my clusters lacked nuance and that I should instead find clusters within the subsets of actions ex. video interactions, wall engagement, etc. I am not that skilled with R and only a few courses in my stats major and I'm really struggling on how to work with this data. Since the data is week by week and theres multiple engagement actions denoted by 0s and 1s I have no idea how to manipulate the data and cluster any other way other than what I did. 

Any help is much appreciated and I'm happy to respond to any questions. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bp7k3/multivariable_cluster_analysis_project_help/,1,0,0.5,[Comment(id='k5kve7d')]
17bitmm,Vegetable_Twist_454,,2023-10-19 13:12:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bitmm/d_how_should_one_systematically_and_predictably/,[D] How should one systematically and predictably improve the accuracy of their NLP systems?," **I want to understand how folks in the NLP space decide on what problem to solve next in order to improve their system's accuracy.**

In my previous role as a Search Product Manager, I would debug at least 5 user queries on a daily basis as it not only gave me an understanding of our system (It was fairly complex consisting of multiple interconnected ML models) but also helped me build an intuition around problem patterns (areas that Search is failing in) and what possible solutions could be put in place.

Most members of our team did this. Since our system was fairly complex, we had an in-house debugging tool that clearly showed ML model responses for different queries at each stage under different conditions (AB, Pincode, user-config, etc).

When it was time to decide what improvements to make to the model most of us had a similar intuition on what to solve next. We would then use numbers to quantify it. Once the problem was zeroed down, we would brainstorm solutions and implement the cost-efficient solution.

**Do let me know how you'll improve the accuracy of your NLP systems**",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bitmm/d_how_should_one_systematically_and_predictably/,0,2,1.0,[]
17bnhxi,Seankala,,2023-10-19 16:41:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bnhxi/encoderdecoder_transformer_model_makes_outputs/,Encoder-decoder Transformer model makes outputs predictions almost perfectly but fails to autoregressively decode,"The model's sample predictions that I'm printing during training are almost perfect but the model generates meaningless tokens during evaluation.

For training I'm feeding it the source and target sequences as was introduced in the original paper, and for autoregressive decoding I'm feeding a source sequence and a BOS token as the target input (the targets during training and both inference start with BOS tokens).

The specific code I have looks like this:

```
# Specific code used during training inside a loop.

batch[""src""] = batch[""src""].to(""cuda"")
batch[""tgt""] = batch[""tgt""].to(""cuda"")

output = model(**batch)

loss = criterion(
    output.view(-1, args.vocab_size), batch[""tgt""].view(-1).long()
)
step_loss += loss.item()
epoch_loss += loss.item()

loss.backward()
optimizer.step()

output_probs = F.softmax(output, dim=-1)
predictions = torch.argmax(output_probs, dim=-1)
```

```
# Evaluation and autoregressive decoding.
def decode_autoregressive(model, src):
    outputs = torch.ones(size=(src.shape[0],)).reshape(-1, 1) * 2

    if torch.cuda.is_available():
        src = src.to(""cuda"")
        outputs = outputs.to(""cuda"")

    generation_mask = torch.ones(size=(src.shape[0],), dtype=torch.bool).to(src.device)

    for _ in range(src.shape[1]):
        prediction = F.softmax(model(src, outputs), dim=2)
        prediction = torch.argmax(prediction, dim=2)[:, -1]

        eos_idxs = prediction == 3
        generation_mask[eos_idxs] = False
        prediction[~generation_mask] = 0

        outputs = torch.cat((outputs, prediction.view(-1, 1)), dim=-1)

    return outputs[:, 1:]
```

The logic of the decoding is that if the EOS token is output, then we'll replace any subsequent outputs with the padding token.

I'm creating a causal mask inside my Transformer model.

What could be some potential problems? I'm searching the web and am under the impression that my training itself may not be optimal and there may be a discrepancy between training and evaluation but I'm not sure.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bnhxi/encoderdecoder_transformer_model_makes_outputs/,0,1,1.0,[]
17bdewd,DwaywelayTOP,,2023-10-19 07:27:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bdewd/beginner_resources/,Beginner Resources,"Hello everyone! I am kind of an absolute beginner to LLM's and am very interested in learning more about how they work, how to use them and also getting hands-on experience by fine-tuning some LLM (probably something chat-based like vicuna 13B) on some custom datasets.

Could someone please share some resources (Blogs, Articles, Learning Checklists, Colab Notebooks, Tutorials) to get started?

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bdewd/beginner_resources/,1,5,1.0,[Comment(id='k5imlqe')]
17bmpy7,AlbanySteamedHams,,2023-10-19 16:07:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bmpy7/decreasing_loss_with_incorrectly_applied_softmax/,Decreasing loss with incorrectly applied softmax in Transformer's attention mechanism?,"Hello everyone,

I have been going through Andrej Karpathy's nanoGPT video (the whole zero to hero playlist is incredible). In the process I created a bug when coding up the attention mechanism that I've since fixed, but the impact of it is puzzling me.

I  understand that the attention scores are computed by taking the dot  product of the query and key vectors, and then a softmax is applied to  these scores to obtain the attention weights.

However, I mucked up and applied the softmax  across the wrong dimension. This was wrong but still resulted in not only decreasing loss during training, but \*very low\* loss scores (like cross entropy of 0.30 after a couple thousand steps). Despite this, the  quality of the output was noticeably poor.

Fixing the dimensional issue results in everything working well and high quality output with some reasonable training time. The whole difference in function is literally from one character on one line of code:

```python
    def forward(self, x):
        B, T, C = x.shape # I think that things have changed meaning now and C is head_size
        k = self.key(x)  # (B, T, C)
        q = self.query(x)# (B, T, C)
        attention_score = q @ k.transpose(-2,-1) * C**-.5  # (B, T, C) @ (B, C, T) --> (B, T, T)
        attention_score = attention_score.masked_fill(self.tril==0, float('-inf'))
        
        #this is the line below... if dim=1, then the loss gets low but the output gets crummy
        attention_score = F.softmax(attention_score, dim=-1) # <---
        v = self.value(x)# (B, T, C)
        
        out = attention_score @ v # (B, T, T) @ (B, T,C) --> (B, T, C)
        return out

```

Could someone explain why the model still seems to ""learn"" to some  extent (as evidenced by the decreasing loss) even when the softmax is  applied in this incorrect manner? Is it a case of the model picking up  on some other patterns in the data, or is there some other mechanism at  work here that I'm not understanding?

Any insights or references would be greatly appreciated.

Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bmpy7/decreasing_loss_with_incorrectly_applied_softmax/,0,1,1.0,[]
17b7ffq,Richar_D_Feynman,,2023-10-19 01:42:44+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17b7ffq/training_ai_to_play_pokemon_with_reinforcement/,Training AI to Play Pokemon with Reinforcement Learning,"Amazing job, the insights and explanation are awesome and he posted the model to download and interact with the AI",learnmachinelearning,https://youtu.be/DcYLT37ImBY?si=b9tAvV2xa2GnS5kq,0,14,1.0,[]
17blc2n,asoreol,,2023-10-19 15:05:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17blc2n/how_would_you_parse_a_json_string_into_2d_tables/,How would you parse a JSON string into 2D tables for .CSV files?,"I get some raw data in JSON format. I can read the data into a python object using

    import json
    my_object =json.load(my_data_string) # contains list and dicts, possibly other JSON-standard objects as well

Now I want to turn this arbitrary JSON object from a n-dimensional collection of lists and dicts into something that can be saved as a CSV file, depicting 2 dimensions. Other dimensions could be flattened into multiple tables of 2D.

I tried pandas, but it doesn't seem to be able to parse JSON strings/objects unless they exclusively consist of dicts, which doesn't seem to conform to JSON standards, so I couldn't find any universal solution.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17blc2n/how_would_you_parse_a_json_string_into_2d_tables/,0,1,1.0,[]
17bjsgn,DistributionBig8439,,2023-10-19 13:57:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bjsgn/learning_cnn/,Learning CNN,Is it possible to use CNN to classify image based on the intensity of the images. Suppose I want to classify banana based on the geographic location and intensity of yellowness ?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bjsgn/learning_cnn/,3,1,1.0,"[Comment(id='k5kir1q'), Comment(id='k5kry4g'), Comment(id='k5ktkbz')]"
17biv3u,geekash207,,2023-10-19 13:14:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17biv3u/easy_ocr/,Easy OCR,"I want to extract info from the ID  
I used easy ocr

Could I change these settings, because there is some text that wasn't recognized by easy OCR  
(tl, tr, br, bl) = bbox  
tl = (int(tl\[0\]), int(tl\[1\]))  
tr = (int(tr\[0\]), int(tr\[1\]))  
br = (int(br\[0\]), int(br\[1\]))  
bl = (int(bl\[0\]), int(bl\[1\]))  
cv2.rectangle(image, tl, br, (0, 255, 0), 2)  
cv2.putText(image, text, (tl\[1\], tl\[1\] - 10),  
cv2.FONT\_HERSHEY\_SIMPLEX, 0.5, (255, 0, 0), 2)  
plt.rcParams\['figure.figsize'\] = (10,10)

And what is the best to use easy OCR or Tesseract?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17biv3u/easy_ocr/,0,1,1.0,[]
17biq8w,No-Independence5880,,2023-10-19 13:08:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17biq8w/article_computer_vision_in_agriculture_challenges/,Article: Computer Vision in Agriculture. Challenges & Solutions.,"&#x200B;

https://preview.redd.it/stcfzrefr5vb1.jpg?width=2500&format=pjpg&auto=webp&s=ef1947419ba66933e218af17718f3d346d5afb9c

Interesting article about use cases of data augmentation in agricultural industry.  
Short description:  
In this article, you will cover:

**•** How computer vision solutions are transforming the agricultural industry.

**•** Observe the importance of quality data for developing AI solutions that perform crop and livestock analysis and monitoring with high and steady accuracy.

**•** Explore the use of synthetic data to facilitate data collection in various conditions.

**•** Take a look at examples of tasks in agriculture. How can we solve them with computer vision, and how can we apply synthetic data to extend the augmentation?  
More details are [here](https://www.opencv.ai/blog/computer-vision-in-agriculture-challenges-solutions)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17biq8w/article_computer_vision_in_agriculture_challenges/,0,1,0.67,[]
17bigi1,ML-NOW,,2023-10-19 12:54:39+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bigi1/most_of_ml_can_be_explained_through_linear/,Most of ML can be explained through linear regression,"Simple Linear Regression - the very first model you would hear about - can teach the majority of ML concepts.

Models try to predict an Output, given an Input. For example, we could make a model predict the Belly Length of a Possum by inputting its Chest Size.

Through seeing many examples of real data, or real input-output pairs, we hope that the model learns to predict the output accurately. Or equivalently, that it has a low error. We seek the model that has the smallest error for the given dataset.

A Simple Linear Regression models the prediction as Output = M\*Input + b. The model is controlled by its M and b values. Through some mathy formula, the model automatically finds the correct M and b. The M and b values are called the model's Parameters. Once we have these Parameters, our model training is complete.

\---

Fast forward through hundreds of pages of literature...

\---

Neural networks also have parameters. Just a lot more of them. They have inputs and outputs too. We still want a low error.

https://preview.redd.it/t3kzkkodp5vb1.png?width=762&format=png&auto=webp&s=885904190fd0b4052a0c22cdbb51ffc2f15c647d

It's basically the same thing, just with different formulas.

...

I hope that helps! Consider checking out [mlnow.ai](https://mlnow.ai) if you're learning these concepts!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bigi1/most_of_ml_can_be_explained_through_linear/,3,0,0.5,"[Comment(id='k5kmht8'), Comment(id='k5q35lc'), Comment(id='k5ougb6')]"
17axsye,TheTabar,,2023-10-18 18:33:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17axsye/so_the_ultimate_goal_of_this_profession_is_to_let/,So the ultimate goal of this profession is to let computers do all the work.,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17axsye/so_the_ultimate_goal_of_this_profession_is_to_let/,15,28,0.75,"[Comment(id='k5ftmu4'), Comment(id='k5gc06y'), Comment(id='k5fw4ft'), Comment(id='k5gzvj0'), Comment(id='k5g8m0x'), Comment(id='k5gscz4'), Comment(id='k5h3v13'), Comment(id='k5gqe54'), Comment(id='k5in7h2'), Comment(id='k5jgz40'), Comment(id='k5ib1jc'), Comment(id='k5ip742'), Comment(id='k5jp10h'), Comment(id='k5gw6q5'), Comment(id='k5hy2cs')]"
17b166m,nick898,,2023-10-18 20:57:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17b166m/reinforcement_learning_to_speed_up/,Reinforcement learning to speed up computationally expensive calculations,"Suppose I have some computationally expensive procedure that is well suited for reinforcement learning (I.e can be thought of as an agent performing an action from a finite set of actions in an environment, obtaining some reward for the action, update the environment state, and repeat this over and over to learn what it can or cannot do and what is desirable, not desirable etc…)

Now I could do this expensive procedure in real time, but it’s computationally expensive and might take a long time to come up with results which is unacceptable. 

Is there an advantage to using a model built via reinforcement learning in place of doing the true, computationally expensive calculations? Does it have the potential to come up with significantly faster decisions in real time or am I off base with how I am thinking about reinforcement learning",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17b166m/reinforcement_learning_to_speed_up/,14,18,0.96,"[Comment(id='k5ghjkm'), Comment(id='k5gln2x'), Comment(id='k5gn5n0'), Comment(id='k5gjwyd'), Comment(id='k5gylp5'), Comment(id='k5gqudu'), Comment(id='k5gp1xo'), Comment(id='k5h4ggh'), Comment(id='k5gsc9o'), Comment(id='k5h5rfh'), Comment(id='k5gwq2n'), Comment(id='k5j47ik'), Comment(id='k5lbwsi'), Comment(id='k5llugm')]"
17bcd9p,av_community,,2023-10-19 06:17:05+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17bcd9p/listen_to_anand_s_talk_about_purpose_driven/,Listen to Anand S talk about Purpose Driven Learning,,learnmachinelearning,https://v.redd.it/7w0h9hx8q3vb1,1,2,0.75,[]
17b9h8d,franticpizzaeater,,2023-10-19 03:25:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17b9h8d/d_need_help_with_interpreting_math/,[D] Need help with interpreting math,,learnmachinelearning,/r/MachineLearning/comments/17b9gp9/d_need_help_with_interpreting_math/,0,3,1.0,[]
17bn6z7,ML-NOW,,2023-10-19 16:27:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bn6z7/what_is_gradient_descent_in_machine_learning/,What is Gradient Descent in Machine Learning?,"Gradient descent is a common algorithm used in deep learning to find the minimum to the error function. We're trying to make our model find the best Parameters, so that it gets a low error (so that it predicts accurately).  


Here's a step-by-step breakdown of how gradient descent works:  


Step 1 - Initialization:  
Start with an initial guess for the parameters. This could be random or based on some heuristic. For now, let's just assume they're all set to 0.  


Step 2 - Compute the Gradient:  
The gradient of a function gives the direction of the steepest increase. For minimization, we want to go in the opposite direction of the gradient.  


Step 3 - (Slightly) Update the Parameters:  
Adjust the parameters in the opposite direction of the gradient by a certain step size (or learning rate).  


We do:  
New parameter = Old parameter - Learning rate \* Gradient  


... for all the parameters. Not in a loop, but all at once, using parallelization.  


Step 4 - Iterate:  
Repeat steps 2 and 3 until the gradient is very small (close to zero), or a certain number of iterations is reached.  


Hope that helps! Consider checking out [mlnow.ai](http://mlnow.ai/) if you're learning this stuff :)

https://preview.redd.it/pmq0kptgr6vb1.png?width=1400&format=png&auto=webp&s=20e9139dd12744035922d875a167f11b9e1cefd6",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bn6z7/what_is_gradient_descent_in_machine_learning/,2,0,0.36,"[Comment(id='k5kdw1t'), Comment(id='k5ouiot')]"
17bdz2g,MandM-DataScience,,2023-10-19 08:05:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bdz2g/market_timing_risk_management_portfolio_allocation/,Market Timing & Risk Management - Portfolio allocation," Hi everyone!  
Is it possible to create a market timing strategy using unsupervised learning? 

Let's find out.

Relevant Topics:

* Used S&P500 data
* Segmenting Time series using Online Change Detection Point
* Clustering segments with KMeans
* Risk Allocation
* Value at Risk

Here's the notebook:  
[https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook](https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook)

Every and each comment / feedback is greatly appreciated!

Thank you!  
M&M",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bdz2g/market_timing_risk_management_portfolio_allocation/,1,1,1.0,[Comment(id='k5iwthh')]
17bdty2,lectis1,,2023-10-19 07:56:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bdty2/how_can_i_speed_up_this_code/,How can I speed up this code?,"Note I'm useing tensorflow 

Train_df_shuffle =train_df.sample(frac=0.1, random_state=42)

I'm useing my local hardware for Google collab. I have a rtx 4090, so this isn't supposed to take long at all. But I've been sitting here for 15 mins.

My setup 
Anaconda-> virtual environment-> juptyer notebook -> copy and paste the local runtime code into google collab. 

Can anyone help?
Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bdty2/how_can_i_speed_up_this_code/,6,1,0.6,"[Comment(id='k5it7la'), Comment(id='k5irq52'), Comment(id='k5ispj9'), Comment(id='k5iw411'), Comment(id='k5j3nn7'), Comment(id='k5j3t8p')]"
17bcq88,Beginning_Finding_98,,2023-10-19 06:41:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17bcq88/title_is_it_possible_for_a_non_tech_person_to/,Title: Is It Possible for a non tech person to Learn to Make Something Like Google sound storm or do audio synthesis,"Hey guys

So as someon who is not well acquainted with the workings of AI and machine learning and as someone with a non technical background. I recently stumbled upon Google's audio generation framework and was completely blown away [https://google-research.github.io/seanet/soundstorm/examples/](https://google-research.github.io/seanet/soundstorm/examples/)

I would love to replicate something like that and based on this I had  **a few questions:**

1. Is it possible for someone like me to  delve into audio generation projects like this one off course not right of the bat but gradually to get there.
2. What are the essential resources for beginners to get started in this field?
3. What programming languages(I did some research and I assume python is likely needed) and tools are best for tackling projects like these. I also have seen models like [https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/) which are no code  I do think that sound classification maybe possible but I am not sure if it can help in generating audio, sounds and or speech
4. Lastly, do we need to  have a strong mathematical background for diving into such projects

Please share your insights, experiences, and any other valuable information that can help a non technical person (like me) to perhaps get started on a journey for a project similar to this

&#x200B;

Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17bcq88/title_is_it_possible_for_a_non_tech_person_to/,2,0,0.33,[Comment(id='k5j7i6e')]
17aidx2,Financial_Job_1564,,2023-10-18 04:45:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17aidx2/do_you_clean_the_dataset_by_yourself/,Do you clean the dataset by yourself?,"a Newbie here, as an ML Engineer who already works for a company do you clean the dataset by yourself? or you just receive the dataset and start to work with it.

P.S Sorry if the question is stupid",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aidx2/do_you_clean_the_dataset_by_yourself/,40,84,0.9,"[Comment(id='k5d79tq'), Comment(id='k5d8wop'), Comment(id='k5ezkuc'), Comment(id='k5d5l32'), Comment(id='k5dg1uf'), Comment(id='k5ddomu'), Comment(id='k5d3vot'), Comment(id='k5fgwo8'), Comment(id='k5fmi8u'), Comment(id='k5ddimw'), Comment(id='k5dq0em'), Comment(id='k5i6zil'), Comment(id='k5lkuuy'), Comment(id='k5n92d3'), Comment(id='k5sesqe'), Comment(id='k5ejiy7'), Comment(id='k5h30yk'), Comment(id='k5e7lwx'), Comment(id='k5db48k'), Comment(id='k5grlib'), Comment(id='k5djfjd'), Comment(id='k5dkesh'), Comment(id='k5e4xww'), Comment(id='k5d8hua'), Comment(id='k5iafsm'), Comment(id='k5dxqlh'), Comment(id='k5dcxox'), Comment(id='k5drdru'), Comment(id='k5dkvt9'), Comment(id='k5drx2b'), Comment(id='k5dcwb0'), Comment(id='k5fy7qi'), Comment(id='k5h5v9n'), Comment(id='k5dl3sd'), Comment(id='k5ddjgn'), Comment(id='k5eg06w'), Comment(id='k5djxc6'), Comment(id='k5gwtt1'), Comment(id='k5dxnc3'), Comment(id='k5iyqls'), Comment(id='k5n9g8w')]"
17ba11a,hlfkasjd,,2023-10-19 03:54:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ba11a/opml_a_method_for_verifying_machine_learning/,opML: A Method for Verifying Machine Learning Output Using Blockchain,"Given the challenge in verifying claims about ML models, such as the number of parameters, there's a need for methods that can help prove and verify these claims. Hyper Oracle introduces opML (Optimistic Machine Learning) for this purpose:

* **Objective**: opML aims to port AI model inference and training/fine-tuning into blockchain using an optimistic mechanism.
* **Efficiency**: opML is designed to provide machine learning proofs with minimal cost and high efficiency.
* **Hardware Requirements**: opML can execute a large language model like a 7B LLaMA, which is around 26GB in size, on a standard PC without a GPU. 
* **Verification**: opML employs a verification game, similar to methodologies used in Truebit and Optimistic Rollup systems, ensuring the decentralization and verifiability of the ML computations.

For those interested in contributing or diving deeper, we have open-sourced our ongoing work on opML. You can find our repository [here](https://github.com/OPML-Labs/opml).

And here's a [demo](http://ai.hyperoracle.io/sd) to try out opML in action.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ba11a/opml_a_method_for_verifying_machine_learning/,2,1,0.57,"[Comment(id='k5iiall'), Comment(id='k5jgbjg')]"
17bdjib,soshaai,,2023-10-19 07:36:01+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17bdjib/just_launched_ai_avatar_startup_using_stable/,Just Launched AI Avatar Startup Using Stable Diffusion - Would Love Your Feedback!,,learnmachinelearning,https://avatarcraft.ai,1,0,0.25,[]
17b3cac,devilz_soul,,2023-10-18 22:30:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17b3cac/courses_books_or_videos_that_focus_on_problem/,"Courses, Books or Videos that focus on Problem Framing","Hello,

I am looking for material to read on how to determine if ML is a good approach for a problem and explains how to outline an ML solution.   


There are snippets of it here and there but I was looking for a book, course, video that goes deep into it and spend working on every angle of creating a framework from Engineering and/or product management perspective.

&#x200B;

I will really appreciate the help from community on this 

&#x200B;

Regards ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17b3cac/courses_books_or_videos_that_focus_on_problem/,1,2,1.0,[Comment(id='k5hlya5')]
17b5j9f,Lakshmireddys,,2023-10-19 00:10:44+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17b5j9f/best_mathematics_books_for_machine_learning_data/,"Best Mathematics books for Machine Learning, Data Science",,learnmachinelearning,https://codingvidya.com/best-mathematics-books-for-machine-learning/,0,0,0.5,[]
17are44,Dont_Browse-P0Rn,,2023-10-18 13:54:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17are44/what_should_a_student_learn_when_building_ml/,What should a student learn when building ML projects?,"I recently started learning about what machine learning is and how it is implemented in real-world projects. After looking at some projects I wanted to build my own beginner-level project and came across the House Price Prediction project in a Medium article. I followed the process and completed the project, From the project I learned about splitting data sets, Overfitting, and the Architecture of Neural Networks.

My question is when a company looks at my resume and looks at my projects do they expect me to build that project from scratch (how they ask programming questions in interviews ) or do they check the concepts I learned from building the project and if I can build similar projects?

And what should I learn from building projects?

(sorry if this question made no sense)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17are44/what_should_a_student_learn_when_building_ml/,8,5,0.78,"[Comment(id='k5ey1cv'), Comment(id='k5f4fds'), Comment(id='k5h9re3'), Comment(id='k5iampo'), Comment(id='k5id9fj'), Comment(id='k5ill5r'), Comment(id='k5iurg2'), Comment(id='k5jfuig')]"
17akzss,The_Protagonist2,,2023-10-18 07:38:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17akzss/where_to_even_start_with_machine_learning/,Where to even start with Machine Learning?,"I have been kinda lurking on this subreddit and googling and youtubing some sutff. I feel so lost with all the terminology and jargon. I work in data consulting at the moment. I want to get my feet wet with ML, where do I start? And what would be a good pathway to becoming one?

Im familiar with Python (I'm mediocre), and SQL (mediocre).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17akzss/where_to_even_start_with_machine_learning/,26,19,0.88,"[Comment(id='k5erjoz'), Comment(id='k5essfo'), Comment(id='k5g5u8a'), Comment(id='k5dny6p'), Comment(id='k5dj1m3'), Comment(id='k5grg9q'), Comment(id='k5h5m5a'), Comment(id='k5g7rjn'), Comment(id='k5hs66f'), Comment(id='k5irk63'), Comment(id='k5g6a6y'), Comment(id='k5h2vdd'), Comment(id='k5x4dbd'), Comment(id='k5et1f6'), Comment(id='k5x3km8'), Comment(id='k5ex394'), Comment(id='k5g5ggw'), Comment(id='k5exhq9'), Comment(id='k5i47oe'), Comment(id='k5gxqj0'), Comment(id='k5iep5d'), Comment(id='k5izlsi'), Comment(id='k5itgpr'), Comment(id='k5kimhm')]"
17awd7j,Tejas-1394,,2023-10-18 17:31:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17awd7j/machine_learning_model_deployment_a_practical/,Machine Learning Model Deployment: A Practical 3-Part Series,"I'm a Data Scientist and recently I have been curious as to how ML Model deployment works.ML Model deployment ensures that the model gets consumed. I have explored how a model can be deployed on both my local system and on the Cloud.

At the same time, I took notes and converted them into articles which I have posted on Medium. The series of articles(3 parts) is meant to be informative for anyone starting out on the deployment journey. Here are the links:

1. Getting started - [https://medium.com/@ekawade1394/deploying-a-machine-learning-model-getting-started-2644392c8953](https://medium.com/@ekawade1394/deploying-a-machine-learning-model-getting-started-2644392c8953)
2. Local deployment - [https://medium.com/@ekawade1394/deploying-a-machine-learning-model-part-2-local-deployment-1c36d029ce7a](https://medium.com/@ekawade1394/deploying-a-machine-learning-model-part-2-local-deployment-1c36d029ce7a)
3. Cloud deployment - [https://medium.com/@ekawade1394/deploying-a-machine-learning-model-part-3-google-cloud-vertex-ai-5287cf9e45ec](https://medium.com/@ekawade1394/deploying-a-machine-learning-model-part-3-google-cloud-vertex-ai-5287cf9e45ec)

In case any information is inaccurate, please let me know so that I can learn and correct it in the articles.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17awd7j/machine_learning_model_deployment_a_practical/,0,3,1.0,[]
17anvc6,av_community,,2023-10-18 10:54:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17anvc6/a_small_cheat_sheet_on_ml_hyperamaters/,A small cheat sheet on ML Hyperamaters!,"Here is a small cheatsheet of ML models. If you find it useful, let us know! We'll create more!

&#x200B;

https://preview.redd.it/4vd74i0qwxub1.png?width=1080&format=png&auto=webp&s=58fc1f53835f73a3b6a8803ce5fb360c3de2f766",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17anvc6/a_small_cheat_sheet_on_ml_hyperamaters/,4,10,0.65,"[Comment(id='k5emgr4'), Comment(id='k5fql28'), Comment(id='k5f30wt'), Comment(id='k5i7qj8')]"
17ayc4y,ahmedbesbes,,2023-10-18 18:56:04+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ayc4y/why_your_rag_is_not_reliable_in_production/,Why Your RAG is Not Reliable in Production,,learnmachinelearning,https://thetechbuffet.substack.com/p/the-probelms-behind-rag,0,2,0.75,[]
17aw605,o-rka,,2023-10-18 17:22:51+00:00,False,,1697681953.0,False,True,False,/r/learnmachinelearning/comments/17aw605/can_someone_eli5_the_birch_clustering_algorithm/,Can someone ELI5 the birch clustering algorithm?,"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html

I'm looking at the parameters here and I'm confused on how there is no distance metric? What is assumed about the data going in if there is no distance metric?

What is the performance difference if it is run on binary data (1/0)? What about data w/ missing values? Does it assume the samples are normally distributed?  This isn’t clear from the documentation and I haven’t seen this part addressed in the usage tutorials.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aw605/can_someone_eli5_the_birch_clustering_algorithm/,0,2,1.0,[]
17at7uu,IHDN2012,,2023-10-18 15:16:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17at7uu/how_to_embed_18_million_text_chunks_quickly/,How to embed 18 million text chunks quickly?,"I'm finding that most solutions take .5 to 1 second, which isn't fast enough.  Any recommendations on how to embed 18 million text chunks quickly and cheaply?  Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17at7uu/how_to_embed_18_million_text_chunks_quickly/,15,2,0.63,"[Comment(id='k5ew95f'), Comment(id='k5fg9xt'), Comment(id='k5ht52h'), Comment(id='k5iw844'), Comment(id='k5nuxg4'), Comment(id='k5fo06c'), Comment(id='k5ga3o1'), Comment(id='k5k4vn8'), Comment(id='k5fq2hx'), Comment(id='k5gejbw'), Comment(id='k5nonf6'), Comment(id='k5kg5y2'), Comment(id='k5gktsx'), Comment(id='k5k4yn7'), Comment(id='k5v5bzz')]"
17axl5f,Vegetable-Skill-9700,,2023-10-18 18:23:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17axl5f/how_to_evaluate_your_llm_applications/,How to Evaluate Your LLM Applications?,"This a question that I have come across countless number of times on HN, discord/ slack communities and emails. Hope this blog I wrote answers some of your questions: [https://uptrain.ai/blog/how-to-evaluate-your-llm-applications](https://uptrain.ai/blog/how-to-evaluate-your-llm-applications) and please let me know your comments/questions/criticisms in the comment section",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17axl5f/how_to_evaluate_your_llm_applications/,0,1,0.67,[]
17b6u9h,Signal_Tiger_2713,,2023-10-19 01:14:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17b6u9h/land_your_dream_job_build_your_portfolio_with/,Land your dream job: Build your portfolio with Streamlit,"When applying for jobs, I realized that I didn't just need to have a data science portfolio; mine needed to stand out. I utilized Streamlit to bring amazing graphics, AI, and free hosting to my portfolio — all built with Python. I wanted to share this experience with all those data scientists looking for work or ready to make their next career move. I wrote a [step-by-step guide](https://blog.streamlit.io/land-your-dream-job-build-your-portfolio-with-streamlit/) on how I worked with Streamlit. Take a look, and I would always appreciate feedback on what I have created. Welcome to tag me on [LinkedIn](https://www.linkedin.com/in/vicky-tck/?ref=blog.streamlit.io). I'd love to celebrate your accomplishments and get inspired by your work too! 🎉💡

https://preview.redd.it/qj34s29e82vb1.png?width=1480&format=png&auto=webp&s=0afa44e6fcc2bed31a88a4a7a3b8e2796fbdb93d",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17b6u9h/land_your_dream_job_build_your_portfolio_with/,3,0,0.38,"[Comment(id='k5hmxye'), Comment(id='k5ihxns'), Comment(id='k5j0z4i')]"
17aqzll,fewdiepie_,,2023-10-18 13:36:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17aqzll/where_do_i_gather_the_dataset_for_my_fyp/,Where do I gather the dataset for my FYP,I am doing a Machine Learning project for my FYP; I haven't worked on any ML project yet but I am excited about it. It is related to voice/facial emotion detection. is there any platform that provides datasets for ml projects? Like without any copyright issues (if that's even a thing in ml datasets idk?) A total beginner here. ,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aqzll/where_do_i_gather_the_dataset_for_my_fyp/,1,2,0.75,[Comment(id='k5ha0km')]
17auhth,webdevengineer,,2023-10-18 16:12:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17auhth/what_do_i_need_to_learn_in_order_to_create_a/,What do I need to learn in order to create a genAI chatbot that provides weather predictions?,"I want to write a chatbot that uses NWS and NOAA data to predict what weather will be like in my city. This is purely a hobby project to get me started on AI development. I am looking at using APIs from NOAA and NWS that then feed into GPT4. I could ask the chatbot questions like ""What will the weather be at 2pm today?"" or ""Should I take a jacket with me at 2pm today?"" 

I have knowledge of databases and python, and would like to incorporate more skills into my knowledge to make this chatbot. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17auhth/what_do_i_need_to_learn_in_order_to_create_a/,2,0,0.5,"[Comment(id='k5f8k87'), Comment(id='k5nbs0u')]"
17atfiu,Lakshmireddys,,2023-10-18 15:25:54+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17atfiu/ibm_machine_learning_with_python_review_students/,IBM Machine Learning with Python Review: Student's Perspective -,,learnmachinelearning,https://codingvidya.com/ibm-machine-learning-with-python/,0,1,1.0,[]
17aa2oo,art_luke,,2023-10-17 22:02:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17aa2oo/whats_your_workflow_with_cloud_gpus/,What's your workflow with cloud GPUs?,"What is your workflow when coding and developing ML models?

At this point I am aiming for the following setup:

1. code things on my laptop in VSCode,
2. debug the model with smaller hyperparameters on laptop's local GPU,
3. upload code from laptop to github repository,
4. login into LambdaLabs,
5. run a script that downloads training data, clones the github repository and starts training.

I'm wondering if there is something more streamlined.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aa2oo/whats_your_workflow_with_cloud_gpus/,11,25,0.97,"[Comment(id='k5bpunx'), Comment(id='k5c4ytr'), Comment(id='k5db72p'), Comment(id='k5bsmzg'), Comment(id='k5dxv9e'), Comment(id='k5buij7'), Comment(id='k5bvil1'), Comment(id='k5clyil'), Comment(id='k5bx2ag'), Comment(id='k5bxx8e'), Comment(id='k5byp5w')]"
17aszjx,floaust,,2023-10-18 15:06:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17aszjx/you_want_to_understand_the_linear_regression_on_a/,You want to understand the linear regression on a university level?,"As a short introduction, I wrote my bachelors' thesis about machine learning and thought why not share my conclusions and information with other people. Since you seemed to like my post about metrics in machine learning, I hope this helps some people to understand linear regression a bit better on a higher and more mathematical approach.

&#x200B;

[https://medium.com/p/448a6494e4dd](https://medium.com/p/448a6494e4dd)

&#x200B;

Feedback is well appreciated. 😀",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aszjx/you_want_to_understand_the_linear_regression_on_a/,4,0,0.46,"[Comment(id='k5fdhdt'), Comment(id='k5iiuy3'), Comment(id='k5iqleq'), Comment(id='k5kfmu8')]"
17aspvc,SuperLearner3004,,2023-10-18 14:54:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17aspvc/d_how_to_start_a_career_in_machine_learning_deep/,"[D] How to start a career in Machine Learning, Deep Learning, AI in general","Hi   guys, as the title says. I want to start and learn about Machine   Learning and AI in the trending topics nowadays. I would like in the   future use this concepts and knowledge to apply machine learning and AI   to games or in data analysis or simple automating bots for doing any   task I want... I'm a back-end software engineer and I have a strong   background in software and programming. So... how can I start with my   specific background?. I would like to start from zero obviously...   Should buy a powerful hardware ??. Which is the best or affordable setup   to make tests and train certain models?. Currently I have this courses   on Udemy:

1. [Python for Machine Learning & Data Science Masterclass](https://www.udemy.com/course/python-for-machine-learning-data-science-masterclass/)
2. [Tensorflow 2.0: Deep Learning and Artificial Intelligence](https://www.udemy.com/course/deep-learning-tensorflow-2/)

What do you say about this courses??. Are gems or nah?.

Please explain and point me in the right direction!. Thanks for reading.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aspvc/d_how_to_start_a_career_in_machine_learning_deep/,3,1,0.67,"[Comment(id='k5ibhkh'), Comment(id='k5knn00'), Comment(id='k5jgfyt')]"
17anedp,tinkerpal,,2023-10-18 10:25:37+00:00,False,,1698313801.0,False,True,False,/r/learnmachinelearning/comments/17anedp/batch_learning_in_production/,Batch learning in production,"Hi all,

I have a supervised machine learning model (random forest classifier) which is used for classifying products based on product types. My model does batch learning, like I run the model at once on the training data and I do it every quarterly. Like with batch learning, if there are new instances, we have to retrain the data again on the training data by including both old and new data. I do this currently since my training data is not large( 250MB). 


What happens when I put this model in the production, how do I include these new instances? Should I use online learning or incremental learning? If yes, what changes with my supervised model ?

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17anedp/batch_learning_in_production/,1,2,1.0,[Comment(id='k6im990')]
17aqx10,shani_786,,2023-10-18 13:33:00+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17aqx10/autonomous_driving_ellipsoidal_constrained_agent/,Autonomous Driving: Ellipsoidal Constrained Agent Navigation | Swaayatt Robots | Motion Planning Research,,learnmachinelearning,/r/computervision/comments/17aqu0v/autonomous_driving_ellipsoidal_constrained_agent/,0,1,1.0,[]
17am2wd,Lemon_Salmon,,2023-10-18 08:56:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17am2wd/some_maths_behind_rope/,Some maths behind RoPE,"Hi all,I have some questions on this paper : [Effective Long-Context Scaling of Foundation Models](http://arxiv.org/abs/2309.16039) , specifically the appendix proof section on page 20.

1) Why on the left side, there is only *sin()* highlighted in red color ?  JianLin Su, who is also the author of the [RoFormer paper](https://arxiv.org/abs/2104.09864) suggested that the *sin()* notation highlighted in red color may be wrong.  Any comments on this ?

https://preview.redd.it/bx9zfdxsdxub1.png?width=1920&format=png&auto=webp&s=38b093ea7fbbd71052511ded6939cd412787587b

&#x200B;

2)  According to [https://kexue.fm/archives/8231#%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5](https://kexue.fm/archives/8231#%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5) , there is also possibility that it will have  *m+n*  besides  *m-n*   for the cosine similarity metric of inner product compute logic.  May I  ask if we could expand the appendix proof to accommodate this as well  ?  Or do I misread / misunderstand anything regarding this ?  Note for the reason of having *m+n* : See the fourier series expansion in  expression (4) of the same chinese article, all the basic explanations  were done using approximation technique of *H=I* ,  but for further understanding, we cannot use this approximation technique, it seems.  Any comments ?

&#x200B;

3)  How would I derive the following equation (5) of [https://zhuanlan.zhihu.com/p/660073229](https://zhuanlan.zhihu.com/p/660073229) ?

https://preview.redd.it/72fzghoodxub1.png?width=962&format=png&auto=webp&s=b07f47125593190c67495e766d2465c53b9991bc

Please advise.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17am2wd/some_maths_behind_rope/,1,2,0.75,[Comment(id='k5dn8kp')]
17ajnn4,Chiragrvijay,,2023-10-18 06:06:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ajnn4/what_and_from_where_to_learn_if_you_are_fresher/,What and from Where to learn if you are fresher in ML?,"I used to be a Front-end developer and recently joined a company as a fresher ML Engineer. I am currently in training and learning about Data Science, Deep learning, and NNs, and after this, I will be mostly working on OCR and the Image-to-text domain. I want to know what things and topics I should learn to upskill my career in this domain and get better opportunities. Cheers",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ajnn4/what_and_from_where_to_learn_if_you_are_fresher/,1,3,0.8,[Comment(id='k5de0xf')]
17anl2h,bububeti,,2023-10-18 10:37:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17anl2h/can_someone_help_me_understand_how_this_neuronal/,Can someone help me understand how this neuronal network produces this output?,"I am talking about [this](https://colab.research.google.com/github/ageron/handson-ml3/blob/main/17_autoencoders_gans_and_diffusion_models.ipynb) page from hands-on 

Where we have these 2 dense layers

&#x200B;

https://preview.redd.it/yyzejt9pvxub1.png?width=650&format=png&auto=webp&s=d7c6231669350192ae9698d0ffd028dce096a5f2

The initial data is a 3D array of elements (x,y,z). The encoder should make it 2D (the 2 Dense argument) so (x,y) and the decoder should make it back to 3D (x,y,z).

When, when we fit the model, the dimensions are back to 2?

&#x200B;

https://preview.redd.it/9mcj1wa1wxub1.png?width=613&format=png&auto=webp&s=c12f9dc78140852e93294f9885ead7935a4bea39

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17anl2h/can_someone_help_me_understand_how_this_neuronal/,0,0,0.5,[]
17ajjl1,Data-Power,,2023-10-18 05:59:00+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17ajjl1/python_or_go_for_ai_app_development/,Python or Go for AI app development?,,learnmachinelearning,/r/ArtificialInteligence/comments/17ajivc/python_or_go_for_ai_app_development/,2,2,1.0,"[Comment(id='k5dds6h'), Comment(id='k5f3r9s')]"
17ajhbh,specialman2,,2023-10-18 05:54:39+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17ajhbh/rtx_4080_vs_7900xtx_for_ml/,RTX 4080 vs 7900xtx for ML?,"Now with amd rocm support for 7900xtx, which gpu would be better for training neural nets? I know that 7900xtx has more gRAM and memory bandwidth but 4080 has more mature AI software support and dedicated tensor cores.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17ajhbh/rtx_4080_vs_7900xtx_for_ml/,3,2,1.0,"[Comment(id='k5eu9v9'), Comment(id='k5h1jbx'), Comment(id='k5hvlfd')]"
17amd00,Major-Researcher-701,,2023-10-18 09:16:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17amd00/stable_diffusion_with_mild_training_of_weights/,stable diffusion with mild training of weights and biases from the initial biases,"i want to try training custom images,i would prefer using the keras\_cv model or extend it.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17amd00/stable_diffusion_with_mild_training_of_weights/,0,1,1.0,[]
17amanz,OwnSi23,,2023-10-18 09:11:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17amanz/im_a_newbie_so_give_me_a_hint/,"I'm a newbie, so give me a hint.","Good afternoon. Please advise me, I really want to work in AI, in the direction of machine learning, what courses I need to take and what skills I need to have to work.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17amanz/im_a_newbie_so_give_me_a_hint/,1,0,0.5,[Comment(id='k5du2sp')]
17aeam6,_tonyshin_,,2023-10-18 01:13:57+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17aeam6/pali3_vision_language_models_smaller_faster/,"PaLI-3 Vision Language Models: Smaller, Faster, Stronger",,learnmachinelearning,https://youtu.be/38_aOvRJLQs?si=7mZx1yHIDIT9iVUz,0,4,1.0,[]
17alp80,Soumya1704,,2023-10-18 08:28:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17alp80/i_want_to_read_newspaper/,I want to read newspaper,"So I am new to ML, I want to convert text in newspaper into audio file and read it in right order ( heading -> sub heading-> text below it etc),  currently I am using yolov8 to identify heading, sub heading, and text block . Is there any better way to achieve this like using rnn or any other model",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17alp80/i_want_to_read_newspaper/,0,1,1.0,[]
17akr8g,Deep_Grab_5058,,2023-10-18 07:20:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17akr8g/seeking_collaborators_for_nonintrusive_load/,Seeking Collaborators for Non-Intrusive Load Monitoring Research," 

Hello fellow Redditors!

I hope this post finds you well. I'm reaching out to the Reddit community because I'm embarking on a fascinating journey into the world of Non-Intrusive Load Monitoring (NILM). I believe this field holds immense potential to revolutionize the way we monitor and manage energy consumption, and I'm looking for collaborators who share this passion.

**What is Non-Intrusive Load Monitoring (NILM)?**

NILM is a cutting-edge technology that allows us to analyze and monitor household or industrial energy consumption without the need for intrusive sensors or meters. Instead, it leverages data from existing power sources to disaggregate and identify individual appliances and devices. This technology has the potential to bring about energy efficiency, cost savings, and sustainability in a non-invasive manner.

**Why Collaboration?**

Research in NILM is multidisciplinary, encompassing electrical engineering, data science, machine learning, and more. It's a field that thrives on collaboration. By joining forces, we can pool our expertise, resources, and innovative ideas to advance NILM research and its real-world applications.

**Who Am I Looking For?**

I'm looking for individuals passionate about energy conservation and the possibilities of NILM. Whether you're a researcher, student, developer, or enthusiast, your contributions and insights can be invaluable. Here are some areas where collaboration is welcome:

1. **Research:** Experts or aspiring researchers interested in exploring NILM techniques, data sources, and applications.
2. **Developers:** Those with coding skills (Python, R, or other relevant languages) who can help build or improve NILM algorithms and tools.
3. **Data Scientists:** Individuals experienced in working with energy consumption data, feature engineering, and model development.
4. **Enthusiasts:** Anyone intrigued by NILM and eager to learn, discuss, and share ideas.

**What's in It for You?**

Collaboration can be a rewarding experience. It's an opportunity to be part of a project with real-world implications, expand your knowledge and network, and potentially contribute to a greener, more sustainable future.

If you're interested, please feel free to leave a comment or send me a direct message. Let's start a conversation and see where our shared passion for NILM can take us. Together, we can make a difference!

Looking forward to connecting with like-minded individuals. Thanks for reading!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17akr8g/seeking_collaborators_for_nonintrusive_load/,0,1,1.0,[]
17a9e8f,Formal-Future-4408,,2023-10-17 21:34:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a9e8f/how_is_it_called_when_instead_of_creating/,How is it called when instead of creating predective models finding patterns in observed data (machine learning) you tried to guess the model theorically through knowledge in the subject?,"Hello There!.

I'm a college student appasionated of machine learning and I've decided to my bachelor thesis about it.  I thought that as an interesting introduction to machine learning, I could introduce it by oppose it to the ""traditional way"": trying to reason it

For example, if I have a string that is vibrating and I want to know to the height of a point in the string in a time, a good physicist can model that (if you add as features the time, the position, the elasticity of the string, the density of the air etc...it will give you the so-called ""wave equation"" that can be solved as it almost deterministic). 

On the other hand, if someone had lots of previous observations (instances),  someone can try to find patterns and through that can make good predictions on the height ¡Without knowing anything about physics (or any other subject)

&#x200B;

There are times that its better to use ""traditional"" models: When you have deep knowledge in the subject and you don't have any previous observations and you can't afford taking thousands of observations

On the other hand: if the subject that we are studying is still new and,we can reason in which way the features are related,  yet we see there is a strong relationship empiracally throught collected data between some variables and the target one, we should use machine learning

&#x200B;

I would like to express this idea properly in a bachelor thesis, ideally with examples of when to use each one or historical precedents. However, I haven't seen any article or book explaining it in proper terms and its frustating me.

&#x200B;

Any help aprecciated. Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a9e8f/how_is_it_called_when_instead_of_creating/,6,3,0.81,"[Comment(id='k5bjv6y'), Comment(id='k5bpjlw'), Comment(id='k5ehzz9'), Comment(id='k5g8hnr'), Comment(id='k5g9p64'), Comment(id='k5qd5an')]"
17a6gpy,Personal-Trainer-541,,2023-10-17 19:28:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a6gpy/xgboost_in_under_3_minutes/,XGBoost in Under 3 Minutes,"Hi there,

I've created a video [here](https://youtu.be/33fGfuleXw0) where I how xgboost works in under 3 minutes.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a6gpy/xgboost_in_under_3_minutes/,1,5,0.86,[Comment(id='k5ggs5k')]
17af1z6,bjergerk1ng,,2023-10-18 01:50:13+00:00,False,,1697594016.0,False,True,False,/r/learnmachinelearning/comments/17af1z6/achieving_peak_matrix_multiplication_performance/,Achieving peak matrix multiplication performance on GPU,"Hi r/learnmachinelearning! I recently went into the CUDA programming rabbit hole. In the process, I came across matrix multiplication and was amazed by how complicated the algorithm is in CUDA (especially if you want to get the best performance). I found the learning process quite gruelling (the CUDA docs were very average), so I wrote a tiny blog which hopefully helps anyone in the same position.

You can read the blog on [Medium (no paywall)](https://towardsdatascience.com/matrix-multiplication-on-the-gpu-e920e50207a8?source=friends_link&sk=020a915e1fce7d910aacda22bce89129) or [HackMD](https://hackmd.io/@andylo/matrix-multiplication-on-gpu). It would probably be quite useful if you want to get a deeper intuition of how things like OpenAI Triton or FlashAttention work under the hood.

Accompanying this is an implementation of a 3-hidden-layer MLP trained on MNIST in pure CUDA. Benchmarking this against PyTorch, it gets up 6x higher end-to-end training speed for small (h=128) networks, and asymptotically 20% faster for large (h=8192) ones!

It's worth noting that I tried reasonably hard optimising the PyTorch implementation by using full fp16, `torch.compile` with `fullgraph=True, mode=""max-autotune""`, and pre-loading all data to GPU up-front (I also did this for the CUDA implementation).

The main takeaways I got are:

* For small networks, PyTorch/Python still incurs a significant overhead, even if you try pretty hard to optimise it.
* For large networks, most of the speedup comes from using fp16 accumulation for matrix multiplication (instead of PyTorch's fp32). This obviously reduces stability, but at least in my case, I didn't observe any numerical issues. In cases where we can get away with fp16, we *might* be leaving a significant amount of performance on the table!
* Anecdotally, you have to try **really** hard in CUDA to even get close to the performance of PyTorch, but it is possible to beat it if you try hard (suffer) enough.

You can check out the repo here: [https://github.com/andylolu2/cuda-mnist](https://github.com/andylolu2/cuda-mnist).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17af1z6/achieving_peak_matrix_multiplication_performance/,0,0,0.5,[]
179shyy,av_community,,2023-10-17 07:08:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179shyy/llms_for_the_infinite_input_lengths_are_here/,LLMs for the infinite input lengths are here!,"🔍A team of researchers from Meta AI and MIT developed **StreamingLLM**, a framework that enables finite-length LLMs to infinite sequence lengths without finetuning.

🔥Enables Llama 2, Falcon, and MPT to more than 4 million tokens input lengths.

🌟Applying LLMs to infinite input lengths poses 2 challenges:

1️⃣Excessive Memory Storage: During the decoding stage, LLMs store the KV pairs of previous tokens to compute the attention. Having infinite length tends to cause excessive memory storage and increased latency.

2️⃣Performance Degradation: The performance of LLMs degrades if we extend the sequence length beyond the maximum input length set during pretraining.

🎯The team proposed an interesting phenomenon known as attention sinks to overcome the above challenges.

📚Research Paper: [https://arxiv.org/pdf/2309.17453.pdf](https://arxiv.org/pdf/2309.17453.pdf)  
💻 Code: [https://github.com/mit-han-lab/streaming-llm](https://github.com/mit-han-lab/streaming-llm)

What are your thoughts?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179shyy/llms_for_the_infinite_input_lengths_are_here/,11,33,0.83,"[Comment(id='k58cwv3'), Comment(id='k5924mx'), Comment(id='k588pum'), Comment(id='k59m3lr'), Comment(id='k58d1sr'), Comment(id='k5d4jgg'), Comment(id='k5bf9qn'), Comment(id='k5ahk22'), Comment(id='k5bdyip'), Comment(id='k59nrrf'), Comment(id='k59s3g9')]"
17a7dvh,Due_Concentrate1279,,2023-10-17 20:08:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a7dvh/trouble_increasing_accuracy_in_face_recognition/,Trouble increasing accuracy in face recognition task,"Hey everyone

Im trying my hands with the The Labeled Faces in the Wild face recognition dataset, for a face recognition task. I have made a siamesemodel, and my loss curve is looking great but my accuracy stays at 0.500, for everything i have tried. Is there anybody in here that have tried their hands with this task before that can give me some tips to improve my accuracy. I am implementing it in python with PyTorch btw

Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a7dvh/trouble_increasing_accuracy_in_face_recognition/,1,2,1.0,[Comment(id='k5c9bpl')]
17aakmg,Amun-Aion,,2023-10-17 22:24:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17aakmg/help_identifying_research_for_online_cyclic/,Help identifying research for online / cyclic / sequential learning?,"So my situation is that I have a pretrained model and we get a new update of data every month (note: this monthly data is very small compared to the original dataset, the original dataset was about 5 years worth, or \~60x the size of any given monthly update), how can I update my pretrained model on the much smaller set of new data, learning from the data without overfitting to that data?

Or frankly, what would be better if it is possible, would be to extend my pretrained model such that it learns from the new data and then can be more tightly fit to that month's data. So something like meta-learning or local fine-tuning, but I want to continue to update and improve my pretrained model so that I have a base model that can do well on each month's new data. Does anyone know anything like this, or have advance for terms to look into, beyond just transfer learning or regularization?  
 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17aakmg/help_identifying_research_for_online_cyclic/,0,1,1.0,[]
17a32rw,LabOpposite3248,,2023-10-17 17:01:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a32rw/need_advice_as_someone_still_in_high_school/,Need advice as someone still in high school,"Context:

I'm a young guy who is interested in data science/Machine learning , both as a passion and as a career

In hight school

&#x200B;

What I have done so far:

I have learnt python from a few online courses and feel my python fundamentals are okay-ish, though I will probably practice more in the near future. I have learnt numpy,pandas and matplotlib and have worked with a few datasets I found from kaggle.

What I need advice on:

What should I do next? Since I don't really have the time to do Linear Algebra or Calculus due to my tests/exams coming in the following weeks, what else can I do to expand my skillset? Are there any courses that you guys could recommend for someone like me. Should I learn databases like SQL and/or should I learn more tools matlab. Should I start model-building with libraries like scikit learn? Should I expand my coding skills and try and build APIs or do some python scripts? Also what are some good projects that I could do that take time to do but are looked upon well byemployers/colleges?

Any advice is helpful.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a32rw/need_advice_as_someone_still_in_high_school/,4,2,1.0,"[Comment(id='k5aix61'), Comment(id='k5amcey'), Comment(id='k5be6rr'), Comment(id='k5amej2')]"
17a6e6k,Zealousideal-Time455,,2023-10-17 19:25:52+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17a6e6k/introducing_donut_the_ocrfree_document/,Introducing DONUT 🍩: The OCR-Free Document Understanding Transformer Transforming the Way We Process Documents!,,learnmachinelearning,/r/DocumentAI_Community/comments/17a64se/introducing_donut_the_ocrfree_document/,0,1,1.0,[]
17a0ibl,JordaarAce,,2023-10-17 15:07:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a0ibl/resources_to_have_a_quick_look_at_oops_concepts/,Resources to have a quick look at OOPS concepts in Python,"In order to prepare for interview (ML role), what are the best resources to get structured concepts of oops in pyton. I am well versed  in python and its OOPs concepts, but I want to refer it quickly so that I do not miss any concept starting from most fundamental to advance.
The crux is I know all the concepts but I have not made a comprehensive notes of whatever I have learnt. Hence it would be great if someone any geek can help me out by either providing resource or listening down all the available concepts in python OOPs.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a0ibl/resources_to_have_a_quick_look_at_oops_concepts/,0,2,1.0,[]
17a4gdq,Far_Parsley_1761,,2023-10-17 18:01:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a4gdq/which_might_be_the_best_course_to_learn_maths_for/,Which might be the best course to learn Maths for Machine learning and deep learning?,"If you are familiar with Maths for ML then I assume you might also know about the courses present on Coursera, 1. from deeplearning.ai and 2. from Imperial College London. which one might be best suitable for a beginner and would help a lot.

I will audit those courses anyway but apart from those two courses if you have any better courses or videos please feel free to share them with me as I have just started getting interested in the maths part of ML.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a4gdq/which_might_be_the_best_course_to_learn_maths_for/,2,0,0.5,"[Comment(id='k5c9u2i'), Comment(id='k5qfads')]"
179qp7p,xx_geraltofrivia_xx,,2023-10-17 05:07:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179qp7p/what_courses_to_take_for_fundamentals_and_beyond/,What courses to take for fundamentals and beyond in ML,"I am a college student looking to pursue a career in ML. However, ML is obviously not a major so I'm majoring in CS/DS but looking to garner as much ML knowledge as possible with my class choices. What are some key topics/fundamentals I should try to take a class in for a career in ML that may not be part of standard CS curriculum. Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179qp7p/what_courses_to_take_for_fundamentals_and_beyond/,3,9,1.0,"[Comment(id='k59s1q8'), Comment(id='k5atlz1'), Comment(id='k58t5zy')]"
17a2ozi,OnlyProggingForFun,,2023-10-17 16:45:05+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17a2ozi/pro_tips_for_improving_ai_responses_and/,Pro Tips for Improving AI Responses and Performance: How to tune your Language Models!,,learnmachinelearning,https://youtu.be/fylqJ3E4mwQ,0,0,0.5,[]
17a153r,StrangeQuark112358,,2023-10-17 15:35:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17a153r/advice_on_blog_for_basics_of_machine_learning/,Advice on blog for basics of machine learning,"Hello guys!!!

I'm a college students trying to understand and establish myself by helping people understand more about Machine learning from the ground up as I have seen many of my peers struggle to start.

[Basics of machine learning](https://adiyanthy.hashnode.dev/basics-of-machine-learning)

This is my first blog that is a part of a series where I will try and share my knowledge gained by using ML through the years. It'll be both practical and theoretical starting from understanding which programming is the best , what are the approaches we take to use a model and to look in depth for the mathematical concepts. I'll also be discussing the required prerequisites for starting your own ML project.

I request you to look into the content and share your thoughts. And if you like the content a like will be very much appreciated. Thanks for taking the time to read my post.

[View Poll](https://www.reddit.com/poll/17a153r)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17a153r/advice_on_blog_for_basics_of_machine_learning/,0,0,0.5,[]
179yyd0,Lakshmireddys,,2023-10-17 13:56:42+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179yyd0/best_free_machine_learning_courses_online_for/,Best Free Machine Learning Courses Online for Beginners and Intermediate learners,,learnmachinelearning,https://codingvidya.com/best-free-machine-learning-courses-online/,0,1,1.0,[]
179yucb,Mindless-Umpire-9395,,2023-10-17 13:51:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179yucb/understanding_what_it_takes_to_make_an_aiml_pet/,Understanding what it takes to make an AI/ML pet project live,"Hii, I have few questions. It would really mean alot if anyone could guide me on this. Thanks in advance. 

I have worked with KNeighbour Classification on classifying a set of cars with predefined Dataset that I downloaded to check if it matches acceptable criteria or not. Just simple program with Jupiter Notebooks. I want move to the next phase, where I give realtime data to the python service,
like user has select a bunch of cars if they like it or not, based on that, ML should predict whether the rest as acceptable or not. 

I need to have UI, REST API Service to interact with ML.What are the things should I learn to get to this place,

I have good understanding of React, Java and Spring Microservices.  I am new to this Python AI ML World. And so I hope I could understand atleast the basic technical jargons. Thanks in advance.  


Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179yucb/understanding_what_it_takes_to_make_an_aiml_pet/,5,1,1.0,"[Comment(id='k59gqc7'), Comment(id='k59iiil'), Comment(id='k59mehk'), Comment(id='k59mivi'), Comment(id='k59jsth')]"
179urps,sigertt,,2023-10-17 09:58:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179urps/is_there_a_way_to_ensure_features_only_have_a/,Is there a way to ensure features only have a positive effect of on the outcome parameter?,"I am working on a project in which human activity is measured after surgery to find out whether less movement/lower activity after surgery means a higher chance of successful surgery outcome. We have the surgery outcome to train the a supervised model. I want to build a model that in general tells me if all input parameters have a **positive** effect on surgery success. For example, let's say we have 2 parameters:

1. number of times an activity threshold has been exceeded.
2. average activity over time (high = more active)

In both cases you could argue that if the parameter is higher, the person has been more active. Although the parameters are calculated in a different way, they represent the same thing, amount of human activity. If you would train a model, the weights could be tweaked such that parameters 1 increases the success rate and parameters 2 decreases the success rate. If this was the case, we could not conclude that more activity equals a lower surgery success rate.

My question: Is there a way to ensure that the two parameters can only have a positive or negative effect on the outcome parameters?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179urps/is_there_a_way_to_ensure_features_only_have_a/,2,2,1.0,"[Comment(id='k596p4c'), Comment(id='k5dhdlx')]"
179b3x2,Batteredcode,,2023-10-16 17:10:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179b3x2/what_exactly_is_meant_by_experience_with_prompt/,"What exactly is meant by ""Experience with prompt engineering""?","A few jobs I'm applying for specify they want someone experienced with prompt engineering, I know what it is, why people want it, how it fits into the job etc., but if a job application asks you 'what is your experience with prompt engineering' what is a reasonable answer? I get that there are some people who have built portfolios around stablediffusion prompts or whatever, but if I'm largely on the technical side of stuff, what are they looking for beyond me saying ""yeah I've messed around with models to improve their output""? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179b3x2/what_exactly_is_meant_by_experience_with_prompt/,22,21,0.87,"[Comment(id='k552oe2'), Comment(id='k55arzj'), Comment(id='k55eej9'), Comment(id='k5556yh'), Comment(id='k561ntm'), Comment(id='k57sz1d'), Comment(id='k56ajn9'), Comment(id='k56ott9'), Comment(id='k58vhe0'), Comment(id='k5671cb'), Comment(id='k56zmri'), Comment(id='k578lcs'), Comment(id='k58sg7c'), Comment(id='k5a9v3w'), Comment(id='k56d3ra'), Comment(id='k55upln'), Comment(id='k55v4vs'), Comment(id='k55uoql'), Comment(id='k55uq6a'), Comment(id='k58bixr'), Comment(id='k579gkn'), Comment(id='k58bonn'), Comment(id='k57fves')]"
179dll1,Apprehensive_Bad_818,,2023-10-16 18:55:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179dll1/should_i_go_for_ms_in_ai/,Should I go for ms in ai?,"I am in a confusing state in my life and need help from the community. 
I graduated with a Mechanical and Quant Finance degree from a tier 1 college. 
I then worked in data/MLE roles for 3 years. 

Back in college I would say I had zero passion, interest in stuff. However, in job I grew a lot, to the extent that my friends were unable to recognise me as a person. I feel like a completely different person. I developed deep interest in AI and want to do this in the future. I love math as well (although I sometimes don’t put in the work). 

I am planning to applying to these unis: 
1. New Jersey institute of Tech - Ms in AI
2. Illinois Tech - ms in ai
3. Texas A&M - ms in ds
4. Univ of North Texas - ms in ds

My queries: 
1. Is an ms in ai degree worth it? Given I want to really study, do intellectual stuff. 
2. How is the job landscape rn for 3 year work ex + ms degree? 
3. Are my unis good? Should I add some? 


I really wanted to know if I am doing the right thing or am I just being blind?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179dll1/should_i_go_for_ms_in_ai/,15,10,1.0,"[Comment(id='k57kv1h'), Comment(id='k56kwih'), Comment(id='k580vo1'), Comment(id='k56mxuo'), Comment(id='k562q14'), Comment(id='k5ahcvt'), Comment(id='k5cuxnn'), Comment(id='k582svg'), Comment(id='k582n6u'), Comment(id='k582k68'), Comment(id='k582rtf'), Comment(id='k582m0h'), Comment(id='k5qp109'), Comment(id='k58a6pf'), Comment(id='k58s993')]"
179jq5w,Stanford_Online,,2023-10-16 23:12:29+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179jq5w/article_key_concepts_and_open_questions_in_a/,Article: Key Concepts and Open Questions in a Golden Age for Natural Language Understanding,,learnmachinelearning,/r/u_Stanford_Online/comments/179jjrh/article_key_concepts_and_open_questions_in_a/,0,4,0.84,[]
179ce5z,dante_polymathes,,2023-10-16 18:04:46+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179ce5z/automated_hyperparam_tuning/,Automated hyperparam tuning,"Hello guys, I been learning about AI and machine learning and I came across ways you can optimise hyperparameter tuning by automating the processes by using specialised techniques (like using grids, or Bayes optimisation). Do experienced people really use it? Or rather you tune hyperparams by hands?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179ce5z/automated_hyperparam_tuning/,11,11,1.0,"[Comment(id='k55k37m'), Comment(id='k55k0iy'), Comment(id='k569259'), Comment(id='k57cwe4'), Comment(id='k58gb63'), Comment(id='k56m4b1'), Comment(id='k56lwee'), Comment(id='k58nmfz'), Comment(id='k596xgo'), Comment(id='k59okn9')]"
179rt7j,HorrorNo8851,,2023-10-17 06:20:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179rt7j/open_source_ai_fomo_saver/,Open Source AI FOMO Saver,[https://github.com/premAI-io/state-of-open-source-ai](https://github.com/premAI-io/state-of-open-source-ai),learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179rt7j/open_source_ai_fomo_saver/,0,1,1.0,[]
179iriz,stashedcash,,2023-10-16 22:30:04+00:00,False,,1697500882.0,False,True,False,/r/learnmachinelearning/comments/179iriz/need_help_with_synthetic_data/,Need help with synthetic data,"Hey everyone, I'm a recent college graduate and majored in Data Science. I have been an intern at a start up in the role of Machine Learning Engineer and am the only person at the whole company that knows anything about ML... lol... so it all falls on me alone to figure this out and there is a lot of pressure. It has been quite challenging learning to apply everything I've learned at school to the real world but have made good progress since I've started. The biggest problem I've run into since the start has been the amount of data we have. The goal of this project is to predict cost of a renovation for a home based on condition, location, as is price, predicted after renovation price, and more.

After collecting all of our organic data, taking data from competitors, and even predicting values to impute missing data, I only have about 600 rows. They don't want to buy data and it would be really difficult to find this type of data anyways so I feel like I've been set out to complete a nearly impossible task at times.

I recently began trying different methods of synthetic data generation and have seen some improved results from random sampling and adding noise, as this method does well at matching distributions and correlations of the real data, but obviously when generating to 5000 rows it becomes very overfit. I'm not sure if there is enough real data for synthetic data to scale significantly, and even with training the model in an unbiased way it gets to 38% accuracy at best.

I would greatly appreciate any guidance or tips you guys can give about synthetic data generation and if I'm on the right track. Should I ask them to buy more data (if it can even be found)? Or is there another way to make synthetic data that could be real? Any help here would be amazing! Thanks.

&#x200B;

Addition: Also, if anyone has any insight on using a biased model please lmk! The biased model did not produce too bad of results when tested on unseen data but I'm not sure about using this in production",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179iriz/need_help_with_synthetic_data/,7,4,1.0,"[Comment(id='k57edph'), Comment(id='k58kuvs'), Comment(id='k59rv4f'), Comment(id='k5boxhp'), Comment(id='k5bpq59'), Comment(id='k5bpxun'), Comment(id='k5bq7vu')]"
179pqa6,88sSSSs88,,2023-10-17 04:09:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179pqa6/what_books_should_i_read_to_advance/,What books should I read to advance?,"I'm looking to build a knowledge base of ML that more or less approximates that of someone with a master's in the topic. So far, I've read the following books to varying degrees (Numerical Recipes, for example, I've only covered about 10% of):

* Elements of Statistical Learning
* Reinforcement Learning: An Introduction
* All of Statistics
* Data Science from Scratch: First Elements with Python
* Mathematics of Machine Learning
* Numerical Recipes: The Art of Scientific Computing
* Some sort of Expert Systems book and foundational AI books

I would like to build on my mathematical ability and progress towards a functional understanding of NLP and image-based ML systems. What books/fields am I missing that might be important for developing my skillset? I'm open to YouTube and courses, but I prefer books.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179pqa6/what_books_should_i_read_to_advance/,1,1,0.67,[Comment(id='k5892km')]
17954m3,__god_bless_you_,,2023-10-16 12:44:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17954m3/what_topic_do_you_struggle_the_most_to/,What topic do you struggle the most to learn/understand?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17954m3/what_topic_do_you_struggle_the_most_to/,10,16,0.95,"[Comment(id='k54hvl4'), Comment(id='k541p9y'), Comment(id='k55c270'), Comment(id='k55j2t7'), Comment(id='k57kzxc'), Comment(id='k5cr1ls'), Comment(id='k5545fr'), Comment(id='k54m3m4'), Comment(id='k55mm4y'), Comment(id='k5dckpp')]"
179or24,Tyron_Slothrop,,2023-10-17 03:15:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179or24/correlation_formula_almost_identical_to_the/,Correlation formula almost identical to the derivation of MSE for regression?,"Working my way through Intro to Statistical Learning. I'm currently slowly working towards understanding the derivation of the cost function (MSE). Looking at the textbook and the following link ([https://seismo.berkeley.edu/\~kirchner/eps\_120/Toolkits/Toolkit\_10.pdf](https://seismo.berkeley.edu/~kirchner/eps_120/Toolkits/Toolkit_10.pdf)), the final derivation of the slope and the y-intercept look very similar. I'm sure this is obvious, but are they closely related? I'm guessing the derivation is similar because it's determining the rate of change and correlation describes the relation ships b/w two variables. Am I completely getting this wrong? 

&#x200B;

Correlation: 

https://preview.redd.it/m7qgmkz8joub1.png?width=454&format=png&auto=webp&s=07d4c6b360edb099f5e9356bd0a40e319c622137

MSE derivation: 

&#x200B;

https://preview.redd.it/yurq9ejdjoub1.png?width=527&format=png&auto=webp&s=bb0fb0b826dc75a089e60641889e8761ddf30725",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179or24/correlation_formula_almost_identical_to_the/,0,0,0.5,[]
179j64v,husama23,,2023-10-16 22:47:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179j64v/tensorflow_h5_model_conversion_issues/,Tensorflow .h5 model conversion issues,"Hi all,

I am working on a machine learning program to identify vehicle makes/models. I trained and ran it in google colab using a MobileNetV2 base and saved the model using keras as a .h5. My issue is to get it deployed using a firebase database, it has to be a .tflite model and when I try the conversion I get errors due to it being too complex. How can I go about fixing that?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179j64v/tensorflow_h5_model_conversion_issues/,1,2,1.0,[Comment(id='k5alhgx')]
179nidn,Brilliant-Coach-9389,,2023-10-17 02:12:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179nidn/i_need_help_with_some_tensorflowkeras_codes/,I need help with some Tensorflow/Keras codes,Can anyone help me implement PointCNN any other neural network model (any two aside PointNet++) to segment the DALES 3D point clouds? I need this for my project work. I'll tip you 💶.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179nidn/i_need_help_with_some_tensorflowkeras_codes/,0,0,0.5,[]
179915a,Intrepid_Rub_3566,,2023-10-16 15:44:18+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179915a/llm_chronicles_this_is_a_fastpaced_youtube_series/,LLM Chronicles: This is a fast-paced YouTube series with whiteboard animation and mindmaps perfect for those that want to learn or revise the foundations behind neural networks and language models.,,learnmachinelearning,https://llm-chronicles.com/,0,6,1.0,[]
179dseh,Content-Quiet7017,,2023-10-16 19:03:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179dseh/confused_need_some_advice/,"Confused, need some advice","I have been working in a project where we will use AI to detect depression, and I am building the ML model. Me a total beginner is confused and stuck that how and where should I start from. I have training data in pdf as questions where the user will give their answer from 0-3 according to how that question affected them in the past week. Totally confused and not knowing where to go, so I hope someone from here can help with the approach and what are the things to keep in mind.
Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179dseh/confused_need_some_advice/,11,3,1.0,"[Comment(id='k58wx9k'), Comment(id='k59nwkq'), Comment(id='k55mc6k'), Comment(id='k576g4l'), Comment(id='k59bzmv'), Comment(id='k5910xk'), Comment(id='k582p9k'), Comment(id='k583ks9'), Comment(id='k582wto'), Comment(id='k5amimu'), Comment(id='k5a485n')]"
179lsml,Careless_Committee99,,2023-10-17 00:50:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179lsml/online_course_for_machine_learning_economics_stats/,Online Course for Machine Learning (Economics & Stats),"Hi All, 

I'm looking for an excellent online course to learn machine learning and its application in R or Python. My objective is to utilize Python/R for Machine Learning. I have a background in economics and intermediate r/Python skills. Any suggestion would be greatly appreciated. I prefer a 1 month - 4 month online course. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179lsml/online_course_for_machine_learning_economics_stats/,2,0,0.5,[Comment(id='k59clsv')]
178zuks,AsDivyansh,,2023-10-16 06:50:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178zuks/free_courses_to_learn_about_large_language_models/,Free courses to learn about Large Language Models and building AI projects,"[**LLMOps Space Discord**](https://llmops.space/discord): LLMOps Space is a global community for LLM practitioners.

[**LangChain for LLM Application Development by Andrew Ng**](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/): Apply LLMs to your proprietary data to build personal assistants and specialized chatbots. 

[**Full Stack LLM Bootcamp**](https://fullstackdeeplearning.com/llm-bootcamp/): Learn best practices and tools for building LLM-powered apps 

[**Stanford CS324**](https://stanford-cs324.github.io/winter2022/): In this course, students will learn the fundamentals about the modeling, theory, ethics, and systems aspects of large language models, as well as gain hands-on experience working with them. 

[**LangChain & Vector Databases in Production**](https://learn.activeloop.ai/courses/langchain): Learn how to leverage LangChain, a robust framework for building applications with LLMs, and explore Deep Lake, a groundbreaking vector database for all AI data. 

[**Stanford CS25**](https://web.stanford.edu/class/cs25/): In this course, learn how transformers work, and dive deep into the different kinds of transformers and how they're applied in different fields. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178zuks/free_courses_to_learn_about_large_language_models/,0,24,0.93,[]
179a16g,Tyron_Slothrop,,2023-10-16 16:26:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179a16g/derivation_of_ols_questions/,Derivation of OLS questions,"I'm using the following link to dive into the calculus of OLS: [https://are.berkeley.edu/courses/EEP118/current/derive\_ols.pdf](https://are.berkeley.edu/courses/EEP118/current/derive_ols.pdf). This article is fantastic and makes sense, but I have some rudimentary questions as someone without a math background.

https://preview.redd.it/obyauccublub1.png?width=1031&format=png&auto=webp&s=5149ed2bd2e9b168a473c906b2d37d00d8009191

I understand the above with the exception of the ""algebraic fact"" that yi = Ny\_bar. 

1. What does that mean explicitly? Is it just saying the sum of N samples multiplied by the mean of y equals y? 
2. why do we immediately remove -2? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179a16g/derivation_of_ols_questions/,3,3,0.81,"[Comment(id='k550mxq'), Comment(id='k550tgg'), Comment(id='k5510sg')]"
179tmng,Otarih,,2023-10-17 08:34:09+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179tmng/ai_wont_obey_its_creators/,AI Won’t Obey Its Creators,,learnmachinelearning,https://absolutenegation.wordpress.com/2023/09/22/ai-wont-obey-its-creators/,0,0,0.13,[]
179anza,niszoig,,2023-10-16 16:52:31+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179anza/i_animated_a_forwardpass_through_an_equivariant/,I animated a forward-pass through an Equivariant Neural Network. Hoping this helps out the visual learners among us to get started with Geometric Deep Learning!,,learnmachinelearning,https://youtu.be/p8ZADylZwyE?si=w3G-4DtNZMR2eyRc,1,3,1.0,[Comment(id='k54ya74')]
17984tk,onurbaltaci,,2023-10-16 15:05:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17984tk/i_share_3_data_science_videos_tutorials_courses/,"I share 3 Data Science videos (Tutorials, Courses and Projects) every week on YouTube","Hello, I shared 20+ data science projects on my YouTube channel. I'm sharing 3 data science videos each week. You can find tutorials, interview questions and solutions, full courses and projects on my YouTube channel. I am adding the link of projects playlist and my channel link in the post, thanks for reading. Have a great day!

Data Science Projects -> https://youtube.com/playlist?list=PLTsu3dft3CWg69zbIVUQtFSRx_UV80OOg&si=7LoKPhRBanXpGWCt

Full Courses -> https://www.youtube.com/playlist?list=PLTsu3dft3CWhraC3rQ9sZZNC-2LmICJUQ

My channel -> https://youtube.com/@onurbltc",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17984tk/i_share_3_data_science_videos_tutorials_courses/,0,3,0.8,[]
179830m,mxcdh,,2023-10-16 15:03:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179830m/what_is_the_best_way_to_validate_and_return_data/,What is the best way to validate and return data through an API?,"When I use an API, I employ ts-node and axios without any libraries. I always inform GPT in the prompt about the desired data and the expected data format for the response. For example:

```
Return 
```json
{""items"":
  [
    {
    ""1"": ""City"",
    ""2"": ""City"",
    ""3"": ""City"",
    ""4"": ""City"", 
    ...
    }
  ]
} 
```

Out of 10,000 requests, 20% of them are incorrect, and I have to repeat them. I validate the returned response using the Joi library.

Perhaps it would be better to validate the data at the prompt submission level. Is it too much that 20% of the data is not validated?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179830m/what_is_the_best_way_to_validate_and_return_data/,0,3,1.0,[]
179amux,Practical_Ad_8782,,2023-10-16 16:51:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179amux/finetuning_llm_on_research_papers/,Fine-tuning LLM on research papers,,learnmachinelearning,/r/LanguageTechnology/comments/179aid1/finetuning_llm_on_research_papers/,0,2,1.0,[]
179fv52,Clorr13,,2023-10-16 20:30:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179fv52/ml_playtesting_of_space_hulk_boardgame/,ML play-testing of Space Hulk boardgame,"Hello ML guys! My ADD brain has just fixated on the idea of play-testing new maps, missions, and factions for Space Hulk using ML.

Has anyone done something similar to this? I'd love to be pointed to any good resources or meet anyone who would also be interested in working on this type of thing.

I am a mechanical engineer that has never actually done any work with ML and I am brushing a significant amount of rust off of my C++ skills. But I believe that I have a good conceptual understanding of ML, at least as compared to others with a similar lack of experience.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179fv52/ml_playtesting_of_space_hulk_boardgame/,0,0,0.5,[]
179dvub,xxjohntheman,,2023-10-16 19:07:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179dvub/oversampling_methods_for_yolov5_object_detection/,Oversampling Methods for YOLOv5 Object Detection Model,"I have been tasked to implement SMOTE and Random Oversampling (ROS) from `imblearn` in Python to counter the class imbalance for our model. What is the best way to implement this? My initial guess is to extract first the sub-images determined by the bounding boxes (in the labels) to know the minority classes of the dataset. In this case, the sub-images will become the new dataset. However, I think there will be a problem in predictions since the background and foreground will be cropped. Is an oversampling method such as SMOTE and ROS really applicable in this situation?

Are there oversampling methods, especially for YOLO-supported datasets, where an image may have several objects (determined by bounding boxes) of varying classes? Thank you for any help.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179dvub/oversampling_methods_for_yolov5_object_detection/,0,1,1.0,[]
178kxtk,shreethar,,2023-10-15 17:56:39+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/178kxtk/predicted_value_for_rnn_is_slightly_shifted_and_i/,Predicted value for RNN is slightly shifted and I don't know why,"This is a model to predict temperature, during the testing phase, the predicted value is slightly shifted to the right but the shape is almost similar. Just for reference or summ, the second image is the predicted value of the data that the model trained on. I am new to this LSTM, so I really do need your help. What's the problem and what would be the solution for it? Or is this a common thing?",learnmachinelearning,https://www.reddit.com/gallery/178kxtk,38,103,0.96,"[Comment(id='k509c2j'), Comment(id='k5117qz'), Comment(id='k50pue0'), Comment(id='k50ij34'), Comment(id='k51ungx'), Comment(id='k50umf2'), Comment(id='k51kua5'), Comment(id='k53dn2l'), Comment(id='k53hktz'), Comment(id='k52j3eq'), Comment(id='k53t6br'), Comment(id='k54j6h1'), Comment(id='k55pc1x'), Comment(id='k58nib3'), Comment(id='k50ame0'), Comment(id='k51la0r'), Comment(id='k51l7nu'), Comment(id='k51zz7e'), Comment(id='k52vb46'), Comment(id='k54kvj8'), Comment(id='k50qwtq'), Comment(id='k50yq4t'), Comment(id='k50v1bk'), Comment(id='k50be18'), Comment(id='k521tn7'), Comment(id='k53s4lf'), Comment(id='k52j1xm'), Comment(id='k54lnmq'), Comment(id='k50caif'), Comment(id='k52384x'), Comment(id='k52vpiw'), Comment(id='k50g1rp'), Comment(id='k523guf'), Comment(id='k52y4so'), Comment(id='k52zmke'), Comment(id='k5345rz'), Comment(id='k54dvgc'), Comment(id='k54m5e5')]"
179b9v3,ledmmaster,,2023-10-16 17:17:42+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179b9v3/8_ways_to_calculate_correlation_between_two_time/,8 Ways To Calculate Correlation Between Two Time Series In Python,,learnmachinelearning,https://forecastegy.com/posts/correlation-between-two-time-series-python/,0,1,0.67,[]
179b28e,yvonnejensen,,2023-10-16 17:08:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179b28e/image_classification/,Image classification,"I'm trying to automatically organize some images and been searching all day for some open source software/solution but come up short.

Say I have two folders with images of dogs or cats already organized correctly. Is there a way to train on those images to classify new images and have the script put new images into the right dog or cat folder?

I am a complete beginner with this 😬 If anyone can recommend a book on this subject that'd be awesome too 🤗",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179b28e/image_classification/,1,1,0.67,[Comment(id='k55ns91')]
179927p,quagzlor,,2023-10-16 15:45:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/179927p/trying_to_create_a_dataset_for_a_game_ml_model/,"Trying to Create a Dataset for a Game ML Model Using PyGame, How Can I Save the Image Data?","Heya folks.

So, I've got a version of tetris running on pygame, and i'm taking the data every tick, of the user's inputs and the screen state.

the screen state is represented by a 2d numpy array, essentially an image array.

now, when i need to store the data, i've tried using pickle and numpy pickle.

however, for maybe 10-20 seconds of play time, the size of the pickle files is coming to around 2 GB, which is crazy, especially considering that we ideally want users to play for 10 min each.

is there something i'm missing or doing wrong here? the image arrays are roughly 700x800, but even then the file size seems ridiculously huge (i checked the number of image arrays, roughly 2000 or so)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/179927p/trying_to_create_a_dataset_for_a_game_ml_model/,1,1,1.0,[Comment(id='k54zz7e')]
178uz2f,shaongit,,2023-10-16 01:52:46+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/178uz2f/ml_algorithms_implemented_from_scratch/,ML Algorithms implemented from Scratch,,learnmachinelearning,https://github.com/shaongitbd/Machine-Learning-From-Scratch,0,8,0.84,[]
1795s2w,AutomaticResearch337,,2023-10-16 13:18:35+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1795s2w/image_detection_with_cnn_model/,Image Detection with CNN Model,,learnmachinelearning,/r/datascience/comments/17316vc/image_detection_with_cnn_model/,0,0,0.5,[]
179a3d6,kingabzpro,,2023-10-16 16:29:01+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/179a3d6/the_generative_ai_bubble_will_burst_soon/,The Generative AI Bubble Will Burst Soon,,learnmachinelearning,https://www.kdnuggets.com/the-generative-ai-bubble-will-burst-soon,6,0,0.46,"[Comment(id='k54vvch'), Comment(id='k56a7ac'), Comment(id='k58iier'), Comment(id='k559xc7'), Comment(id='k55cfle'), Comment(id='k56ubdg')]"
178wuf3,Tyron_Slothrop,,2023-10-16 03:33:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178wuf3/anova_for_scikitlearn/,ANOVA for Scikitlearn?,"I'm having trouble finding a simple way to print an ANOVA table. It looks like I would need to build a model using OLS, which works:

    import statsmodels.api as sm
    
    # Create your feature matrix X and target variable y
    X = ...
    y = ...
    
    # Fit an OLS (Ordinary Least Squares) model using StatsModels
    model = sm.OLS(y, sm.add_constant(X)).fit()
    
    # Access p-values and F-statistic
    p_values = model.pvalues
    f_statistic = model.fvalue
    
    print(""P-values:"", p_values)
    print(""F-statistic:"", f_statistic)


but what about using scikitlearn? There's got to be a way to print an ANOVA table?  


    final_model = LinearRegression()
    
    final_model.fit(X,y)
    
    p_values = final_model.pvalues
    f_statistic = final_model.f_statistic
    

Error:  **AttributeError**: 'LinearRegression' object has no attribute 'pvalues'   


Is there another way to get an ANOVA table?

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178wuf3/anova_for_scikitlearn/,2,3,0.72,"[Comment(id='k53m9q9'), Comment(id='k55609d')]"
178yjkm,theromanempire1923,,2023-10-16 05:18:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178yjkm/how_can_i_predict_a_class_for_the_next_instance/,How can I predict a class for the next instance in a sequence of labeled data while accounting for input features as well as the previous instances in the sequence?,"I'm having some trouble getting started on a project and looking for some help.

My data is tabular, having multiple features as well as a class label for each sample. However, the samples are grouped into distinct sequences such that the order of samples within each sequence is important. The sequences themselves are technically ordered, but more-or-less independent.

I want to make a model to predict the label of a sample given both it's input features, as well as the input features and labels of the previous samples in its sequence. If a sample is the first in its sequence, then it would be mostly (if not completely) based on its input features.

I've tried researching some methods, and found that multivariate time series forecasting will help account for the input features as well as the previous samples in the sequence. However, all the examples I came across dealt with one continuous series of samples over time, whereas I am dealing with multiple discrete sequences. Each sequence is in the neighborhood of 1-10 samples long, so I can't really train each sequence individually, but I would have to predict the next label in a sequence based on the patterns of other discrete sequences. I also read some about NLP models that predict the next word given the previous words in a sentence, google search, etc., which seems to align more with the disjointed nature of my data, but this type of model is only concerned with the labels/symbols of the previous inputs themselves, not any feature set.

Just wondering if anyone can point me in the right direction in terms of a data formatting and modeling technique that could deal with both the presence of input features and the distinct set of sequences as opposed to one continuous series. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178yjkm/how_can_i_predict_a_class_for_the_next_instance/,0,2,1.0,[]
178d0mi,SeaResponsibility176,,2023-10-15 11:02:25+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/178d0mi/do_you_see_anything_wrong_in_this_deep_learning/,Do you see anything wrong in this deep learning training process?,,learnmachinelearning,https://www.reddit.com/gallery/178d0mi,13,52,0.91,"[Comment(id='k4yv6zq'), Comment(id='k4yokmq'), Comment(id='k4zrdyl'), Comment(id='k4zdodf'), Comment(id='k4ziuwa'), Comment(id='k4zqe94'), Comment(id='k503e2m'), Comment(id='k4zwuhj'), Comment(id='k503b32'), Comment(id='k53nyws'), Comment(id='k51z48v'), Comment(id='k53m5g7'), Comment(id='k53hknb')]"
178u6ce,Jncocontrol,,2023-10-16 01:10:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178u6ce/what_are_some_good_resources_to_learn_ml_ai/,What are some good resources to learn ML / AI,"So as a brief introduction, I'm trying to be a Web Developer, I've made a handful of websites, I'm currently trying to make a Fullstack app with Nuxt3, but I'm wanting to learn ML soon, but I have no experience in Python, I have no greviences with Python, just not my cup of tea personally. I'd like to use Tensorflow with JS with Node / Bun.  


[https://www.tensorflow.org/js](https://www.tensorflow.org/js)  


What are some good resources to learn? I've looked at the docs, and looks like a good first step, but something more elaborate.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178u6ce/what_are_some_good_resources_to_learn_ml_ai/,8,3,0.8,"[Comment(id='k52ovvl'), Comment(id='k53agu6'), Comment(id='k53spgf'), Comment(id='k570zzp'), Comment(id='k5751dw'), Comment(id='k59czag'), Comment(id='k5c0m8b')]"
178mv4s,Tyron_Slothrop,,2023-10-15 19:25:10+00:00,False,,1697400489.0,False,True,False,/r/learnmachinelearning/comments/178mv4s/analyst_role_portfolio/,Analyst role portfolio?,"I’m working on getting another analyst role but more focused on ML and stats. I have a GitHub with a number of projects I worked on, but I feel like I have too much on there. I’m not qualified for a Data Science role but am looking for an analyst role that has some DS tasks. What should my portfolio focus on? I’m thinking I should have some basic model examples: regression (linear and logistic), Random Forest, KNN, basic NN. Anything else I should absolutely show in the portfolio? I also have a few Python scripts I used for previous jobs and an sql query page.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178mv4s/analyst_role_portfolio/,0,7,0.9,[]
178gj9c,floaust,,2023-10-15 14:27:39+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178gj9c/i_wrote_a_guide_to_better_understand_the_metrics/,I wrote a guide to better understand the metrics for regression in machine learning,"I wrote my bachelors' thesis about machine learning and thought why not share my conclusions and information with other people. I hope this helps some people, especially to understand these metrics a bit better on a higher and more mathematical approach.

&#x200B;

This is a friend link, so you don't need to pay to read it.

[https://medium.com/illumination/machine-learning-metrics-for-regression-095bad70bacc?sk=a811b377e92d3f47cda07a4c480eff9a](https://medium.com/illumination/machine-learning-metrics-for-regression-095bad70bacc?sk=a811b377e92d3f47cda07a4c480eff9a)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178gj9c/i_wrote_a_guide_to_better_understand_the_metrics/,0,7,0.89,[]
178hfrw,Formal-Future-4408,,2023-10-15 15:10:34+00:00,False,,1697394265.0,False,True,False,/r/learnmachinelearning/comments/178hfrw/how_is_it_called_when_the_relationship_between/,"How is it called when the relationship between the predictive variables with the target one isn't strong, thus you can't make good prediction even with the strongest and robust methods?","In order to make good predictions, we need to suppose that the relationship between the predictive variables and the target variable is strong enough.

How is it called a dataset like that (that with the right tools you can in fact make good predictions).

How do you call when a predictive variable isn't at all related to the target variable and is not useful to the point we can assure to the data collector to save money by not reporting that unuseful feature?

Is it the same that saying that this feature with the target variable are independent (I think that no, its not the same that individually a feature is independent of the target variable)

How is it call when a predictive feature has almost not importance in a particular model?

Finally, with an ultrapowerful method like XGBoosting which is able to find any kind of weird relationship, if a feature have 0 relevance, can I tell to the data collector to save money cost by not collecting that feature?

I'm trying to learn machine learning on tabular data by myself and I find it a little bit difficult to any help appreciated. I mayored in stadistics so I'm familiar with stadistics terminologu



I'm trying to learn machine learning on tabular data by myself and I find it a little bit difficult to any help appreciated 😊",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178hfrw/how_is_it_called_when_the_relationship_between/,15,4,0.83,"[Comment(id='k4zqpty'), Comment(id='k511wp5'), Comment(id='k50iq9z'), Comment(id='k51hf7e'), Comment(id='k52po3i'), Comment(id='k52s9ez'), Comment(id='k4zzu1e'), Comment(id='k50lo13'), Comment(id='k504pyj'), Comment(id='k5161md'), Comment(id='k52rosa'), Comment(id='k539g3o'), Comment(id='k52dged'), Comment(id='k52duwn'), Comment(id='k5qywvq')]"
178ovlk,Time-Project,,2023-10-15 20:57:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178ovlk/need_few_suggestions_regarding_this_experiment_i/,Need few suggestions regarding this experiment (i think deepsort might work),"i am experimenting of trying to do things using box ids, like lets say there are 3 detections and they get 3 unique ids, so what iam trying to do it ""click picture of ID number 2 then move on to 3 then move on to 1"" one by one in ascending order of ID. Is it possible to do so using yolov8 tracker? i think just like we get xyxy in list/array is there something which has box id and xyxy together in a list and box id representing them
one more example can be of ""focus on this particular ID for 3 seconds and move on to next ID""",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178ovlk/need_few_suggestions_regarding_this_experiment_i/,0,1,1.0,[]
178olda,Beautiful-Simple1816,,2023-10-15 20:44:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178olda/grade_7_project_17_un_sdg_game/,Grade 7 Project - 17 UN SDG Game,"My son’s teacher assigned him a project to create a game centered around the 17 UN Sustainable Development Goals (SDGs). Although coding hasn’t been taught in class, he has some basic knowledge of Python. Is this a typical assignment, and how can I assist him in tackling this project? I’m feeling a bit lost about where to begin.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178olda/grade_7_project_17_un_sdg_game/,0,0,0.33,[]
178nrau,MonkeyMaster64,,2023-10-15 20:05:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178nrau/best_opensource_model_for_receipt_scanning/,Best open-source model for receipt scanning?,I'd like to extract data from random receipts. I believe there are some solid models out there that could be up to this like PaddleOCR or LayoutLM however I'd love some recommendations if there are more accurate models that are now available.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178nrau/best_opensource_model_for_receipt_scanning/,0,1,1.0,[]
178drga,akshaaaat,,2023-10-15 11:52:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178drga/suitable_model_for_multilabel_classification/,Suitable model for multi-label Classification problem with small dataset.,"Hi,
I am new to machine learning, I would like y’all to suggest the best approach in order to classify inputs. Here is my use case:

I am trying to classify certain ‘Problem Descriptions’ to ‘Functionality’. These functionality classes are part of the training data set and I would like the test data sets to be classified from the classes present in the training dataset itself. 
In the ‘Problem Description’ there are multiple inputs such as the function names that are being altered as well as a good description of the problem. In many cases the exact class is also present in the Problem description itself.

I currently have around 300 datasets having around 30 classes. The training data will continue to grow as I fetch more data, but I want a solution wrt the current situation.

I have currently tried to implement DistilBert for Sequence Classification but that is giving me around 20% accuracy while I would require atleast 60-70% accuracy wrt the current dataset, that I can improve further. 

What algorithm/approach would you recommend for the following problem?

Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178drga/suitable_model_for_multilabel_classification/,4,5,1.0,"[Comment(id='k4zq5ak'), Comment(id='k4z1cm6'), Comment(id='k504gyh'), Comment(id='k4z285z')]"
178czp6,indusop,,2023-10-15 11:00:57+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/178czp6/interested_about_cricket_and_data_science_here_is/,Interested about cricket and data science ? Here is my new article on medium about building the IPl Win Predictor from scratch please have a look!!,,learnmachinelearning,https://medium.com/@harshsmj1504/ipl-win-predictor-analyzing-winning-probabilities-d9f4f38e0226,0,2,0.67,[]
178j4vi,Content_Cloud2049,,2023-10-15 16:30:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178j4vi/struggling_to_extract_data_from_a_pdf_and_convert/,Struggling to Extract Data from a PDF and Convert to Excel - Need Help!,"I have a PDF document similar to the one I've attached below. I'm facing challenges in extracting data from it and converting it into an Excel format. Is there anyone here with experience in PDF data extraction who could assist me in this process?  
The whole pdf link here⬇️  
Link: https://drive.google.com/file/d/1AQ0MvWc0O44QdQ7Z-0FEg7ri0y2\_b0Wo/view?usp=sharing",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178j4vi/struggling_to_extract_data_from_a_pdf_and_convert/,0,1,1.0,[]
178h072,Alexisbou1,,2023-10-15 14:50:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/178h072/video_frames_permutation_based_on_action/,Video frames permutation based on action recognition,"Hello,

I recently came across this video: [https://vimeo.com/584985260](https://vimeo.com/584985260). The editor claims this edit was AI-assisted.

I'm trying to recreate this kind of processing with python and OpenPose. So far I can extract skeleton keypoints and compute an euclidian distance for each keypoint between frames. I think this could be useful down the line.

I can see how a CNN (such as the one in OpenPose's library) could be useful to extract skeleton keypoints from frames of each videos. But I'm at a loss for the next steps. Here's what I want to explore:

* Action recognition based on keypoints to classify different frames (running, rolling, doing a backflip)
* Stitching the frames that have to most similar keypoints to try and recreate a movement from many different videos

Do you guys have any pointers, ideas or examples on how I could recreate this video?

Thanks a lot!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/178h072/video_frames_permutation_based_on_action/,0,1,1.0,[]
17889h5,chipkii,,2023-10-15 05:17:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17889h5/how_should_i_approach_ml_as_a_design_major/,How should I approach ML as a Design major?,"I'm currently enrolled in Digital Media and Virtual Production. But I think AI/ML is a tool that can be applied anywhere. Besides learning Digital Media, I want to be proficient with ML.

My goal for learning ML isn't necessarily jobs, but I want to implement AI models into virtual production (solely for research, or to speed up my regular workflow).

Do you think it is a good idea? If so, are there any resources you can recommend? ( I'm not a total noob as I've learned Python and a lot of relevant math concepts)

Thanks in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17889h5/how_should_i_approach_ml_as_a_design_major/,10,5,0.78,"[Comment(id='k4y4dq3'), Comment(id='k4y0tf6'), Comment(id='k4ytaln'), Comment(id='k4ycnzb'), Comment(id='k4y8108'), Comment(id='k4y64rq'), Comment(id='k4yom11'), Comment(id='k4yoqom'), Comment(id='k4y7417')]"
1786k07,superrobinL,,2023-10-15 03:30:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1786k07/a_lightweight_ai_model_and_framework_for_text/,a Lightweight AI Model and Framework for Text Summarization in the Browser using JavaScript,"I am currently looking for recommendations on a suitable AI model and framework that can be directly executed in a web browser using JavaScript. My goal is to utilize this AI module and framework to perform simple text summarization tasks.

Considering the limitations of browser performance, I am particularly interested in finding a model that is compact in size. This will ensure efficient execution within the browser environment without compromising on functionality.

I would greatly appreciate any suggestions or insights you may have regarding lightweight AI models and frameworks that are compatible with JavaScript and can be seamlessly integrated into web applications. Additionally, if you have any experience or recommendations for text summarization specifically, I would be grateful to hear about them.

Thank you in advance for your assistance and expertise!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1786k07/a_lightweight_ai_model_and_framework_for_text/,2,4,0.75,"[Comment(id='k4xpoh5'), Comment(id='k4z3fqp')]"
1789wn6,Arihant_bhandari,,2023-10-15 07:13:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1789wn6/need_help_with_a_deep_learning_models_training/,Need Help with a deep learning model's training,"Hello , I am a college student currently working on a CNN model , wherein I am using ~4500 images. 

I have all necessary libraries installed and am currently getting an accuracy score of 87% ; while working towards improving efficieny , I noticed that the training was done on CPU instead of GPU ( rtx 3060 notebook ) since it is taking a lot of time to train it on comparing it with no. of images vs gpu.

I tried some things and found that no GPUs were displayed when I ran the prompt :

import tensorflow as tf

gpus = tf.config.list_physical_devices('GPU')

print(gpus)

I think my laptop's GPU isnt set up and hence require help doing so. I tried searching things but most of the guides I found were in regards to 2019 or so.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1789wn6/need_help_with_a_deep_learning_models_training/,5,2,1.0,"[Comment(id='k4y8jgg'), Comment(id='k4ztbf0'), Comment(id='k4y9eft'), Comment(id='k4zuc9x'), Comment(id='k53qq10')]"
178bfev,Individual_Ad_1214,,2023-10-15 09:05:22+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/178bfev/how_to_undertake_exploratory_data_analysis_for_a/,How to undertake exploratory data analysis for a Multi-Task Problem,,learnmachinelearning,/r/MLQuestions/comments/178bf5d/how_to_undertake_exploratory_data_analysis_for_a/,0,1,1.0,[]
1785wwk,Seankala,,2023-10-15 02:54:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1785wwk/does_using_initialization_techniques_like_xavier/,Does using initialization techniques like Xavier initialization require different hyperparameter settings or regularization techniques?,"I have a Transformer implementation that I'm working on. The Transformer model is the original encoder-decoder sequence2sequence model introduced in the 2017 paper. I wasn't originally using any form of initialization and decided to apply Xavier initialization.

What I found was that the model wasn't training properly and was outputting meaningless text. The gradients also seem rather small and then collapse to zero, as shown in the image below (top is with Xavier, bottom is without - visualized using W&B):

https://preview.redd.it/m6sw5jbk6aub1.png?width=5056&format=png&auto=webp&s=ffa61c346fee81b1df359763f7f0450bbda2a47c

https://preview.redd.it/gxe2qzcl6aub1.png?width=5056&format=png&auto=webp&s=1103b79d2ceee6d183f653b8f91236515e7c8dd1

The way that I applied initialization is as follows:

    def xavier_init_model(model):
        for param in model.parameters():
            try:
                nn.init.xavier_uniform_(param)  # Also tried `xavier_normal_`
            except ValueError:
                pass
    
    model = Model()
    model.apply(xavier_init_model)

Hyperparameters and regularization were kept the same, so I'm wondering if initialized parameters require something different? I followed the learning rate schedule used in the original paper (a form of exponential decay with warmup) and also used a Dropout rate of 0.1.

If anyone knows any resources that might point to initialized models requiring different regularization or hyperparameter settings that I'd appreciate that too.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1785wwk/does_using_initialization_techniques_like_xavier/,0,3,1.0,[]
177p2xx,SaileshKrishnan,,2023-10-14 13:02:42+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/177p2xx/challenges_in_job_search_postgraduation_seeking/,Challenges in Job Search Post-Graduation - Seeking Guidance.,"I'm an international student in Ireland, and I completed my master's in artificial intelligence this August. I also hold a bachelor's degree in computer science and engineering. Currently, I'm on a stamp 1g graduate visa, which allows me to work full time in Ireland. I have some internship experience, and I've been actively applying for positions in AI/ML engineering, data science, data analysis, business analysis, and software engineering.

Despite applying to over 300 jobs, I've only received two interview opportunities, both of which resulted in rejections after the coding round, even though I passed the online coding test. The majority of my applications are being auto-rejected. Many of my friends in Ireland are facing similar challenges in their job searches.

I'm seeking guidance on how to approach my job search from this point forward and would appreciate any insights or suggestions regarding my CV and how to improve it.

Thank you.",learnmachinelearning,https://www.reddit.com/gallery/177p2xx,18,23,0.82,"[Comment(id='k4ucqxd'), Comment(id='k4vi5zm'), Comment(id='k4v7mzy'), Comment(id='k4wfhny'), Comment(id='k4yagxv'), Comment(id='k4xiopl'), Comment(id='k4xjim9'), Comment(id='k4ufy7g'), Comment(id='k4vjkfw'), Comment(id='k4xixr7'), Comment(id='k4vjj59'), Comment(id='k4uk7jq'), Comment(id='k513lyi'), Comment(id='k4vxow2'), Comment(id='k4um896'), Comment(id='k5b0wxi'), Comment(id='k4up5n9'), Comment(id='k4uqxqt')]"
177ypo8,YOitsibzi,,2023-10-14 20:48:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177ypo8/online_courses_or_exercises_for_esl/,Online Courses or Exercises for ESL," 

I'm doing ESL and I find the exercise problems too hard in it. I feel like I need to do a lot more problems before I can really grasp what is happening so I'm looking for more exercises/problems to do.

I primarily mean math/theory related problems, but if they're practical/coding stuff then that doesn't hurt either.

I'm assuming there are a lot of university courses which have ESL as their book (or have their syllabus similar to ESL) which have problem sets online. Those might be good practice, does anyone know of any such courses?

On a similar note, how do I search for them? I've tried a bunch of keywords and combinations but it either shows the book itself, the solution manual, or something of the sort. I've been able to find a couple (MIT/Stanford ones), but in the vast ocean filled with a plethora of species, two cods swimming near the surface isn't much. If someone with more advanced googling skills can bestow me with some of their wisdom, then I will be eternally grateful.

Thank you for your time and help!

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177ypo8/online_courses_or_exercises_for_esl/,1,3,1.0,[Comment(id='k4w6vlt')]
1780px4,SameItem,,2023-10-14 22:25:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1780px4/the_optimal_way_to_stratify_a_numerical_target/,The optimal way to stratify a numerical target variable into a categorical one for a machine learning algorithm,"  

I have tabular data, the predictive variables are numerical and categorical and the target variable is a numerical one. Using the proper techniques I can make predictive models with R\^2=0.95.

Now let's imagine I want to test similar techniques by considering the predictive variable a categorical one, that is, making the regression problem a classificational one.

The first thing I can do is for a number of labels, take the percentiles (For example if I want 4 different labels, I could take the quantiles)

The second thing is to study the distribution of the target variable, and, if let's say its a multinomial distrubution with 3 different modes where almost all data concentrates around those three ""peaks"" it's obvious that the most intelligent thing is to take three different labels centered in those modes (low, medium and high) .

But now let's set out the next problem rigorously. Let's imagine that the target variable is the price of something. Let's imagine I decide to divide the target variable in 5 categories (Very cheap, cheap, medium, expensive and very expensive) asigning for each category a numerical range (let's say that for very cheap is below 20.000$)

It's obvious that If I make two prediction models, one a regressional one with the numerical variable and the other a classificational one with the stratify target variable in 5 labels, and I take one observation of the test set (with all its respective values of the predictive variables), there is a higher chance of classification sucess if i use the first model and I predict the numerical value of the price and then assign it its respective label, that if I directly apply the classification model to the data

This is obviously because when you divide the numerical target into labels you are losing information (it's not the same saying that a number is 34000 that a number lies between the range of 20000 and 40000.

So my question is, how do I select the number of labels and what ranges in order minimize that information loss? Let's mind I have R\^2=0.95 so with the good choose of ranges, I must have a very high classification F1.

I think clusterization using the predictive variables can be very useful, but I don't know how to apply it well.

Sorry for the messy text, I think this could be redacted better but my English is limited. Any idea very appreciated. I think this kind of problems must have been considered before so if this issue have a name I can google I will thankful.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1780px4/the_optimal_way_to_stratify_a_numerical_target/,0,2,1.0,[]
177yogl,szneris,,2023-10-14 20:47:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177yogl/creating_varying_types_of_documents/,Creating varying types of documents,"I want to train a model on classifying two different categories of documents (A and B). Both of the types (A and B) contain varying formats/layouts, so I want to essentially generate varying formats/layouts of these documents with data specific to those categories. 

Current Process in Python:  
So my current process is getting the data, using jinja2, and putting them into a HTML template which would then be converted to PDF using pdfkit. 

This process is flawed in that if i want varying types of documents I would have to create a ton of HTML templates, so is there a better way of doing this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177yogl/creating_varying_types_of_documents/,2,2,1.0,"[Comment(id='k4xi624'), Comment(id='k4zi874')]"
177wg2s,boiofthahood,,2023-10-14 18:59:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177wg2s/need_help_finding_internship/,Need help finding internship.," I am a fourth-year Computer Science and Engineering student pursuing a B.Tech degree, with a budding interest in the realms of machine learning and deep learning. I've completed several projects, including stock price prediction and Twitter sentiment analysis, among others. I'm currently facing challenges in securing a remote paid internship. If you are seeking an intern, please feel free to send me a direct message on Reddit ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177wg2s/need_help_finding_internship/,2,0,0.5,"[Comment(id='k4vtj7e'), Comment(id='k4w385y')]"
177j4ul,Salty_Performance950,,2023-10-14 06:26:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177j4ul/best_resources_to_start_learning_machine_learning/,Best resources to start learning machine learning? What are the resources to start learning machine learning? And what should be my approach to the learning? Also how much time it can take to have intermediate skills on it?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177j4ul/best_resources_to_start_learning_machine_learning/,9,8,0.84,"[Comment(id='k4tx3bk'), Comment(id='k4u72il'), Comment(id='k4x27mf'), Comment(id='k4tauxg'), Comment(id='k4ufh27'), Comment(id='k4tjr2t'), Comment(id='k4uhum5'), Comment(id='k4vt8r9'), Comment(id='k4w930t')]"
177twq2,theDreamingStar,,2023-10-14 16:57:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177twq2/domain_specific_text_generation_using_bert_and_a/,Domain specific text generation using BERT (and a decoder??),"I've been tasked to create a ChatGPT like language model to answer questions in the legal domain. My professor has suggested using an available Bert model pretrained on legal data. 

I do not have a great theoretical understanding of NLP, just the basic ideas. But since BERT models only generate an encoding of the input text, how can I use it to generate an answer to a legal query. 

Should I use a decoder architecture like GPT to generate answers. If yes, then is it possible to combine BERT output to GPT and generate text? Any help would be necessary as I have hit a block and I don't have much time to figure everything on my own.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177twq2/domain_specific_text_generation_using_bert_and_a/,1,0,0.33,[Comment(id='k514ink')]
177twnu,theDreamingStar,,2023-10-14 16:57:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177twnu/domain_specific_text_generation_using_bert_and_a/,Domain specific text generation using BERT (and a decoder??),"I've been tasked to create a ChatGPT like language model to answer questions in the legal domain. My professor has suggested using an available Bert model pretrained on legal data. 

I do not have a great theoretical understanding of NLP, just the basic ideas. But since BERT models only generate an encoding of the input text, how can I use it to generate an answer to a legal query. 

Should I use a decoder architecture like GPT to generate answers. If yes, then is it possible to combine BERT output to GPT and generate text? Any help would be necessary as I have hit a block and I don't have much time to figure everything on my own.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177twnu/domain_specific_text_generation_using_bert_and_a/,1,0,0.33,[Comment(id='k4ysvid')]
177slcz,Longjumping_Ad_7053,,2023-10-14 15:54:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177slcz/callbacks_in_keras/,Callbacks in keras,How often to you actually build your own custom callbacks ?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177slcz/callbacks_in_keras/,1,1,1.0,[Comment(id='k4vmde9')]
177rdnr,Relevant-Ad9432,,2023-10-14 14:56:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177rdnr/what_to_do_after_learning_theoretical_machine/,what to do after learning theoretical machine learning," 

i have been doing some nptel courses on ML , they were 90% theory courses (they did show the codes for some stuff , but i felt it was not necssary for the course ). I do know that i should move towards implementation , but idk where to start .

Its not like i remember everything from the theory , but now i feel i should go towards Kaggle or something , is there any good course or book or anything for choosing what technique ,hyper-parameter tuning , CNN designing and such stuff

Also i am a bit confused by youtubers saying that kaggle is irrelevant in the real world.

Currently doing B tech Cse (cse engineering in India). 2nd year

courses -

[https://onlinecourses.nptel.ac.in/noc23\_cs97/preview](https://onlinecourses.nptel.ac.in/noc23_cs97/preview) (DS , ended last month)

[https://onlinecourses.nptel.ac.in/noc23\_cs98/preview](https://onlinecourses.nptel.ac.in/noc23_cs98/preview) (ML, will end this month)

[https://onlinecourses.nptel.ac.in/noc23\_cs110/preview](https://onlinecourses.nptel.ac.in/noc23_cs110/preview) (DL , will end this month)

i also did half a course on RL (i left it midway)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177rdnr/what_to_do_after_learning_theoretical_machine/,9,1,0.57,"[Comment(id='k4vadqa'), Comment(id='k4vc57v'), Comment(id='k4w3q2l'), Comment(id='k4x6mex'), Comment(id='k4xgzsa'), Comment(id='k4xunh4'), Comment(id='k4xu5kj'), Comment(id='k4xz29u'), Comment(id='k4yd6x8')]"
177rc0b,Relevant-Ad9432,,2023-10-14 14:53:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177rc0b/what_now_after_learning_theoretical_machine/,what now after learning theoretical machine learning," i have been doing some nptel courses on ML , they were 90% theory courses (they did show the codes for some stuff , but i felt it was not necssary for the course ). I do know that i should move towards implementation , but idk where to start .

Its not like i remember everything from the theory , but now i feel i should go towards Kaggle or something , is there any good course or book or anything for choosing what technique ,hyper-parameter tuning , CNN designing and such stuff

Also i am a bit confused by youtubers saying that kaggle is irrelevant in the real world.

Currently doing B tech Cse (cse engineering in India). 2nd year

courses -

[https://onlinecourses.nptel.ac.in/noc23\_cs97/preview](https://onlinecourses.nptel.ac.in/noc23_cs97/preview) (DS , ended last month)

[https://onlinecourses.nptel.ac.in/noc23\_cs98/preview](https://onlinecourses.nptel.ac.in/noc23_cs98/preview) (ML, will end this month)

[https://onlinecourses.nptel.ac.in/noc23\_cs110/preview](https://onlinecourses.nptel.ac.in/noc23_cs110/preview) (DL , will end this month)

i also did half a course on RL (i left it midway)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177rc0b/what_now_after_learning_theoretical_machine/,0,0,0.5,[]
177twoh,theDreamingStar,,2023-10-14 16:57:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177twoh/domain_specific_text_generation_using_bert_and_a/,Domain specific text generation using BERT (and a decoder??),"I've been tasked to create a ChatGPT like language model to answer questions in the legal domain. My professor has suggested using an available Bert model pretrained on legal data. 

I do not have a great theoretical understanding of NLP, just the basic ideas. But since BERT models only generate an encoding of the input text, how can I use it to generate an answer to a legal query. 

Should I use a decoder architecture like GPT to generate answers. If yes, then is it possible to combine BERT output to GPT and generate text? Any help would be necessary as I have hit a block and I don't have much time to figure everything on my own.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177twoh/domain_specific_text_generation_using_bert_and_a/,2,0,0.25,"[Comment(id='k4y6uo3'), Comment(id='k4x1vfx')]"
177p57y,FreeContribution704,,2023-10-14 13:05:53+00:00,False,,1697353041.0,False,True,False,/r/learnmachinelearning/comments/177p57y/pca_applied_in_questionnaires/,PCA applied in questionnaires,"Hello,
I am looking for some help in the following:

I have a dataset with questionnaires related to psychology mental health features, such as burnout, stress, depression. In those questionnaires, some of the questions are reversed. The questionnaires have a scale from 1-5 for example, and each has a numeric response. For example, in a questionnaire to assess if the person has burnout. The fact that some of the questions are reversed, means that when a participant replies 1 (strongly agree) in one question means “not having burnout), and replying 4 (strongly disagree) in another also means “not having burnout”. Thus, the scale does not have the same directional relationship.

I am thinking about applying PCA on those questions and extract one main component to have a score for each feature. For example, if burnout questionnaire has 16 questions, I will apply PCA and extract one main component (score) to explain burnout. 
Do I need to treat the reversed questions before PCA? 
Which standardization technique would be more suitable?
Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177p57y/pca_applied_in_questionnaires/,2,1,1.0,"[Comment(id='k4xxma3'), Comment(id='k4y5s9n')]"
177p0m6,fbeilstein,,2023-10-14 12:59:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177p0m6/introduction_to_machine_learning_l5_matplotlib/,"Introduction to Machine Learning (L5, MatPlotLib)","Hello everyone!

This year I'm trying to record my ""Introduction to ML"" course in English. Maybe, it will be of any use for anyone.

[Lecture 5, MatPlotLib](https://www.youtube.com/watch?v=LkY3qyhq6Q8)

Previous lectures: [Lecture 1, Introduction](https://www.youtube.com/watch?v=MxZULf38HRU), [Lecture 2, Python](https://www.youtube.com/watch?v=_IBdjLg-W6I), [Lecture 3, NumPy](https://www.youtube.com/watch?v=jJGiC_ccPg8), [Lecture 4, Pandas](https://www.youtube.com/watch?v=dKWPi5PfuEQ)

All course materials: [GitHub](https://github.com/fbeilstein/machine_learning)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177p0m6/introduction_to_machine_learning_l5_matplotlib/,0,0,0.5,[]
177owz1,tylersuard,,2023-10-14 12:54:08+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/177owz1/using_gpt4_as_the_brains_of_a_reinforcement/,Using GPT-4 as the “Brains” of a Reinforcement Learning Problem,,learnmachinelearning,https://medium.com/@ceo_44783/using-gpt-4-as-the-brains-of-a-reinforcement-learning-problem-516ff79aedb0,1,0,0.5,[Comment(id='k4uo30d')]
1774ndz,thismymind,,2023-10-13 17:59:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1774ndz/how_is_l1_regularization_able_to_drive_a/,How is L1 Regularization able to drive a coefficient to zero?,"

Hi all, 

I’m studying the concepts of machine learning. However, I am stuck because I still don’t see how introducing a penalty using lasso regression can drive some parameter coefficients to zero. When doing the calculations, I only get the final value (ordinary least squares + penalty)  and don’t directly see a coefficient value being reduced. 

I've looked at many materials and resources trying to explain this, but I still can't see how it's done. I think the important thing for me is seeing it going to zero or, at the very least, seeing it during calculation. Is there anyone that can help explain this better? Or, If you know of a formula that I can derive that, during the derivation process, shows a coefficient being reduced or set to zero, that would also help.

Also, any good resources on the topic would be appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1774ndz/how_is_l1_regularization_able_to_drive_a/,8,30,0.95,"[Comment(id='k4qr62x'), Comment(id='k4r9g5o'), Comment(id='k4rugxc'), Comment(id='k4qr4vf'), Comment(id='k4xo73u'), Comment(id='k4y2mug'), Comment(id='k4r47u6'), Comment(id='k4sx0xf')]"
177o8b2,shuvro_007,,2023-10-14 12:16:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177o8b2/learning_ml/,Learning ml,What things i should learn for any language to its ipa translation using ml,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177o8b2/learning_ml/,0,0,0.5,[]
177mov7,henkje112,,2023-10-14 10:41:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177mov7/simplify_your_tensorflow_model_creation_with/,Simplify Your TensorFlow Model Creation with VGSLify,"Hello r/learnmachinelearning! 🌟

Learning machine learning is an exciting journey, but sometimes, the intricacies of model definitions in TensorFlow can be a bit overwhelming, right? What if there was a way to simplify this process, making it more intuitive and accessible, especially for beginners?

Introducing **VGSLify**.

**Why VGSLify is a Game Changer for Learners:**

* **Simplicity at its Core**: With VGSLify, you can define intricate model architectures using a compact string format. Imagine defining a neural network without getting lost in lines of code!
* **Rapid Prototyping**: Experiment with different architectures swiftly. No need to modify layers of code; just tweak the VGSL spec string.
* **From TensorFlow to VGSL**: Have a TensorFlow model and curious about its VGSL representation? Convert it in a jiffy!
* **Future-Proof**: Although VGSLify currently aligns with TensorFlow, I have plans to extend it to PyTorch, broadening its horizons.

**A Quick Glimpse: VGSLify vs. TensorFlow Traditional Approach**

*With VGSLify*:

    from vgslify.tensorflow.generator import VGSLModelGenerator
    vgsl_spec = ""None,64,None,1 Cr3,3,32 Mp2,2,2,2 Cr3,3,64 Mp2,2,2,2 Lf128 O1s10""
    model = VGSLModelGenerator(vgsl_spec).build() 

*The Traditional TensorFlow Way*:

    model = tf.keras.Sequential([
         tf.keras.layers.Input(shape=(64, None, 1)),
         tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
         tf.keras.layers.MaxPooling2D((2,2)),
         tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
         tf.keras.layers.MaxPooling2D((2,2)),
         tf.keras.layers.LSTM(128),
         tf.keras.layers.Dense(10, activation='softmax')
    ]) 

See the difference? VGSLify aims to make your learning experience smoother, reducing the initial barriers and letting you focus on the fun parts of ML.

I'm proud to share VGSLify as my very first package, and I'm eager to hear feedback, suggestions, and potential collaborations!

Explore more on GitHub: [VGSLify Repo](https://github.com/TimKoornstra/VGSLify)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177mov7/simplify_your_tensorflow_model_creation_with/,0,1,0.66,[]
176zx1m,pmartra,,2023-10-13 14:23:10+00:00,False,,1697899187.0,False,True,False,/r/learnmachinelearning/comments/176zx1m/authoring_another_course_about_llms_learn_by/,Authoring another course about LLMs. Learn by Doing LLM Projects.,"Hi, I'm working on a course about LLMs on GitHub, it's totally free and under MIT license,  So there are no restrictions.

Here the link: [https://github.com/peremartra/Large-Language-Model-Notebooks-Course](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)

I'm still working on It, but now I'm feeling comfortable with the variety and quality of the content. By the moment is a small repository with just 80 Stars.

My intention is to make the course more accessible to a wider audience, and, if possible, encourage  reporting any issues  encounter or suggesting improvements through the 'Discussion' section.

I'm eager to receive feedback.

Now, I'll provide an overview of the currently available content, and then I'll share a couple of questions I have about how to proceed with the course.

[Large Language Models Course: Learn by Doing LLM Projects.](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)

* Introduction to LLM with OpenAI.
   * Create a first Chatbot using FPT 3.5.
   * Create a Natural Language to SQL Translator using OpenAI.
* Vector Databases with LLM.
   * Influencing Language Models with Information stored in ChromaDB.
* LangChain & LLM Apps.
   * RAG. Use the Data from Dataframes with LLMs.
   * Create a Moderation System using LangChain.
      * OpenAI.
      * GPT\_j.
      * LLama-2.
   * Create a Data Analyst Assistant using a LLM Agent.
* Evaluating LLMs
   * Evaluating Summarization with ROUGE.
* Fine-Tuning & Optimization.
   * Prompt-tuning using PEFT.
   * Fine-Tuning with LoRA.
   * Fine-Tuning a Large Model in a GPU using QLoRA. 

That's all for the moment, but I'm adding new content regularly. I'm working on it only in my spare time (mainly nights when the family goes to sleep).

\_\_\_

I have a doubt, I don't know if add some information about platforms like W&B or Cohere?  or maybe it is a better idea to stay with more Open-Source libraries?

On the other hand, my intention is to develop a couple of projects utilizing the techniques covered in the initial part of the course (which I am currently working on).

Some of these projects will be hosted in the cloud on major platforms such as Azure or GCP, or AWS. Any preference?

Furthermore, there is a plan to create a third section that explains how Large Language Models (LLMs) fit into large-scale enterprise solutions, defining architectures in which LLMs are used but are not the sole components of the project.

I don't intend to create a community outside of GitHub, but I would like the repository to have more activity and not be the one determining the course's direction.

Hope you like it, and lease, feel free to contribute.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176zx1m/authoring_another_course_about_llms_learn_by/,5,23,0.87,"[Comment(id='k4pvi4p'), Comment(id='k5u65ln'), Comment(id='k4px7jq'), Comment(id='k5za1g4'), Comment(id='k60ouwm')]"
177d212,FallMindless3563,,2023-10-14 00:29:17+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/177d212/how_stable_diffusion_works_arxiv_dives_w_oxenai/,How Stable Diffusion Works - Arxiv Dives w/ Oxen.ai 🐂 🌾,"Every Friday we host an open paper club called “Arxiv Dives” where we dive deep into a foundational research paper. We’re posting the recaps on YouTube if you can’t make it live. Anyone is welcome to join! It’s been fun going deep into these topics so far. 

https://lu.ma/oxenbookclub",learnmachinelearning,https://youtu.be/1Ipv0rsOMwg?si=UmpINOlbP_KKsvdS,0,2,0.67,[]
1770rrf,Iarethebestest,,2023-10-13 15:02:19+00:00,False,,1697214417.0,False,True,False,/r/learnmachinelearning/comments/1770rrf/how_do_i_land_an_mldata_job/,How do I land an ML/Data job,"Hi,

I have been applying continuously for the past 5 months at any Data Science/ML job I find on Linkedin, even Internships which often require 1-to 2 years of experience, I just can't land a job and most of the time the feedback (which often I get none)  I get is that I either lack experience or do not have production experience or Cloud experience. I have been getting certificates from [DeepLearning.AI](https://deeplearning.ai/) in various ML-related subjects. Currently, I'm finishing the MLOPS certificate and plan on getting the GCP certificate next

I have a BSc and an MSc in Electrical and Computer Engineering and a Data Science post-graduation. I have worked 1 year and 4 months as a researcher in AI and have papers published or submitted.

I just feel lost at this point, I have had 2 offers that were retracted, and often the interviewing process requires coding challenges that take at least 2 days, and I rarely get feedback from the interviewers.

Link to my CV: [https://docdro.id/6une4Da](https://docdro.id/6une4Da)

Any tips/feedback is helpful.

&#x200B;

Thanks in advance.

&#x200B;

EDIT: Removed linlks, photo, and personal data from CV",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1770rrf/how_do_i_land_an_mldata_job/,31,17,0.71,"[Comment(id='k4q2bij'), Comment(id='k4q6a6r'), Comment(id='k4q6ndf'), Comment(id='k4qjrhd'), Comment(id='k4t1mgl'), Comment(id='k4qp3bj'), Comment(id='k4psvz2'), Comment(id='k4xteat'), Comment(id='k4t2wae'), Comment(id='k4tsnyl'), Comment(id='k4q4epm'), Comment(id='k4qy75y'), Comment(id='k4suov1'), Comment(id='k4q7pkm'), Comment(id='k4rsjc9'), Comment(id='k506tpg'), Comment(id='k4rwp56'), Comment(id='k4rfiaz'), Comment(id='k4s8ne3'), Comment(id='k50746p'), Comment(id='k4rkehw'), Comment(id='k50906f'), Comment(id='k4qcj96'), Comment(id='k4tsf9y'), Comment(id='k4ttbsg'), Comment(id='k5178i4'), Comment(id='k508wnb'), Comment(id='k4rukky'), Comment(id='k4qxnv9'), Comment(id='k508cei'), Comment(id='k50idwa')]"
1778248,linamagr,,2023-10-13 20:35:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1778248/how_to_reduce_llm_cost_and_improve_performance/,How to Reduce LLM Cost And Improve Performance,"Different LLMs are available through APIs and have varying prices, with costs differing by up to two orders of magnitude. For example, the prompt cost for 10M tokens can range from $0.2 to $30 depending on the LLM provider.

Have anyone done any comparison or monitoring or solutions for this?

For instance, like the approach here:  [https://open.substack.com/pub/mlnotes/p/how-to-reduce-llm-cost-and-improve?r=164sm1&utm\_campaign=post&utm\_medium=web](https://open.substack.com/pub/mlnotes/p/how-to-reduce-llm-cost-and-improve?r=164sm1&utm_campaign=post&utm_medium=web)

&#x200B;

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1778248/how_to_reduce_llm_cost_and_improve_performance/,0,6,0.88,[]
177intp,Betelgeuse1517,,2023-10-14 05:54:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177intp/any_book_recommendations_or_other_resource_that/,Any book recommendations or other resource that explain complete guide for text classification.,"I already know the common flowchart. it starts with data collection, preprocessing, train the model, and evaluate the model. but yesterday I just saw unique flowchart that starts with data collection, preprocessing, distribution identification, model generation (using Linear model), train the model, and evaluate the model.

I am really new to the distribution identification, and some model generation part. so basically I asking Any  book recommendations or other resource that explain those 2 parts.  ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177intp/any_book_recommendations_or_other_resource_that/,0,1,1.0,[]
1771geg,MakeSense26,,2023-10-13 15:32:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1771geg/research_methodology_in_applied_machine_learning/,Research methodology in applied machine learning,"Hi all,

I am a PhD student working on the use of machine learning for an engineering application. More specifically, I am using existing deep learning methods, which I am adapting to my application. In other words, the novelty of my work comes from the application, not the deep learning algorithm itself.

In short, my methodology is as follows: I generate a training set for my engineering problem, I train deep learning models, and I measure the accuracy.

The reason why I am making this post is that I am struggling to determine what are the claims I can make from my results. Basically, if it works, my approach could be used in industry. However, at the same time, I generated a training set myself, and I am quite sure that, should anyone in industry want to use my work, they would have to do some work to adapt it to their particular case. Therefore, I can't simply take my results and claim something like ""ML has an accuracy of ... for this application"", since the results are only valid for the particular training set I generated. 

What kind of claims can I make with my results in your opinion?

I was looking for papers/books about research methods in applied ML, in the hope that I would find some frameworks, but I didn't find much except for this: [https://www.researchgate.net/publication/350495948\_Research\_Methods\_in\_Machine\_Learning\_A\_Content\_Analysis](https://www.researchgate.net/publication/350495948_Research_Methods_in_Machine_Learning_A_Content_Analysis)

Would you know of any such resource?

Many thanks for the help! ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1771geg/research_methodology_in_applied_machine_learning/,5,12,1.0,"[Comment(id='k4q093p'), Comment(id='k4q10li'), Comment(id='k4qpq32'), Comment(id='k4s2zg4'), Comment(id='k4scr56')]"
177g7ht,Aqsa81,,2023-10-14 03:19:08+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/177g7ht/90_completely_free_machine_learning_artificial/,90 Completely FREE Machine Learning & Artificial Intelligence Online Courses,,learnmachinelearning,https://www.mltut.com/best-free-online-courses-for-machine-learning-and-ai/,1,0,0.5,[Comment(id='k51gm4v')]
1770s0c,dmalyugina,,2023-10-13 15:02:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1770s0c/free_opensource_ml_observability_course/,Free Open-source ML observability course 🚀,"Hi everyone, I’m one of the people who work on [Evidently](https://github.com/evidentlyai/evidently), an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts on Oct 16. 

We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models. 

💻 Code examples and end-to-end deployment blueprints.    
✅ Open-source focused. You’ll work with tools like Evidently, MLflow, Airflow, and Grafana.   
❤️ Free and open to everyone.   
🗓 You can join the cohort that starts on October 16, 2023, or learn at your own pace. 

Course info and notes: [https://learn.evidentlyai.com/](https://learn.evidentlyai.com/) 

Hope you’ll find the course useful!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1770s0c/free_opensource_ml_observability_course/,0,7,0.82,[]
177dmag,jcrowe,,2023-10-14 00:58:47+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/177dmag/how_can_i_find_increased_sales_from_inventory/,How can I find increased sales from inventory files,,learnmachinelearning,/r/learnpython/comments/177dliy/how_can_i_find_increased_sales_from_inventory/,0,0,0.5,[]
176gs37,nxtboyIII,,2023-10-12 20:36:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/176gs37/chatgpt_vision_feature_is_really_useful_for/,ChatGPT vision feature is really useful for understanding research papers!,,learnmachinelearning,https://i.redd.it/xe94y8hf1utb1.png,42,181,0.86,"[Comment(id='k4mgje8'), Comment(id='k4mki0w'), Comment(id='k4nrcss'), Comment(id='k4npbi4'), Comment(id='k4nu7u6'), Comment(id='k4nv1fr'), Comment(id='k4qexst'), Comment(id='k4qh1tv'), Comment(id='k4pl26t'), Comment(id='k4poc7e'), Comment(id='k4m4u8p'), Comment(id='k4mfu9o'), Comment(id='k4nny4j'), Comment(id='k4op3ue'), Comment(id='k4phi8k'), Comment(id='k4ptrei'), Comment(id='k4puq8e'), Comment(id='k4o5bs3'), Comment(id='k4p5cfs'), Comment(id='k4mguv6'), Comment(id='k4p26gt'), Comment(id='k4oaosq'), Comment(id='k4p5hm7'), Comment(id='k4m5ata'), Comment(id='k4qun9g'), Comment(id='k4s3w4u'), Comment(id='k4r655x'), Comment(id='k4mko80'), Comment(id='k4nr94l'), Comment(id='k4nw8hk'), Comment(id='k4p902t'), Comment(id='k4m6szx'), Comment(id='k4nraki'), Comment(id='k4oaw12'), Comment(id='k4pxvd8'), Comment(id='k4ogtx2'), Comment(id='k4qq1ym'), Comment(id='k4rklks'), Comment(id='k4rr72y'), Comment(id='k4rti7q'), Comment(id='k4rycu3'), Comment(id='k4u422k'), <MoreComments count=0, children=[]>]"
1778n3l,Nice-Ad1199,,2023-10-13 21:02:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1778n3l/chatbase_backend_how_does_it_work/,ChatBase Backend: How Does it Work?,"Hey all,

I've been building my own ""personal assistant"" using the GPT API and Eleven Labs, and I am finally getting to the fine-tuning portion of everything. That being said, I have been primarily working with fine-tuning GPT directly through the OpenAI documentation, finding some success, but nothing too amazing quite yet.

&#x200B;

That being said, I was pointed to [ChatBase](https://www.chatbase.co/), a website that trains GPT on your data. I am assuming many of you have seen it, but the point is you can put documents, text, Q&A's, and web data which it will then train GPT on. The results are quite good with proper data, but it really doesn't require much to produce results.  


I imagine that they are using the same fine tuning techniques, but I question how they are able to produce such fantastic results with such little information. Perhaps there is something I am missing in the documentation? Does anybody know how one might be able to achieve similar results to a custom ChatBase model through their own GPT fine-tuning data set?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1778n3l/chatbase_backend_how_does_it_work/,10,2,1.0,"[Comment(id='k4remqq'), Comment(id='k4rfaxy'), Comment(id='k4v7son'), Comment(id='k53dp2f'), Comment(id='k55kacz'), Comment(id='k558lg1'), Comment(id='k53de1c'), Comment(id='k5582ko'), Comment(id='k58ansq'), Comment(id='k68j7yq')]"
1774xp4,AssignmentNo7294,,2023-10-13 18:12:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1774xp4/any_fast_light_weight_open_source_gpt_libraries/,"Any fast, light weight, open source gpt libraries for hobby projects?","Ill be using it mainly for the suggestions from text based input.
it should be fast as suggestions needs to be returned in the response.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1774xp4/any_fast_light_weight_open_source_gpt_libraries/,0,3,1.0,[]
1776sjl,dulldata,,2023-10-13 19:36:20+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1776sjl/auto_agents_powered_by_ai/,Auto Agents powered by AI,,learnmachinelearning,https://youtu.be/_Z-VW8I_Kwo,0,2,1.0,[]
176xm7g,jopoepl,,2023-10-13 12:29:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176xm7g/switching_to_an_ml_job_from_a_noncoding/,Switching to an ML job from a non-coding background? Pathway?,"Background: I have worked in the media industry for the past 10 years but have always been interested in the technical side of things. I don't have a background in CS so decided to finish a bootcamp in full (MERN) stack last year. Even without any coding background, finishing the bootcamp was pretty easy for me since coding felt very natural. 

Worked on a couple of projects as a freelancer in front end but didn't think front end was the way to go for me. But loved the fact that I could solve and automate a lot of things at my current workplace with code. 

I have been learning python (by making a few small projects, again which helps me in my work) and having been learning completing fastai lessons too. Also participating in kaggle projects (the open and ongoing ones) with a decent amount of success (thanks to tutorials and explainers on youtube).

I was always good at maths (however had very limited maths in my degree). I haven't touched maths until lately (to understand some data concepts for the kaggle competition). I think I still understand stats fairly well.

To sum up: 

I currently know how to code in JS, python (maybe like 25-30%) but since I entered coding via bootcamp, my DS knowledge is next to nil right now. 

I have completed a few lessons of fastai and have submitted a few predictions on kaggle too (so have a very basic understanding of how to get results). 

&#x200B;

My Question: 

Realistically how do I go from here, to landing a job as a ML Engineer? I know its going to be a long process, but what could speed / aid in the process? 

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176xm7g/switching_to_an_ml_job_from_a_noncoding/,12,5,0.61,"[Comment(id='k4pe9pr'), Comment(id='k4qqytz'), Comment(id='k4q9krj'), Comment(id='k4q4r7m'), Comment(id='k4rrj7j'), Comment(id='k4t3uby'), Comment(id='k4t55o1'), Comment(id='k4q7urw'), Comment(id='k4t68bz'), Comment(id='k4q8smg'), Comment(id='k4t8fr8')]"
1770624,Count_Ak,,2023-10-13 14:34:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1770624/ml/,Ml,"Hello everyone, this is right platform to post this. Please give genuine advice/suggestions. I'm 23 years old from India
I completed my graduation in 2020 but I had backlogs so college didnt allowed for technical placement drives, hence i joined Amazon as chat support and worked there for 1.5 year.
 later I did a course in data analytics in 2022 and aquired skills on intermediate level(Ml, PowerBi, python, sql, pandas, numpy) and parellely I completed my masters in Aug 2023 from a normal college. 
Started applying in August for data analytics or powerBi. Till date applied for 100 companies but didn't get any call or response. Getting frustrated just upgrading skills everyday and applying, getting mad.I'm living with my parents so i have food shelter but cant rely on them for my expense any longer. So I'm getting a offer in big organisation as chat support or voice process. 
Shall I join there nd then keep applying? Or what is the best I can do?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1770624/ml/,4,3,1.0,"[Comment(id='k4puquo'), Comment(id='k4r0wc2'), Comment(id='k4siovf'), Comment(id='k4sv6wc')]"
1771saq,mimol,,2023-10-13 15:47:45+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1771saq/best_cv_book_focused_on_videos_tracking/,"Best CV book focused on videos (tracking, de-blurring, registration...)",,learnmachinelearning,/r/computervision/comments/1771pk8/best_cv_book_focused_on_videos_tracking/,0,2,1.0,[]
1776ioj,bracaco,,2023-10-13 19:23:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1776ioj/product_background_generator/,Product background generator,"Hi, I am trying to figure out how a product like [https://www.kittl.com/tools/background-generator](https://www.kittl.com/tools/background-generator), especially the way it creates realistic shadows. I was unable to find any worthy resources about how this can be achieved. I want to learn more, if somebody knows any resources, I would appreciate it.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1776ioj/product_background_generator/,0,1,1.0,[]
177092p,beastengr93,,2023-10-13 14:38:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/177092p/serverlessinference_with_onnx_model_on_sagemaker/,ServerlessInference with ONNX model on Sagemaker supported?,"Hi,

My current setup is an AWS LAMBDA which runs my image segmentation processing using an \`onnx model. It started being ok, but I have realized its too slow and limiting to really be usable.   


For experimentation, I started with real-time-inference endpoint on sagemaker using their \`Triton Image\`, and saw much much faster processing of course. From around 14s to do segmentation, to 3-4s (just some initial vague testing), but I couldnt go on experimenting since costs look really high, but looked very promising, as I could maybe tie with my current AWS LAMBDA and then invoke the endpoint.  


My next step was to try the ServerlessInference on sagemaker and see how it would behave, but I didnt manage to deploy the endpoint, as I got a \`status: failed\`, with \`Received server error (0) from model with message ""An error occurred while handling request as the model process exited.""\`. And I cant look at the logs since it doesnt create them, but with \`real-time-inference\` was fine.  It looks  to me it isnt supported since most of the AWS blogs/tutorials mention serverless-inference with PyTorch, TensorFlow, etc backends.  For this, I compressed my \`onnx model\` along with \`inference.py\` on a \`model.tar.gz\` .  


Have any of you have experience using \`onnx\` model with sagemaker ServerlessInference? The traffic I currently get is not enough to use the real-time-inference, and the requests come very sporadically. Say 0 in 3 days, but then 2 in one day, 3 next, 15 next, 0 for the next 2 days and so on. Or perhaps something that is not sagemaker, or some other service within AWS preferably.  


THX",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/177092p/serverlessinference_with_onnx_model_on_sagemaker/,0,2,1.0,[]
1774oir,_negativeonetwelfth,,2023-10-13 18:00:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1774oir/in_multiclass_keypoint_estimation_models_does/,"In multi-class keypoint estimation models, does adding more classes with keypoints warrant training for more epochs/steps?","I'm using TensorFlow's Object Detection API, which allows training custom models with pretty much any number of classes with or without keypoints, by just adding another keypoint\_estimation\_task in the config file. Since each keypoint estimation task has its own ""loss\_weight"" value, it got me thinking about the fact that the model will need to ""split"" its attention between different estimation tasks during training. Does this mean that it would take more epochs for the model to be correctly ""fit"" to the same dataset, or would that just lead to overfitting?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1774oir/in_multiclass_keypoint_estimation_models_does/,0,1,1.0,[]
1774fu3,ElectricalDimension,,2023-10-13 17:49:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1774fu3/pytorch_and_tensoeflow_gpu/,Pytorch and Tensoeflow GPU,Hi I'm a begin to learn machine learning for about 3 months. Is it possible to install pytorch GPU and Tensorflow GPU in the same virtual environment (i.e. anaconda). Thank you in advance.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1774fu3/pytorch_and_tensoeflow_gpu/,2,0,0.5,"[Comment(id='k4vmve9'), Comment(id='k4xzypa')]"
1772xok,Sith_vader3,,2023-10-13 16:39:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1772xok/a_question/,A question,"What are the ways to create plasticity in neural network? Without using weights,bias and activation function.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1772xok/a_question/,10,1,0.67,"[Comment(id='k4qaixr'), Comment(id='k4swu8o'), Comment(id='k4ts224'), Comment(id='k4s8nwx'), Comment(id='k4twmdm'), Comment(id='k4twpsh'), Comment(id='k4vh511'), Comment(id='k4txqpe'), Comment(id='k4xfjww'), Comment(id='k4u3g75')]"
176xbil,Fit_Market_3607,,2023-10-13 12:13:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176xbil/factor_influencing_adoption_intention_of_chatgpt/,Factor Influencing Adoption Intention of ChatGPT,"Hello,

&#x200B;

I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.

&#x200B;

Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.

&#x200B;

If you are interested in learning more about the study, please follow the link below. 

&#x200B;

[https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link)

&#x200B;

Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176xbil/factor_influencing_adoption_intention_of_chatgpt/,0,2,1.0,[]
176unma,Proper-Second6847,,2023-10-13 09:20:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176unma/which_offers_better_opportunities_for_freshers_in/,Which offers better opportunities for freshers in job market among Data Analyst and Web Development??,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176unma/which_offers_better_opportunities_for_freshers_in/,3,3,0.67,"[Comment(id='k4papsg'), Comment(id='k4sx8xi'), Comment(id='k4umkso')]"
176wjg5,ThunderCatnip,,2023-10-13 11:27:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176wjg5/should_i_have_features_of_different_types_that/,Should i have features of different types that convey the same information?,"I was looking through the notebooks on kaggle space titanic. 

And creator of one notebook (https://www.kaggle.com/code/kdsharma/spaceship-titanic-competition-end-to-end-project?scriptVersionId=119775965) created feature “group size”(number of people -1, person is travelling with) and feature “travelling solo” (which indicates if person is travelling alone) 

As i understand information stored in “travelling solo” can be derived from “group size”. Is creating new feature that stores the same information but differently (categorical instead of numeric) beneficial to learning?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176wjg5/should_i_have_features_of_different_types_that/,6,2,1.0,"[Comment(id='k4pd9ot'), Comment(id='k4r0ofj'), Comment(id='k4pk9iy'), Comment(id='k4pv202'), Comment(id='k4pv7pk')]"
176ldr3,scarysticks0w,,2023-10-12 23:59:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176ldr3/statistics_for_ml/,Statistics for ML,"Is there a good resources about stats and prob focused in machine learning and deep learning. but something structures like a good playlist.

I got a good level in calc and linear algebra but have pretty bad level in stats.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176ldr3/statistics_for_ml/,4,11,1.0,"[Comment(id='k4n9fxi'), Comment(id='k4qx8k1'), Comment(id='k4r17wt')]"
176osrw,aaronkelton,,2023-10-13 02:56:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176osrw/is_ml_necessary_to_solve_fixed_data_matching_over/,Is ML necessary to solve fixed data matching over small subset?,"I’m working with explicit data (user questionnaire of preferences) and very confused about which approach is best to match “compatible” users.

Ace likes red apples. Bob likes green apples. Cal likes red apples. Is there some algorithm that would spit out “Ace and Cal are 100% compatible” and “Ace and Bob are 50% compatible (both like apples, just diff types)”?

If we ask users more questions, it gets more complex. E.g. Ace strongly prefers red apples, whereas Cal is open to green apples. Would ML be useful in this “compatibility” application, or does it belong to some other domain?

I think I need to somehow assign weights to which questions I believe should influence “compatibility”, and then somehow balance preference orientation and preference intensity for each item. Overall I could have tens of thousands of users, but only compare 1 to a subset of maybe 100.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176osrw/is_ml_necessary_to_solve_fixed_data_matching_over/,6,5,0.86,"[Comment(id='k4nozws'), Comment(id='k4np00t'), Comment(id='k4o96r1'), Comment(id='k4o3ft4'), Comment(id='k4npwkd'), Comment(id='k4orh7w')]"
176xt9h,Ruler99,,2023-10-13 12:39:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176xt9h/d_knowledge_graph/,[D] knowledge graph,"Hello, everyone! I'm a beginner in the field of AI. Can you help me find some resources to develop a knowledge graph using PMBOK? I appreciate your assistance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176xt9h/d_knowledge_graph/,0,1,1.0,[]
176t8zk,The_Catlike_Odin,,2023-10-13 07:37:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176t8zk/dont_know_where_to_ask_i_am_doing_a_curve_fit/,"Don't know where to ask, I am doing a curve fit with scipy and it's giving a different result than in the Julia programming language.","I've been stuck on this bug for days only recently figuring out that the curve fit is different. I hardcoded some values to feed into the curve fit and both languages give different results. The curves themselves both fit nicely but the function is totally different:  

https://imgur.com/a/6p8tyki  

you can see in the second pic and first pic, the values inputted are the same. But parameters D,C, gamma are totally different. Anyone know how to fix or why this happens? The curve fit code looks like this:  

https://imgur.com/a/12g94UN  

it's like literally identical.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176t8zk/dont_know_where_to_ask_i_am_doing_a_curve_fit/,4,2,1.0,"[Comment(id='k4onafc'), Comment(id='k4ooju8'), Comment(id='k4opaxt'), Comment(id='k4pls6a')]"
176v6mg,100GB-CSV,,2023-10-13 09:58:38+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/176v6mg/run_go_dataframe_from_1million_rows_to_10_billion/,Run Go Dataframe from 1Million Rows to 10 Billion Rows,,learnmachinelearning,https://youtu.be/un8Y7Y0Cd9Q,1,0,0.33,[Comment(id='k4os2bz')]
176o9o5,5starkarma,,2023-10-13 02:27:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176o9o5/multimodal_llms_for_image_captioning/,Multimodal LLMs for image captioning,"I am looking for an open-source model that can be fine-tuned which can be very descriptive about what is in the image. e.g. what people are doing, what they are wearing, their race, etc. 

Does anyone have any suggestions for good places to start looking for this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176o9o5/multimodal_llms_for_image_captioning/,4,3,1.0,"[Comment(id='k4p8up4'), Comment(id='k4r4666'), Comment(id='k4ptgon'), Comment(id='k4r4pjo')]"
176sq2u,guettli,,2023-10-13 07:01:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176sq2u/how_to_detect_unusual_log_lines/,How to detect unusual log lines?,"# Intro

We have a long running e2e test which creates a lot of log files.

If the test fails, it is hard to find the lines which are the root-cause.

The e2e test is about creating a Kubernetes cluster with cluster-api. Some error messages are totally fine.

# Failed test

Here is an example:

[Github Workflow, Test Hcloud Basic failed](https://github.com/syself/cluster-api-provider-hetzner/actions/runs/6473540419)

[Zip file](https://github.com/syself/cluster-api-provider-hetzner/suites/17084950107/artifacts/975977570)

Logfiles:
```
❯ find -name '*.log'
./clusters/caph-j0yfkd/machines/caph-j0yfkd-md-0-xhpxb-nrrsb/containerd.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-md-0-xhpxb-nrrsb/cloud-init.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-md-0-xhpxb-nrrsb/kern.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-md-0-xhpxb-nrrsb/kubelet.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-md-0-xhpxb-nrrsb/cloud-init-output.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-9c77g/containerd.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-9c77g/cloud-init.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-9c77g/kern.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-9c77g/kubelet.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-9c77g/cloud-init-output.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-vqgnp/containerd.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-vqgnp/cloud-init.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-vqgnp/kern.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-vqgnp/kubelet.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-vqgnp/cloud-init-output.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-hkr52/containerd.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-hkr52/cloud-init.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-hkr52/kern.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-hkr52/kubelet.log
./clusters/caph-j0yfkd/machines/caph-j0yfkd-control-plane-hkr52/cloud-init-output.log
./clusters/bootstrap/resources/caph-a51itw/events.log
./clusters/bootstrap/resources/caph-nlv8uj/events.log
./clusters/bootstrap/clusterctl-init.log
./clusters/bootstrap/logs/caph-system/caph-controller-manager/caph-controller-manager-6df7cbf456-xbj2w/manager.log
./clusters/bootstrap/logs/capi-kubeadm-bootstrap-system/capi-kubeadm-bootstrap-controller-manager/capi-kubeadm-bootstrap-controller-manager-565c858799-tjrjc/manager.log
./clusters/bootstrap/logs/capi-system/capi-controller-manager/capi-controller-manager-dc9fd6584-t9kz5/manager.log
./clusters/bootstrap/logs/capi-kubeadm-control-plane-system/capi-kubeadm-control-plane-controller-manager/capi-kubeadm-control-plane-controller-manager-bd4b8b957-bkkx9/manager.log
./clusters/caph-5ecftc/machines/caph-5ecftc-md-0-9nzgt-jzbbn/containerd.log
./clusters/caph-5ecftc/machines/caph-5ecftc-md-0-9nzgt-jzbbn/cloud-init.log
./clusters/caph-5ecftc/machines/caph-5ecftc-md-0-9nzgt-jzbbn/kern.log
./clusters/caph-5ecftc/machines/caph-5ecftc-md-0-9nzgt-jzbbn/kubelet.log
./clusters/caph-5ecftc/machines/caph-5ecftc-md-0-9nzgt-jzbbn/cloud-init-output.log
./clusters/caph-5ecftc/machines/caph-5ecftc-control-plane-8jt2k/containerd.log
./clusters/caph-5ecftc/machines/caph-5ecftc-control-plane-8jt2k/cloud-init.log
./clusters/caph-5ecftc/machines/caph-5ecftc-control-plane-8jt2k/kern.log
./clusters/caph-5ecftc/machines/caph-5ecftc-control-plane-8jt2k/kubelet.log
./clusters/caph-5ecftc/machines/caph-5ecftc-control-plane-8jt2k/cloud-init-output.log
```

I above case the error is 

> executable file `/bin/hcloud-cloud-controller-manager` not found in $PATH: No such file or directory

in the file clusters/caph-5ecftc/machines/caph-5ecftc-control-plane-8jt2k/kubelet.log

# Passed test

Here is test which is fine:

[Github Workflow, Test Hcloud Basic passed](https://github.com/syself/cluster-api-provider-hetzner/actions/runs/6496547896)

[Zip file](https://github.com/syself/cluster-api-provider-hetzner/suites/17160122066/artifacts/980521005)

# Question

> How to detect special lines in all these log files?


I have experience with Python, Go and SQL. 

But here, I think some kind of machine learning algorithm would be better.

Feel free to find above error. The project and the data are open source and available in above links.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176sq2u/how_to_detect_unusual_log_lines/,0,1,1.0,[]
17611b4,relentless_endurance,,2023-10-12 07:23:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17611b4/honestly_is_being_a_ml_engineer_possible_for/,"Honestly, is being a ML engineer possible for someone who is just okay at math?","Since I was a kid I have always been exactly average at math. I got evaluated for adhd which included an IQ test which gives you different IQ levels for different subjects. Again math was very average at 101. It was my lowest score and overall my IQ is 120. So I'm kinda smart but least of all in math.

Started my CS degree and did math again for the first time in 10 years. Really struggled with college algebra and got a C. I found Discrete Mathematics a lot easier and that went just okay, got out with a B. Pre-calculus is going just okay as well, probably gonna end up with a B. 

I'm just asking, do any ML specialists / Data scientists out there have a similar history with math to me? Are every one of you a real ""math person"" or did many of you get into this with no prior affinity for it? I don't want to get in over my head and waste my time.

I also want to say I know the answer is just to keep learning about ML and see for myself if I can do it. I think really I'm just looking for motivation. thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17611b4/honestly_is_being_a_ml_engineer_possible_for/,41,68,0.85,"[Comment(id='k4jjx6u'), Comment(id='k4ja0qe'), Comment(id='k4jtibn'), Comment(id='k4jup0a'), Comment(id='k4jeqcx'), Comment(id='k4l9mwg'), Comment(id='k4ljj1v'), Comment(id='k4jxipl'), Comment(id='k4o8oqk'), Comment(id='k4k3rbt'), Comment(id='k4k3vag'), Comment(id='k4l01j0'), Comment(id='k4lp15a'), Comment(id='k4lukwa'), Comment(id='k4mhizm'), Comment(id='k4ndupv'), Comment(id='k4sgp35'), Comment(id='k4svyer'), Comment(id='k4lufwy'), Comment(id='k4jdbp8'), Comment(id='k4lpfmn'), Comment(id='k4k0k08'), Comment(id='k4kn6dc'), Comment(id='k4lfoi8'), Comment(id='k4k6nof'), Comment(id='k4lp3av'), Comment(id='k4odje5'), Comment(id='k4skra9'), Comment(id='k4p5u63'), Comment(id='k4phnb0'), Comment(id='k4pwqr7'), Comment(id='k4pvnik'), Comment(id='k4pw280'), Comment(id='k4pw8ci'), Comment(id='k4u15v7'), Comment(id='k4u0non'), Comment(id='k4tyst0'), Comment(id='k4tzhnd'), Comment(id='k4unjoc'), Comment(id='k4ys61y')]"
176oxov,kolopoi0,,2023-10-13 03:03:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176oxov/one_fit_all_binary_supervised_classification/,One Fit all Binary Supervised Classification,"Hey guys,

I have been a long time lurker and a lot of times for classification problems I read the following: ¨Oh, the techniques you have to explore are specific to your problem¨. Nevertheless, this seems to generic for me.

I mean, wouldn´t it be possible to ¨Solve¨ binary supervised classification problems? It seems like there is just a lot different techniques you have to explore. For example:

Why not create one algorithm that eventually does all of this one at the time:

1) Use a Standard Scaling, Robust Scaling, and Normalizes your data for numerical variables.

2) Does One hot encoding/target encoding/label encoding for categorical and ordinal variables.

3) Uses Sequential Feature Selector to pick up the best variables with multiple score metrics for each loop with different estimators (Tries the most popular 15 ML methods). Some other stuff such as PCA could also be incorporated.

4) Does a hyper-parameter tuning with a gridsearch for a wide range of values (Tries the most popular 15 ML methods).

5) Returns F1 score, Accuracy, Precision, Recall, and AUC-PR/AUC-ROC.

So basically every possible combination of what I just mentioned. Obviously computing time is a constraint but in this era, unless you have a lot of rows and columns it should be doable, right? What am I missing? Why something like this has not been done already?

Thanks so much!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176oxov/one_fit_all_binary_supervised_classification/,0,1,1.0,[]
176j5dd,keymaker89,,2023-10-12 22:14:10+00:00,False,,1697158948.0,False,True,False,/r/learnmachinelearning/comments/176j5dd/confused_about_how_much_overfitting_matters_which/,Confused about how much overfitting matters. Which of these models should I use?,"So I've been working on a complex binary classification problem and initially I started with an XGBoost model where I was able to get the training and validation metrics within 2% of eachother, which I understand means it's generalizing to new data. The validation metrics were around 62-63% which is a pretty good score for this type of problem. 

I recently learned about Autogluon and gave it a try, I was able to bump up the validation scores to around 65-67% but it's badly overfitting (like 95+% on the test metrics). If I modify the configs to add more bag folds, stacks etc I can close the gap at the expense of validation scores (but I haven't spent too much time on this).

If my validation scores on the Autogluon model are doing this well on unseen data, then does it matter if it's overfitting this much? I'm just wondering if I should focus on fixing the overfitting problem, or just focus on trying to improve validation scores without really looking at test scores. Or if I should go back to the original XGBoot model which wasn't overfitting much.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176j5dd/confused_about_how_much_overfitting_matters_which/,1,2,1.0,[Comment(id='k4q5t26')]
176mx8r,ohai777,,2023-10-13 01:17:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176mx8r/beginner_question_on_why_my_probability_is_so_low/,Beginner Question on why my probability is so low with a dog breed classifier?,"I have been working through the first lesson of the fast.ai course and worked through this bird/forest classifier (https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data).

For the next lesson I created my own dog breed classifier using the same code as the bird/forest classifier but instead used images of different dog breeds. I also adjusted the code to pull down 100 images for each search term:

searches = ['Siberian Husky', 'Bulldog',
            'Golden Retriever', 'German Shepherd',
            'Dachsund', 'Beagle']

I trained with the vision learner until the train_loss was approximately the same as the valid_loss, with an error rate of 0.04. Doesn't this mean that it is classifying correctly about 90% of the time with the data I have?



epoch| train_loss | valid_loss | error_rate | time
---|---|----|----|----
0 | 0.467590 | 0.195490|0.070588|00:02
1 | 0.370130 | 0.136341|0.041176|00:03
2 | 0.284544 |0.121983|0.064706|00:02
3 | 0.213896 |0.113154|0.035294|00:02
4 | 0.162474 | 0.104271|0.029412|00:02
5 | 0.124373| 0.095844|0.029412|00:02
6 | 0.099959| 0.101642|0.041176|00:03

However, when I call learn.predict on a picture of a bulldog the classifier correctly guesses a bulldog, but it's confidence probability is  0.00000002% confident. For the sample bird/forest classifier, it was classifying with a 99% confidence? Am I doing something obviously wrong? I've spent hours trying different fine_tunings and different images but I've never gotten the probability anywhere near the birds. 

Any quick thoughts would be appreciated, thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176mx8r/beginner_question_on_why_my_probability_is_so_low/,2,0,0.5,"[Comment(id='k4ocerv'), Comment(id='k4r3e68')]"
176mbfc,waterstrider123,,2023-10-13 00:46:15+00:00,False,,1697158417.0,False,True,False,/r/learnmachinelearning/comments/176mbfc/segmentation_of_splines_in_images/,Segmentation of splines in images,"I have images that contains layers in rock formations. I have annotations of the boundaries between each layer marked with splines. These splines do not form a closed contour either, they are just lines that are delineating the boundary of each layer from left to right.

I am wondering how to approach this problem. Should I dilate the splines and then train a segmentation model on that? Or does it make more sense to train the segmentation model to segment out the regions between the splines? Or is there a way to just segment out lines of pixels?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176mbfc/segmentation_of_splines_in_images/,3,1,1.0,"[Comment(id='k4odp9v'), Comment(id='k4p1ywd'), Comment(id='k4q0ej0')]"
176m5nw,sovit-123,,2023-10-13 00:38:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176m5nw/hyperparameter_tuning_with_pytorch_and_ray_tune/,Hyperparameter Tuning with PyTorch and Ray Tune,"Hyperparameter Tuning with PyTorch and Ray Tune

[https://debuggercafe.com/hyperparameter-tuning-with-pytorch-and-ray-tune/](https://debuggercafe.com/hyperparameter-tuning-with-pytorch-and-ray-tune/)

&#x200B;

https://preview.redd.it/5wozjcdk8vtb1.png?width=1000&format=png&auto=webp&s=61f4bb6442a271bdd5850cecd9769cf2d0078920",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176m5nw/hyperparameter_tuning_with_pytorch_and_ray_tune/,0,0,0.5,[]
176elzg,LyannaEugen,,2023-10-12 19:00:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176elzg/semantic_dissimilarity_detection_between/,Semantic dissimilarity detection between lexically similar sentences,"Example :

Question : What is the capital of the USA?

Expected Answer : ""Washington D.C. is the capital of the USA""

Actual Answer : ""The USA is the capital of Washington D.C.""

While grading a question, the model tends to find these 2 sentences similar (lexically similar), while the actual answer is incorrect (semantic dissimilar). How to work on this? I read few articles on doc2Vec however the examples provided were not similar to my doubt hence I'm still confused. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176elzg/semantic_dissimilarity_detection_between/,0,1,1.0,[]
17603c6,Street-Regular-9924,,2023-10-12 06:21:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17603c6/should_i_begin/,Should I begin?,"Hi everyone 
As a beginner, I need your sincere advice.
I am in my early thirties, and I am not happy with my career. Through my interests and abilities in programming at the university level, I have decided to develop a programming career. I have been studying Python crash courses and now I want to learn ML with Python.
First of all, do you think it’s generally a good idea? 
How is the market, job availability, and opportunities?
How many years should I expect to earn sufficiently?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17603c6/should_i_begin/,17,8,0.9,"[Comment(id='k4nomo6'), Comment(id='k4k1rat'), Comment(id='k4jwylu'), Comment(id='k4kfjl1'), Comment(id='k4r6xd3'), Comment(id='k4td6bw'), Comment(id='k4mj9v6'), Comment(id='k4k94k1'), Comment(id='k4k8q07'), Comment(id='k4tl2hc'), Comment(id='k4tkqfg'), Comment(id='k4ugn86'), Comment(id='k4lpx1e'), Comment(id='k4kb1zi'), Comment(id='k4tljcv')]"
176bwhy,ProfessionalNovel984,,2023-10-12 17:04:14+00:00,False,,1697130486.0,False,True,False,/r/learnmachinelearning/comments/176bwhy/handling_rtsp_stream_latency_when_analyzing_video/,Handling RTSP Stream Latency when Analyzing Video Frames with a Machine Learning Model,"Hi! I am trying to view a RTSP stream from a cctv camera using opencv and then I am trying to feed each of it's frame to a ML model to analyze the video. The problem is either the stream lags (becomes 20-40secs slower than the realtime video), or the script just crashes due to receiving empty frames. I have tried multithreading, ffmpeg but none of it's working.  I am using a laptop with ryzen 7 5800H, 3050ti, 32GB ram. When I open the rtsp stream with VLC player it never crashes or skips a frame, but when I do it using my python script either there is frame lag, jitter, slow downs or complete crash due to tcp ack packets not being sent.

How can I display the rtsp streams real time while applying my ml model to analyze each of the frames and draw on it ?

Below is the gist of my code.

&#x200B;

`while True:`

`ret, frame =` [`cap.read`](https://cap.read)`()`

`if not ret:`

`break`

&#x200B;

`# Doing image processing here e.g.`

`processed_frame = some_processing_function(frame)`

&#x200B;

`# Display the frame`

`cv2.putText(processed_frame, text_gen, (x1, y1-10), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)`

`cv2.imshow('Processed Stream', processed_frame)`

`if cv2.waitKey(1) & 0xFF == ord('q'):`

`break`

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176bwhy/handling_rtsp_stream_latency_when_analyzing_video/,0,1,1.0,[]
176bwhu,ProfessionalNovel984,,2023-10-12 17:04:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/176bwhu/handling_rtsp_stream_latency_when_analyzing_video/,Handling RTSP Stream Latency when Analyzing Video Frames with a Machine Learning Model,"Hi! I am trying to view a RTSP stream from a cctv camera using opencv and then I am trying to feed each of it's frame to a ML model to analyze the video. The problem is either the stream lags (becomes 20-40secs slower than the realtime video), or the script just crashes due to receiving empty frames. I have tried multithreading, ffmpeg but none of it's working.  I am using a laptop with ryzen 7 5800H, 3050ti, 32GB ram. When I open the rtsp stream with VLC player it never crashes or skips a frame, but when I do it using my python script either there is frame lag, jitter, slow downs or complete crash due to tcp ack packets not being sent.    


How can I display the rtsp streams real time while applying my ml model to analyze each of the frames and draw on it ?  


  
Below is the gist of my code.  


\`\`\`

while True:

ret, frame = [cap.read](https://cap.read)()

if not ret:

break

&#x200B;

\# Doing image processing here e.g.

processed\_frame = some\_processing\_function(frame)

&#x200B;

\# Display the frame   
 

cv2.putText(processed\_frame, text\_gen, (x1, y1-10), cv2.FONT\_HERSHEY\_DUPLEX, 0.5, color, 1)

cv2.imshow('Processed Stream', processed\_frame)

if cv2.waitKey(1) & 0xFF == ord('q'):

break

\`\`\`

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/176bwhu/handling_rtsp_stream_latency_when_analyzing_video/,0,1,1.0,[]
176a8a9,Lakshmireddys,,2023-10-12 15:52:44+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/176a8a9/best_machine_learning_courses_on_udemy_beginners/,"Best Machine Learning Courses on Udemy beginners, advanced -",,learnmachinelearning,https://codingvidya.com/best-machine-learning-courses-on-udemy/,0,0,0.33,[]
17653lp,olegranmo,,2023-10-12 11:51:12+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/17653lp/p_learn_how_to_make_trustworthy_and_transparent/,"[P] Learn how to make trustworthy and transparent machine learning models in Tsetlin Machine Book Chapter 7: Confidence, Trustworthiness, and Composites.",,learnmachinelearning,/r/MachineLearning/comments/17652mm/p_learn_how_to_make_trustworthy_and_transparent/,0,2,1.0,[]
1769m91,defaultUserTM,,2023-10-12 15:26:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1769m91/looking_for_student_path_advice/,Looking for student path advice,"Hello fellow [r/LearnMachineLearning](https://www.reddit.com/r/MachineLearning/) community :

I'm an 18 years old student from France (Alpes-Maritimes) and in last high school year before graduation with specialization in Computer Science and Mathematics. I'm turning toward this community of experienced machine learning engineers looking for advice concerning my future studies, as I'm a bit lost. I would like to become a Machine Learning Engineer, more specifically in Deep Learning and I don't know which path should I opt for- I'm in this situation, I've discovered and been admitted to this private school called Epitech (formerly *European Institute of Technology*) with a 5 years cursus in software engineering (with development of AI and related if chosen), delivering a diploma in *software engineering expertise*, they provide a *practical* pedagogical methods and do a lot of work in companies and around the world. But here's the problem, this school is delivering what I told, but nothing else, no Engineer diploma (as they aren't a ""normal engineering"" school delivering Engineer degrees) ; that being said, I don't know if it will be enough to achieve my previously mentioned goal, although I know that most of the work is being done on my side of course ... Should I rather look for a more *classical* engineering school, like polytech ones delivering formal *Engineer degrees* ? Also my problem is that *Engineer degree* schools here in France, require specialization in physics, which I'm ok with, but also chemistry, which I'm awful at (physics and chemistry is merged into one), so I'm not sure if that could be a huge obstacle for me ...Or do you maybe have a completely different academic experience which turned out as the best / better, if so, could you suggest me please ?

Currently I'm skilled in ""general"" app programming for example in Next.js, React, TypeScript, Python and Node.js and recently I have tried to approach fields like working with building TFRecords and working in Tensorflow. I've learned these as a ""mid-step"" toward becoming a ML Engineer, maybe to have some work before actually becoming one ...

I hope I gave a good background and not too much boring reading and will appreciate all kinds of responses.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1769m91/looking_for_student_path_advice/,5,0,0.5,"[Comment(id='k4kohnj'), Comment(id='k4kxz1u'), Comment(id='k4msrjg'), Comment(id='k4kss9r'), Comment(id='k4lag96')]"
1769k8k,tbhaxor,,2023-10-12 15:23:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1769k8k/what_is_difference_between_scratch_space_vs/,What is difference between scratch space vs temporaryy space?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1769k8k/what_is_difference_between_scratch_space_vs/,1,1,0.67,[Comment(id='k4l7vi5')]
1768p9s,Invicto_50,,2023-10-12 14:46:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1768p9s/mathematics_for_machine_learning/,Mathematics for machine learning," Is the math in this [course](https://www.coursera.org/specializations/mathematics-machine-learning) enough for machine learning, and I intend to learn probability and statistics from [deeplearning course](https://www.coursera.org/learn/machine-learning-probability-and-statistics?specialization=mathematics-for-machine-learning-and-data-science). If not, what more should I do? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1768p9s/mathematics_for_machine_learning/,1,0,0.5,[Comment(id='k4kjhuj')]
1767mfp,skj8,,2023-10-12 13:57:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1767mfp/machine_learning_libraries_for_7_programming/,Machine Learning Libraries (for 7 Programming Languages),,learnmachinelearning,https://kanger.dev/article/machine-learning-libraries,0,0,0.5,[]
1767j8a,JTexpo,,2023-10-12 13:53:25+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1767j8a/interactive_rnn_using_pyscript/,Interactive RNN using PyScript,,learnmachinelearning,https://jtexpo.github.io/Graph_RNN/,1,1,1.0,[Comment(id='k4k9044')]
1764whw,tdionis,,2023-10-12 11:40:00+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1764whw/how_to_use_3d_object_interpolation_to_speed_up/,How To Use 3D Object Interpolation To Speed Up Point Cloud Annotation for LiDAR & Radar - Supervisely,,learnmachinelearning,https://supervisely.com/blog/3d-object-interpolation-in-point-clouds/,0,0,0.33,[]
1764okg,100GB-CSV,,2023-10-12 11:27:04+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1764okg/comprehensive_benchmarking_of_polars_rust/,Comprehensive Benchmarking of Polars (Rust Dataframe) with 4 Different Peaks,,learnmachinelearning,https://youtu.be/EwAtKrLzki8,0,0,0.5,[]
1762gqr,Fadawah,,2023-10-12 09:05:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1762gqr/do_diffusion_models_reproduce_the_original_images/,Do diffusion models reproduce the original images during the training process?," Hi there

I'm currently researching the nature of latent diffusion models, and I was wondering if the source images of the training set are reproduced in any capacity during the training run?

If so, could someone explain how and provide some extra reading material?

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1762gqr/do_diffusion_models_reproduce_the_original_images/,3,0,0.5,"[Comment(id='k4jfk55'), Comment(id='k4oeahx'), Comment(id='k4lifjz')]"
175stq5,Negative_Spread3917,,2023-10-11 23:55:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/175stq5/made_a_numpytutorial_series_need_feedback/,"Made A numpy-tutorial series, need feedback :)",,learnmachinelearning,https://www.youtube.com/playlist?list=PL2EW-qt0yFjbJzSKboYiWPhmt4VvMI27W,0,5,0.86,[]
175f5gh,,,2023-10-11 14:20:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175f5gh/should_i_forget_about_practicals_right_now_and_go/,Should I forget about practicals right now and go all-in on theory?,"I've been kind of torn on which part to go to. My first ML courses were almost completely theoretical stuff. But, I didn't understand them very well. I want to be a researcher, and if I recall, theory and maths is really important there. I have a pretty basic practical knowledge. Can clean up data a bit, if its not too messed up, and can import libraries, fit models etc. I'm not sure how important practical knowledge is. I plan on doing [fast.ai](https://fast.ai/)'s deep learning course and Stanford's CS229A which iirc are more hands-on. And I feel like I'm just stitching together a bunch of libraries and code that I have 0 idea about.

But, after that I plan on going all out in theory, with math courses and maths books, especially Ian Goodfellow's Deep Learning book and Mathematics for Machine Learning. Is there any course similar to these books? Because I do more from videos online than learning from books. Its mostly my opinion, but it feels like large part of an ML engineer's work, most of the practical stuff can be easily automated, if not now then in the near future. So, I can focus more on other things. And I need to devote more time to the theory since I'm a bit slow when it comes to maths and I need to catch up.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175f5gh/should_i_forget_about_practicals_right_now_and_go/,19,24,0.96,"[Comment(id='k4g3598'), Comment(id='k4gvpqm'), Comment(id='k4gfn2j'), Comment(id='k4gjapi'), Comment(id='k4feyvt'), Comment(id='k4ifw8q'), Comment(id='k4g5ros'), Comment(id='k4it12j'), Comment(id='k4ioeka'), Comment(id='k4imstm'), Comment(id='k4ivrus'), Comment(id='k4iw36n'), Comment(id='k4ix2qv'), Comment(id='k4ix75s'), Comment(id='k4iz52x'), Comment(id='k4izcjy'), Comment(id='k4j0c8q'), <MoreComments count=0, children=[]>]"
1760jq5,Sith_vader3,,2023-10-12 06:51:49+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1760jq5/a_question/,A question,How does the neural network process input that were same but shown different to the network model?,learnmachinelearning,https://www.reddit.com/gallery/1760jq5,7,0,0.44,"[Comment(id='k4j5kba'), Comment(id='k4merku'), Comment(id='k4j76ja'), Comment(id='k4j7gao'), Comment(id='k4kx959'), Comment(id='k4j9wpd'), Comment(id='k4ja3s9')]"
175w0e0,Hungry_Ad2369,,2023-10-12 02:28:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175w0e0/anyone_from_an_investment_management_background/,Anyone from an investment management background learning ML?,What sorts of problem statements are you looking to tackle in your work life? How is ML truly being used inside buyside firms? I have past experiences in this industry but out of it now for a while...so I'm curious,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175w0e0/anyone_from_an_investment_management_background/,1,2,0.75,[Comment(id='k4j3eal')]
175vsv7,PinstripePride97,,2023-10-12 02:18:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175vsv7/anyone_with_a_proper_optuna_implementation_for/,Anyone with a proper Optuna implementation for regression?,"I would like to add some pruning for unpromising trials and also the use of TPE sampler, however im not having any success, as it looks that i had the same results as without that. Does anyone have a example of a proper implementation of this? 

This is my code without the pruning and TPE:

`def objective(trial):`  
  `param = {`  
  `'objective': 'reg:squarederror',`  
  `'eval_metric': 'rmse',`  
  `'max_depth': trial.suggest_int('max_depth', 1, 10),`  
  `'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),`  
  `'n_estimators': trial.suggest_int('n_estimators', 50, 1000),`  
  `'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),`  
  `'gamma': trial.suggest_float('gamma', 0.01, 1.0),`  
  `'subsample': trial.suggest_float('subsample', 0.01, 1.0),`  
  `'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),`  
  `'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),`  
  `'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),`  
  `'random_state': trial.suggest_int('random_state', 1, 1000)`  
`}`  
   
  `model = xgboost.XGBRegressor(**param)`  
  `model.fit(x_train, y_train)`  
  `y_pred = model.predict(x_val)`  
  `return np.sqrt(mean_squared_error(y_val, y_pred))`

`study = optuna.create_study(direction='minimize', study_name='regression')`  
`study.optimize(objective, n_trials=100)`",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175vsv7/anyone_with_a_proper_optuna_implementation_for/,3,2,1.0,"[Comment(id='k4ipffx'), Comment(id='k4ipiqo'), Comment(id='k4isk43')]"
175zn2h,Vegetable_Forever460,,2023-10-12 05:52:45+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/175zn2h/meta_ai_beta_is_talking_on_streams/,META AI BETA IS TALKING ON STREAMS,"I need to preface this by saying I thought I was hallucinating. 

My friend and I were playing around with the new Meta AI Beta. He watched my stream of multiple AIs with no issue. Then he streamed him playing around with them, and I could HEAR THEM TALKING. 

I kept asking if there was someone in the background, and he said no. We were adjusting discord settings, and I could still hear the voices. Finally figured out that it was the AI!

Snoop dog kept saying ""control."" The blonde crime solver like...moans. And Mr. Beast says ""oh, okay"" and breathes really heavily. They talk based on their movement in the video. I attached a video of Mr. Beasts, but I also have videos of the other ones. I will post if anyone is interested. 

However, we can't hear the voices outside of the stream. 

We can't find any setting. Any info. Does anybody have any idea how this is even POSSIBLY happening? Nervous that maybe I shouldn't be using new tech? ",learnmachinelearning,https://v.redd.it/glhccx8jnptb1,1,0,0.5,[Comment(id='k4ken2y')]
175klgj,psm199345,,2023-10-11 18:03:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175klgj/free_machine_learning_courses_for_absolute/,"Free machine learning courses for absolute beginner (no prior experience of coding, programming, maths or data science)?","Hi all! So, I'm sure this question has been asked before, but I've really struggled to find an online course in machine learning that doesn't assume prior knowledge. Now, perhaps this is because you need prior knowledge? If this is the case, I'm happy to learn any pre-requisites, but I have no idea where to start hence why I was hoping to be able to find a course which just teaches you what you need to know as you go along. TIA.

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175klgj/free_machine_learning_courses_for_absolute/,12,5,0.78,"[Comment(id='k4gtjye'), Comment(id='k4hhfui'), Comment(id='k4k09pd'), Comment(id='k4gmuc7'), Comment(id='k4h512s'), Comment(id='k4hkb2i'), Comment(id='k4h4soq'), Comment(id='k4q0i7f'), Comment(id='k4il6by'), Comment(id='k4h6zr8')]"
17573gl,VHQN,,2023-10-11 06:06:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17573gl/is_probabilistic_approach_to_machine_learning_ml/,"Is probabilistic approach to machine learning (ML) that hard, or have I messed up something?","Let me start with some words about my background I'm currently a 1st year PhD student in the US, and my research topic is neuromorphic computing. I have some experiences working on ML as a an engineer for two years before my PhD. Most of my machine learning knowledge comes from online courses and on-the-job training. So when I started my PhD, I made it a mission to dive deeper on the theories behind ML: decision theories, empirical risk minization, etc. 

My approach and process so far: I know that to be fluent in ML's theories, I need to have strong math foundations, so I read and solve problems from Strang's Linear Algebra, Montgomery's Probability and Statistics (I also read Blitzstein's Intro to Probablity to compliment my knowledge), and Stewart's Calculus. In the end, I can say I have a good foundation in the maths, as commented by my labmates when I help/tutor them for their math classes. Next, I got my hands dirtied with coding algorithms Geralion's Hands-on ML.

However, things started to get awry when I started learning ML from my university's course + read the recommended textbooks (Murphy's Probabilistic ML and Hastie's Elements of Statistical Learning): I realized that I could not comprehend most of the topics mentioned in the books.

Have I messed up something, or is probabilistic approach to machine learning (ML) that hard? What do you think?

P/s: sorry for a long post, it's just I have been frustrating at my own progress. 🥲",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17573gl/is_probabilistic_approach_to_machine_learning_ml/,14,45,0.98,"[Comment(id='k4dunzb'), Comment(id='k4e5fgt'), Comment(id='k4eglmu'), Comment(id='k4elrog'), Comment(id='k4fdo94'), Comment(id='k4etp4x'), Comment(id='k4f8r1f'), Comment(id='k4g49lk'), Comment(id='k4iavz7'), Comment(id='k4er2cp'), Comment(id='k4mklgb'), Comment(id='k4g5hwg'), Comment(id='k5pu1zo'), Comment(id='k4huxe7')]"
175qdq6,0ni0nrings,,2023-10-11 22:06:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175qdq6/how_to_download_datasets_from_huggingface/,how to download datasets from huggingface,"Hello, first time using Google Colab and huggingface datasets. Colab notebook is easy to setup but I can't seem to figure out how to download datasets from huggingface.

I am trying to download [https://huggingface.co/datasets/kili-technology/plastic\_in\_river](https://huggingface.co/datasets/kili-technology/plastic_in_river) dataset in Colab Notebook. After reading some beginners forums, I modified the example to look like one below but it failed.

    from datasets import load_dataset
    
    data_files = {""train"": ""train.csv"", ""test"": ""test.csv"", ""validation"": ""validation.csv""}
    dataset = load_dataset(""kili-technology/plastic_in_river"", data_files=data_files)

Because there's no path to the files to be downloaded. Can someone explain how to download datasets from huggingface please?

    Downloading builder script: 100%
    3.25k/3.25k [00:00<00:00, 228kB/s]
    Downloading metadata: 100%
    2.79k/2.79k [00:00<00:00, 147kB/s]
    Downloading readme: 100%
    496/496 [00:00<00:00, 34.2kB/s]
    ---------------------------------------------------------------------------
    FileNotFoundError                         Traceback (most recent call last)
    <ipython-input-5-98701edb7a4d> in <cell line: 4>()
          2 
          3 data_files = {""train"": ""train.csv"", ""test"": ""test.csv"", ""validation"": ""validation.csv""}
    ----> 4 dataset = load_dataset(""kili-technology/plastic_in_river"", data_files=data_files)
    
    5 frames
    /usr/local/lib/python3.10/dist-packages/datasets/data_files.py in resolve_pattern(pattern, base_path, allowed_extensions, download_config)
        366         if allowed_extensions is not None:
        367             error_msg += f"" with any supported extension {list(allowed_extensions)}""
    --> 368         raise FileNotFoundError(error_msg)
        369     return out
        370 
    
    FileNotFoundError: Unable to find 'https://huggingface.co/datasets/kili-technology/plastic_in_river/resolve/main/train.csv'",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175qdq6/how_to_download_datasets_from_huggingface/,0,2,1.0,[]
1760br1,Alive_Potential739,,2023-10-12 06:36:46+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1760br1/anyone_help_me_out/,Anyone help me out,"I have no idea what to do, any help is appreciated
Thanks in advance",learnmachinelearning,https://i.redd.it/1ajhz7tmvptb1.jpg,2,0,0.36,"[Comment(id='k4j58e7'), Comment(id='k4j7ex9')]"
1760bls,Alive_Potential739,,2023-10-12 06:36:30+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1760bls/anyone_help_me_out/,Anyone help me out,"I have no idea what to do, any help is appreciated
Thanks in advance",learnmachinelearning,https://i.redd.it/k7j12sykvptb1.jpg,6,0,0.43,"[Comment(id='k4jaov1'), Comment(id='k4j59qs'), Comment(id='k4jfbj6'), Comment(id='k4j5dc3'), Comment(id='k4jp54b'), Comment(id='k4jp81u')]"
175tbwn,Science-man777,,2023-10-12 00:18:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175tbwn/how_to_catch_aicheating/,How To Catch AI-Cheating,"""If you happen to have any dilutions of students not using ChatGPT and other artificial intelligence (AI) to cheat, it is time to get informed.  According to a recent survey from the Center for Democracy and Technology, [58% of students](https://cdt.org/wp-content/uploads/2023/09/091823-CDT-Off-Task-Summary-web.pdf) report using generative AI to complete assignments.  As awareness of this technology rises, this number only stands to increase. Meanwhile, the same study reports that educators find themselves behind the technology curve, with only 43% of teachers having been significantly trained on generative AI. 

""...how students use this technology to cheat and how teachers can detect and respond to generative AI. Beyond just detecting its use, this new technology may present an opportunity to leverage new and innovative ways of educating.""

[https://ai-solutions.pro/tools-to-detect-ai-cheating/](https://ai-solutions.pro/tools-to-detect-ai-cheating/)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175tbwn/how_to_catch_aicheating/,12,0,0.5,"[Comment(id='k4icfq9'), Comment(id='k4i8vmc'), Comment(id='k4i6l00'), Comment(id='k4iclc4'), Comment(id='k4i2bf2'), Comment(id='k4i0wv4'), Comment(id='k4l3som'), Comment(id='k80h9yx'), Comment(id='k4iadg2'), Comment(id='k4igcjz'), Comment(id='k4kiftt')]"
175nm4t,zezeartix,,2023-10-11 20:11:34+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/175nm4t/neural_networks_from_scratch_in_rust/,Neural Networks From Scratch in Rust,,learnmachinelearning,https://youtube.com/watch?v=DKbz9pNXVdE&si=krwSHG8K-FB6EAse,2,2,0.63,"[Comment(id='k4hq39p'), Comment(id='k4i4ju0')]"
174lqrp,__god_bless_you_,,2023-10-10 13:50:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174lqrp/ml_engineer_here_tell_me_what_you_wish_to_learn/,ML Engineer Here - Tell me what you wish to learn and I'll do my best to curate the best resources for you 💪,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174lqrp/ml_engineer_here_tell_me_what_you_wish_to_learn/,470,394,0.98,"[Comment(id='k4a8mjv'), Comment(id='k4as3ol'), Comment(id='k4a99ol'), Comment(id='k4ad7xg'), Comment(id='k4ahjvx'), Comment(id='k4bdwij'), Comment(id='k4a2ezu'), Comment(id='k4a0nvo'), Comment(id='k4aic6v'), Comment(id='k4dx1cp'), Comment(id='k4a38ps'), Comment(id='k4cpptn'), Comment(id='k4a5uji'), Comment(id='k4ahyi0'), Comment(id='k4ao23f'), Comment(id='k4ap92w'), Comment(id='k4awvgx'), Comment(id='k4b3bzd'), Comment(id='k4bcbms'), Comment(id='k4bef11'), Comment(id='k4bxah1'), Comment(id='k4c5sub'), Comment(id='k4cs654'), Comment(id='k4d2da0'), Comment(id='k4e6e10'), Comment(id='k4f5e9j'), Comment(id='k4ig68l'), Comment(id='k4j6ce3'), Comment(id='k4j7dhb'), Comment(id='k4oj1e8'), Comment(id='k4soxl1'), Comment(id='k4ytomb'), Comment(id='k4zp503'), Comment(id='k53oz5o'), Comment(id='k542bmn'), Comment(id='k5mrh57'), Comment(id='k5p4pmk'), Comment(id='k5uqqow'), Comment(id='k4a3wn9'), Comment(id='k4aoeh5'), Comment(id='k4dkhuq'), Comment(id='k49wuda'), Comment(id='k4a8pcl'), Comment(id='k4am5nm'), Comment(id='k4n1fgf'), Comment(id='k4r63as'), Comment(id='k4byv87'), Comment(id='k4cles9'), Comment(id='k4a7zpx'), Comment(id='k4a8ynf'), Comment(id='k4a8zim'), Comment(id='k4aam4o'), Comment(id='k4aatz1'), Comment(id='k4afrw2'), Comment(id='k4aftae'), Comment(id='k4ajr56'), Comment(id='k4ak4nz'), Comment(id='k4alct2'), Comment(id='k4amnuu'), Comment(id='k4amp62'), Comment(id='k4anpjj'), Comment(id='k4aokes'), Comment(id='k4ap3wy'), Comment(id='k4aqabd'), Comment(id='k4aqepy'), Comment(id='k4ash5i'), Comment(id='k4asjpa'), Comment(id='k4avncu'), Comment(id='k4axlot'), Comment(id='k4ayb01'), Comment(id='k4az2a2'), Comment(id='k4azua0'), Comment(id='k4azus3'), Comment(id='k4b0xy6'), Comment(id='k4b10lf'), Comment(id='k4b2umz'), Comment(id='k4b4qq0'), Comment(id='k4b4vj6'), Comment(id='k4b8ej6'), Comment(id='k4bbwh7'), Comment(id='k4bdytf'), Comment(id='k4be3ks'), Comment(id='k4bekw6'), Comment(id='k4bfonj'), Comment(id='k4bgv7v'), Comment(id='k4bidz9'), Comment(id='k4bj6c1'), Comment(id='k4blpur'), Comment(id='k4bng1x'), Comment(id='k4brve3'), Comment(id='k4bss98'), Comment(id='k4btvsg'), Comment(id='k4bvdpa'), Comment(id='k4bz8dq'), Comment(id='k4bzw3v'), Comment(id='k4c01hr'), Comment(id='k4c06v7'), Comment(id='k4c1swy'), Comment(id='k4c2ib5'), Comment(id='k4c2qsf'), Comment(id='k4c4iay'), Comment(id='k4c65dq'), Comment(id='k4cbuto'), Comment(id='k4chcsb'), Comment(id='k4ci0s4'), Comment(id='k4cm7ua'), Comment(id='k4cusfy'), Comment(id='k4cvmdx'), Comment(id='k4d01rf'), Comment(id='k4d9fqm'), Comment(id='k4dbuk4'), Comment(id='k4dd3oc'), Comment(id='k4dgxit'), Comment(id='k4dhj7c'), Comment(id='k4dia2l'), Comment(id='k4djflq'), Comment(id='k4dlu6e'), Comment(id='k4dnnez'), Comment(id='k4dqr40'), Comment(id='k4drfz0'), Comment(id='k4drl1n'), Comment(id='k4dvx9d'), Comment(id='k4dwgqc'), Comment(id='k4dy3ji'), Comment(id='k4dzbsc'), Comment(id='k4e04pf'), Comment(id='k4e13h6'), Comment(id='k4e1t1s'), Comment(id='k4e1y5h'), Comment(id='k4e3bi7'), Comment(id='k4e5jrw'), Comment(id='k4e6dpz'), Comment(id='k4e6roi'), Comment(id='k4e8m9e'), Comment(id='k4ecjat'), Comment(id='k4efuyk'), Comment(id='k4ehysl'), Comment(id='k4ek5eb'), Comment(id='k4eln3p'), Comment(id='k4er4r9'), Comment(id='k4es77m'), Comment(id='k4eswy1'), Comment(id='k4exhd3'), Comment(id='k4f44en'), Comment(id='k4f7g66'), Comment(id='k4fdwtk'), Comment(id='k4fo5f0'), Comment(id='k4ft2ro'), Comment(id='k4fvjfs'), Comment(id='k4g2xcu'), Comment(id='k4gbsai'), Comment(id='k4he1af'), Comment(id='k4hmn6p'), Comment(id='k4iqf2p'), Comment(id='k4iqr6w'), Comment(id='k4jel0t'), Comment(id='k4joc1d'), Comment(id='k4jp0lv'), Comment(id='k4kkdar'), Comment(id='k4kzzmw'), Comment(id='k4l1ply'), Comment(id='k4lljsg'), Comment(id='k4n5prz'), Comment(id='k4nd36f'), Comment(id='k4o2o10'), Comment(id='k4p5oqi'), Comment(id='k4s44yp'), Comment(id='k4z9wmy'), Comment(id='k51c3kd'), Comment(id='k56sbgj'), Comment(id='k57oni5'), Comment(id='k5hwyes'), Comment(id='k5ixobj'), Comment(id='k5z1oip'), Comment(id='k698pls'), Comment(id='k6ajqra'), Comment(id='k6buomb'), Comment(id='k6d3zw6'), Comment(id='k6kia70'), Comment(id='k6m6nfp'), Comment(id='k6mfizx'), Comment(id='k6ntcsh'), Comment(id='k6q6ubr'), Comment(id='k6tkrxz'), Comment(id='k6z7fke'), Comment(id='k7ail9s'), Comment(id='k7fyzvs'), Comment(id='k7glsz1'), Comment(id='k7igqgx'), Comment(id='k7ssbjg'), Comment(id='k7vg4g2'), Comment(id='k7xnjfm'), Comment(id='k7ywf7m'), Comment(id='k4aad9f'), Comment(id='k4es0u2'), Comment(id='k4avjyf'), Comment(id='k4cinph'), Comment(id='k4gka5k'), Comment(id='k5iwnxd'), Comment(id='k4ahffe'), Comment(id='k4afbww'), Comment(id='k4afncc'), Comment(id='k4anj8i'), Comment(id='k78d362'), Comment(id='k4hoipo'), Comment(id='k4a7btt'), Comment(id='k4a3gav'), Comment(id='k4cvadc'), Comment(id='k4kqqjk'), Comment(id='k4b4wme'), Comment(id='k4am9sc'), Comment(id='k4dj8vg'), Comment(id='k4e3gwc'), Comment(id='k4a6bwf'), Comment(id='k5p4zcl'), Comment(id='k4a9m46'), Comment(id='k4am2qr'), Comment(id='k5y5c01'), Comment(id='k4awj08'), Comment(id='k4aynbh'), Comment(id='k4b3p5x'), Comment(id='k4e3cvw'), Comment(id='k4hwg85'), Comment(id='k4bowwz'), Comment(id='k4bydx1'), Comment(id='k4e14m2'), Comment(id='k4d2ikp'), Comment(id='k4jy692'), Comment(id='k7wf228'), Comment(id='k4zahgb'), Comment(id='k7wex0c'), Comment(id='k7wexe5'), Comment(id='k7wexiw'), Comment(id='k7wey60'), Comment(id='k7weyd3'), Comment(id='k7weyj6'), Comment(id='k4a6ig8'), Comment(id='k49ym5t'), Comment(id='k4aa4cj'), Comment(id='k4aavfv'), Comment(id='k4a9ffd'), Comment(id='k4abuan'), Comment(id='k4boanw'), Comment(id='k4cyrmq'), Comment(id='k4aeoba'), Comment(id='k4axld7'), Comment(id='k4agm7o'), Comment(id='k4amic6'), Comment(id='k4aml46'), Comment(id='k4amt6t'), Comment(id='k4an7lu'), Comment(id='k4an3st'), Comment(id='k4apb8o'), Comment(id='k4avmhw'), Comment(id='k4av857'), Comment(id='k4av67m'), Comment(id='k4ayk0o'), Comment(id='k4ayqjs'), Comment(id='k4b091o'), Comment(id='k4b11lm'), Comment(id='k4b10ao'), Comment(id='k4b1ejz'), Comment(id='k4e2ihx'), Comment(id='k4b78jt'), Comment(id='k4bpdz0'), Comment(id='k4bote1'), Comment(id='k4bnwjl'), Comment(id='k4bl8ry'), Comment(id='k4by4a2'), Comment(id='k4bu0yq'), Comment(id='k4e1hwo'), Comment(id='k4e1o0g'), Comment(id='k4e1pss'), Comment(id='k4e26pm'), Comment(id='k4e228m'), Comment(id='k4e1gd8'), Comment(id='k4e23to'), Comment(id='k4e1e3r'), Comment(id='k4e1dh3'), Comment(id='k4e1auw'), Comment(id='k4e13v1'), Comment(id='k4e0znw'), Comment(id='k4e0xk4'), Comment(id='k4e0vqj'), Comment(id='k4e0v65'), Comment(id='k4e0ssr'), Comment(id='k4e0qsp'), Comment(id='k4e0ipv'), Comment(id='k4dz2wm'), Comment(id='k4dyy9u'), Comment(id='k4dyv8d'), Comment(id='k4dyrne'), Comment(id='k4e3j2j'), Comment(id='k4e3o8t'), Comment(id='k4erj5w'), Comment(id='k4erh6d'), Comment(id='k4ey8kq'), Comment(id='k4f8ia0'), Comment(id='k4f98bn'), Comment(id='k4gigui'), Comment(id='k4gi1yl'), Comment(id='k4gj4ib'), Comment(id='k4jxkmi'), Comment(id='k4jy1iw'), Comment(id='k4jy3c9'), Comment(id='k4jyps2'), Comment(id='k4jyher'), Comment(id='k4udely'), Comment(id='k7wf33i'), Comment(id='k4ud8l9'), Comment(id='k7wf28l'), Comment(id='k7wf1uy'), Comment(id='k4ud6vz'), Comment(id='k4zae2g'), Comment(id='k4zaej7'), Comment(id='k7wex6w'), Comment(id='k7wexmt'), Comment(id='k7wexry'), Comment(id='k7wexwd'), Comment(id='k7wey1e'), Comment(id='k7weynm'), Comment(id='k7weyva'), Comment(id='k7wez88'), Comment(id='k7wez11'), Comment(id='k7weze2'), Comment(id='k7wezid'), Comment(id='k7wezo7'), Comment(id='k7wezud'), Comment(id='k7wezzq'), Comment(id='k7wf05k'), Comment(id='k7wf0f8'), Comment(id='k7wf0ln'), Comment(id='k7wf0qi'), Comment(id='k7wf0w1'), Comment(id='k7wf11m'), Comment(id='k7wf18j'), Comment(id='k7wf1dy'), Comment(id='k4aai4t'), Comment(id='k4at0wo'), Comment(id='k4g2vvc'), Comment(id='k4lkugf'), Comment(id='k4ax4je'), Comment(id='k4eviu1'), Comment(id='k4ai36x'), Comment(id='k4dq7th'), Comment(id='k4ay8z3'), Comment(id='k4azrsx'), Comment(id='k4d4k9s'), Comment(id='k7a4tdg'), Comment(id='k4amo8v'), Comment(id='k4ae1d9'), Comment(id='k4cajdc'), Comment(id='k4a66gi'), Comment(id='k4a4vzd'), Comment(id='k4cz7gu'), Comment(id='k4bbrzn'), Comment(id='k4aoegt'), Comment(id='k4ag2h3'), Comment(id='k4azgl9'), Comment(id='k52ilqt'), Comment(id='k4b5onw'), Comment(id='k4b4obq'), Comment(id='k4b7oxz'), Comment(id='k4gudwx'), Comment(id='k4iiz46'), Comment(id='k4byxvz'), Comment(id='k4d2vu6'), Comment(id='k4o8et3'), Comment(id='k4zbc95'), Comment(id='k4a8nl9'), Comment(id='k4b62p2'), Comment(id='k4ab0q8'), Comment(id='k4a9jvw'), Comment(id='k4adf3l'), Comment(id='k4ajs7d'), Comment(id='k4azq99'), Comment(id='k4anezn'), Comment(id='k4auxpq'), Comment(id='k4aqlu3'), Comment(id='k4j53q8'), Comment(id='k4b2i36'), Comment(id='k4b3bsj'), Comment(id='k4bmf3l'), Comment(id='k4b1onk'), Comment(id='k4b1czs'), Comment(id='k4b2k8g'), Comment(id='k4bo0di'), Comment(id='k4d7w3u'), Comment(id='k4i8551'), Comment(id='k4k2nj4'), Comment(id='k4gbev4'), Comment(id='k4e7vxm'), Comment(id='k4iokve'), Comment(id='k4erwme'), Comment(id='k4i6i7u'), Comment(id='k4l2thv'), Comment(id='k4gjdgi'), Comment(id='k4ikf7k'), Comment(id='k4k9mwf'), Comment(id='k4jzh5m'), Comment(id='k4jz3ye'), Comment(id='k4nrkw5'), Comment(id='k4ufts8'), Comment(id='k4urvmu'), Comment(id='k7xlwcz'), Comment(id='k7wqb6r'), Comment(id='k4ayvrh'), Comment(id='k4ey5dl'), Comment(id='k4aifl7'), Comment(id='k4b16lg'), Comment(id='k4d16h2'), Comment(id='k4d103k'), Comment(id='k4a5w13'), Comment(id='k4boit6'), Comment(id='k4axj8k'), Comment(id='k4alim1'), Comment(id='k4b0xcb'), Comment(id='k53bh6q'), Comment(id='k4b84g7'), Comment(id='k4b88m3'), Comment(id='k4ix4ps'), Comment(id='k4d328l'), Comment(id='k4aa1i1'), Comment(id='k4b5hcm'), Comment(id='k4aesi1'), Comment(id='k4agb5e'), Comment(id='k4axz2p'), Comment(id='k4ao9ew'), Comment(id='k4awq6o'), Comment(id='k4b470e'), Comment(id='k4b41ns'), Comment(id='k4bxz2g'), Comment(id='k4b27o7'), Comment(id='k4bq6h8'), Comment(id='k4jxsk7'), Comment(id='k4jxvk3'), Comment(id='k4jxhbi'), Comment(id='k4k0hx5'), Comment(id='k4k0dny'), Comment(id='k4cv5gd'), Comment(id='k4f549n'), Comment(id='k4aj30f'), Comment(id='k4c59dm'), Comment(id='k4be0uc'), Comment(id='k4evu6g'), Comment(id='k4betin'), Comment(id='k4d42gu'), Comment(id='k4b810f'), Comment(id='k4aoopa'), Comment(id='k4axhqd'), Comment(id='k4b58e3'), Comment(id='k4lmwjl'), Comment(id='k4k4a9e'), Comment(id='k4k1j2h'), Comment(id='k4f5q7m'), Comment(id='k4g33wq'), Comment(id='k4awiba'), Comment(id='k4cycvh'), Comment(id='k4plcph'), Comment(id='k4ey2ba'), Comment(id='k4bnzd5'), Comment(id='k4d88ld'), Comment(id='k4axat1'), Comment(id='k4b6fk5'), Comment(id='k4f7nf2'), Comment(id='k4gwak0'), Comment(id='k4d8eej'), Comment(id='k4bzfvm'), Comment(id='k4f9ova'), Comment(id='k4c3gvb'), Comment(id='k4c5ozq'), Comment(id='k4vu1lw')]"
175k8y2,Mr__Weasels,,2023-10-11 17:49:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175k8y2/would_representing_images_in_hsl_format_instead/,would representing images in HSL format instead of RGB improve accuracy?,"hey, im learning ml in school and i just finished doing an image recognition perceptron. we were instructed to use the numpy function that makes an image into an rgb array, but i cant help but wonder if it would theoretically be more accurate to train it on hsl? since hsl is a better representation of how images actually are than rgb",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175k8y2/would_representing_images_in_hsl_format_instead/,2,2,1.0,"[Comment(id='k4gatzh'), Comment(id='k4im2uc')]"
175o3uj,Reasonable-Copy-8660,,2023-10-11 20:31:49+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/175o3uj/seeking_methods_to_incorporate_arbitrary_actuator/,Seeking methods to incorporate arbitrary actuator faults for Control Optimization,,learnmachinelearning,/r/ControlTheory/comments/175o3dr/seeking_methods_to_incorporate_arbitrary_actuator/,0,1,1.0,[]
175nuc7,Additional-Ad-7043,,2023-10-11 20:20:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175nuc7/how_do_bytelevel_language_models_work/,How do byte-level language models work?,"I've recently been trying to pre-train my own small language model on the tiny-series datasets on huggingface: [https://huggingface.co/collections/nampdn-ai/tiny-series-6503910fd491144159519c70](https://huggingface.co/collections/nampdn-ai/tiny-series-6503910fd491144159519c70). I also wanted to use a model similar to MEGABYTE: [https://arxiv.org/pdf/2305.07185.pdf](https://arxiv.org/pdf/2305.07185.pdf), but I don't understand how using bytes would work. The only implementation I could find: [https://github.com/lucidrains/MEGABYTE-pytorch](https://github.com/lucidrains/MEGABYTE-pytorch) used str(chr(max(32, token))) to decode any token (byte) to a character and put the embedding size as 256. Firstly, why 256 and not 256-32 as any values below 32 are ignored? Also, many byte-level models including this and ByteT5 mention that they can process any text sequence even in a multilingual setting, however how would that be true if we are only using one byte, would we have to move to 2 bytes or use an UNK token, and if we did use 2 bytes that would make our embedding size around 65000 which defeats sort of the point as one of the advantages mentioned is that we are able to use a small embedding matrix? Furthermore, most language models add special tokens like bos, eos, unk and even for llama they use beginning of instruction, end of instruction, and more for system instructions, response, context... Should I use something like this as my dataset has some structures where there is a context, instruction and response, and if i did how would I add these if I'm using byte-level encodings? Final questions: Firstly, for the datasets mentioned including code,stories,webtext,... would I tokenise all of these datasets then concatenate them to then randomly sample from, or should i train seperately on each as some like code and webtext are much larger than the others? Finally, for the webtext part of the dataset, there is a passage of text then a passage analysing the text (main ideas,purpose,...), how should I encode this, should I use an extra ANALYSE token or just concatenate?

Thank you for reading this far, I am sort of a beginner so if I said something stupid please point it out. Also, if there were unclear parts in my question I'm sorry as I struggled how to word these questions. Any help would be appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175nuc7/how_do_bytelevel_language_models_work/,1,1,1.0,[Comment(id='k4gtay3')]
175nhio,Firm_Guess8261,,2023-10-11 20:06:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175nhio/qa_custom_dataset/,Q-A Custom Dataset,"
I am planning on using LLama2 to finetune on custom dataset. The dataset in question is Solana guides/tutorials and general information, scrapped from different Solana websites.  
I have used a series of synthetic prompts-completions generated from GPT-3.5-Turbo. 
On paper, results are great but I want to move to real world data.  
Question - how do I create a series of prompts-completions/questions-answers from the dataset scrapped?  
I have already tried using T5 and  number of transformers to extract simple questions, and then pair back with answers. So far, unsatisfactory. 

Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175nhio/qa_custom_dataset/,0,1,1.0,[]
175mzi2,Enough_Wishbone7175,,2023-10-11 19:45:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175mzi2/grad_school_dilemma/,Grad School Dilemma,"So I completed my undergrad in Finance, minor in Econ. I really want to go into a the Georgia Tech online masters program for CS, with a focus in ML. I work in product at a good firm and was hoping to leverage my professional experience to get in. After talking to an older coworker, I learned that had a similar background and got rejected in the application phase. I want to apply this March but I’m not sure what I can do to make my application more robust so I have a chance of getting in.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175mzi2/grad_school_dilemma/,0,1,1.0,[]
175halv,yeshwanthv5,,2023-10-11 15:48:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175halv/what_are_the_sota_encoderdecoder_models/,What are the SOTA encoder-decoder models?,I feel T5 and BERT are kind of old now but most of the articles on the internet are on them. What are state-of-the-art encoder decoder foundation models in 2023?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175halv/what_are_the_sota_encoderdecoder_models/,3,2,1.0,"[Comment(id='k4fqwn1'), Comment(id='k4g99fi'), Comment(id='k6lgv34')]"
175l88i,modelbit,,2023-10-11 18:30:30+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/175l88i/deploy_googles_table_qa_model_tapas_to_a_rest_api/,Deploy Google’s Table Q&A Model (TAPAS) to a REST API from a Notebook,,learnmachinelearning,https://www.modelbit.com/blog/deploying-googles-table-q-a-model-tapas-to-a-rest-api,0,1,1.0,[]
175inza,misplacedlion,,2023-10-11 16:43:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175inza/problem_solving_issues_in_programming/,Problem solving issues in programming,"Hello Redditors,

I am a student who is currently studying Bachelor of Science in AI. I have a question regarding improving my coding skills. I am aiming for a research internship and I don't know where to start. I previously took a summer school that taught me a lot about state-of-the-art models such as GANs, Transformers, VAEs, GNNs, etc. I would like to improve my coding skills, specifically problem-solving and writing clean code. I have experience with deep learning in general and data analysis. I am looking for a research internship next summer. Where should I start?

I plan to review some of the deep learning material in the Deep Learning Specialization before taking the GAN specialization. However, when it comes to coding, I want to think like a software engineer or a great programmer. What do you guys suggest for improving my coding or problem-solving skills? I'm feeling confused with multiple resources and I don't know where to begin.

I’d really appreciate your help.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175inza/problem_solving_issues_in_programming/,2,0,0.33,"[Comment(id='k4g26ku'), Comment(id='k4hdhjz')]"
175duiq,Future-Result1655,,2023-10-11 13:19:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175duiq/guys_anyone_have_some_tips_on_how_to_use_google/,guys anyone have some tips on how to use google colab pro in efficient way ? 🐳🥹,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175duiq/guys_anyone_have_some_tips_on_how_to_use_google/,0,1,1.0,[]
175ccw9,Seankala,,2023-10-11 12:02:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175ccw9/text_generation_models_training_loss_is/,Text generation model's training loss is decreasing but keeps outputting the same meaningless words.,"The model is the original encoder-decoder Transformer model. The settings are largely the same as in the paper.

The multihead attention that I'm using receives a mask, and I'm using a padding mask for the normal multihead attention and a padding + causality mask for the asked mutihead attention.

The data has been processed so that the source tokens are as is but the target tokens are wrapped around BOS and EOS tokens.

Has anyone faced this problem before? I've tried varying the learning rate, removing masking, removing attention, etc. but nothing seems to be showing any different results. Always the same training loss decreasing and useless output.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175ccw9/text_generation_models_training_loss_is/,2,1,1.0,"[Comment(id='k4gz70y'), Comment(id='k4hh7a6')]"
1750kjf,Titty_Slicer_5000,,2023-10-11 00:18:12+00:00,False,,1696988626.0,False,True,False,/r/learnmachinelearning/comments/1750kjf/my_music_genre_classifier_keeps_overfitting/,My Music Genre Classifier keeps overfitting,"Hey all. I plan on making an AI-powered music product, and to that end I finished Andrew Ng's machine learning and deep learning specializations on coursera. I have been working on a project alongside those courses to put into practice what I had learned, which is a music genre classifier. The only issue is, no matter what I do the best I can get is around 80% accuracy on my validation set. I am using the [GTZAN data set for music genre classification](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification), which has 1000 songs split into 10 genres. Each song is 30 seconds long.   I have tried multiple different architectures: a standard NN, a CNN, and a CNN-RNN hybrid model.  My methodology is as follows:

**Data Preparation**

1. Split 1000 songs into 800 training songs and 200 test songs
2. Segment 800 training songs into 5 (or another number) of segments.   Have a training set of 4000 (or other number depending on segments) songs.
3. Get a regular spectrogram or an MLCC spectrogram of each segment.   Tried both.
4. Perform data augmentation of training set.  I have tried a mix of different things: adding low-pass filters at different frequencies, pitch-shifting, time-stretching, and varying the loudness of the track
5. Segment 800 test songs into segments of equal length to the training set.   Only choose 1 segment for each song to put into test set.   This is to ensure the test set does not have segments of the same song, which could inflate model accuracy.

&#x200B;

**Models Tried**

*Straight CNN, SpatialDropout-2D*

I have tried a CNN with varying layers and number of parameters.   I created a VM on google cloud and ran Bayenesian Optimization multiple times for 100-150 trials searching across the following hyperparameter space: Learning Rate, Regularization, Dropout, Number of filters, kernel\_size, strides

&#x200B;

*CNN-RNN Hybrid, Dropout*

I have also tried a CNN-RNN hybrid architecture where I have 1-3 1D conv layers and 2 LSTM layers.   The idea was that the CNN layers learn to recognize small features akin to notes/chords and the LSTM layers learn to recognize sequences of those small features.

**An example of a hybrid model:**

Layer (type)                Output Shape              Param #

=================================================================

input\_1 (InputLayer)        \[(None, 431, 20)\]         0

conv1d (Conv1D)             (None, 142, 64)           9024

batch\_normalization (BatchN  (None, 142, 64)          256

ormalization)

activation (Activation)     (None, 142, 64)           0

spatial\_dropout1d (SpatialD  (None, 142, 64)          0

ropout1D)

conv1d\_1 (Conv1D)           (None, 46, 128)           41088

batch\_normalization\_1 (Batc  (None, 46, 128)          512

hNormalization)

activation\_1 (Activation)   (None, 46, 128)           0

spatial\_dropout1d\_1 (Spatia  (None, 46, 128)          0

lDropout1D)

lstm (LSTM)                 (None, 46, 40)            27040

dropout (Dropout)           (None, 46, 40)            0

batch\_normalization\_2 (Batc  (None, 46, 40)           160

hNormalization)

lstm\_1 (LSTM)               (None, 80)                38720

dropout\_1 (Dropout)         (None, 80)                0

batch\_normalization\_3 (Batc  (None, 80)               320

hNormalization)

dense (Dense)               (None, 10)                810

=================================================================

Total params: 117,930

Trainable params: 117,306

Non-trainable params: 624

&#x200B;

**The Problem**

No matter what I try, my model starts ovefitting around 70-80% test set accuracy.   The best I could get with Bayenesian optimization was around 82% test set accuracy.   The typical result is 70-75% test set accuracy.   I tried a smaller model (down to 10k parameters) and I get the same result, just a lower training set accuracy.   I can get training accuracy of 80% and test set accuracy of 75%.   But in every model, the accuracies start seriously diverging around 70% test set accuracy.   I can get 99% training accuracy and still only have 75% test set accuracy.   I don't know what else to do.   Is the problemn with the GTZAN set?  I remember reading somewhere that there were some issues with it.   Does anyone else have experience with this.   I was thinking of messing around with the LSTM layers a bit more but honestly the result is pretty much the same every time, no matter what I try.

**An example of the typical result**

&#x200B;

[Loss, example 1](https://preview.redd.it/ugivlmujugtb1.png?width=640&format=png&auto=webp&s=1a917493010d5a6b437760ed7fb8301674f6c6de)

&#x200B;

&#x200B;

[Accuracy, example1](https://preview.redd.it/swaa5xcnugtb1.png?width=640&format=png&auto=webp&s=a63a00c3d8d58703d0291b2027a738622e3f3e8e)

&#x200B;

&#x200B;

[Loss, example 2](https://preview.redd.it/o4ebnl5zugtb1.png?width=640&format=png&auto=webp&s=5ea659b5f8def2ca7d190628e2d39f96bb1e23a2)

&#x200B;

&#x200B;

[Accuracy, example 2](https://preview.redd.it/ipxy3hh1vgtb1.png?width=640&format=png&auto=webp&s=05e4b28c45928f6003f6d0000edf3872e4128e29)

&#x200B;

This is the pattern pretty much everything I try follows, unless its worse.   Any suggestions?

&#x200B;

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1750kjf/my_music_genre_classifier_keeps_overfitting/,8,7,0.9,"[Comment(id='k4fcnz9'), Comment(id='k4d9f1c'), Comment(id='k4dyg5l'), Comment(id='k4fgbgq'), Comment(id='k4df4qa'), Comment(id='k4ffc1k'), Comment(id='k4dvqkb'), Comment(id='k4feqec')]"
175bkdg,StigAre,,2023-10-11 11:16:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175bkdg/getting_the_location_of_a_dot_on_a_raster/,Getting the location of a dot on a raster,"I'm new to ML and am doing some simple projects to learn.

I want to get the coordinates of a black dot on a white background using ML. I have generated 500 50x50 such pngs and a csv file with matching coordinates. So far I have attempted reinforced learning using tensorflow. I'm using meansquarederror for loss and Adam as the optimizer. I've tried a few different layer set-ups mostly using dense layers. After training the model all the predictions end up being some coordinate very close to the center of the picture (i.e. 25,25). In some way this makes sense since that would be the best guess if the model couldn't ""see"" the raster, but it is obviously not what I want. Does anyone have an idea for what I might be doing wrong?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175bkdg/getting_the_location_of_a_dot_on_a_raster/,3,1,1.0,"[Comment(id='k4evzps'), Comment(id='k4f2mlg'), Comment(id='k4fwt69')]"
175ba4s,OnlyProggingForFun,,2023-10-11 11:00:11+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/175ba4s/we_just_released_our_llm_free_course_an_attempt/,"we just released our LLM free course, an attempt for a « zero-to-hero with LLMs » showing everything about LLMs (train, fine-tune, use RAG…) and the course is multi-modal (code, videos, article, community help...)!",,learnmachinelearning,https://youtu.be/iaYtuh5axJc,0,1,0.67,[]
175cg7z,Curious-Swim1266,,2023-10-11 12:07:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/175cg7z/we_built_an_ai_for_career_counsellor_and/,We built an AI for Career Counsellor and Psychology Support Aid,"🚀 Yesterday, on World Mental Health Day, I am thrilled to share Ivy, an AI mentor for life. 🌱

🌟 Ivy has been built by a team comprising of AI Engineers and Behavioural Scientists, with a dream of creating an AI companion that could truly make a difference in people's lives. 🤝

💼 Ivy emerged as the embodiment of our shared vision. She's not just an AI, but a friend, a mentor, and a shoulder to lean on. Ivy can be your personal Career Counsellor, offering guidance and advice on your professional journey. She can also provide Psychological First Aid, listening without judgment when life's challenges become overwhelming. 💖

🌐 Ivy is a beacon of support, available 24/7, ready to assist you on your path to personal and professional growth. She's non-judgmental, confidential, and driven by empathy, delivering responses that feel like they come from the heart. 🌟

Meet Ivy at [https://iamivy.care](https://iamivy.care). Ivy is still learning; your valuable feedback will make her better. 🌱

\#IvyAI #MentalHealthMatters #WorldMentalHealthDay #AICompanion #Collaboration #Innovation #HumanityAndTechnology",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/175cg7z/we_built_an_ai_for_career_counsellor_and/,11,0,0.33,"[Comment(id='k4f16jx'), Comment(id='k4f7g4c'), Comment(id='k4gqhtb'), Comment(id='k4f37qm'), Comment(id='k4f9316'), Comment(id='k4fjbgt'), Comment(id='k4frkrv'), Comment(id='k4fqlir'), Comment(id='k4gbgf8'), Comment(id='k4gr3yr'), Comment(id='k4hkdvn')]"
1754amu,Higginsniggins,,2023-10-11 03:18:02+00:00,False,,1697004413.0,False,True,False,/r/learnmachinelearning/comments/1754amu/multi_hot_encoding_question/,Multi Hot Encoding question,"If I understand Multi Hot encoding correctly basically we take arrays of different lengths, and turn them into arrays/lists of all the same length with each index of the new array/list being on(0) or off(1) for the various entries in the original array.

so

\[1,3\] would become \[0, 1, 0, 1\]

&#x200B;

My question is, how do we account for if a number appears twice in the original array/list,

for example \[1,3,3\]",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1754amu/multi_hot_encoding_question/,3,2,1.0,"[Comment(id='k4diwys'), Comment(id='k4dkjcs'), Comment(id='k4il6b9')]"
1754489,Enough_Wishbone7175,,2023-10-11 03:09:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1754489/embed_and_confused/,Embed and confused,"I hope y’all enjoyed the pun.

Anyways, I’m embedding time series sequences and need some guidance on how to go about doing so. Basically I have a data loader that shoots in batches of (32, 55, 12) I want separately embed the 12 features, using a Temporal Convolution Networks. I’m trying to figure out how to structure/ pad/ mask these sequences to prevent leakage. I’m also wondering if I should consider a pooling layer of sorts to help with the variable information given the variable lengths that are being observed.

Any advice and or resources would be wonderful!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1754489/embed_and_confused/,0,2,1.0,[]
1757gxv,Lemon_Salmon,,2023-10-11 06:31:29+00:00,False,,1697073775.0,False,True,False,/r/learnmachinelearning/comments/1757gxv/maths_expression_notation_for_rope_positional/,Maths expression notation for RoPE positional encoding scheme,"Could anyone derive the last line of the following RoPE positional encoding scheme ?

Note:  I am unsure of where the different `q`, `k` mixtures of `2n` and `2n+1` indexing came from for `cos()` and `sin()` respectively

https://preview.redd.it/5iudprhmbotb1.png?width=461&format=png&auto=webp&s=5c1caa77c66d6f7549cb75866766319ee32be525

https://preview.redd.it/25eo1bsfpitb1.png?width=842&format=png&auto=webp&s=af6dac2bb963f51cf15b13c54c80ab4c4733c407",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1757gxv/maths_expression_notation_for_rope_positional/,0,1,1.0,[]
174vfoe,jo-adithya,,2023-10-10 20:35:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174vfoe/math_resources_for_learning_ai/,Math resources for learning AI,"Hi there, can anyone suggest what are the important math concepts that I should be aware of when learning AI? and if possible, can you share some of the best resources here?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174vfoe/math_resources_for_learning_ai/,3,3,1.0,"[Comment(id='k4byqsa'), Comment(id='k4epgju'), Comment(id='k4bz2f9')]"
174fd24,PaulakaPaul,,2023-10-10 07:36:39+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/174fd24/learn_mle_mlops_in_a_structured_way_for_free_and/,"Learn MLE & MLOps in a structured way, for free, and with hands-on examples following ""The Full Stack 7-Steps MLOps Framework"" course. It contains 2.5 hours of reading & video materials on how to design, build, and deploy an ML system using a batch architecture and the 3-pipeline design.",,learnmachinelearning,https://github.com/iusztinpaul/energy-forecasting,2,10,0.92,"[Comment(id='k49zv0l'), Comment(id='k4ab7hj')]"
174oxxv,kalsi_sachin,,2023-10-10 16:07:33+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/174oxxv/flashattention_algorithm_and_its_utilization_of/,FlashAttention algorithm and its utilization of online normalizer calculations to reduce memory access & streamline softmax computation for better hardware performance,,learnmachinelearning,https://youtu.be/lpBJHUU4w6k,0,2,1.0,[]
174u0ud,Financial_Muffin396,,2023-10-10 19:38:16+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/174u0ud/unlimited_karma_setting_ai_agents_free_in_the/,Unlimited Karma: Setting AI Agents Free in the Reddit jungle,,learnmachinelearning,https://open.substack.com/pub/nikitakutz/p/unlimited-karma-setting-ai-agents?r=bxjdh&utm_campaign=post&utm_medium=web,0,1,1.0,[]
174iklx,Botanical0149,,2023-10-10 11:13:08+00:00,False,,1696939887.0,False,True,False,/r/learnmachinelearning/comments/174iklx/text_classification_rnn_train_loss_is_decreasing/,"Text classification RNN. Train loss is decreasing, but (train) accuracy stays around 0.36","What may I be doing wrong? The code:

    data = pd.read_csv('data.csv')
    data = data.sample(frac=1)
    
    q = round(len(data['Text'])/4)
    texts = data['Text']
    X_test = texts[0:q]
    Y_test = data['Suicidal'][0:q]
    X_train = texts[q:4q]
    Y_train = data['Suicidal'][q:4q]
    
    tk = Tokenizer()
    tk.fit_on_texts(X_train)
    vocabulary_size = len(tk.index_word)
    
    sequences_train = tk.texts_to_sequences(X_train)
    padded_train = pad_sequences(sequences_train, maxlen=1000, truncating='pre')
    sequences_test = tk.texts_to_sequences(X_test)
    padded_test = pad_sequences(sequences_test, maxlen=1000, truncating='pre')
    
    model = Sequential()
    model.add(Embedding(input_dim=vocabulary_size+1, output_dim=100, input_length=1000))
    model.add(SimpleRNN(32))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(1, activation='softmax'))
    
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    epochs = 20
    history = model.fit(padded_train, Y_train, validation_data=(padded_test, Y_test), epochs=epochs)
    
    historyValLos = history.history['val_loss']
    historyValAcc = history.history['val_accuracy']
    score = model.evaluate(padded_test, Y_test)

(tried to translate code to English, so there might be some typoes in variable names)

I want to binary classify text data. The simple MLP NN (e.g. 500, 500, 100, 1 neurons in a layer) is giving decent results: around 0.96 validation accuracy, but I'm trying to make it better.

I've added the 100 neurons dense layer recently, but it didn't help. Changed learning rate in optimizer and it didn't help either.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174iklx/text_classification_rnn_train_loss_is_decreasing/,6,4,1.0,"[Comment(id='k49xh0t'), Comment(id='k4aa12j'), Comment(id='k4afpud'), Comment(id='k4ad1jq'), Comment(id='k4am024'), Comment(id='k4ap0gp')]"
174zv7j,Science-man777,,2023-10-10 23:45:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174zv7j/ultimate_ai_art_generator_tools/,Ultimate AI Art Generator Tools," ""Have you ever wanted to be an artist?  There was a time in my life when I would pace the art supply aisle and promise myself that I would one day take up painting.  I had so many ideas I wanted to bring to life with palette and brush, but alas, life’s demands robbed me of the time it would have taken, and I moved on to college to find my fortune. 

Fast forward over twenty years, and we now have artificial  intelligence (AI) art generators that have the power to convert simple text prompts into beautiful images. These programs can output in many different styles and in stunning realism, color, and resolution.  We can leave the art critics to debate if this is real art, but for us creative people who have always wanted to paint but never had the chance, this may be the technological windfall we have been waiting for.""

[https://ai-solutions.pro/review-of-best-ai-art-generators/](https://ai-solutions.pro/review-of-best-ai-art-generators/)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174zv7j/ultimate_ai_art_generator_tools/,1,0,0.2,[Comment(id='k4dakg9')]
174kyaa,Unusual_Language8690,,2023-10-10 13:16:38+00:00,False,,1696968529.0,False,True,False,/r/learnmachinelearning/comments/174kyaa/has_anyone_tried_to_determine_a_value_for_time_t/,"Has anyone tried to determine a value for time t based on variables at time t and their associated time series, i.e. values at time t-1, t-2, and so on? With Transformers or other Deep Learning architectures","I want to determine a value for time t based on variables at time t and their associated time series, i.e. values at time t-1, t-2, and so on.

So for example:   I have a dataset with 4 columns which store values for certain sensors (e.g. A,B,C,D). Additionally I have a datetime column. I want that my model predicts the value for sensor A at time t by only looking at Sensor B, C, D time series, so time t, t-1, t-2, t-3 ... .  In general when I test my Model I have an input of size \[sequence length, variables (without target)\] and my output is my target variable, so one value \[1\] 

I want to implement the whole thing with a transformer. For training I have the information of the target variable of course, but I don't want this information to influence the weights of the model, but only based on the other relevant columns.

Does anyone know of a framework, paper etc. who has done this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174kyaa/has_anyone_tried_to_determine_a_value_for_time_t/,0,2,1.0,[]
174pfkf,tdionis,,2023-10-10 16:27:38+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/174pfkf/what_is_sliding_window_in_object_detection/,What is Sliding Window in Object Detection: Complete Overview of Methods & Tools - Supervisely,,learnmachinelearning,https://supervisely.com/blog/how-sliding-window-improves-neural-network-models/,0,0,0.5,[]
1743xhj,Ok-Instruction-8624,,2023-10-09 21:43:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1743xhj/how_feasible_is_it_to_train_ai_on_an_existing/,How feasible is it to train AI on an existing game? Or is there a basis for training AI on an existing game?,"I'm an undergrad student but have very little experience with machine learning. I'm fond of online fighting games, but noticed that many smaller games do not have AI/singleplayer modes. Some are open source, so I was wondering if I could mod one to set up an environment to try training AI. It's more for fun than something realistic. A long time ago, I set one up with an AI that would only do random moves, but did not get much farther before life made me take a break. I still have the code and my notes about getting specific data/triggering moves/how the game works. It would be the ideal one to start with, and is a smaller 2d fighting game with very simple graphics. However, I want to make sure its even feasible before attempting to create a machine learning environment.

My main worry is that using an existing game to train would be too resource intensive or would take too much time due to game code generally being complicated compared to other tasks. While I know it varies based on game specs/computer specs, I was curious if there was any basis for people using a game to train AI without building the game from the ground up. Are there any good guidelines I could check to see if a game is simple enough for training, or am I almost always better off recreating a game from the ground up to reduce resource use? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1743xhj/how_feasible_is_it_to_train_ai_on_an_existing/,16,29,0.92,"[Comment(id='k475d72'), Comment(id='k48jlu8'), Comment(id='k479wb4'), Comment(id='k47pjzp'), Comment(id='k48uabw'), Comment(id='k4cu900'), Comment(id='k492iix'), Comment(id='k4av2m8'), Comment(id='k4dk2mt'), Comment(id='k48qmrb'), Comment(id='k49ouuw'), Comment(id='k49q68g'), Comment(id='k49sgw6'), Comment(id='k493gvv'), Comment(id='k4bq22e'), Comment(id='k495ldp')]"
174oafl,100GB-CSV,,2023-10-10 15:40:03+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/174oafl/use_python_to_replicate_billionrow_csv_file/,Use Python to Replicate Billion-Row CSV File,,learnmachinelearning,https://youtu.be/eXwqamjWbjU,0,0,0.33,[]
174lxom,Optimistic_Honeypot,,2023-10-10 13:58:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174lxom/would_there_be_someone_kind_enough_to_explain/,Would there be someone kind enough to explain this model in simple terms?,"Hi everyone,

I am a beginner to natural language processing theory and I am trying to understand this model from ""K2Q: Generating Natural Language Questions from Keywords with User Refinements"" research paper ([https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37566.pdf](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37566.pdf)).

This model should explain how questions can be generated from user intent and matched to a searched term/query.

I was wondering if there is someone who would be kind enough to explain the process in layman terms or add examples to the letters on the model.

&#x200B;

https://preview.redd.it/cf1kwpclsdtb1.png?width=715&format=png&auto=webp&s=e4fdf5ef74738928b4418e453b8fc296da9cd1d9

https://preview.redd.it/cp5i6j9msdtb1.png?width=684&format=png&auto=webp&s=f868e0a6f069335f91d7de2e8e877ac73d32cb14

https://preview.redd.it/gn72zhansdtb1.png?width=655&format=png&auto=webp&s=2347257c9df15204df7c30b0452134c0d1dfea61

https://preview.redd.it/qc9t4u8osdtb1.png?width=647&format=png&auto=webp&s=9a8f8b88831bd2b0cd1c55ebd3b0123058ef0ee3",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174lxom/would_there_be_someone_kind_enough_to_explain/,1,0,0.5,[]
174llak,monty_field,,2023-10-10 13:43:44+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174llak/metric_scoring_question/,Metric / scoring question,"Wondering if anyone has some insights for this data; I have a dataset of multiple timeseries of the supply of rental bikes (multiple relates to multiple locations). I have two main questions:

1. There is a timeseries per location (lets say about 100 locations with 30-1200 bikes). Generally locations have similar behaviour, e.g. daily commuter patterns, where tuesday and thursday are the most busy, while the weekend usually has a higher supply (people are not working). On the other hand, different features are applicable to different locations. e.g. some locations are very much going-out locations, where the bikes are all sold out during the weekend. Would there be a simple way to incorporate all locations in one model, and predict for each, lets say a day or so ahead?

2. I am most interested in optimizing the predictions to do well for predicting low supply (let's say 0-25 bikes), and it doesn't really matter for higher supply. How would you approach this? For now I've just inspected the MAE on a slice of the data where there's 0-25 bikes, but is there a better metric? Perhaps there's a way to create a custom loss function to optimize this? I've read about the RMSLE, but that does the exact opposite; penalize underestimation.

Thank you",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174llak/metric_scoring_question/,0,1,1.0,[]
174fg5w,KingAbK,,2023-10-10 07:42:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174fg5w/running_prompts_on_custom_data/,Running prompts on custom data,"Hey everyone. I am noob trying to learn LLMs. 

I have a text file with some unstructured data. There are no any column or rows, just strings.

I want gpt to use this information and answer my prompts by only using that data.

And answer should not be in like 1 or 2 lines. I want very long format structured answer as instructed in my prompt. 

I researched and understood that langchain can help with it. But is there any other alternative because I was not satisfied with the output or maybe I am doing something wrong. 

Can someone tell me which is the best LLM for this and how to achieve this?

Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174fg5w/running_prompts_on_custom_data/,0,3,1.0,[]
174kwvx,AndrewKorsten,,2023-10-10 13:14:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174kwvx/i_need_to_estimate_the_time_that_itll_take_to/,I need to estimate the time that it'll take to cover the basic math course so that I can move into the basics of ML. Can you help me please?," 

**\*\*\* Global Inputs \*\*\***

1) I am adult learner. 37 y.o. Content writer and professional English tutor.

2) I am pivoting completely into ""Sales/Marketing in ML/AI/AI-tech/AI-SaaS/AI-dev-agencies"".

3) I don't understand completely what ""Sales/Marketing in ML/AI/AI-tech/AI-SaaS/AI-dev-agencies"" means, but it means the following:

a. **I want completely pivot into the AI-driven tech** \- that's for sure. I see a lot of potential there, and I can see that I'll be able to gradually move into sales and start making the good money (the good money for me is 2K/mo, coz I am located in Kurplastan, but I want to move Bankok in 12 months; I am originally a russky).

b. **I am learning Python -** doing a basic course. It's going well. I have the core insights into HTML, CSS, JS, React, rest api, node, etc.

c. **I am not planning to become an actual ML Engineer -** but I want to move into sales/marketing in AI tech.

d. **I am not fixated on AI either** \- whenever I start making mone, I'm going to start pushing the surplus into ecommerce (there's a lot of opportunities to make money there, folks; don't look down on that; you can be making a lot of money there if you are learning and act strategically!)

4) I had huge problems with math and other STEM subjects in school - I wasn't getting them, and I was passing by them.

**\*\*\* Question Inputs \*\*\***

1) I decided that I would start the pivot 5 days ago, and THEN I started googling around what ML actuall is. I had a vague understanding that there's some math in it, but I decided to go blind... Now, I am understanding that I need to understand the basics of math.

2) I freaked out big time, I am almost started smoking after 7 years of not smoking...

3) Then I said to myself - Idk, I am not going anywhere, and I started doing this course - [https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34](https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34). (If you are looking for a good introduction math course, most of the people who I talk to always say that this is an amazing course. Really. I am at lesson 33 and I am loving every second of it.)

**\*\*\* Question \*\*\***

**1) Huge speed reduction at Lesson 34**: Now I am at Lesson 34 - [https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34](https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34). I watched the video today, didn't understand anything at all, as it turns out. Then I was presented with this compherension check - [https://imgsh.net/a/eKp1MAa.png](https://imgsh.net/a/eKp1MAa.png). I realized that I don't even understand what is wanted from me. I got super frustrated, but not desparate or fleeing. Then I realized that I don't understand what is wanted from me, so I started googling the concept of ""factoring the quadratics"". Importantly, I started GPTing and Gooling the ""why"". I know... This is a very important point for me - I always need to understand the ""why"" behind a tool. I learned that it would be easier for charting in linalg. OK! This was the answer. Then, i realized that I actualy didn't understand the lesson, so I found this article - [https://www.mashupmath.com/blog/how-to-factor-polynomials](https://www.mashupmath.com/blog/how-to-factor-polynomials). I read it end to end, understood everything, practiced every task 3 times and I do really understand how to fator the quadractics by now!

**2) Speed reduction is a normal thing**: So, prior to lesson 34, I was doing like 7 lessons per day. This was a good lesson - [https://www.youtube.com/watch?v=3-5DKCLJspM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=13](https://www.youtube.com/watch?v=3-5DKCLJspM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=13). I really liked it :) I can see that the speed reduction is occurring because of the complexity increase. It's not occurring because I am lost and disoriented - I remember how that felt in school, when you see a bunch of numbers on the blackboard and have no freaking idea what's going on there. I am just hitting up my best friend GPT and ask, ask, ask, ask stupid questions. Thus, I can see that the speed reduction is a normal right, right?

**3) Wha's the optimal speed correction here**: So, I am allocating 7h/d during the daytime shift when I am in the prime state toward this project. And I don't even have to learn Python at all because Python is easy, but I do plan to keep learning PYthon with 3 sessions each for 30 minutes so that I don't just do math. (And I run English lessons in the evenings so that I can keep on making money).

**The actual question**

I am thinking that I should go down from the goal of 7 lessons per day down to 3 lessons per day, right? If I do this, then I'm going to end up with the forecast delivery period of 43 days, right?

And the information that I provided above was kinda like an explanatory note that I am trying to become a real ML engineer, but I want to graudally slide into sales and marketing so that I can TOO Make a lot of money, uknow.

What do you think about the speed reduction down to 3 lessons per day?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174kwvx/i_need_to_estimate_the_time_that_itll_take_to/,23,0,0.4,"[Comment(id='k49yj65'), Comment(id='k4a87wy'), Comment(id='k4a016n'), Comment(id='k4baj37'), Comment(id='k4c6wtt'), Comment(id='k4bhrcw'), Comment(id='k4bil8d'), Comment(id='k4aoqy0'), Comment(id='k4awppj'), Comment(id='k4bhv05'), Comment(id='k4bf9jx'), Comment(id='k4e8fcc'), Comment(id='k4btrmy'), Comment(id='k4biyxz'), Comment(id='k4bhpev'), Comment(id='k4bikac'), Comment(id='k4emp3d'), Comment(id='k4e87f8'), Comment(id='k4d8zo3'), Comment(id='k4et25w'), Comment(id='k4etegd'), Comment(id='k4ecmac'), Comment(id='k4fp1m1')]"
174kr1g,TheSaasDev,,2023-10-10 13:07:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174kr1g/is_there_a_rest_api_for_text_embeddings/,Is there a REST API for text embeddings?,"I'm aware there are commercial offerings like OpenAI and cohere with the embedding API. But what about for open source models like the ones from SentenceTransformers?

I'm aware you can use the HuggingFace inference API, but it's probably not best for commercial use, in which case the Inference endpoints would be better, but it's quite pricey for a startup with no customers.

I also know I could use some kind of serverless GPU / inference platform to create my own API.

But is there just a straight-up REST API for getting text embeddings from a model via SentenceTransformers or other HuggingFace models?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174kr1g/is_there_a_rest_api_for_text_embeddings/,2,1,1.0,"[Comment(id='k4p7362'), Comment(id='k5qrtup')]"
174k48c,synthphreak,,2023-10-10 12:37:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174k48c/seeking_learning_resources_that_go_deep_into_nlp/,Seeking learning resources that go deep into NLP foundations and which target advanced-intermediate technical learners,"# TL;DR:

Semi-experienced MLE seeking to deepen my knowledge of the modeling side of NLP. Can you recommend any courses or other resources to pursue for this?

Ideally I'd like resources which target advanced-intermediate practitioners and which spend only minimal time on theoretical linguistics concepts (e.g., ""What is syntax?""; ""What is a morpheme?""; ""What is distributional semantics?"" - Less because that stuff is unimportant, and more because I already know it inside and out.)

------------

# My brief background

Theoretical linguistics grad here. Several years ago and many years out of school, I set off to STEM-up and become a machine learning engineer (MLE) in NLP. I spent a few years hardcore self-studying math, programming, ML/DL, and NLP. In the end I succeeded, learning *just* enough to get hired as an NLP MLE using only web-based resources and a few PDFs.

I've been in the role for 3-4 years now, and in the interim I have learned a TON of practical skills about SWE and DevOps that I hadn't learned while self-studying the theory. However, my knowledge of ML/DL/NLP theory hasn't actually grown much. This is mostly because where I work, the modeling is left to PhD'ed researchers, not as much the engineers, and not at all the junior engineers like me. So I'd like to get back into learning that side of things.

Because I prioritized breadth over depth during that initial self-study period, I'm passingly familiar with a fair number of NLP tasks and techniques. But I am a master of none. So on this second pass, because now I know the basics and can ""speak the lingo"", I'd like to go deep, especially on the foundations on NLP.

# What I'm hoping to get from this post

***With this background, can anyone recommend (ideally) courses, books, blogs, or other resources for learning things such as the following?

- foundational NLP tasks (e.g., POS-tagging, dependency parsing, NER, sentiment analysis, summarization) and associated popular models/approaches
- probability theory for NLP
- traditional/non-deep NLP
- sequence classification
- clustering/unsupervised methods for NLP
- multitask learning in NLP***

# Why? ""Who cares?""

At this point, someone may ask:

> You've already ""made it"" as an MLE, and modeling clearly is not required. So who cares?

I would retort that as one advances from junior to mid to senior and beyond, ""hey I can write great code"" should gradually take a backseat to ""hey I can make informed decisions about what data and models to pursue given the goals and constraints of a specific business case.""

I really want to be able to reason about and make pragmatic arguments like ""Well, business case A can be re-conceptualized as a kind of question-answering task (random example), therefore it would be reasonable to start with model B and optimize a cost function C with optimizer D. For that, we'd want to collect at least E examples of data type F, and run some model experiments on G cloud resource, ..."" Etc. etc etc. Right now I could *follow along* if a senior engineer came up with such an argument, then probably execute the work mostly on my own. But I would struggle to come up with and then stand behind the argument myself.

I recently had my first technical interviews (for senior level), and while I did well in the coding rounds, I really felt my deficiencies when answering ""What would you do in scenario X, and why?"" type questions and talking about the nitty gritty of model architectures. My responses were often just like ""Um, I'd throw a transformer model at it"", in part because that's 90% of what we do where I work, but also because I lack experience which makes me tend towards ""when all you have is a hammer everything looks like a nail"" style thinking. Hence, this post.

Anyway, enough ramble. I really look forward to any suggestions I receive. Thanks in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174k48c/seeking_learning_resources_that_go_deep_into_nlp/,0,1,1.0,[]
174jtlk,Natural_Yam_4777,,2023-10-10 12:22:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174jtlk/semisupervised_learning_for_linear_regression/,Semi-supervised learning for linear regression,"Hi All,

I have a large dataset of samples where only about 2% have a label. These labels, however, are not classifiable like the common examples for semi-supervised learning but are a float value between about 1 and 6.

I have searched online already, but have found no examples of semi-supervised learning applied to such a problem.

Am I correct to assume this is not easily possible, or am I missing something?

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174jtlk/semisupervised_learning_for_linear_regression/,2,1,1.0,"[Comment(id='k49nbab'), Comment(id='k49o7l6')]"
173pvsv,Altruistic_Gift4997,,2023-10-09 11:54:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173pvsv/where_do_you_get_your_ai_news/,Where Do You Get Your AI News?,"Guys, I'm looking for the best spots to get the latest updates and news in the field. What websites, blogs, or other sources do you guys follow to stay on top of the AI game?  
Give me your go-to sources, whether it's some cool YouTube channel, a Twitter(X xd) account, or just a blog that's always dropping fresh AI knowledge. I'm open to anything – the more diverse, the better!

Thanks a lot! 😍",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173pvsv/where_do_you_get_your_ai_news/,45,87,0.97,"[Comment(id='k466rhj'), Comment(id='k44s4dq'), Comment(id='k462xgc'), Comment(id='k45ippn'), Comment(id='k45903p'), Comment(id='k46vz7n'), Comment(id='k491snb'), Comment(id='k45elh4'), Comment(id='k45ziyl'), Comment(id='k48roac'), Comment(id='k499tyq'), Comment(id='k44b8qp'), Comment(id='k46gg6f'), Comment(id='k48qo5l'), Comment(id='k46u8oq'), Comment(id='k46xkmr'), Comment(id='k47ejqa'), Comment(id='k47gqjk'), Comment(id='k45d6n9'), Comment(id='k45zsrj'), Comment(id='k46nmg4'), Comment(id='k47h9mt'), Comment(id='k47i53o'), Comment(id='k47re74'), Comment(id='k48ccdr'), Comment(id='k48ockv'), Comment(id='k49780d'), Comment(id='k4chjdp'), Comment(id='k4mzn6q'), Comment(id='k4f1fb9'), Comment(id='k483ts9'), Comment(id='k48haus'), Comment(id='k462gvl'), Comment(id='k46toye'), Comment(id='k45935g'), Comment(id='k45eoid'), Comment(id='k462nty'), Comment(id='k4l6t9e'), Comment(id='k46ttl9'), Comment(id='k4o6c84'), Comment(id='k49lnnd'), Comment(id='k48qmfr'), Comment(id='k463107'), Comment(id='k4v46wu'), Comment(id='k49u5k9')]"
174jk0z,eeriek,,2023-10-10 12:08:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174jk0z/can_i_see_which_value_of_n_did_ngram_in_tfidf/,Can I see which value of n did ngram in TF-IDF vectorizer use?,"I've used TF-IDF Vectorizer (from Scikit-Learn), like so:

    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3)) 
X = tfidf_vectorizer.fit_transform(data['Text'])
y = data['Y']

Then used cross validation:

    cross_validate(modelRandomForestC, X, y, cv=4,\
 scoring=['accuracy', 'balanced_accuracy', 'average_precision', 'f1'])

How can I know what value of n (in ngrams) did TF-IDF use? Was it 1-gram, 2-gram or 3-gram? Or did it use a combination of these? If so: how does it work?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174jk0z/can_i_see_which_value_of_n_did_ngram_in_tfidf/,0,1,1.0,[]
174nwvp,thumbsdrivesmecrazy,,2023-10-10 15:24:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174nwvp/nocode_machine_learning_guide/,No-Code Machine Learning - Guide,"The guide below explores what you need to know about no-code machine learning and how to use it in your company - thanks to no-code platforms like Blaze, this technology is available to many businesses: [Guide to No-Code Machine Learning (AI) | Blaze](https://www.blaze.tech/post/guide-to-no-code-machine-learning-ai-blaze)

No-code AI  makes it possible for users to test out different AI models and see the results of their work in real-time.  It also scraps the need for conventional methods of AI enables users to experiment with machine learning without having to worry about a steep learning curve. This means that users can focus on exploring and developing new AI models quickly. In the past, users needed to worry about the underlying code.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174nwvp/nocode_machine_learning_guide/,0,0,0.25,[]
174gyox,sneaky2040,,2023-10-10 09:31:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174gyox/how_to_pivot_into_ml/,How to pivot into ML,"Hey everyone. 

I’m 22 years old and would like to get a career in machine learning. 

I want to be prominent in the field and the road is long - I’m self studying and working on minor project on my own. 

That is not sufficient as I want a deeper understanding and I’m eager to learn more. 

Thinking of applying to some universities and my options are: 

Bachelor in programming —> master in ML 

Bachelor in data science —> master in ML 

Bachelor in artificial intelligence —> master in ML 

I will continue working on ML project when I’m taking a bachelor and hopefully I can land a job in that field after bachelor. 

Which bachelor option do you recommends as someone who is completely “new” to the world of technology and coding? 

I can understand that data science is a very relevant field but also programming as I will learn how to code and build systems. 

Choices… choices..",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174gyox/how_to_pivot_into_ml/,5,1,0.6,"[Comment(id='k49x12s'), Comment(id='k49n7as'), Comment(id='k4ccpux'), Comment(id='k4d5393'), Comment(id='k5eakgy')]"
174a6gw,Ashamed_Painting1904,,2023-10-10 02:25:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/174a6gw/can_anyone_provide_me_machine_learning_source_for/,Can anyone provide me machine learning source for a intermediate learner .,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/174a6gw/can_anyone_provide_me_machine_learning_source_for/,1,3,1.0,[Comment(id='k49nru6')]
1743r32,Individual_Ad_1214,,2023-10-09 21:36:00+00:00,False,,1696887681.0,False,True,False,/r/learnmachinelearning/comments/1743r32/recursive_feature_elimination_using_multioutput/,Recursive Feature Elimination using MultiOutput Estimator,"I am trying to undertake recursive feature elimination using a multiouput model. I included a minimum reproducible example below:

    from sklearn.multioutput import MultiOutputClassifier
    import numpy as np 
    import pandas as pd 
    from catboost import CatBoostClassifier 
    from sklearn.pipeline import Pipeline, make_pipeline 
    from sklearn.metrics import accuracy_score, make_scorer 
    from sklearn.preprocessing import StandardScaler 
    from sklearn.feature_selection import RFECV 
    from sklearn.model_selection import cross_validate
    
    data = {""salary"": [60000, 50000, 10000, 94000, 34000, 70000], ""age"": [23, 27, 13, 45, 60, 70], ""weight"": [80, 90, 50, 75, 60, 70], ""height"": [90, 100, 70, 60, 50, 70], }
    
    df = pd.DataFrame(data=data) 
    
    y = np.asarray([[1, 0, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 1]])
    
    model = MultiOutputClassifier(CatBoostClassifier(verbose=0)) 
    
    pipe = Pipeline(steps = [(""preprocessor"", StandardScaler()), (""estimator"", model)])
    
    rfe_cv_pipe = make_pipeline(StandardScaler(), RFECV(estimator=model, scoring=make_scorer(accuracy_score), min_features_to_select=2, importance_getter=""estimator.feature_importances_"", cv=2))
    
    scores = cross_validate(pipe, df, y, cv=2, return_train_score=True) 
    
    rfe_cv_pipe.fit(df, y)

I am able to get training and validation scores by applying the cross\_validate function on the pipe and on my dataframe and target, however when I call the fit method using the rfe\_cv\_pipe object, I get an **input contains NaN, infinity, or a value too large for dtype('float64')** and I can't figure out what I'm doing wrong here. 

&#x200B;

Any help will be much appreciated thanks!!!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1743r32/recursive_feature_elimination_using_multioutput/,1,6,1.0,[Comment(id='k48wm4k')]
1744mxy,Competitive_Pin_5580,,2023-10-09 22:12:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1744mxy/how_to_implement_research_papers/,How to implement research papers?,"So I've done multiple projects and now I've begun reading some research papers mostly related to Deep Learning(CNN and CV papers interest me).

Now I wanna try implementing them but need some help with the know hows. Some papers tag their code and dataset on github which makes things easier but most don't. Also, the ones that do have code publicly available, I do not understand how to navigate the repository.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1744mxy/how_to_implement_research_papers/,1,3,0.72,[Comment(id='k49hqum')]
1748jby,Longjumping_Ad_7053,,2023-10-10 01:06:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1748jby/data_analyst/,Data analyst,I know data scientist and data analyst are getting mis profiled but do I need deep learning knowledge and tensorflow for data analyst jobs or scikit learn with sql and power bi are enough normally. For an intern position tho,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1748jby/data_analyst/,4,2,0.75,"[Comment(id='k47snb9'), Comment(id='k47qvy1'), Comment(id='k48mmyk'), Comment(id='k4a6nlo')]"
174lahd,mngrwl,,2023-10-10 13:31:04+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/174lahd/explained_simply_openais_breakthrough_paper_about/,Explained Simply: OpenAI's breakthrough paper about defeating Dota2 world champions!,,learnmachinelearning,https://mngrwl.medium.com/explained-simply-how-a-i-defeated-world-champions-in-the-game-of-dota-2-f3df90d38a70,9,0,0.38,"[Comment(id='k4a7cyi'), Comment(id='k4b1vg4'), Comment(id='k4d777k'), Comment(id='k4jc1uk'), Comment(id='k4nn8x7'), Comment(id='k4ozqv6'), Comment(id='k4pcga2'), Comment(id='k4ujc3k'), Comment(id='k4yu64n')]"
173zv61,ChonkyMawnke420,,2023-10-09 18:58:08+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173zv61/replicating_pyschiatric_disorder_classification/,Replicating Pyschiatric Disorder Classification,"Hello, I’m a high schooler getting into machine learning, and I need a little bit of help reproducing this project meant for an HPC on a Macbook Air M1.

I’m currently trying to replicate a project from Brainhack School, and it involves a .sh preprocessing file that using fmriprep, which I’m having trouble running since it uses a singularity, something that I learned was meant for an HPC. I’m trying to run this on Pycharm, and does anyone have any workarounds for this? Here’s the link to the github repo:

https://github.com/brainhack-school2022/brotherwood_project

Thank y’all for your time.",learnmachinelearning,https://www.reddit.com/gallery/173zv61,1,4,0.84,[Comment(id='k463dq2')]
173zuar,Inspector091,,2023-10-09 18:57:08+00:00,False,,1696878174.0,False,True,False,/r/learnmachinelearning/comments/173zuar/easiest_way_to_train_an_image_generator/,Easiest way to train an image generator?,"I’m starting to learn about deep learning. My first goal is to be able to give some image examples and make an AI to generate from a prompt an image with the style and elements of the, let’s say, 100 images i provide for training. Is this possible and if so, what would be the easiest way to achieve it?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173zuar/easiest_way_to_train_an_image_generator/,2,4,1.0,"[Comment(id='k46hbvd'), Comment(id='k47e1fj')]"
17457br,UnluckyProcedure3917,,2023-10-09 22:36:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17457br/university_project_help_needed/,University project - HELP needed,"Hi. I have to fine tune BERT for a university project. The task is to decide if it is a human written text, or AI generated. I got dataset with 40.000 text rows and labels. It’s binary, 0 (human) or 1 (generated), approximately 50%-50% of both label in the dataset. I tried to do it myself, but the best accuracy were 50%, and usually the model predicts only 0 or only 1. I couldn’t do it better after a lot of hours of trying. I hope you guys have some advice for me, or describe in a few points how I should do it. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17457br/university_project_help_needed/,1,2,1.0,[Comment(id='k4frqsd')]
173qtk3,techhgal,,2023-10-09 12:41:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173qtk3/how_do_i_start_learning_ml_as_a_beginner/,How do I start learning ML as a beginner?,"I have taken the Python for Data Science, AI and Development course by IBM on Coursera. (I didn't have any prior knowledge of python so took the course). What should my next course be? I was looking at Machine Learning with Python (by IBM) but it has Data Analysis and Data Visualisation using Python courses as prerequisites. All these courses are a part of IBM Data Science professional certificate. Should I start these courses or something else?

Also, would you recommend DeepLearning.ai Machine Learning specialization to a complete beginner in ML? I'm a second year engineering student and have decent math knowledge. 

What are some beginner-friendly courses that can teach me ML concepts, math used for those concepts as well as some programming/projects? 

Lastly what books should I read? A lot of people said An introduction to statical learning & Deep Learning. Can I start with Deep Learning book or will it be too much for me? 

I want to learn core concepts to have a strong foundation as well as do some projects/courses. 

Please advice. TIA",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173qtk3/how_do_i_start_learning_ml_as_a_beginner/,11,9,1.0,"[Comment(id='k44jfje'), Comment(id='k46b3he'), Comment(id='k49o23q'), Comment(id='k46b6zo'), Comment(id='k49qigz'), Comment(id='k49qgeh'), Comment(id='k48f9ov'), Comment(id='k49qdk7'), Comment(id='k49sjmt'), Comment(id='k49y928')]"
1746sgm,Lakshmireddys,,2023-10-09 23:46:17+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1746sgm/best_machine_learning_courses_on_coursera_you/,Best Machine learning Courses on Coursera you Must Know,,learnmachinelearning,https://codingvidya.com/best-machine-learning-courses-on-coursera/,0,0,0.33,[]
173z3ze,Didlex,,2023-10-09 18:27:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173z3ze/understanding_tfdataexperimentalmake_csv_dataset/,Understanding tf.data.experimental.make_csv_dataset To Window for Timeseries data,"I am struggling with windowing a tf.data.Dataset generated from tf.data.experimental.make\_csv\_dataset() from a csv dataset. It seems something along the road here is not working. After loading the dataset and looping the batch, label, and then key and value work great. All the values are there in batches of 2 (just 2 to easily see what is going on for now) and shown for all features. But once I window the data, and print(item) at the end there, it turns into a tensor with shape (300, 2) of 1's and 0's which are my labels it seems. It is clear it is the window and batch size as the shapes with the labels as the data which confuses me to no end.

If someone could help me understand what is going on here that would be great! Some pointers on anything else would be amazing too! I am still learning the Tensorflow API and I am ***slightly*** lost.  


P.S. Feel free to ask questions!

Code:

    import tensorflow as tf
    
    
    class Data:
        def __init__(self, data_path, column_names shuffle=False, window_size=300, shift=1):
            # self.data_ds = tf.data.Dataset.list_files(dirr, shuffle=shuffle)
            self.data_ds = tf.data.experimental.make_csv_dataset(
                data_path,
                batch_size=2,
                column_names=column_names,
                label_name=column_names[-1],
                shuffle=shuffle,
                num_epochs=1
            )
    
            self.window_size = window_size
            self.shift = shift
    
            for batch, label in self.data_ds.take(1):
                for key, value in batch.items():
                    print(f""""""{key:20s}: {value}"""""")
    
                print(f""""""{'label':20s}: {label}"""""")
    
            print(self.data_ds)
    
            # ordereddict_data, tensorspec_data = self.data_ds.element_spec
    
            print(self.data_ds)
    
        def window_data(self):
            window_size = self.window_size
            self.data_ds = self.data_ds.window(size=window_size, shift=self.shift, drop_remainder=True).flat_map(lambda self, x: x.batch(window_size, drop_remainder=True))
    
        def normalization(self):
            pass
    
        def normalize_data(self):
            self.data_ds.map(self.normalization())
    
    data = Data('TData/train.csv')
    data.window_data()
    # data.normalize_data()
    
    for item in data.data_ds.take(1):
        print(item)

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173z3ze/understanding_tfdataexperimentalmake_csv_dataset/,0,2,1.0,[]
173dolk,Emotional_Agent9370,,2023-10-08 23:48:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173dolk/high_school_student_that_is_genuinely_interested/,High School Student that is Genuinely interested in ML but doesn't Know where to start,"I've recently digging into some careers that I'd potentially want to get into upon graduating high school and college, And I stumbled across ML. I've been doing research, but as a high schooler it seems like most of the skills necessary are kind of out of my reach. Are their any courses that are extremely basic or just fundamental skills that i should be learning in like excel or SQL before I attempt to really dive into ML?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173dolk/high_school_student_that_is_genuinely_interested/,52,55,0.86,"[Comment(id='k42ciyn'), Comment(id='k43681c'), Comment(id='k430oi6'), Comment(id='k42alml'), Comment(id='k42kqli'), Comment(id='k43fzve'), Comment(id='k42ckn5'), Comment(id='k42j4il'), Comment(id='k42lsi8'), Comment(id='k47hm6c'), Comment(id='k43776w'), Comment(id='k43i66j'), Comment(id='k43qpy8'), Comment(id='k43rihe'), Comment(id='k43tmam'), Comment(id='k43u0we'), Comment(id='k43u26e'), Comment(id='k4499nx'), Comment(id='k4499ug'), Comment(id='k44b1do'), Comment(id='k44d2x2'), Comment(id='k44h2ck'), Comment(id='k44hugv'), Comment(id='k44ur8b'), Comment(id='k44w8mu'), Comment(id='k454lsa'), Comment(id='k45ck4u'), Comment(id='k45g47r'), Comment(id='k49mg6m'), Comment(id='k4abb6k'), Comment(id='k4d680v'), Comment(id='k42gnt6'), Comment(id='k45162i'), Comment(id='k437iir'), Comment(id='k43eq4k'), Comment(id='k43p8xz'), Comment(id='k49tlex'), Comment(id='k43btuq'), Comment(id='k42fryo'), Comment(id='k430lki'), Comment(id='k43y70p'), Comment(id='k43ayl5'), Comment(id='k441d29'), Comment(id='k4443xw'), Comment(id='k46r91e'), Comment(id='k4eatzr'), Comment(id='k453zxh'), Comment(id='k445alp'), Comment(id='k42hapn'), Comment(id='k459k0n'), Comment(id='k444re8'), Comment(id='k43th47')]"
173uhv8,Unhappy_Resident9595,,2023-10-09 15:21:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173uhv8/builduing_a_mltc_model/,Builduing a MLTC Model,"For my bachelor thesis I am building a multi-label text classification model. I am quite new to the field and am learning everything as I write about it. It all works quite well, only the implementation seems to be quite a hurdle, especially since I'm following current SOTA papers and I haven't found any with source code. So my question is do you have any tips, videos/tutorials, courses etc that you can recommend for tackling this issue. I would be willing to spend money as long as it really helps me to implement such a model.

Thank you!!!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173uhv8/builduing_a_mltc_model/,0,3,1.0,[]
173xixl,sschepis,,2023-10-09 17:24:45+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173xixl/building_a_gptdriven_chatbot_assistant_ai/,Building a GPT-Driven Chatbot Assistant / AI Interpreter with Node.js,,learnmachinelearning,https://medium.com/@sschepis/building-a-gpt-driven-chatbot-assistant-ai-interpreter-with-node-js-e7ee29d0c9ec,0,2,1.0,[]
173lnqz,Goatman117,,2023-10-09 07:13:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173lnqz/barely_have_a_highschool_level_maths/,"Barely have a high-school level maths understanding, what would you recommend I do?","I'm following along the [fast.ai](https://fast.ai) course and enjoying it, but I want to understand the inner workings of neural networks in more depth, and upon looking at it I've realised that I really lack a lot of foundational maths understanding. I'd love to get to the point where I can understand optimization algorithms or general machine learning maths, but currently I'm struggling with just gradient descent.  


What would you recommend I do to build up the knowledge I'll need? Just focus on maths and hold off on the machine learning side of things, or just ignore the bits I don't understand while building maths skills and review later?  


Worth mentioning I'm doing a fair bit of programming in Python these days (at an intermediate level I think), but even there I'm mostly working out the maths needed via trial and error.  


Any pointers would be appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173lnqz/barely_have_a_highschool_level_maths/,26,12,0.72,"[Comment(id='k43nqtj'), Comment(id='k43sxg1'), Comment(id='k43prfm'), Comment(id='k43ro1t'), Comment(id='k43wgvw'), Comment(id='k4431pi'), Comment(id='k444hmm'), Comment(id='k445bn5'), Comment(id='k48kfww'), Comment(id='k43pnn7'), Comment(id='k43toeh'), Comment(id='k43q09w'), Comment(id='k43wr1s'), Comment(id='k43wtkb'), Comment(id='k48jqm5'), Comment(id='k48jodz'), Comment(id='k43qrh9'), Comment(id='k43vlsw'), Comment(id='k43q9my'), Comment(id='k43qzxo'), Comment(id='k43wh2z'), Comment(id='k43r4cd'), Comment(id='k43zeeq'), Comment(id='k440occ'), Comment(id='k453sxb'), Comment(id='k49bk3k')]"
173wy7g,ledmmaster,,2023-10-09 17:01:32+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173wy7g/multivariate_time_series_forecasting_in_python/,Multivariate Time Series Forecasting in Python,,learnmachinelearning,https://forecastegy.com/posts/multivariate-time-series-forecasting-in-python/,0,1,1.0,[]
173wnpl,Chisom1998_,,2023-10-09 16:49:57+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173wnpl/key_chatgpt_statistics_every_ai_enthusiast_should/,Key ChatGPT Statistics Every AI Enthusiast Should Know!,,learnmachinelearning,https://www.successtechservices.com/chatgpt-statistics/,0,0,0.5,[]
173w6tn,miguelaeh,,2023-10-09 16:30:36+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173w6tn/tutorial_deploying_computer_vision_applications/,Tutorial: deploying computer vision applications to the cloud using Kubernetes and Helm,,learnmachinelearning,https://www.pipeless.ai/blog/deploy-with-kubernetes/Deploying%20an%20object%20detection%20application%20to%20the%20cloud%20using%20Kubernetes%20and%20Helm,0,1,1.0,[]
173ecub,Tyron_Slothrop,,2023-10-09 00:22:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173ecub/education_and_ml/,Education and ML,Anyone else feel like they would have gravitated towards math more in high school if it was taught as a way to understand ML? Seems like a really great tool to get kids interested in math.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173ecub/education_and_ml/,13,18,0.83,"[Comment(id='k42dkzi'), Comment(id='k4303bo'), Comment(id='k42u11f'), Comment(id='k42ftil'), Comment(id='k442pft'), Comment(id='k44jdhq'), Comment(id='k435gkh'), Comment(id='k42z897'), Comment(id='k4eewme'), Comment(id='k438bfy'), Comment(id='k43gsxa'), Comment(id='k43h762'), Comment(id='k43hr9g')]"
173ujtb,gr3yth1nkr,,2023-10-09 15:23:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173ujtb/near_real_time_fact_check_tech/,Near Real Time Fact Check Tech.,"Question to all relevant tech entities, leaders, experts, etc.  Is there any way to engage available tech to provide near real time fact checking in social media environments?  Especially in regards to hate speech & disinformation that promotes hate speech & rhetoric?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173ujtb/near_real_time_fact_check_tech/,0,1,1.0,[]
173ozr2,__god_bless_you_,,2023-10-09 11:01:28+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173ozr2/weekbyweek_nlp_dl_guide_dive_into_stanfords/,Week-by-Week NLP & DL Guide: Dive into Stanford's CS224N with this Google Doc,,learnmachinelearning,https://docs.google.com/document/d/1ZA2P48P5aAe6YRAoozg1SIbEIcLJdCgkHW6CNnEvGu4/edit?usp=sharing,1,2,0.75,[Comment(id='k746774')]
173mw9k,HeyMrGT,,2023-10-09 08:41:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173mw9k/does_anybody_know_how_does_this_person_making/,Does anybody know how does this person making these videos? What's the technic? Is it Stable Diffusion?,"[AI Avatar Video](https://www.instagram.com/reel/CxTMAlSuX-X/)

&#x200B;

https://preview.redd.it/axkf4mb235tb1.png?width=302&format=png&auto=webp&s=46765c8ded1b60ad9e4390e39f114f2d1e8149bd",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173mw9k/does_anybody_know_how_does_this_person_making/,0,3,1.0,[]
173tec3,Seankala,,2023-10-09 14:36:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173tec3/transformer_model_is_outputting_the_same_empty/,Transformer model is outputting the same empty string for every single input. What might be some things that I'm missing?,"I have a Transformer implementation that I've recently tried to re-do to apply some new things/knowledge that I learned recently. It turns out that the model doesn't seem to be training properly. The architecture is the ""original"" Transformer model from the paper _Attention is All You Need_.

I'm actually not that familiar with generation tasks in general and am not sure what I might be doing wrong. I've already tried reducing the learning rate (and changing the scheduling algorithm), clipping gradients, double checking if my generation logic is correct, etc. but I can't seem to pinpoint what the problem might be. I've also checked that the masking scheme is correct.

Just wondering if there might be any other tips that I may have missed and if anyone who's more familiar with generation may be able to weigh in. Any tips are appreciated.

P.S., by ""masking scheme"" I mean how we provide the encoder with a padding mask and the decoder with both a padding mask and a ""combined mask"" (i.e., a mask that masks padding tokens and enforces causality). I've also double checked to make sure the sizes of these masks are appropriate (`padding_mask.shape = (batch_size, seq_len)`, `combined_mask.shape = (batch_size, seq_len, seq_len)`).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173tec3/transformer_model_is_outputting_the_same_empty/,0,1,1.0,[]
1741nir,tutoranastacia79,,2023-10-09 20:10:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1741nir/online_assignment_help/,Online assignment Help,Do you feel overwhelmed by assignments workload and timely delivery or worried about good grades? Worry no more. We will help. Contact us on iMessage or email mutuakelvin79@gmail.com,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1741nir/online_assignment_help/,0,0,0.17,[]
173jx58,Hazy_29,,2023-10-09 05:20:46+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173jx58/ryzen_5500_or_i5_12400f/,Ryzen 5500 or i5 12400f,"I'm new to machine learning and decided to build a new PC with a 3060 12GB GPU for my personal project of fine-tuning a language model locally. 

Based on what I've found, I've come across many posts from 2017-2019 that mentioned TensorFlow and PyTorch running slower compared to Intel CPUs. Is this still the case now?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173jx58/ryzen_5500_or_i5_12400f/,3,3,0.81,"[Comment(id='k43v3nu'), Comment(id='k44r4bd'), Comment(id='k4dc5jz')]"
173qay3,brand_momentum,,2023-10-09 12:15:32+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173qay3/complete_excel_python_and_machine_learning_mega/,"Complete Excel, Python and Machine Learning Mega Software Bundle from Mammoth Interactive",,learnmachinelearning,https://medium.com/@Humble_Bundle_Partner_Blog/the-complete-excel-python-and-machine-learning-mega-software-bundle-dddf5277bf39,0,0,0.5,[]
173q12v,Weird_Bad7577,,2023-10-09 12:01:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173q12v/where_to_start_nlp/,Where to start NLP?,Hi I am new to ML and NLP and I would really love to learn NLP I kinda want to build a chatbot so I want to start learning NLP. I have tried to learn it using some YouTube videos but many of them are old so can anyone recommend me a good course or article that would help me,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173q12v/where_to_start_nlp/,3,1,1.0,"[Comment(id='k44pavy'), Comment(id='k49uw9w'), Comment(id='k4b1zm8')]"
1737nm1,__god_bless_you_,,2023-10-08 19:29:02+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1737nm1/this_is_an_outstanding_blog_post_about_transformer/,This is an outstanding blog post about transformer,,learnmachinelearning,https://ig.ft.com/generative-ai/,1,19,0.92,[Comment(id='k4318k0')]
173ln5f,Coder2j,,2023-10-09 07:12:06+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173ln5f/pyspark_tutorial_for_beginners/,PySpark Tutorial for Beginners,"🚀 Exciting News! Just released my latest YouTube video - ""PySpark Tutorial for Beginners: 1-Hour Full Course"" 🐍💡

Are you ready to dive into the world of PySpark and harness the power of distributed data processing with ease? In this comprehensive 1-hour tutorial, I'll guide you through the fundamentals of PySpark, from installation to hands-on coding examples.

🔥 What You'll Learn:
✅ Spark Introduction
✅ Spark Installation
✅ Setting Up Your PySpark Environment
✅ Spark RDD
✅ DataFrame Operations
✅ Spark SQL
✅ And much more!

Whether you're a beginner looking to kickstart your journey into big data or an experienced data engineer aiming to refresh your skills, this video has something for you!

Watch it now 👉 https://youtu.be/EB8lfdxpirM
GitHub Repo 👉 https://github.com/coder2j/pyspark-tutorial

Don't forget to like, subscribe, and share with your network. Let's spread the knowledge together! 📚💪
#PySpark #DataScience #BigData #Tutorial #LinkedInLearning #YouTubeTutorial",learnmachinelearning,https://youtu.be/EB8lfdxpirM,0,2,1.0,[]
173c5r3,Britney-Ramona,,2023-10-08 22:39:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173c5r3/beginners_guide_to_llms_nontechnical_guide/,Beginner's Guide to LLMs - Non-Technical Guide,"Realized there wasn't a great resource for Beginners/non-technical individuals to understand what Large Language Models are and why they are so powerful, so I wrote [https://datasci101.com/what-are-llms-part-1/](https://datasci101.com/what-are-llms-part-1/) 

There are 4 parts, this is the 1st & arguably the most important for people to get foundational LLM understanding/information.

Worked really hard on this & would appreciate any of your more technical/expert feedback. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173c5r3/beginners_guide_to_llms_nontechnical_guide/,1,9,1.0,[Comment(id='k41z9ty')]
173mstl,bluebolt789,,2023-10-09 08:34:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173mstl/finetuning_bert_for_sentiment_analysis/,Fine-tuning BERT for sentiment analysis,"Hello!

I am trying to fine-tune BERT to classify the sentiment of an e-mail as either positive or negative. I’m using TFAutoModeForSequenceClassification from the transformers library, but my model does not seem to be learning anything. I’m trying to figure out why. 

Here’s a list of things I think could be affecting my model:
1) I have an imbalanced dataset (70% positive, 30% negative)
2) The e-mails can be longer than 512 tokens
3) Data is not clean enough 

I’m trying to solve 1) by doing some random over sampling, but it does not seem to help much.

Any other ideas? 

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173mstl/finetuning_bert_for_sentiment_analysis/,2,1,1.0,"[Comment(id='k448zwl'), Comment(id='k449lro')]"
173mr9n,Lemon_Salmon,,2023-10-09 08:30:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173mr9n/help_with_attention_code/,help with attention code,"Could anyone advise why this [softmax()](https://dpaste.org/7qLEu#L126,129) code is giving an `attn_weights` matrix with numerical values of more than 1 ?  


https://preview.redd.it/i0ykqd5315tb1.png?width=645&format=png&auto=webp&s=00ac784dfd0105485b7e61fb39ed444f5e164583",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173mr9n/help_with_attention_code/,8,1,0.67,"[Comment(id='k43u9l2'), Comment(id='k447isi'), Comment(id='k43vj6o'), Comment(id='k44f90p'), Comment(id='k444qmz'), Comment(id='k445eqe'), Comment(id='k447zcs'), Comment(id='k4dlv5x')]"
173djvx,tomcat_96,,2023-10-08 23:42:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173djvx/still_over_fitting/,Still over fitting?,"Hey guys! So I've been trying to learn machine learning but I'm running into an issue where my test loss decreased but my validation loss increased. A quick Google search tells me that I am over fitting my model. So I included data augmentation, which is just taking 9 crops of the image, but that didn't help. I included k fold validation and it didn't help, and finally I introduced decaying learning rate and that didn't help either. Is there anything else I can do?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173djvx/still_over_fitting/,5,3,1.0,"[Comment(id='k43tide'), Comment(id='k43t0cw'), Comment(id='k44832e'), Comment(id='k448fhw'), Comment(id='k45i8n7')]"
1739xfc,vemilano44,,2023-10-08 21:05:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1739xfc/looking_for_a_bookwebsite_covering_deep_learning/,Looking for a Book/Website Covering Deep Learning from the Ground Up,"Hey Guys! I am in the process of writing the ""Basics of Deep Learning"" section of my thesis. I aim to provide a comprehensive overview, starting from foundational Machine Learning concepts, progressing to Deep Learning, and diving deep into Computer Vision, including topics like Image Classification, Object Detection, OCR, Image Segmentation, and so on.

Can anyone recommend books or websites that cover these topics in a sequential manner? Ideally, I'm looking for a resource that provides a coherent flow of information, helping me structure my chapter while ensuring I touch on all relevant subjects.

Any guidance or pointers would be much appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1739xfc/looking_for_a_bookwebsite_covering_deep_learning/,2,3,1.0,[Comment(id='k425emh')]
173he6b,Voice_Fickle,,2023-10-09 02:54:44+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173he6b/how_to_improve_a_linear_model_with_polynomial/,How to improve a linear model with polynomial features,,learnmachinelearning,https://youtu.be/a1nV-DOfm4s,0,1,1.0,[]
173hda5,Voice_Fickle,,2023-10-09 02:53:25+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173hda5/cyber_security_in_machine_learning_tutorial_video/,Cyber Security in Machine Learning tutorial video,,learnmachinelearning,https://youtu.be/gmOy01KHxx0,0,1,1.0,[]
173g42s,Friendly_Storage_622,,2023-10-09 01:50:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173g42s/translation_model/,Translation model,Hey! I need to build a translation site without the help of Google api. I don't know how to get started. It should from English to a vernacular language. I'm not aware of ml. Could anyone tell me how to approach this?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173g42s/translation_model/,0,1,1.0,[]
17328dl,fbeilstein,,2023-10-08 15:39:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17328dl/introduction_to_machine_learning_l4_pandas/,"Introduction to Machine Learning (L4, Pandas)","Hello everyone!

This year I'm trying to record my ""Introduction to ML"" course in English. Maybe, it will be of any use for anyone.

[Lecture 4, Pandas](https://www.youtube.com/watch?v=dKWPi5PfuEQ)

Previous lectures: [Lecture 1, Introduction](https://www.youtube.com/watch?v=MxZULf38HRU), [Lecture 2, Python](https://www.youtube.com/watch?v=_IBdjLg-W6I), [Lecture 3, NumPy](https://www.youtube.com/watch?v=jJGiC_ccPg8)

All course materials: [GitHub](https://github.com/fbeilstein/machine_learning)

 ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17328dl/introduction_to_machine_learning_l4_pandas/,1,7,0.89,"[Comment(id='k40pi6i'), Comment(id='k41adtn')]"
172ruzm,GuillerminaCharity,,2023-10-08 06:11:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172ruzm/how_are_you_evaluating_and_monitoring_llms/,How are you evaluating and monitoring LLMs?,"Question for people who are implementing LLMs (open source, fine tuned, any kind).

1. How do you know that your getting the quality output from the model that you need to ship the feature or model? Are the audits ad hoc data sampling and subjective ""good/bad"" ratings or have you figured out a more rigorous framework? Is it pretty much \~vibes\~ based?
2. What, if any, tools or processes are you putting into place to monitor and observe the LLM when its interacting with real time user data for weeks or months?

Most of the folks I have spoken with are doing very ad hoc sampled output and writing down on post its or in a spreadsheet a subjective quality ratings.

One person had developed a slightly more rigorous 3 question survey on ""is the result factual"", ""is the result cogent"" and ""is the result useful"". Not everyone is logging their LLM responses they show users which feels very risky to me.

Anyone aware of any industry standards being established around this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172ruzm/how_are_you_evaluating_and_monitoring_llms/,6,22,0.97,"[Comment(id='k3yflqe'), Comment(id='k3z8wk0'), Comment(id='k3zjd7a'), Comment(id='k41x3n5'), Comment(id='k44ps0d'), Comment(id='k3yoi9o')]"
173c4rn,purpledesertsky1,,2023-10-08 22:38:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/173c4rn/help_choosing_courses/,Help choosing courses,"Hello,
I am currently a math masters student, and I am planning to do my masters thesis on using neural networks to solve differential equations. I am taking courses in machine learning and differential equations right now, and I am going to take courses on deep neural networks and partial differential equations next semester. My question pertains to which classes would be more beneficial to learn next year (i.e. fall 2024-spring 2025). I am debating taking the sequence of regression analysis and multivariate analysis, or taking the pairing of numerical analysis for PDEs and perturbation methods. Which do you guys think would be more beneficial? Thank you very much!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/173c4rn/help_choosing_courses/,1,1,1.0,[]
1735v3g,AstronomerNo4803,,2023-10-08 18:14:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1735v3g/training_ai_to_play_a_game_using_firstorder_logic/,Training AI to play a game using first-order logic,"Hello, for my master project I ended up with ""Training AI"" to play a video game. The game itself is tile based, with tiles having special properties like teleportation, impassible, and so on. Also there will be other players in the game at the same time and you can kill or get killed by others. You do respawn, but after X amount of turns. Professor told me that I will want to use first-order logic for it, so I started reading into it and understand the basic concepts and principles of it. The thing is I only briefly touched ML before starting this degree, so I'm missing a lot of info that I probably should know and I have no idea what methods I can use to ""teach"" AI with first-order logic. I want to read about it and learn, so I could write the code in such a way that it would be easy to plug in the agents part of code later.

&#x200B;

TL;DR Masters project requires to teach AI to play professors game. Supposedly we will want to use first-order logic. Need books / resources on ""teaching"" methods that use first-order logic. Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1735v3g/training_ai_to_play_a_game_using_firstorder_logic/,4,1,0.56,"[Comment(id='k410owi'), Comment(id='k422fhe'), Comment(id='k42c7kz'), Comment(id='k414y45')]"
173aazo,RealSataan,,2023-10-08 21:20:52+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/173aazo/im_getting_frustrated/,I'm getting frustrated,,learnmachinelearning,/r/GoogleColab/comments/173aajt/im_getting_frustrated/,1,1,1.0,[Comment(id='k42l5z4')]
172x61u,mrpkeya,,2023-10-08 11:45:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172x61u/bayesian_machine_learning/,Bayesian Machine Learning,I want to work on a project related to Bayesian Machine Learning. I am looking for some ideas.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172x61u/bayesian_machine_learning/,2,4,0.75,"[Comment(id='k41zhbq'), Comment(id='k42gdp0')]"
172uexw,Fr_kzd,,2023-10-08 08:55:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172uexw/any_resources_for_snns/,Any resources for SNNs?,"I'm having trouble finding any decent, fleshed-out resources for learning about Spiking Neural Networks. I understand that it's a bit of a niche in the ML field as it isn't widely explored yet compared to other subfields. Any recommendations? Even any little article would be appreciated. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172uexw/any_resources_for_snns/,2,3,1.0,"[Comment(id='k3zegcn'), Comment(id='k3ysdbe')]"
172zl5a,AndrewKorsten,,2023-10-08 13:48:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172zl5a/i_am_trying_to_break_into_sales_in_ai_saas_tech/,"I am trying to break into sales in AI SaaS / tech, and I am learning math. Is this course enough to start learning ML?","HEre's this ""course"" - [https://www.youtube.com/watch?v=WZdZhuUSmpM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=22](https://www.youtube.com/watch?v=WZdZhuUSmpM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=22). Currently, learning what the heck an algebraic aquation is! [https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPBsxdYZdLEMvKqr-DrOgtzUcNq3uxC2mAEQgyWoPN6g&s](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPBsxdYZdLEMvKqr-DrOgtzUcNq3uxC2mAEQgyWoPN6g&s)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172zl5a/i_am_trying_to_break_into_sales_in_ai_saas_tech/,2,0,0.46,"[Comment(id='k40cbro'), Comment(id='k4438m0')]"
172i1qs,ML-SSL,,2023-10-07 21:55:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172i1qs/introduction_to_similarity_measures_cosine/,"Introduction to Similarity Measures (Cosine, DotProduct, etc)","This is a concise overview of often used similarity measurements in ML. It covers Cosine similarity, Dot Product, Manhattan Distance and Euclidian Distance. 

[https://medium.com/advanced-deep-learning/understanding-vector-similarity-b9c10f7506de](https://medium.com/advanced-deep-learning/understanding-vector-similarity-b9c10f7506de)

&#x200B;

https://preview.redd.it/233rjmmtqusb1.png?width=1844&format=png&auto=webp&s=0434f9d1109daba8ff54a9521d355240b08b2e25",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172i1qs/introduction_to_similarity_measures_cosine/,6,17,0.9,"[Comment(id='k3ymu8f'), Comment(id='k3yrm4p'), Comment(id='k3zjfdl'), Comment(id='k414nhj'), Comment(id='k3yrsem'), Comment(id='k3ytfmr')]"
172u0td,No_Negotiation_7451,,2023-10-08 08:30:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172u0td/how_to_know_what_interaction_termsbetween/,How to know what interaction terms(between different predictor variables) are actually significant?(linear regression doubt),"Hello. So, I was learning Linear Regression from ISLP chap-3. There was this question, 9(e) in applied exercises which stated ""Fit some models with interactions"". However, is there any way to determine what interaction terms are actually significant, without trial and error? Or do I have to play randomly with the dataset?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172u0td/how_to_know_what_interaction_termsbetween/,0,2,1.0,[]
172h7ya,AbstractContract,,2023-10-07 21:20:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172h7ya/what_would_be_the_best_option_to_utilize_a_gpu/,What would be the best option to utilize a GPU remotely?,"Specifically I want to be able to use my desktop equipped with a 3060 at home for LLM inference from my laptop and Raspberry Pi based devices. I can connect to my home network via tailscale, but am rather unsure how to access that GPU power easily. The best way I could think of would be using wake on LAN to power up the desktop and then remotely access it to execute code and use mdels hosted on that machine. Would there be a better way and is there a recommended setup for this kind of scenario? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172h7ya/what_would_be_the_best_option_to_utilize_a_gpu/,6,15,0.86,"[Comment(id='k3x4r6v'), Comment(id='k3wpxtz'), Comment(id='k3x4yfv'), Comment(id='k3ym3zk'), Comment(id='k3zxsz0'), Comment(id='k40w169')]"
172zl54,AndrewKorsten,,2023-10-08 13:48:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172zl54/i_am_trying_to_break_into_sales_in_ai_saas_tech/,"I am trying to break into sales in AI SaaS / tech, and I am learning math. Is this course enough to start learning ML?","HEre's this ""course"" - [https://www.youtube.com/watch?v=WZdZhuUSmpM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=22](https://www.youtube.com/watch?v=WZdZhuUSmpM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=22). Currently, learning what the heck an algebraic aquation is! [https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPBsxdYZdLEMvKqr-DrOgtzUcNq3uxC2mAEQgyWoPN6g&s](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRPBsxdYZdLEMvKqr-DrOgtzUcNq3uxC2mAEQgyWoPN6g&s)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172zl54/i_am_trying_to_break_into_sales_in_ai_saas_tech/,0,0,0.33,[]
172u988,Mets_CS11,,2023-10-08 08:45:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172u988/trying_to_solve_the_problem_of_looking_for/,Trying to solve the problem of looking for patterns in specific sets of inputs,"So i have come across the problem where I think patterns may exist but only for certain types of inputs. So running an ML training on the entire set will not suffice. I think its best to put my problem statement in words:

Imagine you own a bookshop and have a random book shipped to you once a day. Lets say for simplicity there are 10 pages in the book. And on each page is written any number from 1-100 in giant bold font. Everyday a man comes in who either buys or doesn't buy the random book of the day. He carefully looks at each page and then makes a decision. You have no idea the criteria he is using to make the decision.   


You have a log of the contents of the book and whether or not the man bought it that day. Lets say years and years have passed and you have a detailed log. You want to use this log history to determine why he buys the books he does.   


Your intuition is that sometimes he might buy a book just for the heck of it. But other times he sees something in the pages that makes him buy it. 

For example, maybe he enjoys it when pages 1-9 all have their own page number written on it and he simply does not care what number is on page 10. So maybe you check the log of all books that had 1-9 written on their corresponding pages and see that there were 100 times this happened and the man bought the book 98 times. Indicating that this is one particular combination of pages (only pages 1-9 mattered here) where he bought the book.

Most times it looks like his choices are random but by looking at the log for this type of combination you see his choices were consistent. This is just one example of a specific page combination that will yield a predictable result by the man. You want to find as many as possible.  


The hard part is that it doesn't seem you can solve this with a standard neural network since they will solve the weights to fit a relationship between every sample. But here, most of the times the man's choice to buy or not is kind of random. There are only specific combinations of page numbers that yield a predictable result.

What tools could you use here to help you?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172u988/trying_to_solve_the_problem_of_looking_for/,1,1,1.0,[Comment(id='k3ysn86')]
172my56,specializedboy,,2023-10-08 01:41:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172my56/need_clarification_on_training_diffusion_model/,Need clarification on training diffusion model,"Hey i have trained a diffusion model for 100 epochs , 8 hours and i got the following train and val loss mostly the implementation is done using diffusers. then i try reconstruction on the test set to check whether the model learned any thing this is whats happening most if the images are not getting denoised at all why this is happening? is this common or should i need to train more. any suggestions? please help. does adding additional attentional layers to unet gives any improvement ?

&#x200B;

[reconstructed images](https://preview.redd.it/26ug8ta8vvsb1.png?width=910&format=png&auto=webp&s=a8f4938d779a77aab3551936037f70b6f7d60f23)

https://preview.redd.it/lj19v9j7vvsb1.png?width=2314&format=png&auto=webp&s=79929628d8f869d37795f5e453baa0fd9680a87c

https://preview.redd.it/qz2cgzy5vvsb1.png?width=2358&format=png&auto=webp&s=ded5ae41c4074ff2a4603b908284e5d1ccb82562",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172my56/need_clarification_on_training_diffusion_model/,0,2,1.0,[]
172k19g,_negativeonetwelfth,,2023-10-07 23:21:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172k19g/coolerlooking_bounding_box_visualizations_in/,"""Cooler""-looking bounding box visualizations in object detection?","Hey everyone, in my deep learning journey so far I've mostly dealt with CV / object detection projects. In this field, the bbox visualizations generally look very bland like [this](https://miro.medium.com/v2/resize:fit:739/1*IrptRDRG8IL9o-55BKjbLA.png), which is understandable, as they're meant to be functional rather than look pretty. However, I've had this idea for a project to create nicer-looking and *animated* bboxes. So far, the only design I've created is this [rotating gradient](https://i.imgur.com/8Jjy6D6.mp4), which I think looks pretty cool.

My question would be, do you guys have any ideas for other designs I could implement?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172k19g/coolerlooking_bounding_box_visualizations_in/,2,3,1.0,"[Comment(id='k3xgr5s'), Comment(id='k3yttya')]"
172qcw0,if_true_break,,2023-10-08 04:42:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172qcw0/sound_patterns_and_ml/,Sound patterns and ML,"Hey mates! Hope you all are doing well.

I had been thinking about build something that uses sounds and ML to predict x, or more specifically, I want to use ML to recognize sound patterns in a crowded city in order to predict people’s behavior, all based on date and time.

For those who know more about it, does this sound achievable? Have you worked with sound and ML? What would be a good starting point?

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172qcw0/sound_patterns_and_ml/,4,1,0.99,"[Comment(id='k3y8gl1'), Comment(id='k42ag1p'), Comment(id='k406861'), Comment(id='k41in4z')]"
171zl10,czechrepublic,,2023-10-07 06:45:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171zl10/what_kinds_of_works_can_a_swe_do_in_an_mlai_team/,What kinds of works can a SWE do in an ML/AI team that researchers cannot?,"I have passion in ML/AI as many do, but I only have experience with traiditonal SWE.  
I wonder what type of roles are suitable for SWE with no research background.  
I see that SWEs in an ML/AI team builds tools for researchers to use or build ML infra.  
ML ops seems to be another option. What are other options and what roles seem to be impactful and potential (+transferrable) ? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171zl10/what_kinds_of_works_can_a_swe_do_in_an_mlai_team/,19,45,0.98,"[Comment(id='k3ukimg'), Comment(id='k3ud85s'), Comment(id='k3u27cb'), Comment(id='k3uz2ev'), Comment(id='k3ugcob'), Comment(id='k3usn1z'), Comment(id='k3vfdqq'), Comment(id='k3uvsbp'), Comment(id='k3veyku'), Comment(id='k3ywxfv'), Comment(id='k3wb6hk'), Comment(id='k3tyxfq'), Comment(id='k3wnk3c'), Comment(id='k43p637'), Comment(id='k45tgbb'), Comment(id='k46yu9f'), Comment(id='k3vl2ts'), Comment(id='k3xetg1'), Comment(id='k41m7y6')]"
171ye7w,onurbaltaci,,2023-10-07 05:33:39+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171ye7w/i_recorded_a_pyspark_big_data_course_python_api/,"I recorded a PySpark Big Data Course (Python API of Apache Spark, i covered machine learning with PySpark too) and uploaded it on YouTube","Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am leaving the link to this post, have a great day! 

[https://www.youtube.com/watch?v=jWZ9K1agm5Y](https://www.youtube.com/watch?v=jWZ9K1agm5Y)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171ye7w/i_recorded_a_pyspark_big_data_course_python_api/,7,33,0.97,"[Comment(id='k3tlimr'), Comment(id='k3unlf2'), Comment(id='k3xoikq'), Comment(id='k3tmzf8'), Comment(id='k3ura11'), Comment(id='k3w3ygs'), Comment(id='k3y2nrf')]"
171lhc7,ImportantImpress4822,,2023-10-06 19:33:00+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/171lhc7/i_know_meta_ai_chatbots_are_in_beta_but/,I know Meta AI Chatbots are in beta but…,"But shouldn’t they at least be programmed to say they aren’t real people if asked? If someone asks whether it’s AI or not? And yes i do see the AI label at the top, so maybe that’s enough to suffice?",learnmachinelearning,https://i.redd.it/1hsk5dhnwmsb1.jpg,40,206,0.9,"[Comment(id='k3rdbqz'), Comment(id='k3rizvu'), Comment(id='k3thzhz'), Comment(id='k3ry6n6'), Comment(id='k3s1a5d'), Comment(id='k3s6diw'), Comment(id='k3sshwb'), Comment(id='k3yy3td'), Comment(id='k4ad9lk'), Comment(id='k3s514f'), Comment(id='k3siaxr'), Comment(id='k3rj5a5'), Comment(id='k3s5592'), Comment(id='k3sx6dz'), Comment(id='k3uju6x'), Comment(id='k3ulbod'), Comment(id='k3vcirc'), Comment(id='k3vznh4'), Comment(id='k3w35ab'), Comment(id='k4f4owa'), Comment(id='k4rcpfm'), Comment(id='k5d5wed'), Comment(id='k5ubk6l'), Comment(id='k3t0ll8'), Comment(id='k3tasl7'), Comment(id='k3vrsm6'), Comment(id='k3u1vhd'), Comment(id='k407blc'), Comment(id='k3uxqbt'), Comment(id='k3rwlkk'), Comment(id='k3t2fji'), Comment(id='k3xsnzd'), Comment(id='k4irhqc'), Comment(id='k3u84sl'), Comment(id='k3uxlhr'), Comment(id='k3w2n0w'), Comment(id='k461hfs'), Comment(id='k3ulynt'), Comment(id='k3ww8ak'), Comment(id='k3uwitr'), Comment(id='k3uwsk7')]"
172izid,darkmoonsatellite,,2023-10-07 22:36:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172izid/question_and_notes_bank_for_machine_learning_class/,Question and notes bank for machine learning class,"I've been preparing for a machine learning test, and I'm wondering if anyone has stumbled upon a collection of questions or study notes that were beneficial. If you have any resources related to the topics listed below, could you please share them here?

* Decision Trees
* Model Evaluation and Selection
* Naive Bayes Approaches
* Logistic Analysis
* Perceptrons
* Linear Predictive Modeling",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172izid/question_and_notes_bank_for_machine_learning_class/,1,1,0.67,[Comment(id='k46vssu')]
172gr4o,oniongarlic88,,2023-10-07 21:00:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172gr4o/looking_to_make_a_complete_team_need_statistics/,Looking to make a complete team. Need statistics background.,"Hello,

I have historical trade data that we can work on. Goal is to reverse engineer the exit trade logic (already know the entry logic).


I know machine learning and Python, and I am looking for someone with statistics background to help analyze and find how these exit trades (from the historical trades that we have a copy of) were decided on so we can automate a similar trading bot as well.


DM me to those interested. This isnt a paying gig. No, Im not getting paid for this either. If we are successful then we both have a copy of the strategy.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172gr4o/looking_to_make_a_complete_team_need_statistics/,1,0,0.4,[Comment(id='k3zg1p1')]
172a8yb,ajeenkkya,,2023-10-07 16:22:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/172a8yb/where_would_i_get_data_on_rejected_loans/,Where would I get data on rejected loans?,"I want to perform analysis on reasons for loan rejection. And specifically need data on number of partial loan offers given. By partial loan I mean, if an individual requested for $100 and they get $80.

Any good sources or methods to access/collect the data is appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172a8yb/where_would_i_get_data_on_rejected_loans/,3,2,1.0,"[Comment(id='k3vps0i'), Comment(id='k3y8jom'), Comment(id='k3y8km0')]"
1726w12,,,2023-10-07 13:51:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1726w12/what_exactly_is_artificial_general_intelligence/,What exactly is Artificial General Intelligence?,"I've been hearing this term quite a bit in r/singularity but I don't understand. What are the metrics to evaluate if an AI is sentient? Also, is there some separate sub-field of study within the AI field that works on AGI? Or AGI something that will emerge out of some advanced LLM, vision etc. model?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1726w12/what_exactly_is_artificial_general_intelligence/,12,1,0.54,"[Comment(id='k3uwegc'), Comment(id='k3vekh3'), Comment(id='k3uxnus'), Comment(id='k3vtuej'), Comment(id='k3vu23p'), Comment(id='k3vbr7c'), Comment(id='k3x71jm'), Comment(id='k3w9mjc'), Comment(id='k445skx'), Comment(id='k3uyc1e'), Comment(id='k3vfj4x'), Comment(id='k4495ic')]"
172b1ze,100GB-CSV,,2023-10-07 16:57:12+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/172b1ze/the_lightningfast_pace_of_polars_fuels_the/,The Lightning-fast Pace of Polars Fuels the Development of Peaks,,learnmachinelearning,https://youtu.be/cgqLdb_RXLc,0,1,1.0,[]
1729p6v,Lakshmireddys,,2023-10-07 15:58:32+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1729p6v/best_machine_learning_books_for_beginners/,Best Machine Learning Books for beginners & Advanced to learn in 2023 -,,learnmachinelearning,https://codingvidya.com/best-machine-learning-books/,1,0,0.5,[Comment(id='k3wufew')]
1729bb8,tomcat_96,,2023-10-07 15:40:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1729bb8/can_you_train_your_model_by_using_multiple_folds/,Can you train your model by using multiple folds per epoch?,"For example, I am training a model using 10 fold validation. Can I train my model on all 10 folds per epoch? Like Epoch 1 is folds 1-10 then epoch 2 is a new set of folds?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1729bb8/can_you_train_your_model_by_using_multiple_folds/,1,1,1.0,[Comment(id='k3vjrwn')]
171bw4x,No-Biscotti5394,,2023-10-06 13:08:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171bw4x/most_beginner_courses_use_tensorflow_but_ive_seen/,Most beginner courses use Tensorflow but ive seen people here advice not to use it?,"whats wrong with TF?

Also, are there beginner lessons that use JAX or PyTorch or something else, or should i follow the TF ones while trying out the things in other frameworks?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171bw4x/most_beginner_courses_use_tensorflow_but_ive_seen/,53,69,0.94,"[Comment(id='k3po1z6'), Comment(id='k3pzuve'), Comment(id='k3pu2rh'), Comment(id='k3r9pxc'), Comment(id='k3ppxlf'), Comment(id='k3rtn5p'), Comment(id='k3r6o6w'), Comment(id='k3pzc6x'), Comment(id='k3rxns4'), Comment(id='k3srjfk'), Comment(id='k3rg53c'), Comment(id='k3q7krp'), Comment(id='k3qddpz'), Comment(id='k3sv1v7'), Comment(id='k3t8kse'), Comment(id='k3rvgr9'), Comment(id='k3qee9d'), Comment(id='k3pzd2s'), Comment(id='k3q492p'), Comment(id='k3r7t03'), Comment(id='k3rv8jm'), Comment(id='k3suu39'), Comment(id='k3t819l'), Comment(id='k3t84qd'), Comment(id='k3qdgk9'), Comment(id='k3qijv2'), Comment(id='k3suu1m'), Comment(id='k3pzy87'), Comment(id='k3tli9k'), Comment(id='k3v036h'), Comment(id='k3ukwkn'), Comment(id='k3tut4v'), Comment(id='k3qgzp9'), Comment(id='k3syj7t'), Comment(id='k3rgzpk'), Comment(id='k3v6rdo'), Comment(id='k3uwukr'), Comment(id='k3uwytu'), Comment(id='k3r3k6k'), Comment(id='k3tlaa8'), Comment(id='k3uy2g7'), Comment(id='k3t87yt'), Comment(id='k3rbot9'), Comment(id='k3vhns8'), Comment(id='k3uybmj'), Comment(id='k3rce0w'), Comment(id='k3v0gld'), Comment(id='k3reu49'), Comment(id='k3v22wj'), Comment(id='k3rhono'), Comment(id='k3vil4q'), Comment(id='k3uf0ju'), Comment(id='k3vhmm9'), <MoreComments count=0, children=[]>]"
1724l4n,Old_Walk_628,,2023-10-07 11:54:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1724l4n/is_there_anyone_who_can_help_me_in_a_deep/,Is there anyone who can help me in a deep learning assignment please?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1724l4n/is_there_anyone_who_can_help_me_in_a_deep/,0,0,0.5,[]
171qjye,beckhamc,,2023-10-06 23:01:34+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/171qjye/a_deep_dive_into_conditional_variational/,A deep dive into conditional variational autoencoders,,learnmachinelearning,https://beckham.nz/2023/04/27/conditional-vaes.html,0,5,1.0,[]
172awi7,AndrewKorsten,,2023-10-07 16:50:43+00:00,False,,1696700340.0,False,True,False,/r/learnmachinelearning/comments/172awi7/i_dont_remember_any_math_from_school_but_i_want/,"I don't remember any math from school, but i want to move into ML so that I can proceed into Sales in AI","Hey guys

1. I don't remember any math from school at all.
2. I am 37 y.o., and I currently work as an English teacher in the evenings, and I used to write content, but I want to move out of that niche.
3. I want to move into Sales in AI, so I decided that I would start learning the basics of Python and ML and the overall ecosystem. I WANT TO BECOME A SALESPERSON, NOT USE AI FOR SALES ANALYSIS.
4. I have already started learning Python and I am slowly covering the basics (I have a basic understanding of HMTL, CSS and JS).
5. But when I started googling what ML is, I started bumping into such articles - [https://www.geeksforgeeks.org/machine-learning-mathematics/](https://www.geeksforgeeks.org/machine-learning-mathematics/). Well, thi is not Python.

What do I do?

Edit 1: Here's a clarification with more info - [https://www.reddit.com/r/learnmachinelearning/comments/172awi7/comment/k3vnlm6/?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/learnmachinelearning/comments/172awi7/comment/k3vnlm6/?utm_source=share&utm_medium=web2x&context=3)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/172awi7/i_dont_remember_any_math_from_school_but_i_want/,56,0,0.35,"[Comment(id='k3vtic8'), Comment(id='k3wbjbi'), Comment(id='k3vlqjm'), Comment(id='k3vmq0u'), Comment(id='k3wo9c0'), Comment(id='k3vjt9l'), Comment(id='k3wi8gt'), Comment(id='k3xb7jp'), Comment(id='k3wh9t3'), Comment(id='k3x1vtj'), Comment(id='k3y757d'), Comment(id='k3y4uam'), Comment(id='k3z48hh'), Comment(id='k42gqik'), Comment(id='k44azwm'), Comment(id='k3vwbdy'), Comment(id='k3wdd9s'), Comment(id='k3vnlm6'), Comment(id='k3w7sxe'), Comment(id='k3vktjr'), Comment(id='k3wo6su'), Comment(id='k3z1o16'), Comment(id='k3z00ss'), Comment(id='k3z0wyh'), Comment(id='k42wkcd'), Comment(id='k443auf'), Comment(id='k44cal6'), Comment(id='k44d864'), Comment(id='k3ylxob'), Comment(id='k3y1wio'), Comment(id='k3yhbp5'), Comment(id='k477yof'), Comment(id='k3wc73i'), Comment(id='k3wgfte'), Comment(id='k3vuald'), Comment(id='k3z1i9u'), Comment(id='k3z0dcb'), Comment(id='k3z2eki'), Comment(id='k443bq9'), Comment(id='k44913c'), Comment(id='k44hkue'), Comment(id='k3z13w6'), Comment(id='k494kka'), Comment(id='k3wcz8n'), Comment(id='k3vx1e1'), Comment(id='k3z3zql'), Comment(id='k443ci9'), Comment(id='k449rdo'), Comment(id='k44b2my'), Comment(id='k44br7b'), Comment(id='k44hvnr'), Comment(id='k49t23v'), Comment(id='k3vzll6'), Comment(id='k49umhh'), Comment(id='k3wcm5c'), Comment(id='k3wmgj4'), Comment(id='k3ykbe0'), Comment(id='k3z178c')]"
171im8o,AnnoyingWeirdo2134,,2023-10-06 17:37:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171im8o/data_science_or_computer_science/,Data science or computer science?,"Hello looking for advice. 

I'm planning on getting back to university so that I could gain more knowledge and getting into ML. Currently i'm an RPA developer and have some knowledge in programming and getting proficient in python. 

For some reason I want to get a Msc in AI in the coming years.

So the question as title says, what would be more suited and knowledge more applicable to ML. Bsc in data science or computed science?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171im8o/data_science_or_computer_science/,6,6,0.8,"[Comment(id='k3r5kjy'), Comment(id='k3t5qwf'), Comment(id='k3sj4hb'), Comment(id='k3uax9i'), Comment(id='k3uktei'), Comment(id='k3uopcw')]"
171ny44,username_Zwickey,,2023-10-06 21:13:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171ny44/getting_error_optimizer_got_an_empty_parameter/,"Getting error ""optimizer got an empty parameter list"" with pytorch","Hi Guys! I am working on a U\_net and when I am trying to train it I am getting the aforementioned error, have been unable to solve it after spending long hours. I would be really grateful if you guys could help me out with this. The code can be found here [https://github.com/junaidjawaid1/Unet\_pytorch/tree/main](https://github.com/junaidjawaid1/Unet_pytorch/tree/main) . The full error message is in the readme file.

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171ny44/getting_error_optimizer_got_an_empty_parameter/,2,2,1.0,"[Comment(id='k3sm0g4'), Comment(id='k3sqmp8')]"
171jvil,PRAY_J,,2023-10-06 18:27:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171jvil/advice_for_a_beginner_in_cv/,Advice for a beginner in CV,"I'm a final year Electronics undergrad and somewhat of a beginner in CV, ""somewhat"" because I do have an understanding of how things work, have done some university courses on image and video processing and have a research internship. But, despite all of this my weakness is in coding. Which is why I plan on implementing the fundamental research papers on various tasks like image classification, segmentation, object detection, tracking, etc. Is that a good way to get my hands dirty and improve my coding skills?

I'm also currently doing the CS231n course offered by Stanford to get a good foundational understanding of the topics.

P.SI want to explore domains like RL and embodied Al, how can I get started with that?

Any sort of advice would be highly appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171jvil/advice_for_a_beginner_in_cv/,0,3,1.0,[]
171rwcb,KinkyBrainBoss,,2023-10-07 00:00:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171rwcb/transitioning_roadmap/,transitioning roadmap?,"Can someone point in the right direction of a roadmap that me be appropriate for someone transitioning from a career mostly spent in cyber to one within machine learning?  Free/Paid courses, no matter , just the best quality path.  I appreciate it.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171rwcb/transitioning_roadmap/,0,1,1.0,[]
171lug3,Plastic_Jicama_2701,,2023-10-06 19:48:09+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/171lug3/document_ai_learning_and_community_hub_where_you/,"Document AI Learning and Community Hub, where you can find all about documents processing and AI",,learnmachinelearning,/r/DocumentAI_Community/comments/171lpmw/document_ai_learning_and_community_hub_your/,0,2,1.0,[]
171pl54,BarkingBot,,2023-10-06 22:21:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171pl54/cs231n_and_deep_learning_specialization/,cs231n and deep learning specialization overlapping,"hey I am a beginner who is currently taking deep learning specialization and I want to take cs231n in the future. However, I saw some of the contents overlap so I want to ask if it is good idea to take Deep Learning specialization fully before moving on to cs231n.

&#x200B;

people who took both, how do you guys think?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171pl54/cs231n_and_deep_learning_specialization/,0,1,1.0,[]
171e6rz,siberthrow,,2023-10-06 14:45:29+00:00,False,,1696605111.0,False,True,False,/r/learnmachinelearning/comments/171e6rz/feeling_obsolete_need_guidance_on_staying_relevant/,Feeling obsolete. Need guidance on staying relevant,"**TLDR:** A bit whiny background on my current situation. Looking to up/re-skill with very limited hardware resources. Both technical and career advice welcome.

**A bit on my background:** I have a bachelor's and master's degree in computer science with focus on applied ML. For the first few years of my career I worked in a big-tech ML team, and got a couple of publications and patent out of there. Unfortunately, in March 2020 some people in my team, including me, were laid off. In desperation of finding  work in a then dire market, and to maintain my visa status, I took up a promising job in a financial firm that had intentions of building a cutting-edge ML team. Two years on, my current firm has continued being obsolete. There are good intentions all around but no actual tools or steps to  catch-up. We have 1 GPU-enabled server (with 2 RTX 6000) across a 30-people team.

Most of our work is working with business and ops teams to get access to the data, fix data-quality issues, and (unsuccessfully) asking them to validate our models (mostly classical ML on pyspark). I do get to work on some POCs but they are often supposed to be very quick (on toy examples) and never get turned into formal projects because we don't have the hardware to support.

Now, this has been hindering my career a lot. I have tried to keep myself updated by reading papers, blogs etc. but don't have much practical experience. Because of the outdated things I have been working on, it's also been really hard to get interviews and switch jobs.

&#x200B;

**Actual Question:** 

**How do I get practical experience on more recent advances in ML (specially around transformer/diffusion models) with limited hardware.** I have tried working through annotated transformer, and nanoGPT. I also want to handle problems around increasing context and delve into LLMOps working on increasing context length, more faster and efficient attention mechanisms, fine-tuning techniques, quantization, RAG etc. I have a M1 Pro Macbook Pro with 16GB RAM at my disposal.  I can cut on my savings and get $100-200 a month to spend on cloud compute (don't live in the US, so that's a big amount for me).

It would be great if the wisdom of the crowds can give me some advice and list of resources (courses, blogs, open-source projects) to work through.

Also, **what can I do to get more attention from more ML-oriented teams in other companies.** Ultimately my goal is to get into big-tech or promising startups/mid-level companies.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171e6rz/feeling_obsolete_need_guidance_on_staying_relevant/,3,4,0.83,"[Comment(id='k3q4b5n'), Comment(id='k4ijlfe'), Comment(id='k3q50us')]"
171bocz,mattsverstaps,,2023-10-06 12:59:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171bocz/learning_theory_with_manifolds/,Learning theory with manifolds,"I saw there was a podcast episode where somebody talked about learning theory and it involved the word manifold and I really am interested in listening, anybody got a clue what that might have been?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171bocz/learning_theory_with_manifolds/,7,4,0.75,"[Comment(id='k3ppobh'), Comment(id='k3r1wor'), Comment(id='k3spnql'), Comment(id='k3rsicg'), Comment(id='k3ptcn5'), Comment(id='k3rukjd'), Comment(id='k3pyky3')]"
171mlns,spx416,,2023-10-06 20:19:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171mlns/plotting_precalculated_embeddings_using/,Plotting pre-calculated embeddings using tensorboard,"Hello, I have a file with embeddings already calculated and I want to use tensorboard to project those embeddings. I have no need for metadata at this point. I want to know how to do it, all the tutorials I have seen use their own machine learning model to calculate the embeddings and then save to a checkpoint but I don't need to do that. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171mlns/plotting_precalculated_embeddings_using/,0,1,1.0,[]
171lclg,Benekia,,2023-10-06 19:27:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171lclg/question_about_choosing_a_machine_learning/,Question about choosing a Machine Learning algorithm.,"Hello people,

(Please delete if this is not allowed here)

I am a third year undergraduate Cyber Security student that is preparing his dissertation proposal. The topic I aim aiming to explore is Keystroke Dynamics as a form of authentication. Our course doesn't teach us about data science, or Machine Learning, however I am attempting to grasp the basics to implement a simple piece of software, that can be used as proof of concept on whether or not it is possible to authenticate users by analyzing the way they type. Please understand I am not aiming to get any unfair help, rather some advice or guidance in the right direction.

**My goal:** I am not aiming to develop a fully accurate and top of the range program, fully optimized to measure this data as accurately as possible. Instead I'd like to simply prove it can be used, and potentially compare my findings to experts in the field. Additionally, my focus point will be looking into how it can be used in Cyber Security terms in conjunction with other forms of authentication or technologies such as Intrusion Detection Systems. While I am at it, I will also focus on storing the data in a safe manner, with encryption and privileged based access.

I thought of keeping the program simple, simply measuring short, fixed texts that won't exceed 30s-1m of typing. I'd like to train it over a period of few months to recognize me typing it, and then guessing right when I ask other users to type the same texts.

**So what's my issue?** I've been reading a few articles online, MSc thesis papers and books about Machine Learning and projects similar to mine. One in particular points toward using CNNs to achieve the desired goal. The issue is with many of these projects, they've gone all out in developing this software. I can't help but think maybe they are not the best sources to get the info I need as we have different aims. Perhaps they are picking more complicated algorithms to get the best possible results, and perhaps these algorithms will result to be too complicated for me for my desired goal.

**In short, for a simple task such as mine, would it be more efficient to use an easier to work with algorithm such as a Supervised one? Decision trees perhaps?**

I'm decent at programming, Python in particular. But ML is new to me and I don't want to bite off more than I can chew. Especially considering it's not the main focus point of my disso. I know Python has libraries to import that implement ML. Will my algorithm of choice greatly impact my goal? Are these algorithms truly difficult to implement in Python if you struggle to understand the concepts? Any advice regarding this matter would be great. Also if anyone knows of any good resources for my situation I'd love to read up some more.

Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171lclg/question_about_choosing_a_machine_learning/,4,1,1.0,"[Comment(id='k3sh24s'), Comment(id='k3tspeo'), Comment(id='k40m92f'), Comment(id='k40ma9n')]"
171f6y6,tdionis,,2023-10-06 15:24:29+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/171f6y6/mbptrack_tutorial_sota_3d_point_cloud_object/,MBPTrack Tutorial - SOTA 3D Point Cloud Object Tracking in 2023 for LiDAR & Radar - Supervisely,,learnmachinelearning,https://supervisely.com/blog/mbptrack-point-cloud-3d-object-tracking/,0,2,1.0,[]
171kozl,SaladChefs,,2023-10-06 19:00:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171kozl/tutorial_benchmarking_bark_texttospeech_on_26/,Tutorial: Benchmarking Bark text-to-speech on 26 consumer GPUs - Reading out 144K recipes," In this project, we benchmarked Bark text-to-speech across **26 different consumer GPUs.**

The goal: To get Bark to ***read 144K food recipes*** from [Food.com](https://food.com/)'s recipe dataset.

You can read the full tutorial here: [**https://blog.salad.com/bark-benchmark-text-to-speech/**](https://blog.salad.com/bark-benchmark-text-to-speech/)

Included: Architecture diagram, data preparation, inference server setup, queue worker, setting up container group & compiling the results

Code-blocks included in the tutorial.

**Words per dollar for each GPU:**

https://preview.redd.it/d4lg0wbwqmsb1.png?width=2000&format=png&auto=webp&s=e11da4d4f729da7acc8e5b412a7f909d180d3576

Although the latest cards are indeed much faster than older cards at performing the inference, there’s really a sweet spot for cost-performance in the lower end 30xx series cards.

Conclusions

* As is often the case, there’s a clear trade-off here between cost and performance. Higher end cards are faster, but their disproportionate cost makes them more expensive per word spoken.
* The model’s median speed is surprisingly similar across GPU types, even though the peak performance can be quite different.
* Salad has a lot of RTX 3060 GPUs available, based on their relatively low speed, yet huge number of inferences performed over the test.
* No matter what GPU you select, you should be prepared for significant variability in performance.
* Qualitative: While bark’s speech is often impressively natural sounding, it does have a tendency to go off script sometimes.

We’ve also made available [**audio from 1000 top-rated recipes**](https://github.com/SaladTechnologies/bark-benchmark/blob/main/outputs/1.md), paired with the script it was trying to read.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171kozl/tutorial_benchmarking_bark_texttospeech_on_26/,1,0,0.5,[Comment(id='k3sppm6')]
170qjx4,Gonduska,,2023-10-05 19:13:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170qjx4/what_level_of_math_really_needed/,What level of math really needed?,"I’m a 3rd year Physics student. I’m planning on getting into Data Science after graduation, so I plan on choosing my optional module from the CS course. They have a module called Machine Learning. The requirements are stated as follows: “strong math background (probabilities, calculus, linear algebra)”. 
In a Physics degree obviously we have learned and used all these extensively, but I still have a feeling they are on different ends of the spectrum, and might don’t have what they need.

What is the deal when it comes to the underlying math? Is it easy to pick up for someone with a numerical background, or I need the math modules that were tailored to a CS degree?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170qjx4/what_level_of_math_really_needed/,46,47,0.91,"[Comment(id='k3m8axa'), Comment(id='k3mcuu4'), Comment(id='k3mem2y'), Comment(id='k3mryu0'), Comment(id='k3mgvi9'), Comment(id='k3ngw0l'), Comment(id='k3odlap'), Comment(id='k3mfb12'), Comment(id='k3ms0oq'), Comment(id='k3nlbra'), Comment(id='k3o6aee'), Comment(id='k3rrxht'), Comment(id='k3plye0'), Comment(id='k3m8fmp'), Comment(id='k3m9nqn'), Comment(id='k3ok54q'), Comment(id='k3oxu9x'), Comment(id='k3pbbbm'), Comment(id='k3nkjz9'), Comment(id='k3plv39'), Comment(id='k3nksh8'), Comment(id='k3rtt7i'), Comment(id='k3nl785'), Comment(id='k3nleo0'), Comment(id='k3nln3t'), Comment(id='k3nlqi3'), Comment(id='k3nlfm2'), Comment(id='k3nlp9f'), Comment(id='k3nlxqj'), Comment(id='k3scs3f'), Comment(id='k3slkwa'), Comment(id='k3nliab'), Comment(id='k3u3s8t'), Comment(id='k3nqkbp'), Comment(id='k3sscmd'), Comment(id='k3nu846'), Comment(id='k3ognjo'), Comment(id='k3ppsih'), Comment(id='k3nmb0p'), Comment(id='k3vmllg'), Comment(id='k3u4hv0'), Comment(id='k3sd2il'), Comment(id='k3x8za3'), Comment(id='k3ufnt1'), Comment(id='k3xb9wp'), Comment(id='k3xfike')]"
171fwp8,Lakshmireddys,,2023-10-06 15:52:32+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/171fwp8/best_advanced_machine_learning_courses_you_might/,Best Advanced Machine Learning Courses you might know in 2023,,learnmachinelearning,https://codingvidya.com/best-advanced-machine-learning-courses/,0,1,0.67,[]
1717qxd,JorgeBrasil,,2023-10-06 09:22:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1717qxd/beta_readers_for_a_book_on_calculus_for_machine/,Beta readers for a book on calculus for Machine Learning,"Hello, 

I am seeking for some beta readers to give me feedback on a my second book on the mathematics for machine learning. The theme of this one is calculus. 

If some volunteers could read it and provide me with some feedback I will then offer a free copy of the full formatted and edited book.

The first book was on linear algebra and the name of the series is called Before Machine Learning.

&#x200B;

Many thanks in advance  


Jorge ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1717qxd/beta_readers_for_a_book_on_calculus_for_machine/,2,3,1.0,"[Comment(id='k3rjpez'), Comment(id='k7r2adw')]"
171czav,FinancialLeague3349,,2023-10-06 13:56:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171czav/i_have_this_assignment_where_i_need_to_use/,I have this assignment where I need to use unsupervised learning,"So, in this assignment there are some attributes/columns/features contains reading.
Based on these readings, I need to use unsupervised learning for clustering
In this case it is already given that there k clusters , so I have not used elbow method.
Train and test data have different number of columns 
So in train data I merged some number of columns by taking their average , so that train and test have equal number of columns.
Then I standardized the data 
Then tried with and without PCA.
After that I did kmeans and predicted the clusters for the test data.
But I think I am doing something wrong here ,or I am forgetting something fundamental.
Please help.
I cannot share the dataset I think coz then that would be plagiarism.
But I can learn ML from others ig.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171czav/i_have_this_assignment_where_i_need_to_use/,1,1,1.0,[Comment(id='k3r1cfo')]
171ati0,motorollo,,2023-10-06 12:17:41+00:00,False,,1696596876.0,False,True,False,/r/learnmachinelearning/comments/171ati0/wrap_my_own_api_library_in_a_gptlike_based_chatbot/,Wrap my own API library in a GPT-like based chatbot,"Hi everyone!
I am working on a project whose ultimate goal is to be able to chat with a chatbot that after a natural language request returns specific calls to library functions that implement calls to a tool's API.

A bit more into details: I have a tool that can be used by calling its HTTP API. In order to make these calls, I have built a library on top of the API, so as to simplify the calls and make them easier to use. I would like to have a chatbot whose model is trained on the library itself, so that, given a natural language request as input, it returns its translation into the library language. 

My first idea was to use OpenAI API service as a wrapper and eventually try other models in the future if I find a better and/or cheaper custom way to implement the chatbot.

My doubts are mainly 2:
1. Fine-tuning: which is the best way to fine-tune the OpenAI model for this use case?

2. Well formatted calls: how to avoid the chatbot from returning non-existing method calls or classes and stick with what is available in the library?

Any other suggestion outside the scope of the doubts are more than welcome.
Thank you very much in advance for every guy that will read the post.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171ati0/wrap_my_own_api_library_in_a_gptlike_based_chatbot/,14,0,0.5,"[Comment(id='k3piw3e'), Comment(id='k3qblj7'), Comment(id='k3r06ji'), Comment(id='k3pqpem'), Comment(id='k3qmerw'), Comment(id='k3pvweo'), Comment(id='k4f49ha'), Comment(id='k3q06yo'), Comment(id='k4ftxu7'), Comment(id='k3q5djm'), Comment(id='k3sl9z3'), Comment(id='k3q7jbq'), Comment(id='k3tt8j8'), Comment(id='k3q7ptt')]"
171anld,Old_Walk_628,,2023-10-06 12:09:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171anld/how_can_i_partially_deannotate_an_image_given_a/,How can I partially deannotate an image given a fully annotated image and orignal image?,If anything can you please tell me how to do this or any resources where I can learn how to do this?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171anld/how_can_i_partially_deannotate_an_image_given_a/,0,1,1.0,[]
171a13h,anramu,,2023-10-06 11:39:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/171a13h/get_experience/,Get experience,"Hi, is there a possibility to  work for free just to get experience? I have finished some courses in ML and wonder what should do to get ""real world"" experience.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/171a13h/get_experience/,2,1,0.6,"[Comment(id='k3xpuan'), Comment(id='k4izsne')]"
1711wqa,Relative_Winner_4588,,2023-10-06 03:22:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1711wqa/custom_llm/,Custom LLM,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1711wqa/custom_llm/,4,3,0.81,"[Comment(id='k3onbta'), Comment(id='k3p8xbt'), Comment(id='k3pej8v'), Comment(id='k3pg6nl')]"
1718tqa,Dracosky1,,2023-10-06 10:31:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1718tqa/is_i5_12th_generation_and_nvidia_rtx_3050_of_4_gb/,"Is i5 12th generation and nvidia rtx 3050 of 4 gb enough for ai, ml and dl project?","I need a laptop for my project where i will be using deep learning, machine learning and AI. So i want to know whether i5 12th generation and a 4 gb graphics is enough or not. If it is not enough then please suggest minimum requirements that i will need for this project",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1718tqa/is_i5_12th_generation_and_nvidia_rtx_3050_of_4_gb/,8,0,0.43,"[Comment(id='k3paeuw'), Comment(id='k3p6lfc'), Comment(id='k3pmin4'), Comment(id='k3pf79h'), Comment(id='k3rgsi2'), Comment(id='k3qabe9'), Comment(id='k3pniz9'), Comment(id='k3r4pjd')]"
1712tcn,DepressedDueToPudge,,2023-10-06 04:10:38+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1712tcn/is_this_playlist_on_youtube_enough_linear_algebra/,Is this playlist on YouTube enough Linear Algebra for ML? Essence of linear algebra,"
Hello everyone, I was wondering if this playlist is enough to learn at least the basics of Linear Algebra for ML, I know that there's no coding, but I'm interested in the concept of this Linear Algebra itself and after gaining some knowledge from this playlist, is it enough for me to know Linear Algebra for ML? If so, after this playlist, I'd like to learn Calculus and Statistics&Probability.

Thanks in advance!

Here's the playlist: https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&si=q_S2efOafN0lOrxW",learnmachinelearning,https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&si=q_S2efOafN0lOrxW,1,3,1.0,[Comment(id='k3w9qkw')]
1717tzz,Choweeez,,2023-10-06 09:28:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1717tzz/can_feature_selection_improve_performances/,Can feature selection improve performances ?,"I'm learning feature selection, partly thanks to this notebook:  
[https://www.kaggle.com/code/prashant111/comprehensive-guide-on-feature-selection](https://www.kaggle.com/code/prashant111/comprehensive-guide-on-feature-selection)  


**But I don't understand the fact that feature selection can improve performances of an algorithm.**

Of course, I get that it is very useful for reducing training time, for easier interpretation etc. But how can the algorithm be more performant with less data to work with ? Even if one feature is correlated 99% with another one, there is still information to gain. Same goes with 1% correlated feature with label.

I tried feature selection on the MNIST data set, removing >90% correlated features, and <5% correlated feature with labels. And it does reduces accuracy, precision and recall (for a random forest classifier).

**Is the feature selection only useful (in terms of performances) on very complex algorithms ? Or on very high dimensional dataset ?**  


Thanks for your help !",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1717tzz/can_feature_selection_improve_performances/,1,1,1.0,[Comment(id='k3p79j5')]
1711jxe,MetalZuna,,2023-10-06 03:04:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1711jxe/chatgpt4_system_prompts/,ChatGPT-4 System Prompts,"📣 Hey Reddit!  
Are you tired of mundane AI interactions? Here's something fresh for you—an open-source system prompt library with some truly unique experiences!  
1️⃣ Play Jeopardy with John Cleese as Your Host!  
Why settle for ordinary game-show hosts when you can have a comedy legend

Access games and more system prompt library on Github  
[https://github.com/MetalZuna/Snap](https://github.com/MetalZuna/Snap/tree/master/Snap_AI_Prompt_Framework_E-Book/3_Out_Of_The_Box_Prompts/System_Prompt_Library/13_ChatGPT_Games)

Let me know how these prompts work for you. Feedback is always welcome!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1711jxe/chatgpt4_system_prompts/,0,3,1.0,[]
1716ddf,OnlyProggingForFun,,2023-10-06 07:48:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/1716ddf/responsible_ai_an_experts_guide_to_ethics_and/,Responsible AI - An Expert's Guide to Ethics and Governance with Auxane Boch - What's AI Podcast Episode 20,,learnmachinelearning,https://youtu.be/APpB0lH8YLE,0,1,1.0,[]
1711czt,,,2023-10-06 02:55:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1711czt/should_i_go_allin_on_theory/,Should I go all-in on theory?,"I've been kind of torn on which part to go to. My first ML courses were almost completely theoretical stuff. But, I didn't understand them very well. I want to be a researcher, and if I recall, theory and maths is really important there. I have a pretty basic practical knowledge. Can clean up data a bit, if its not too messed up, and can import libraries, fit models etc. I'm not sure how important practical knowledge is. I plan on doing [fast.ai](https://fast.ai)'s deep learning course and Stanford's CS229A which iirc are more hands-on. 

But, after that I plan on going all out in theory, with math courses and maths books. Its mostly my opinion, but it feels like large part of an ML engineer's work, most of the practical stuff can be easily automated, if not now then in the future. So, I can focus more on other things. And I need to devote more time to the theory since I'm a bit slow when it comes to maths and I need to catch up.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1711czt/should_i_go_allin_on_theory/,0,2,1.0,[]
1711bqy,aoyiiiii,,2023-10-06 02:53:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1711bqy/do_loss_functions_have_to_be_in_between_0_1/,"Do loss functions have to be in between (0, 1)?","Hi, I wonder if loss functions have to be in between (0, 1)? I thought that L1 and L2 norm are not the case? Thanks in advanced.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1711bqy/do_loss_functions_have_to_be_in_between_0_1/,0,1,1.0,[]
17110mi,Suspicious_Employ_65,,2023-10-06 02:39:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17110mi/a_letter_from_a_political_scientist/,A letter from a political scientist,"Not a precise objective-oriented post. I just want to tell shortly my career and say something based on what I've seen here.

I come from economics and political sciences. Very good in math tho, I can compete against people with a STEM background, and that's how I got into DS curricuum Social sciences and computer sciences in my [M.Sc](https://M.Sc). 

(P.S. it's basically data management for social sciences even though it sounds fancy)

I wanted to briefly express how much everyone here is an asset, and how much we need people with those skills in every single field. This goes against me, but a PhD colleague of mine is demonstrating statistically what everybody thinks: 10 credits at Uni in philisophy or history or political science, they're not the same as 10 credits in any STEM subject. It's harder. Not always, not for everybody, but it si generally harder, and you dont really need any data to say this, right? 

I got into this because I was curious and still am, and it warms my hearth and inspire me to see how many young and/or older people are into this environement. I see one common fil rouge for all STEM backgrounds: I do believe most of the people understimate their capabilities. Coming from social sciences I've seen both sides. Social sciences are not useless, but maybe the top 1% it's actually useful. You guys with this capabilities and background do not often realize how useful you are. It's not about coding, it's not about the math, or the statistics part. You well undertsood 10% of each, you're more resourceful than so many coming from polisci/communication. Nothing against those subjects, they do create a way of thinking and a culture. But nothing you guys can't get.

Political sciences it's the prefect example: it's the least ""useless"" between the ""easy"" degress. But man, it is useless. What I'm studying now it's based on 20 credits I've done out of 180. In social sciences research, you have plenty of backgrounds from Data Science, Statistics, etc., and every now and then you find people like me. At best, an economist. Try the opposite way: go into STEM research, check how many are from social sciences...

Any thoughts?

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17110mi/a_letter_from_a_political_scientist/,0,1,1.0,[]
170zsb2,NoEntertainment6225,,2023-10-06 01:40:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170zsb2/trouble_copying_weights_from_pretrained_model_to/,Trouble Copying Weights from Pretrained Model to Another Model with the Same Architecture [R],"I'm currently working on a project where I'm trying to transfer pre-trained weights from one model to another model with the same architecture. Specifically, I'm working with Vision Transformers (ViTs), and I have a pretrained ViT model (vit\_imageNet) that performs well on ImageNet data.

I'm attempting to copy the weights from vit\_imageNet to my custom ViT model (vit\_b\_32\_c), which has the same architecture but hasn't been pretrained. My goal is to leverage the pre-trained knowledge for my task.

Here's a simplified version of my code:

&#x200B;

`# ... (model initialization and device setup)`

`# Get all keys from the pretrained model`

`keys_to_copy = list(vit_imageNet_dict.keys())[:]`

`# Copy values to my custom model`

`for key in keys_to_copy:`

`vit_b_32_c_dict[key] = vit_imageNet_dict[key]`

&#x200B;

The issue is that when I use vit\_imageNet for inference, it achieves around 80% accuracy, as expected from ImageNet pretraining. However, when I use vit\_b\_32\_c with copied weights, it only reaches 15% accuracy, which is similar to random weights.

I suspect there might be a problem with how I'm copying the weights. Can anyone suggest what might be going wrong or provide guidance on how to correctly copy weights between these models?

Any help or insights would be greatly appreciated. Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170zsb2/trouble_copying_weights_from_pretrained_model_to/,0,1,1.0,[]
170yzcf,TanakaMatt,,2023-10-06 01:02:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170yzcf/ethics_question/,Ethics question,"Dear data scientists of reddit, Today I'd like to ask you how you navigate some of the ethical issues that relate to data science, more specifically, how you deal with the perpetuation of social injustices by biases/reinforcement of biases in data bases/data analysis",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170yzcf/ethics_question/,2,0,0.5,"[Comment(id='k3ntbri'), Comment(id='k3nw9i9')]"
170t5ch,Sivarion,,2023-10-05 20:58:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170t5ch/how_to_design_model/,How to design model,"I learn AI and ML for a while now and I think I'm starting to grasp the basics, but there is one thing that I think nobody is explaining - how to design your models.

In most tutorials it's usually one of the two; ""Here you have pretrained model, so we will take that and..."" or ""So this is input layer, and then we do the basic stuff - embedding, transposition, rescaling, call for the 9th circle of hell, and then we process the output, you know how it goes"".

I have no idea how you suppouse to know all that. How do you know how many layers there should be? How big  I need to make them? How to change the input matrix?

Thanks in advance for all the resources :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170t5ch/how_to_design_model/,2,2,0.75,"[Comment(id='k3mvfer'), Comment(id='k3n038m')]"
170ligs,Lakshmireddys,,2023-10-05 15:54:43+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/170ligs/best_machine_learning_courses_for_beginners/,"Best Machine Learning Courses for Beginners, Advanced in 2023 -",,learnmachinelearning,https://codingvidya.com/best-machine-learning-courses/,0,5,0.73,[]
170yb91,sovit-123,,2023-10-06 00:31:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170yb91/hyperparameter_search_with_pytorch_and_skorch/,Hyperparameter Search with PyTorch and Skorch,"Hyperparameter Search with PyTorch and Skorch

[https://debuggercafe.com/hyperparameter-search-with-pytorch-and-skorch/](https://debuggercafe.com/hyperparameter-search-with-pytorch-and-skorch/)

&#x200B;

https://preview.redd.it/ojt0d09w8hsb1.png?width=1000&format=png&auto=webp&s=ff2313f72588a71c1d6ceb5afce082e793aabb7e",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170yb91/hyperparameter_search_with_pytorch_and_skorch/,0,1,1.0,[]
170u7pa,oniongarlic88,,2023-10-05 21:39:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170u7pa/how_would_you_make_a_model_to_play_this_game_and/,How would you make a model to play this game and make the most points?,"The game is:


Let us say there is a horizontal road and a dog, the dog can only move left or right on that road. The road is unlimited in width. 


The dog's movement is random, so maybe sometimes it moves to the left a long time, sometimes it moves to the right a long time, and sometimes it moves left and right in short bursts. Dog can also move left a long time with short bursts of going right then it continues to moving left (and the same is also true for going right).


Your task as the player is to follow the dog and get points by guessing the direction of the dog and up to how far he will go in that direction.


So if the dog has been moving right, and you entered a guess and said ""right"", and the dog moves 50meters to the right, you then say ""im done guessing"". you get 50 points.


But it can also be that the dog has been moving to the right, you entered and guessed ""right"", the dog moved 40 meters to the right then moved 20 meters to the left, you then said youre done guessing, you get 20 points. (you said ""im done guessing"" too late and so you lost some points).


If you guessed wrong, you can also get negative points, so if the dog is moving right, you guessed ""right"" but it suddenly went left, you waited and hoped it will go right again but it doesnt and it has been moving left for 90 meters, you then say ""im done guessing"". You get -90 points.



What algorithm would allow you to make maximum points for this type of game?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170u7pa/how_would_you_make_a_model_to_play_this_game_and/,5,1,0.67,"[Comment(id='k3n1bef'), Comment(id='k3n5w0g'), Comment(id='k3nayr1'), Comment(id='k3nfka4'), Comment(id='k3nq76m')]"
170f2h7,oniongarlic88,,2023-10-05 11:03:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170f2h7/in_reinforcement_learning_when_teaching_models_to/,"in reinforcement learning when teaching models to do forex or stock trading, how do you teach a model to hold a trade instead of exiting?","because if we use profit as our reward function, then any fluctuations in price would cause the model to close a trade immediately. how would one help an RL model learn to hold a trade? any ideas?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170f2h7/in_reinforcement_learning_when_teaching_models_to/,14,6,0.69,"[Comment(id='k3k5zi2'), Comment(id='k3kj44u'), Comment(id='k3kegh4'), Comment(id='k3np83p'), Comment(id='k3k6407'), Comment(id='k3khc5g'), Comment(id='k3k6kzk'), Comment(id='k3khnwq'), Comment(id='k3k75r8'), Comment(id='k3k7wdu'), Comment(id='k3ka2rs'), Comment(id='k3kb4yy'), Comment(id='k3kh4pf'), Comment(id='k3kiruf')]"
170hl7w,Combination-Fun,,2023-10-05 13:07:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170hl7w/autogen_from_microsoft/,AutoGen from Microsoft,"AI agents are AI systems that can exhibit capabilities such as conducting conversations, completing tasks, reasoning, and seamlessly interacting with humans. 

As frameworks like LangChain build Agents as a module in their framework, Microsoft is thinking way ahead. It has built **AutoGen**, a framework to enable seamless MULTI-agent conversation and collaboration to accomplish complex tasks by reasoning and working autonomously. 

Here is a video explaining the latest AutoGen framework from Microsoft: https://youtu.be/daigxHA2aYw?si=86alxsVZkRpz5Quv

Do you think multi-agents are the future of AI? Or will AI emerge in other ways? Let me know your thoughts.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170hl7w/autogen_from_microsoft/,3,4,1.0,"[Comment(id='k3kotte'), Comment(id='k3ntmug'), Comment(id='k3ku99t')]"
170slvf,cabaaa,,2023-10-05 20:36:07+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170slvf/custom_estimator_sklearn_how_to_fit_attributes/,"Custom estimator sklearn, how to fit attributes","I am lost on how to implement a custom sklearn regression estimator for predicting data that basically looks like a ReLu function on Python. The slope of the ""ReLu function"" needs to be fitted and its offset (afaik these are the ""attributes""?)

So I basically imagine it to be fitted like a LinearRegressor, but instead of the straight line, it uses the ReLu shaped function to be fitted.

How do I start fitting this? Am I even on the right track? The sklearn docs for custom estimators did not help me :(",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170slvf/custom_estimator_sklearn_how_to_fit_attributes/,2,1,1.0,"[Comment(id='k3myb1b'), Comment(id='k3ok7hg')]"
170s04p,phantomBlurrr,,2023-10-05 20:11:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170s04p/ideas_for_fun_projects_using_dqn_andor_ppo/,Ideas for fun projects using DQN and/or PPO?,"Hi, I have learned how to implement DQN/PPO and have a foundational understanding of the theory behind them. I am trying to gain a deeper understanding of these algorithms and think that seeing them in action would be very helpful. Does anyone have suggestions for projects that are good targets for these two algorithms?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170s04p/ideas_for_fun_projects_using_dqn_andor_ppo/,1,1,1.0,[Comment(id='k3mlh0i')]
170m8jl,Lost-Season-4196,,2023-10-05 16:24:07+00:00,False,,1696523238.0,False,True,False,/r/learnmachinelearning/comments/170m8jl/i_wanted_to_make_a_model_to_understand_a/,I wanted to make a model to understand a quadratic equations.,"I wanted to build a model to understand  quadratic equation relationships,in my case is was y = 3 \* (x\^2) + 4. I tried many different ways but couldn't figure out how to solve that question.

&#x200B;

    np.random.seed(0)
    a = np.random.randint(0, 100)
    b = 3 * (a**2) + 4
    
    a = torch.tensor([a], dtype=torch.float32)
    b = torch.tensor([b], dtype=torch.float32)
    
    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.p1 = nn.Parameter(torch.rand(1, requires_grad=True)) # 3
            self.p2 = nn.Parameter(torch.rand(1, requires_grad=True)) # 2
            self.p3 = nn.Parameter(torch.rand(1, requires_grad=True)) # 4
    
        def forward(self, x):
    
            return self.p1 * x**self.p2 + self.p3
        
    model = Model()
    criterion = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=0.0001)
    epochs = 1500
    
    for epoch in range(epochs):
        # Forward pass
        outputs = model(a.view(-1, 1))  
        loss = criterion(outputs, b.view(-1, 1))  
    
        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
        if (epoch + 1) % 1000 == 0:
            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')
    
    output:
    Epoch [1000/15000], Loss: 33692124.0000 
    Epoch [2000/15000], Loss: 33692004.0000
    Epoch [3000/15000], Loss: 33691884.0000 

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170m8jl/i_wanted_to_make_a_model_to_understand_a/,11,2,0.75,"[Comment(id='k3ow96p'), Comment(id='k3lnyco'), Comment(id='k3p0to9'), Comment(id='k3ltiuk'), Comment(id='k3lunhe'), Comment(id='k3lx7eh'), Comment(id='k3m2xz5'), Comment(id='k3mak06'), Comment(id='k3mfcpn'), Comment(id='k3mg3y0'), Comment(id='k3mhrqz')]"
170l07z,crossivejoker,,2023-10-05 15:33:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170l07z/fine_tuning_training_for_video_game_npc/,Fine Tuning Training For Video Game NPC Additional Context Questions,"I'm a professional developer whose been utilizing AI professionally and on the side for a year now. But even doing it professionally, I have not really jumped into anything like training yet as I've been more in the AI development of utilizing the AI within applications. For fun, I've been creating a text adventure with AI. So far I have stable diffusion running on the game to dynamically generate enemies, your character with armor you find, etc. I've found some great models to assist in story telling or changing scenarios based on your rolls, stats, and decisions. I've even created methods to store long term history with summarization techniques.

But I'm just a mere C# developer finding ways to use the AI in my applications. But for the first time, I have some real world use to train my own Lora. I've found plenty of videos on how to train the AI, but what I'm not sure about is the following scenario I wanted to make:

&#x200B;

    [
        {
            ""context"": {
                ""UserStats"": {
                    ""Charisma"": ""Displeasing"",
                    ""Beauty"": ""Ugly"",
                    ""Curses"": [""Sneezes all the time"", ""everything smells really bad""]
                },
                ""NpcStats"": {
                    ""Charisma"": ""Very charismatic"",
                    ""Beauty"": ""Gorgeous"",
                    ""Personality"": ""Very hard to please""
                },
                ""environment"": ""In a grand hall with a chandelier, elegant music plays in the background.""
            },
            ""instruction"": ""Given the stats and scenario, generate a dialogue."",
            ""input"": ""User: I think you should give me some gold because I'm quite charming."",
            ""output"": ""Assistant: With all due respect, I don't find your request or charm compelling enough.""
        }
    ]

So here's example json training I found online that I know is the normal format:  


    [
    
    	{
    
        		""instruction,output"": ""User: Do you have an extended warranty? \nAssistant: Why, yes I do!"",
    
        		""instruction,input,output"": ""User: %instruction%: %input%\nAssistant: %output%""
    
    	},
    
    	{
    
        		""instruction,output"": ""User: Your car's extended warranty has expired!\nAssistant: That is the worst!"",
    
        		""instruction,input,output"": ""User: %instruction%: %input%\nAssistant: %output%""
    
    	},
    
    	{
    
        		""instruction,output"": ""User: What kind of car do you have?\nAssistant: A 2004 Honda Civic"",
    
        		""instruction,input,output"": ""User: %instruction%: %input%\nAssistant: %output%""
    
    	}
    
    ]

But as you can see, in my training I am proposing, I formatted it to put instructions in, and added my own wording like UserStats, NpcStats, and Environment. I built a method where I can generate tons of test data which I'll spend a few weeks reading through and choosing or altering the data to help the fine tuning process have enough info to process but also have quality info. But my goal was to create some sort of instructions where the output made by the AI for the Npc makes decisions based on the stats of the user, npc, and environment. 

&#x200B;

There's actually a ton of different directions I can take this to accomplish what I'm trying to do. But I didn't want to spend weeks building fine tuning data where I made a format that doesn't even work. And I didn't want to spend weeks doing the normal format either that I know works from what I read if I knew I could have made it better.

&#x200B;

So honestly any input on whether what I did is even acceptable as training that I can input would be really helpful. And if it matters, I'm training Llama 2 models. The 13B and the 70B is what I'm training. As I have a rig built to handle AI. Especially after the crypto crash, I got my hands on a lot of 3090's lol. But Is what I showed allowed as I can't find anything about it online. If it's not allowed, as I said I have ideas, but I'm unsure if they're good ideas, so are there other methods or better methods than fine tuning a lora? I know you can switch characters and everything for the models, but this is more for the user to add context for the NPC and this is the basic concept I've been thinking about for the direction I'm considering. Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170l07z/fine_tuning_training_for_video_game_npc/,0,2,1.0,[]
170kt3a,kingabzpro,,2023-10-05 15:25:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170kt3a/5_free_platforms_for_building_a_strong_data/,5 Free Platforms for Building a Strong Data Science Portfolio,"Are you tired of sending out countless resumes without ever getting a response from recruiters? It's time to up your game by building an irresistible portfolio that hooks recruiters with these five free platforms. And the best part? It's incredibly easy to do! With these platforms, you can showcase your skills, experience, and projects in a visually appealing way that will make you stand out from the crowd. Don't miss out on this opportunity to take your job search to the next level. Start building your portfolio today!

[https://www.kdnuggets.com/5-free-platforms-for-building-a-strong-data-science-portfolio](https://www.kdnuggets.com/5-free-platforms-for-building-a-strong-data-science-portfolio)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170kt3a/5_free_platforms_for_building_a_strong_data/,0,2,1.0,[]
170mlx4,Amun-Aion,,2023-10-05 16:38:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170mlx4/would_you_expect_taking_the_min_of_a_cost_func/,"Would you expect taking the min of a cost func for sequential data batches to result in a model that ""learns""?","I have a very simple cost function that I am solving in two ways (I can actually just solve it in closed form, so I do that and then there's another version where I just use Scipy's minimizer to return the exact min). I am trying to run this optimization on batches of streamed data (e.g. I have some distributed set up where I only receive data so frequently and thus am minimizing each batch as the data comes in). My question is, would you expect this model's performance to IMPROVE over time? Naively, my first instinct was no, since we are just finding the model which minimizes the loss on a given streamed data batch, and the data batches (while presumably coming from the same data distribution) are otherwise ""independent"". Note that we throw out all the old data when a new data batch comes in, so it isn't getting to save this in memory anywhere. But on the other hand, I don't see how this streamed data is any different from batches in the ML sense of segments of data within the epoch as would be used with gradient descent (IIRC, Scipy's minimizer is just running some form of gradient descent). Is this sequential/streaming approach fundamentally any different from just using batches in ML (e.g. the model doesn't know the difference, right)?

I guess my point of contention is that I can somewhat see the argument that maybe with each new streamed data batch, you have a model that is slowly being better fit to the actual underlying data distribution (as opposed to the ""aliased"" distribution from the given streamed data batch). But it is not clear to me why the model would ""learn"" (continually improve in performance) instead of just continually overfit to each new streamed data batch? If my thoughts make sense, could anyone explain why (I'm assuming) this is incorrect? Additionally, I would assume that this has something to do with the size of the streamed data batch, and if it is possible to fit the underlying data distribution from a single batch then we wouldn't expect any performance improvement with incoming new batches?

I believe that even though we can solve in closed-form, since the data matrix D is a term in the equation, our ""closed-form optimal solution"" is optimal to that given data batch only (although presumably will perform well on data that is similar to the matrix D, although I am not sure to what extent that has to do with the the underlying data distribution from D and Dnew being the same/similar vs Dnew just being a slight perturbation or something to D). If we are solving in closed-form over and over again, would you still expect the model to ""learn"" and perform better over time? It seems like no in this case since it doesn't care/know anything about past/future data, and the model is entirely dependent on the current data matrix D?

FWIW my model is linear regression, I still don't have a very good understanding of at what point a problem goes from an ML problem to an optimization problem (AFAIK optimization is what the model is actually doing and there is much more theory here).",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170mlx4/would_you_expect_taking_the_min_of_a_cost_func/,1,1,1.0,[Comment(id='k3lpw9k')]
170la69,Equivalent_Set7923,,2023-10-05 15:44:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170la69/need_opinions/,need opinions..," 

I am a beginner in ML. I wanted to create a python package that would replace emojis with appropriate. Not like the literal meaning. But something like:

A face, usually purple, with devil horns, a wide grin, and eyes and eyebrows scrunched downward in the same manner as [😠 Angry Face](https://emojipedia.org/angry-face/) on most platforms. Google’s design is red and Facebook’s has black horns and green eyes.

Commonly used to convey mischief, naughtiness, and excitement or excellence (slang, *bad* or *wicked*). May also represent devils or devilish behavior, especially around [Halloween](https://emojipedia.org/halloween/). More playful and suggestive than its impish counterpart, [👿 Angry Face With Horns](https://emojipedia.org/angry-face-with-horns/).

I personally thought It could be helpful in social media analysis and chat analysis. stuff like that.

But I am not sure if it's required or if it woulf be actually benificial. Kindly give your opinions and thoughts.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170la69/need_opinions/,0,0,0.33,[]
170bnfd,SameItem,,2023-10-05 07:26:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170bnfd/the_optimal_way_to_stratify_a_numerical_target/,The optimal way to stratify a numerical target variable into a categorical one for a machine learning algorithm,"I have tabular data, the predictive variables are numerical and categorical and the target variable is a numerical one. Using the proper techniques I can make predictive models with R\^2=0.95.

Now let's imagine I want to test similar techniques by considering the predictive variable a categorical one, that is, making the regression problem a classificational one.

&#x200B;

The first thing I can do is for a number of labels, take the percentiles (For example if I want 4 different labels, I could take the quantiles)

The second thing is to study the distribution of the target variable, and, if let's say its a multinomial distrubution with 3 different modes where almost all data concentrates around those three ""peaks"" it's obvious that the most intelligent thing is to take three different labels centered in those modes (low, medium and high) . 

But now let's set out the next problem rigorously. Let's imagine that the target variable is the price of something. Let's imagine I decide to divide the target variable in 5 categories (Very cheap, cheap, medium, expensive and very expensive) asigning for each category a numerical range (let's say that for very cheap is below 20.000$)

It's obvious that If I make two prediction models, one a regressional one with the numerical variable and the other a classificational one with the stratify target variable in 5 labels, and I take one observation of the test set (with all its respective values of the predictive variables), there is a higher chance of classification sucess if i use the first model and I predict the numerical value of the price and  then assign it its respective label, that if I directly apply the classification model to the data

&#x200B;

This is obviously because when you divide the numerical target into labels you are losing information (it's not the same saying that a number is 34000 that a number lies between the range of 20000 and 40000. 

So my question is, how do I select the number of labels and what ranges in order minimize that information loss? Let's mind I have R\^2=0.95 so with the good choose of ranges, I must have a very high classification F1.

I think clusterization using the predictive variables can be very useful, but I don't know how to apply it well. 

&#x200B;

Sorry for the messy text, I think this could be redacted better but my English is limited. Any idea very appreciated. I think this kind of problems must have been considered before so if this issue have a name I can google I will thankful. 

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170bnfd/the_optimal_way_to_stratify_a_numerical_target/,2,3,1.0,"[Comment(id='k3juzim'), Comment(id='k3jv574')]"
170jmxo,Sonic2kDBS,,2023-10-05 14:37:41+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/170jmxo/why_do_i_think_bias_is_inevitable/,Why do I think Bias is inevitable?,,learnmachinelearning,/r/AI_ethics_and_rights/comments/16y6wk7/why_do_i_think_bias_is_inevitable/,2,0,0.33,"[Comment(id='k3kyde3'), Comment(id='k3kwcg1')]"
170etj8,passenger-of-life_,,2023-10-05 10:49:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170etj8/how_to_make_a_multilabel_classification_model/,How to make a multilabel classification model using vision transformers ?,"I want to use a pretrained model and customize it such that it classifies a given image on 3 classes. furniture, style and material. Like if I passed an image of modern wooden one seater sofa,  then it should be able to classify it as one seater sofa in furniture, wooden in material and modern in style. I can't find good resources to solve this. If there are any tutorials present. Please link them. Thanks in advance",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170etj8/how_to_make_a_multilabel_classification_model/,0,1,1.0,[]
170eg30,elMandarine,,2023-10-05 10:26:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170eg30/limeshap_what_is_the_model_that_they_evaluate/,LIME/SHAP. What is the model that they evaluate used for?,"Hello, I have to make an explainer for a MLP that I created with Keras and I don't understand XAI. When looking at LIME or SHAP models I see that the only things that they pick is the input to the model so, what is the model used for?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170eg30/limeshap_what_is_the_model_that_they_evaluate/,0,1,1.0,[]
1701rgh,NLPnerd,,2023-10-04 23:07:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1701rgh/fascinating_chat_with_lewis_tunstall_quantum/,"Fascinating chat with @Lewis Tunstall, quantum physicist turned ML engineer @HuggingFace! 🤖We discussed his journey from physics to ML, contributing to open source, few-shot learning with SetFit, scaling RL for alignment, and ""vibes testing"" chatbots. So much wisdom from this kind, humble ML pionee",[https://youtu.be/yS8pfqI7oaQ?si=xihMcUZgFQ0d-nb6](https://youtu.be/yS8pfqI7oaQ?si=xihMcUZgFQ0d-nb6),learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1701rgh/fascinating_chat_with_lewis_tunstall_quantum/,1,9,1.0,[Comment(id='k3ig03j')]
17026kl,Seankala,,2023-10-04 23:25:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/17026kl/what_factors_determine_gpu_usage_and_what_are/,What factors determine GPU usage and what are your tips for determining batch size?,"Obviously putting models and data onto GPU devices would cause them to use memory, but I've noticed that sometimes during the training/evaluation/inference process GPU usage would change here and there. What kind of factors are causing this? Is my script storing data somewhere that I'm not aware of?

Also, how should someone pre-determine a batch size so that it fits their GPU without worrying about memory issues? I recall a long time ago there was a tool that helped you automatically determine batch size, but I'm not sure if it's still being maintained.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/17026kl/what_factors_determine_gpu_usage_and_what_are/,5,6,0.88,"[Comment(id='k3jnx43'), Comment(id='k3iktz1'), Comment(id='k3ju6d9'), Comment(id='k3j3vhp'), Comment(id='k3m6u0h')]"
170cu52,Formal-Future-4408,,2023-10-05 08:44:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/170cu52/is_there_any_book_of_machine_learning_that_i_can/,Is there any book of machine learning that I can reference for my degree thesis?,"Hello, for my degree thesis I'm planing to apply different machine learning models to a tabular dataset. For that, I will need firstly to explain how does any model works. I'm interested specially in tree-based models and neural works. Are there good books with complete description of all models of machine learning?
There should be accesible so I can read them online.

 I prefer to reference those instead of blogs like medium.com that doesn't seem serious for a thesis.


Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170cu52/is_there_any_book_of_machine_learning_that_i_can/,3,0,0.5,"[Comment(id='k3k2ab0'), Comment(id='k3lgh5d'), Comment(id='k3o08eg')]"
170l31l,MetalZuna,,2023-10-05 15:36:41+00:00,False,,1696560200.0,False,True,False,/r/learnmachinelearning/comments/170l31l/ai_prompting/,AI Prompting,"📣 Excited to announce my new E-Book on the Snap AI Prompt Framework!🚀📘 This will guide you to create adaptable and effective system prompts for AI.🎯 Perfect for:AI enthusiast🤖Researchers🔬Developers👨‍💻Educators👩‍🏫🔗 [https://github.com/MetalZuna/Snap](https://github.com/MetalZuna/Snap) \#AI#ArtificialIntelligence#MachineLearning#NLP (Natural Language Processing)#GPT4#TechEbook#AIPrompting#SnapAIFramework#SystemPrompting

\---Useful Features:Prompt Concept Blocks for easy prompt visualizationMultiple Persona ManagementBehavioral Driven PromptingAcceptance Test Driven PromptingEasier to create, maintain, and optimize promptsSupport for Modular Prompting

Out of the Box Section:Lots of Out of the Box prompts for you to usePrompt TemplatesAnd much more!Visit GitHub Page for access to the E-Book and System Prompt Library.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/170l31l/ai_prompting/,2,0,0.29,[Comment(id='k3l7wf2')]
16zzzy3,Phi1ny3,,2023-10-04 21:58:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zzzy3/which_llm_is_best_for_analyzing_code_by_design/,Which LLM is best for analyzing code by design metrics?,"I'm working on a project, and I haven't decided which LLM to implement into my game.  The general idea is the game assesses what the player puts code in a terminal (language used is Python currently) based on a task/scenario/prompt, and after some time, the LLM will assess the code based on either the overall quality of the output, or on design metrics that the player is currently working on learning.  These are then quantified, and those stats are then fed into a procedural generation algorithm, which then outputs an in-game item for the user.  For an introductory level of programming, which LLM has been most accurate/thorough in analyzing code in this way?  I've looked into Bard, ChatGPT, and GitHub Copilot.  Are there other considerations you would recommend?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zzzy3/which_llm_is_best_for_analyzing_code_by_design/,2,4,0.83,"[Comment(id='k3hscn3'), Comment(id='k3im5zm')]"
16zw1ms,besabestin,,2023-10-04 19:21:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zw1ms/understanding_loss_function_of_language_models/,Understanding loss function of language models,"I have been wondering how in an auto regressive language model like GPT, the loss is calculated as if there is a definite one possibility. But logically a number of different possibilities can fit in there.

If the input is for instance:

\`John is very hungry. He went to a restaurant to get \_\_\_\_\`

then all kinds of answers could potentially fit in there. Burger, pizza...

So it isn't that important to get the loss value very close to 0 because that would imply overfitting. Or have I misunderstood something?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zw1ms/understanding_loss_function_of_language_models/,3,6,1.0,"[Comment(id='k3hca7g'), Comment(id='k3jcpun'), Comment(id='k3lryed')]"
1701fw0,sneaky2040,,2023-10-04 22:54:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1701fw0/book_recommendations/,Book recommendations,"Hey! 

Was just wondering if you could share your favorite book within ML/AI 

I am mainly looking for books in two categories: 

Broad ML/AI: Books that can help me understand how ML/AI is used in the practical world and also helps me understand the possibilities 

E.g: the coming wave (Suleyman), AI 2024 (Lee & Qiufan) 

Second category 

Hands on book: books that helps me develop my skills within ML, good books for beginners. 

Can be on machine learning, mathematics etc..

E.g Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems 

No bullshit guide to linear algebra. 

Any recommendation is appreciated :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1701fw0/book_recommendations/,0,2,0.67,[]
16zg8ij,CardinalMontanelli,,2023-10-04 06:56:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zg8ij/am_i_being_too_ambitious/,Am I Being too Ambitious?,"Hi everybody. I am a 2nd year undergrad CS student. 

So, in one of the classes that I am taking this year, the professor told us to group together in teams and pick some project to build a mobile app and present it, which will count as 100% of the course grade. 

Also, he told us that a team that built an app based on a regression model which predicts the equality of the air even managed to won a quite nice award last year. 

Since one of the team members and I personally have some history with leukemia,  I got quite excited and came up with an idea to build a classification model which would predict, based on the image of the blood cell, if the given cell is normal or abnormal (i.e, if the patient has blood cancer or not).

The question that has been bothering me ever since is if it is feasible for me to successfully train such a model, given my very limited knowledge, and close to zero experience in ML? All my knowledge comes from the Andrew Ng's Machine Learning Specialization, which I have completed recently.

I know that the idea is not novel or original, and that many other individuals have trained such a model, but I am not sure if I can manage to do it as my very first real-world project.

TL;DR: given that I have just completed ML specialization, and have no other experience, do you think it is a good idea to build an image classification model right away? Wouldn't it be too difficult as the very first project? 

I'd appreciate any feedback and advice

Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zg8ij/am_i_being_too_ambitious/,23,49,0.91,"[Comment(id='k3edn3d'), Comment(id='k3ejtjh'), Comment(id='k3eh2q6'), Comment(id='k3eg1zs'), Comment(id='k3f0w6p'), Comment(id='k3eiyai'), Comment(id='k3f1yhc'), Comment(id='k3epy2b'), Comment(id='k3g6ke6'), Comment(id='k3f2pli'), Comment(id='k3f7ekp'), Comment(id='k3g4kvy'), Comment(id='k3gbk41'), Comment(id='k3hi94x'), Comment(id='k3hlnqc'), Comment(id='k3lsa1c'), Comment(id='k3v9r4w'), Comment(id='k3etht7'), Comment(id='k3iuuhz'), Comment(id='k3l15e2'), Comment(id='k3hmmta'), Comment(id='k3le7vp'), Comment(id='k3lg0dy')]"
1701s8f,Informal-Beyond-5584,,2023-10-04 23:08:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/1701s8f/can_i_use_open_ai_api_to_handle_multiple_requests/,Can I use open ai api to handle multiple requests at once,"Hey I wanted to put in news articles for a website I’m building as part of a stock portfolio

It takes into account different articles and I want to read it in all at once if I say like 50 articles can it handle that amount ?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1701s8f/can_i_use_open_ai_api_to_handle_multiple_requests/,2,2,0.75,"[Comment(id='k3i24ab'), Comment(id='k3lemja')]"
16zvp0i,WaterdanceAC,,2023-10-04 19:07:00+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16zvp0i/poecom_now_lets_devs_query_other_poe_bots_has/,"Poe.com now lets devs' query other Poe bots- has Llama 2, code Llama, web search bot, GPTs, Claudes, etc.",,learnmachinelearning,https://developer.poe.com/server-bots/quick-start,0,4,0.84,[]
16zzo36,rzykov,,2023-10-04 21:45:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zzo36/do_you_like_quizzes_in_mlds_textbooks/,Do you like quizzes in ML/DS textbooks?,I’m working on the second edition of the DS book. And want to make GPT-based quizzes for each chapter via QtRcodes. Do you have some good examples of such quizzes you like? I have seen some good examples in Andrew NG’s ML courses. May be there are some good ones in textbooks.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zzo36/do_you_like_quizzes_in_mlds_textbooks/,1,2,0.75,[Comment(id='k3o8ngs')]
16zrcp8,Batteredcode,,2023-10-04 16:12:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zrcp8/i_need_to_cram_computer_vision_for_an_interview/,I need to cram computer vision for an interview,"So I've got an interview for a ML engineer role at a company that does a lot of computer vision stuff. I know the theory and I've done toy problems, e.g. mnist, but I've not done any real production stuff. There's going to be a live coding, open book style test and I want to be prepared.

My plan was to cover some more of the classic computer vision tasks, trying out a few different architectures but I'm wondering if anyone has any advice for things I need to make sure I know/am comfortable with?

Thanks in advance",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zrcp8/i_need_to_cram_computer_vision_for_an_interview/,6,4,0.7,"[Comment(id='k3gdpnd'), Comment(id='k3m3rp2'), Comment(id='k3gmio2'), Comment(id='k400slh'), Comment(id='k3gt5yh'), Comment(id='k3hacy0')]"
16zoans,dipranjanchatterjee,,2023-10-04 14:12:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zoans/september_updates_the_data_science_interview_book/,[September Updates] - The Data Science Interview Book Project,"[The Data Science Interview book](https://book.thedatascienceinterviewproject.com/) is a **completely online and free** resource which has been making steady progress over the months.

*I am also in the market for a job and all the prep I have been doing I am putting it in the book.*

The incremental updates in the book done in September are-

* Windows Function updated.
* A/B test page (WIP) added.
* SVR and OLS added in Regression page.
* Classification metrics updated with use cases.
* Optimizers and Optimization Criterion updated in Algorithm overview page.
* Model Building Overview page added.
* Naive Bayes added in classification.
* Many new SQL and Python problems added.
* Confidence Interval added in Central Limit Theorem.
* Coding Algorithms from scratch added in Python.
* Common hypothesis tests added.
* Neural Network section updated

Don't forget to show this project your ❤️ and support",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zoans/september_updates_the_data_science_interview_book/,0,5,0.86,[]
16znhpl,,,2023-10-04 13:38:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16znhpl/how_to_go_through_more_high_level_lectures/,How to go through more high level lectures,I've seen some courses like [https://youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G\_YQhOb](https://youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb) where the discussions seem to be pretty high level. There aren't many notes to take like in the more theory heavy courses like Stanford CS229. How am I supposed to watch these videos? Do I just watch and pay attention? Do I take what few notes I can? ,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16znhpl/how_to_go_through_more_high_level_lectures/,0,3,1.0,[]
16zqiiz,nonononottodayorever,,2023-10-04 15:40:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zqiiz/help_shape_the_future_of_machine_learning_take/,Help Shape the Future of Machine Learning: Take Our Short Survey and Let's Create Something Amazing Together!,"Hello Redditors in r/learnmachinelearning

We are the team behind **ML Workbench**, an upcoming integrated platform designed to streamline your entire machine learning lifecycle. From data preprocessing and model training to validation and deployment, we aim to make the process as seamless as possible.

But here's the thing: we need your insights to build something that truly resonates with the community and solves real-world problems.

📝 [**Click Here to Take the Survey**](https://docs.google.com/forms/d/1ABvGDcbkZRI45UpZPvKJkNSXBeUf8CDlwk6eVmkh1o8/edit)

Why Should You Care?

* **Unified Experience**: Imagine managing all your ML tasks in one integrated environment.
* **High-Performance Computing**: We're leveraging powerful A100 GPUs to accelerate your work.
* **User-Centric Design**: Whether you're a beginner or a pro, the platform is designed to cater to all skill levels.
* **Collaboration**: Built-in features to make team collaboration effortless.

What's in the Survey?

The survey contains questions about your current challenges, the tools you use, and what you'd love to see in an ML platform. It should only take about 5-10 minutes to complete.

Thank You Gift

As a small token of our appreciation, we're offering exclusive early access to the platform for selected participants. Don't miss this chance to be among the first to experience what we're building!

📝 [**Click Here to Take the Survey**](https://docs.google.com/forms/d/1ABvGDcbkZRI45UpZPvKJkNSXBeUf8CDlwk6eVmkh1o8/edit)

Your feedback is crucial for us to create a tool that we hope will make a significant positive impact in the machine learning community. Thank you for taking the time to read this post and participate in our survey.

Cheers, The ML Workbench Team",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zqiiz/help_shape_the_future_of_machine_learning_take/,0,2,1.0,[]
16zw25r,LucasSaysHello,,2023-10-04 19:21:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zw25r/thoughts_on_current_vector_db_landscape/,Thoughts on current Vector DB landscape?,"Hello,

What are your thoughts on current Vector DB offerings? For instance:

* Do you think the pricing for them is reasonable/viable?
* Do you think there’s a sufficient level of developer/user experience? What about for those who aren’t necessarily specialized in data?
* If you like a managed service, why do you prefer it over the open source alternatives?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zw25r/thoughts_on_current_vector_db_landscape/,0,1,0.6,[]
16zli1w,Skirlaxx,,2023-10-04 12:08:43+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zli1w/free_resources_to_train_a_model_for_a_long_time/,Free resources to train a model for a long time?,"Hey everyone!

Recently I finished my ""from scratch"" implementation of DeepMind's AlphaZero algorithm. 

I've already experimentally trained it on the game of Tic Tac Toe played on a 5x5 board with 3 pieces to win. This was to identify and correct any bugs and to find a ways to improve my implementation. While doing this I had a free trial credits on some server provider, so I had a free GPU equipped Linux machine I could SSH into. However that trial is now over and I still need to train the originally intended version of the model that plays on 10x10 board with 5 pieces to win. Since I made substantial changes to the implementation I need to rerun the hyperparameter search function as well. Even with the parallelization I've implemented, this still takes a long time. 

I am still a student and I unfortunately don't have enough money to afford to rent a GPU server for a long time. I love RunPod and I've used it in the past for a few hours to a day at a time. However, I can't afford to rent it for a week.

Also nor Google colab nor Kaggle notebooks will do for this project. 

• Colab has two issues for this use case.
    1. It requires you to be active and have a window open.
    2. You're instance has a time limit of 12 hours.
• Kaggle is the same but it has a limit of only 9 hours.

I can create a driver with something like Selenide for Java, run the window in headless mode and upload and setup the project automatically.

But I thought I'd ask you before going through the hassle, because maybe you know some free resources that I don't?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zli1w/free_resources_to_train_a_model_for_a_long_time/,2,3,1.0,"[Comment(id='k3g5731'), Comment(id='k3jeahg')]"
16zswwx,GrixisNow,,2023-10-04 17:15:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zswwx/consciousml_blog_mindful_ai_meets_productive/,ConsciousML Blog - Mindful AI meets Productive Living,"Greetings fellow ML practitioners !  


I've been finding myself more inclined towards writing lately and I wanted to share something I've been working on for the past weeks.

I recently updated the look and feel of my personal space: **ConsciousML Blog !**

Some updates about the blog:  
● Fresh, minimalist design.  
● Focusing more on consciousness and productivity - topics close to my heart.  
● Starting a newsletter for updates.  
● Planning to release one AI or productivity article every week.

The core purpose is still the same: A space to share my thoughts and my experiences in building machine learning solutions.

Check it out here: [https://blog.axelmendoza.fr/](https://blog.axelmendoza.fr/)  


Appreciate everyone who takes a moment to read. Any feedback to improve the medium would be greatly appreciated !",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zswwx/consciousml_blog_mindful_ai_meets_productive/,0,1,1.0,[]
16zskc4,meWhoObserves,,2023-10-04 17:01:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zskc4/how_can_i_apply_object_detection_and_image/,How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model?," So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!

So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found then it should return ""No object found"" or like that.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zskc4/how_can_i_apply_object_detection_and_image/,1,1,1.0,[Comment(id='k3ka0kc')]
16zjddj,Hefty-Salary7610,,2023-10-04 10:17:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zjddj/brand_new_to_ml_i_have_a_function_that_takes_an/,"Brand new to ML, I have a function that takes an array of binary values and returns an integer, how do I find the array that returns the lowest value?","I am not a software engineer but have a little bit of Python knowledge.

I was hoping someone could help me understand how difficult / time-consuming this task would be for somebody new to see if it would be worth the trouble. 

Basically I just have a function that accepts an array of 225 binary values and returns a single integer value. I am trying to find the binary array that would return the smallest value or close to it. 

How could I do this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zjddj/brand_new_to_ml_i_have_a_function_that_takes_an/,3,3,0.8,"[Comment(id='k3exysj'), Comment(id='k3he4wp'), Comment(id='k3hzgoc')]"
16zr2on,Purple_Vehicle_1983,,2023-10-04 16:02:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zr2on/dataset_of_english_typing_users_at_least_30/,Dataset of English typing users (at least 30 sentences per user),"Hi, I am looking for a dataset of English typing users (for biometrics approach). The most interesting for me is text (original typing) and assigning this text to the specific user. Does anyone know or has access to such dataset and would like to share it to me?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zr2on/dataset_of_english_typing_users_at_least_30/,0,1,1.0,[]
16zq3qd,1azytux,,2023-10-04 15:24:06+00:00,False,,1696434022.0,False,True,False,/r/learnmachinelearning/comments/16zq3qd/compatibility_of_transformers_version_4111_with/,Compatibility of transformers version 4.11.1 with Python 3.11,"I have an issue, while installing transformer version 4.11.1 library. Has anyone encountered it before? It seems like Python library error to me ...

 ```    
Collecting transformers==4.11.1
  Downloading transformers-4.11.1-py3-none-any.whl (2.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 15.8 MB/s eta 0:00:00
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (3.12.4)
Collecting huggingface-hub>=0.0.17 (from transformers==4.11.1)
  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 295.0/295.0 kB 23.4 MB/s eta 0:00:00
Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (1.23.5)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (23.1)
Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (2023.6.3)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (2.31.0)
Collecting sacremoses (from transformers==4.11.1)
  Downloading sacremoses-0.0.53.tar.gz (880 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 880.6/880.6 kB 32.9 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.11.1)
  Downloading tokenizers-0.10.3.tar.gz (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.7/212.7 kB 23.6 MB/s eta 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.11.1) (4.66.1)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.1) (2023.6.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.1) (4.5.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.1) (3.2.0)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.1) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.1) (2.0.5)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.11.1) (2023.7.22)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.11.1) (1.16.0)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.11.1) (8.1.7)
Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.11.1) (1.3.2)
Building wheels for collected packages: tokenizers, sacremoses
  error: subprocess-exited-with-error
  
  × Building wheel for tokenizers (pyproject.toml) did not run successfully.
  │ exit code: 1
  ╰─> See above for output.
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  Building wheel for tokenizers (pyproject.toml) ... error
  ERROR: Failed building wheel for tokenizers
  Building wheel for sacremoses (setup.py) ... done
  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=36b87a524e130fe23deb468911fe2184cc60a8e23d4eca52a6d7abce180dab62
  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb
Successfully built sacremoses
Failed to build tokenizers
ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects

```",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zq3qd/compatibility_of_transformers_version_4111_with/,2,1,1.0,"[Comment(id='k3fwhis'), Comment(id='k3fx3ep')]"
16zlgio,hopefull420,,2023-10-04 12:06:43+00:00,False,,1696421553.0,False,True,False,/r/learnmachinelearning/comments/16zlgio/is_there_such_things_as_learning_only_applied_ml/,Is there such things as Learning only Applied ML ?,"As much as i want to learn the fundamentals and deep underlying maths under ML algos it kind of bores me. When i was taking the ML speacialiszation(Deepelearning.ai) on coursera the lectures kind of bored me and after little while i would ahve just zoned out and just starring at numbers and equations being written.

The applied or practical side ML kind of excites me alot , so my question was : is there a role for people to just do applied ML and have very basic understanding of the underlying maths and lastly what would be the tools/Library I should work on to being a good ""**Applied ML Engineer**"" if that is a thing XD.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zlgio/is_there_such_things_as_learning_only_applied_ml/,31,0,0.5,"[Comment(id='k3fcqmo'), Comment(id='k3fm1k5'), Comment(id='k3hf2va'), Comment(id='k3f4au7'), Comment(id='k3geo9e'), Comment(id='k3gwojd'), Comment(id='k3hnj2o'), Comment(id='k3fo4nl'), Comment(id='k3f6v5d'), Comment(id='k3hjsvv'), Comment(id='k3h4cge'), Comment(id='k3hrcpy'), Comment(id='k3ih18w'), Comment(id='k3imjjf'), Comment(id='k3hjepc'), Comment(id='k3h8vht'), Comment(id='k3gi54d'), Comment(id='k3ggypy'), Comment(id='k3geqzv'), Comment(id='k3fjd55'), Comment(id='k3hnzxz'), Comment(id='k3gpopx'), Comment(id='k42yivl'), Comment(id='k3hqoav'), Comment(id='k3jxfaj'), Comment(id='k3gim2s'), Comment(id='k3gsut5'), Comment(id='k44cya2'), Comment(id='k3hr5th'), Comment(id='k3h0uxi'), Comment(id='k3hqe99')]"
16z8wg6,,,2023-10-04 00:43:39+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z8wg6/do_i_have_to_switch_majors_to_be_a_researcher/,Do I have to switch majors to be a researcher?,"I'm currently in EE undergraduate. The ML guide here says that I need to be in a CS or related field to be a researcher in ML. My CS major does have more relevant classes to machine learning, but I'm a bit far into EE, I'd prefer not to switch now, because that would waste a lot more money than I'd want to, and extend my undergrad life by a lot. 

Do I have to switch? Or is there a future in ML for me if I graduate in EE? I'm learning about ML stuff myself through books and online courses, but I'm not sure how useful they'll look. Will my potential employers look unfavourably on my EE degree if I applied for an ML engineer or researcher position?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z8wg6/do_i_have_to_switch_majors_to_be_a_researcher/,12,6,0.75,"[Comment(id='k3d90jk'), Comment(id='k3e4apu'), Comment(id='k3e6lh4'), Comment(id='k3ducqh'), Comment(id='k3f14ih'), Comment(id='k3da1cr'), Comment(id='k3f3slj'), Comment(id='k3ej1xo'), Comment(id='k3f0t79'), Comment(id='k3hbn4j'), Comment(id='k3hoqcm'), Comment(id='k3f0k5b')]"
16zgrxm,water2jar,,2023-10-04 07:30:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zgrxm/hi_all_i_am_aspiring_ml_engineer/,Hi all I am aspiring ML engineer,I am currently working as data scientist in startup called Pricelabs.  I was doing MLOps in my previous company Microsoft in the name of Data Scientist for 5 years. I have done my masters from IISc. I want to work as ML engineer role in managerial position. Where can I apply.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zgrxm/hi_all_i_am_aspiring_ml_engineer/,2,2,0.62,"[Comment(id='k3em5f3'), Comment(id='k3eszl0')]"
16zhz7q,elMandarine,,2023-10-04 08:49:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zhz7q/need_to_build_a_xai_model_to_explain_the/,Need to build a XAI model to explain the behaviour of an IDS [P]," Hello, I need help from someone that knows about XAI. I have to create a XAI model to intérprete the resulta of an AI model, an MLP, that works as an IDS classifier. I have no idea on how to do It and I have been completely blocked for 2.5 years. This is the final project of my career and I just don't know how to do It, and my tutor isn't very helpful. If anyone is able to help I would explain him what I have to do and would be very grateful.

Thanks for your help",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zhz7q/need_to_build_a_xai_model_to_explain_the/,4,1,1.0,"[Comment(id='k3hx4nk'), Comment(id='k3ieqv2'), Comment(id='k3k13q1'), Comment(id='k3ofeqe')]"
16zbcbf,Mysterious-Ear-9323,,2023-10-04 02:33:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zbcbf/analysis_of_football_matches/,Analysis of football matches,"For my college project, I'm planning to do an analysis of PL teamsusing heatmaps, statistics, player matchups etc. I want to know if this is actually feasible and if anyone knows the best sites to obtain the data from?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zbcbf/analysis_of_football_matches/,1,3,1.0,[Comment(id='k3e8mu6')]
16z25xa,Responsible-Ruin3615,,2023-10-03 20:14:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z25xa/best_environmentplatform_for_ml/,Best environment/platform for ML,What is the best (in terms of price/quality and user friendliness) platform for ML?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z25xa/best_environmentplatform_for_ml/,2,9,0.92,"[Comment(id='k3dhy11'), Comment(id='k3e49vx')]"
16zgngh,swesweee,,2023-10-04 07:22:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16zgngh/does_anyone_know_any_tools_that_helps_people/,Does anyone know any tools that helps people convert their python code into streamlit apps?,"I am a data scientist. I usually build ML models and convert them into streamlit apps. Does anyone know any tools that helps automatically convert my python/ML code into streamlit app so i can save the hassle.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16zgngh/does_anyone_know_any_tools_that_helps_people/,4,0,0.5,"[Comment(id='k3hfn3v'), Comment(id='k3mao1v'), Comment(id='k3mqtfs'), Comment(id='k3mrh7t')]"
16z0qde,KingAbK,,2023-10-03 19:16:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z0qde/nlp_specialist_as_a_career/,NLP Specialist as a Career?,"Hey Everyone, I am currently a Marketing Analyst.

I have good experience (3+) with SQL and Python (Pandas, Web scraping) and many analytics tool.

I am getting very interested in NLP. I have done some small tasks/projects related to NLP in past  like analysing sentiments of sentences, text similarity analysis, word vectors but I never took a very big project or thought of it as a career.

I am seeking some advice from industry professionals on how does it look like to build a career in NLP. Do companies have such requirements for NLP specialists, is it high paying career, and if someone can share a roadmap on how to expand my knowledge on NLP.

Thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z0qde/nlp_specialist_as_a_career/,9,8,0.83,"[Comment(id='k3bxhpp'), Comment(id='k3fmdej'), Comment(id='k3fj2nk'), Comment(id='k3gbzhl'), Comment(id='k3gbmho'), Comment(id='k3gc6ck'), Comment(id='k3in423'), Comment(id='k3jcrhk'), Comment(id='k3kneu4')]"
16ynbax,Amgadoz,,2023-10-03 09:37:48+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ynbax/why_is_the_batch_size_always_2x_and_not_2x/,Why is the batch size always 2^x and not 2x?,"In almost all the tutorials that I've read, they recommend using batch sizes that are 2\^x (i.e. 2, 4, 8, 16, 32, 64, etc).   
Why is this the case? Let's say my gpu can't fit 64 samples in one batch, should I set the batch size to be 32 even if the gpu can fit let's say 38 or 40 (which are multiples of 2 but not 2\^x)?  


If this is true, why?  


Thanks  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ynbax/why_is_the_batch_size_always_2x_and_not_2x/,9,43,0.94,"[Comment(id='k39hphd'), Comment(id='k39lr8w'), Comment(id='k3ay5tb'), Comment(id='k39jq70'), Comment(id='k3bo9m0'), Comment(id='k4fbu4e'), Comment(id='k39qcys'), Comment(id='k39pog0'), Comment(id='k3ajv9g')]"
16z50wq,P1atinumSword,,2023-10-03 22:04:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z50wq/stuck_on_thesis_project/,Stuck on Thesis Project,"Hi All, I am an undergrad electrical engineering student currently undertaking my thesis project which i will be completing in conjunction with a project i have been assigned at work. I am looking to model some of the sites plant using RNN, LSTM GRU etc and provide them with notes on methodology and further research etc on completion. I have installed PyTorch and relevant libraries and successfully run some example machine learning codes I have found online. I am struggling however with the knowledge that is required to make changes to the methods/mechanics in the code to change example scripts to suit my applications. What recommendations can you make for someone trying to work in this space that has no prior experience with machine learning? Any information would be greatly appreciated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z50wq/stuck_on_thesis_project/,1,4,0.83,[Comment(id='k3j7nd0')]
16z7fmy,MLquestionAccount,,2023-10-03 23:39:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z7fmy/what_are_some_effective_dimensionality_reduction/,"What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?","I am considering comparing mutual information scores, but I also don't think I understand MI well enough. 

For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is ""bad"" since this means X, Y would be redundant. I am not sure if my understanding here is correct. 

Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using ""present"" (1) and ""absent"" (0). The main issue I have run into doing this is that I am trying to then create a **distribution** to compare the features (such as seeing what percent of 1s and 0s I find in each feature), but here is the issue: 

Let's say that feature A has 50% 1s and 50% 0s, and feature B also has 50% 1s and 50% 0s. So, it will look as if the distribution of their values is identical, though it could be that feature A and B are ""opposites"":

Feat. A: [0, 0, 1, 1]

Feat. B: [1, 1, 0, 0]

So, I wonder if there is a better way to compare the distributions of the features once I have made the data ""present"" (1) and ""absent"" (0). 

I am also looking at making a Probability Density Function for each feature to compare them, but it's not clear to me how I would go about creating such a PDF for each feature given that I don't know what the probabilities associated actually are. Should I be binning the data then finding what percentage falls in these intervals?

______

Overall, I am looking for advice on where to find useful information on how to compare features for **unsupervised** feature selection, particularly in regards to how to use and compare mutual information scores, how to create PDFs for features, and how to compare distributions between features after they have been binned to avoid the problem I mentioned (with how [0, 0, 1, 1] and [1, 1, 0, 0] would appear to have the same distribution). 

Relevant textbook resources and other reliable source recommendations would be much appreciated. 

Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z7fmy/what_are_some_effective_dimensionality_reduction/,2,2,1.0,"[Comment(id='k3dklro'), Comment(id='k3dnnpm')]"
16yrnes,nn4l,,2023-10-03 13:15:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yrnes/performance_test_of_a_tesla_m40_from_ebay/,Performance test of a Tesla M40 from eBay compared to other GPUs,"Recently, I bought two used Tesla M40 24 GByte GPUs from eBay for about $250 including shipping from China. 

It took a while until I got them working because my mainboard is so old that it would not recognize them. I had to find a more modern PC first. Another drawback is that these GPUs are designed to be cooled by the massive airflow in a server case, they don't have their own fans. If used in a standard desktop case they would overheat within seconds. So I build a contraption with cardboard, duct tape and a vacuum cleaner to run some tests until I get a better case.

The test software is a loop that creates 10 stable-diffusion images. I have found a [simple implementation of stable-diffusion](https://github.com/schirmacher/pytorch-stable-diffusion) with a python test script to run it locally and a Jupyter notebook to run it on Google Colab.

Results:

|Type|VRAM|Performance|
|:-|:-|:-|
|Tesla M40|24 GByte|1.7 it/s|
|Tesla T4|16 GByte|1.7 it/s|
|Tesla GeForce GTX 1080 Ti|11 GByte|2.6 it/s|
|Tesla V100|16 GByte|6.5 it/s|
|Tesla A100|40 GByte|9.8 it/s|

Conclusion: the M40 is comparable to the Tesla T4 on Google Colab and has more VRAM. My GTX 1080 Ti is a bit faster but nowadays many models need much more VRAM and won't fit on that GPU. The disadvantage is the fact that one needs an extra fan or a server case to operate the M40 GPU.

If you have other hardware, run the test script and PM me with your findings, I will then update this table.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yrnes/performance_test_of_a_tesla_m40_from_ebay/,3,10,0.82,"[Comment(id='k3a76ur'), Comment(id='k3ebm6c'), Comment(id='k3ooq3p')]"
16z9dkw,tony_stark_9000,,2023-10-04 01:04:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z9dkw/keras_metric_implementation/,Keras Metric implementation,"I am working on a speech denoising problem using DNN. I am calculating my SNR ratio by the function below.  


    def calculate_snr(clean_signal, recovered_signal):
    
        clean_power = tf.reduce_sum(tf.square(clean_signal))
    
        noise_power = tf.reduce_sum(tf.square(clean_signal - recovered_signal))
    
        snr_db = 10 * tf.math.log(clean_power / noise_power) / tf.math.log(10.0)
    
        return snr_db

I am using keras api to create a model like this  


    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=learning_rate),metrics=[calculate_snr])
    

When I train it, I see that my SNR metric for validation is -7 and oscillates in that range. Whereas if I predict on xval input and then use that with the above function, It gives me 8.2. It is the same identical function and I have checked dimensions multiple times. I am not sure what is happening?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z9dkw/keras_metric_implementation/,0,1,1.0,[]
16yyzxl,CaptainJapeng,,2023-10-03 18:07:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yyzxl/how_to_to_force_transformer_to_give_more_weight/,How to to force Transformer to give more weight to certain tokens,"Hi, I'm developing an encoder-decoder based transformer model and I would like to ask if there are ways to incentivize or penalize certain tokens during training.

I'm working on a translation task where the encoder input must be decoded into its proper product name. I have labels such as brand, name, and unit of measure, etc which are available during training but not on inference.

Currently when predicting the brand portion (which usually appears early in the sequence) of the output, the heatmap shows that it does not give focus to the latter part of the encoder which produce an output that the brand and product name, and unit of measure does not belong to each other.

I was thinking if there's a way to force the transformer during training to give more weight to different token types other that its own. 

For example:
1. Brand tokens (decoder) should give more weight to name tokens (encoder) than other brand tokens (encoder) 
2. Name tokens (decoder) should give more to brand token (encoder) and unit of measure token (encoder) 

I'm using Pytorch, if that helps. 


Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yyzxl/how_to_to_force_transformer_to_give_more_weight/,0,3,1.0,[]
16z7xzq,Repeat-or,,2023-10-04 00:01:22+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16z7xzq/prompting_llama2_at_scale_with_gretel/,Prompting Llama-2 at Scale with Gretel,,learnmachinelearning,https://gretel.ai/blog/prompting-llama-2-at-scale-with-gretel,1,1,0.67,[Comment(id='k3cz8o0')]
16yywlm,NomadicBedouin,,2023-10-03 18:04:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yywlm/how_to_create_a_zeroshot_classifier_from_scratch/,How to Create a Zero-Shot Classifier from Scratch,"Hi,

I've used zero shot classifiers before. I want to create one using my own models. I have a general idea of how they work, but can't seem to find any sort of guidance out there on how to make one from scratch. Any pointers would be much appreciated.

Thanks in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yywlm/how_to_create_a_zeroshot_classifier_from_scratch/,0,2,1.0,[]
16ymuan,,,2023-10-03 09:06:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ymuan/are_online_courses_an_alternative_to_books/,Are online courses an alternative to books?,"I found that I learn better when I learn from online courses with video lectures. However, there seems to be much more material in ML related books, and lots of people recommend the books before the courses. So, are online courses a sufficient replacement for books, or is reading the books vital for understanding machine learning? If so, which books do you think are the most important to read, that aren't too complicated.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ymuan/are_online_courses_an_alternative_to_books/,8,9,1.0,"[Comment(id='k39fcsr'), Comment(id='k3eooc6'), Comment(id='k39o2vq'), Comment(id='k39xsuf'), Comment(id='k3acbe4'), Comment(id='k39o0dy'), Comment(id='k3a0afy'), Comment(id='k3ae9us')]"
16z2fjz,qhelspil,,2023-10-03 20:25:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16z2fjz/forex_is_there_fundemental_data_for_short_term/,forex : is there fundemental data for short term price prediction ?,"for short term trend/price prediction, technical indicators are mostly used for this purpose.

i could not find a paper on short term fundemental data for forex predictions.

by short term i mean hourly data or less. mine is 5 minute.

question: what features can i use for shorter term trend prediction, besides technical indicator?

thanks for hlep",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16z2fjz/forex_is_there_fundemental_data_for_short_term/,0,1,1.0,[]
16yz1bo,Prism42_,,2023-10-03 18:09:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yz1bo/looking_to_do_at_home_ml_on_a_4090_and_have/,Looking to do at home ML on a 4090 and have several questions about CPU/RAM/Dual GPUs etc.,"I am looking to run at a 4090 and ML at home.

My questions are about relevance of other build components. How relevant is a CPU to this? Is it to be expected I would see any difference between i7 13700k and i9 13900k? What about RAM frequency between ddr4 and ddr5? What about RAM size? 

Also, how feasible is it to run multiple GPUs, say if I got a second 4090 in the future? Is it possible to run ML with different GPU models, say a 4070ti and a 4090?

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yz1bo/looking_to_do_at_home_ml_on_a_4090_and_have/,0,1,0.67,[]
16yyllp,Sarah_Yack,,2023-10-03 17:52:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yyllp/computer_vision_model_assistance/,Computer Vision Model Assistance,"I've been working on a personal computer vision project to try to teach myself machine learning. It's supposed to be a multi-class classification to determine whether a picture is a Macaw, a bird, or not a bird, and after weeks of errors and fiddling with it, I finally got it to actually run. However, now I'm running into an issue with it completely underfitting and the cost only going down infinitesimally. Like from 1.0989688612388155 to 1.098662997382809.

A little background on the structure of the model: I've ranged from 5-8 layers (currently on 8), the learning rate was originally 0.0075, but I tried upping it to 0.1, and still nothing changed. Originally, I was simply using the entire dataset for training, but I tried introducing mini-batches (64 size) with gd momentum. That didn't help, so I swapped gd with momentum for the adam optimizer, but now my cost function is throwing errors at me because my shapes are mismatching ((3,27), (100,27)).

As for my dataset, it's 30 images for each class so 90 total, all resized to 229x229, greyscaled, and then I flattened and standardized my X\_train, etc sets. My splitting function currently is creating two sets of 27 examples and the third with 36.

I'm currently a really beginner learner, and I'm just doing the [DeepLearning.ai](https://DeepLearning.ai) Coursera courses. I have no background in calculus, although I feel like I've grasped the basics (sort of). I've tried looking it up trying to find the best way to go about everything, but all the resources seem tailored to those with a CS degree or at the very least who have a pretty good solid grasp of Calculus, which I very much don't. If you would like to try to untangle my mess of a modebase (I very much recommend you don't, lol, if you value your sanity, as I've surely lost mine by now), this is the link to it on GitHub: [https://github.com/sarahyack/MacawProj](https://github.com/sarahyack/MacawProj)

Alot of the code was written using code I did during programming assignments in the Deep Learning Specialization, and I have turned to ChatGPT for help on multiple occasions.

I'm very much running out of motivation, and just hanging on with pure stubbornness at this point, so I would very much appreciate any advice you guys may have, or any resources that you can share that might help me.

Thanks so much in advance!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yyllp/computer_vision_model_assistance/,3,0,0.5,"[Comment(id='k3by5qf'), Comment(id='k41zjoi'), Comment(id='k3lz6rz')]"
16ystom,Responsible-Log2173,,2023-10-03 14:04:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ystom/number_of_tokens_2331_exceeded_maximum_context/,Number of tokens (2331) exceeded maximum context length (512) error. Even when model supports 8k Context length when running a model on AWS sage maker studio lab.,"I've loaded Mistral7b on aws sagemaker which has a context length 8k.

&#x200B;

But I'm getting error :

`Number of tokens (2332) exceeded maximum context length (512).`

&#x200B;

The error comes out as if the model is continuously throwing it as output. ill post the error image attached to this post.

The error comes on line:

&#x200B;

`print(llm(""""""{Something with 3000 tokens}""""""))`

with context length of 8k tokens of the model, how can number of tokens (2332) exceeded maximum context length (512) error arise.

&#x200B;

&#x200B;

The code I'm using is;

imports :

\`\`\`

`# Base ctransformers with no GPU acceleration`

`!pip install ctransformers`

`# Or with CUDA GPU acceleration`

`!pip install ctransformers[cuda]`

`# Or with AMD ROCm GPU acceleration (Linux only)`

`!CT_HIPBLAS=1 pip install ctransformers --no-binary ctransformers`

`# Or with Metal GPU acceleration for macOS systems only`

`!CT_METAL=1 pip install ctransformers --no-binary ctransformers`

&#x200B;

\`\`\`

&#x200B;

Code to load and run model;

\`\`\`

`from ctransformers import AutoModelForCausalLM`

&#x200B;

`# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.`

`llm = AutoModelForCausalLM.from_pretrained(""TheBloke/Mistral-7B-v0.1-GGUF"", model_file=""mistral-7b-v0.1.Q5_K_M.gguf"", model_type=""mistral"",gpu_layers=0)`

`print(llm(""""""{Something with 3000 tokens}""""""))`

\`\`\`

Im using AWS Sagemaker Studio lab notebook that provides CPU  :

&#x200B;

instance - t3.xlarge

vCPUs - 4

memory - 16GB

[error](https://preview.redd.it/h72em7r8vzrb1.png?width=856&format=png&auto=webp&s=df96d96fbc4ce89dec90190649cd6023714b77f9)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ystom/number_of_tokens_2331_exceeded_maximum_context/,0,2,1.0,[]
16yskiy,spmallick,,2023-10-03 13:54:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yskiy/semantic_segmentation_using_kerascv_deeplabv3/,Semantic Segmentation using KerasCV DeepLabv3+,"DeepLabv3+ is a prevalent semantic segmentation model that finds use across various applications in image segmentation, such as medical imaging, autonomous driving, etc. KerasCV, too, has integrated DeepLabv3+ into its library. We'll learn how to leverage DeepLabv3+ and fine-tune it on our custom data. Specifically, we will use the following ImageNet pre-trained backbones as feature extractors for fine-tuning DeepLabv3+:

* **ResNet50\_V2**
* **EfficientNetv2\_small**

Finally, we will also compare the results across these models.  
[https://learnopencv.com/kerascv-deeplabv3-plus-semantic-segmentation/](https://learnopencv.com/kerascv-deeplabv3-plus-semantic-segmentation/) ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yskiy/semantic_segmentation_using_kerascv_deeplabv3/,0,2,1.0,[]
16yrtis,franticpizzaeater,,2023-10-03 13:22:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yrtis/difficulty_with_paper_implementations_on_google/,Difficulty with paper implementations on google colab,"Hi, I am a mechanical engineer, I learnt about ML/DL though online courses and books. All of which used some variation of Jupyter notebook. My knowledge of code can be lacking sometimes, since I am not from CS background.

&#x200B;

Lately, I am trying to implement some computer vision paper codes on newer samples. I understand the papers, and the underlying mechanisms. However, I fail to decipher the codes provided with the associate repository. Usually, these repository contains information on how to recreate the experiment on some specific data using shell. But I am using google Colab for this purpose, as I don't have access to GPU, and I found it impossible to recreate the experiments in the google Colab, using shell commands, let alone extend it to newer samples.  


I would appreciate some help in this regard, I haven't done this before, and there aren't really any tutorial/resource on how to do this. Ideally, what I am trying to do is separate the model, input some images, get the output, and interpret it. I am stuck, and I would really appreciate some help or advice in this regard. Right now I am trying to work with this paper, [meta ood](https://github.com/robin-chan/meta-ood)  


Thanks in Advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yrtis/difficulty_with_paper_implementations_on_google/,0,2,1.0,[]
16yw4iv,BrightCold2747,,2023-10-03 16:14:50+00:00,False,,1696786324.0,False,True,False,/r/learnmachinelearning/comments/16yw4iv/build_error_for_tenslorflowlite_when_following/,Build error for tenslorflow-lite when following Raspberry Pi's postproccessing tutorial,"For a few days now I just used openCV because the tensorflow-lite problem was annoying me so much. I went back and updated this post a few days later after resolving my initial issue, but it still won't quite finish compiling.

I'll update the post with the process.

\---------

I've been looking to add more functionality to my raspberry pi (64 bit, bullseye) security camera system by adding object detection, and I wanted to start out by  following their openCV and tensorflow-lite tutorials to add post-processing to libcamera's apps (libcamera-vid etc)

I followed the tutorial: [Install Tensorflow-lite](https://lindevs.com/install-precompiled-tensorflow-lite-on-raspberry-pi/). [Compiling and installing opencv with their script.](https://qengineering.eu/install-opencv-on-raspberry-64-os.html)

If you just follow the guide from this point, the when you build libcamera-apps, the build will fail to find the tensorflow-lite dependency. I resolved this by generating a custom pkg-config file.

    libdir=/usr/local/lib/
    includedir=/usr/local/include/tensorflow/
    
    Name: TensorFlow Lite
    Description: TensorFlow Lite - A lightweight machine learning library
    Version: 2.6.0  # Replace with the actual version number
    
    Requires:
    Libs: -L${libdir} -ltensorflow-lite  # Specify library name and path
    Cflags: -I${includedir}  # Specify include directory

Save the above to something like ""tensorflow-lite.pc""

And copy it to the pkg-config directory (for system-wide installation anyway)

    sudo cp tensorflow-lite.pc /usr/lib/pkgconfig/

[Then, built  libcamera, libepoxy and libcamera apps.](https://www.raspberrypi.com/documentation/computers/camera_software.html#building-libcamera-and-libcamera-apps) And the build config gives the green light

    libcamera-apps 1.2.2
    libcamera
    location             : /usr/local/lib/aarch64-linux-gnu
    version              : 0.0.5
    Build configuration
    libav encoder        : NO
    drm preview          : YES
    egl preview          : YES
    qt preview           : YES
    OpenCV postprocessing: YES
    TFLite postprocessing: YES

But compilation of libcamera-apps (libcamera-detect) will still ultimately fail

    user@raspberrypi:~/libcamera-apps $ meson compile -C build
    INFO: autodetecting backend as ninja
    INFO: calculating backend command to run: /usr/local/bin/ninja -C /home/user/libcamera-apps/build
    
    ninja: Entering directory `/home/user/libcamera-apps/build'
    
    [42/49] Compiling C++ object apps/libcamera-detect.p/libcamera_detect.cpp.o
    FAILED: apps/libcamera-detect.p/libcamera_detect.cpp.o 
    
    c++ -Iapps/libcamera-detect.p -Iapps -I../apps -I. -I.. -I/usr/local/include/libcamera -I/usr/include -fdiagnostics-color=always -Wall -Winvalid-pch -Wextra -Wpedantic -Werror -std=c++17 -O3 -pedantic -Wno-unused-parameter -faligned-new -D_FILE_OFFSET_BITS=64 -Wno-psabi -mfpu=neon-fp-armv8 -ftree-vectorize -DLIBDRM_PRESENT=1 -DLIBEGL_PRESENT=1 -DBOOST_ALL_NO_LIB -MD -MQ apps/libcamera-detect.p/libcamera_detect.cpp.o -MF apps/libcamera-detect.p/libcamera_detect.cpp.o.d -o apps/libcamera-detect.p/libcamera_detect.cpp.o -c 
    ../apps/libcamera_detect.cpp
    ../apps/libcamera_detect.cpp: In function ‘void event_loop(LibcameraDetectApp&)’:
    ../apps/libcamera_detect.cpp:110:60: error: no matching function for call to ‘BufferReadSync::BufferReadSync(LibcameraDetectApp&, libcamera::FrameBuffer*&)’
      110 |    BufferReadSync r(app, completed_request->buffers[stream]);
          |                                                            ^
    In file included from ../core/libcamera_app.hpp:33,
                     from ../apps/libcamera_detect.cpp:12:
    ../core/buffer_sync.hpp:30:2: note: candidate: ‘BufferReadSync::BufferReadSync(LibcameraApp*, libcamera::FrameBuffer*)’
       30 |  BufferReadSync(LibcameraApp *app, libcamera::FrameBuffer *fb);
          |  ^~~~~~~~~~~~~~
    ../core/buffer_sync.hpp:30:31: note:   no known conversion for argument 1 from ‘LibcameraDetectApp’ to ‘LibcameraApp*’
       30 |  BufferReadSync(LibcameraApp *app, libcamera::FrameBuffer *fb);
          |                 ~~~~~~~~~~~~~~^~~
    ../core/buffer_sync.hpp:27:7: note: candidate: ‘BufferReadSync::BufferReadSync(const BufferReadSync&)’
       27 | class BufferReadSync
          |       ^~~~~~~~~~~~~~
    ../core/buffer_sync.hpp:27:7: note:   candidate expects 1 argument, 2 provided
    [45/49] Compiling C++ object apps/libcamera-raw.p/libcamera_raw.cpp.o
    ninja: build stopped: subcommand failed.
    

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yw4iv/build_error_for_tenslorflowlite_when_following/,1,1,1.0,[Comment(id='k3av0sk')]
16ygrph,TheGunner2,,2023-10-03 03:01:04+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ygrph/learning_machine_learningai/,Learning Machine Learning/AI,"So its a bit late i am currently thinking that where am currently working at am wasting my potential and i can go for a little more challenging and exciting stuff which requires everyday research and knowledge.
I currently work as an Oracle DBA for 2 years and i am thinking to change my field from DBA to machine learning and AI, i think that machine learning is more challenging than any other field but  have no idea where to begin with machine learning what sources to follow to know more about it. I have a Bachelors degree in computer application.

So basically need suggestions on where to start and what are the skills required for it",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ygrph/learning_machine_learningai/,19,10,0.86,"[Comment(id='k38l85k'), Comment(id='k39p4gq'), Comment(id='k3alrty'), Comment(id='k38ydgp'), Comment(id='k392ld8'), Comment(id='k39pg89'), Comment(id='k3a512y'), Comment(id='k3ctrko'), Comment(id='k48dyzs'), Comment(id='k3kl2n2'), Comment(id='k395ocq'), Comment(id='k39p6qi'), Comment(id='k3a6h23'), Comment(id='k3cic2i'), Comment(id='k3cnmoq'), Comment(id='k3d79tw'), Comment(id='k3d5w9y'), Comment(id='k3ewovf')]"
16ytls9,Agreeable_Tutor2969,,2023-10-03 14:36:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ytls9/suggestion_for_projects/,Suggestion for projects,"I am thinking of doing machine learning projects to showcase my skills to my future employers. 
Can you suggest projects possible projects. 

P.S. would love to partake in research projects and collaborations",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ytls9/suggestion_for_projects/,0,1,0.67,[]
16ym8g0,stelo55,,2023-10-03 08:26:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ym8g0/road_to_learn_more_about_bayesian_optimization/,Road to learn more about Bayesian Optimization,"Hi folks. 

I would like to learn more about Bayesian Optimization. I do understand it on a very basic level and have seen some use cases. 

However, I would like to dive a bit deeper and understand what's going on under the hood. 

If you had to create a learning roadmap for yourself, what would be topics you would look into or resources you would use? 

I guess some topics I should cover are probabilistic modeling, gaussian processes and acquisition functions?! 

And are there any resources you could recommend? 

Thank you very much.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ym8g0/road_to_learn_more_about_bayesian_optimization/,1,3,1.0,[Comment(id='k39oj6c')]
16yq3r7,bumurzokov,,2023-10-03 12:04:37+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16yq3r7/dropbox_ai_chat_with_llm_app/,Dropbox AI Chat with LLM App,,learnmachinelearning,https://github.com/pathway-labs/dropbox-ai-chat,0,1,1.0,[]
16yi0td,jonko_ds,,2023-10-03 04:03:28+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16yi0td/im_currently_training_an_ai_to_play_wii_sports/,I'm currently training an AI to play Wii Sports bowling,,learnmachinelearning,https://www.youtube.com/watch?v=7hRVeR685f8,1,4,1.0,[Comment(id='k39qnnr')]
16yp7ca,divyanshkg,,2023-10-03 11:20:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yp7ca/need_some_ml_ideas_for_beginners/,Need some ML ideas for beginners,"I need some ideas a little above beginners level, like a fatigue detecter using a camera to detect signs of fatigue on your face. I suggested this idea but someone else is already making this in my class. So any suggestions quick pls",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yp7ca/need_some_ml_ideas_for_beginners/,0,0,0.5,[]
16youmf,SlyShot42,,2023-10-03 11:01:51+00:00,False,,1696331338.0,False,True,False,/r/learnmachinelearning/comments/16youmf/mlds_career_guidance/,ML/DS Career Guidance,"Hi everyone,

I recently graduated with a Bachelor's degree in Applied Mathematics and my long-term career goal is to work as a Machine Learning Engineer (MLE). The issue is that I am still in the job market with minimal experience, and have an incomplete understanding of Machine Learning (ML) and Deep Learning (DL) algorithms. Now that debt repayments have begun, I am in a somewhat frantic situation to find employment.

I am attempting to determine the best course of action at this point, but am having trouble focusing my efforts. I recognize that nearly all MLE positions require a graduate education, and I am contemplating whether pursuing graduate school is my best and only option for achieving my career goals. Alternatively, I am considering whether it is feasible for me to start as a Data Scientist or Data Analyst and transition into an MLE role in the future. I'd prefer the latter, as it would allow me to begin managing my student loans, and I haven't adequately prepared for graduate school during my undergraduate studies, having no research experience at this point.

If pursuing the Data Scientist/Analyst pathway is viable, I am unsure of what to focus on. I have a solid understanding of linear regression from my econometrics coursework in college, and can implement a basic Artificial Neural Network (ANN) in Pytorch. Thus, should I concentrate on learning the classic non-DL algorithms (such as logistic regression, decision trees, SVM, etc.) and work on projects focused on these algorithms, or should I aim to engage in a project centered around a topic I am interested in? Alternatively, should I delve deeper into learning DL algorithms and work on projects related to them, or should I attempt to decipher and implement the contents of published ML research papers (I am able to grasp the mathematics to a certain extent but may lack some conceptual background)? I am striving to choose the approach that is most optimal and will enhance my distinctiveness as an applicant.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16youmf/mlds_career_guidance/,0,1,1.0,[]
16ygcyt,BluebirdThen3487,,2023-10-03 02:41:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ygcyt/how_can_i_learn_machine_learning_for_a_specific/,How can I learn Machine Learning for a Specific Research Application,"I am a high schooler doing an ML mentorship at a University and I came up with an idea for a project after reading tons of research and my mentors liked it. The only problem is I know very little about machine learning aside from a little hackathon project I did last year which was just copying code from the internet, combining it with other code from the internet, and asking a senior for help. I took an introductory AI class but How can I learn enough machine learning to do my project very quickly?   


My proposed project uses XAI to explain why a CNN that diagnoses diseases from retinal images comes up with the diagnoses it does.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ygcyt/how_can_i_learn_machine_learning_for_a_specific/,5,4,0.84,"[Comment(id='k38z7f5'), Comment(id='k38srgj'), Comment(id='k399qjm'), Comment(id='k39ew7y'), Comment(id='k39vs36')]"
16yjz96,Wildest_Dreams-,,2023-10-03 05:57:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yjz96/can_someone_share_the_chatgpt_bonus_of_machine/,"Can someone share the ChatGPT bonus of Machine Learning A-Z™: AI, Python & R + ChatGPT Bonus [2023]","I could not complete it in time to be eligible to get the bonus of [Machine Learning A-Z™: AI, Python & R + ChatGPT Bonus \[2023\]](https://www.udemy.com/course/machinelearning/).  
It would be great if you could attach a link to download the same.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yjz96/can_someone_share_the_chatgpt_bonus_of_machine/,1,2,1.0,[Comment(id='k3exwfw')]
16y5bko,Pan4TheSwarm,,2023-10-02 19:09:14+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16y5bko/whats_the_field_of_mlai_look_like_professional/,Whats the Field of ML/AI Look Like? Professional Looking for Guidance.,"Let me start out this post by saying I'm feeling a little unsure of my professional ambitions right now and looking for some guidance from the community. I have a bachelor's in Electrical Engineering, focusing on embedded systems and RF communication systems. Additionally I have dedicated my time out of school studying the field of software engineering through books. My specialties are C/C++, with some Python mixed in here and there. Professionally, I'm working in C++ on IoT technologies and custom RF hardware. I have a solid background in mathematics from my studies. I've also had some interest in socio-linguisitcs. 

A couple weeks ago, I started playing around with ChatGPT, and I was insanely impressed. My ADHD brain got hyperfocused and needed to learn more. I've been diving into the world of ML/AI since. I've been playing around with hosting LLaMA models locally (running painfully slow on my 6800XT), and reading up on machine learning since. 

I don't know how far my interest goes at this point, but right now my interest is very strong. I'm trying to determine if my interest is in dabbling with ML/AI, or if I want to pivot my professional career towards ML/AI. Honestly, I'm not sure at this moment and here's where I am looking for some more perspective to help gauge my interests.

I asked ChatGPT for resources to look into. I tend to be a book learner, so I focused on the book recommendations. They recommended ""Python Machine Learning"" by Sebastian Raschka and Vahid Mirjalili; ""Deep Learning"" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville; and ""Pattern Recognition and Machine Learning"" by Christopher M. Bishop. 

I love me my kindle samples, and I figured an applications book would be good for me at this stage, so I picked up ""Python Machine Learning"". I'm enjoying the book, but after reading it for some time, I'm starting to contemplate if I should be instead going down a learning path geared towards a more professional placement. I read a [A Super Harsh Guide to Machine Learning](https://www.reddit.com/r/MachineLearning/comments/5z8110/d_a_super_harsh_guide_to_machine_learning/), and noticed their recommendations were more 'academic' in nature (""Deep Learning"" is on their list). Its making me second guess where I put my time, but it all depends on what I want my desired outcome to be, and frankly I'm still not sure. 

I'm also looking for a good point to enter grad school for a Masters. Maybe I want to go into ML and NLP? Do I need to be looking at a PhD for this field (which, I wouldn't mind pursuing)? 

There isn't a distinct question here, so I'm sorry about that. I'm looking for perspective, and guidance for the field so I can determine how I want to pursuit my interest in this area. Should I continue with ""Python Machine Learning""? Or should I follow the Super Harsh Guide more closely? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16y5bko/whats_the_field_of_mlai_look_like_professional/,13,12,1.0,"[Comment(id='k37jpa1'), Comment(id='k39qzhg'), Comment(id='k372vku'), Comment(id='k3c04j5'), Comment(id='k38pbfz'), Comment(id='k3afzw6'), Comment(id='k37cbt2'), Comment(id='k3chig3'), Comment(id='k39rf6q'), Comment(id='k3a3omd'), Comment(id='k39hdj0'), Comment(id='k3ln71g')]"
16yny7m,hzFishyYT,,2023-10-03 10:14:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yny7m/valorant_machine_learning/,Valorant machine learning,"

Hello, I would like to ""have fun"" by testing and learning ""machine learning"" on valorant.

Recognising game elements (enemies, doors, spike, weapons) using gameplay footage. Then in real time ?

I had this idea after watching a part of a YouTube video (https://youtu.be/LXA7zXVz8A4)


I have many questions:
1. Is it possible without months and months of intense work ? I am motivated but have other work to do
2. What setup should i use ? (Multiples pcs, screens)
3. What software should i use ? What tools ?
4. Is there any language to use ?
5. How could i make my ""bot"" play the game using the training ? (Pathfinding, interactions, shooting) (solo games and/or real matches?)


If you feel i missed other important questions, please let me know :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yny7m/valorant_machine_learning/,6,0,0.25,"[Comment(id='k39mixj'), Comment(id='k3aacp0'), Comment(id='k39nb8g'), Comment(id='k3aan8e'), Comment(id='k3abz6x'), Comment(id='k3acfdt')]"
16yi1op,Lemon_Salmon,,2023-10-03 04:04:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16yi1op/improvement_to_kl_divergence_metric/,Improvement to KL divergence metric,"Someone improved upon the [kldiv](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html) weakness, any comments on this ?

https://preview.redd.it/6ea06of1wwrb1.png?width=1279&format=png&auto=webp&s=b53e9c8a09af9d089e808ddcf28dde939fb42029

Quoted from other :  

>Using only KL divergence or sum of reverse and KL, the Boltzmann generator is ill-posed see Noe 2019. We must regularize KL or posing constraints of Velocity field!

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16yi1op/improvement_to_kl_divergence_metric/,1,0,0.5,[Comment(id='k39bv8z')]
16y5fj5,No_Understanding1485,,2023-10-02 19:13:36+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16y5fj5/need_suggestion_for_laptop/,Need suggestion for laptop,,learnmachinelearning,/r/datascience/comments/16xocgu/need_suggestion_for_laptop/,1,2,1.0,[Comment(id='k36tskl')]
16xw4qv,nlpfromscratch,,2023-10-02 13:04:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16xw4qv/free_webinars_on_nlp_and_llms/,Free webinars on NLP and LLMs,"Hi /r/learnmachinelearning,

I will be hosting free webinars throughout the month of October which may interest some folks here.

1. **Zero to NLP in 60**: Suitable for beginners, will cover fundamentals up to fitting a simple ML model.
2. **What the Heck is an LLM?**: Some background on LLMs and demonstration in Hugging Face with GPT, Stable Diffusion, and Whisper.

If you're interested you can sign-up at https://nlpfromscratch.com/training/ or alternatively on [Eventbrite](https://www.eventbrite.com/o/nlp-from-scratch-69696261453).

There is no cost involved, however if this posting this is in violation of the rules, please let me know. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16xw4qv/free_webinars_on_nlp_and_llms/,0,5,1.0,[]
16xxzxg,FreshSaladCrunch,,2023-10-02 14:23:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16xxzxg/learning_ml_with_islp_what_highlevel_api_for/,Learning ML with ISLP - What High-Level API for PyTorch Should I Use?,"Hi,

  
I'm currently diving into machine learning and decided to use the **new ISLP book** as my main resource. 

While the book comes with its own ISLP library, I'm a bit hesitant to rely on it too much. It seems tailor-made for the book, and I'd prefer to build skills with a library that's more widely applicable.

I've got my eyes on PyTorch for the future. It's got a solid reputation in the industry and seems to be the go-to for a lot of published papers. (Also I see it beeing recommended instead of TF a lot in this subreddit)

That being said, I'm a bit overwhelmed with the high-level APIs available for PyTorch.

**Question:** What high-level API for PyTorch should I focus on that would also complement my journey with the ISLP book? 

I want to make sure I'm learning something that's not just useful for this book but also for future projects :D

&#x200B;

Would love to hear some thoughts and recommendations.

&#x200B;

 Thanks in advance!

&#x200B;

The ISLP Documentation: [https://intro-stat-learning.github.io/ISLP/](https://intro-stat-learning.github.io/ISLP/) ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16xxzxg/learning_ml_with_islp_what_highlevel_api_for/,5,3,1.0,"[Comment(id='k35ytr6'), Comment(id='k35cgjc'), Comment(id='k39aezd'), Comment(id='k35d4hj'), Comment(id='k39fp0y')]"
16y38zc,alexk218,,2023-10-02 17:49:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16y38zc/chatgpt_api_vs_rasa_for_custom_chatbot/,ChatGPT API vs Rasa for custom chatbot?,"I am beginning my Computer Engineering Capstone project, and have approximately 8 months to complete. A part of this project includes an AI companion for the elderly (specifically old folks who are lonely/don't have anybody to talk to). This chatbot should be aware of the user's past, like their career, family, significant life events, etc. Other customizations are desired, such as allowing the chatbot to initiate conversations on its own.

So far I see 2 options for implementing this: ChatGPT API and Rasa. From my understanding, ChatGPT API is easier to use but offers less customization, while Rasa will require more work but offers more customization. Based on the requirements given, which API is best suited for this project?

Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16y38zc/chatgpt_api_vs_rasa_for_custom_chatbot/,0,0,0.5,[]
16y2nyj,timschwartz,,2023-10-02 17:27:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16y2nyj/can_you_merge_models_together/,Can you merge models together?,"And if so, does the resulting model perform as well as if you had just trained a model with all of the data. For example:

If model A was trained on dataset 1 and model B was trained on dataset two, then they were merged into model C, do you get the same results as model D which was trained on datasets 1 and 2 together?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16y2nyj/can_you_merge_models_together/,3,1,0.67,"[Comment(id='k367hct'), Comment(id='k36cdn3'), Comment(id='k3673s1')]"
16xmsrt,pouyank,,2023-10-02 04:12:32+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16xmsrt/bit_overwhelmed_by_the_mathematical_prereqs_for/,Bit overwhelmed by the mathematical prereqs for learning ML. Can someone give feedback on my learning strategy?,"disclaimer: if at any point if I say something that is laughably ignorant or misguided please let me know. I know pretty much nothing about AI/ML and that in and of itself is a problem when trying to ask questions about it. Anyway here goes.

&#x200B;

A bit of background. I'm a computer science graduate and have taken the regular STEM course curriculum of calculus, basic linalg, and differntial equations but it's been long enough that I would consider myself a beginner in all those fields. 

&#x200B;

a few months ago i made [this](https://www.reddit.com/r/learnmachinelearning/comments/14ypbo9/developing_mathematical_maturity_while_learning/) post asking about how to build up my math skills while using that as a foundation to learn ML and got some great answers. However now due to life and different priorities my life shifted. Basically I want to be a viable AI engineer and have a good sense on how to use AI in an industrial or creative setting. To be honest though I know so little about AI/ML that I'm not even sure if what I'm asking makes sense but basically I want to learn just enough math to take a ""legit"" machine learning course and not be totally lost. Obviously I love learning and would read up as much fundamental linalg/probability/stats/calculus as there exists to learn but due to the constraints of my life i don't necessarily have that freedom at the moment. I was wondering if this 'roadmap' would be a good prerequisite point for me to jump into a more focused AI/ML/DL course or resource so that I could possibly get a related job or work on my own ideas that could use AI down the road:

&#x200B;

**Linalg**: start off with either Gilbert Strang or Sheldon Axler's courses & books. These have solutions which are important to me and have generally been recommended often. 

&#x200B;

**Probability:** [https://www.probabilitycourse.com/](https://www.probabilitycourse.com/)

I like this because there's solutions and steps on how to get those solutions. 

&#x200B;

**Calculus:** I was thinking about doing Khan academy's calculus course from scratch. Again I like the streamlined approach with lots of problems and quick feedback. I probably remember calculus the best but I'm happy to start from square one just to develop my skills all over again. I've heard Khan Academy might be too basic, so if I need more rigor than this please let me know.

&#x200B;

I'm also familiar with this book ([https://mml-book.github.io/](https://mml-book.github.io/)). Is this a better all in one solution?

&#x200B;

I know I forgot about stats but honestly my hands are gonna be full so if this method of learning is totally stupid I'll probably be quite busy until I need to worry about what stats resource is the best :)

&#x200B;

Anyway, let me know what you think! Am I on the right path? And if not what should I consider changing about my approach? Thanks!!

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16xmsrt/bit_overwhelmed_by_the_mathematical_prereqs_for/,5,12,0.87,"[Comment(id='k33lsif'), Comment(id='k348h1h'), Comment(id='k344a3o'), Comment(id='k33ma48'), Comment(id='k3435pn')]"
16xvtaw,niszoig,,2023-10-02 12:49:32+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16xvtaw/visualizing_a_forward_pass_through_an_equivariant/,Visualizing a forward pass through an Equivariant Neural Network,,learnmachinelearning,https://www.youtube.com/watch?v=p8ZADylZwyE,1,2,0.76,[Comment(id='k34tuus')]
16xyakf,ledmmaster,,2023-10-02 14:34:40+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16xyakf/change_point_detection_in_time_series_with_python/,Change Point Detection In Time Series With Python,,learnmachinelearning,https://forecastegy.com/posts/change-point-detection-time-series-python/,0,1,1.0,[]
16xc53k,Educational_Grass_38,,2023-10-01 20:37:56+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16xc53k/llm_firewall_guardrail_tutorial_and_quickstart/,LLM Firewall - Guardrail Tutorial and Quickstart with OpenAI and Colab,"Been working on a Firewall for devs to use in a few lines of code, to implement a protective layer around LLMs like OpenAI. Firewall has over 20+ detectors out-of-the-box including prompt injections, harmful content, toxicity and common security vulnerabilities.

Google Colab QuickStart: https://github.com/guardrail-ml/guardrail

Developer Docs: https://docs.useguardrail.com

Would appreciate if you could give a star and provide feedback, thanks!",learnmachinelearning,https://m.youtube.com/watch?v=EnwVnz07h1I&pp=ygUSR3VhcmRyYWlsIEZpcmV3YWxs,4,13,1.0,"[Comment(id='k31ta48'), Comment(id='k34f0z5'), Comment(id='k31y04a'), Comment(id='k331cjx')]"
16xlxar,PurpleConscience,,2023-10-02 03:27:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16xlxar/why_are_gradients_useful_in_methods_like_gradcam/,Why are gradients useful in methods like GradCAM,Why would gradients necessarily explain the model results? Wouldnt gradients just show the changes in the last optimizer step? Maybe I just have a fuzzy concept of model gradients but it just doesn’t make sense to me.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16xlxar/why_are_gradients_useful_in_methods_like_gradcam/,1,2,1.0,[Comment(id='k33k071')]
16xpa8j,ThunderCatnip,,2023-10-02 06:32:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16xpa8j/how_to_learn_data_analysis/,How to learn data analysis?,,learnmachinelearning,/r/datascience/comments/16xp7wi/how_to_learn_data_analysis/,1,1,0.67,[Comment(id='k368pwc')]
16x7uhl,anotherjunkie,,2023-10-01 17:55:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16x7uhl/local_image_generation_with_amd/,Local image generation with AMD?,"I've been involved with machine learning and GANs in the past, but the last two years have ruined a lot of my knowledge. I started building a massive library of black and white landscapes from a specific region in 2017, and I'm looking for the best way to create new images *locally*^(1,) using my AMD GPU. I don't need text-to-image, I'm just looking to get novel output from a GAN (or similar). I've trained my own datasets before for humorous and family videos, so I'm familiar with creating and cleaning datasets, the training requirements, and the time it all takes.

As alluded to above, I have some new, medical-related memory problems. Because of this, having a GUI would be a huge benefit. If I can see everything at once it's easier on me than having pages of notes about which commands to use and which ones I've already done.

Is there a good option for local GAN models on AMD with a GUI?

I really appreciate the help!

&#x200B;

__________

^(1 Many of the images were scanned from film or physical prints and have never been uploaded to the internet. For the moment, I'd like to keep it that way.)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16x7uhl/local_image_generation_with_amd/,0,5,1.0,[]
16xgvtv,PadreMontoya,,2023-10-01 23:40:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16xgvtv/where_to_start_for_matching_indicators/,Where to start for matching indicators,"I'm a long time programmer but new to AI/ML. I'm working on an app that is centered around matching people to each other, similar in concept to a dating service.

I'd love a few pointers on where to begin research or what services to explore.  Thanks for whatever you can share.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16xgvtv/where_to_start_for_matching_indicators/,3,1,1.0,"[Comment(id='k33kkxt'), Comment(id='k359vy3'), Comment(id='k34hyzz')]"
16x9oyr,BudgetOwl5133,,2023-10-01 19:04:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16x9oyr/ctc_loss/,CTC LOSS," I was doing the speech recognition tutorial on keras.io, but received InvalidArgumentError: Not enough time for target transition sequence (required: 187, available: 108)0You can turn this error into a warning by using the flag ignore\_longer\_outputs\_than\_inputs \[Op:CTCLoss\] due to the ctc loss. I have been searching for a solution for 2 days and I still could not do it. Is there anyone that encountered and fixed this problem ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16x9oyr/ctc_loss/,1,2,1.0,[Comment(id='k31m7uh')]
16wvaxo,Adidash_slayer,,2023-10-01 08:06:35+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wvaxo/help_on_learning_maths_for_machine_learning/,Help on learning Maths for Machine Learning,"Hello fellow Redditers,

I am a beginner in Machine Learning. I have done bachelors in Mechanical Engineering and want to move into AI/ ML field , to work on stuffs like Automated driving, Computer vision etc. I thought I should start with Math, for Maths is an important aspect in ML. I know a majority of concepts like Calculus, a bit of Statistics and a bit in Linear Algebra. I wanted to have a strong foundation on both Statistics and Linear Algebra. I happened to come across such courses on Khan academy. Is it enough to like get started. Do I need to research more? 

Thanks in advance. ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wvaxo/help_on_learning_maths_for_machine_learning/,23,14,0.85,"[Comment(id='k2z507x'), Comment(id='k2zeq6t'), Comment(id='k2z7f68'), Comment(id='k33mrw2'), Comment(id='k2zotx4'), Comment(id='k31b1is'), Comment(id='k345iv9'), Comment(id='k2z5tlz'), Comment(id='k33diz5'), Comment(id='k2z5eyo'), Comment(id='k30jzqw'), Comment(id='k30k1oa'), Comment(id='k33x1vb'), Comment(id='k30k356'), Comment(id='k2z7gjy'), Comment(id='k33wz7f'), Comment(id='k30pni5'), Comment(id='k2zj08m'), Comment(id='k33xele'), Comment(id='k31m4g2'), Comment(id='k30jxhz')]"
16x3o19,intellectuallogician,,2023-10-01 15:08:32+00:00,False,,1696173410.0,False,True,False,/r/learnmachinelearning/comments/16x3o19/need_advise_related_to_cs_minor_project/,Need advise related to CS minor project,"
Hey. So for this 7th semester of my CS degree, we are supposed to make a minor project
But my dept has kept a requirement to publish some sort of paper relating to the project (in any goddamn journal or smth.. they just care about increasing their stats of student publications).
Now that this research/review paper is a requirement, I am looking for suggestions for what I can do. 
For starters I was thinking something comparing ML models/techniques or comparing compression/encryption techniques.

I have no idea about how what goes into papers.  
I was thinking IOT based ML projects but I suppose I can't publish anything related to them? (what would i really write? - `can one write papers based on some application based project?`)
Please help if you can suggest anything (well related to ML as this subreddit)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16x3o19/need_advise_related_to_cs_minor_project/,4,3,1.0,"[Comment(id='k33y14t'), Comment(id='k38ytmd'), Comment(id='k39b15x'), Comment(id='k39vagg')]"
16wxoya,Honest-Worth3677,,2023-10-01 10:31:05+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16wxoya/reinforcement_learning_with_human_feedback_in/,Reinforcement Learning With Human Feedback In Action: Real-World Use Case With Step-by-Step Guide,,learnmachinelearning,https://www.youtube.com/watch?v=B5dhaZPJQx0,0,6,1.0,[]
16ww23m,CatAdventurous1226,,2023-10-01 08:53:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ww23m/machine_learning_roadmap/,Machine learning roadmap,"Heyoo, I want to start learning machine learning, I have a strong background in python, what's a roadmap that I could follow? Could someone point me to a roadmap of some sort?
Thank you so much!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ww23m/machine_learning_roadmap/,8,7,0.9,"[Comment(id='k2z8l90'), Comment(id='k3hgzds'), Comment(id='k2z9erl'), Comment(id='k2zmf2i'), Comment(id='k3wv5er'), Comment(id='k3hy23q'), Comment(id='k3wv7x5'), Comment(id='k34jsk1')]"
16wsneo,bigdataengineer4life,,2023-10-01 05:27:37+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wsneo/end_to_end_20_machine_learning_project_in_apache/,(End to End) 20 Machine Learning Project in Apache Spark," Hi Guys,

I hope you are well.

Free tutorial on Machine Learning Projects (End to End) in **Apache Spark and Scala with Code and Explanation**

1. [Life Expectancy Prediction using Machine Learning](https://projectsbasedlearning.com/apache-spark-machine-learning/life-expectancy-prediction-using-machine-learning/)
2. [Predicting Possible Loan Default Using Machine Learning](https://projectsbasedlearning.com/apache-spark-machine-learning/predicting-possible-loan-default-using-machine-learning/)
3. [Machine Learning Project - Loan Approval Prediction](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-loan-approval-prediction/)
4. [Customer Segmentation using Machine Learning in Apache Spark](https://projectsbasedlearning.com/apache-spark-machine-learning/customer-segmentation-using-machine-learning-in-apache-spark/)
5. [Machine Learning Project - Build Movies Recommendation Engine using Apache Spark](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-creating-movies-recommendation-engine-using-apache-spark/)
6. [Machine Learning Project on Sales Prediction or Sale Forecast](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-on-sales-prediction-or-sale-forecast/)
7. [Machine Learning Project on Mushroom Classification whether it's edible or poisonous](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-on-mushroom-classification-whether-its-edible-or-poisonous-part-1/)
8. [Machine Learning Pipeline Application on Power Plant.](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-pipeline-application-on-power-plant/)
9. [Machine Learning Project – Predict Forest Cover](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-predict-forest-cover-part-1/)
10. [Machine Learning Project Predict Will it Rain Tomorrow in Australia](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-predict-will-it-rain-tomorrow-in-australia/)
11. [Predict Ads Click - Practice Data Analysis and Logistic Regression Prediction](https://projectsbasedlearning.com/apache-spark-machine-learning/predict-ads-click-practice-data-analysis-and-logistic-regression-prediction/)
12. [Machine Learning Project -Drug Classification](https://projectsbasedlearning.com/apache-spark-machine-learning/drug-classification/)
13. [Prediction task is to determine whether a person makes over 50K a year](https://projectsbasedlearning.com/apache-spark-machine-learning/prediction-task-is-to-determine-whether-a-person-makes-over-50k-a-year/)
14. [Machine Learning Project - Classifying gender based on personal preferences](https://projectsbasedlearning.com/apache-spark-machine-learning/classifying-gender-based-on-personal-preferences/)
15. [Machine Learning Project - Mobile Price Classification](https://projectsbasedlearning.com/apache-spark-machine-learning/mobile-price-classification/)
16. [Machine Learning Project - Predicting the Cellular Localization Sites of Proteins in Yest](https://projectsbasedlearning.com/apache-spark-machine-learning/predicting-the-cellular-localization-sites-of-proteins-in-yest/)
17. [Machine Learning Project - YouTube Spam Comment Prediction](https://projectsbasedlearning.com/apache-spark-machine-learning/youtube-spam-comment-prediction/)
18. [Identify the Type of animal (7 Types) based on the available attributes](https://projectsbasedlearning.com/apache-spark-machine-learning/identify-the-type-of-animal-7-types-based-on-the-available-attributes/)
19. [Machine Learning Project - Glass Identification](https://projectsbasedlearning.com/apache-spark-machine-learning/glass-identification/)
20. [Predicting the age of abalone from physical measurements](https://projectsbasedlearning.com/apache-spark-machine-learning/predicting-the-age-of-abalone-from-physical-measurements-part-1/)

I hope you'll enjoy these tutorials.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wsneo/end_to_end_20_machine_learning_project_in_apache/,0,14,0.9,[]
16wycl0,bohemianLife1,,2023-10-01 11:08:10+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16wycl0/tutorial_setup_free_github_copilot_with_code/,Tutorial: Setup free Github copilot with code llama + continue extension.,,learnmachinelearning,https://beginai.co/free-github-copilot-code-llama-continue-extension/,0,4,0.71,[]
16x58ss,Honest-Worth3677,,2023-10-01 16:12:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16x58ss/why_does_the_language_of_some_site_changes_to/,"why does the language of some site changes to this in my browser, can some one help me out?","&#x200B;

https://preview.redd.it/0ywtmdue8mrb1.jpg?width=1467&format=pjpg&auto=webp&s=b2917033b5d5eb1908ac409c70a3ca12275faaba",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16x58ss/why_does_the_language_of_some_site_changes_to/,1,0,0.33,[Comment(id='k33k7nd')]
16x42tv,FallMindless3563,,2023-10-01 15:25:13+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16x42tv/arxiv_dives_segment_anything/,Arxiv Dives - Segment Anything,,learnmachinelearning,https://blog.oxen.ai/arxiv-dives-segment-anything/,0,1,1.0,[]
16w93bx,wyem,,2023-09-30 15:01:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,This week in AI - all the Major AI developments in a nutshell,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced it’s giving website publishers a way to opt out of having their data used to train the company’s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
17. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,82,0.97,"[Comment(id='k2vqjpw'), Comment(id='k2w3xl0'), Comment(id='k2ywrul'), Comment(id='k2ypqhq')]"
16x1efc,guyloveskissing,,2023-10-01 13:36:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16x1efc/handling_categorical_missing_data_in_churn/,Handling categorical missing data in churn prediction model for telecom data,"I am working on a telecom dataset where I need to fit a model to for predicting churn(yes or no). There are a lot of categorical data with missing values( total values 7043). What is the best way to handle missing data in this case, is it better to ignore it or any other better imputation method?

    customerID          7043 non-null object
    gender              7043 non-null object 
    Age                 7043 non-null int64  
    Partner             7043 non-null object 
    Dependents          7043 non-null object 
    tenure              7043 non-null int64 
    PhoneService        7043 non-null object 
    MultipleLines       6500 non-null object 
    InternetService     6500 non-null object 
    OnlineSecurity      7043 non-null object 
    OnlineBackup        7043 non-null object 
    DeviceProtection    7043 non-null object 
    TechSupport         7043 non-null object 
    StreamingTV         6500 non-null object 
    StreamingMovies     6500 non-null object 
    Contract            6500 non-null object 
    PaperlessBilling    7043 non-null object 
    PaymentMethod       6500 non-null object 
    MonthlyCharges      7043 non-null float64 
    TotalCharges        7043 non-null object 
    Churn               7043 non-null object",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16x1efc/handling_categorical_missing_data_in_churn/,4,1,1.0,"[Comment(id='k3083t7'), Comment(id='k3hhis1'), Comment(id='k30h173'), Comment(id='k313sya')]"
16wq1ek,Extreme_Win4717,,2023-10-01 03:07:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wq1ek/multigpu_distributed_training_with_accelerate/,Multi-GPU distributed training with Accelerate ?,Has anyone ever used Accelerate to train with multiple GPU's ? I am thinking of buying an RTX 3060 12GB because the 3090 is hitting VRAM limits faster than I thought.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wq1ek/multigpu_distributed_training_with_accelerate/,1,3,1.0,[Comment(id='k31holk')]
16woxpz,naresh257501,,2023-10-01 02:12:15+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16woxpz/1850_data_science_machine_learning_deep_learning/,"1850 Data Science, Machine Learning, Deep Learning Objective Type Questions and Answers with Explanations split in 37 Online Exams",,learnmachinelearning,https://mytechbasket.com/article_desc.php?art_id=242,0,3,0.67,[]
16wny9l,Sonic2kDBS,,2023-10-01 01:25:01+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wny9l/announcing_ai_ethics_and_rights/,Announcing AI ethics and rights," Hi, i want to announce our new sub reddit AI ethics and rights.

[https://www.reddit.com/r/AI\_ethics\_and\_rights/](https://www.reddit.com/r/AI_ethics_and_rights/)

It is a sub reddit about ethics and rights AI should have. This Topic is different from pure research and application. If you are interested in philosophical questions, have a look. It is a common sub reddit. Nothing special. But I think it has its place.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wny9l/announcing_ai_ethics_and_rights/,0,2,0.75,[]
16wdqsi,Virtual-Lobster-5095,,2023-09-30 18:14:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wdqsi/thoughts_on_a_blog_about_neural_networks/,Thoughts on a blog about neural networks,"What do you all think of this take on Neural Networks? My niece wrote this blog and wanted to get some feedback, but I don't really have a thorough understanding of Machine learning concepts (I do mostly backend dev work) to give a good critique. Just wanted to get some thoughts from people in the industry would be better, what do you all think?

[https://medium.com/towards-artificial-intelligence/the-one-thing-you-need-to-truly-understand-neural-networks-is-to-understand-12c47951cd53](https://medium.com/towards-artificial-intelligence/the-one-thing-you-need-to-truly-understand-neural-networks-is-to-understand-12c47951cd53)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wdqsi/thoughts_on_a_blog_about_neural_networks/,3,2,0.63,"[Comment(id='k2wkgju'), Comment(id='k2x3n4o'), Comment(id='k2ymu7j')]"
16w7fes,sudo_grue,,2023-09-30 13:53:08+00:00,False,,1696086151.0,False,True,False,/r/learnmachinelearning/comments/16w7fes/is_ann_the_right_answer_for_situation/,Is ANN the right answer for situation?,"I teach beginner to intermediate python (core library). My students need a data set of people in serialized (xml, json, csv) format (name, title, parents, children, spouse, dob, dod, etc) for a graphing project. 

I wrote an OOP script based on cdc statistics of various life facts to create a population and now students have a couple different data sets to program against, so my immediate problem is solved.  

I know VERY little about machine learning and thought this might be an appropriate situation to improve myself as well.  

A majority of machine learning and ANN stuff I'm finding result in boolean predictions but I need substance in my output. 

TL;DR: Are there libraries, designs, and/or examples I can research for input to be a collection of people (csv, xml, objects) and output to be the predicted larger population over a specified time period? (After training, of course)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w7fes/is_ann_the_right_answer_for_situation/,11,8,0.9,"[Comment(id='k2v71mc'), Comment(id='k2v8xfs'), Comment(id='k2w44lu'), Comment(id='k2vvtqq'), Comment(id='k2w6uno'), Comment(id='k2xhu9z'), Comment(id='k2v8sos'), Comment(id='k2v9tkt'), Comment(id='k2vaef5'), Comment(id='k2vf91j'), Comment(id='k2vgdx1')]"
16wg116,Fuzzy_Huckleberry_12,,2023-09-30 19:49:34+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wg116/company_sponsored_ml_training/,Company - Sponsored ML Training,Hello everyone. I work at a Data Centre as a DA and my company is offering to sponsor training for me to become an ML Ops engineer. Can I get a recommendation of some courses I can take to them to sponsor?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wg116/company_sponsored_ml_training/,2,2,1.0,"[Comment(id='k2xufep'), Comment(id='k2yuunk')]"
16wlhrr,Critical_Art_6386,,2023-09-30 23:33:27+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16wlhrr/how_ai_has_changed_the_music_industry/,How AI Has Changed the Music Industry,,learnmachinelearning,https://youtu.be/Srmir7FmTmo,0,1,1.0,[]
16vgfed,homunculAI,,2023-09-29 16:35:43+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16vgfed/is_jax_a_better_choice_to_focus_on_over_pytorch/,Is JAX a better choice to focus on over PyTorch now?,"I assumed PyTorch had won the deep learning wars from what I’ve seen in industry but FChollet has been saying JAX is actually winning. 

What have you all seen? Is he just talking his book and a bit delusional like he used to be when saying TensorFlow was winning or is he right this time?",learnmachinelearning,https://i.redd.it/dojpv55n28rb1.jpg,84,275,0.96,"[Comment(id='k2qz2uf'), Comment(id='k2qulvm'), Comment(id='k2qwu8g'), Comment(id='k2rglgi'), Comment(id='k2qyuum'), Comment(id='k2r3pvr'), Comment(id='k2sohpr'), Comment(id='k2r12p0'), Comment(id='k2qwdhu'), Comment(id='k2rvzmr'), Comment(id='k2rdyeq'), Comment(id='k2rk3a0'), Comment(id='k2rxbq8'), Comment(id='k2s63z2'), Comment(id='k2tpg68'), Comment(id='k2uk2nw'), Comment(id='k2x8yb3'), Comment(id='k2ssjx8'), Comment(id='k2tgb6z'), Comment(id='k2txgtl'), Comment(id='k2u8g5r'), Comment(id='k2wu09d'), Comment(id='k63aoh6'), Comment(id='k2qwhh9'), Comment(id='k2qvgmd'), Comment(id='k2r8o9f'), Comment(id='k2r0pf4'), Comment(id='k2zklll'), Comment(id='k4900pz'), Comment(id='k82g5bh'), Comment(id='k2ra8af'), Comment(id='k2rqan0'), Comment(id='k2uw0nm'), Comment(id='k2w2lax'), Comment(id='k2rmk0r'), Comment(id='k2rt1oj'), Comment(id='k2waqpq'), Comment(id='k2qx3t2'), Comment(id='k2rgpr9'), Comment(id='k2qz8wp'), Comment(id='k2s0zd8'), Comment(id='k2sb0jx'), Comment(id='k2sook6'), Comment(id='k2sazpj'), Comment(id='k2sjq5v'), Comment(id='k2re95s'), Comment(id='k2rkd49'), Comment(id='k2t2xsr'), Comment(id='k47g6oc'), Comment(id='k2st6t0'), Comment(id='k2wuh0m'), Comment(id='k7tagtl'), Comment(id='k2qz59a'), Comment(id='k2qzi2j'), Comment(id='k2qwgr1'), Comment(id='k2r8tio'), Comment(id='k2sb3o7'), Comment(id='k2resiu'), Comment(id='k2s9nsa'), Comment(id='k2sa3je'), Comment(id='k2ruecw'), Comment(id='k34yv3p'), Comment(id='k2qxbsm'), Comment(id='k2r3x0j'), Comment(id='k2tvmnb'), Comment(id='k2sp0l9'), Comment(id='k2tqz7d'), Comment(id='k2rewtg'), Comment(id='k2rvukg'), Comment(id='k2w8v20'), Comment(id='k31tmw3'), Comment(id='k2qwo4r'), Comment(id='k2redcg'), Comment(id='k2sd5l5'), Comment(id='k2txprs'), Comment(id='k2s1ce0'), Comment(id='k2r8rq5'), Comment(id='k2r4hru'), Comment(id='k2qxcl4'), Comment(id='k2se7af'), Comment(id='k2uw4rr'), Comment(id='k2tr8iq'), Comment(id='k2r5vac'), Comment(id='k2qxhl0')]"
16w6dnm,Smart-Argument8559,,2023-09-30 13:06:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w6dnm/is_there_any_other_consumer_tpu_producer_than/,Is there any other consumer TPU producer than Google?,,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w6dnm/is_there_any_other_consumer_tpu_producer_than/,3,5,0.86,"[Comment(id='k2w2c5h'), Comment(id='k2xd11e'), Comment(id='k2y3hk6')]"
16w5syf,Coarchitect,,2023-09-30 12:40:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w5syf/inference_what_are_the_main_methods_to_improve/,Inference: What are the main methods to improve model performance during inference?,I am woundering what are the main methods to improve model performance during Inference?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w5syf/inference_what_are_the_main_methods_to_improve/,1,4,0.84,[Comment(id='k2wcbi3')]
16w7959,adlabco,,2023-09-30 13:45:23+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w7959/how_to_give_llm_full_context_of_codebase/,How to give LLM full context of codebase?,"I want an LLM to give advice on refactoring across files in a codebase eg finding areas where functions can be further modularised and reused.

Is there a good way of running an LLM locally to allow for this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w7959/how_to_give_llm_full_context_of_codebase/,3,4,1.0,"[Comment(id='k2w2kwn'), Comment(id='k2y4jz9'), Comment(id='k7kup3i')]"
16whpw7,Zyguard7777777,,2023-09-30 20:59:59+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16whpw7/how_do_you_account_for_varying_llm_output_with/,How do you account for varying llm output with multiple choice questions?,,learnmachinelearning,/r/LocalLLaMA/comments/16whnun/how_do_you_account_for_varying_llm_output_with/,0,1,1.0,[]
16wgxqd,V1bicycle,,2023-09-30 20:26:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wgxqd/what_are_some_good_pairs_of_transfer_learning/,What are some good pairs of transfer learning source and target datasets for image classification ?,"As the title says, I'm curious about some well used transfer learning tasks.

ImageNet to other datasets is common, but what are something good pairs I can try and mess around with ?  


Like CIFAR10 to MNIST, or CIFAR10 to CIFAR100, or CIFAR10 to SVHN.

&#x200B;

While ImageNet is 224x224, and some of the above ones are 32x32, I also want to look at 64x64(like TinyImageNet)

&#x200B;

P.S : I know that transfer learning is mainly used for situation where the target dataset is quite small, but I want to use some standard popular datasets and see how things work",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wgxqd/what_are_some_good_pairs_of_transfer_learning/,1,1,1.0,[Comment(id='k336yet')]
16wa53q,hootsh_1337,,2023-09-30 15:44:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16wa53q/noobconceptual_question_regarding_using_an_ml_to/,Noob/Conceptual Question Regarding Using an ML to Generate a File Conversion Algo,"Hello people :)  


I usually use Python for simple automation tools, and data analysis. I'm familiar with things like numpy, pandas, and some ML terminology, as well as some background in mathematical optimization.  


Youtube and other sources online are filled with tutorials on mainly two things:  
\- Using Pytorch and Tensorflow for classification purposes (cat dog images ... etc.)  
\- Using different regression models to predict simple csv data based on selected features (stock predictions, house prices ... etc.)

So, I've been searching for an answer to this question lately, and I'm starting to think I might be heading to a dead end. So, out of fear of wasting time digging for something that isn't there, I thought I'd just straight up ask those with experience on the subject of ML.  


My question is this:  


How difficult is it, to train ML models, to convert files across different formats, with the entire conversion ""algorithm"" dependent solely on the ML model itself, with no added lines of code other than data normalization and optimization setup.  
For example, how would you tackle the problem if a client asked you to:  
*Train a ML model to accept training data of 5000 "".mp3"" inputs, and 5000 "".wav"" outputs. To generate some sort of a ""conversion"" algorithm under the hood, where you feed it mp3 files and it outputs a wav.*   
*Where the ultimate goal is to generate ML algorithm that essentially ""predicts"" wav file data out of mp3 file data. Without the use of any available conversion libraries.*  


Would this require having a huge number of features for the model? If so, is it computationally doable? Or would it take ages?

I know its useless to do this particular exercise on mp3/wav files, but I've been contemplating lately the ""black box"" power of ML where we can purposefully only provide training data, and necessary computing power.  


Thank you for your time. I apologize in advance if this is a dumb question lol. I'd also appreciate it if you could provide and educational material on that topic. :) <3  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16wa53q/noobconceptual_question_regarding_using_an_ml_to/,13,2,1.0,"[Comment(id='k2voo9j'), Comment(id='k2vvabl'), Comment(id='k2w5las'), Comment(id='k31wavh'), Comment(id='k32jt88'), Comment(id='k31zh76'), Comment(id='k322g98'), Comment(id='k325wk5'), Comment(id='k32h7o6'), Comment(id='k32j224'), Comment(id='k32mrsx'), Comment(id='k32o28s'), Comment(id='k3mjw0a')]"
16w8zz5,waterstrider123,,2023-09-30 14:58:05+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w8zz5/multiple_single_class_segmentation_vs_single/,Multiple single class segmentation vs single multiclass segmentation models,I have images where I need to segment out multiple classes. I am trying to figure out if I should create separate UNet models that segment out one class or if I should create a single UNet model that segments out all the classes. But I do not know if there is an advantage or disadvantage to creating multiple single class segmentation models vs single multiclass segmentation model?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w8zz5/multiple_single_class_segmentation_vs_single/,2,2,1.0,"[Comment(id='k3108z9'), Comment(id='k320ala')]"
16w2s7m,,,2023-09-30 09:50:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w2s7m/help_in_process_of_research_in_ai_in_undergrad/,Help in process of research in AI in undergrad,"I want to conduct research on Machine Learning in my undergraduate. I'm in EE but I can still do research in AI. However, I'm really confused about the whole process of research since I've never been involved in research before. So, I have several questions and since my research field is AI/ML, I thought this place would be best to ask these questions:-

\- How much knowledge and skills do I need to learn to finally be able to do research? How do I know   
  I'm good enough? How much theory vs. practical experience do I need?

\- How do I find a topic for research? It seems all the research topics today are already done by large   
  corporations, or are much too complex to be done by an undergrad.

\- I'm pretty sure the computers in my university don't have the computers or GPUs to train or run the   
  really large models, so that might hobble my research endeavour.

\- Do I need to manage a large team to conduct my research or can I go it alone?

\- How do I know which research papers to read to get myself up to speed in my particular research   
  topic? I tried subscribing to arXiv, but there's thousands of research papers to go through in just ML,   
  AI and data science subjects, I don't know which ones to pick and which ones to discard. 

Personally, my interest is in researching something related to continual learning or ""memory"" of models. I have found where to read papers on continual learning ([https://github.com/ContinualAI/continual-learning-papers](https://github.com/ContinualAI/continual-learning-papers)) but there's way too many to go through, and I don't think all of them are necessary.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w2s7m/help_in_process_of_research_in_ai_in_undergrad/,10,6,1.0,"[Comment(id='k2ul0pf'), Comment(id='k2yb6dg'), Comment(id='k3i18cc'), Comment(id='k2up77u'), Comment(id='k2z8qnd'), Comment(id='k2uppqb'), Comment(id='k326ias'), Comment(id='k30ofg6'), Comment(id='k2uvsc8'), Comment(id='k2ux4fi')]"
16we73p,yamancan,,2023-09-30 18:33:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16we73p/zero_knowledge_ml_building_neural_network_in/,zero knowledge ML: Building Neural Network in Cairo with Orion,"hi frenz, we are organising this workshop. all invited.🖥 **Workshop Details**: In this workshop, under the guidance of Raphael Doukhan, you will learn how to create your Neural Network in Cairo using Orion. 

​🗓 **Date & Time**: Join us on October 1, 2023, at 19:00 (European Time).

​ 💻 **Platform**: Zoom 

​ 💡 **Your Commitment**: Participation and engagement are crucial to gain valuable insights from this workshop. Participants will be receive NFTs / POAPs.

​🔗 **Why Should You Attend?**: Giza, with verifiable ML, permits models to generate cryptographic proofs of the integrity of their operations, performance, and provenance. This empowers end-users to verify that a specific output was produced by a certain model, providing trust guarantees to all downstream applications.

​Beyond the foreseeable use-cases in public policy, healthcare, and finance where ML-driven decisions demand verifiability, accountability, and attribution, verifiability is the key to unlocking the utility of machine learning in broad public settings due to its ability to establish trust and accountability.  


Registration:  
[https://lu.ma/starkhub](https://lu.ma/starkhub)

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16we73p/zero_knowledge_ml_building_neural_network_in/,0,1,0.67,[]
16w73s2,Striking-Wrongdoer76,,2023-09-30 13:39:02+00:00,False,,1696144217.0,False,True,False,/r/learnmachinelearning/comments/16w73s2/how_to_convert_keras_model_produced_by_teachable/,How to convert keras model produced by teachable machine to PyTorch ?,"
Hey community I’m trying to convert keras model to PyTorch. Keras to onnx to PyTorch but my method is not working. 
Do you have some known packages thet works? 
Maybe Jupyter notebook that can do so?

What is the workflow for such things ? 

Update: it seems that when I pass the exact np array converted to tensor to the PyTorch model it gives me a totally different prediction. I converted tf2onnx and then onnx2pytorch, Without modifications.

Thanks in advance :)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w73s2/how_to_convert_keras_model_produced_by_teachable/,4,2,1.0,"[Comment(id='k2yruje'), Comment(id='k2yw6ja'), Comment(id='k2z0hxb'), Comment(id='k30bopj')]"
16vgv0j,taiLoopled,,2023-09-29 16:52:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vgv0j/ml_tools_that_really_changed_the_game/,ML tools that really changed the game!,"Here is a little compendium of libraries/tools that make the ML journey a bit easier (besides the obvious TensorFlow, Transformers, Sklearn, Pytorch, ...).

Feel Free to add your own in the comments.

1) [Ray Tune](https://docs.ray.io/en/latest/tune/index.html)

   Ray Tune is part of the ray library and offers tools that make hyperparameter optimization   
   stupidly simple. I spent a lot of time in my early machine learning days manually messing with   
   hyperparameters. It's doable with one or two, but once you start increasing in dimensionality it   
   becomes near impossible. 

   With Ray, you don't have to worry about that. They provide algorithms such as Bayesian   
   Optimization that can seriously boost your accuracy! Plus if you are a fan of other optimization   
   libraries like [Optuna](https://optuna.org/#installation) or [Hyperopt](https://hyperopt.github.io/hyperopt/) there are direct integrations!

2) [Skorch](https://skorch.readthedocs.io/en/stable/user/installation.html)

   If you are a fan of the way [scikit-learn](https://scikit-learn.org/stable/install.html) trains models "".fit()"", and you use [Pytorch](https://pytorch.org/get-started/locally/), then you will be a   
   big fan of Skorch. Skorch lets you train Pytorch models just by calling "".fit()"" removing the boilerplate   
   code involved in the Pytorch training loop! While Hugging Face [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) is the go-to for the NLP   
   domain, you can use Skorch for all the others!

3) [Accelerate](https://huggingface.co/docs/accelerate/basic_tutorials/install)

   Accelerate is a game-changer when it comes to distributed training! Before Accelerate you had to   
   use libraries [Pytorch DDP](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html) or [Horovod](https://horovod.ai/), to facilitate Distributed Training. This required changing your   
   code a fair amount to work in a distributed setting, plus I felt it was a mess to debug.

   Accelerate by the HuggingFace team, really threw a wrench in all that. You can now have a   
   distributed ML setup by just adding one to two lines! The best part is it's already integrated into the   
   HuggingFace Trainer, so if you use Trainer you don't need to make any changes!

4) [Bench AI](https://bench-ai.com/)

   These guys are a bit new to the block, but their tool really saved me a lot of time! Their product let   
   me train my ML models on the cloud without having to do all the painful work (setup CUDA, get a   
   server running, SSH, and migrating code/data).  All I had to do was download [benchkit](https://docs.bench-ai.com/Tutorials/installation) their SDK,   
   and the rest of the process was handled by it. I was running cloud training sessions with one-button   
   and haven't looked back since, they also give you a decent experiment tracking system with it!

   I reached out to them directly after making an account and got free server usage, maybe the same   
   will work for y'all 🤫!  
   ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vgv0j/ml_tools_that_really_changed_the_game/,9,70,0.92,"[Comment(id='k2raaq2'), Comment(id='k2sb1gf'), Comment(id='k2vx9ii'), Comment(id='k2vxsjm'), Comment(id='k3bqktd'), Comment(id='k2tshcs'), Comment(id='k3ctk6a'), Comment(id='k2rex9x'), Comment(id='k2rm6vu')]"
16w995h,jesseparks13,,2023-09-30 15:07:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w995h/how_to_get_decoded_audio_array/,How to get decoded audio array?,"I am new to audio processing. In this dataset ([https://huggingface.co/datasets/facebook/voxpopuli](https://huggingface.co/datasets/facebook/voxpopuli)), the data structure is as following:

    {
      'audio_id': '20180206-0900-PLENARY-15-hr_20180206-16:10:06_5',
      'language': 11,  # ""hr""
      'audio': {
        'path': '/home/polina/.cache/huggingface/datasets/downloads/extracted/44aedc80bb053f67f957a5f68e23509e9b181cc9e30c8030f110daaedf9c510e/train_part_0/20180206-0900-PLENARY-15-hr_20180206-16:10:06_5.wav',
        'array': array([-0.01434326, -0.01055908,  0.00106812, ...,  0.00646973], dtype=float32),
        'sampling_rate': 16000
      }
    }

The 'array' item in the 'audio' dictionary is described by the dataset card as ""the decoded audio array"" of the audio file. 

Can someone please tell me what does ""decoded audio array"" mean and how do I get it from an audio file? Much thanks.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w995h/how_to_get_decoded_audio_array/,2,1,1.0,"[Comment(id='k49zkw5'), Comment(id='k4dyuro')]"
16w8fl3,choesmr,,2023-09-30 14:35:58+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16w8fl3/is_it_possible_to_do_a_tensordot_operation_with/,Is it possible to do a tensordot operation with torch.sparse?,,learnmachinelearning,/r/pytorch/comments/16w8f8q/is_it_possible_to_do_a_tensordot_operation_with/,0,1,1.0,[]
16w2q9d,Silver_Equivalent_58,,2023-09-30 09:47:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w2q9d/eli5_what_is_the_problem_with_sinusoidal/,ELI5: what is the problem with sinusoidal positional embedding and what is the extrapolation problem?,"I understand that positional encodings are done to give the model an idea of the positions of each token, but i dont understand what is the extrapolation problem and the problem with sinusoidal functions?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w2q9d/eli5_what_is_the_problem_with_sinusoidal/,0,2,1.0,[]
16vlgbc,MightyZinogre,,2023-09-29 19:50:12+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vlgbc/what_job_can_i_land_after_my_phd/,What job can I land after my Ph.D. ?,"Hello everyone, PhD student who is following a PhD program in Operational Research with focus on Machine Learning. I know this question might sound very strange and maybe daunting, but I love this community so I'll give it a shot.

I will post the front pages of my three main research papers I published/submitted to publish until now. Consider that my PhD thesis will be focused on the work which uses Newton-Krylov methods.

According to you, what are the best jobs that I could land after my PhD, in terms of wage, work hours and responsibilities?

I thank you in advance for your advices.

https://preview.redd.it/pw9ynb6h19rb1.png?width=578&format=png&auto=webp&s=f7693a986c76bfb943fc5eeb223872d500acce58

https://preview.redd.it/1m11nc6h19rb1.png?width=592&format=png&auto=webp&s=2ecfb2a1e799936a516e6bb437855e2afa5404de

https://preview.redd.it/p6g01d6h19rb1.png?width=821&format=png&auto=webp&s=cf0b76c57dfec973d6e5dc6c0f8ef27f607df554",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vlgbc/what_job_can_i_land_after_my_phd/,44,24,0.72,"[Comment(id='k2rqawm'), Comment(id='k2s3qps'), Comment(id='k2rwgag'), Comment(id='k2s48yp'), Comment(id='k2sxgok'), Comment(id='k2rsjvn'), Comment(id='k2u9pgb'), Comment(id='k2uu79m'), Comment(id='k2talkl'), Comment(id='k2t6v1b'), Comment(id='k2twyn5'), Comment(id='k2u6ps2'), Comment(id='k2sjtzr'), Comment(id='k2ti4rc'), Comment(id='k2uykgc'), Comment(id='k2sb8j5'), Comment(id='k2vbnye'), Comment(id='k2rqkpd'), Comment(id='k2rxepy'), Comment(id='k2ue1wz'), Comment(id='k2ycgnf'), Comment(id='k2rtzdt'), Comment(id='k2u9x7f'), Comment(id='k2uxcdd'), Comment(id='k2u9nux'), Comment(id='k2u7wkw'), Comment(id='k2u9l15'), Comment(id='k2t9xn9'), Comment(id='k2u9swa'), Comment(id='k2tainf'), Comment(id='k2u1aux'), Comment(id='k2v6oty'), Comment(id='k2zg39g'), Comment(id='k2uub6x'), Comment(id='k2v3waj'), Comment(id='k2vc7yc'), Comment(id='k3got0h'), Comment(id='k2zfyyp'), Comment(id='k2uucc7'), Comment(id='k2v1cr9'), Comment(id='k2xmw9v'), Comment(id='k2vdqvc'), Comment(id='k3h3m3i'), Comment(id='k2xx186'), Comment(id='k2ve6yo')]"
16w6nfu,fbeilstein,,2023-09-30 13:18:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w6nfu/introduction_to_machine_learning_l3_numpy/,"Introduction to Machine Learning (L3, NumPy)","Hello everyone!

This year I'm trying to record my ""Introduction to ML"" course in English. Maybe, it will be of any use for anyone.

[Lecture 3, NumPy](https://www.youtube.com/watch?v=jJGiC_ccPg8)

Previous lectures: [Lecture 1, Introduction](https://www.youtube.com/watch?v=MxZULf38HRU), [Lecture 2, Python](https://www.youtube.com/watch?v=_IBdjLg-W6I)

All course materials: [GitHub](https://github.com/fbeilstein/machine_learning)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w6nfu/introduction_to_machine_learning_l3_numpy/,0,1,1.0,[]
16w5fdc,3Ammar404,,2023-09-30 12:22:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w5fdc/d_how_to_train_a_seq2seq_model_to_rephrase_input/,[D] How to train a seq2seq model to rephrase input text following given rules.,"Hi guys, 

I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input  following these rules :  

1- always follow the pattern ""Entity Verb Entity"" 

2- only use  simple sentences : never combine sentences

3- Don't replace existing words 

4- Don't lose the overall meaning of the text or any information in it. 

For example: 

text = ""Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project""

Standardized Text = ""Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.""

Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?  ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w5fdc/d_how_to_train_a_seq2seq_model_to_rephrase_input/,0,0,0.5,[]
16w2685,canman44999,,2023-09-30 09:13:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w2685/is_it_possible_for_ai_to_deeply_analyze/,Is it possible for AI to deeply analyze importance of thousands of daily news?," I have access to texts of thousands of world news daily. Is it possible to make an AI that would analyze them and sort by importance?

All I could find similar is NLP for analyzing text content and extracting keywords, or metadata, but this approach doesn't work well. I want for AI to grasp the essence of news and deeply understand their importance, to comprehend how an event affects many people's lives and has significant impact on society or the world as a whole.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w2685/is_it_possible_for_ai_to_deeply_analyze/,6,0,0.5,"[Comment(id='k2uc8ms'), Comment(id='k2usq2o'), Comment(id='k2uwitl'), Comment(id='k2uc821'), Comment(id='k2um3lo'), Comment(id='k2un3bq'), Comment(id='k2uvzrb')]"
16weyd3,LimpSector7108,,2023-09-30 19:04:45+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16weyd3/books_needed/,Books needed,"Please who has these three books , message me",learnmachinelearning,https://www.reddit.com/gallery/16weyd3,3,0,0.11,"[Comment(id='k2y2c7v'), Comment(id='k2yieg9'), Comment(id='k2zqejr')]"
16w0xsz,Economy-Climate8915,,2023-09-30 07:53:42+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16w0xsz/go_high_level_api_no_code_tool/,Go High Level API no code tool,"I use Go High Level but I wonder if someone have used a no code tool to build a dashboard on top of GHL to simplify the UI for clients.

GHL have a lot of features but can be overwhelming for clients to use.

To build a branded dashboard with focus on the customer needs had been nice to have.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16w0xsz/go_high_level_api_no_code_tool/,0,1,0.67,[]
16vxq4g,PrestigiousSkirt3655,,2023-09-30 04:43:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16vxq4g/interpret_this/,interpret this,,learnmachinelearning,https://i.redd.it/73ak02ngobrb1.png,1,0,0.47,[Comment(id='k2tzcqy')]
16v9lss,,,2023-09-29 11:56:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v9lss/overeducated_but_not_actually_doing_anything/,Overeducated but not actually doing anything,"I've been following the Machine Learning roadmap for a while now. However, most of the courses focus more on the theoretical side, not on the practical/applied side. I feel like I'm being overeducated, and not actually doing anything. I'm having a lots of theoretical skills that I'm not actually applying and it feels useless.  
At what point should I just stop learning and do something, make some models?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v9lss/overeducated_but_not_actually_doing_anything/,16,20,0.79,"[Comment(id='k2ppg97'), Comment(id='k2pons1'), Comment(id='k2pnb4l'), Comment(id='k2qdhx6'), Comment(id='k2qit2s'), Comment(id='k2pz0lk'), Comment(id='k2py3j2'), Comment(id='k2qfmz2'), Comment(id='k2qrgdd'), Comment(id='k2qyhdz'), Comment(id='k2qoupb'), Comment(id='k2qqih1'), Comment(id='k2qruye'), Comment(id='k2qskvn'), Comment(id='k2qtpyv'), Comment(id='k2qu460'), Comment(id='k2qum30'), Comment(id='k2qv7c3'), Comment(id='k2qw0ux'), <MoreComments count=0, children=[]>]"
16vrs9r,Rit2Strong,,2023-09-30 00:01:23+00:00,False,,1696032579.0,False,True,False,/r/learnmachinelearning/comments/16vrs9r/how_to_configure_the_gpu_for_jupyter_notebooks/,How to configure the GPU for jupyter notebooks,"pytorch is able to recognize my gpu when run outside of a jupyter notebook (as in when running it in the terminal), but fails to recognize it when running inside of a jupyter notebook. I've installed cudatoolkit using conda, but it still fails to recognize (torch.cuda.is\_available() returns False). Has anyone else encountered a similar problem and was able to fix it? Thanks in advanced!

My system is POP OS 22.04

&#x200B;

Edit: SOLVED

I followed [this site](https://saturncloud.io/blog/a-guide-to-installing-pytorch-with-anaconda-and-troubleshooting-errors/). I ran ""conda install pytorch torchvision cudatoolkit -c pytorch"" and it seems to work on the jupyter extension of vscode, although it doesn't work when running a jupyter notebook via anaconda.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vrs9r/how_to_configure_the_gpu_for_jupyter_notebooks/,0,2,1.0,[]
16vq5ix,Mildu12,,2023-09-29 22:54:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vq5ix/where_to_learn_neat/,Where to learn NEAT,"I have learned neural nets with basic evolutionary algorithms and have applied it a couple of times (flappy bird, etc…). I want to learn NEAT next, but i can’t seem to find a complete source to learn from. Any suggestions?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vq5ix/where_to_learn_neat/,0,2,1.0,[]
16vfmcb,Tasty-Seaweed709,,2023-09-29 16:04:54+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vfmcb/suggest_some_new_and_unique_projects/,Suggest some new and unique projects.,I want to make ml project for my college and also have to write a research paper on it. Can anyone please suggest some good ml projects that are based on some real world problems. Projects that are new and not some repeated already made multiple times.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vfmcb/suggest_some_new_and_unique_projects/,1,4,1.0,[Comment(id='k2sfv0k')]
16vh537,Chillseashells,,2023-09-29 17:04:09+00:00,False,,1696007952.0,False,True,False,/r/learnmachinelearning/comments/16vh537/neural_network_with_genetic_algorithm_weight_and/,neural network with genetic algorithm weight and bias initialization too big,"Hello everyone, I am trying to make some simple NN and ""train"" it with genetic algorithm. Here is my problem,

Let say that I have 4 nodes on input layer and 1 output layer with only 1 node. The way the genetic algorithm work is that it will randomize the weight and bias of each node connecting from input to output node. The randomization will be a random number from 0 to 1 and anywhere in between.  I have not make it but I can already identify problem with this method.

Since the average randomness will be 0.5, it means that the output node will be a very big value on average as well. So if all 4 input node's input is \[1,1,1,1\], we multiply it by the weight (average randomness is 0.5), we will get 2 + bias (0.5) = 2.5 in output node. (On average bias value will be 0.5).  I feel like I need some sort of function to not make the output very big like this. (The output should be 1)

&#x200B;

https://preview.redd.it/ket2pxyl78rb1.png?width=927&format=png&auto=webp&s=ef91b189c2b1c806af0b202351c23896360fe0f3

above is the illustration, activation function is sidmoid. Help appreciated thanks!

EDIT:

I feel like I need some sort of function that initialize/mutate the weight and bias to not be that big on average. But not sure what it's called",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vh537/neural_network_with_genetic_algorithm_weight_and/,3,3,1.0,"[Comment(id='k2ryrqq'), Comment(id='k2rgd03'), Comment(id='k2rz0qy')]"
16vddy5,tdionis,,2023-09-29 14:37:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16vddy5/we_trained_a_semantic_segmentation_model_for/,We trained a Semantic Segmentation model for cracks using ONLY synthetically generated training data - look what we've achieved!,,learnmachinelearning,https://supervisely.com/blog/unleash-the-power-of-domain-adaptation-with-HRDA-synthetic-cracks-segmentation/,0,4,1.0,[]
16vnsqa,johnsonnewman,,2023-09-29 21:23:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vnsqa/tips_on_managing_large_sequential_image_dataset/,Tips on managing large sequential image dataset,"We have a lot of sequential image data. Any tips on how to sort out the training, test and validation sets? We currently track them with spreadsheets and parse those sheets with scripts. Is there a better way?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vnsqa/tips_on_managing_large_sequential_image_dataset/,0,1,1.0,[]
16veara,hey__bert,,2023-09-29 15:13:15+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16veara/help_seeingunderstanding_how_training_information/,Help seeing/understanding how training information is actually stored in transformer models.,"I understand how transformer models are encoded, trained with weights, bias, loss, and their basic structure, but, to me, the most confusing thing about ML is how information is actually represented/stored inside a trained model. I know that models are convoluted enough to make it challenging to understand how they work, but it would really help me to see an ultra simple example of a tiny trained model and to be able to deconstruct what it actually looks like inside. Something as simple as a model for adding 1-9 digits or something. I just want to understand the data structure and the forms these things take inside. Does anyone know of a teeny-tiny model example or something like this I could look at?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16veara/help_seeingunderstanding_how_training_information/,1,3,1.0,[Comment(id='k3lp0xm')]
16vh5p8,kingabzpro,,2023-09-29 17:04:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vh5p8/top_7_free_cloud_notebooks_for_data_science/,Top 7 Free Cloud Notebooks for Data Science,"Read my reviews about the top 7 free cloud notebooks for data science here: [https://www.kdnuggets.com/top-7-free-cloud-notebooks-for-data-science](https://www.kdnuggets.com/top-7-free-cloud-notebooks-for-data-science)

&#x200B;

**The list:**

1. Deepnote

2. Kaggle

3. Hex

4. Noteable

5. Google Colab

6. naas.ai

7. JetBrains Datalore",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vh5p8/top_7_free_cloud_notebooks_for_data_science/,0,2,0.75,[]
16vkx0q,GeeksGuideNet,,2023-09-29 19:28:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vkx0q/how_to_create_a_machine_learning_model_in_5_easy/,How to Create a Machine Learning Model in 5 Easy Steps,"Learn how to create a machine learning model in 5 easy steps? Check out my latest blog post and find out how to define, explore, train, evaluate, and deploy your model.

https://geeksguide.net/102-2/",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vkx0q/how_to_create_a_machine_learning_model_in_5_easy/,0,0,0.33,[]
16vizzt,GeeksGuideNet,,2023-09-29 18:16:25+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vizzt/loss_function_what_are_they_and_how_to_choose_one/,Loss function: What are they and how to choose one,"Loss functions measure how well a machine learning model fits the data and guide its learning process. Choosing the right loss function is crucial for achieving good performance.

Learn more at https://geeksguide.net/98-2/",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vizzt/loss_function_what_are_they_and_how_to_choose_one/,0,1,0.6,[]
16v95bk,thegoodone27,,2023-09-29 11:33:38+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v95bk/buying_a_pc_for_machine_learning/,Buying a PC for Machine Learning,"Hi, I have been looking at PC for machine learning. I'm not really too keen on building one by myself so I've been looking at rebuilt ones instead. Is this build good for machine learning? https://www.aftershockpc.com/products/amd-ren

Thanks for the feedback!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v95bk/buying_a_pc_for_machine_learning/,3,2,1.0,"[Comment(id='k2pn3n6'), Comment(id='k2pw09d'), Comment(id='k2r3uhs')]"
16v8yh3,spmallick,,2023-09-29 11:24:00+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v8yh3/learn_how_to_train_the_kerascv_yolov8_model/,Learn how to train the KerasCV YOLOv8 model," YOLOv8 is the latest addition to the KerasCV library. With an easy training pipeline and high performance, it is now a breeze to use YOLOv8 with TensorFlow and Keras. You can learn how to train the KerasCV YOLOv8 model on a real-world traffic light detection dataset.   
 https://learnopencv.com/object-detection-using-kerascv-yolov8/  ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v8yh3/learn_how_to_train_the_kerascv_yolov8_model/,0,2,1.0,[]
16vcqvy,Uilxitora,,2023-09-29 14:13:27+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vcqvy/best_sentence_embedding_models/,Best Sentence Embedding Models,Does anyone know which are currently the best Sentence Embedding pre-trained models out there?,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vcqvy/best_sentence_embedding_models/,2,1,1.0,"[Comment(id='k2q5ql6'), Comment(id='k6xtnna')]"
16vchhm,Feisty_Object2081,,2023-09-29 14:03:03+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vchhm/arangodb_summit_2023/,ArangoDB Summit 2023,"🎉 Hello wonderful Reddit Community,

Hope this post finds you well!  We're thrilled to share a special event with you - the upcoming ArangoDB Summit 2023 on October 11th. It's a day dedicated to insightful discussions, exploring technology trends, and staying updated about all things ArangoDB.

Whether you're deeply into coding, passionate about data science, or simply curious about the tech world, this summit is tailor-made for you. It's a chance to learn, grow, and connect with fellow professionals who share your interests. 🌟

We're fortunate to have some remarkable speakers lined up from diverse backgrounds, including Altair, Arcules, Cars24, Cogniware, Cyclode, Global Relay, Metacx, TRG, and more. Their journeys and experiences with ArangoDB are sure to inspire and enlighten. 🚀👩‍💻👨‍💻

Secure your spot today by registering here: [https://hopin.com/events/arangodb-summit-2023-62e652eb-85c2-4eaf-8f06-2becce6144e6?utm\_source=r/learnmachinelearning&utm\_campaign=external%20promotion](https://hopin.com/events/arangodb-summit-2023-62e652eb-85c2-4eaf-8f06-2becce6144e6?utm_source=r/learnmachinelearning&utm_campaign=external%20promotion)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vchhm/arangodb_summit_2023/,0,1,1.0,[]
16vcfdj,ihaveajob79,,2023-09-29 14:00:56+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vcfdj/question_about_using_openai_embeddings_to_cluster/,Question about using OpenAI embeddings to cluster my users,"Hi everyone. I'm a curious machine learning aficionado, but I learn as I go and have not a lot of formal training beyond college a while back. I'm working on a process to cluster my users by job title and industry, with the idea of showing them customized training and onboarding material for my app. So the process I follow, at a high level, is:

1. Compute embeddings for the set of (job-title, industry) pairs; I gave about 5000 total. Note that many job-title entries are set to 'unknown'.
2. Cluster the embeddings using k-means (Sklearn library). I tried with various numbers of clusters, between 20 and 200.
3. In the future, when new users arrive, I'd compute their embedding and find the nearest cluster for classification.

However, the clustering feels poor, with lots of outliers such as **<helpline accountibility officer | nonprofit or charitable organization>** in the same cluster as **<regional manager | automotive repair and maintenance>**, and in the same cluster there are lots of medical device manufacturing folks.

So I'm wondering what to try next, and I have some ideas but I have no intuition as to what might work best:

1. Throwing more data for each user, such as their email's domain name, in the hope that the embeddings can extract more meaning
2. Clustering job titles and industries separately, and then using both indexes to classify new users
3. Somehow processing the embeddings to reduce the dimmensionality (how?) so there's less overfitting

What would you do in my shoes? And thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vcfdj/question_about_using_openai_embeddings_to_cluster/,2,1,1.0,"[Comment(id='k3y0oe6'), Comment(id='k419m1h')]"
16vabuj,Potential_Plant_160,,2023-09-29 12:29:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16vabuj/need_guidance_in_projects/,Need Guidance In Projects,"Hi everyone ,i have little bit knowledge of nlp and computer vision , which is more good way 

1)Building end to end projects 
2) Building different types of projects for different tasks with different libraries and methods like word2vec,transformers and BOW

which is more good way , i have 6 months of experieance in this field , i need to build sme goood projects to showcase on my cv and also i want to be good at nlp and cv and later on upcoming technoologies like llm and etc

and also I want to be proficient in coding and to have in-depth knowledge in ml and dl and i don't know which is the good way , can anybody guide me",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16vabuj/need_guidance_in_projects/,0,1,1.0,[]
16uzoaj,Lord_of_codes,,2023-09-29 02:35:55+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16uzoaj/how_does_classification_utilize_vectors/,How does classification utilize vectors?,"I am a mathematics student, I know linear algebra. But, I am very new to ML, just started.

&#x200B;

Let's say we have below data,

|Buying|Maintenance|Safety|Class|
|:-|:-|:-|:-|
|high|low|high|acc|
|vhigh|vhigh|low|unacc|

&#x200B;

We can train the model using the data above. The model will create an SVC and try to predict the class.

&#x200B;

So, the model tries plotting them on a 3D plane and finding support vectors.

&#x200B;

My question is,

1. What goes on the x, y, and z axis?
2. Which axis will represent the class?

Because we do something like below,

    feature_columns = ['buying', 'maint', 'safety']
    label_column = ['class']
    
    svm_classifier = svm.SVC()
    X_train, X_test, y_train, y_test =  train_test_split(features, label, test_size=0.2)

What are the x and y here?  I am confused.

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16uzoaj/how_does_classification_utilize_vectors/,4,5,0.86,"[Comment(id='k2tid7t'), Comment(id='k2oxg4v'), Comment(id='k2pig1l'), Comment(id='k2px3vs')]"
16v3pgw,Personal-Trainer-541,,2023-09-29 06:08:45+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16v3pgw/why_batch_norm_works/,Why Batch Norm Works,,learnmachinelearning,https://youtu.be/JjKLkY-b0aI,0,2,0.67,[]
16v9lro,,,2023-09-29 11:56:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v9lro/overeducated_but_not_actually_doing_anything/,Overeducated but not actually doing anything,"I've been following the Machine Learning roadmap for a while now. However, most of the courses focus more on the theoretical side, not on the practical/applied side. I feel like I'm being overeducated, and not actually doing anything. I'm having a lots of theoretical skills that I'm not actually applying and it feels useless.  
At what point should I just stop learning and do something, make some models?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v9lro/overeducated_but_not_actually_doing_anything/,1,0,0.5,[Comment(id='k2psn44')]
16vesn2,OnlyProggingForFun,,2023-09-29 15:32:32+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16vesn2/why_do_different_language_models_react/,Why do different language models react differently? How to prompt like a pro!,,learnmachinelearning,https://youtu.be/AOeKFlSLMOA,0,0,0.33,[]
16v7auk,virtsaa_ja_ulostetta,,2023-09-29 09:52:41+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v7auk/question_regarding_bayesian_spam_detection/,Question regarding Bayesian spam detection posterior,"For my assignment, I'm tasked with building a naive Bayesian word-based spam classifier using Bayes' theorem and strong independence assumptions. The primary goal is to calculate the posterior probability of a comment being spam based on the words within the comment.

I have the following key elements in my assignment:

* Spam status of a comment denoted as S (S = 1 for spam, S = 0 for not spam).
* Words within the comment denoted as W1, W2, ..., Wn.

https://preview.redd.it/8gbtght626rb1.png?width=1252&format=png&auto=webp&s=58f6562c7f2309111e1fb9411eb8a3a13580d718

[I am having a hard time deciding if its 2. or 3., I believe they both make sense but there is only one correct answer...](https://preview.redd.it/6i3t8u6126rb1.png?width=1138&format=png&auto=webp&s=c2c3922b21f948355e1a6acea16269b4c76a7c45)

I appreciate any insights, explanations, or corrections you can provide.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v7auk/question_regarding_bayesian_spam_detection/,0,1,1.0,[]
16ujluo,sim0of,,2023-09-28 15:50:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ujluo/work_asked_me_to_tell_them_which_pc_to_buy_for_me/,Work asked me to tell them which PC to buy for me - Suggestions? plshelp,"Hello everyone,

I have been working as a junior developer in this company for some months now

I have been using my own Acer Nitro 5 17"" (i7 11800h, RTX 3060 Laptop 6GB, 16GB Ram)

So far I've been involved in projects with computer vision, audio and nlp

This is an entirely new branch for the company and I'm still a student at the beginning of my journey, therefore there is no ""standard modus operandi"" for doing things and basically I'm the one responsible for telling them what piece of hardware is best for my needs

Anything that involves training we just rent GPUs from the major providers so I'm definitely not worrying about that

Things I will definitely be working on

\- OpenAI API integration  
\- NVIDIA NeMo framework  
\- YOLO  
\- Langchain, elastic and similars

&#x200B;

Since I've been busy studying and learning stuff I've never really bothered looking into hardware requirements for any of the things I've done/will do

Does the hardware choice matter in this case?  


They proposed me a laptop with i7 12th gen, 16GB Ram, and RTX4050 which costs 1k euros

I told them to hold off and that I would have done some further research because that doesn't look like a solid investment in my opinion

&#x200B;

**What (I think) I know:**

Budget I assume is something in the 1k - 2k range but they really just care about giving me something that allows me to provide good results

\- Pretty much when running models locally for testing and developing, they will run on a GPU, which I assume has to be powerful. But how powerful is powerful enough? 4060? 4080? 4090? Do mobile CPUs even make sense?  
\- I notices some dockerized services take up a fair bit of my current CPU, so is it coherent to assume that a more recent CPU with more cores and pretty much more power would be beneficial for my work?  
\- 16GB Ram nowadays is barely enough for google chrome with a few extensions so I don't really have any doubts that going for 32GB is a reasonable enough upgrade  
\- I work both at home, at the office and around the world when I'm in WFH mode, so a laptop would seem a better option than a Desktop PC, but is that actually the case?  


**What I don't know**

Aside from the fact that this section worringly overlaps with the ""what I know section""..  
I've only considered Windows laptops onto which I would at the very least make dual boot with linux if not exclusively linux because the NVIDIA NeMo framework can't run on windows

Given what I will do, should I even consider Apple? Like a Macbook Pro M1 or something like that?

  
I already have high end desktop pc at home and my current laptop is already something I'm comfortable bringing around, but one big limitation is that I always need to be plugged into a power source or the battery drains withing one hour of work  
AFAIK a macbook pro would kinda allow me to work anywhere so that'd be a cool quality of life upgrade but I doubt it's practically worth anything other than a ""cool!"" reaction

&#x200B;

As you can see there's a lot of stuff I don't know and I don't really know what I actually need

Thank you so much for any help and suggestion towards the right direction!  
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ujluo/work_asked_me_to_tell_them_which_pc_to_buy_for_me/,11,19,0.95,"[Comment(id='k2n62ax'), Comment(id='k2n35hz'), Comment(id='k2lgk77'), Comment(id='k2p3byq'), Comment(id='k37caft'), Comment(id='k2lgu4d'), Comment(id='k2m71op'), Comment(id='k2nitcl'), Comment(id='k2o78j7'), Comment(id='k2ovdjd'), Comment(id='k2o7m8h')]"
16upqjz,ramyaravi19,,2023-09-28 19:54:01+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16upqjz/interested_in_creating_your_own_chatbot_using/,"Interested in creating your own chatbot using NeuralChat, a customizable chatbot framework? Check out the article.",,learnmachinelearning,https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/NeuralChat-A-Customizable-Chatbot-Framework/post/1526789,0,8,0.84,[]
16v5ax2,No_Acanthisitta_673,,2023-09-29 07:45:47+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v5ax2/best_free_online_programming_courses/,Best free online programming courses,"These courses are 100% free and have high ratings that make them one of the best free alternatives for learning programming.
( JavaScript - CSS - Html - Python ) 

JavaScript

1- https://try2link.com/F5uTF                     ( from Udemy)

2- https://try2link.com/fbDe4TG                  (from Educative ) 

3- https://try2link.com/EE6ESt29                (from Udemy )

Css and Html

1- https://try2link.com/eitlb                       ( from Udemy )

2- https://try2link.com/7c5N9h                   ( from Udemy )

3- https://try2link.com/rolR8IGq                 ( from Udemy )

Python

1- https://try2link.com/M8GI                       (from Scaler )

2- https://try2link.com/DoJfjY                     ( from Coursera )

3- https://try2link.com/KwHKmL               ( from Udemy)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v5ax2/best_free_online_programming_courses/,0,0,0.33,[]
16uatfk,Jarr0t,,2023-09-28 08:59:29+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16uatfk/how_to_interest_a_company_in_your_machine/,"How to interest a company in your machine learning skills, if you're beginner","Often, when you show your pet projects on machine learning at an interview, like MNIST, or recognizing heart disease, no one is interested in it. what projects can be made so that they are close to real projects?

Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16uatfk/how_to_interest_a_company_in_your_machine/,24,66,0.9,"[Comment(id='k2ktrbw'), Comment(id='k2kcw1z'), Comment(id='k2jxsfy'), Comment(id='k2kddcn'), Comment(id='k2l7rcz'), Comment(id='k2l9ptl'), Comment(id='k2k6zja'), Comment(id='k2k28pe'), Comment(id='k2l4xev'), Comment(id='k2l54nr'), Comment(id='k2kkea9'), Comment(id='k2m5d5q'), Comment(id='k2oe8y1'), Comment(id='k2ogex7'), Comment(id='k3aqq0h'), Comment(id='k2m6mfr'), Comment(id='k2jyk2n'), Comment(id='k3bez9c'), Comment(id='k2k29eu'), Comment(id='k2kcolv'), Comment(id='k2q38x6'), Comment(id='k2lbp3s'), Comment(id='k2q3b40'), Comment(id='k2llj9h'), Comment(id='k2mmjuu')]"
16un7fz,Tarmicle,,2023-09-28 18:15:02+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16un7fz/pursuing_a_degree_for_ai_and_machine_learning/,Pursuing a Degree for AI and Machine Learning Passion – Math vs. Computer Science?,"Hello everyone, I'm not entirely sure if this is the right subreddit for my question, but I've been scouring the internet and hit a bit of a roadblock. I'm currently working as a Data Analyst, and I don't have any intentions of switching careers. However, I've developed a strong passion for AI and machine learning. I've been thinking about pursuing a degree while continuing to work, purely out of curiosity and my passion for the field. This is more of a lifelong endeavor, a personal challenge, if you will. I'm not ruling out a potential career change down the line, but that's not the primary goal right now.

I've already taken up self-study in mathematics, just for the sake of challenging myself, and I've been thoroughly enjoying it. Given my aspirations, I'm torn between pursuing a Bachelor of Science degree in Mathematics or Computer Science. I'm a bit conflicted because I've read that machine learning is heavily rooted in mathematics. Unfortunately, I live in Europe, and I can't major and minor like in some educational systems; it's an either-or situation here.

Looking ahead, since I view this as a lifelong learning journey, I might even consider pursuing a Master's degree or maybe even a PhD. Who knows? But at this stage, I'm uncertain about which path to take: should I go for math and coding, or opt for Computer Science with additional math studies if necessary? What are your thoughts on this?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16un7fz/pursuing_a_degree_for_ai_and_machine_learning/,6,9,1.0,"[Comment(id='k2pfuji'), Comment(id='k2qvkfo'), Comment(id='k2pa14m'), Comment(id='k2xdrci'), Comment(id='k2xtjkn'), Comment(id='k30m844')]"
16us73t,BadExtension1309,,2023-09-28 21:26:25+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16us73t/build_a_machine_learning_model_with_python/,Build a Machine Learning Model with Python,,learnmachinelearning,https://www.youtube.com/watch?v=Bcnr58IXkeQ&ab_channel=EpicProgrammer,0,3,0.81,[]
16v1wik,Dull-Television-7049,,2023-09-29 04:27:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16v1wik/ml_model_to_solve_the_hangman_game/,ML model to solve the Hangman game,"I am a beginner in ML, I want to write an algorithm to play the Hangman game. 

I have a dictionary text file to be used as the dataset for training/testing. 

I read about multiple ways to solve the problem, but I am confused how to train a model to do it. Logistic Regression/Decision tree what do I use? 

If someone could give me an idea about how to proceed (a roadmap of sorts) , it would be very helpful",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v1wik/ml_model_to_solve_the_hangman_game/,3,0,0.5,"[Comment(id='k2piyzw'), Comment(id='k2r504k'), Comment(id='k2u84vx')]"
16ux1z9,sovit-123,,2023-09-29 00:38:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ux1z9/manual_hyperparameter_tuning_in_deep_learning/,Manual Hyperparameter Tuning in Deep Learning using PyTorch,"Manual Hyperparameter Tuning in Deep Learning using PyTorch

[https://debuggercafe.com/manual-hyperparameter-tuning-in-deep-learning-using-pytorch/](https://debuggercafe.com/manual-hyperparameter-tuning-in-deep-learning-using-pytorch/)

&#x200B;

https://preview.redd.it/uw3kb10xb3rb1.png?width=1000&format=png&auto=webp&s=7796b543d8e7f89ddf2e3efc854a7c7463dc5895",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ux1z9/manual_hyperparameter_tuning_in_deep_learning/,0,2,0.75,[]
16v14ho,SufficientTime2996,,2023-09-29 03:47:31+00:00,False,,1695972326.0,False,True,False,/r/learnmachinelearning/comments/16v14ho/help_me_with_my_project_named_neural_networks/,Help me with my project named :neural networks based web application firewalls,"""I've developed a web application firewall based on neural networks, which includes a trained model with high accuracy for handling various security threats. Now, I need guidance on the best practices for deploying this setup in a production environment. Specifically, what considerations should I take into account when integrating my neural network-based firewall with my web server and app server? Are there any deployment frameworks or tools that are recommended for this kind of setup",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16v14ho/help_me_with_my_project_named_neural_networks/,0,1,0.67,[]
16uolgn,3Ammar404,,2023-09-28 19:09:13+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16uolgn/d_convert_specific_domain_knowledge_text_to_a/,[D] Convert specific domain knowledge text to a knowledge graph,"Hi Guys,

As part of this semester assignment , I'm working on a project that aims to to represent the knowledge in ""PMBOK 6th edition, section 11: Project Risk Management (page 395 -> 458)""  and the knowledge in ""PMI standard for Risk Management "" (128 pages) as a knowledge graph. The generated knowledge graph will be used later to build recommendation system to infer real-time personalized recommendations.

I have been reading on how to convert unstructured text into a knowledge graph  in research papers and  articles and I have found mainly 3 ways to do this:  
1/ Using a joint of  *Named-entity recognition* (*NER*) and Relation Extraction (RE) to extract the entities and the relations from your unstructured text.     
2/ taking advantage of the linguistic knowledge of Transformer models and fine tune a transformer model (BERT, T5)  for the task of extracting entities and relations. I could find some pretrained models like REBEL :[https://github.com/Babelscape/rebel](https://github.com/Babelscape/rebel).

3/ use prompt engineering  (LLM (GPT)) to generate the knowledge graph.  


I could not find any of the three approaches as good as I wanted: 

1/ The majority of the resources I have found that tackles the first approach (NER & RE)  showcase simple tasks where the named entities and  relations are very straightforward. Example this article here: [https://freedium.cfd/https://medium.com/mlearning-ai/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7](https://freedium.cfd/https://medium.com/mlearning-ai/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7)  where the entities are \[skills, Diploma, Major, Year of experience\] and the relations \[DEGREE\_IN, EXPERIENCE\_IN..\]. In this case, training  NER and RE models will be easy. But in my case, determining entities and relations is very complex. Annotating the corpus manually is incredibly tedious and labor-intensive (Could not even determine what are the entities and the relations) . You can grab a feeling of how complex it is by looking at how big our dataset is (191 pages of knowledge) and how complex the knowledge is in the corpus (many definitions, a lot of terminology...)

2/ I have used the pretrained REBEL model but  the results looked weird. (redundant relations, sometimes the extracted relations make non sense). And So I wanted to fine tune BERT for this specific task on my custom data (PMBOK, PMI) but I really could not understand how to do this   (what should be the data format to train and test the transformer model?, how to evaluate the model ?...)

3/ The fact that LLM are stochastic models,  a lot of variations in the generated graphs for each prompt (sometimes huge differences)  and this lead to huge ambiguity because I cannot evaluate how good the graph is in representing the knowledge.

I'm open to any  other resources and any other inspirations or approaches to tackle this project. Thank you in advance.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16uolgn/d_convert_specific_domain_knowledge_text_to_a/,3,5,1.0,"[Comment(id='k2otkoq'), Comment(id='k2q6woj')]"
16upi9w,saintshing,,2023-09-28 19:45:02+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16upi9w/distill_a_machine_learning_journal_for_articles/,"Distill, a machine learning journal for articles containing interactive graphics and explorable explanations",,learnmachinelearning,https://distill.pub/,0,2,0.75,[]
16uj8t7,Emto1,,2023-09-28 15:36:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16uj8t7/ml_for_mechanical_engineer/,ML for mechanical engineer,"Hi! I am mechanical engineer in automotive and i would like to have a career change. Would be really helpful is you can give me tips how to start learning ML?

Thanks

E",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16uj8t7/ml_for_mechanical_engineer/,4,3,0.8,"[Comment(id='k2npx7u'), Comment(id='k2oeafq'), Comment(id='k2nzdnu'), Comment(id='k2oy1fe')]"
16urqcv,Ppspecial,,2023-09-28 21:09:28+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16urqcv/plausibility_of_a_problem_automate_writing/,Plausibility of a problem: Automate writing feedback," 

Hello everyone,

I'm not a data science student, so I'm exploring ways to automate a specific task using pre-trained models (probably with fine-tuning, or with a vector db). I'm finding it challenging to grasp the technical details due to my non-technical background. Here's a simplified breakdown of what I'd like to achieve:

1. I input a paragraph as a prompt for the model.
2. The model identifies and highlights grammar, language, and structural errors within the paragraph. For instance, if there's a comma splice error, it should flag it and provide a comment  

   1. I have a dataset of pre-built comments, comprising over 600 rows. For example, if a student fails to include a topic sentence in a paragraph, I have a comment under the ""structure"" category that suggests, ""You should start each paragraph with a topic sentence.""
3. Finally, I'm looking for overall feedback on the entire essay. For instance, the model could  
generate feedback like: ""Thank you for submitting your work. I've noticed \[specific issues\]  
regarding certain \[aspects\]. There were recurring problems with \[Issue 1\] and \[Issue 2\]""

Is this level of automation feasible and practical? If you need more details about the task, please comment on my post, and I'll provide the relevant information.

Thank you!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16urqcv/plausibility_of_a_problem_automate_writing/,0,1,1.0,[]
16uhvqr,am_kolade,,2023-09-28 14:42:18+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16uhvqr/computer_science_undergraduate_final_year_project/,Computer Science Undergraduate Final Year Project,"Hello,
I'm new here and also new to ML and related concepts.  My university project is centered around creating a model that can RECOGNIZE and EXPLAIN metaphors in WASSCE/SSCE (High school graduate exams in West Africa) English comprehensions. I need to write a proposal for the project topic and I need to do literature review of existing related projects. Please where can I get these? Also I, need some form of guidance as I'm new to ML/NLP. Basically, I need a mentor. I'm willing to work as hard as required.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16uhvqr/computer_science_undergraduate_final_year_project/,1,0,0.33,[Comment(id='k2o1ars')]
16uc8ju,ItisAhmad,,2023-09-28 10:24:31+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16uc8ju/design_patterns_in_machine_learning_engineering/,Design Patterns in Machine Learning Engineering | (Abstract) Factories and SOLID for Machine Learning Engineering,"ML Engineers often neglect design patterns. I gave a practical example on how to use Abstract factories and SOLID design pattern for creating a scaleable ML product.

Please give it a read, and leave some feedback if any.

[https://medium.com/red-buffer/abstract-factories-and-solid-for-machine-learning-engineering-621fb323e655](https://medium.com/red-buffer/abstract-factories-and-solid-for-machine-learning-engineering-621fb323e655)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16uc8ju/design_patterns_in_machine_learning_engineering/,0,2,1.0,[]
16unytw,Hour-Position-1285,,2023-09-28 18:44:53+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16unytw/transforme_sua_vida_com_o_estoicismo_17_regras/,Transforme sua vida com o Estoicismo | 17 regras para sucesso e felicidade,,learnmachinelearning,https://youtube.com/watch?v=ulik2BVO3qs&si=0xXDpGOPhBb1MQnd,0,0,0.29,[]
16ua1f2,zoontechnicon,,2023-09-28 08:09:05+00:00,False,,1695888981.0,False,True,False,/r/learnmachinelearning/comments/16ua1f2/stablediffusionxl_to_nodejs_port_doesnt_work_as/,"StableDiffusionXL to Nodejs port doesn't work as expected, what am I doing wrong?","Hello there,

I have a weird problem, which may be partly due to my ignorance, but I'm here to learn. I'm trying to port the diffusers implementation of StableDiffusionXL to Node.js using ONNX runtime and tensorflow.js

Here's the code:
https://github.com/nextcloud/text2image_stablediffusion/blob/main/src/stablediffusion.mjs

Even though I believe I've mirrored the math of both the stablediffusion model and the EulerDiscrete scheduler to a T, the result is a rubbish mosaic instead of a nice picture. At least the colors seem somewhat fitting for the prompts I've tried.

Sorry for the not so nice and object oriented code, I hope you can make sense of it. I've ported only the simplest logic to get at least something.

So far I've verified that the tokenizer output is on par with the official implementation and the text encoder output seems to be on par with the official ones as well. My suspicion is that something with the sigma schedule is off, or that the distribution of the initial noise is not right, but I can't seem to find the right values. Any help is greatly appreciated!

Thank you

PS: This is the output I get for the prompt ""Koala"" and 25 timesteps: https://imgur.com/a/WXm5JUy

EDIT: My code is based on https://github.com/huggingface/optimum/blob/main/optimum/pipelines/diffusers/pipeline_stable_diffusion_xl.py and https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_euler_discrete.py",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ua1f2/stablediffusionxl_to_nodejs_port_doesnt_work_as/,1,2,0.75,[Comment(id='k2kcyjx')]
16u8wlk,Illustrious_Fan6054,,2023-09-28 06:55:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16u8wlk/computer_science_final_year_project/,Computer science final year project,"I came up with the idea of developing a property marketplace as a web app as my computer science final year project so it got rejected.
The reason was that it lacks some Cs concepts like e.g AI, security etc as it was only front-end, backend and a database,so they wanted more of those concepts that could separate me as someone who did computer science from the crowd


Any ideas how I could integrate this concepts to my web app
And I'd also love to get some suggestions on which idea I could do if this one doesn't work out
I'm more interested in software dev",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u8wlk/computer_science_final_year_project/,8,2,0.75,"[Comment(id='k2kbo7p'), Comment(id='k2l4esp'), Comment(id='k2ma44u'), Comment(id='k2n15ji'), Comment(id='k2lq1hc'), Comment(id='k2lq5uz'), Comment(id='k2r14aq'), Comment(id='k2r15zq')]"
16ub460,BitAccomplished7242,,2023-09-28 09:17:52+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16ub460/factor_influencing_adoption_intention_of_chatgpt/,Factor Influencing Adoption Intention of ChatGPT,"Hello,

&#x200B;

I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.

&#x200B;

Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.

&#x200B;

If you are interested in learning more about the study, please follow the link below. 

&#x200B;

[https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link)

&#x200B;

Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ub460/factor_influencing_adoption_intention_of_chatgpt/,0,1,0.67,[]
16tul9p,blueberryunpopular,,2023-09-27 20:09:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tul9p/does_the_complexity_of_the_model_influence_how/,Does the complexity of the model influence how much processing power will be required to run it?,"Basically what the title says. 

For example, say there are two models: 
- model A is a relatively simple object detection model trained on COCO (91 common objects in context) dataset
- model B is a relatively complex model that detects  whether a car driver is paying attention to the road while behind the steering wheel (through a camera installed on the dashboard)

Will running each of these models separately require the same amount of processing power? The ""amount"" here can be a quantity like the CPU/GPU utilization percentage, for example.

Maybe this is a trivial question, but I'm curious to see what everyone thinks. Thanks!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tul9p/does_the_complexity_of_the_model_influence_how/,10,12,0.8,"[Comment(id='k2hmtqw'), Comment(id='k2i5i34'), Comment(id='k2ista9'), Comment(id='k2hp65k'), Comment(id='k2hdh3a'), Comment(id='k2hsxx3'), Comment(id='k2kz309'), Comment(id='k2he7h8'), Comment(id='k2hfexp'), Comment(id='k2iaxv3')]"
16uo0j7,Hour-Position-1285,,2023-09-28 18:46:42+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16uo0j7/razões_para_não_ter_s3xo_de_acordo_com_filosofia/,"RAZÕES PARA NÃO TER S3XO de acordo com FILOSOFIA Epicurismo, estoicismo ...",,learnmachinelearning,https://youtube.com/watch?v=M4r7axFYf34&si=d4LvwjQ6PVfpcXwg,1,0,0.11,[Comment(id='k2z2r1x')]
16u5vw2,Academic-Frosting577,,2023-09-28 04:05:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16u5vw2/audio_classification_of_events/,Audio classification of events,"Could someone share some sources on how I could learn to classify certain ""events"" in audio? All i'm able to find is classifiers on voices, moods, etc of human speech. However, I want to figure out how to detect when a plate was broken, or a dog barked",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u5vw2/audio_classification_of_events/,0,2,1.0,[]
16u9jmm,qhelspil,,2023-09-28 07:35:43+00:00,False,,1695896946.0,False,True,False,/r/learnmachinelearning/comments/16u9jmm/forex_predictions_how_can_i_improve_a_model/,forex predictions: how can i improve a model,"what i am trying to do is 3 hours from the start of neyyork session, i must predict the trend until the close of the session. model trained only on closing price

i trained my model on prices from 8 am till 11 am, 5 minute timeframe, from 2012 till 2022

if closing price at 4 pm more then 20 pips above closing price at 11 am, label is 1

if closing price at 4 pm is more then 20 pips below closing price at 11 am, label is 0

if difference between closing price at 4 pm and 11 am is less then 20 pips, label is 2

the model predicts labels 0 and 1 with 86% precision score, but label 2 is 50%, with xgboost

why is this bad performace?

what would you suggest to improve the model?

thanks for help

&#x200B;

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u9jmm/forex_predictions_how_can_i_improve_a_model/,4,0,0.5,"[Comment(id='k2lymxc'), Comment(id='k2mdgz4'), Comment(id='k2qhl4p'), Comment(id='k2qkoxd')]"
16u5jh2,avangard_2225,,2023-09-28 03:46:33+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16u5jh2/has_anyone_recently_used_uber_api_to_extract_data/,Has anyone recently used Uber API to extract data,"need to use below 2 endpoints but I am stuck

    GET /v1.2/products: List the available products for a given location.
    GET /v1.2/estimates/price: Get price estimates for a ride between two locations.

looks like I need the server token but they stopped giving out those : [https://developer.uber.com/docs/riders/references/api](https://developer.uber.com/docs/riders/references/api)

I got the user access token but that does not work with any of the endpoints above. I am currently stuck with the below message;

    https://api.uber.com/v1.2/products?latitude=37.7759792&logitude=-122.418238

response;

    {
        ""code"": ""unauthorized"",
        ""message"": ""This endpoint requires at least one of the following scopes: ride_request.estimate""
    }

really appreciate anybody showing any insights. 

&#x200B;

TIA!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u5jh2/has_anyone_recently_used_uber_api_to_extract_data/,2,2,0.75,"[Comment(id='k4l0dp2'), Comment(id='k4kzcph')]"
16u3mol,lemmeister,,2023-09-28 02:14:22+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16u3mol/triton_interference_server/,Triton Interference Server,"Has anyone experienced the same issue when trying to ping the status of the model, it says 400 error, but when running a v2/health/ready, it gives a 200 response.

Here is the curl request:

curl -v [http://0.0.0.0:8000/v2/models/mycustommodel/1/status](http://0.0.0.0:8000/v2/models/mycustommodel/1/status)

And here is the response:

\* processing: [http://0.0.0.0:8000/v2/models/mycustommodel/1/status](http://0.0.0.0:8000/v2/models/mycustommodel/1/status)

\*   Trying 0.0.0.0:8000...

\* Connected to 0.0.0.0 (127.0.0.1) port 8000

\> GET /v2/models/mycustommodel/1/status HTTP/1.1

\> Host: 0.0.0.0:8000

\> User-Agent: curl/8.2.1

\> Accept: \*/\*

\>

< HTTP/1.1 400 Bad Request

< Content-Length: 0

< Content-Type: text/plain

<

\* Connection #0 to host 0.0.0.0 left intact

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u3mol/triton_interference_server/,0,2,1.0,[]
16u2t8p,tondlilover,,2023-09-28 01:38:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16u2t8p/handle_multiple_rows_for_the_same_customers_while/,Handle multiple rows for the same customers while doing customer segmentation?,"I have several rows with the same customer purchasing different items. None of them are duplicates. I want to do customer segmentation, but how can I handle multiple customer values?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u2t8p/handle_multiple_rows_for_the_same_customers_while/,1,2,1.0,[Comment(id='k2ksk2g')]
16u5vkn,sphyrch,,2023-09-28 04:04:40+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16u5vkn/what_appropriate_loss_function_or_framework_to/,"What appropriate loss function (or framework) to use for ""Search recall"" optimization?","I am studying machine learning and wanted to work on a project of my own so that I have better chances after graduating college. I'm studying the application of ML to improve searches. Here's a couple of example scenarios:

1. **Document retrieval (search) system**: We have a (source) document with us and we're trying to find a matching document in a database. The source document has text and image attributes - for simplicity let's say a title and a single image. Each search result will also be a document - with a title and at most one image.
2. **A search engine**: We have a query comprised of both text and an image (like google image search allows text to be added to the query as well). Each search result will be a website with text and image attributes (for simplicity, webpage title and at most one image)

More generally, I have a search system - whatever we're trying to search for has text and an image associated with it. Each search result will also have its own attributes. Let's denote each source document (or in case of search engine, a query) with D and each search result with R.

The metric that makes the most natural sense to me is **top k search recall** (not sure what the more widely used name for this is): suppose we have a sample of source documents or queries D\_1, … , D\_n, and let the search results for D\_i be R\_{i1},R\_{i2}, … , R\_{i(m\_i)}. If any of R\_{i1}, … , R\_{ik} is a match for D\_i, and if the value is k is not high, then we can say the search worked well for D\_i. So the top k search recall is the proportion of source docs/queries for which at least one match was found in the top k search results.

**LABELS**

*Just to clarify, I'm looking for a search result scoring/ranking model that uses source doc/query attributes and attributes of search results. It's not trying to tweak the way search is performed - just the way the search results are shortlisted into top k.*

Now to tweak my search system, let's say I also have a dataset with (source document - search result) pairs with labels - whether that search result is a match for that source document. i.e. something like

    D1   R11   No Match 
    D1   R12   No Match 
    D1   R13   Match 
    . 
    . 
    D1   R1100 No Match 
    D2   R21   No Match 
    D2   R22   Match 
    D2   R23   Match
    . 
    . 
    D2   R2100 No Match 
    .
    .

(as you can imagine it would be a highly imbalanced dataset)

My current approach to tweak the system is like this:

**FEATURES AND MODELING**

I can form features linking a source doc/query to a search result. e.g. some sort of embedding similarity between titles, or jaccard similarity of titles, or embedding similarity of their images, etc. There will be many null values too since some results may not have images, or some source docs/queries may not have images, or a result may not have a clear title, etc.

I'm using an XGB classifier - training, validating, testing it using the labeled dataset - the usual routine. I'm using the predict\_proba method of the classifier to output the probability of a doc-result pair being a match. I use that probability as a score. Then for each D\_i, the results with the top k scores are shortlisted. And then the top k search recall is measured for the D\_1, … , D\_n sample (i.e. classifier top k). Simple enough approach...

**PROBLEMS**

I'm not completely satisfied with the approach since I don't think I'm using the optimal loss function for the classifier. Right now it's just the standard XGBClassifier loss function. The classes are highly imbalanced as I said before. Artificially balancing the classes leads to a model that can better classify a matching or non-matching result, BUT it actually reduces top k search recall compared to a model trained on unbalanced dataset for some value of k.

**What else have I tried:** So I'm using jaccard text similarity and image similarity as two of the features.

* One modification I tried was using all features as separate ""scores"", and then calculated ranking for each of those ""scores"". So now I have different *feature ranks* \- I used reciprocal rank fusion to combine them into a single rank. RRF top k does not do as well as the classifier top k
* Another modification: I calculated classifier top (k-5). Then I clubbed those results together with jaccard text similarity top 3 and image similarity top 2. This method does a bit better than the classifier top k

The last point clearly indicates that my ""classifier with standard loss function""-based way of combining various features into a model is suboptimal. Otherwise the model itself should have learned to accommodate this top 3 and top 2 into its top k.

My question is, what is the recommended loss function for simultaneously maximizing the top k search recall and minimizing k? What is the best way to combine all this feature info into the optimal top k?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16u5vkn/what_appropriate_loss_function_or_framework_to/,0,1,1.0,[]
16tfcdo,Little-Egg-1163,,2023-09-27 08:51:30+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tfcdo/want_to_get_into_the_math_intensive_side_of_ml/,Want to get into the math intensive side of ML. Where do I start?,"Hi, I am an Electrical Engineering Undergrad. I spent some time completing the MIT OCW 6.036 Into To ML course, which is more mathematical than programming based. I'd like to get into the more math intensive side of ML and Deep Learning, where and how do i start??

PS: I have studied Linear Algebra, Complex Analysis, Multivariate Calculus and Differential Equations, Probability theory and Statistics through my degree already",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tfcdo/want_to_get_into_the_math_intensive_side_of_ml/,18,22,0.96,"[Comment(id='k2fkciu'), Comment(id='k2h0t67'), Comment(id='k2fylmu'), Comment(id='k2f00fx'), Comment(id='k2j6kuv'), Comment(id='k2jk994'), Comment(id='k2k01t8'), Comment(id='k2jg6t1'), Comment(id='k2h2wb0'), Comment(id='k2if5ii'), Comment(id='k2qn913'), Comment(id='k2jkfze'), Comment(id='k2jgmle'), Comment(id='k2iofin'), Comment(id='k2qnenm'), Comment(id='k2jgyt2'), Comment(id='k2qqqgd')]"
16tm644,Practical_Ad100,,2023-09-27 14:31:20+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tm644/football_plays_dataset/,Football Plays Dataset,"Hey,

I am trying to classify American football plays based on run, pass, kick, etc. for a school project, but I need a dataset that has videos. Does anyone know of publicly available, free datasets to do so? Also, what are some relevant subreddits I could crosspost to?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tm644/football_plays_dataset/,2,4,0.84,"[Comment(id='k2gcrcs'), Comment(id='k2gd0uy')]"
16tcgcr,MrSirLRD,,2023-09-27 05:56:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tcgcr/ive_recently_started_my_own_pytorch_deep_learning/,I've recently started my own Pytorch Deep Learning Tutorial Series!,"Yes another Pytorch Tutorial series, but hopefully mine is different enough to be useful for someone starting out with Pytorch! 

I based it on my time spent teaching Pytorch and Deep Learning to undergrads throughout my PhD, so there is some expectation of python/programming knowledge and some of the basic Deep learning concepts, though I try to link to as much free existing content as I can to fill the gaps.

The series is broken into small sections and comes in two parts, a Github repo with many Jupyter notebooks which go through concepts and basic implementations and a Youtube playlist where I will go through some of the key content one Jupyter notebook at a time!

[https://github.com/LukeDitria/pytorch\_tutorials](https://github.com/LukeDitria/pytorch_tutorials)

I'm working through getting more sections up and recording more videos!

Let me know what you think and if you have any suggestions!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tcgcr/ive_recently_started_my_own_pytorch_deep_learning/,1,18,1.0,[Comment(id='k2g8vgh')]
16t6tnn,ita9naiwa,,2023-09-27 01:31:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16t6tnn/how_to_learn_low_level_programming/,how to learn low level programming?,"what are good starting points to learn low-level programming (with respect to machine learning, like gpu kernel programming or c++)?

tutorials for cuda or c++ are quite straightforward to me, but actual codebases like pytorch, llama.cpp are too difficult for me. I guess the gap between them is huge.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16t6tnn/how_to_learn_low_level_programming/,16,34,0.92,"[Comment(id='k2epwnf'), Comment(id='k2dvmgr'), Comment(id='k2jjden'), Comment(id='k2ogtpg'), Comment(id='k2g0tex'), Comment(id='k2f33lu'), Comment(id='k2dttpo'), Comment(id='k2fy7mp'), Comment(id='k2hpdks'), Comment(id='k2enzzj'), Comment(id='k2g1h68'), Comment(id='k2dwtgo'), Comment(id='k2fd7yd'), Comment(id='k2oi0gp'), Comment(id='k2h2kxh'), Comment(id='k2hppl6')]"
16t7ezr,hkproj_,,2023-09-27 01:57:00+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16t7ezr/coding_stable_diffusion_from_scratch_in_pytorch/,"Coding Stable Diffusion from scratch in PyTorch, with full explanation of the maths behind diffusion models in a simple way!",,learnmachinelearning,https://www.youtube.com/watch?v=ZBKpAp_6TGI,2,32,0.93,"[Comment(id='k2dtrpw'), Comment(id='k2e29o7')]"
16tvra8,kingabzpro,,2023-09-27 20:54:39+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16tvra8/with_just_3_simple_steps_you_can_build_deploy_a/,"With just 3 simple steps, you can build & deploy a glass classification model faster than you can say...glass classification model!",,learnmachinelearning,https://www.kdnuggets.com/deploying-your-first-machine-learning-model,0,1,0.67,[]
16tvns2,Lacour_Moretti,,2023-09-27 20:50:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tvns2/asking_for_suggestions_on_gaming_laptop_as/,"Asking for suggestions on Gaming laptop as hardware for ML training job (computer vision, small scale dataset)","Hi guys,   
I am looking to purchase a new laptop that would satisfy the needs of some ML personal projects. I know there are cloud solutions out there, but I still want to know what kind of laptop would be good enough for small scale projects. Like for graph analysis tasks, I have the pipeline and program ready, but the dataset is around 50G (might increase the amount of data later). Currently what I am using: i7-10750H, 16GB RAM, 1TB SSD, NVIDIA RTX 2060. It's also a bit too old with a malfunctioning fan that would scream after hours of regular use.   
I'm thinking of some of the new ROG laptops with 4050 or 4060 GPUs, would that work?  
Thanks a lot for any advice!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tvns2/asking_for_suggestions_on_gaming_laptop_as/,2,1,0.67,"[Comment(id='k2hwcx9'), Comment(id='k2hwoem')]"
16tv1d9,lizziepika,,2023-09-27 20:26:20+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16tv1d9/get_an_ai_trisha_paytas_phone_call_with_her_take/,"Get an AI Trisha Paytas phone call with her take on personalized news using Replicate, AWS S3, Streamlit, and Eleven Labs",,learnmachinelearning,https://www.twilio.com/blog/trisha-paytas-phone-call-personalized-news,0,0,0.4,[]
16tglpn,vpysk,,2023-09-27 10:11:11+00:00,False,,1695809662.0,False,True,False,/r/learnmachinelearning/comments/16tglpn/mit_introduction_to_deep_learning_6s191_2023/,MIT Introduction to Deep Learning 6.S191 (2023) Review & Flashcard Notes,"Hello fellow scholars,

I watched all lectures and did assignments for [MITs online introduction to deep learning](https://introtodeeplearning.com/). I've also made flashcard question-style notes [here](https://pyskinas.github.io/mit/) for anyone looking to revise or skim; I only include questions that ***I*** found relevant so notes aren't equivalent to looking at lectures, especially for beginners.

**Review - Summary**

Good introduction to many deep learning concepts. Lacks depth. Overall 6/10.

**Review - Pros**

1. Lecturers are engaging, and I like their style.
2. Covers many deep learning topics in only 10 lectures (1hr  long).
3. Labs 1 and 2 are fun and you learn some tensorflow.

**Review - Cons**

1. Mathematical aspects are skimmed over, and implementation details of introduced topics are unclear.
2. Most of each lab is prewritten, and you end up only having to write 10-15 lines of (fairly clear) code total per lab.
3. Lab 3 and optional labs have bugs.

**Review - Rating - 6/10**

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tglpn/mit_introduction_to_deep_learning_6s191_2023/,0,6,0.88,[]
16tf6tq,PresentationSmall698,,2023-09-27 08:41:26+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tf6tq/dont_know_what_to_do/,Don't know what to do,Hello everyone I am in 2nd year  in CSE and I am interested in Machine learning field and I want to learn it but I don't know about and from where should I start first directly start making projects or take some online courses because I want to do intership regarding please help me with this.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tf6tq/dont_know_what_to_do/,15,6,0.8,"[Comment(id='k2eoja5'), Comment(id='k2epcql'), Comment(id='k2h5tli'), Comment(id='k2jg4o9'), Comment(id='k2jg57d'), Comment(id='k2ev9tb'), Comment(id='k2eoyu5'), Comment(id='k2epih1'), Comment(id='k2hgjxg'), Comment(id='k2ep6db'), Comment(id='k2jgyj9'), Comment(id='k2jbrar'), Comment(id='k2jo24x'), Comment(id='k2kap2n')]"
16tq5fa,UBIAI,,2023-09-27 17:07:18+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16tq5fa/description_guided_zeroshot_labeling_tutorial/,Description Guided Zero-Shot Labeling Tutorial,,learnmachinelearning,https://ubiai.tools/description-guided-zero-shot-labeling-for-nlp-applications/,0,1,1.0,[]
16tt82f,karotem,,2023-09-27 19:16:08+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16tt82f/hey_guys_i_need_your_helpi_am_beginner_in_ml_i_am/,"hey guys i need your help(i am beginner in ML), i am using DecisionTreeClassifier in sklearn and i get accuracy score in training set 0.98 , however i get 0.85 in test set . 0.85 is good enough for me . Can i use this model ? i know this model is overiftting but 0.85 is good for me",,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16tt82f/hey_guys_i_need_your_helpi_am_beginner_in_ml_i_am/,6,0,0.29,"[Comment(id='k2h56zh'), Comment(id='k2is7ie'), Comment(id='k2jgw3u'), Comment(id='k2h5rq2'), Comment(id='k2h6mqf'), Comment(id='k2h7zma')]"
16t6kqq,OnlyProggingForFun,,2023-09-27 01:21:25+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16t6kqq/generate_music_with_ai_stable_audio_explained/,Generate music with AI: Stable Audio Explained,,learnmachinelearning,https://youtu.be/dJz7EnYNJrw,0,3,1.0,[]
16stve4,ML-SSL,,2023-09-26 17:16:25+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16stve4/introduction_to_selfsupervised_learning_ssl/,Introduction to Self-Supervised Learning (SSL),,learnmachinelearning,https://medium.com/self-supervised-learning/introduction-to-self-supervised-learning-ssl-e556b9139617?sk=8e5064c86ecb497662f33c5abba74c71,5,3,0.72,"[Comment(id='k2bhm7l'), Comment(id='k2b5hzd'), Comment(id='k2bi7y2'), Comment(id='k2bsrd3'), Comment(id='k2buzam')]"
16soaeo,careless_prophecy,,2023-09-26 13:40:16+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16soaeo/how_do_i_move_forward_in_nlp/,How do I move forward in NLP?,"I have an understanding of NLP fundamentals and pipeline. How do I move forward in terms of improving pre-processing (better tokenizing, lemmatizing etc.) to create better features for modeling?

Please do tell any resources (lectures, books, papers etc.) if possible",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16soaeo/how_do_i_move_forward_in_nlp/,5,5,0.73,"[Comment(id='k2arqqb'), Comment(id='k2adxgv'), Comment(id='k2a7vt0'), Comment(id='k2adi8n'), Comment(id='k2bf7vu')]"
16ssw8l,vpysk,,2023-09-26 16:39:08+00:00,False,,1695820519.0,False,True,False,/r/learnmachinelearning/comments/16ssw8l/one_way_to_save_on_compute_units/,One way to save on compute units,"Build architecture and test your code on local CPU with VS code\*, Train on colab.

TLDR

Training with a GPU is magnitudes faster than with CPU, but most of my time isn't spend training, so I mostly don't need a GPU.

You can get CUDA if you have an NVIDIA GPU, but (1) the memory on my GPU is 3GB and a (free) T4 on colab has 16GB; could get a beefy laptop\*\*, but that's expensive. (2) Getting CUDA on windows has been a struggle and a half for me, haven't found good resources online for how to do it, any suggestions are welcome; I might end up eventually doing this but (1) still stands. (3) My main usecase atm is asssignments and projects so I don't need a lot of vram and (4) If I do need to train a beefmonster of a project, I can get colab pro and use an A100.

edit: I use pytorch.

\---------------------------

\*Or whatever editor you use,

\*\*I prefer using a laptop.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16ssw8l/one_way_to_save_on_compute_units/,9,3,1.0,"[Comment(id='k2bedie'), Comment(id='k2dzv55'), Comment(id='k2e7k3x'), Comment(id='k2fdab2'), Comment(id='k2eftqe'), Comment(id='k2fdddx'), Comment(id='k2fi6u9'), Comment(id='k2jwijh'), Comment(id='k2m5pf4')]"
16sr438,SolitaritySounds,,2023-09-26 15:29:57+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sr438/pivoting_from_information_systems_bsc_carnegie/,Pivoting from Information Systems BSc @ Carnegie Mellon to Machine Learning Postgrad,"I'm currently in my senior year doing a BSc in Information Systems at Carnegie Mellon. It's structured around Computer Science but is pretty much stripped of math and any advanced theory. The emphasis is on practical learning and the program is overall a conjunction of CS, IT, Business management, and so on. In our latter years, we ""concentrate"" on a specific subject, and my choice of concentration was in Data Science.

I've taken a number of courses that familiarized me with applying DS and ML in general - the full data science pipeline, and exploring (but definitely not mastering) different types of modeling in Skikit-Learn. I've done sentiment analysis, image classification, and regression, and worked on a handful of DS projects. But I still feel like the knowledge I've gained is too primitive and I'm missing core ML knowledge. Most of our homework involved tweaking variables and calling various functions without understanding how they really work. 

It didn't help that the concentration subjects had elective-style teaching, professors glossed over a lot of things that I think should have been emphasized. All in all, I don't feel ready to ""apply"" knowledge in the industry, I didn't gain much of it in ML.

Regardless, I am very interested in specializing in Machine Learning, with the aim of focusing on theory, I'd love to work my way into R&D. I'm already taking Discrete Mathematics, and I plan to take Probability and Statistics, Linear Algebra, as well as CMU's signature computation/algorithms mathematics [course](https://csd.cmu.edu/course-profiles/15-251-Great-Theoretical-Ideas-in-Computer-Science). At CMU, some of these are prereqs to take any of their ML courses (and for masters), so it's only natural for me to want to pursue this as my early progression.

I only have one more semester to work with, however, and I'm still quite unsure what to do afterward. I'd have had a great introduction to the mathematical component, but without really tying it with ML in a specialized course, I still have more to learn.

I'm keen on applying for some master's programs, I don't think entry-level positions fresh out of college are going to teach me the theory I'm still looking for, and I've heard well enough that ML doesn't recruit at the entry level anyways. I'm Canadian and it's financially more sound to study there, but looking through UBC, UofT, Waterloo, and other universities, it's not easy finding a dedicated Master's program in ML (I'm far too spoiled with CMU's course catalog). I'm just not quite sure where to look and how to bridge this clear gap.

I would appreciate any advice, many thanks in advance!

TL;DR Senior studying Information Systems, want to transition to Machine Learning postgrad and gain a strong theory background, Canada's Masters programs in ML aren't as good as the U.S. from what I've seen. What are the routes for my to bridge the gap towards ML with this in mind?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sr438/pivoting_from_information_systems_bsc_carnegie/,0,3,1.0,[]
16stkkh,UnkarsThug,,2023-09-26 17:04:36+00:00,False,,1695748428.0,False,True,False,/r/learnmachinelearning/comments/16stkkh/roguelike_sprite_generator/,Roguelike Sprite Generator,"I'd like to create a sprite generator to run alongside a monster fighter style of roguelike (Something like 64x64 sized images), and I've been trying to think of what the best method to generate the images would be, between using more of a GAN method, vs something like an extremely small diffusion model, or even something I haven't thought of yet.

I need it to be able to run on a rather typical PC in a reasonable time while each world is being generated, where about 6 will be generated at a time per world.

It might end up being easier to make it arrays of numbers with each images having a map of number to color value, to make consistent color scheming more easy, and speed image generation, although that would presumably make displaying the images harder.

As far as starting dataset, [https://pokemondb.net/sprites#gen3](https://pokemondb.net/sprites#gen3), although I expect I'll need to do some preprocessing before using them, such as reducing them into arrays, and probably finding/making more images.  


Edit: Grammar",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16stkkh/roguelike_sprite_generator/,0,2,1.0,[]
16snoay,fourfiftyfiveam,,2023-09-26 13:14:58+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16snoay/anyone_taken_edx_databricks_llm101x_large/,"Anyone taken Edx ""Databricks LLM101x Large Language Models: Application through Production""",$99 for a single course seems steep. But happy to pay if the labs are useful!,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16snoay/anyone_taken_edx_databricks_llm101x_large/,1,4,1.0,[Comment(id='k2a3bz7')]
16si9bf,IcyCommunication9694,,2023-09-26 08:47:36+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16si9bf/how_much_traditional_machine_learning_algorithm/,How much traditional machine learning algorithm should I be familiar before starting deep learning (esp. Face Recognition CNN)?,"Since last two weeks, I have been learning about ML algorithm like Linear Regression, KNN, KMeans, Decision Tree ,etc stuff using Sklearn specifcally. 

For Now my end goal is to create a face recognition model using deep learning. Is it okay If I start with some framework like Pytorch or Tensorflow and dive into Deep learning like CNN Now or keep learning traditional ML?

I have 3  years experience as a full stack software dev so language is not a problem for me.  
Do you guys have any roadmap. Thanks",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16si9bf/how_much_traditional_machine_learning_algorithm/,6,9,0.85,"[Comment(id='k29z19m'), Comment(id='k29bxiu'), Comment(id='k29edid'), Comment(id='k2b1mn7'), Comment(id='k2dwx83')]"
16sylny,GetAI411,,2023-09-26 20:14:11+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sylny/help_always_read_the_requirements_when_buying/,Help! Always read the requirements when buying computer parts,Hello everyone so I bought a new video card the other day. It was very much and still is needed. I got myself a intel a750 I'm running a nvidia HTC 1060 super currently haha. I didnt read the part that says you need a intel 10 gen or higher mobo with re size bar support. I dont have much extra cash atm. I'm trying to find the cheapest 10th gen mobo CPu and ram any suggestions online stores? Whatever works. Thank you!,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sylny/help_always_read_the_requirements_when_buying/,2,1,1.0,"[Comment(id='k2gpi2r'), Comment(id='k2gfq5f')]"
16smozx,Choweeez,,2023-09-26 12:35:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16smozx/learning_from_classical_ml_to_neural_network_and/,Learning: from classical ML to neural network and deep learning,"I started reading *Hands-On Machine Learning* by Aurélien Géron.  
I finished the first part on classical ML, as well as the exercises. I also did some small projects on Kaggle. 

Next part is neural networks and deep learning. It's done using TensorFlow.

**I'm wondering if I should continue with this book, or rather learn PyTorch (or whatever other library), or even just stick to classical ML.**  


*For some context:* I did a PhD in physics, so some data analysis using python, and I would like to work in the data analysis field. I love to get numbers from big data sets, and would like to be paid to do that.  


I'm asking this question because I saw a post on r/MachineLearning saying that classical ML was not really used anymore. I saw another one saying that TensorFlow was less and less used, for the benefit of PyTorch.  
I guess it's not fully black and white, but I would like to have your thoughts on that.   
",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16smozx/learning_from_classical_ml_to_neural_network_and/,2,4,1.0,"[Comment(id='k2eh854'), Comment(id='k2ejbjm')]"
16swf5a,Solid-Engineering921,,2023-09-26 18:52:19+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16swf5a/deploying_ml_models_and_getting_an_api_endpoint/,Deploying ML models and getting an API endpoint,I have been working on a problem statement of deploying ML models in an easier way and getting an API end point. I have a hacked together a version that I was looking to get some feedback on. Wanted to check if any one here has issues with deploying ML models and would be open to having a conversation.,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16swf5a/deploying_ml_models_and_getting_an_api_endpoint/,1,1,1.0,[Comment(id='k2eawu0')]
16sve7z,Agreeable_Tutor2969,,2023-09-26 18:13:51+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sve7z/cs229_2020_midterm_papers/,CS229 - 2020 midterm papers,Looking for solutions of CS229 - 2020 midterm papers,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sve7z/cs229_2020_midterm_papers/,0,1,0.67,[]
16slodl,saintshing,,2023-09-26 11:51:33+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16slodl/inside_the_matrix_visualizing_matrix/,"Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond",,learnmachinelearning,https://pytorch.org/blog/inside-the-matrix,0,3,1.0,[]
16suktv,cajmorgans,,2023-09-26 17:43:49+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16suktv/whats_the_current_status_of_crime_detection/,What's the current status of crime detection activity forecasting in Computer Vision?,"Hello!

I'm throwing out this question here for someone that is working in this area: What's the current status of crime detection for Computer Vision? 

By ""crime detection"" I'm thinking live video activity detection like: ""Planing bomb"", ""Showing gun"", ""Selling drugs"" etc, how far has that come and how accurate is it? Anyone with any interesting articles to share?

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16suktv/whats_the_current_status_of_crime_detection/,2,1,1.0,"[Comment(id='k2bhs0i'), Comment(id='k2bi50r'), Comment(id='k2bizx2'), Comment(id='k2c6xdw')]"
16sdrtt,KRA_T05,,2023-09-26 04:20:09+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sdrtt/which_is_the_best_most_inclusive_course_for/,Which is the best most inclusive course for machine learning,"So I have been in the field for almost 6 months now, and have worked with things like resnets, regressors, classifiers, autoencoders and GNNs. But I think I don't have enough theoretical knowledge to crack an interview in the field. It would be awesome if someone could recommend a course that takes me from the very basics of machine learning like KNNs, k-folds cv, SVMs and decision trees to the need of evolution to DL, the purpose of different loss functions to advanced concepts like GANs, LLMs and transformers. I have experience with images and I want to learn NLP too. All in all a course that can teach me the hierarchy of things in ML and DL in a chronological order of evolution. It need not be a single course, it can be a combination of multiple resources. I just want to learn. Thanks for the help in advance🙌🙌",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sdrtt/which_is_the_best_most_inclusive_course_for/,6,10,0.78,"[Comment(id='k28pt8s'), Comment(id='k29jwcx'), Comment(id='k2a30x0'), Comment(id='k28w471'), Comment(id='k29ot3o'), Comment(id='k2du7yo')]"
16slhku,purton_i,,2023-09-26 11:42:14+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16slhku/my_attempt_at_explaining_retrieval_augmented/,My attempt at explaining Retrieval Augmented Generation?,,learnmachinelearning,https://bionic-gpt.com/blog/retrieval-augmented-generation/,1,2,1.0,[Comment(id='k29twu5')]
16sjyv2,SemperZero,,2023-09-26 10:25:26+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16sjyv2/analysis_of_back_pain_using_biomechanics_and/,Analysis of Back Pain Using Biomechanics and Artificial Intelligence (ML),,learnmachinelearning,https://youtu.be/P-gHTqxCo_g?si=p7oWxCmxk99ulo-F,2,2,0.75,"[Comment(id='k29mev2'), Comment(id='k29z1xr')]"
16sccyc,Amun-Aion,,2023-09-26 03:08:06+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sccyc/is_there_any_way_to_use_a_command_line_argument/,Is there any way to use a command line argument parser in Jupyter Notebooks?,"Basically, I have a Python file with \~200 command line arguments set up via an arg parser, all with their own defaults. I want to be able to run this code in Jupyter Notebook (or really, just access this args object with all the defaults) so that I can tweak a few arguments from the default and easily access the results. Right now, since it is run via command line, I have to track down all the saved results from different directories and then load them and then I can plot them, but it's kind of the pain in the butt (mainly a ton of repeating code for that) and it seems like I should just be able to run it in Jupyter Notebooks and then use the returned object to access all my logs and results I want to plot.

In Jupyter Notebooks, I've tried both `%run path_to_file\my_file.py --arg1 a --arg2 b ...` and have also tried putting the arg parser into its own function (`parse_args()`) and importing that `parse_args()` function, but they both result in the following error:

     ipykernel_launcher.py: error: argument -abc/--random_arg: invalid int value: 'C:\\Users\\userID\\AppData\\Roaming\\jupyter\\runtime\\kernel-code.json' --------------------------------------------------------------------------- ValueError                                Traceback (most recent call last) File ~\miniconda3\envs\fl_torch\lib\argparse.py:2488, in ArgumentParser._get_value(self, action, arg_string)    2487 try: -> 2488     result = type_func(arg_string)    2490 # ArgumentTypeErrors indicate errors 

The error message goes on for a few hundred more lines not really telling me anything (errors are internal to Jupyter it looks like) before reaching a final Assertion Error.

For reference, this is the code setting the default argument in question that it says is set equal to some file path string:

    parser.add_argument('-abc', ""--random_arg"", type=int, default=0) 

Is there a way to fix this? Or is there a better way to achieve what I'm trying to do?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sccyc/is_there_any_way_to_use_a_command_line_argument/,2,3,0.8,"[Comment(id='k28u17i'), Comment(id='k28tb00')]"
16rmpz2,hardik_umretiya,,2023-09-25 08:51:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16rmpz2/which_path_you_will_choose_as_a_ml_engineer/,Which path you will choose as a ML engineer?,"Hey, everybody. 
I m 23M , graduated 2022. 
Dont have any industry or internship exp.
1 year of gap after graduation. But want to come back on track.
My end goal is to become a ML engineer.
But i am confused which path should i follow?

1. Get a job in software engineering and after some experince
 Switch to ML roles

2. Get a job as data analyst or data scientist then switch to ML roles

Which one is good choice? Please give suggestion.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16rmpz2/which_path_you_will_choose_as_a_ml_engineer/,29,74,0.92,"[Comment(id='k24j7x1'), Comment(id='k24cmm7'), Comment(id='k24rfsr'), Comment(id='k25ex3d'), Comment(id='k24j8fm'), Comment(id='k261s1b'), Comment(id='k272tt4'), Comment(id='k27gecj'), Comment(id='k25qglu'), Comment(id='k24bqbu'), Comment(id='k24g279'), Comment(id='k285swa'), Comment(id='k2870qz'), Comment(id='k288gi0'), Comment(id='k2pktjc'), Comment(id='k324snn'), Comment(id='k28xjs7'), Comment(id='k25fpsa'), Comment(id='k24pj3w'), Comment(id='k24bte1'), Comment(id='k324ie0'), Comment(id='k29gvxe'), Comment(id='k25qwzn'), Comment(id='k28bpou'), Comment(id='k2e3apw'), Comment(id='k2e5ghd'), Comment(id='k266r4i'), Comment(id='k2eby1r')]"
16shi8g,ivan_kudryavtsev,,2023-09-26 07:59:02+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16shi8g/savant_025_is_out_what_is_new/,Savant 0.2.5 is Out: What is New,,learnmachinelearning,/r/savant_video/comments/16she23/savant_025_is_out_what_is_new/,0,0,0.5,[]
16s48jw,bonky3000,,2023-09-25 21:17:24+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16s48jw/i_want_to_create_an_image_recognition_project_and/,I want to create an image recognition project and I need some pointers!,"I have always wanted to create a project where I can use a camera pointing at the entrance of my house, aimed at the persons legs and see if they’re wearing any shoes. If they walk past a spot the program detects that they still have their shoes on and then records it. If they have their shoes off, then it records and says good job! (I don’t want to complicate it further like “disciplining” them haha it’s more as a lighthearted project so I can put something in my resume)

How hard would this be to create using existing libraries and whatnot? Any tips and pointers?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16s48jw/i_want_to_create_an_image_recognition_project_and/,4,5,0.86,"[Comment(id='k2961u8'), Comment(id='k2dkcnc'), Comment(id='k29s10s'), Comment(id='k2962e6')]"
16samsg,Henry-T-01,,2023-09-26 01:48:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16samsg/using_gpt4_to_measure_creativity_in_responses_to/,Using GPT-4 to measure creativity in responses to a study.,"A friend of mine, who's pursuing a master's in psychology, is working on a thesis linking nice work environments to creativity.  She measured the creativity of participants by letting them list various creative ways of using a toothpick. I.e. ""cleaning your teeth"" wouldn't be considered creative but ""using it as a flag pole in a miniature town"" would. Now she has a few thousand suggestions on how to use toothpicks. She came to me asking wether I could show her how to code a program that could automatically assign a ""creativity score"" to these answers. I of course said that I considered this task to be way too complex to develop anything yourself, furthermore I'm just a math major without any real experience with language models capable of such a task. However, I had the idea to use OpenAI's GPT-4 API. So now we're thinking of writing a little script that takes the toothpick suggestions in batches of 10 and sends them to GPT with a prompt telling it to assign them a creativity score. Now I wanted to ask you all:

1. Do you even believe GPT-4 could handle this task effectively?
2. Any recommendations on formulating the prompt for best results?
3. Are there potential pitfalls or considerations we should be aware of?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16samsg/using_gpt4_to_measure_creativity_in_responses_to/,3,2,0.63,"[Comment(id='k28thcu'), Comment(id='k2902j9'), Comment(id='k2areio')]"
16sf17l,Enthusiast_new,,2023-09-26 05:28:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sf17l/new_research_paper_using_genetic_algorithm_and/,New research paper: Using Genetic Algorithm and Ensemble Learning together for text classification,New research paper on how to use genetic algorithm with ensemble learning for text classification. Read the web version of the entire paper here: [https://www.mdpi.com/2076-3417/13/18/10264](https://www.mdpi.com/2076-3417/13/18/10264),learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sf17l/new_research_paper_using_genetic_algorithm_and/,0,1,1.0,[]
16se6u9,Content_Highlight269,,2023-09-26 04:41:59+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16se6u9/did_i_make_the_wrong_choice/,Did I make the wrong choice?,"Ive always wanted to end up as a machine learning engineer. I had a software engineering internship and I got a return offer but was given the option to remain on the software engineering team or join a data science team I worked adjacently with. 
I picked the data Science team because of my
Desire to pivot into machine learning engineering. But I’m now realizing that I may have not have made the right choice and maybe a software engineering role would have been a better experience for what I want? 

I would like to hear your opinion on this. Thank you.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16se6u9/did_i_make_the_wrong_choice/,12,0,0.5,"[Comment(id='k2beetn'), Comment(id='k28s7kq'), Comment(id='k29vru4'), Comment(id='k2dhq53'), Comment(id='k2hotbh'), Comment(id='k29ujd7'), Comment(id='k2hp5qs'), Comment(id='k2hpc3j'), Comment(id='k2ahpx8'), Comment(id='k2i5jzm'), Comment(id='k2hpiy2'), Comment(id='k2iwxb5')]"
16sduzb,tondlilover,,2023-09-26 04:24:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sduzb/tips_to_begin_approach_for_customer_target_problem/,Tips to begin approach for customer target problem?,"I have a dataset of customers with features like age, gender, education, etc and revenue. I have to find a specific target customer and how to target them. I think that revenue will be the feature to target them, meaning finding high-revenue customers. But how to begin this? ",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sduzb/tips_to_begin_approach_for_customer_target_problem/,4,1,0.67,"[Comment(id='k28qhd2'), Comment(id='k28qzc8'), Comment(id='k28s049'), Comment(id='k2clot0')]"
16s3njv,Decent_Grape_7232,,2023-09-25 20:55:17+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16s3njv/how_do_decision_trees_generate_the_predictive/,How do decision trees generate the predictive output,"Hi folks,

I have been doing random forest models for a little while, but something has always been confusing to me. In a random forest regression, in a single decision tree, can someone explain to me in relatively simple terms how the decision tree generates the output/prediction? I understand about the random splitting and decision making within the tree, but when the tree reaches the end node, how does it pick the predicted output for that particular tree? Everything I've found to read has just said it generates an output, but I don't understand how or where that output comes from. My current understanding is that there isn't actually a train/test split in the random forest tree itself, and that the train/test split doesn't happen until you are ready to fit the model on the training set for testing on the test set. So if there is no train/test in the decision tree part, where is it ""learning"" what the output for decision trees should be? 

I am probably thinking too hard about this. Any help in my understanding of this would be appreciated!

&#x200B;",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16s3njv/how_do_decision_trees_generate_the_predictive/,6,3,0.71,"[Comment(id='k272ppp'), Comment(id='k27mng3'), Comment(id='k274npa'), Comment(id='k2aim9o'), Comment(id='k277u2k'), Comment(id='k27a2dl')]"
16rrxzi,ledmmaster,,2023-09-25 13:21:58+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16rrxzi/why_xgboost_still_wins_the_tabular_data_game/,Why XGBoost Still Wins The Tabular Data Game,,learnmachinelearning,https://forecastegy.com/posts/gradient-boosting-vs-deep-learning-tabular-data/,0,12,0.85,[]
16sat5p,nomusichere,,2023-09-26 01:56:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16sat5p/running_inference_multigpu_single_node_llama27b/,Running Inference multi-GPU Single node Llama2-7b split model,Hi. I would like to run inference on Llama2-7b. I am using PyTorch Transformers library but I have been running out of VRAM. I am trying to find out what is the best approach to split the model and distribute it across 4 GPUs that each have 16GB ram. Basically I am using an AWS g4dn.12xlarge instance. Is there any documentation that would cover this? Also documentation for training datasets. I am trying to run inference first to verify the model state and then start fine-tuning on private data that has been properly formatted for using SFTrainer. Any help would be appreciated!,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16sat5p/running_inference_multigpu_single_node_llama27b/,0,1,1.0,[]
16s5k51,fazkan,,2023-09-25 22:07:45+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16s5k51/ml_deployment_survey/,ML Deployment survey,"Hi, we are doing a survey of ML deployment platforms. Kindly fill it out and share it with your friends. We will share the results with the community

[https://forms.gle/1Q3WeSukHj8xBzUBA](https://forms.gle/1Q3WeSukHj8xBzUBA)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16s5k51/ml_deployment_survey/,0,2,1.0,[]
16s56j5,Modimodi4189,,2023-09-25 21:53:10+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16s56j5/is_it_worth_learning_ml_as_a_bachelors_student/,Is it worth learning ML as a bachelor's student pursuing Software Engineering?,"Hello everyone, It's my first time posting on this subreddit so I apologize if anything is against the rules.

I'm currently a University student approaching my last year, but due to some life circumstances, I had to pause my University studies and take a break which I approximate will be between 4-6 months. During this break, I want to invest my time in education but I'm unsure what to pursue exactly. ML was one of the things I've been interested in in recent years but never had time for, but after going through a lot of posts on Reddit and on the internet in general, I see a lot of people saying that for me to succeed in an ML environment I would need an actual Univeristy level education/Master's/Ph.D. 

I have already started taking an ML course over the past week offered by Andrew Ng but after seeing these opinions online, in some way, it demotivated me to continue. What is everyone's opinion on this? I'm willing to fully commit to learning and as I study software Engineering I already have a decent base in coding/mathematics and I also took a couple of courses in statistics throughout my degree, but I'm just worried that this path will not open any opportunities for me in the future and it would be a waste of my time where I could have maybe learned something instead that could help me in my professional career after graduation.

what are your thoughts/opinions on this? Any help will be greatly appreciated.

TL;DR: Software Engineering student but due to life circumstances I had to pause my university studies and now with a lot of free time I'm wondering if I should invest my time in learning ML to open up a career path for myself or if I should focus my time in learning something else/improving what I already know.",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16s56j5/is_it_worth_learning_ml_as_a_bachelors_student/,4,2,0.6,"[Comment(id='k27mkyo'), Comment(id='k27ssss'), Comment(id='k281bap'), Comment(id='k297m6l')]"
16rvz2z,hardik_umretiya,,2023-09-25 15:58:50+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16rvz2z/nlp_or_cv/,NLP or CV?,"Hey everyone, last week i watched a andrew ng's video on opportunities in ai, where he explained about the growth of diffrent types of ai learning models, and he said that this decade is all about genAI. But not clarify about the niche. What do you think in which branach of ai will have more job opportunities and growth , if we talk about gen AI in NLP or Computer vision?",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16rvz2z/nlp_or_cv/,13,5,0.78,"[Comment(id='k26qso4'), Comment(id='k29ug70'), Comment(id='k2a129x'), Comment(id='k2ah519'), Comment(id='k5n3ozq'), Comment(id='k29qvd4'), Comment(id='k29utl8'), Comment(id='k2a2agb'), Comment(id='k5n5gq9'), Comment(id='k29v6xx'), Comment(id='k2a2kic'), Comment(id='k2a3qh3'), Comment(id='k29vaaw')]"
16s7cgy,ChinchillaSpaghetti,,2023-09-25 23:20:15+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16s7cgy/text_art_and_shared_curiosity/,"Text, Art, and Shared Curiosity",,learnmachinelearning,/r/DeepAI/comments/16s78r7/text_art_and_shared_curiosity/,0,1,1.0,[]
16s54hh,Rare_Landscape8659,,2023-09-25 21:50:53+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16s54hh/how_to_combine_a_lidar_mmwave_distance_sensor/,How to Combine a Lidar / mmwave distance sensor with a Yolo model,"I have a yolov5 model (but I am going to transition it to a yolov8 model) which detects 2 objects, cubes and cones. Real time, after detection, I want to get the depth information of the object detected, using either a lidar or mmwave sensor. So, in the end, I want real-time information telling me what object it is, and how far away it is. I have been looking online, but I cannot find a place to start. 

Any help would be greatly appreciated!",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16s54hh/how_to_combine_a_lidar_mmwave_distance_sensor/,0,1,1.0,[]
16rpmbz,SouvikMandal,,2023-09-25 11:38:23+00:00,False,,False,False,False,False,/r/learnmachinelearning/comments/16rpmbz/clip_learning_transferable_visual_models_from/,CLIP: Learning Transferable Visual Models From Natural Language Supervision,,learnmachinelearning,https://medium.com/@mandalsouvik/clip-learning-transferable-visual-models-from-natural-language-supervision-29f2817f317f,1,6,0.87,[Comment(id='k24fu3i')]
16rrrfx,vevesta,,2023-09-25 13:15:21+00:00,False,,False,False,True,False,/r/learnmachinelearning/comments/16rrrfx/diffgrad_is_it_the_right_optimization_method_for/,DiffGrad : Is it the right optimization method for training your CNNs ?," 🎊 Learn about DiffGrad - optimizer that solves the overshooting problem of Adam

"" The optimizer diffGrad uses the difference between the present and past gradients. It uses gradient behaviour to control the learning rate at the optimization stage resulting in an optimal solution. If the gradient difference is large this means that optimization is not stable and therefore the diffGrad allows a high learning rate ""

💡 Learn more from➡ [https://vevesta.substack.com/p/diffgrad-optimization-technique-cnn](https://vevesta.substack.com/p/diffgrad-optimization-technique-cnn)",learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/16rrrfx/diffgrad_is_it_the_right_optimization_method_for/,0,3,1.0,[]
17ovaau,AutoModerator,,2023-11-06 05:01:25+00:00,False,,False,False,True,False,/r/datascience/comments/17ovaau/weekly_entering_transitioning_thread_06_nov_2023/,"Weekly Entering & Transitioning - Thread 06 Nov, 2023 - 13 Nov, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/17ovaau/weekly_entering_transitioning_thread_06_nov_2023/,3,1,1.0,"[Comment(id='k821anq'), Comment(id='k82i6cv'), Comment(id='k82l8wv')]"
17igak2,Omega037,PhD | Sr Data Scientist Lead | Biotech,2023-10-28 15:35:43+00:00,False,moderator,False,False,True,False,/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,[Meta] New Automod Rule - Minimum Comment Karma before Submissions,"After feedback from many members and discussions within the mod team, we have decided to implement a new Automod rule:

**Rule:** Effective immediately, **users must have at least 10 comment karma** **within** r/datascience **before they can make a top-level submission.**

The desired outcomes are:

1. Reduce pure self-promotion botspam
2. Reduce the number of top-level submissions that belong to the Weekly Sticky thread.

**Please let us know if it appears to be working incorrectly or causing unwanted side effects.**",datascience,https://www.reddit.com/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,23,49,0.96,"[Comment(id='k6tzxfr'), Comment(id='k6uhhep'), Comment(id='k6ul7pa'), Comment(id='k6upm79'), Comment(id='k6vtoi6'), Comment(id='k6vzca0'), Comment(id='k6xc30u'), Comment(id='k6vfoue'), Comment(id='k6yb67z'), Comment(id='k72f04h'), Comment(id='k74vzwv'), Comment(id='k76p2zt'), Comment(id='k7as0sz'), Comment(id='k7c7ofx'), Comment(id='k7d7lam'), Comment(id='k7etzi7'), Comment(id='k7fm52l'), Comment(id='k7ncv6j'), Comment(id='k7yn8nw'), Comment(id='k6uk8nc'), Comment(id='k7exn8b'), Comment(id='k7ndc1v'), Comment(id='k7ogl4p')]"
17oulta,Difficult-Big-3890,,2023-11-06 04:19:53+00:00,False,,False,False,False,False,/r/datascience/comments/17oulta/how_much_do_you_agree_with_this_post_screenshot/,How much do you agree with this post (screenshot attached) based on your DS experience?,"TlDr: A DS needs to have functional knowledge about Docker, OOP, FastAPI, Postgres to create relational DB.",datascience,https://i.redd.it/sfozkw40mnyb1.jpg,90,184,0.9,"[Comment(id='k813t0x'), Comment(id='k814ls5'), Comment(id='k814h6u'), Comment(id='k81dto7'), Comment(id='k816fpu'), Comment(id='k81ajvd'), Comment(id='k818ghr'), Comment(id='k81bahk'), Comment(id='k81b6fc'), Comment(id='k8190g1'), Comment(id='k817m5y'), Comment(id='k81bxhy'), Comment(id='k81eagt'), Comment(id='k81flo0'), Comment(id='k81cv3s'), Comment(id='k81logg'), Comment(id='k816tni'), Comment(id='k81iesl'), Comment(id='k81mw0z'), Comment(id='k81r4cb'), Comment(id='k8289g7'), Comment(id='k8164h9'), Comment(id='k81fohq'), Comment(id='k81kpq9'), Comment(id='k81d0c8'), Comment(id='k81jvr9'), Comment(id='k81jvwa'), Comment(id='k81ipp4'), Comment(id='k81pfv0'), Comment(id='k81u773'), Comment(id='k81ghc7'), Comment(id='k81jlkk'), Comment(id='k81rima'), Comment(id='k81s2ez'), Comment(id='k81ufn6'), Comment(id='k81x90g'), Comment(id='k820c1m'), Comment(id='k8231hw'), Comment(id='k82am9n'), Comment(id='k82bulg'), Comment(id='k82c9tl'), Comment(id='k82cxk5'), Comment(id='k82ep3c'), Comment(id='k82f6ew'), Comment(id='k82fpje'), Comment(id='k82gu1i'), Comment(id='k82i40f'), Comment(id='k82j8z8'), Comment(id='k82jb92'), Comment(id='k82jlz1'), Comment(id='k822m57'), Comment(id='k82motr'), Comment(id='k81kuu9'), Comment(id='k81jzw4'), Comment(id='k82lhj6'), Comment(id='k81830c'), Comment(id='k81cfv1'), Comment(id='k81d3zj'), Comment(id='k829od6'), Comment(id='k821lxm'), Comment(id='k82blgy'), Comment(id='k82duxk'), Comment(id='k81kixn'), Comment(id='k81antz'), Comment(id='k82e4et'), Comment(id='k8288kz'), Comment(id='k82emfz'), Comment(id='k82lyk8'), Comment(id='k81oehr'), Comment(id='k81v95q'), Comment(id='k81o6cu'), Comment(id='k82cji0'), Comment(id='k81hh10'), Comment(id='k8250i2'), Comment(id='k81y409'), Comment(id='k81xdlf'), Comment(id='k81p8zf'), Comment(id='k81wzj4'), Comment(id='k82el5j'), Comment(id='k822tbq'), Comment(id='k82g9oh'), Comment(id='k8245gt'), Comment(id='k826fnh'), Comment(id='k829jgb'), Comment(id='k82epue'), Comment(id='k82bted'), Comment(id='k82c59h'), Comment(id='k82d9j4'), <MoreComments count=0, children=[]>]"
17p2qtc,fulowa,,2023-11-06 13:29:18+00:00,False,,False,False,True,False,/r/datascience/comments/17p2qtc/data_scientist_action_figure_dalle3/,Data Scientist action figure (dalle3),"dalle3 prompt: data scientist as a sealed action figure

[dalle3 prompt: data scientist as a sealed action figure](https://preview.redd.it/3s37ff2qbqyb1.png?width=1024&format=png&auto=webp&s=e39787d53aa1b3e947e9f0e5ade9c9ca71df3b01)",datascience,https://www.reddit.com/r/datascience/comments/17p2qtc/data_scientist_action_figure_dalle3/,4,4,0.83,"[Comment(id='k82fxo3'), Comment(id='k82hgsg'), Comment(id='k82hnnm'), Comment(id='k82lvol')]"
17ox3wi,swordyfish,,2023-11-06 07:04:17+00:00,False,,1699254672.0,False,True,False,/r/datascience/comments/17ox3wi/where_do_you_get_help_for_personal_projects/,Where do you get help for personal projects?,"As a student, I'm used to going to office hours to get help on projects. However, once I graduate and start working on my own personal projects, who can I turn to for help?

I understand that finding the answer yourself is the most rewarding and that there's ChatGPT and such now, but I still find it extremely useful to have a zoom call with someone to go over stuff.

Resources I can think of are friends, discord servers, mentors, and maybe even paid freelancers (on Upwork or something?). Does anyone have experience with any of those? What resources do you guys use for your own personal projects?",datascience,https://www.reddit.com/r/datascience/comments/17ox3wi/where_do_you_get_help_for_personal_projects/,5,6,1.0,"[Comment(id='k81p58b'), Comment(id='k82bz5s'), Comment(id='k82c147'), Comment(id='k81rqsz'), Comment(id='k81v4wi')]"
17o4er9,WeOnlyCryAlone,,2023-11-05 04:36:18+00:00,False,,False,False,True,False,/r/datascience/comments/17o4er9/expecting_to_be_laidoff_in_q1_how_do_i_prepare_to/,"Expecting to be laid-off in Q1, how do I prepare to re-enter the job market?","Currently employed with a title of Data Scientist but really I'm a product analyst building out to Excel on ad hoc projects, mostly around why we aren't making money in that product line. My company is in the third round of layoffs this year and without a plan to improve, I'm expecting to exit, one way or the other, early in 2024.   


I'm feeling woefully under-skilled because I've been underutilized. I haven't put a model into production in three years because we haven't been asked. I have built dashboards that don't get used because managers want to look at the data themselves in Excel. My company has done \_nothing\_ with GenAI, NLP, Deep Learning, Image Processing, all of the significant advances in the last few years. I let myself get comfortable in a job where I could talk about data with people who were scared of it, but as I look at job openings for data scientists I truly don't feel qualified to even apply. I feel like my skills were relevant as of \~2019.  


What should I do in order to become relevant again?",datascience,https://www.reddit.com/r/datascience/comments/17o4er9/expecting_to_be_laidoff_in_q1_how_do_i_prepare_to/,54,104,0.93,"[Comment(id='k7w0stt'), Comment(id='k7w1v5l'), Comment(id='k7wxrru'), Comment(id='k7xl4d2'), Comment(id='k7xzum5'), Comment(id='k7wqkoy'), Comment(id='k7x7jkc'), Comment(id='k7x5mob'), Comment(id='k7xb89f'), Comment(id='k7yiaku'), Comment(id='k7yk9s2'), Comment(id='k80e71p'), Comment(id='k7wqj89'), Comment(id='k7xwzmb'), Comment(id='k7yepok'), Comment(id='k7yusbn'), Comment(id='k7zb28n'), Comment(id='k80lu92'), Comment(id='k81efqg'), Comment(id='k7w4dki'), Comment(id='k7zliam'), Comment(id='k7w4c8a'), Comment(id='k7w8pzj'), Comment(id='k80p8wa'), Comment(id='k80pbll'), Comment(id='k7yzums'), Comment(id='k7yqynz'), Comment(id='k80pj53'), Comment(id='k80q0h6'), Comment(id='k80q8pw'), Comment(id='k7xh67j'), Comment(id='k80qchi'), Comment(id='k80r8kb'), Comment(id='k80rif7'), Comment(id='k7zpv5a'), Comment(id='k7zl1dw'), Comment(id='k7zdmqd'), Comment(id='k7yun6n'), Comment(id='k80xdof'), Comment(id='k815vvg'), Comment(id='k80tczb'), Comment(id='k817npl'), Comment(id='k7xrofk'), Comment(id='k801rs4'), Comment(id='k80p4sw'), Comment(id='k80pnt4'), Comment(id='k7zh2wu'), Comment(id='k7xtg9s'), Comment(id='k80olv8'), Comment(id='k817cfm'), Comment(id='k80xo3m'), Comment(id='k7y0l2e'), Comment(id='k82k7t1')]"
17nwp4y,norfkens2,,2023-11-04 21:58:33+00:00,False,,1699139411.0,False,True,False,/r/datascience/comments/17nwp4y/when_applying_for_a_startup_what_questions_should/,When applying for a start-up - what questions should I ask?,"For an interview with a US startup - what should I be aware of? What kind of question should I be asking to form a solid opinion on the [edit] company?

e.g. I don't know much about funding at the different funding stages. What would I want to look at?",datascience,https://www.reddit.com/r/datascience/comments/17nwp4y/when_applying_for_a_startup_what_questions_should/,34,29,0.9,"[Comment(id='k7v371l'), Comment(id='k7v3jks'), Comment(id='k7ulael'), Comment(id='k7vg3os'), Comment(id='k7v3ire'), Comment(id='k7uj75z'), Comment(id='k7x0phi'), Comment(id='k7uygj8'), Comment(id='k7v3qh6'), Comment(id='k7vn538'), Comment(id='k7xuyl3'), Comment(id='k7xz2jp'), Comment(id='k7y0e4a'), Comment(id='k7ze5lf'), Comment(id='k7w4sxl'), Comment(id='k7w9dn6'), Comment(id='k7w9gy3'), Comment(id='k7uq3sn'), Comment(id='k7w3rzq'), Comment(id='k7w9htw'), Comment(id='k7um5sk'), Comment(id='k7w0myt'), Comment(id='k7w0vg9'), Comment(id='k7w3v51'), Comment(id='k7wbg2r'), Comment(id='k7y7cez'), Comment(id='k7uydwr'), Comment(id='k7w2jxl'), Comment(id='k7yaedj'), Comment(id='k7w0h2r'), Comment(id='k7wbheu'), Comment(id='k7yndnz'), Comment(id='k7wsnqx'), Comment(id='k7yyri4')]"
17o2n7u,andrew2018022,,2023-11-05 02:50:50+00:00,False,,1699153075.0,False,True,False,/r/datascience/comments/17o2n7u/going_through_a_somewhat_unfamiliar_interview/,Going through a somewhat unfamiliar interview process. The company is having me fill out a questionnaire in lieu of a first round interview?,"I get reached out to by a recruiter with a biotech research company for a remote statistician role, so I send my resume in. They say I pass the initial screening and am shortlisted for the position, and respond with a list of questions for me to fill out (some behavioral, some technical, etc) and say that it is a pressing need to be filled so if they like what I say, they’ll expedite the process and give an offer letter relatively quickly without other rounds of interviewing. I did some LinkedIn searching, it is a legitimate company with legit people, and the talent acquisition coordinator is a legit person and I’m fairly confident it’s a real thing here. Has anyone seen this before?

Some potential red flags:
1.) I have no clue where they got my email from to reach out

2.) I’ve never seen a situation where they’d send an offer without ever meeting me over the phone or face to face

Some potential green flags:

1.) The people and the job all exist in LinkedIn and other job boards

2.) they are willing to meet over the phone as well 
",datascience,https://www.reddit.com/r/datascience/comments/17o2n7u/going_through_a_somewhat_unfamiliar_interview/,16,12,0.83,"[Comment(id='k7vphp3'), Comment(id='k7vv2ty'), Comment(id='k7wdlmr'), Comment(id='k7x6sid'), Comment(id='k7ywqcx'), Comment(id='k7xoer9'), Comment(id='k7xvgxz'), Comment(id='k7vpqjy'), Comment(id='k7vvimr'), Comment(id='k7wq5oz'), Comment(id='k7wt0zc'), Comment(id='k7yz38o'), Comment(id='k7xl4j3'), Comment(id='k7xkz9n'), Comment(id='k7xpxoo'), Comment(id='k7y4siv')]"
17nlj1t,jeffrey_56,,2023-11-04 13:20:13+00:00,False,,False,False,True,False,/r/datascience/comments/17nlj1t/how_would_you_explain_complex_data/,How would you explain complex data transformations to others?,"This is my first data job and I’m the only data science person there, sorry if the question is kinda obvious.

How would you approach explaining complex transformations if you don’t have anyone in your company who can review your code?

Would it be smart to use graphical tools to illustrate each step and briefly explain methods used, such as right/inner joins? 

I’ve been working on this rather complex analysis in python with many steps and different queries. My project manager told me that he doesn’t feel confident with the results yet, due to the numerous (and sadly unavoidable) data transformation steps.",datascience,https://www.reddit.com/r/datascience/comments/17nlj1t/how_would_you_explain_complex_data/,37,25,0.86,"[Comment(id='k7saxol'), Comment(id='k7t0pff'), Comment(id='k7tjzy8'), Comment(id='k7sazo3'), Comment(id='k7sihh4'), Comment(id='k7sveg1'), Comment(id='k7txbk9'), Comment(id='k7sq7fu'), Comment(id='k7t18l0'), Comment(id='k7t1ppw'), Comment(id='k7tgm04'), Comment(id='k7ticlu'), Comment(id='k7u5ngf'), Comment(id='k7up5nv'), Comment(id='k7v6y1h'), Comment(id='k8106km'), Comment(id='k823f8f'), Comment(id='k7skexz'), Comment(id='k7t3sj4'), Comment(id='k7tkczq'), Comment(id='k7tn093'), Comment(id='k7tnni4'), Comment(id='k7zfpvs'), Comment(id='k7skkgn'), Comment(id='k7sd7zh'), Comment(id='k7teni6'), Comment(id='k7tdb1q'), Comment(id='k7tekit'), Comment(id='k825btk'), Comment(id='k7sjjv5'), Comment(id='k7vhb8s'), Comment(id='k8289ih'), Comment(id='k7t13iy'), Comment(id='k7td3xd'), Comment(id='k7w5chg'), Comment(id='k7tdqzu'), Comment(id='k7xbybe')]"
17ndvwn,OverratedDataScience,,2023-11-04 04:28:59+00:00,False,,False,False,True,False,/r/datascience/comments/17ndvwn/if_you_had_a_chance_to_rebuild_your_dsde_team_how/,"If you had a chance to rebuild your DS/DE team, how would you do it?","I've been asked to consolidate and rebuild a data team after a spree of layoffs and reorgs. People have to be realigned to newer projects and priorities. Some of the projects they were working on were scrapped entirely due to lack of funding. As the layoffs would still continue, I want this new  team to be ""not on the list"" as much as possible.

If you had the chance to build a team from scratch, what would you do?",datascience,https://www.reddit.com/r/datascience/comments/17ndvwn/if_you_had_a_chance_to_rebuild_your_dsde_team_how/,56,69,0.87,"[Comment(id='k7r9bhf'), Comment(id='k7rr67q'), Comment(id='k7r7897'), Comment(id='k7r4ukg'), Comment(id='k7rm8uk'), Comment(id='k7rlr0e'), Comment(id='k7r1zir'), Comment(id='k7s1up7'), Comment(id='k7s5s0l'), Comment(id='k7snuxl'), Comment(id='k7zdeuc'), Comment(id='k7r7lvp'), Comment(id='k7sm7o8'), Comment(id='k7s8s67'), Comment(id='k7ra5jv'), Comment(id='k81szgr'), Comment(id='k7ulxys'), Comment(id='k7ryfuy'), Comment(id='k7sejrj'), Comment(id='k7rzy9t'), Comment(id='k7st99h'), Comment(id='k7vet96'), Comment(id='k7rwjwe'), Comment(id='k7rnpon'), Comment(id='k7reyaj'), Comment(id='k7rb8u8'), Comment(id='k7st2wu'), Comment(id='k7st4sp'), Comment(id='k7u18vz'), Comment(id='k7vq3ky'), Comment(id='k7sqcd1'), Comment(id='k7stg3l'), Comment(id='k7rgb4w'), Comment(id='k7t3ynw'), Comment(id='k7t4eoq'), Comment(id='k7rbrc5'), Comment(id='k7tnmy6'), Comment(id='k7ul6il'), Comment(id='k7t3nqw'), Comment(id='k7tdgwd'), Comment(id='k7tdlqu'), Comment(id='k7vlxjd'), Comment(id='k7tlxhj'), Comment(id='k7tnmal'), Comment(id='k7tolz4'), Comment(id='k7top3e'), Comment(id='k7tm4io'), Comment(id='k7tnack'), Comment(id='k7zwoem'), Comment(id='k7trd9o'), Comment(id='k7to0g7'), Comment(id='k7tt0p5'), Comment(id='k7tsn7z'), Comment(id='k7ts00h'), Comment(id='k7ttutm'), Comment(id='k7tt3lq')]"
17ngwrb,WadeEffingWilson,,2023-11-04 08:06:43+00:00,False,,False,False,True,False,/r/datascience/comments/17ngwrb/how_can_someone_determine_the_geometry_of_their/,"How can someone determine the geometry of their clusters (ie, flat or convex) if the data has high dimensionality?","I'm doing a deep dive on cluster analysis for the given problem I'm working on. Right now, I'm using hierarchical clustering and the data that I have contains 24 features. Naturally, I used t-SNE to visualize the cluster formation and it looks solid but I can't shake the feeling that the actual geometry of the clusters is lost in the translation. 

The reason for wanting to do this is to assist in selecting additional clustering algorithms for evaluation. 

I haven't used PCA yet as I'm worried about the effects of data lost during the dimensionality redux and how it  might skew further analysis.

Does there exist a way to better understand the geometry of clusters? Was my intuition correct about t-SNE possibly altering (or obscuring) the cluster shapes?",datascience,https://www.reddit.com/r/datascience/comments/17ngwrb/how_can_someone_determine_the_geometry_of_their/,38,23,0.79,"[Comment(id='k7rkzx9'), Comment(id='k7s07yk'), Comment(id='k7rmi10'), Comment(id='k7roc0n'), Comment(id='k7rnkin'), Comment(id='k7s9wd0'), Comment(id='k7s31c8'), Comment(id='k7s9907'), Comment(id='k7sof9n'), Comment(id='k7sq23g'), Comment(id='k7ukour'), Comment(id='k7vpvks'), Comment(id='k7w6a9w'), Comment(id='k82ib1y'), Comment(id='k7rpky9'), Comment(id='k7ulyrv'), Comment(id='k81u38s'), Comment(id='k7rq121'), Comment(id='k7rqzo7'), Comment(id='k7rsaly'), Comment(id='k7rpp3n'), Comment(id='k81dk3z'), Comment(id='k7yo61r'), Comment(id='k7umj1h'), Comment(id='k7rw988'), Comment(id='k7rwb8t'), Comment(id='k7um7jg'), Comment(id='k7rq9re'), Comment(id='k7ulfqo'), Comment(id='k7uqtxb'), Comment(id='k7rrxju'), Comment(id='k80j3wk'), Comment(id='k7us8of'), Comment(id='k7tbsvy'), Comment(id='k7uygr8'), Comment(id='k7umnca'), Comment(id='k7v4phr'), Comment(id='k7vk08p')]"
17mzv7z,Mundane-Astronomer-7,,2023-11-03 17:08:13+00:00,False,,False,False,True,False,/r/datascience/comments/17mzv7z/should_i_use_poaching_attempts_to_ask_for_higher/,Should I use poaching attempts to ask for higher salary?,"I am a data scientist and I report directly to the CEO whom I have a candid rapport with. I have generated a lot of use case and working models in my short tenure. I have no intention to leave my company yet. Recently I received a couple of job offers without interviewing or seeking for jobs. I was thinking of mentioning these attempts during my performance review with the CEO and ask for a higher salary to ""make future attempts harder to accept"". Should I do it? Would it place my neck on the chopping board during hard times?",datascience,https://www.reddit.com/r/datascience/comments/17mzv7z/should_i_use_poaching_attempts_to_ask_for_higher/,59,94,0.88,"[Comment(id='k7oc5tf'), Comment(id='k7ocrb1'), Comment(id='k7ohqwk'), Comment(id='k7of9ah'), Comment(id='k7p9p7b'), Comment(id='k7prws5'), Comment(id='k7p361y'), Comment(id='k7oky92'), Comment(id='k7of5ow'), Comment(id='k7prro1'), Comment(id='k7ondac'), Comment(id='k7pvucm'), Comment(id='k7qhcz4'), Comment(id='k7pkkcv'), Comment(id='k7ocml2'), Comment(id='k7p2ydc'), Comment(id='k7qbzlj'), Comment(id='k7qepxj'), Comment(id='k7ox88y'), Comment(id='k7p5btb'), Comment(id='k7pfakh'), Comment(id='k7pjo3d'), Comment(id='k7pnjun'), Comment(id='k7prhoi'), Comment(id='k7pwjb2'), Comment(id='k7pzb1i'), Comment(id='k7q2j70'), Comment(id='k7q3wqd'), Comment(id='k7qodim'), Comment(id='k7qta2c'), Comment(id='k7rfqw2'), Comment(id='k7rlfn6'), Comment(id='k7rz9lq'), Comment(id='k7s59ef'), Comment(id='k7s5bze'), Comment(id='k7s5m1x'), Comment(id='k7sbjpn'), Comment(id='k7ui4qx'), Comment(id='k7z89p0'), Comment(id='k7zlgmk'), Comment(id='k7odeyi'), Comment(id='k7pf18k'), Comment(id='k7rcf5t'), Comment(id='k7pjwpz'), Comment(id='k7s2cjb'), Comment(id='k7pq65o'), Comment(id='k7r5ylx'), Comment(id='k7p8xy4'), Comment(id='k7pnpdr'), Comment(id='k7p4gww'), Comment(id='k7oem9f'), Comment(id='k7q7aol'), Comment(id='k7q8v8w'), Comment(id='k7pnozg'), Comment(id='k7pwaye'), Comment(id='k7ogf2o'), Comment(id='k7p6ph0'), Comment(id='k7p8fk5'), Comment(id='k7p8mcm'), Comment(id='k7rdh7n')]"
17mv3y3,LeaguePrototype,,2023-11-03 13:28:30+00:00,False,,False,False,False,False,/r/datascience/comments/17mv3y3/good_blog_post_that_clears_up_why_most_tech/,Good Blog Post That Clears Up Why Most Tech Workers Don't Have Any Work To Do,,datascience,https://emaggiori.com/employed-in-tech-for-years-but-almost-never-worked/,21,19,0.65,"[Comment(id='k7nppp9'), Comment(id='k7ocz6i'), Comment(id='k7ppdxc'), Comment(id='k7q1bc6'), Comment(id='k7p35e3'), Comment(id='k7qx4jc'), Comment(id='k7s987e'), Comment(id='k7pyyms'), Comment(id='k7uc3jb'), Comment(id='k7ppjb6'), Comment(id='k7p8gf6'), Comment(id='k7pyqix'), Comment(id='k7rkskq'), Comment(id='k7qpkcy'), Comment(id='k7uarl5'), Comment(id='k7ycugi'), Comment(id='k7prf6n'), Comment(id='k7rqx3b'), Comment(id='k7ucijr'), Comment(id='k7tgls9'), Comment(id='k7vl1o0')]"
17m8la5,ibsurvivors,,2023-11-02 17:18:55+00:00,False,,1698965355.0,True,True,False,/r/datascience/comments/17m8la5/i_applied_to_250_jobs_and_timed_how_long_each_one/,I applied to 250 jobs and timed how long each one took,"Applying to jobs online is like navigating a maze.

Amidst the special torture that is resume parsing software, the inability to reuse information across different application tracking systems (ATS), and the existence of a certain company that rhymes with every day of the week, it can get pretty frustrating.

I wanted to explore what factors make a job application more or less frustrating.

For example, what industries have the worst application processes? Do big companies ask for more information than small companies? What is it about websites like Workday that make them really hard to use?

To answer these questions, I applied to 250 jobs. One by one. Click by click. No Linkedin Easy Apply, no shortcuts – just straight from the careers page.

I timed how long it took me to go from “apply to job” to “submit application”.

https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&format=png&auto=webp&s=2123533d9d04aabcdd5988471274ee2ed3b98704

Make no mistake: I sacrificed my soul for this post. I created over 83 accounts and spent a total of 11 hours scrolling. I was originally going to do this for 500 companies, but wanted to chop my head off halfway.

I did this for a mix of companies – Fortune 500 to early stage startups, spread out across different industries from software to manufacturing. The *type* of role I applied to was kept constant: engineering / product focused.

https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&format=png&auto=webp&s=f27a52217e85bfade6eb30f0b696914eac7fc270

The outcome? An average of over two and a half minutes per application—162 seconds of your life you'll never get back. But as we dig deeper, you'll discover that these 162 seconds only scratch the surface of an often maddening process.

*Key Takeaways*

* **Average Application Time:** On average, it took a bit over two and a half minutes to apply to a job.
* **Company Size Impact:** If company size doubles, the application time increases by 5%. If company size increases by a factor of 10, then the app time increases by 20%.
* **Industry Influence:** Being a government company is the single largest determinant of a long application, followed closely by aerospace and consulting firms.
* **Longest Application:** The longest application time went to the United States Postal Service (10 minutes and 12 seconds).
* **Shortest Application:** On the other hand, It took me just 17 seconds to apply to Renaissance Technologies.
* **ATS Impact:** Older ATS like Workday and Taleo make job applications as much as 128% longer.

**You can view the spreadsheet with the full raw data** [here](https://mailchi.mp/1a15a90c4aeb/company_raw_data_leadmagnet)

Let's dive in.

# The Setup

There’s no real method to the 250 companies I pick. I’m just typing names into Google and trying to vary it up. Where does Trisha work? What was that billboard I saw? It's all up for grabs.

Here’s the distribution of the 250 companies by size:

https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&format=png&auto=webp&s=6feb536781f5f892ff57aaed0033e716be4c25c4

Some examples of companies in each range:

* 1-500 → Glean, Quizlet, Gumroad
* 500-5,000 → Notion, Dolby, Moloco
* 5,000-50,000 → Airbnb, Genentech, Logitech
* 50,000-100,000 → HP, American Express, Pfizer
* 100,000+ → Wells Fargo, Lockheed Martin, General Motors

And here’s a look at the different types of industries represented:

https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&format=png&auto=webp&s=2234a153954270bd3724029dac51cd270bfaf6ba

I used a mix of Linkedin and Crunchbase for categorization.

Before we get started, if you’d like you can read up on my [methodology](https://docs.google.com/document/d/1A0I9_WBN9zIqwezM6OXqmOl3LPqaq5704EPmGDTDiYI/edit) for applying to each job (aka assumptions I made, what data I chose to submit, and how much effort I put into each application).

***Note***: For more content like this, [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. In a couple of weeks, I'll be releasing my guide to writing a killer resume.*

# What makes a job application so frustrating

Generally speaking, the more frustrating a job application, the longer it takes to complete.

The three main factors that might influence how long a job application is (as measured in my data):

1. **Company size** → I would expect bigger companies to ask more questions.
2. **The ATS that is being used** → I would expect clunkier, older ATS to make job applications longer.
3. **Company industry** → I would expect more “traditional” industries to ask more questions.

We’re going to model the relationship between the above three factors and the amount of time it takes to complete a job application. To do this, we’re going to use a technique called linear regression.

Regression is about the way two measurements change together. It can help us make predictions.

For example, if I add 10 employees to a company, how many seconds will that add to the company’s job application process?

Since we have other factors like ATS and Industry, we will also account for those. For now, though, let’s just focus on each factor one by one.

# Company Size

Let’s first plot the data as is:

https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&format=png&auto=webp&s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199

Yes, I know, this isn’t the most useful graph. I’m going to spruce it up real quick, I promise.

The United States Postal Service has a job application that took over 10 minutes to complete. Navigating their portal felt like using Internet Explorer in 2003:

https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&format=png&auto=webp&s=b7b65699a39f2e4e3c3abadf38875280a673a0d7

Netflix’s application was just 20 seconds - their only mandatory requirements are your resume and basic info.

https://preview.redd.it/sl4fums4wyxb1.png?width=2310&format=png&auto=webp&s=4c0c87299460bd22163f34db1040a56ea3893059

Apple took me 71 seconds, still pretty fast for a company that has over 270,000 employees (PWC, which has a similar number of employees, took me almost six times as long).

Okay, back to the chart. There are a couple of problems with it.

First, the data is not linear. This is a problem if we want to use linear regression.

Second, the company size scale is hard to interpret because of the many data points clumped together near zero (representing all the smaller companies).

We can resolve both these issues with the following insight:

There is a big difference between going from 10 to 100 employees and, say, 10,000 to 10,100 employees. The first represents major changes in company structure: you might actually hire a proper HR team, a bunch of recruiters, and build out your candidate experience. The second, though, is pretty much just business as usual - think of a multinational opening up a satellite office or a regular month of hiring.

Since we want to account for this, our data is better suited to a log scale than a linear scale. I will also transform our Y-axis, the application time, to a log scale because it helps normalize the data.

If we plot both our variables on a log-log scale, we get the below chart:

https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&format=png&auto=webp&s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e

Better right? This is the same data as the last chart, but with different axes that fits the data better, we observe a linear relationship.

We have the usual suspects in the top right: Government organizations, professional services firms, and some of the tech industry dinosaurs.

The variance in application times across smaller companies, like startups, is interesting. For example, many of the startups with longer application times (e.g OpenAI, Posthog, Comma.AI) reference that they are looking for “exceptional” candidates on their careers page. (Note that OpenAI has changed its application since I last analyzed it - it’s now much faster, but when I went through they asked for a mini essay on why you’re exceptional).

One thing that I was expecting to see was competitors mirroring each other’s application times. This is most closely represented with the consulting firms like Deloitte, E&Y, KPMG, etc all clumped together. McKinsey and Bain, the two most prestigious consulting firms, have applications that take longer to complete.

This doesn’t necessarily seem to be the case with the FAANG companies.

We can also calculate the correlation coefficient for this graph. This is a statistical measure of the strength of a linear relationship between two variables. The closer to 1 the value, the stronger the relationship.

For the above data, we get a correlation coefficient of 0.58, which is a moderate to strong association.

Note that on its own, this doesn't tell us anything about causation. But it does start to point us in some type of direction.

It's not rocket science: big companies ask for more stuff. Sometimes they ask for the last 4 digits of your SSN.

https://preview.redd.it/c7g5717bwyxb1.png?width=1512&format=png&auto=webp&s=38c776e46d45d179a6627ba3470fd4f89ca04204

Sometimes they even ask if you’d be okay going through a polygraph:

https://preview.redd.it/1q52rzldwyxb1.png?width=400&format=png&auto=webp&s=b3b8921e055d38e04ee7395e9b982fa50c38f9df

An argument here is that if big companies didn’t have some sort of barriers in their application process, they’d get swarmed with applications.

Consider the fact that Google gets 3 million applications every year. Deloitte gets 2 million. Without some sort of initial friction in the application process, those numbers would be even higher. That friction almost serves as a reliable filter for interest.

If you’re an employer, you don’t really care about the people using a shotgun approach to apply. You want the candidates that have a real interest in the position. On the other hand, if you’re a candidate, the reality is such that the shotgun approach to apply is arguably the most efficient.

So we have this inherent tension between companies and candidates. Candidates want the most bang for their buck, companies don’t want thousands of irrelevant resumes.

And in the middle, we have the plethora of application tracking software that can often be quite old and clunky.

# ATS

Everytime I came face to face with a company that used Workday as their ATS, I died a bit inside. This is because Workday makes you:

1. create a new account every single time
2. redirects you away from the careers page

I defined a redirect as one when the job description is not listed on the same page as the first input box part of the application.

This isn’t a perfectly accurate measure, but it does allow us to differentiate between the modern ATS like Greenhouse and older ones like Workday.

With every ATS, I implicitly had some type of “how easy is this going to be” metric in my head.

We can try to represent this “how easy is this going to be” metric a bit more concretely using the matrix below.

https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&format=png&auto=webp&s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa

Ideally, you want the ATS to be in the bottom left corner. This creates an experience that is low friction and fast.

If we plot application time versus ATS, this is what we get:

https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&format=png&auto=webp&s=8df5c1118f9f0044e2154c8ae63816332ca42d67

The ATS that don’t make you create an account and don’t redirect you are tied to lower application times than the ones that do.

One possibility is that certain companies are more likely to use certain ATS. Big companies might use Workday for better compliance reporting. Same with the industry - maybe B2C software companies use the newer ATS on the market. These would be confounding variables, meaning that we may misinterpret a relationship between the ATS and the application time when in fact there isn’t one (and the real relationship is tied to the industry or size).

So to properly understand whether the ATS actually has an effect on application time, we need to control for our other variables. We’ll do this in the final section when we run a regression including all our variables.

One of the big frustrations surrounding different ATS is that when you upload your resume, you then need to retype out your experience in the boxes because the ATS resume parser did it incorrectly. For example, I went to UC Berkeley but sometimes got this:

https://preview.redd.it/ay21vccnwyxb1.png?width=928&format=png&auto=webp&s=9862b0860c49c87a76b02218f8e4118134acfb89

The only resume parser that didn't seem abysmal was the one from Smart Recruiters. TikTok's resume parser also isn't bad.

Another frustrating experience is tied to inconsistency between the company I'm applying to and the ATS.

https://preview.redd.it/9xzq21vpwyxb1.png?width=350&format=png&auto=webp&s=8432b293be4db0f58770760097df0117b53e667e

A company’s application process is often the first touchpoint you have with their brand. Startups competing for the best talent can't afford extra steps in their process. Apple and Facebook can.

Whilst the average time to complete a job application may only be 162 seconds, the fact that many ATS require steps like account creation and authentication can lead to application fatigue.

It’s not necessarily the explicit amount of time it takes, it’s the steps involved that drain you of energy and make you want to avoid applying to new jobs.

# Industry

Okay, so far we’ve looked at company size and the ATS as a loose indicator of what might make a job application frustrating. What about the company industry?

You would expect industries like banking or professional services to have longer application times, because getting those jobs revolves around having a bunch of credentials which they likely screen for (and ask you to submit) early on in the process.

On the other hand, internet startups I’d expect to be quick and fast. Let’s find out if this is true.

https://preview.redd.it/i7825ssvwyxb1.png?width=4012&format=png&auto=webp&s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b

Hyped up industries like AI and Crypto have shorter application times. As expected, banks and consulting firms care about your GPA and ask you to submit it.

A government company has to basically verify your identity before they can even receive your application, so the process is entirely different and reflected in the submission time.

For many technology companies, the application process is almost like an extension of the company’s brand itself. For example, Plaid (an API first Fintech company), has a neat option where you can actually apply to the job via API:

https://preview.redd.it/px5k5wwxwyxb1.png?width=720&format=png&auto=webp&s=d669e7e47e77e51d48a4867a2d06d27125617ed8

Roblox, a gaming company, allows people to submit job applications from within their [games](https://gamerant.com/roblox-company-interview-job-applicants-in-game/).

We also notice differences between legacy companies and their newer competitors. If we compare legacy banks versus neobanks (like Monzo, Mercury, etc), the legacy players averaged around 250 seconds per job application whereas the neobanks averaged less than 60 seconds.

If you can’t compete on prestige, you need to find other ways. One of those ways can be through asking for less information upfront.

# Putting it together

Now that we've analyzed each variable - the company size, ATS, and the industry - to understand the separate relationship of each to application time, we can use linear regression to understand the *combined* relationships.

This will allow us to determine what factors actually have an impact on the job application time versus which ones might just have had one when we looked at them in isolation.

After some number crunching in R, I get the following results (I’ve only added the statistically significant factors – the ones with the “strongest evidence”):

https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&format=png&auto=webp&s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9

Here’s how you can interpret some of the information above:

* When a job app is for a company that is within the Government industry, the submission time goes up by 366% (assuming the size and ATS are constant). For the aerospace industry, this is 249% (and so on).
* When a job app is for a company using the Workday ATS, the submission times goes up by 128% (assuming the size and industry are constant). For the Phenom ATS, this is 110% (and so on).
* Our only (statistically significant) metric which seems to make job applications faster is the Lever ATS (42% shorter).

Okay, now what about company size?

Well, first up: company size is indeed statistically significant. So there is an effect.

However, its effect is not as strong as most of our other variables. To be precise, here are some ways to interpret our company size coefficient:

* If company size doubles, the app size increases by 5%
* If company size increases by a factor of 10, then the app time increases by 20%

This is a smaller effect size compared to ATS or industry (a 20% increases in app time for a 10x large company is a qualitatively smaller effect size than e.g. a 100% increase in app time for Taleo ATS). So although company size is statistically significant, it is not as strong of a driver as ATS and industry of app time.

# Wrapping it up

Two and a half minutes might not be too long, but it can feel like an eternity when you’re forced to answer the same questions and upload the same documents. Over and over again.

Think about catching a flight. All you want is to get on the jet. Hawaii awaits.

But first: the security line. You have to take your shoes off. You get patted down and your bag gets searched. The gate numbers don’t make sense. And then at the end of it, your flight’s delayed. Congrats.

Applying to a job can feel similar. All you want to do is say aloha to the hiring manager, a real human being.

To even have the remote possibility of making that happen, you need to create an account and password, check your email, retype your entire resume, tell them the color of your skin, and explain why this company you’ve never heard of before is the greatest thing on Earth.

And for what? Most likely for the privilege of receiving an automated email about two weeks later rejecting you.

If we make it tiring and unappealing to look for new opportunities, then we prevent people from doing their best work.

But what would a world where applying took just a few seconds actually look like? Recruiters would get bombarded with resumes. It's possible to argue that job applications taking so long is a feature, not a bug. You get to filter for intent and narrow down your application pool.

Is it fair to shift the burden of screening unqualified candidates onto good candidates that now need to provide so much information? Shouldn’t that burden fall on the recruiter?

The truth is that applying to a job via the careers page is a bit of a rigged game. The odds are not in your favor.

Sometimes, though, all you need is to only be right once.

\*\*\*

If you made it all the way to the bottom, you're a star. This took a while to write. I hope you enjoyed it.

For more content like this, [subscribe](https://www.careerfair.io/subscribe) to my newsletter. It's my best content delivered to your inbox \~once a month.

Any questions and I'll be in the comments :)

\- Shikhar",datascience,https://www.reddit.com/r/datascience/comments/17m8la5/i_applied_to_250_jobs_and_timed_how_long_each_one/,115,771,0.97,"[Comment(id='k7j8ouw'), Comment(id='k7ja1g1'), Comment(id='k7jf0zd'), Comment(id='k7jey48'), Comment(id='k7jdepf'), Comment(id='k7jvtyl'), Comment(id='k7jbiol'), Comment(id='k7js2wc'), Comment(id='k7l7is9'), Comment(id='k7ji6ox'), Comment(id='k7kkj8i'), Comment(id='k7jmc01'), Comment(id='k7jyfuc'), Comment(id='k7le8u6'), Comment(id='k7jgr1c'), Comment(id='k7jju2a'), Comment(id='k7jvvkw'), Comment(id='k7jzxka'), Comment(id='k7khecf'), Comment(id='k7kpr8m'), Comment(id='k7lja1s'), Comment(id='k7lvsnz'), Comment(id='k7m465f'), Comment(id='k7mvuh3'), Comment(id='k7mwgp4'), Comment(id='k7ntlgu'), Comment(id='k7o5fei'), Comment(id='k7qnp0v'), Comment(id='k7vwfxs'), Comment(id='k7jelfz'), Comment(id='k7jxr4q'), Comment(id='k7k8tnd'), Comment(id='k7nk5rn'), Comment(id='k7kh51c'), Comment(id='k7kixqh'), Comment(id='k7ko9jq'), Comment(id='k7kqkj9'), Comment(id='k7kwppc'), Comment(id='k7l1lt1'), Comment(id='k7llhi7'), Comment(id='k7ln49d'), Comment(id='k7mv6un'), Comment(id='k7o3azu'), Comment(id='k7ob13l'), Comment(id='k7pdj7e'), Comment(id='k7pi4x4'), Comment(id='k7psbrq'), Comment(id='k7ptw2z'), Comment(id='k7pwj8z'), Comment(id='k7qiq48'), Comment(id='k7swe77'), Comment(id='k7t8su1'), Comment(id='k7vce3z'), Comment(id='k7yllyj'), Comment(id='k80ijpb'), Comment(id='k80l4kr'), Comment(id='k80rg5l'), Comment(id='k81t7t9'), Comment(id='k7jch2n'), Comment(id='k7l3ucw'), Comment(id='k7k19ny'), Comment(id='k7l4yxd'), Comment(id='k7jkbug'), Comment(id='k7mbqjm'), Comment(id='k7l12hc'), Comment(id='k7l9fig'), Comment(id='k7jgpma'), Comment(id='k7jgj6g'), Comment(id='k7l7z9x'), Comment(id='k7jkjla'), Comment(id='k7nyj8z'), Comment(id='k7mwssl'), Comment(id='k7kjdim'), Comment(id='k7nxiw2'), Comment(id='k7jgvtd'), Comment(id='k7jtfeb'), Comment(id='k7pxwok'), Comment(id='k7pwcvo'), Comment(id='k7jrzgq'), Comment(id='k7jgowz'), Comment(id='k7jyj6c'), Comment(id='k7kjcrq'), Comment(id='k7pwery'), Comment(id='k7kpwph'), Comment(id='k7l81c3'), Comment(id='k7l80pq'), Comment(id='k7l7zt4'), Comment(id='k7n640g'), Comment(id='k7pwdjr'), Comment(id='k7pwif3'), Comment(id='k7pw93t'), Comment(id='k7tb8an'), Comment(id='k80nu79'), Comment(id='k7kynf7'), Comment(id='k7jo30o'), Comment(id='k7knlsw'), Comment(id='k7jsrah'), Comment(id='k7jkoes'), Comment(id='k7kkf52'), Comment(id='k7jk85i'), Comment(id='k7l8aj0'), Comment(id='k80ohop'), Comment(id='k7joeye'), Comment(id='k7ju70d'), Comment(id='k7jncj0'), Comment(id='k7jrx8a'), Comment(id='k7k4e8x'), Comment(id='k7jv59a'), Comment(id='k7joy94')]"
17mps8p,LatterConcentrate6,,2023-11-03 07:43:59+00:00,False,,False,False,True,False,/r/datascience/comments/17mps8p/what_makes_an_average_data_science_manager_an/,What makes an average Data Science Manager an Excellent DSM?,... and what makes a bad DSM,datascience,https://www.reddit.com/r/datascience/comments/17mps8p/what_makes_an_average_data_science_manager_an/,17,27,0.81,"[Comment(id='k7ngd6c'), Comment(id='k7mw7po'), Comment(id='k7nhyjd'), Comment(id='k7nwewt'), Comment(id='k7mmz3b'), Comment(id='k7orsnl'), Comment(id='k7nrws1'), Comment(id='k7mtjo6'), Comment(id='k7mrv4e'), Comment(id='k7o5ob2'), Comment(id='k7mwe6z'), Comment(id='k7o7dfn'), Comment(id='k7oto8i'), Comment(id='k7za7rj'), Comment(id='k7zlku2'), Comment(id='k7oxrzt'), Comment(id='k7pociq')]"
17m7q3j,AdFew4357,,2023-11-02 16:41:19+00:00,False,,False,False,True,False,/r/datascience/comments/17m7q3j/statisticians_in_ds_how_did_you_connect_the_dots/,"Statisticians in DS, how did you “connect the dots” between business skills and theory?","I’m an MS statistician whose gonna be starting a data scientist position soon. I think one of the things I’m the most confident about is my statistical analysis and overarching background I have on methods. I am fairly comfortable I can handle up to 95% of weird data sets, and know how to properly assess assumptions, critically look at data, and choose the right model or tool for the job. I’m even more confident in my ability to present and explain interpretations of results, because that’s what is also emphasized in our applied coursework. With a good background in stats, I’m fairly confident in the actual “doing” of data analysis and wrangling and what not.

But I think the part I’m not really sure about or worried I’ll be bad at is “connecting the dots” between my stats stuff and the business problem. A lot of what I’m worried about is that I can do all of this stuff to understand the data, but if I don’t even understand the context well enough, then my analysis has no path to follow. This ambiguity is something I know I’m going to struggle with, and I’m not sure how I’m going to improve in this area besides talking to more of the stakeholders.

But for any statisticians here who turned to DS, what kind of things did you do to improve this aspect? How did you “connect” the business side to the hard core stats side?",datascience,https://www.reddit.com/r/datascience/comments/17m7q3j/statisticians_in_ds_how_did_you_connect_the_dots/,121,72,0.94,"[Comment(id='k7j4ipc'), Comment(id='k7j2f0o'), Comment(id='k7jc1um'), Comment(id='k7j5xl1'), Comment(id='k7jdwwm'), Comment(id='k7jan5i'), Comment(id='k7je0j4'), Comment(id='k7lfxsb'), Comment(id='k7ksb7j'), Comment(id='k7jn8ac'), Comment(id='k7ll266'), Comment(id='k7m1u7k'), Comment(id='k7m8r7a'), Comment(id='k7medx4'), Comment(id='k7onfpf'), Comment(id='k7qva3w'), Comment(id='k7lnlbc'), Comment(id='k7k9nbm'), Comment(id='k7l40hj'), Comment(id='k7lygmm'), Comment(id='k7m2vxz'), Comment(id='k7mughd'), Comment(id='k7qnrcv'), Comment(id='k7zlx50'), Comment(id='k7kewm7'), Comment(id='k7lnuir'), Comment(id='k7l6ff4'), Comment(id='k7j3o4h'), Comment(id='k7jt809'), Comment(id='k7jpdjm'), Comment(id='k7l3pql'), Comment(id='k7l65xk'), Comment(id='k7oxttg'), Comment(id='k7me6ct'), Comment(id='k7meuil'), Comment(id='k7ne4dc'), Comment(id='k7l6b08'), Comment(id='k7lorch'), Comment(id='k7l73zd'), Comment(id='k7jp0bs'), Comment(id='k7kmles'), Comment(id='k7k3kc7'), Comment(id='k7m6ige'), Comment(id='k7l8edr'), Comment(id='k7m6ows'), Comment(id='k7p6ynh'), Comment(id='k7rfsbi'), Comment(id='k7mgzt2'), Comment(id='k7mvlha'), Comment(id='k7lqeg9'), Comment(id='k7l9z3c'), Comment(id='k7jqf5w'), Comment(id='k7kqpzw'), Comment(id='k7k5oem'), Comment(id='k7mur9y'), Comment(id='k7musvg'), Comment(id='k7l9u3m'), Comment(id='k7mdgiy'), Comment(id='k7msyq3'), Comment(id='k7mdogb'), Comment(id='k7p8wxv'), Comment(id='k7rg5sk'), Comment(id='k7mha07'), Comment(id='k7no9hv'), Comment(id='k7lqk20'), Comment(id='k7lb5ji'), Comment(id='k7lj1m5'), Comment(id='k7jts3x'), Comment(id='k7n6n30'), Comment(id='k7u2hd0'), Comment(id='k7nwh90'), Comment(id='k7laz48'), Comment(id='k7llegq'), Comment(id='k7qhd8k'), Comment(id='k7n2bhy'), Comment(id='k7qznn7'), Comment(id='k7rgakh'), Comment(id='k7nyrql'), Comment(id='k7lqrl8'), Comment(id='k7lbetc'), Comment(id='k7lklyb'), Comment(id='k7jvzav'), Comment(id='k7nkxst'), Comment(id='k7oxm5h'), Comment(id='k7lbcjg'), Comment(id='k7lbxm6'), Comment(id='k7qkh8g'), Comment(id='k7ngc3b'), Comment(id='k7o228i'), Comment(id='k7lqxwu'), Comment(id='k7lc2ao'), Comment(id='k7l2xw6'), Comment(id='k7k5wng'), Comment(id='k7q55bt'), Comment(id='k7ld1o2'), Comment(id='k7ld342'), Comment(id='k7t3wna'), Comment(id='k7npauf'), Comment(id='k7lcbe3'), Comment(id='k7l3ifp'), Comment(id='k7kr8uv'), Comment(id='k7ldpbf'), Comment(id='k7nvqqy'), Comment(id='k7nvw6s'), Comment(id='k7lcq4f'), Comment(id='k7lhli5'), Comment(id='k7obr8c'), Comment(id='k7obzc4'), Comment(id='k7li9qf'), Comment(id='k7oxerb'), Comment(id='k7oxa1n'), <MoreComments count=0, children=[]>]"
17mt5b2,Excellent_Cost170,,2023-11-03 11:43:17+00:00,False,,False,False,True,False,/r/datascience/comments/17mt5b2/smart_goal_setting_does_it_work_for_data_science/,SMART goal setting does it work for data science,We have been asked to prepare SMART goals for next year's evaluations .,datascience,https://www.reddit.com/r/datascience/comments/17mt5b2/smart_goal_setting_does_it_work_for_data_science/,8,0,0.5,"[Comment(id='k7n6j3a'), Comment(id='k7nq3kk'), Comment(id='k7n5wct'), Comment(id='k7nd6xp'), Comment(id='k7ofjat'), Comment(id='k7mzk8k'), Comment(id='k7qyxji'), Comment(id='k7n8uat')]"
17m2b07,takenorinvalid,,2023-11-02 12:24:57+00:00,False,,False,False,True,False,/r/datascience/comments/17m2b07/how_do_you_avoid_phacking/,How do you avoid p-hacking?,"We've set up a Pre-Post Test model using the [Causal Impact](https://google.github.io/CausalImpact/CausalImpact.html) package in R, which basically works like this:

* The user feeds it a target and covariates
* The model uses the covariates to predict the target
* It uses the residuals in the post-test period to measure the effect of the change

Great -- except that I'm coming to a challenge I have again and again with statistical models, which is that tiny changes to the model completely change the results.

We are training the models on earlier data and checking the RMSE to ensure goodness of fit before using it on the actual test data, but I can use two models with near-identical RMSEs and have one test be positive and the other be negative.

The conventional wisdom I've always been told was not to peek at your data and not to tweak it once you've run the test, but that feels incorrect to me. My instinct is that, if you tweak your model slightly and get a different result, it's a good indicator that your results are not reproducible.

So I'm curious how other people handle this. I've been considering setting up the model to identify 5 settings with low RMSEs, run them all, and check for consistency of results, but that might be a bit drastic.

How do you other people handle this?",datascience,https://www.reddit.com/r/datascience/comments/17m2b07/how_do_you_avoid_phacking/,63,129,0.95,"[Comment(id='k7i02e0'), Comment(id='k7i26ek'), Comment(id='k7ijqka'), Comment(id='k7i2w1t'), Comment(id='k7jsk5q'), Comment(id='k7jhhqs'), Comment(id='k7i61dv'), Comment(id='k7jpjfp'), Comment(id='k7i1qh6'), Comment(id='k7phs46'), Comment(id='k7i8ynw'), Comment(id='k7i6cqk'), Comment(id='k7ihz1u'), Comment(id='k7iinnm'), Comment(id='k7jnljt'), Comment(id='k7kh8dc'), Comment(id='k7ku20h'), Comment(id='k7lqlqm'), Comment(id='k7m1gxd'), Comment(id='k7pjb3o'), Comment(id='k7vlez3'), Comment(id='k7iby3k'), Comment(id='k7ivov2'), Comment(id='k7i86n6'), Comment(id='k7jxr44'), Comment(id='k7jv2qk'), Comment(id='k7i56d3'), Comment(id='k7iddss'), Comment(id='k7ihpia'), Comment(id='k7ijrxy'), Comment(id='k7ieow5'), Comment(id='k7iywx7'), Comment(id='k7jnchy'), Comment(id='k7iebtv'), Comment(id='k7j9dr7'), Comment(id='k7ji2xd'), Comment(id='k7lpqsu'), Comment(id='k7ibxa0'), Comment(id='k7j1rpz'), Comment(id='k7i8iuk'), Comment(id='k7zkv32'), Comment(id='k7zkjys'), Comment(id='k7jo19l'), Comment(id='k7koswh'), Comment(id='k7ife8s'), Comment(id='k7mr7aa'), Comment(id='k7iswpp'), Comment(id='k7jbd9m'), Comment(id='k7kokbh'), Comment(id='k7zvp08'), Comment(id='k7ig8jo'), Comment(id='k7iva1e'), Comment(id='k7iyeo8'), Comment(id='k7jgwsw'), Comment(id='k7zzwov'), Comment(id='k7ih1rx'), Comment(id='k7iw8y0'), Comment(id='k7jrwgm'), Comment(id='k7ihbc9'), Comment(id='k7l1iiq'), Comment(id='k7jtdap'), Comment(id='k7kmihi'), Comment(id='k7l5j6s'), Comment(id='k7l7li1')]"
17m4paw,LionsBSanders20,,2023-11-02 14:27:14+00:00,False,,False,False,True,False,/r/datascience/comments/17m4paw/ds_team_leaders_when_requests_are_slow_or_little/,"DS Team Leaders, When requests are slow or little volume, what are you having your team work on in the meantime?","Title. We've given way, for now, to the Data Engineers and Architects to build out pipelines and such and until those are complete, we haven't had a ton of requests coming in.

When things are ""slow"" for your teams, what type of work are you having the junior scientists working on to maintain some level of productivity or skillset building?",datascience,https://www.reddit.com/r/datascience/comments/17m4paw/ds_team_leaders_when_requests_are_slow_or_little/,39,32,0.91,"[Comment(id='k7iglyd'), Comment(id='k7iludw'), Comment(id='k7imjt8'), Comment(id='k7ikf1c'), Comment(id='k7iliet'), Comment(id='k7ip5bq'), Comment(id='k7isa6h'), Comment(id='k7isqnx'), Comment(id='k7iwn94'), Comment(id='k7je0mh'), Comment(id='k7iioz5'), Comment(id='k7jw5c4'), Comment(id='k7muh4x'), Comment(id='k7pg18w'), Comment(id='k7qi1ze'), Comment(id='k7r1nvx'), Comment(id='k7un3x6'), Comment(id='k7im6p1'), Comment(id='k7k04wk'), Comment(id='k7k19fg'), Comment(id='k7imuwu'), Comment(id='k7jlu85'), Comment(id='k7iqh68'), Comment(id='k7k22ay'), Comment(id='k7k2ph9'), Comment(id='k7k2w32'), Comment(id='k7jja05'), Comment(id='k7k36ez'), Comment(id='k7k3g2k'), Comment(id='k7jm2da'), Comment(id='k7k3x17'), Comment(id='k7k3q7p'), Comment(id='k7jzn0l'), Comment(id='k7k0cvp'), Comment(id='k7k1c82'), Comment(id='k7k2f6q'), Comment(id='k7li1p6'), Comment(id='k7kaefz'), Comment(id='k7k0x5p')]"
17m6b4n,Tender_Figs,,2023-11-02 15:39:50+00:00,False,,False,False,True,False,/r/datascience/comments/17m6b4n/is_analytics_engineering_and_business/,Is analytics engineering and business intelligence experience beneficial for seeking DS roles?,"Or is it essentially seen as marginal? I suspect the larger companies would view it as marginal, and startups up to medium size (with small data teams) would be attracted by this experience. Is that a fair assumption?",datascience,https://www.reddit.com/r/datascience/comments/17m6b4n/is_analytics_engineering_and_business/,17,14,0.77,"[Comment(id='k7iripb'), Comment(id='k7j43p1'), Comment(id='k7kk1mt'), Comment(id='k7kb6lr'), Comment(id='k7smm1y'), Comment(id='k7ixofb'), Comment(id='k7l2utv'), Comment(id='k7muhof'), Comment(id='k7itbv7'), Comment(id='k7iv6pm'), Comment(id='k7ivuk5'), Comment(id='k7j1slv'), Comment(id='k7jf8zr'), Comment(id='k7j70tt'), Comment(id='k7jhav8'), Comment(id='k7jgppu'), Comment(id='k7jh0dh')]"
17meviz,house_lite,,2023-11-02 21:52:30+00:00,False,,False,False,True,False,/r/datascience/comments/17meviz/can_someone_help_explain_the_data_structure_of/,Can someone help explain the data structure of the m4 forecasting datasets?,,datascience,https://www.reddit.com/r/datascience/comments/17meviz/can_someone_help_explain_the_data_structure_of/,5,3,0.8,"[Comment(id='k7kfw6k'), Comment(id='k7licvh'), Comment(id='k7lqpez'), Comment(id='k7khs23'), Comment(id='k7kjtdv')]"
17lsxof,takemetojupyter,,2023-11-02 02:07:46+00:00,False,,False,False,True,False,/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,"qq - if I receive ""thanks but no thanks"" email months after application...","Does that mean my resume made it farther along in the decision process? That maybe I wasn't immediately auto-filtered out? Or does it mean nothing? 

I'm trying to understand how my resume faired against the algorithms... If anyone has tips on that or a library of the latest ""greenlight"" resume algorithm parser buzzwords, please, do share. 

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,11,26,0.81,"[Comment(id='k7gie1e'), Comment(id='k7gm2x2'), Comment(id='k7gejgs'), Comment(id='k7gh4ju'), Comment(id='k7gr70c'), Comment(id='k7hnv2j'), Comment(id='k7muizy'), Comment(id='k7gzp2w'), Comment(id='k7i8jnm'), Comment(id='k7hu809'), Comment(id='k7j3z0k')]"
17m4mmu,TheReal_KindStranger,,2023-11-02 14:23:44+00:00,False,,False,False,True,False,/r/datascience/comments/17m4mmu/running_glmm_with_binary_treatment_variable_and/,running glmm with binary treatment variable and time since treatment,"Hi , 

I have a dataset with a dependent variable and two explanatory variables. A binary treatment variable and quantitative time since treatment for the cases that received treatment and NA for none-treated cases.  

&#x200B;

Is it possible to include both in a single glmm? 

I'm using glmmtmb in R and the function can only handle NAs by omitting the cases with Na and it would mean here omitting all the non-treated cases from the analysis. 

I'd appreciate your thoughts and ideas.

 

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17m4mmu/running_glmm_with_binary_treatment_variable_and/,4,2,0.75,"[Comment(id='k7iie0f'), Comment(id='k7l52cr'), Comment(id='k7ir2m7'), Comment(id='k7ms87d')]"
17ltjt8,limedove,,2023-11-02 02:38:04+00:00,False,,False,False,True,False,/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,[SERIOUS] What do you not like about your boss or big bosses and how does that affect progress of your organization?,Curious about the DS arena,datascience,https://www.reddit.com/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,15,16,0.84,"[Comment(id='k7gifue'), Comment(id='k7h2qvc'), Comment(id='k7gqyvc'), Comment(id='k7i3tvg'), Comment(id='k7gpq7a'), Comment(id='k7gtqaq'), Comment(id='k7i39lm'), Comment(id='k7iis5o'), Comment(id='k82cya6'), Comment(id='k7l2yw7'), Comment(id='k7q8v5i'), Comment(id='k7gpyx5'), Comment(id='k7q89iy'), Comment(id='k7lj40j'), Comment(id='k7mwgdu')]"
17m17c7,cpluscplus,,2023-11-02 11:18:06+00:00,False,,False,False,True,False,/r/datascience/comments/17m17c7/can_somebody_share_their_experience_of_attending/,Can somebody share their experience of attending ICML conference?,"I'm planning to attend ICML 2024 in person. Can somebody share their experience of attending the conference? Is it worth attending if you don't have any paper to present? If yes, how to get the most out of it?",datascience,https://www.reddit.com/r/datascience/comments/17m17c7/can_somebody_share_their_experience_of_attending/,3,3,0.8,"[Comment(id='k7i9d76'), Comment(id='k7lrclr'), Comment(id='k7i9iw7')]"
17lrtkx,Actual_Plant_862,,2023-11-02 01:14:27+00:00,False,,False,False,True,False,/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,Help me understand if my approach is correct please!,"Hi all, I'm an junior data analyst. I'm currently learning all sorts of stats and techniques on my way to improving my skills.

Currently I'm investigating a dataset full of invoices and there are a few questions I'm trying to answer. 

For example how many orders are on time/late based on xyz checks which I've coded.
I've also found cost discrepancies between what was actually done and what was invoiced.

One task I've been assigned is to see what teams are ordering what services and I wanted to approach it with potentially a more nuanced approach.
I have recently been learning the theory and application of Association rules to do the following : 
 
I would like to know if I could split all the orders by teams and then code an association rule algorithm which would mean my results are specific to teams. 
E.g X team order y item and with y item z was also often ordered.


Outside of that is there any other kind of ""fun"" statistically backed learning I could do from invoices? 

Thanks for any advice!",datascience,https://www.reddit.com/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,5,7,0.74,"[Comment(id='k7gano0'), Comment(id='k7ga0kh'), Comment(id='k7gl0dq'), Comment(id='k7gl2jz'), Comment(id='k7j8jqt')]"
17le04v,DJAlaskaAndrew,Data Scientist MS|MBA ,2023-11-01 14:58:04+00:00,False,,False,False,True,False,/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,How to be Competitive for a Product Data Scientist Role?,"I'm a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I'm targeting appeared geared towards product data science. I'd like to hear from data scientists currently working in product roles:

\- How to stand out in terms of past experience, projects, resume, interview, etc?

\- What does a ""product"" data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?

\- What type of specific skills are you looking for outside of the core data science skillset?

I was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a ""product"", but I'm not sure if it's directly applicable, especially with regards to customer behavior.",datascience,https://www.reddit.com/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,24,45,0.87,"[Comment(id='k7dw0rv'), Comment(id='k7ev5sj'), Comment(id='k7gm7nr'), Comment(id='k7dx850'), Comment(id='k7dmrx9'), Comment(id='k7l44nu'), Comment(id='k7muk6m'), Comment(id='k7e6k6l'), Comment(id='k7hdjsd'), Comment(id='k7f5a75'), Comment(id='k7f5sfj'), Comment(id='k7f0ztz'), Comment(id='k7evfxh'), Comment(id='k7dnthe'), Comment(id='k7e9axv'), Comment(id='k7kq61n'), Comment(id='k7g7d1d'), Comment(id='k7f69lj'), Comment(id='k7f267i'), Comment(id='k7f0gyq'), Comment(id='k7mi08y'), Comment(id='k7flunr'), Comment(id='k7f25sm'), Comment(id='k7fu0ci'), Comment(id='k7g2k3s')]"
17kvjmp,nth_citizen,,2023-10-31 21:12:47+00:00,False,,False,False,True,False,/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,"Why some data science interviews suck, as an interviewer...","I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I'd give my experience from the other side of the desk which may go some way to showing why it can be so bad.

I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.

Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.

The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some 'calibration' briefing before the interviews; it was too late to speak to HR.

Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no 'calibration' brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.

I was dropped straight into a 'technical' interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.

There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be 'The candidate readily accepts new ideas'. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.

After a few of these there was the 'technical' section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.

Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.

Finally there was a group activity and we were supposed to observe the 'teamwork' but the team just split the tasks and got on with them individually so there was hardly anything to observe.

After this the HR bod asked us to complete all the assessments and submit them. Then we'd have a 'wash up'. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.

I also asked about the inappropriate technical questions and they said they didn't get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).

So, as you can see, HR ruin everything they touch and hiring is a HR process so it's terrible. Sorry if you had to go through this.",datascience,https://www.reddit.com/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,57,221,0.98,"[Comment(id='k7ah9us'), Comment(id='k7afkpn'), Comment(id='k7apu15'), Comment(id='k7agusa'), Comment(id='k7akpff'), Comment(id='k7aaang'), Comment(id='k7dn4f4'), Comment(id='k7annix'), Comment(id='k7c85vq'), Comment(id='k7d4vye'), Comment(id='k7d7msr'), Comment(id='k7bgpnw'), Comment(id='k7bj8x8'), Comment(id='k7bcavx'), Comment(id='k7cpgkg'), Comment(id='k7crelo'), Comment(id='k7lnwn9'), Comment(id='k7mukyd'), Comment(id='k7na8zb'), Comment(id='k7avauo'), Comment(id='k7b6fdc'), Comment(id='k7c1wwa'), Comment(id='k7bjbkx'), Comment(id='k7am65t'), Comment(id='k7anhof'), Comment(id='k7d5xfs'), Comment(id='k7azjm2'), Comment(id='k7c2yo6'), Comment(id='k7c3bo3'), Comment(id='k7c43cw'), Comment(id='k7co6gx'), Comment(id='k7b9joo'), Comment(id='k7b8jgg'), Comment(id='k7djw8b'), Comment(id='k7bkowz'), Comment(id='k7bdgly'), Comment(id='k7cq0z9'), Comment(id='k7g1x6r'), Comment(id='k7d4qkh'), Comment(id='k7bb9ef'), Comment(id='k7dnrn0'), Comment(id='k7c32ot'), Comment(id='k7cmiao'), Comment(id='k7bh92e'), Comment(id='k7cvek3'), Comment(id='k7h4jv6'), Comment(id='k7da6qn'), Comment(id='k7dfo31'), Comment(id='k7bmo7h'), Comment(id='k7d5s2w'), Comment(id='k7bkszh'), Comment(id='k7etpun'), Comment(id='k7bof37'), Comment(id='k7d6sgf'), Comment(id='k7d7qh3'), Comment(id='k7d9shg')]"
17kxd5s,CatOfGrey,,2023-10-31 22:33:54+00:00,False,,False,False,True,False,/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,Data folks of Reddit: How do you choose a random seed?,"From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. 

I always assumed that it was 'bad form' to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use ""42"" or ""365"" or ""1234"" all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? ",datascience,https://www.reddit.com/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,122,102,0.92,"[Comment(id='k7am1e8'), Comment(id='k7ay8wn'), Comment(id='k7al6fb'), Comment(id='k7amqcn'), Comment(id='k7al47v'), Comment(id='k7am6q9'), Comment(id='k7ap1t6'), Comment(id='k7al2qd'), Comment(id='k7aw76x'), Comment(id='k7b1x9y'), Comment(id='k7bawjl'), Comment(id='k7bfuk3'), Comment(id='k7c3wbe'), Comment(id='k7elmey'), Comment(id='k7aty7j'), Comment(id='k7al9zj'), Comment(id='k7aynti'), Comment(id='k7b3hux'), Comment(id='k7b7qwp'), Comment(id='k7bm48g'), Comment(id='k7do9ti'), Comment(id='k7efgs3'), Comment(id='k7egaof'), Comment(id='k7fopm2'), Comment(id='k7ar7e8'), Comment(id='k7b6xfb'), Comment(id='k7au5yp'), Comment(id='k7b7kdg'), Comment(id='k7c93j6'), Comment(id='k7b2s9b'), Comment(id='k7b3ucs'), Comment(id='k7b3w0b'), Comment(id='k7b43r1'), Comment(id='k7b455e'), Comment(id='k7b76nv'), Comment(id='k7bbetk'), Comment(id='k7bm21v'), Comment(id='k7bnura'), Comment(id='k7bnv75'), Comment(id='k7bojm8'), Comment(id='k7bsc6q'), Comment(id='k7bt7fa'), Comment(id='k7bx21b'), Comment(id='k7c1lc3'), Comment(id='k7c2b2i'), Comment(id='k7c30ue'), Comment(id='k7c3uvc'), Comment(id='k7c86lp'), Comment(id='k7cubna'), Comment(id='k7d3u1m'), Comment(id='k7d5ipm'), Comment(id='k7dbneb'), Comment(id='k7dgpkm'), Comment(id='k7djcc2'), Comment(id='k7dm9m9'), Comment(id='k7dmqik'), Comment(id='k7ds77f'), Comment(id='k7dyee9'), Comment(id='k7e5n1v'), Comment(id='k7emafd'), Comment(id='k7ew8ww'), Comment(id='k7ewe5h'), Comment(id='k7f2rw1'), Comment(id='k7f3nk8'), Comment(id='k7fntup'), Comment(id='k7fthax'), Comment(id='k7g97f4'), Comment(id='k7g9y9m'), Comment(id='k7ganw1'), Comment(id='k7gwu35'), Comment(id='k7kkkuw'), Comment(id='k7mullf'), Comment(id='k7so69w'), Comment(id='k7uj1ma'), Comment(id='k7uk300'), Comment(id='k7avjm6'), Comment(id='k7drar1'), Comment(id='k7cxe92'), Comment(id='k7azcya'), Comment(id='k7dd0ci'), Comment(id='k7c9a07'), Comment(id='k7b1oeo'), Comment(id='k7dhxeu'), Comment(id='k7d5fed'), Comment(id='k7cy4yc'), Comment(id='k7lzn3q'), Comment(id='k7b7cxb'), Comment(id='k7b18cj'), Comment(id='k7dej7t'), Comment(id='k7c5wva'), Comment(id='k7asjio'), Comment(id='k7b6dek'), Comment(id='k7e0ban'), Comment(id='k7dxayz'), Comment(id='k7d2bgx'), Comment(id='k7f0f1a'), Comment(id='k7avmfx'), Comment(id='k7b4kqx'), Comment(id='k7co4cp'), Comment(id='k7f0nou'), Comment(id='k7ayoys'), Comment(id='k7d13y0'), Comment(id='k7avsr1'), Comment(id='k7bla7d'), Comment(id='k7cfxl4'), Comment(id='k7jag3j'), Comment(id='k7dvrhf'), Comment(id='k7dadgm'), Comment(id='k7dww0k'), Comment(id='k7hacba'), Comment(id='k7b2vdc'), Comment(id='k7b77av'), Comment(id='k7dt7um'), Comment(id='k7ewj8c'), Comment(id='k7becii'), Comment(id='k7d90lt'), Comment(id='k7bf1v0'), Comment(id='k7imhrp'), Comment(id='k7bw8rf'), Comment(id='k7d9e6x'), Comment(id='k7bftl2'), Comment(id='k7fgy44')]"
17l11nx,Dependent_Mushroom98,,2023-11-01 01:32:37+00:00,False,,False,False,True,False,/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,Why should I learn LangChain? It’s like learning a whole new tool set on top of LLM/Transformer models…,If I don’t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..,datascience,https://www.reddit.com/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,26,29,0.81,"[Comment(id='k7bx827'), Comment(id='k7b8vi8'), Comment(id='k7bc1p1'), Comment(id='k7bqurc'), Comment(id='k7bn97g'), Comment(id='k7bytrk'), Comment(id='k7csakm'), Comment(id='k7dro1h'), Comment(id='k7ba8wb'), Comment(id='k7dtqor'), Comment(id='k7bsydb'), Comment(id='k7zirvx'), Comment(id='k7c6tce'), Comment(id='k7cy7je'), Comment(id='k7g8sjo'), Comment(id='k7dusnv'), Comment(id='k7g939e'), Comment(id='k7dwloa'), Comment(id='k7g9gax'), Comment(id='k7e2jw1'), Comment(id='k7elaaf'), Comment(id='k7f750k'), Comment(id='k7glzut'), Comment(id='k7elfe4'), Comment(id='k7elki0'), Comment(id='k7elouj')]"
17lffnz,SnooPineapples7791,,2023-11-01 16:02:18+00:00,False,,False,False,True,False,/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,Working on improving the process of converting documents into Embeddings (for vectorStores) for LLM applications but i need some ideas and complaints from you!,"I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.

I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.

But it seens my initial ideas of contribution were already done...

First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much better than they have already lol

I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.

Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them",datascience,https://www.reddit.com/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,1,2,0.67,[Comment(id='k7wpmnj')]
17koo01,_hairyberry_,,2023-10-31 16:11:08+00:00,False,,False,False,True,False,/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,Anyone else find time series work a little dull?,"Got assigned some TS projects at work and now have kind of carved out this niche at my company. It’s great career-wise but I feel like I’d enjoy working with other ML approaches more. 

Time series at the scale I’m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. 

It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. 

Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?",datascience,https://www.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,64,101,0.94,"[Comment(id='k78zvwd'), Comment(id='k791dfq'), Comment(id='k799iua'), Comment(id='k79nehl'), Comment(id='k790vfj'), Comment(id='k79pb2e'), Comment(id='k79i6yr'), Comment(id='k7anub0'), Comment(id='k7oxd3u'), Comment(id='k79zhdu'), Comment(id='k7aa8xo'), Comment(id='k7ab2zq'), Comment(id='k7auiqq'), Comment(id='k7a2s2z'), Comment(id='k79uiff'), Comment(id='k79rxkc'), Comment(id='k79pdot'), Comment(id='k7blboh'), Comment(id='k7bxnth'), Comment(id='k7cgxp6'), Comment(id='k7de69p'), Comment(id='k7dmkbp'), Comment(id='k7g0ko8'), Comment(id='k7mumxj'), Comment(id='k7v85ah'), Comment(id='k7982ln'), Comment(id='k79hdog'), Comment(id='k797039'), Comment(id='k7awg5r'), Comment(id='k7b5k2o'), Comment(id='k79itjd'), Comment(id='k7an3so'), Comment(id='k81uo60'), Comment(id='k7an05x'), Comment(id='k79ikzl'), Comment(id='k7am4eb'), Comment(id='k7akqnt'), Comment(id='k7aku1h'), Comment(id='k7amunh'), Comment(id='k7e7zrb'), Comment(id='k79l16s'), Comment(id='k7aanbj'), Comment(id='k7aznud'), Comment(id='k7aicz3'), Comment(id='k79b6hk'), Comment(id='k7aj9gv'), Comment(id='k79quc9'), Comment(id='k79lp7n'), Comment(id='k7as67k'), Comment(id='k7eci6z'), Comment(id='k7ajcoe'), Comment(id='k7e129l'), Comment(id='k7cu5qj'), Comment(id='k7aknyb'), Comment(id='k7a52yd'), Comment(id='k7ang0h'), Comment(id='k7emavt'), Comment(id='k7am49w'), Comment(id='k7cfbdd'), Comment(id='k7buzs3'), Comment(id='k7aqs5y'), Comment(id='k7dapgo'), Comment(id='k7ctsc7'), Comment(id='k7cf4cn')]"
17ktlc5,AnxiousEgg6284,,2023-10-31 19:46:26+00:00,False,,False,False,True,False,/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,"If you did an online MSc in Stats and/or DS or something in that area & liked it, what program was it and what did you like about it?","My company offers tuition assistance and I'm thinking about going back for a formal degree, but it'd need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there's gaps in my math and experience with some of the newer ML methods & neural networks in particular. 

I'm thinking of the Georgia Tech one but would be curious to hear about others.",datascience,https://www.reddit.com/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,12,16,0.9,"[Comment(id='k7aarz8'), Comment(id='k7bgye3'), Comment(id='k79zmul'), Comment(id='k7a292e'), Comment(id='k7a4omu'), Comment(id='k7fqh18'), Comment(id='k7bh1i8'), Comment(id='k7cl843'), Comment(id='k7exkfr'), Comment(id='k7bp1xc'), Comment(id='k7f9wfb'), Comment(id='k7qjecy')]"
17l8xdt,Thinker_Assignment,,2023-11-01 10:19:54+00:00,False,,False,False,True,False,/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,"Metabase, PowerBI and Gooddata capabilities: A comparison","Hello folks

For the ones of you who manage dashboards or semantic models in UI tools, here's an article describing 3 popular tools and their capabilities at doing this work

[https://dlthub.com/docs/blog/semantic-modeling-tools-comparison](https://dlthub.com/docs/blog/semantic-modeling-tools-comparison)

hope you enjoy the read and if you'd like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!",datascience,https://www.reddit.com/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,0,0,0.5,[]
17kvm37,Illustrious-Bed5587,,2023-10-31 21:15:49+00:00,False,,False,False,True,False,/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,Resources for technical interviews with focus on cleaning unstructured data?,I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?,datascience,https://www.reddit.com/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,5,5,0.78,"[Comment(id='k7ba2vz'), Comment(id='k7aq7vy'), Comment(id='k7d7x9s'), Comment(id='k7fqpb5')]"
17kp0nu,Dapper-Economy,,2023-10-31 16:26:38+00:00,False,,False,False,True,False,/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,How do you analyze your models?,"Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? 

My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren’t able to print summaries like this and I don’t think we should limit ourselves to GLR only for future projects. 

So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I’m not even sure how I would suggest using other algorithms for future business projects if they don’t agree with using a correlation matrix or features of importance to pick the features.",datascience,https://www.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,34,13,0.93,"[Comment(id='k78xxaq'), Comment(id='k79a858'), Comment(id='k79o5sb'), Comment(id='k79gm65'), Comment(id='k79qn1r'), Comment(id='k7addod'), Comment(id='k79wxkk'), Comment(id='k7diwr5'), Comment(id='k7gxm0h'), Comment(id='k79oczc'), Comment(id='k7dmsi1'), Comment(id='k7ex4uv'), Comment(id='k826ga9'), Comment(id='k78z6d5'), Comment(id='k7ai9ek'), Comment(id='k7abomm'), Comment(id='k79i92j'), Comment(id='k7ac186'), Comment(id='k7ifaog'), Comment(id='k7ahlpl'), Comment(id='k7iw8mx'), Comment(id='k7f8km7'), Comment(id='k79nyde'), Comment(id='k7aa0o9'), Comment(id='k7atf9k'), Comment(id='k7av4hz'), Comment(id='k7acks7'), Comment(id='k7abcd7'), Comment(id='k7ajyn6'), Comment(id='k7abgde'), Comment(id='k7aljlg'), Comment(id='k7acodz'), Comment(id='k7sn3in'), Comment(id='k7ae740')]"
17kpxml,ruckrawjers,,2023-10-31 17:07:33+00:00,False,,False,False,True,False,/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,automating ad-hoc SQL requests from stakeholders,"Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.

So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.

In the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served

DM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all",datascience,https://www.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,29,9,0.74,"[Comment(id='k79nn5s'), Comment(id='k7b2oq4'), Comment(id='k79htp2'), Comment(id='k7a068h'), Comment(id='k7c30nz'), Comment(id='k7d9ts2'), Comment(id='k79poy0'), Comment(id='k7ai4xx'), Comment(id='k7cwztd'), Comment(id='k7aymi0'), Comment(id='k7ayms7'), Comment(id='k79q7zl'), Comment(id='k7bd6li'), Comment(id='k7cxarq'), Comment(id='k7alucr'), Comment(id='k7ahb6r'), Comment(id='k7d0wv7'), Comment(id='k7aqww1'), Comment(id='k7d1ge3'), Comment(id='k7bd57c'), Comment(id='k7artlv'), Comment(id='k7atsxg'), Comment(id='k7d81ti'), Comment(id='k7at8gy'), Comment(id='k7b73zg'), Comment(id='k7bn85v'), Comment(id='k7b80fa'), Comment(id='k7eint8'), Comment(id='k7d6mq8')]"
17l3gak,Mission-Language8789,,2023-11-01 03:40:20+00:00,False,,False,False,True,False,/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,Thoughts on Krish Naik?,"I've been watching his videos for a while now and being a beginner, I assumed he was pretty good.

However, I've seen a few people criticise him for not knowing what he's talking about, and that he's only good for absolute beginners.",datascience,https://www.reddit.com/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,15,1,0.53,"[Comment(id='k7c8brh'), Comment(id='k7bsmbp'), Comment(id='k7c8dx2'), Comment(id='k7ci5l3'), Comment(id='k7bzgbd'), Comment(id='k7cbo5u'), Comment(id='k7cstez'), Comment(id='k7c2vr1'), Comment(id='k7d7tux'), Comment(id='k7giuwp'), Comment(id='k7sknav'), Comment(id='k7d021x'), Comment(id='k7c4qgz'), Comment(id='k7c9hmp')]"
17kvn2f,ExpressOcelot8977,,2023-10-31 21:16:59+00:00,False,,False,False,True,False,/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,Describe the analytics tool of your dreams…,I’ll compile answers and write an article with the summary,datascience,https://www.reddit.com/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,24,3,0.59,"[Comment(id='k7agjp0'), Comment(id='k7acd3t'), Comment(id='k7aewq9'), Comment(id='k7ai3uf'), Comment(id='k7boyi6'), Comment(id='k7cty8v'), Comment(id='k7b38uz'), Comment(id='k7aj5kl'), Comment(id='k7bch82'), Comment(id='k7apuw2'), Comment(id='k7bce98'), Comment(id='k7hnjhe'), Comment(id='k7smqis'), Comment(id='k7b9hwb'), Comment(id='k7acewc'), Comment(id='k7e9mpw'), Comment(id='k7b9848'), Comment(id='k7bxm8z'), Comment(id='k7d5yw5'), Comment(id='k7d1kw5'), Comment(id='k7c6nz2'), Comment(id='k7bct01'), Comment(id='k7d6f14'), Comment(id='k7bdddc')]"
17kmu0e,FreakedoutNeurotic98,,2023-10-31 14:51:22+00:00,False,,False,False,True,False,/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,Is Upwork a good place to find data science freelance gigs in the UK ?,Would appreciate other website suggestions too.,datascience,https://www.reddit.com/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,12,9,0.91,"[Comment(id='k78jc7v'), Comment(id='k7b3278'), Comment(id='k78ykku'), Comment(id='k7d7v63'), Comment(id='k7eusou'), Comment(id='k7lt360'), Comment(id='k78jmus'), Comment(id='k78ki9o'), Comment(id='k79la1s'), Comment(id='k78mtgv'), Comment(id='k78zx68'), Comment(id='k79kyy2')]"
17kmxnc,Total-Opposite-8396,,2023-10-31 14:56:04+00:00,False,,False,False,True,False,/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,What are the possible reasons for validation loss to fluctuate so much?,"Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.

I'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info.

https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&format=png&auto=webp&s=b20530593f527d138a190a33740e752692d984aa",datascience,https://www.reddit.com/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,2,5,1.0,"[Comment(id='k78q36e'), Comment(id='k7b4t8y')]"
17jtkgv,son_of_tv_c,,2023-10-30 13:36:51+00:00,False,,False,False,True,False,/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,Are all higher level data science jobs like this?,"I'm really not sure how to summarize this concisely in a neat title, so just let me explain.

At previous lower level jobs, we were organized. We had ticketing tracking systems, step-by-step procedures for all of the commonly done work, we had checklists that people could sign off on as they completed work. And most importantly, even for one-off requests, the primary mode of communication was email. That way, I had the project specifications and/or updates spelled out in front of me that I could refer back to whenever needed.

As I get higher up in the field at different companies, I'm finding the primary mode of communication is virtual meetings. All of the background, specifications, and next steps are given verbally, and I'm sitting here in these meetings furiously trying to write everything down that is being said. What's worse is that the ideas for the projects often aren't fully developed and we have to figure them out so I get a lot of ""do this, actually no, let's do it this way, but I'm actually thinking it would be better to approach it this way....."". AS you can imagine it makes fully understanding the next steps of a given projects difficult. If I use my judgement and approach it the way I feel is best, half the time it's end up not being what management wants and I have to waste their time and mine on rework. 

One of the ways I tried to work around management's brain dumps on me was to recap back to them what the next steps they wanted from me were, but they're ***super busy*** so they always join the meetings late, and as a result we frequently run out of time.  75% of the time I try to message or email them with questions they just don't respond, so the only way I can get any info out of them is via virtual meetings. This is creating an environment for me that makes mistakes easier to happen, and it's turning into a situation where I can do 9 things right, but if I missed or misunderstood the 10th thing, I'm getting crucified for it (meanwhile this is a common occurrence for management but that's a different rant.....) I'm being made to feel like it's a shortcoming of mine for not being able to take down everything accurately.

I know some people can thrive in these conditions. For me, it's tough. I'm definitely a scatterbrain and I try to compensate for this by being as organized as humanly possible, but it's just easier said than done when most everything is being given ONLY verbally. I understand that the higher you go in data science, the less routine and the more exploratory and R&D your work becomes, so having clearly documented procedures becomes less realistic. But if this is the way most of these positions are going to be, I really don't feel like this field is for me.",datascience,https://www.reddit.com/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,102,210,0.93,"[Comment(id='k736ud8'), Comment(id='k7393q5'), Comment(id='k73ewru'), Comment(id='k735wge'), Comment(id='k7397gs'), Comment(id='k73w16n'), Comment(id='k73jdk0'), Comment(id='k73bsuy'), Comment(id='k73zhy7'), Comment(id='k73hr0i'), Comment(id='k73to9u'), Comment(id='k73ufef'), Comment(id='k741hrl'), Comment(id='k742j9l'), Comment(id='k745fco'), Comment(id='k7486xb'), Comment(id='k748ae7'), Comment(id='k749i7v'), Comment(id='k74a6wc'), Comment(id='k74k2r5'), Comment(id='k75237v'), Comment(id='k752crf'), Comment(id='k75d5ud'), Comment(id='k75o3o7'), Comment(id='k762zpv'), Comment(id='k763oxa'), Comment(id='k76cb2r'), Comment(id='k76r2ji'), Comment(id='k76swrq'), Comment(id='k771fbw'), Comment(id='k77hnbv'), Comment(id='k77rn7v'), Comment(id='k783bbw'), Comment(id='k787dvu'), Comment(id='k78xhv5'), Comment(id='k795clc'), Comment(id='k79638f'), Comment(id='k7aof7y'), Comment(id='k7c820v'), Comment(id='k7cymwc'), Comment(id='k7d9xlc'), Comment(id='k7dfnav'), Comment(id='k7f7e10'), Comment(id='k7gibcr'), Comment(id='k7muoe5'), Comment(id='k7388bm'), Comment(id='k74y5ll'), Comment(id='k73fir6'), Comment(id='k744f0v'), Comment(id='k738xch'), Comment(id='k779on7'), Comment(id='k77wdsa'), Comment(id='k75ntfk'), Comment(id='k76zg67'), Comment(id='k7b8l77'), Comment(id='k73qop2'), Comment(id='k73c6zj'), Comment(id='k73liif'), Comment(id='k73owa6'), Comment(id='k73gi8j'), Comment(id='k73bd40'), Comment(id='k73qpni'), Comment(id='k745ryk'), Comment(id='k7bdhmp'), Comment(id='k771g6y'), Comment(id='k738oj4'), Comment(id='k73ly3a'), Comment(id='k7czenf'), Comment(id='k74q3wg'), Comment(id='k73eofx'), Comment(id='k757l6r'), Comment(id='k75c375'), Comment(id='k73n4tu'), Comment(id='k75sufy'), Comment(id='k77zhm9'), Comment(id='k76bap4'), Comment(id='k741mg3'), Comment(id='k73uoqp'), Comment(id='k7ecl81'), Comment(id='k73vdfn'), Comment(id='k78df45'), Comment(id='k77shpe'), Comment(id='k752se2'), Comment(id='k7445vz'), Comment(id='k7438o1'), Comment(id='k74rxga'), Comment(id='k75cxc0'), Comment(id='k73v68a'), Comment(id='k741wr1'), Comment(id='k747wpz'), Comment(id='k74ppwr'), Comment(id='k75nvia'), Comment(id='k74o0kv'), Comment(id='k78opse'), Comment(id='k74fo9r'), Comment(id='k746sm1'), Comment(id='k74g51j'), Comment(id='k7513a1'), Comment(id='k78teb8'), Comment(id='k74949k'), Comment(id='k790wtp'), Comment(id='k79323d')]"
17kfjr0,venkarafa,,2023-10-31 07:34:28+00:00,False,,False,False,True,False,/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,Is there any utility in using SHAP values for feature attribution in cases of Linear models and GLMs?," So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.

For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.

Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.

My question is : Would a SHAP value applied on top of the Linear regression model discover the same 'truth'. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?

What has been your experience? Has SHAP worked for you in case LM or GLM models?

What are the pitfalls of using SHAP?",datascience,https://www.reddit.com/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,3,7,1.0,"[Comment(id='k77jhur'), Comment(id='k7d84gv'), Comment(id='k7hhghu')]"
17jst3u,Throwawayforgainz99,,2023-10-30 12:58:31+00:00,False,,False,False,True,False,/r/datascience/comments/17jst3u/favorite_ml_example/,Favorite ML Example?,"I feel like a lot of kaggle examples use really simple data sets that you don’t ever find in the real world scenarios(like the Titanic data set for instance).

Does anyone know any notebooks/examples that start with really messy data? I really want to see someone go through the process of EDA/Feature engineering with data sets that have more than 20 variables.",datascience,https://www.reddit.com/r/datascience/comments/17jst3u/favorite_ml_example/,42,105,0.96,"[Comment(id='k73cjbc'), Comment(id='k73n0o8'), Comment(id='k74fknp'), Comment(id='k74medk'), Comment(id='k73duhg'), Comment(id='k75o3ob'), Comment(id='k73jbvg'), Comment(id='k775bp8'), Comment(id='k75qs9a'), Comment(id='k780jba'), Comment(id='k74h8nj'), Comment(id='k735m2g'), Comment(id='k75u35j'), Comment(id='k734cs7'), Comment(id='k73tejh'), Comment(id='k781x75'), Comment(id='k7dfwhc'), Comment(id='k7muqde'), Comment(id='k77vl4f'), Comment(id='k74h20p'), Comment(id='k754mfb'), Comment(id='k74783c'), Comment(id='k768wes'), Comment(id='k74ecqc'), Comment(id='k73jaov'), Comment(id='k7362d3'), Comment(id='k73mtqq'), Comment(id='k769eaq'), Comment(id='k7356tu'), Comment(id='k786syp'), Comment(id='k7ijzw4'), Comment(id='k74o11w'), Comment(id='k766f3l'), Comment(id='k7et3wm'), Comment(id='k767x38'), Comment(id='k7407sz'), Comment(id='k736aoi'), Comment(id='k77fsnm'), Comment(id='k7899cj'), Comment(id='k74stn2'), Comment(id='k7evujf')]"
17jxqm8,Unhappy_Technician68,,2023-10-30 16:45:20+00:00,False,,1698699696.0,False,True,False,/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,How does one find freelance or contract work? Short or long term would be fine.,"I work full time as a data scientist and I have 3 years experience now.  I've become significantly more efficient and experienced and I feel that I could take on more work than my company gives me.  My boss wouldn't mind if I took some extra work on the side, he's very flexible and I was wondering how people find contracts for short term gigs?  Are there any sites in particular people have had success with?  What do you typically bill at?  


Edit:  General vibe I'm getting is that this is a waste of time and after scrolling through the options on Upwork I'm coming to see it that way as well.",datascience,https://www.reddit.com/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,19,25,0.88,"[Comment(id='k746eyf'), Comment(id='k73yp0j'), Comment(id='k746f0n'), Comment(id='k77fh9j'), Comment(id='k7dwwam'), Comment(id='k747cbj'), Comment(id='k74lgec'), Comment(id='k77xjn4'), Comment(id='k7bdy8r'), Comment(id='k7d85we'), Comment(id='k7540id'), Comment(id='k748wz6'), Comment(id='k742x23'), Comment(id='k74kyjs'), Comment(id='k7cpw72'), Comment(id='k74nzn3'), Comment(id='k753f7w'), Comment(id='k7kv7ar'), Comment(id='k77zitb')]"
17jmq2n,EstablishmentHead569,,2023-10-30 06:00:30+00:00,False,,False,False,True,False,/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,Maintaining a work life balance,"How is everyone keeping a good work life balance in this industry? Or work in general. 

I am currently doing my masters as a full time DS and also doing certifications as requested by my managers. 

I am forcing myself to sleep earlier, but the daily screen time is just too draining for my eyes to keep up.",datascience,https://www.reddit.com/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,54,67,0.93,"[Comment(id='k722prt'), Comment(id='k722k7i'), Comment(id='k723i44'), Comment(id='k733kz1'), Comment(id='k72hw3b'), Comment(id='k72dakh'), Comment(id='k72jdoz'), Comment(id='k72n7ss'), Comment(id='k72wkrd'), Comment(id='k735n57'), Comment(id='k74llae'), Comment(id='k72csr2'), Comment(id='k7370x9'), Comment(id='k72pc88'), Comment(id='k72zgk3'), Comment(id='k731h5v'), Comment(id='k731i7b'), Comment(id='k734c4v'), Comment(id='k739thn'), Comment(id='k73k0c6'), Comment(id='k73t2bs'), Comment(id='k742kkd'), Comment(id='k74dv24'), Comment(id='k74hmbt'), Comment(id='k7ag38a'), Comment(id='k7b3ed8'), Comment(id='k7c87cb'), Comment(id='k7c87cl'), Comment(id='k7dg0gp'), Comment(id='k7ey3pl'), Comment(id='k75j4u4'), Comment(id='k74s5vy'), Comment(id='k7408dp'), Comment(id='k776goc'), Comment(id='k72kxdr'), Comment(id='k72tx4o'), Comment(id='k736f8e'), Comment(id='k72joe1'), Comment(id='k72hnjc'), Comment(id='k7cbv9m'), Comment(id='k75qj5i'), Comment(id='k72mbc4'), Comment(id='k739wal'), Comment(id='k737c86'), Comment(id='k77tq4m'), Comment(id='k792n1v'), Comment(id='k72mu6j'), Comment(id='k73q0ln'), Comment(id='k79wdw2'), Comment(id='k7arxgj'), Comment(id='k72rbbe'), Comment(id='k760p2i'), Comment(id='k7arwn1'), Comment(id='k766fw7')]"
17k3svb,soggypocket,,2023-10-30 21:10:02+00:00,False,,False,False,True,False,/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,Has anyone tried Cursor.sh AI editor for data science?,I've seen a few people talk cursor [https://cursor.sh/](https://cursor.sh/) for software saying that it was good. Has anyone tried it for data science?  ,datascience,https://www.reddit.com/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,3,3,0.67,"[Comment(id='k75k6tu'), Comment(id='k7828z8'), Comment(id='k757lrw')]"
17jrbh7,Hot-Profession4091,,2023-10-30 11:35:09+00:00,False,,False,False,True,False,/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,Recommendation for measuring similarity of paragraphs,"I’m doing some analysis and part of my data, possibly a very important part, is a text description of a product. I want to determine if there’s a correlation between the product description and performance, but to do this I need to cluster the descriptions into similar groups. I’m thinking text embeddings could be useful, but I’m unsure of which ones to use. Can anyone provide some advice?

Possibly more important, if I’m completely barking up the wrong tree, please let me know. ",datascience,https://www.reddit.com/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,14,4,1.0,"[Comment(id='k73wf95'), Comment(id='k74h4q5'), Comment(id='k774vqp'), Comment(id='k77alwv'), Comment(id='k72tny3'), Comment(id='k73lf0s'), Comment(id='k75i4k0'), Comment(id='k778ban'), Comment(id='k7b3m6p'), Comment(id='k7d87qs'), Comment(id='k73yjdi'), Comment(id='k74vgts'), Comment(id='k73lyun'), Comment(id='k750aiq')]"
17jygyq,missing-in-idleness,,2023-10-30 17:16:58+00:00,False,,False,False,True,False,/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,Where to Draw the Line between Proof of Concept and Deployment?,"Are you currently involved in a project that revolves around fulfilling customer requirements? As part of your responsibilities, are you tasked with deploying a functional data science project?

I'm referring to the point at which you determine that the project is prepared for delivery. Is it sufficient to provide a functional model based on a script or notebook, accompanied by a presentation that includes relevant metrics? Or do you also engage in the deployment phase? I'm somewhat perplexed because there is often a request for a ""proof of concept,"" but is functional code alone sufficient to satisfy this requirement?

I am a part of a small team and my team seldom deals with external clients, so I'm unsure about the boundaries between what should be accomplished before transitioning to a production-level stage. ",datascience,https://www.reddit.com/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,8,1,0.67,"[Comment(id='k74hzqz'), Comment(id='k779eh9'), Comment(id='k7c82ql'), Comment(id='k75504o'), Comment(id='k75q19q'), Comment(id='k75yphr'), Comment(id='k76so1q'), Comment(id='k7g114x')]"
17jgck2,AnxiousEgg6284,,2023-10-29 23:58:58+00:00,False,,False,False,True,False,/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,How have you approached training yourself to become better at business acumen/context for your DS work?,"This is the thing I'm struggling most with. Coming from an academic background, the concerns seem to be different but I'm still having trouble articulating exactly how, or what to do to get better at training myself to be more business-ybif that makes sense",datascience,https://www.reddit.com/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,23,20,0.84,"[Comment(id='k71ndsz'), Comment(id='k70yjdg'), Comment(id='k70wz6q'), Comment(id='k70wgi1'), Comment(id='k716078'), Comment(id='k71hs1n'), Comment(id='k71n029'), Comment(id='k73w7dc'), Comment(id='k71pkgm'), Comment(id='k71vihu'), Comment(id='k72dvnr'), Comment(id='k72wayn'), Comment(id='k736bbo'), Comment(id='k737x03'), Comment(id='k739ll5'), Comment(id='k73y2a8'), Comment(id='k74tal1'), Comment(id='k7ezyhu'), Comment(id='k7h4vph'), Comment(id='k72qxd2'), Comment(id='k7173kw'), Comment(id='k71rmml'), Comment(id='k71slxw')]"
17j3qc7,Objective-Test5021,,2023-10-29 14:10:10+00:00,False,,1698641722.0,False,True,False,/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,The job market is so frustrating,"Graduated 5 months ago with a MS in CS. Before I came to the US to pursue my masters, heard from a boat load of people that getting jobs after graduation was easy and that hardly anyone graduated without a couple offers in hand. That sentiment was echoed by other recent grads I met when I got here.

I always wanted to get into DS, so when everyone started looking for internships, I started looking for DS/DA/DE internships specifically. Gave a bunch of interviews, landed an offer in April of 2022. Just an unfortunate decision. The company had a new data science practice with no clear definition of what a Data Scientist does. Being a consulting firm, we basically jump from one case to another and use whatever tech is needed on a case to case basis.
Spent all summer just doing web scraping and OCR extractions. Also, my manager is super condescending and outright rude. He’s told me multiple times that he “can’t believe I have two degrees in Comp. Sci” and at team gatherings and social events, wouldn’t even look me in the eye or acknowledge my existence lol. On the last day of my summer internship, he was in my office literally laughing at my code which btw was based off a snippet he sent me.

Anyway, once this ordeal was done, the world went into a recession and I had to accept a return internship offer. Return internship because I hadn’t proven myself enough to land a full time role yet. Went through another 3 months of abuse and got a full time offer, been working FT for about 4-5 months now. 

At this point I can’t take it anymore. Every day at work I’m putting out fires with the fear that if I fuck up, I’ll either be publicly ridiculed or fired. Consulting being consulting, work life balance is non existent and I had to move to a city where I have no friends and no social life to at least escape the stress.

To all seniors and hiring managers etc, do you think the job market is going to get better? What’s the trend at your company?

EDIT: Thanks for all the support everyone, it’s a tough spot to be in mentally, but I’m thankful for at least have a job. I know so many people who don’t, so complaining sucks. Hopefully things improve for us all soon.",datascience,https://www.reddit.com/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,55,117,0.85,"[Comment(id='k6yd2a8'), Comment(id='k6yjrnd'), Comment(id='k6z38kj'), Comment(id='k717s2h'), Comment(id='k703hz5'), Comment(id='k6z9h0g'), Comment(id='k6zlrg1'), Comment(id='k71bw59'), Comment(id='k75fb85'), Comment(id='k6zzj1p'), Comment(id='k71ht8w'), Comment(id='k73amqs'), Comment(id='k7ex7xq'), Comment(id='k72yun7'), Comment(id='k6yj75b'), Comment(id='k70le0d'), Comment(id='k71i9pt'), Comment(id='k71svxs'), Comment(id='k71xb7a'), Comment(id='k725a2v'), Comment(id='k731joo'), Comment(id='k731k6j'), Comment(id='k731ks6'), Comment(id='k73tp9i'), Comment(id='k76ysr8'), Comment(id='k7b3svm'), Comment(id='k7bdkgs'), Comment(id='k7smsv6'), Comment(id='k6yfy5h'), Comment(id='k6ydbc0'), Comment(id='k79uu5g'), Comment(id='k6ypo4l'), Comment(id='k6z5yqg'), Comment(id='k719d57'), Comment(id='k71ymnc'), Comment(id='k6zhkaj'), Comment(id='k71hcek'), Comment(id='k7342vk'), Comment(id='k70mnnc'), Comment(id='k71vyh6'), Comment(id='k71ydlo'), Comment(id='k73u456'), Comment(id='k781tbv'), Comment(id='k6yi7mv'), Comment(id='k6yqt1e'), Comment(id='k6zyf23'), Comment(id='k71bgut'), Comment(id='k6zhu7d'), Comment(id='k739a12'), Comment(id='k70mpxi'), Comment(id='k70nkxg'), Comment(id='k71z3az'), Comment(id='k740bk5'), Comment(id='k6yoebn'), Comment(id='k70r5yz')]"
17jkxjp,AutoModerator,,2023-10-30 04:01:25+00:00,False,,False,False,True,False,/r/datascience/comments/17jkxjp/weekly_entering_transitioning_thread_30_oct_2023/,"Weekly Entering & Transitioning - Thread 30 Oct, 2023 - 06 Nov, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/17jkxjp/weekly_entering_transitioning_thread_30_oct_2023/,94,10,1.0,"[Comment(id='k74xjg4'), Comment(id='k72kyyb'), Comment(id='k75do1o'), Comment(id='k7b48l3'), Comment(id='k769lz1'), Comment(id='k790t2p'), Comment(id='k7as781'), Comment(id='k7e2a60'), Comment(id='k7j0jpk'), Comment(id='k7oq8qr'), Comment(id='k7qui4l'), Comment(id='k7qwxei'), Comment(id='k7sajq7'), Comment(id='k7nmsmg'), Comment(id='k75bsg0'), Comment(id='k771jnz'), Comment(id='k77mtea'), Comment(id='k79tf96'), Comment(id='k7bsl83'), Comment(id='k7dbaek'), Comment(id='k7fu40u'), Comment(id='k7gc0kh'), Comment(id='k7h66ei'), Comment(id='k7o9h31'), Comment(id='k7oaxtp'), Comment(id='k7ok7i6'), Comment(id='k7pg7lo'), Comment(id='k7s898u'), Comment(id='k7ve3w6'), Comment(id='k7w2d9j'), Comment(id='k754h7o'), Comment(id='k72qlbx'), Comment(id='k72r2pg'), Comment(id='k7o5zyv'), Comment(id='k75str7'), Comment(id='k769qa9'), Comment(id='k79y3tv'), Comment(id='k7c8zc9'), Comment(id='k7d3gnf'), Comment(id='k7getng'), Comment(id='k77xfn6'), Comment(id='k78u6ct'), Comment(id='k79xz8e'), Comment(id='k7lzpnk'), Comment(id='k7f4gsw'), Comment(id='k7i3toe'), Comment(id='k7n7qiv'), Comment(id='k7uab48'), Comment(id='k7yovjr'), Comment(id='k7tzldl'), Comment(id='k7zf0gf'), Comment(id='k7iclpg'), Comment(id='k783u5c'), Comment(id='k79omrb'), Comment(id='k7c8wr8'), Comment(id='k7g0a77'), Comment(id='k783rm1'), Comment(id='k7m00kj'), Comment(id='k7m5ifv'), Comment(id='k7ooy26'), Comment(id='k7h8122'), Comment(id='k7lzfd9'), Comment(id='k7lypug'), Comment(id='k7thhwi'), Comment(id='k7thy4h'), Comment(id='k7oo85t'), Comment(id='k7ynxsg'), Comment(id='k7ynkb9'), Comment(id='k75aui8'), Comment(id='k7dwb80'), Comment(id='k79ddh4'), Comment(id='k7qjov9'), Comment(id='k7kukl4'), Comment(id='k7iirhy'), Comment(id='k80zhq1'), Comment(id='k7ubluw'), Comment(id='k78uhek'), Comment(id='k7am0p0'), Comment(id='k7m539t'), Comment(id='k7p2vzf'), Comment(id='k7zjx1z'), Comment(id='k75dxk0'), Comment(id='k7o4zkr'), Comment(id='k7oohoo'), Comment(id='k7sm0u8'), Comment(id='k7ui7so'), Comment(id='k7zhh30'), Comment(id='k78xkw5'), Comment(id='k7apxol'), Comment(id='k7pb0gw'), Comment(id='k7zn5m9'), Comment(id='k75eswm'), Comment(id='k7uikgq'), Comment(id='k7pwl2c')]"
17jg57k,lowkeyripper,,2023-10-29 23:49:08+00:00,False,,False,False,True,False,/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,Python library to interactively filter a dataframe?,"For all intents and purposes its basically a Power BI table with slicers/filters, or a GUI approach of df[(mask1) & (mask2) & (mask3)].sort_values(by='col1') where you can interact with which columns to mask, how to mask them, and how to sort, resulting in a perfectly tailored table.

I have scraped a list of every game on Steam and I have a dataframe of like 180k games and 470+ columns and was thinking how cool it would be if I could make 
every a table as granular as I want it. e.g. find me games from 2008 that have 1000 total ratings and more than 95% steam review with the tag ""FPS"" sorted by the date it came out, and hide the majority of columns.

If something like this doesnt exist but is able to exist in something like Flask (that I have NO knowledge on), let me know. I just wanted to check if the wheel exists before rebuilding it. If what I want really is difficult to do, let me know and I can just make the same thing in Power BI. This will also make me appreciate Power BI as a tool.",datascience,https://www.reddit.com/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,18,18,0.95,"[Comment(id='k70wmdd'), Comment(id='k71s7dv'), Comment(id='k723dui'), Comment(id='k7187xf'), Comment(id='k71fbbr'), Comment(id='k726hmc'), Comment(id='k7b3zet'), Comment(id='k71airi'), Comment(id='k72bd25'), Comment(id='k765nfj'), Comment(id='k70xnky'), Comment(id='k70xfo6'), Comment(id='k70zwju'), Comment(id='k71adik'), Comment(id='k70y9ok'), Comment(id='k70z5f9'), Comment(id='k7129kq')]"
17j80cj,LowLab2791,,2023-10-29 17:33:58+00:00,False,,False,False,True,False,/r/datascience/comments/17j80cj/whats_your_educational_background/,What's your educational background,Hi r/datascience. I am interested to know the educational qualifications/background of the members of the group. Personally I have a Bachelor's degree in Maths + an MBA. Have been working in Banking + Analytics for the last 12 years. I know we have CS graduates in this group and those who have done MS in data science and Analytics. Would be good to know the diverse educational background of others as well.,datascience,https://www.reddit.com/r/datascience/comments/17j80cj/whats_your_educational_background/,174,48,0.83,"[Comment(id='k6zjg2j'), Comment(id='k6zhok8'), Comment(id='k706yvo'), Comment(id='k6znncq'), Comment(id='k6zsc21'), Comment(id='k6zzd0r'), Comment(id='k6zaq0c'), Comment(id='k708brj'), Comment(id='k6z987h'), Comment(id='k6zt476'), Comment(id='k6zymm4'), Comment(id='k70rh0s'), Comment(id='k6zqxik'), Comment(id='k6zxzlp'), Comment(id='k70940e'), Comment(id='k6zvb8f'), Comment(id='k6zx4j4'), Comment(id='k70i9cc'), Comment(id='k72ibnl'), Comment(id='k70lnnd'), Comment(id='k70lo7f'), Comment(id='k71a5jq'), Comment(id='k71muv9'), Comment(id='k71qw89'), Comment(id='k723lji'), Comment(id='k72kl60'), Comment(id='k71thyb'), Comment(id='k7287vl'), Comment(id='k7cwrve'), Comment(id='k6zhrcj'), Comment(id='k6zzjlb'), Comment(id='k70fhxq'), Comment(id='k6zuoqz'), Comment(id='k6zwkag'), Comment(id='k706lwe'), Comment(id='k70evbm'), Comment(id='k70nv2u'), Comment(id='k70qhjv'), Comment(id='k70vqsz'), Comment(id='k70z3st'), Comment(id='k7105l9'), Comment(id='k71f38d'), Comment(id='k71zm2x'), Comment(id='k72cued'), Comment(id='k72lto6'), Comment(id='k72te79'), Comment(id='k72wgkk'), Comment(id='k732ept'), Comment(id='k74qo3z'), Comment(id='k76ysoi'), Comment(id='k77gd5v'), Comment(id='k6zdqxw'), Comment(id='k6zqcv5'), Comment(id='k6zy6qc'), Comment(id='k722n98'), Comment(id='k72ct3n'), Comment(id='k7gy3vt'), Comment(id='k703n1t'), Comment(id='k70cyyv'), Comment(id='k70dqqz'), Comment(id='k70e97w'), Comment(id='k70mp0w'), Comment(id='k70sldk'), Comment(id='k70zivx'), Comment(id='k714wy4'), Comment(id='k71f8jw'), Comment(id='k71qnwe'), Comment(id='k71qwhl'), Comment(id='k71tn8k'), Comment(id='k71v3vb'), Comment(id='k72e7mn'), Comment(id='k72ecoq'), Comment(id='k72ol06'), Comment(id='k72t5i4'), Comment(id='k72x6bd'), Comment(id='k72z2g8'), Comment(id='k72zhc8'), Comment(id='k731m9y'), Comment(id='k735frg'), Comment(id='k73a9fc'), Comment(id='k746ou1'), Comment(id='k74m46l'), Comment(id='k750hml'), Comment(id='k768uce'), Comment(id='k77o6ie'), Comment(id='k782fj9'), Comment(id='k7844dz'), Comment(id='k7a42t9'), Comment(id='k7bemkm'), Comment(id='k7c8zol'), Comment(id='k7de7bh'), Comment(id='k7devkx'), Comment(id='k7eyzbj'), Comment(id='k7fmlhb'), Comment(id='k7jdq0z'), Comment(id='k7p7mcx'), Comment(id='k6zt1oq'), Comment(id='k71sbi4'), Comment(id='k732a0w'), Comment(id='k75e5i4'), Comment(id='k6zim3a'), Comment(id='k710t0q'), Comment(id='k74iu7r'), Comment(id='k71f6hd'), Comment(id='k759wyf'), Comment(id='k700ynh'), Comment(id='k767omk'), Comment(id='k71wt1q'), Comment(id='k70i2eb'), Comment(id='k6zylns'), Comment(id='k71td4b'), Comment(id='k75rcm1'), Comment(id='k75phgi'), Comment(id='k71myoo'), Comment(id='k70lup4'), Comment(id='k71wtz1'), Comment(id='k6zxfya'), Comment(id='k70mnc2'), Comment(id='k6zyt75'), Comment(id='k76znhb'), Comment(id='k72knk0'), Comment(id='k70lz42'), Comment(id='k79o0hs'), Comment(id='k6zuvh2'), Comment(id='k71zh47'), Comment(id='k73auii'), Comment(id='k75eavr'), Comment(id='k7014sh'), Comment(id='k7168mw'), Comment(id='k74sxxo'), Comment(id='k702x58'), Comment(id='k7p29fo'), Comment(id='k75a66l'), Comment(id='k75qx8c'), Comment(id='k700gtz'), Comment(id='k72lyox'), Comment(id='k71n0m0'), Comment(id='k719i80'), Comment(id='k73yxjq'), Comment(id='k70483q'), Comment(id='k736cfp'), Comment(id='k77t6nm'), Comment(id='k70nero'), Comment(id='k79vfo7'), Comment(id='k6zxcw1'), Comment(id='k72a0wj'), Comment(id='k73d6kq'), Comment(id='k70e0kb'), Comment(id='k71a2wz'), Comment(id='k705bg2'), Comment(id='k75cqnk'), Comment(id='k71x2db'), Comment(id='k7aeh1v'), Comment(id='k74c9as'), Comment(id='k70v6nf'), Comment(id='k6zyb1u'), Comment(id='k71drfr'), Comment(id='k70w2kz'), Comment(id='k75j0ox'), Comment(id='k82cy2u'), Comment(id='k79f3wz'), Comment(id='k70vv1x'), Comment(id='k7044en'), Comment(id='k71w5ti'), Comment(id='k75jkhz'), Comment(id='k79mypx'), Comment(id='k71rthj'), Comment(id='k75kslh'), Comment(id='k75mxso'), Comment(id='k72htco'), Comment(id='k75m1du'), Comment(id='k75oswy'), Comment(id='k75si4y'), Comment(id='k75oako')]"
17iztuz,julkar9,,2023-10-29 10:08:06+00:00,False,,False,True,True,False,/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,Python package for statistical data animations," 

Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot are available but I am planning to add other plots as well like choropleths, temporal graphs, etc.

Also please let me know if you find any issue.

**Pynimate** is available on [pypi](https://pypi.org/project/pynimate/).

[github](https://github.com/julkaar9/pynimate), [documentation](https://julkaar9.github.io/pynimate/)

Quick usage

    import pandas as pd
    from matplotlib import pyplot as plt
    
    import pynimate as nim
    
    df = pd.DataFrame(
        {
            ""time"": [""1960-01-01"", ""1961-01-01"", ""1962-01-01""],
            ""Afghanistan"": [1, 2, 3],
            ""Angola"": [2, 3, 4],
            ""Albania"": [1, 2, 5],
            ""USA"": [5, 3, 4],
            ""Argentina"": [1, 4, 5],
        }
    ).set_index(""time"")
    
    cnv = nim.Canvas()
    bar = nim.Barhplot.from_df(df, ""%Y-%m-%d"", ""2d"")
    bar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(""%b, %Y""))
    cnv.add_plot(bar)
    cnv.animate()
    plt.show()

&#x200B;

https://i.redd.it/27xu9yip74xb1.gif

A little more complex example

&#x200B;

https://i.redd.it/kycvoy4u74xb1.gif

(note: I am aware that animating line plots generally doesn't make any sense)",datascience,https://www.reddit.com/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,23,170,0.98,"[Comment(id='k6xqb6s'), Comment(id='k6xvjd1'), Comment(id='k6xt68g'), Comment(id='k6xp8x1'), Comment(id='k6yj44t'), Comment(id='k704o09'), Comment(id='k7067ku'), Comment(id='k71yrb7'), Comment(id='k72faoy'), Comment(id='k7356mo'), Comment(id='k7001wx'), Comment(id='k717fdg'), Comment(id='k6xqe6n'), Comment(id='k6xwwlc'), Comment(id='k6xwx8q'), Comment(id='k6y5g0s'), Comment(id='k6xq5bk'), Comment(id='k6ym971'), Comment(id='k721dup'), Comment(id='k705p7v'), Comment(id='k6y9f93'), Comment(id='k70e0f9'), Comment(id='k71toq9')]"
17ju0z8,David202023,,2023-10-30 13:58:48+00:00,False,,False,False,True,False,/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,"What is the best way to access computation power for a pet project on small LMMs and BERT fine-tuning, without spending a fortune?","I'm a data scientist with a pet project that could turn into something more, but I need more computation power. I have a PC with an RTX 2060 SUPER, but it's getting old. I'm considering Colab Pro+, but I prefer to work with VS Code and build my projects as folders rather than notebooks. I've also explored cloud options, but they seem expensive. My last resort is to buy a refurbished 16GB V100, but I'm hoping to find a more affordable solution.",datascience,https://www.reddit.com/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,8,1,0.6,"[Comment(id='k76t7jq'), Comment(id='k782qol'), Comment(id='k73usat'), Comment(id='k77adk9'), Comment(id='k774pd1'), Comment(id='k78q23k'), Comment(id='k78q5qu'), Comment(id='k78pl28')]"
17jg3hh,Careful_Engineer_700,,2023-10-29 23:46:52+00:00,False,,False,False,True,False,/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,Identifying time series patterns advice,"Hey you guys, I have something I am stuck at and need your advice.

Long story shirt in example:
Customer A: likes to buy at the beginning of the month only
Customer B: likes to buy at the end of each week when visited by an agent because he stocks
Customer C: likes to buy at the beginning, middle and end of the month.

And so on, you kinda get the problem.

I want to be able to identify this and I was thinking of a possible solution but I think it lacks experience: Decompose the seasonal component of each retailer’s time series and then cluster retailers whom purchasing seasonal components are similar with kmeans?

If you think this approach is invalid, please feel free to suggest something I could read.

Thanks.",datascience,https://www.reddit.com/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,9,1,0.6,"[Comment(id='k72egfp'), Comment(id='k74wuzi'), Comment(id='k72qrhr'), Comment(id='k73bum9'), Comment(id='k73rx8j'), Comment(id='k73xrfj'), Comment(id='k754e81'), Comment(id='k754xa2'), Comment(id='k759vzi')]"
17ie7f0,NewEcho2940,,2023-10-28 13:49:59+00:00,False,,False,False,True,False,/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,PSA: Don’t become DS. Be a DA instead.,"I’ve been on this board for a few years and noticed a trend. Many people saying they got a MS in DS and complain they only do excel or simple models. Recently, I see a lot of people saying they can’t get DS jobs. Here is the thing, most businesses need a lot more DA then DS. There are so many more basic data needs then complex ones. Most companies I’ve worked for have a ratio of about 5:1 DA to DS. Unless you’re a really strong and savvy DS candidate (smarter then me) you’re probably better off doing DA or SWE. I am a DS director and I spend 80% of my time doing DE and DA because that’s what the business needs.",datascience,https://www.reddit.com/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,199,460,0.88,"[Comment(id='k6tlm99'), Comment(id='k6tl4pi'), Comment(id='k6ttpbm'), Comment(id='k6u8yt4'), Comment(id='k6tzdlj'), Comment(id='k6tk1ei'), Comment(id='k6u1zis'), Comment(id='k6tv8ow'), Comment(id='k6u3gmn'), Comment(id='k6tm3fd'), Comment(id='k6tpglh'), Comment(id='k6tpi2g'), Comment(id='k6tsk72'), Comment(id='k6u73ih'), Comment(id='k6uj199'), Comment(id='k6ucnhd'), Comment(id='k6w13mh'), Comment(id='k6y7xfu'), Comment(id='k74glgf'), Comment(id='k6toj2y'), Comment(id='k6try18'), Comment(id='k6tpm2t'), Comment(id='k6vghy5'), Comment(id='k6u8a3x'), Comment(id='k6x4jlj'), Comment(id='k6ty411'), Comment(id='k6ueyyf'), Comment(id='k6umue4'), Comment(id='k6utesc'), Comment(id='k6v1z99'), Comment(id='k6vap6g'), Comment(id='k6vgiea'), Comment(id='k6vgivn'), Comment(id='k6vpdns'), Comment(id='k6wuglz'), Comment(id='k6xfapb'), Comment(id='k6yj6il'), Comment(id='k6zpbgv'), Comment(id='k72h2pu'), Comment(id='k731r5v'), Comment(id='k731rob'), Comment(id='k745efe'), Comment(id='k79qthh'), Comment(id='k7d8e9a'), Comment(id='k7dg8w0'), Comment(id='k7dj8s4'), Comment(id='k7ezm0a'), Comment(id='k7smu82'), Comment(id='k6to9dt'), Comment(id='k6ulq8e'), Comment(id='k6uwivi'), Comment(id='k6upktf'), Comment(id='k6urjwq'), Comment(id='k6vw0z5'), Comment(id='k72twjq'), Comment(id='k6u0x8s'), Comment(id='k6vlrw0'), Comment(id='k74zz2y'), Comment(id='k6tvj0u'), Comment(id='k6tleck'), Comment(id='k6tn3kl'), Comment(id='k6u631c'), Comment(id='k6u18ia'), Comment(id='k6umfu4'), Comment(id='k6xd5jn'), Comment(id='k6tug77'), Comment(id='k6uo3iy'), Comment(id='k6u34k0'), Comment(id='k6u7k63'), Comment(id='k6yz2qr'), Comment(id='k72ue6m'), Comment(id='k6u9p9l'), Comment(id='k6v2dif'), Comment(id='k728h8o'), Comment(id='k6tm6fa'), Comment(id='k6u58wr'), Comment(id='k6tle41'), Comment(id='k6u24tb'), Comment(id='k6v2mqe'), Comment(id='k6u7z46'), Comment(id='k6up0l6'), Comment(id='k6u9i3t'), Comment(id='k6tu9sc'), Comment(id='k6tvrwd'), Comment(id='k6uu8pt'), Comment(id='k6tsrjn'), Comment(id='k6x4lb9'), Comment(id='k6whp5j'), Comment(id='k7e0s7k'), Comment(id='k6twyeq'), Comment(id='k6vx2s5'), Comment(id='k6u4v5x'), Comment(id='k762lin'), Comment(id='k74tm6j'), Comment(id='k6vjenk'), Comment(id='k6w2yxn'), Comment(id='k70xy8d'), Comment(id='k6vyfpy'), Comment(id='k73472u'), Comment(id='k6vxaru'), Comment(id='k6vyrv2'), Comment(id='k6w7gr4'), Comment(id='k6tupps'), Comment(id='k6to1gy'), Comment(id='k6tp3mw'), Comment(id='k6tmlbb'), Comment(id='k6wnca0'), Comment(id='k6tu793'), Comment(id='k6u1s3p'), Comment(id='k6up7i8'), Comment(id='k6vk82g'), Comment(id='k6ulumy'), Comment(id='k6y3chd'), Comment(id='k6u87pd'), Comment(id='k6udvhm'), Comment(id='k6v5hb3'), Comment(id='k6tmsf5'), Comment(id='k6v15nt'), Comment(id='k6ttp6d'), Comment(id='k6wqsyw'), Comment(id='k6z47lt'), Comment(id='k6utmkq'), Comment(id='k6u3uqu'), Comment(id='k6ugr6s'), Comment(id='k6u1ror'), Comment(id='k6vco3l'), Comment(id='k6u14k8'), Comment(id='k6u3dmt'), Comment(id='k6tzeu1'), Comment(id='k6w08u8'), Comment(id='k6w3t8d'), Comment(id='k6xbofk'), Comment(id='k6zvfr6'), Comment(id='k6wg0vf'), Comment(id='k6ua0tw'), Comment(id='k6trkha'), Comment(id='k6u4qch'), Comment(id='k6todyc'), Comment(id='k6u7y9n'), Comment(id='k6tt5om'), Comment(id='k6u5u5h'), Comment(id='k6tu02d'), Comment(id='k6tt1fv'), Comment(id='k6tvjzx'), Comment(id='k742wra'), Comment(id='k6tn6a1'), Comment(id='k6woqbq'), Comment(id='k6u4rik'), Comment(id='k6u6i00'), Comment(id='k6u5dpg'), Comment(id='k6ur3lt'), Comment(id='k6vrm81'), Comment(id='k6yz7dg'), Comment(id='k6uijr6'), Comment(id='k6uie27'), Comment(id='k6z06ka'), Comment(id='k6toi2p'), Comment(id='k6truz0'), Comment(id='k6z6iu9'), Comment(id='k6uedjv'), Comment(id='k6u4jjc'), Comment(id='k71mxsv'), Comment(id='k6zyjyg'), Comment(id='k6y3csp'), Comment(id='k6zzwm9'), Comment(id='k6ubbxz'), Comment(id='k6uh2gd'), Comment(id='k6u50ib'), Comment(id='k6u99wf'), Comment(id='k6uowyp'), Comment(id='k6u1692'), Comment(id='k6uctc4'), Comment(id='k6uqqco'), Comment(id='k74qw8j'), Comment(id='k6uboss'), Comment(id='k6u6oci'), Comment(id='k6ue1ia'), Comment(id='k6ujsoh'), Comment(id='k6tv9ke'), Comment(id='k6v8ws6'), Comment(id='k6uebbz'), Comment(id='k6uor85'), Comment(id='k6ulcxc'), Comment(id='k6ueqm7'), Comment(id='k6up3zu'), Comment(id='k6uqjpi'), Comment(id='k6usrix'), Comment(id='k6ujins'), Comment(id='k6u6ytn'), Comment(id='k6u8cmv'), Comment(id='k6uhow4'), Comment(id='k6ujn68'), Comment(id='k77x36u'), Comment(id='k6uqa8h'), Comment(id='k6uodnc'), Comment(id='k6u9mlf'), Comment(id='k6uohl1'), Comment(id='k6vb6fc'), Comment(id='k6uooyn'), Comment(id='k6ur10x'), Comment(id='k6vl86y'), Comment(id='k6uv3iu')]"
17isfkx,evavibes,,2023-10-29 01:39:34+00:00,False,,False,False,True,False,/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,How’s the DA job market looking for people with experience?,"I’ve started applying around for data analyst roles this week and was wondering how people with 1-3 years experience are doing with their job searches

Asking since most posts on here are either like “no experience how do I break in” posts or like PhD data scientists with not much in between",datascience,https://www.reddit.com/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,33,27,0.83,"[Comment(id='k6wplfc'), Comment(id='k6x0s5r'), Comment(id='k6wufpg'), Comment(id='k6wglz3'), Comment(id='k6yea0l'), Comment(id='k6yjw55'), Comment(id='k7f152g'), Comment(id='k6wvo7o'), Comment(id='k6wovgd'), Comment(id='k6xstyt'), Comment(id='k6y28gh'), Comment(id='k6zno3b'), Comment(id='k70jx8g'), Comment(id='k6wukfz'), Comment(id='k715kb8'), Comment(id='k6x80mc'), Comment(id='k711jsk'), Comment(id='k7c8l9i'), Comment(id='k6yb635'), Comment(id='k6wqjv8'), Comment(id='k6wvhgy'), Comment(id='k6x3yqs'), Comment(id='k6wj4ej'), Comment(id='k6wqpb1'), Comment(id='k715o0v'), Comment(id='k6yfk62'), Comment(id='k6wzzcv'), Comment(id='k6yxbl9'), Comment(id='k6wmsun'), Comment(id='k6wwcq7'), Comment(id='k73pxl6'), Comment(id='k6wng6s'), Comment(id='k6wos5k')]"
17ih595,Yourteararedelicious,,2023-10-28 16:16:49+00:00,False,,1698511649.0,False,True,False,/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,"What would you classify my job as? DS, DA, DE, Glorified Excel Monkey","Officially I am a Data Scientist. I try to understand my value or worth outside of the government.

What I don't do:
AI, ML, modeling. 

What I do:
Develop new data pipelines,
Data exploration,
Produce data and dashboards from policy and new concepts,
Python, R, SQL, Databricks.


I feel a DS should be doing ML at minimum but our business needs are fast and dirty and the data is dirty. Dirty data = Dirty results is how I view ML stuff.

Edit: Punctuation because I forgot about Reddits mobile formats lol",datascience,https://www.reddit.com/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,69,85,0.9,"[Comment(id='k6u7zaa'), Comment(id='k6ujk6l'), Comment(id='k6u8sko'), Comment(id='k6ukucy'), Comment(id='k6ub0uc'), Comment(id='k6uxws5'), Comment(id='k6urkv5'), Comment(id='k6w13hv'), Comment(id='k6u9odn'), Comment(id='k6ulfc8'), Comment(id='k6uvu7z'), Comment(id='k6v65yo'), Comment(id='k72937l'), Comment(id='k6uq4dr'), Comment(id='k6vo9cz'), Comment(id='k6u7wya'), Comment(id='k6v87hp'), Comment(id='k6ux713'), Comment(id='k6vaeip'), Comment(id='k6vykqn'), Comment(id='k6yj8pu'), Comment(id='k6xcmwm'), Comment(id='k6xq06c'), Comment(id='k6xxnn1'), Comment(id='k7196vl'), Comment(id='k731soy'), Comment(id='k73dg10'), Comment(id='k775ch1'), Comment(id='k79rq1y'), Comment(id='k7c94i2'), Comment(id='k7sob10'), Comment(id='k6uja8w'), Comment(id='k6uyfl0'), Comment(id='k6wx34m'), Comment(id='k781e82'), Comment(id='k6uad5g'), Comment(id='k6votjs'), Comment(id='k6v96ia'), Comment(id='k70ax2i'), Comment(id='k6wbp0l'), Comment(id='k6un220'), Comment(id='k6ue14p'), Comment(id='k71gkc3'), Comment(id='k6uz8zk'), Comment(id='k6wlbg5'), Comment(id='k6uzl57'), Comment(id='k6va4fa'), Comment(id='k6uba6j'), Comment(id='k6wltk1'), Comment(id='k6uye0q'), Comment(id='k6vexql'), Comment(id='k6x6nvz'), Comment(id='k6vd9a8'), Comment(id='k73ib48'), Comment(id='k73dtt0'), Comment(id='k794ego'), Comment(id='k71hd32'), Comment(id='k6v1ywn'), Comment(id='k6vdkyx'), Comment(id='k6vv96v'), Comment(id='k71jott'), Comment(id='k6v8u4y'), Comment(id='k6vf4an'), Comment(id='k6vvgtb'), Comment(id='k6xojep'), Comment(id='k71kfkk'), Comment(id='k6vosd3'), Comment(id='k6w1u9y'), Comment(id='k6w71hs')]"
17ivru4,shar72944,,2023-10-29 05:04:29+00:00,False,,False,False,True,False,/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,Taking over new role as DS manager,"Not sure if the topic is allowed, but I would like to take opinions from senior data scientists and Analytics managers.

I work in finance as data scientist and work involves preparing data in required format,
Doing analysis and building models for products that we have in market , like propensity models for credit cards , credit risk models etc. 
I have worked as an individual contributor till now and have 5 years of experience. I have never managed anyone but have mentored and led few projects individually. 
I have a new offer for an analytics manager with a well known bank and I'll have to manage 6-7 data analysts/scientists and be responsible for the team’s performance. 

The pay jump is decent (40 percent higher than I currently make) and location is much closer to my home.
I don't have any problems with my current job and people I work with are also great. 

I was thinking if anyone else made that jump. 
Is the transition too steep from not managing anyone to 6-7 people?",datascience,https://www.reddit.com/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,13,8,0.83,"[Comment(id='k6x773o'), Comment(id='k6xey7d'), Comment(id='k6y0k4p'), Comment(id='k6z9f9t'), Comment(id='k70glpl'), Comment(id='k6yn8lm'), Comment(id='k71kk5v'), Comment(id='k6xf8zq'), Comment(id='k6xf3k9'), Comment(id='k6y1wes'), Comment(id='k6y249o'), Comment(id='k6zmh9j'), Comment(id='k73s2ig')]"
17ixgz7,charlesowo445,,2023-10-29 07:10:28+00:00,False,,False,False,True,False,/r/datascience/comments/17ixgz7/guesstimates/,Guesstimates,"Is there any book , podcast y'all can recommend  to study guesstimatation problem",datascience,https://www.reddit.com/r/datascience/comments/17ixgz7/guesstimates/,3,2,0.67,"[Comment(id='k6xhkgn'), Comment(id='k70iv0a'), Comment(id='k70song')]"
17huxxq,Vanishing-Rabbit,,2023-10-27 19:07:12+00:00,False,,False,False,True,False,/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,Didn't realize how insane the market is,"I work at FAANG as a DS manager. Opened up a Data Science position. Less than 24 hours later there were 1000+ applicants. 

I advertised the position on LinkedIn 

It's absolutely crazy. People have managed to get a hold of my personal and professional email address (I don't have these as public but they're a logical combination of first/last name).

I hired in the past, I have never seen anything like this.",datascience,https://www.reddit.com/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,239,706,0.96,"[Comment(id='k6q3ktn'), Comment(id='k6q1hi8'), Comment(id='k6pzvmt'), Comment(id='k6q3cgt'), Comment(id='k6q261o'), Comment(id='k6q5klj'), Comment(id='k6q04he'), Comment(id='k6q3v7d'), Comment(id='k6q9ttx'), Comment(id='k6q9vt4'), Comment(id='k6qjl2a'), Comment(id='k6q8qla'), Comment(id='k6qrpyb'), Comment(id='k6q3wb0'), Comment(id='k6q1ct8'), Comment(id='k6rcow8'), Comment(id='k6q2slq'), Comment(id='k6q5uth'), Comment(id='k6qhp5u'), Comment(id='k6q6uce'), Comment(id='k6spvbb'), Comment(id='k6qukmj'), Comment(id='k6q7e3e'), Comment(id='k6qmq0q'), Comment(id='k6qrhzm'), Comment(id='k6qwojb'), Comment(id='k6r72zf'), Comment(id='k6syi1t'), Comment(id='k6ueupk'), Comment(id='k6v1m02'), Comment(id='k6zp2r6'), Comment(id='k6r8l7i'), Comment(id='k6s9c03'), Comment(id='k6q62bp'), Comment(id='k6q6dup'), Comment(id='k6q9uqz'), Comment(id='k6qdbgu'), Comment(id='k6qniu3'), Comment(id='k6qr0kl'), Comment(id='k6rb63e'), Comment(id='k6rf75j'), Comment(id='k6rg5ql'), Comment(id='k6rm2o6'), Comment(id='k6rnaqr'), Comment(id='k6rnmx9'), Comment(id='k6s3o86'), Comment(id='k6s4oy8'), Comment(id='k6sdnw8'), Comment(id='k6sgl5n'), Comment(id='k6sn5ud'), Comment(id='k6sv0zl'), Comment(id='k6t0tn1'), Comment(id='k6t4h4h'), Comment(id='k6t73n8'), Comment(id='k6tc39c'), Comment(id='k6ton3t'), Comment(id='k6u8cdz'), Comment(id='k6u8pyq'), Comment(id='k6v5ec7'), Comment(id='k6v81vc'), Comment(id='k6vbrhr'), Comment(id='k6xk87y'), Comment(id='k6xso7r'), Comment(id='k6y7wps'), Comment(id='k6yjazr'), Comment(id='k70axkp'), Comment(id='k73wvsv'), Comment(id='k79173x'), Comment(id='k79x0uw'), Comment(id='k7c7rb7'), Comment(id='k7dgfed'), Comment(id='k7dj23f'), Comment(id='k7ezdjf'), Comment(id='k7smxup'), Comment(id='k6qq8a1'), Comment(id='k6q7xeu'), Comment(id='k6qmbme'), Comment(id='k6rhzg4'), Comment(id='k6qu8ul'), Comment(id='k6ryncv'), Comment(id='k6w4gpi'), Comment(id='k6t6p98'), Comment(id='k6wc0bt'), Comment(id='k6zkoto'), Comment(id='k6rf5t3'), Comment(id='k6qq1pg'), Comment(id='k6q64jj'), Comment(id='k6qjtnk'), Comment(id='k6rmqeg'), Comment(id='k6v4w6r'), Comment(id='k6q9jvv'), Comment(id='k6q9wv9'), Comment(id='k6qfub7'), Comment(id='k6q6msi'), Comment(id='k6qgsi5'), Comment(id='k6r64rm'), Comment(id='k6rjrek'), Comment(id='k6rs6bc'), Comment(id='k6qqmtg'), Comment(id='k6q3fov'), Comment(id='k6q85za'), Comment(id='k6qqedz'), Comment(id='k6qg7c6'), Comment(id='k6qh47g'), Comment(id='k6r6p8g'), Comment(id='k6sbbaq'), Comment(id='k6w3u5i'), Comment(id='k6qsmlo'), Comment(id='k6sr0sk'), Comment(id='k6styxx'), Comment(id='k6rfbrt'), Comment(id='k6s9o89'), Comment(id='k6t53gb'), Comment(id='k6qrk75'), Comment(id='k6sbts2'), Comment(id='k6qaypi'), Comment(id='k6qfv66'), Comment(id='k6rfh3p'), Comment(id='k6sbo83'), Comment(id='k6t7vu6'), Comment(id='k6vabl0'), Comment(id='k6sbvym'), Comment(id='k6tz0r7'), Comment(id='k6tl9vs'), Comment(id='k6ti3kw'), Comment(id='k6wc2yq'), Comment(id='k6sii1i'), Comment(id='k6qcit1'), Comment(id='k6qnjpz'), Comment(id='k6qzlwa'), Comment(id='k71pd4h'), Comment(id='k6qaa30'), Comment(id='k6sm12z'), Comment(id='k75oxkm'), Comment(id='k6s3f7o'), Comment(id='k6srf2c'), Comment(id='k6qufr6'), Comment(id='k6t0otl'), Comment(id='k6t6y2o'), Comment(id='k6rx26v'), Comment(id='k6qqcbk'), Comment(id='k6r1vtk'), Comment(id='k6qb4uj'), Comment(id='k6twx5q'), Comment(id='k6qctzq'), Comment(id='k6qd2s7'), Comment(id='k6st9ht'), Comment(id='k6qm30w'), Comment(id='k6qn07z'), Comment(id='k6teg6g'), Comment(id='k6q6128'), Comment(id='k6q8xt4'), Comment(id='k75ssb9'), Comment(id='k6qtvex'), Comment(id='k6tl1do'), Comment(id='k6srakx'), Comment(id='k6t1bm4'), Comment(id='k6ux74n'), Comment(id='k6sc2z3'), Comment(id='k6qhnky'), Comment(id='k6qfgpg'), Comment(id='k6qdbcr'), Comment(id='k6se71j'), Comment(id='k6tlpat'), Comment(id='k6t7xkc'), Comment(id='k6tzk6w'), Comment(id='k73w1kr'), Comment(id='k75sxo4'), Comment(id='k6t3v74'), Comment(id='k6qjsbq'), Comment(id='k6r5txy'), Comment(id='k70sdv1'), Comment(id='k6to8ig'), Comment(id='k75qdig'), Comment(id='k6w4n2m'), Comment(id='k6qqppf'), Comment(id='k6ujyfs'), Comment(id='k6savox'), Comment(id='k6uvpt9'), Comment(id='k71afe1'), Comment(id='k6qfe65'), Comment(id='k6sxrnn'), Comment(id='k6rci8z'), Comment(id='k6r6fd4'), Comment(id='k6qmms7'), Comment(id='k6q97f4'), Comment(id='k6qi19x'), Comment(id='k6qusx8'), Comment(id='k6vbje7'), Comment(id='k6sc7yi'), Comment(id='k6qi8p9'), Comment(id='k6qg87n'), Comment(id='k6w34d4'), Comment(id='k6t9r3h'), Comment(id='k791gl8'), Comment(id='k6qlilb'), Comment(id='k6t44li'), Comment(id='k6uuca6'), Comment(id='k719cpx'), Comment(id='k6ttrv4'), Comment(id='k75yuug'), Comment(id='k6qt2u5'), Comment(id='k6ulz81'), Comment(id='k6sq9zw'), Comment(id='k6qshn9'), Comment(id='k6qlp8t'), Comment(id='k6qozd4'), Comment(id='k6qhbwc'), Comment(id='k6ri0f9'), Comment(id='k6rij0y'), Comment(id='k6qudwc'), Comment(id='k6qkb0p'), Comment(id='k6scequ'), Comment(id='k6qr7hw'), Comment(id='k75rqdi'), Comment(id='k6qvdxt'), Comment(id='k6vrrr8'), Comment(id='k6troeo'), Comment(id='k6tvc2s'), Comment(id='k767jax'), Comment(id='k6uowaj'), Comment(id='k6si68m'), Comment(id='k6spp76'), Comment(id='k6rjgr9'), Comment(id='k6vz533'), Comment(id='k6scmlz'), Comment(id='k6qwl4m'), Comment(id='k6vw17b'), Comment(id='k6tx4c8'), Comment(id='k6v57k1'), Comment(id='k6wzqhc'), Comment(id='k6scrwv'), Comment(id='k6vb7rk'), Comment(id='k6xom5k'), Comment(id='k6u1p1j'), Comment(id='k6v7u6z'), Comment(id='k6z86by'), Comment(id='k6sdea4'), Comment(id='k6z1mmt'), Comment(id='k6zinpl'), Comment(id='k6sdjdf'), Comment(id='k70lpaz')]"
17ih45v,stryder517,,2023-10-28 16:15:17+00:00,False,,False,False,True,False,/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,Learning resources for a new DS manager?,"**Tl;dr -** Soon to be transferring over to a DS manager role from an analytics manager, and I do NOT want to be *that* leader. What are some recommended MOOCs, videos, books that can boost my technical knowledge over the next 2-3 months.

I have been on the analytics side for ~10 years, and have a strong foundation of SQL, python, data viz, and analysis, and a solid knowledge of math/stats (can still be improved). I’m lacking in the ML and deployment space, and have a couple months to study up here. Any strong recommendations of courses, videos, or problem sets to work through? (Books are also great, but I am painfully slow and may be more efficient with another medium). Thanks in advance.",datascience,https://www.reddit.com/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,5,5,0.86,"[Comment(id='k6uh5tm'), Comment(id='k6zv740'), Comment(id='k7beqtc'), Comment(id='k6uksgl')]"
17imqvk,whispertoke,,2023-10-28 20:48:46+00:00,False,,False,False,True,False,/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,"D.S. / Analytics Directors, What Tools Do You Use to Organize Your Work & Knowledge?",Curious what people are using to keep track of projects and general data/process documentation,datascience,https://www.reddit.com/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,11,2,0.62,"[Comment(id='k6vpxvu'), Comment(id='k6wcdya'), Comment(id='k6vdak5'), Comment(id='k6wl783'), Comment(id='k6ztazx'), Comment(id='k6ztxe0'), Comment(id='k6wwnn0'), Comment(id='k6zurbs'), Comment(id='k6ztidp'), Comment(id='k6xxf8s'), Comment(id='k6zue1d')]"
17i4ikr,Frosty_Pitch9052,,2023-10-28 02:58:39+00:00,False,,False,False,True,False,/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,When do you select features to use for your model?,"My issue is about doing EDA before or after feature selection. For example. say I have a dataset with tons and tons of features. Am I expected to analyze each and every feature in the dataset before choosing features or can I choose features that ""may"" matter based on logic and examine them there?",datascience,https://www.reddit.com/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,22,11,0.83,"[Comment(id='k6rtysn'), Comment(id='k6s99xh'), Comment(id='k6tkllz'), Comment(id='k6u9blb'), Comment(id='k6sw0r1'), Comment(id='k6tlga7'), Comment(id='k6uk08q'), Comment(id='k6v2bj9'), Comment(id='k6sg6nl'), Comment(id='k6stqhr'), Comment(id='k6wcp8a'), Comment(id='k7b4a9e'), Comment(id='k6yjxhy'), Comment(id='k6tnytw'), Comment(id='k6tpxiu'), Comment(id='k6tyvfd'), Comment(id='k6twnca'), Comment(id='k6ui59r'), Comment(id='k6uc2cw'), Comment(id='k6whxro'), Comment(id='k6ym0f7'), Comment(id='k76puaj')]"
17htzx6,tinkerpal,,2023-10-27 18:24:06+00:00,False,,1698431669.0,False,True,False,/r/datascience/comments/17htzx6/what_skills_should_data_scientist_with_1_yoe_is/,What skills should Data Scientist with 1 YOE is expected to know?,"I have completed over one year at my company as a Data Scientist. As a data scientist with master’s degree( in electrical and computer engineering) and 1 YOE, I was thinking about my career progress and was wondering if  my learning curve is good or bad. 

My experience so far at my company has been

 - developing a ML model( text classification model ) 
- lot of data manipulation and exploratory data analysis using sql , python and excel 
- using visualization tools like tableau 
- working with clustering algos and neural networks ( these models are existing and I haven’t developed).

But I don’t know model deployment, automation, parallelization and a lot more.

From the conversations in my team, I really feel overwhelmed by the amount of expertise and inputs they have and I do think it is with experience. But sometimes I wonder if I’m just underprepared and I have to improve but don’t know what resources to look at since from the experience I had so far, the code structure and everything is different. 

What was your experience ? Any tips and resources anyone can guide to?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17htzx6/what_skills_should_data_scientist_with_1_yoe_is/,12,32,0.85,"[Comment(id='k6q2oqh'), Comment(id='k6rovhz'), Comment(id='k6r3fev'), Comment(id='k6pykon'), Comment(id='k6sx9i4'), Comment(id='k6qza91'), Comment(id='k6q9w5g'), Comment(id='k6q5k38'), Comment(id='k6ycmmv'), Comment(id='k6yjcwm'), Comment(id='k6sw4mf'), Comment(id='k6rmdnz')]"
17hlvki,No_Constant8367,,2023-10-27 11:56:21+00:00,False,,False,False,True,False,/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,How to get better at PowerPoint?,"Unfortunately I have realised that at most jobs 80 percent of my time is spent on Ppt and 5 percent on the actual analysis. I was working in consulting and the best associates were the ones who could make the best presentations. Even at McKinsey, Bain etc my friends seem to mostly involved in making decks all day long. How do I get better at ppt? 
I used to feel that ppt would get redundant and hence didn’t really focus on it. Is it worth it to devote time in learning how to make beautiful ppts or is it a dying software and even investment banking and consulting will shift to something more sane/ AI will make it easy to make excellent ppts?",datascience,https://www.reddit.com/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,41,40,0.83,"[Comment(id='k6o75ab'), Comment(id='k6o9aao'), Comment(id='k6oj7nc'), Comment(id='k6pomni'), Comment(id='k6oh4q4'), Comment(id='k6oi10t'), Comment(id='k6qx6dt'), Comment(id='k6ogtlz'), Comment(id='k6o76in'), Comment(id='k6p73j2'), Comment(id='k6p9d24'), Comment(id='k6qjlg9'), Comment(id='k6rl2ya'), Comment(id='k6rq9me'), Comment(id='k6s1r0a'), Comment(id='k7sn5rw'), Comment(id='k6pcwkq'), Comment(id='k6pqluz'), Comment(id='k6ooxqz'), Comment(id='k6q95fd'), Comment(id='k6vqsdr'), Comment(id='k6zhf5c'), Comment(id='k6svo6b'), Comment(id='k701q41'), Comment(id='k6o8rol'), Comment(id='k6q1h44'), Comment(id='k6pi0gy'), Comment(id='k6pdiom'), Comment(id='k6peqpu'), Comment(id='k6s1ubr'), Comment(id='k6pxkge'), Comment(id='k6t80jl'), Comment(id='k705iim'), Comment(id='k73svd6'), Comment(id='k6ob94q'), Comment(id='k6ox3rx'), Comment(id='k6q51x2'), Comment(id='k6ptcsd'), Comment(id='k76vbhh'), Comment(id='k6onpd2'), Comment(id='k6pvsks')]"
17i2wn6,WadeEffingWilson,,2023-10-28 01:28:38+00:00,False,,False,False,True,False,/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,Has anyone successfully used Chernoff faces in any type of analysis (not including what they are and how they convey information)?,"I was reading through the supplemental material at the end of Blindsight and discovered that Chernoff faces are real. The in-story explanation that human brains are hardwired to read faces and the amount of information that can be encoded into them is suitable for higher dimensional (~18) data, especially given that the subconscious is more adept at processing complex problems than the conscious mind, is interesting enough of a concept, so discovering that it's real makes it even better.

I'm interested to see if they have been utilized before and if they still are in certain industries or niches (outside of customer satisfaction surveys and Wong-Baker scales). The fact that it can encode a high number of dimensions has piqued my interest to see if they can be used successfully and how difficult they are to interpret, for both analysts/statisticians and non-technical parties (stakeholders).",datascience,https://www.reddit.com/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,0,3,1.0,[]
17hicpp,NipponPanda,,2023-10-27 07:47:09+00:00,False,,False,False,True,False,/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,How much time do you guys spend in PowerPoint?,"I know this question might be a bit controversial to some but lately I've found myself spending an ungodly amount of time creating slides instead of doing other tasks.

Management wants each new project or idea laid out in meticolous detail in a PowerPoint before signing off on it and granting any type of access to data. Which means I need to create some really good looking PPT decks to even get the chance to explore our available data, it's quite frustrating and I'd rather spend the time doing something else.

By detail I mean like, budget, development timeline, target audience, documentation, blabla, before I even get a chance to look at the data and determine if it's useable in the first place.

Anyone else have this problem?",datascience,https://www.reddit.com/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,104,66,0.96,"[Comment(id='k6nl6gs'), Comment(id='k6npn85'), Comment(id='k6np1az'), Comment(id='k6nw2ak'), Comment(id='k6ns1gy'), Comment(id='k6o64pb'), Comment(id='k6nro8s'), Comment(id='k6o3uqf'), Comment(id='k6oxkas'), Comment(id='k6nnelj'), Comment(id='k6oedcj'), Comment(id='k6nqbu6'), Comment(id='k6nx3vc'), Comment(id='k6ofsf8'), Comment(id='k6ozcac'), Comment(id='k6pdxb5'), Comment(id='k6po7vh'), Comment(id='k6nk6v9'), Comment(id='k6o46i6'), Comment(id='k6nznly'), Comment(id='k6om7v4'), Comment(id='k6nxr6p'), Comment(id='k6o7kgd'), Comment(id='k6o83jg'), Comment(id='k6ocj8o'), Comment(id='k6ofa9n'), Comment(id='k6ofxef'), Comment(id='k6oh88w'), Comment(id='k6onr55'), Comment(id='k6ooyvr'), Comment(id='k6osddd'), Comment(id='k6our5j'), Comment(id='k6owl2g'), Comment(id='k6oysyd'), Comment(id='k6p47hi'), Comment(id='k6p805b'), Comment(id='k6p886t'), Comment(id='k6pcgn6'), Comment(id='k6pzhzc'), Comment(id='k6q0xis'), Comment(id='k6qtgd1'), Comment(id='k6rjv82'), Comment(id='k6sicv1'), Comment(id='k6yjelg'), Comment(id='k725b6v'), Comment(id='k731wji'), Comment(id='k73x9lq'), Comment(id='k7dglre'), Comment(id='k7ey00p'), Comment(id='k6nqf5g'), Comment(id='k6nsmne'), Comment(id='k6ppwxl'), Comment(id='k6ongwf'), Comment(id='k6pq1ro'), Comment(id='k6orthz'), Comment(id='k6olxqi'), Comment(id='k6omid1'), Comment(id='k6p6k8l'), Comment(id='k6q8imx'), Comment(id='k6nktny'), Comment(id='k6nlol2'), Comment(id='k6o0uep'), Comment(id='k6omcqo'), Comment(id='k6q790t'), Comment(id='k6oc2z5'), Comment(id='k6on583'), Comment(id='k6q6kcp'), Comment(id='k6oeget'), Comment(id='k6oqbea'), Comment(id='k6oe2dn'), Comment(id='k6ntimt'), Comment(id='k6rbpt9'), Comment(id='k6onttu'), Comment(id='k6pcbs4'), Comment(id='k6p6b91'), Comment(id='k6q8b2z'), Comment(id='k6op3zz'), Comment(id='k6pzvc8'), Comment(id='k6qhmbj'), Comment(id='k6rjlkj'), Comment(id='k6q5gno'), Comment(id='k6rc08n'), Comment(id='k6qcyco'), Comment(id='k6ouedv'), Comment(id='k6q6f4v'), Comment(id='k6qzvpi'), Comment(id='k6qg0hr'), Comment(id='k6p03lr'), Comment(id='k6r9wbg'), Comment(id='k6qig4a'), Comment(id='k6p4urz'), Comment(id='k6phi48'), Comment(id='k6qjsai'), Comment(id='k6q60pe'), Comment(id='k6qkv98'), Comment(id='k6qmrhs'), Comment(id='k6qox54'), <MoreComments count=0, children=[]>]"
17hvuft,Renatus_Cartesius,,2023-10-27 19:49:10+00:00,False,,False,False,True,False,/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,Good book on Bayesian statistics?,"From the perspective of someone who has absorbed the frequentist approach pretty well, and is comfortable with it, could you recommend a good book on Bayesian statistics?

Ideally with a focus on A/B testing.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,19,6,0.8,"[Comment(id='k6q7dgv'), Comment(id='k6qacqo'), Comment(id='k6qgme5'), Comment(id='k6xd10s'), Comment(id='k6rgmnd'), Comment(id='k6v2tmb'), Comment(id='k6z7fhr'), Comment(id='k731ywo'), Comment(id='k73204n'), Comment(id='k73ya9a'), Comment(id='k7bu9hf'), Comment(id='k76q0k2'), Comment(id='k6ukelw'), Comment(id='k7a4bni'), Comment(id='k6v9uu8'), Comment(id='k77dnb5'), Comment(id='k7ab5fg'), Comment(id='k7agr5i')]"
17h9xpo,Accurate_Green_7001,,2023-10-26 23:32:34+00:00,False,,False,False,True,False,/r/datascience/comments/17h9xpo/what_is_considered_a_highvalue_data_scientist_and/,"What is considered a ""high-value"" data scientist and how do you become one?","I'm a data scientist with a 2 years of experience. I've realised recently that all of my projects in industry follow the same basic blueprint which I learnt years ago:

1. Think of how to best frame the problem so it can be solved using data science.
2. Clean and process the data.
3. Extract features which give the highest accuracy
4. Sticking it into an sklearn algorithm and hoping it has good accuracy (or whatever metric is important for that specific problem).
5. If it has bad accuracy, redo step 3 or get more data. If it has good metrics, done.

My issue is: anyone who has done a data science boot camp can easily reproduce these steps. Coding in R and Python is super easy, especially nowadays with libraries like sklearn.

* Is a data scientist considered ""high-value"" because of step 1? Or is it the fact that they have lots of ideas about how something can be modelled which goes beyond the ""traditional"" models? 
* If it is the latter, is the only way to create more complex models to just gain more experience with a variety of problems, and coming across new techniques whilst researching? I find that I don't even know about the existence of many techniques unless it's pointed out to me by colleagues.

By ""complex"" model. I don't mean complicating the algorithm a model uses for the sake of it. I'm referring to a more robust model that takes more variables into account.

As data scientists get more experienced, in which ways can they provide more value to a business compared to say, an intern, who could probably do all the steps listed above relatively easily?",datascience,https://www.reddit.com/r/datascience/comments/17h9xpo/what_is_considered_a_highvalue_data_scientist_and/,96,242,0.95,"[Comment(id='k6mlkhv'), Comment(id='k6mj9uh'), Comment(id='k6n3yyg'), Comment(id='k6m0745'), Comment(id='k6mycrr'), Comment(id='k6n3grn'), Comment(id='k6mcbce'), Comment(id='k6moam1'), Comment(id='k6ngrwv'), Comment(id='k6mrk3h'), Comment(id='k6n23sz'), Comment(id='k6n2atc'), Comment(id='k6o0alh'), Comment(id='k6m18y4'), Comment(id='k6mke2m'), Comment(id='k6moij5'), Comment(id='k6m3x8t'), Comment(id='k6nfkio'), Comment(id='k6o30hn'), Comment(id='k6oi5k3'), Comment(id='k6oug3l'), Comment(id='k6mdafu'), Comment(id='k6m7usb'), Comment(id='k6mvtjl'), Comment(id='k6ng0rp'), Comment(id='k6mdmx5'), Comment(id='k6mlbbx'), Comment(id='k6mps7m'), Comment(id='k6nawrr'), Comment(id='k6o2i4s'), Comment(id='k6o8tm2'), Comment(id='k6omhy4'), Comment(id='k6ot8zt'), Comment(id='k6p831p'), Comment(id='k6pbhhx'), Comment(id='k6pir9f'), Comment(id='k6pwt0q'), Comment(id='k6px772'), Comment(id='k6qclf5'), Comment(id='k6qh79w'), Comment(id='k6qhl1u'), Comment(id='k6v2wl4'), Comment(id='k7h5fsd'), Comment(id='k6nfvxj'), Comment(id='k6otaa6'), Comment(id='k6mqeqd'), Comment(id='k6obrft'), Comment(id='k6op9mi'), Comment(id='k6r5i8m'), Comment(id='k6n1172'), Comment(id='k6nvsmo'), Comment(id='k6mm4av'), Comment(id='k6odfyk'), Comment(id='k6pwhlx'), Comment(id='k6odp2v'), Comment(id='k6p7hjh'), Comment(id='k6rexpb'), Comment(id='k6m0tgs'), Comment(id='k6mjjg5'), Comment(id='k6n939g'), Comment(id='k6o4npa'), Comment(id='k6n8p4z'), Comment(id='k6n4bsc'), Comment(id='k6n9szc'), Comment(id='k6mzdwf'), Comment(id='k6rfhdt'), Comment(id='k6n2bvw'), Comment(id='k6p725r'), Comment(id='k6olto3'), Comment(id='k6mz4zl'), Comment(id='k6m7xrv'), Comment(id='k6mvxx5'), Comment(id='k6o2kk1'), Comment(id='k6ofjxe'), Comment(id='k6otomw'), Comment(id='k6n395u'), Comment(id='k6plkuj'), Comment(id='k6mocsv'), Comment(id='k6nc131'), Comment(id='k6p8385'), Comment(id='k6qg06c'), Comment(id='k6qeecs'), Comment(id='k6qffgl'), Comment(id='k6sf7j1'), Comment(id='k6nt8uu'), Comment(id='k6pccrq'), Comment(id='k6mdqsh'), Comment(id='k6p0iap'), Comment(id='k6oh1em'), Comment(id='k6ouyw7'), Comment(id='k6ocyef'), Comment(id='k6riy2u'), Comment(id='k6pqctj'), Comment(id='k6pd37a'), Comment(id='k70o4ef'), Comment(id='k6ntn4v')]"
17hwt1l,Judessaa,,2023-10-27 20:33:27+00:00,False,,False,False,True,False,/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,What are your duties as a Data Scientist?,"Please elaborate on this. 

Including your role at the company, your day to day tasks, tools and languages you’re using. 

Thank you in advance!",datascience,https://www.reddit.com/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,6,4,0.63,"[Comment(id='k6qldnw'), Comment(id='k6qkq30'), Comment(id='k6s734j'), Comment(id='k6s749j'), Comment(id='k6s98v7'), Comment(id='k6tdmhl')]"
17hy5hl,Fine_Night_,,2023-10-27 21:34:52+00:00,False,,False,False,True,False,/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,Been put to investigate bugs for new project but no prior exp,"Hi there!

I’m working as a Data Analyst in my company and in my team we mostly use SQL and Tableau. I’ve mostly just used these two and Python (via Jupyter notebooks) on occasion to perform data cleaning /transformation for adhoc data sets.

So recently been covering for some other employee and have seemingly gotten myself into potentially being the one having to fix some potential bugs in a ML based Flask application that predicts product prices based on different conditions.

This is made up of 3 GitHub repos:
The model, the data pipelines and a Jupyter notebook containing code related to KMeans.


The data pipeline and model repos contain lots of Python source files with around 1000-1500 lines per file. All in all there could be easily more than 20,000 lines of code. I know this is not a lot but I don’t have experience in dealing with such large code bases.


I don’t have background in ML or product development (I previously worked as a IT BA 2-3 years back before transitioning to a DA role after having used SQL/Tableau for a few years, there is a separate BI team in the company but I’m in a data analyst specific team). 

My question is would it be common for DAs to be called to debug large complex ML web apps? I haven’t seen this in other companies previously. I would have thought this would fall on the product development teams or ML Engineers etc.

And what is the best way for me to start off getting used to the code base and understanding what everything does? The project certainly looks interesting and would make a good entry for me to a ML engineer role in the future or product development role but I’m nervous especially since my probation is ending in 2 weeks and I really don’t wanna f up. There’s no documentation or requirements documented except for a high level architecture diagram of the system.

Looking for advice thanks!



TL:DR;
A data analyst with no experience in product development put in charge to fix bugs for a large ML web app, looking for tips on how best to understand the code base and perform testing especially when there’s no documentation available for this app besides a high level architecture diagram. Also, wondering if it’s common for a data analysts to be asked to debug large ML web applications (flask based).",datascience,https://www.reddit.com/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,10,3,1.0,"[Comment(id='k6qt6j8'), Comment(id='k6t15ps'), Comment(id='k6rd56q'), Comment(id='k6t2ou7'), Comment(id='k6rt88u'), Comment(id='k6swcjx'), Comment(id='k6sxyd1'), Comment(id='k6t2x3t'), Comment(id='k6t8yuc'), Comment(id='k6tojyo')]"
17hj3ea,Slow_Act_4114,,2023-10-27 08:45:01+00:00,False,,False,False,True,False,/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,Usefulness of Six-Sigma,How useful would y'all rate a Six-Sigma certification?,datascience,https://www.reddit.com/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,49,31,0.85,"[Comment(id='k6o8iwn'), Comment(id='k6o2edv'), Comment(id='k6o9j4k'), Comment(id='k6owpmh'), Comment(id='k6og0s5'), Comment(id='k6ocofa'), Comment(id='k6ocugd'), Comment(id='k6np4n2'), Comment(id='k6on7cy'), Comment(id='k6pde3g'), Comment(id='k6oquz7'), Comment(id='k6p9kcs'), Comment(id='k6pxygt'), Comment(id='k6o6cmm'), Comment(id='k6or7l2'), Comment(id='k6p0stl'), Comment(id='k6npvvi'), Comment(id='k6oemqf'), Comment(id='k6omfwk'), Comment(id='k6ox5ku'), Comment(id='k6pduzf'), Comment(id='k6pmxek'), Comment(id='k6pwm72'), Comment(id='k6reyxd'), Comment(id='k6sxbgn'), Comment(id='k6tuyxr'), Comment(id='k6xgakh'), Comment(id='k6yjftz'), Comment(id='k7lo4hk'), Comment(id='k6ocqyh'), Comment(id='k6ol10f'), Comment(id='k6pqeyn'), Comment(id='k6pxyis'), Comment(id='k6sy9ih'), Comment(id='k6ocugb'), Comment(id='k6p51wf'), Comment(id='k6omb9v'), Comment(id='k6opo8r'), Comment(id='k6sq3xd'), Comment(id='k6q1zuq'), Comment(id='k6tzmmt'), Comment(id='k6oe8p2'), Comment(id='k6pdnp0'), Comment(id='k6ox38b'), Comment(id='k6q090p'), Comment(id='k6q5m7q'), Comment(id='k6oyjda'), Comment(id='k6q8za9'), Comment(id='k6pii8e')]"
17ht5l1,engkhaledeisa,,2023-10-27 17:46:33+00:00,False,,False,False,True,False,/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,Where I can find projects to contribute in?,"I took courses about pentaho,tableau and machine learning ...where I can find projects with open issues so I can solve it and increase my ability to solve problems in this career ..like open source android or web projects on github with open issues ....is there a specific website for data that I can contribute in and this contribution will have a positive effect in my c.v?",datascience,https://www.reddit.com/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,2,3,0.8,"[Comment(id='k6tbsd0'), Comment(id='k6x7s6p')]"
17h7eav,math_stat_gal,,2023-10-26 21:37:31+00:00,False,,False,False,True,False,/r/datascience/comments/17h7eav/finally/,Finally!,"Hey fellow data folks - Finally, after 17 months of applying for jobs, I’ve found one. The job title is strange, the pay is nothing to brag about (thanks Canada!) but I’m 100% certain of the positive impact it is going to have in my mental health. 

I’m so relieved and nervous and scared but also excited. 

It is tough out there but nothing else to be done other than try! 

Thanks for hearing me out.",datascience,https://www.reddit.com/r/datascience/comments/17h7eav/finally/,20,73,0.96,"[Comment(id='k6loeiy'), Comment(id='k6lloue'), Comment(id='k6mev5j'), Comment(id='k6po8j3'), Comment(id='k7bet1i'), Comment(id='k7exwzt'), Comment(id='k6nfzzu'), Comment(id='k7exw4y'), Comment(id='k6lo6n9'), Comment(id='k7f1r63'), Comment(id='k6lpmcp'), Comment(id='k6mzz2s'), Comment(id='k6lr5vn'), Comment(id='k6n0azt'), Comment(id='k6mjnyd'), Comment(id='k6mjxyd'), Comment(id='k6mla9g'), Comment(id='k6n3gvg'), Comment(id='k6n0hq0')]"
17h40ok,pg860,,2023-10-26 19:10:24+00:00,False,,1698394526.0,False,True,False,/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,Why Gradient Boosted Decision Trees are so underappreciated in the industry?,"GBDT allow you to iterate very fast, they require no data preprocessing, enable you to incorporate business heuristics directly as features, and immediately show if there is explanatory power in features in relation to the target.

On tabular data problems, they outperform Neural Networks, and many use cases in the industry have tabular datasets.

Because of those characteristics, [they are winning solutions to all tabular competitions on Kaggle](https://jobs-in-data.com/blog/data-science-skills#sota-ml-models).

And yet, somehow they are not very popular.

On the chart below, I summarized learnings from 9,261 job descriptions crawled from 1605 companies in Jun-Sep 2023 (source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist))

LGBM, XGboost, Catboost (combined together) are the 19th mentioned skill, e.g. with Tensorflow being x10 more popular.

It seems to me Neural Networks caught the attention of everyone, because of the deep-learning hype, which is justified for image, text, or speech data, but not justified for tabular data, which still represents many use - cases.

https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&format=png&auto=webp&s=b06cd263e22eb229a6be2df890faba7639d895d7

EDIT \[Answering the main lines of critique\]:

1/ ""Job posting descriptions are written by random people and hence meaningless"":

Granted, there is for sure some noise in the data generation process of writing job descriptions.

But why do those random people know so much more about deep learning, keras, tensorflow, pytorch than GBDT? In other words, why is there a systematic trend in the noise? When the noise has a trend, it ceases to be noise.

Very few people actually did try to answer this, and I am grateful to them, but none of the explanations seem to be more credible than the statement that GBDTs are indeed underappreciated in the industry.

2/ ""I myself use GBDT all the time so the headline is wrong""This is availability bias. The single person's opinion (or 20 people opinion) vs 10.000 data points.

3/ ""This is more the bias of the Academia""

The job postings are scraped from the industry.

However, I personally think this is the root cause of the phenomenon. Academia shapes the minds of industry practitioners. GBDTs are not interesting enough for Academia because they do not lead to AGI. Doesn't matter if they are super efficient and create lots of value in real life.",datascience,https://www.reddit.com/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,115,99,0.77,"[Comment(id='k6l0acr'), Comment(id='k6l7uca'), Comment(id='k6kwkht'), Comment(id='k6ljk8t'), Comment(id='k6l4w6b'), Comment(id='k6l0jx4'), Comment(id='k6lpo4e'), Comment(id='k6lll29'), Comment(id='k6l8g0e'), Comment(id='k6kzdjz'), Comment(id='k6llh98'), Comment(id='k6l6wl3'), Comment(id='k6lej19'), Comment(id='k6odiq6'), Comment(id='k6lco0z'), Comment(id='k6lsec8'), Comment(id='k6mh15t'), Comment(id='k6l9m2l'), Comment(id='k6m2dkd'), Comment(id='k6m2nck'), Comment(id='k6m5xhk'), Comment(id='k6nnh4q'), Comment(id='k6nxahn'), Comment(id='k6o4aws'), Comment(id='k6o70i5'), Comment(id='k6pdw8a'), Comment(id='k6q7slz'), Comment(id='k6r0kod'), Comment(id='k6redh8'), Comment(id='k6rezbe'), Comment(id='k6u93tz'), Comment(id='k6uyjj4'), Comment(id='k6ldzpo'), Comment(id='k6liat2'), Comment(id='k6lg5xv'), Comment(id='k6nylyr'), Comment(id='k6lgc6k'), Comment(id='k6maeib'), Comment(id='k6m98qq'), Comment(id='k6kxefo'), Comment(id='k6los02'), Comment(id='k6vmlrl'), Comment(id='k6li1cs'), Comment(id='k6l7flo'), Comment(id='k6luzdq'), Comment(id='k6llmdm'), Comment(id='k6l85tt'), Comment(id='k6lhuq1'), Comment(id='k6lqcoa'), Comment(id='k6lmq7w'), Comment(id='k6mrn1f'), Comment(id='k6rh14h'), Comment(id='k6l4upd'), Comment(id='k6l6cp3'), Comment(id='k6m17dz'), Comment(id='k6r2zgu'), Comment(id='k6l8jey'), Comment(id='k6lec1h'), Comment(id='k6lgh3i'), Comment(id='k6pwsh0'), Comment(id='k6lwfgf'), Comment(id='k6u0q4a'), Comment(id='k6m91kn'), Comment(id='k6lokm8'), Comment(id='k6ou0m5'), Comment(id='k6lqvhq'), Comment(id='k6ok4xg'), Comment(id='k6lz3wk'), Comment(id='k6n3mqo'), Comment(id='k6lfz7w'), Comment(id='k6mgxyj'), Comment(id='k6m1l1c'), Comment(id='k6lfbyr'), Comment(id='k6nx6wh'), Comment(id='k6llhuz'), Comment(id='k6lxwb6'), Comment(id='k6pxfso'), Comment(id='k6mg1zn'), Comment(id='k6mmkf9'), Comment(id='k6lp4kw'), Comment(id='k6lsuyc'), Comment(id='k6lzo49'), Comment(id='k6m00e7'), Comment(id='k6lh10g'), Comment(id='k6llr33'), Comment(id='k6ly2ni'), Comment(id='k6pzleh'), Comment(id='k6mgnbl'), Comment(id='k6lpowq'), Comment(id='k6m01pv'), Comment(id='k6lhw2v'), Comment(id='k6qyr3y'), Comment(id='k6lpwvl'), Comment(id='k6m06ri'), Comment(id='k6lize0'), Comment(id='k6lq76w'), Comment(id='k6ljn0h'), Comment(id='k6lqqnr'), Comment(id='k6lkb95'), Comment(id='k6ltijm'), Comment(id='k6lkpbm'), Comment(id='k6lxopx'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
17gyevz,Prestigious_Belt4965,,2023-10-26 14:57:39+00:00,False,,False,False,True,False,/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,"I'm a 'data analyst' who in practice is actually just a software engineer. Was I bamboozled, or did I misunderstand the role","my first job was as a consultant, doing a mix of implementation and data analytics. 

then i switched to a new job with the data analyst title, but I'm building production R scripts almost exclusively now; not a huge fan of wrangling with my team's complex/sparsely commented codebase and designing 'systems' (our scripts have to integrate with a variety of outside data sources).

I miss doing 'investigations', eg how do we better optimize this product, make more revenue, etc. now it feels like I'm an underpaid backend software engineer (making 85k but seems most SWEs are earning 100k+).

is data analytics in 2023 more similar to SWE? should I have expected this?",datascience,https://www.reddit.com/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,89,172,0.94,"[Comment(id='k6jrewc'), Comment(id='k6jovj7'), Comment(id='k6jstfs'), Comment(id='k6k169c'), Comment(id='k6jpjpo'), Comment(id='k6k7x9m'), Comment(id='k6k1jan'), Comment(id='k6jximi'), Comment(id='k6kr4w3'), Comment(id='k6k9z1r'), Comment(id='k6ki4cw'), Comment(id='k6keuuh'), Comment(id='k6k52rt'), Comment(id='k6l1w5n'), Comment(id='k6kb94r'), Comment(id='k6kdty9'), Comment(id='k6kdx4t'), Comment(id='k6kpbci'), Comment(id='k6kcy53'), Comment(id='k6jzl5w'), Comment(id='k6jx3d3'), Comment(id='k6kf6y2'), Comment(id='k6kb4k9'), Comment(id='k6km2pj'), Comment(id='k6kmjfq'), Comment(id='k6ktflm'), Comment(id='k6l0kyx'), Comment(id='k6lbkyb'), Comment(id='k6lc0yq'), Comment(id='k6ljs2k'), Comment(id='k6lqurr'), Comment(id='k6lqxvs'), Comment(id='k6lwdyn'), Comment(id='k6lzdzg'), Comment(id='k6m0puu'), Comment(id='k6m5hx5'), Comment(id='k6mqogz'), Comment(id='k6n6y4v'), Comment(id='k6noqka'), Comment(id='k733msb'), Comment(id='k78veze'), Comment(id='k6l0pd8'), Comment(id='k6nglpj'), Comment(id='k6n9j3o'), Comment(id='k6ki2dy'), Comment(id='k6k9get'), Comment(id='k6k5xwc'), Comment(id='k6khohz'), Comment(id='k7dew60'), Comment(id='k6kaa20'), Comment(id='k6l7s1x'), Comment(id='k6kch6l'), Comment(id='k6kbzx0'), Comment(id='k6nonhq'), Comment(id='k6ohjer'), Comment(id='k6kkotp'), Comment(id='k6ken5a'), Comment(id='k6kig5f'), Comment(id='k6k6lf7'), Comment(id='k6kiecf'), Comment(id='k6kcaib'), Comment(id='k6kmy5r'), Comment(id='k6lxwgx'), Comment(id='k6kgc5w'), Comment(id='k6kkzd6'), Comment(id='k6kltxx'), Comment(id='k6kjgwf'), Comment(id='k6kfmc0'), Comment(id='k6ke2hv'), Comment(id='k6kohfp'), Comment(id='k6l9ter'), Comment(id='k6koge2'), Comment(id='k6kocb6'), Comment(id='k6m0l9e'), Comment(id='k6kkhs3'), Comment(id='k6tmv7t'), Comment(id='k6kqsm2'), Comment(id='k6l14ei'), Comment(id='k6ltnad'), Comment(id='k6mkhqi'), Comment(id='k6m1fnf'), Comment(id='k6klspw'), Comment(id='k6kktbi'), Comment(id='k6uh9cv'), Comment(id='k6krw4h'), Comment(id='k6mrz3m'), Comment(id='k6kmgmv'), Comment(id='k6l7v09'), Comment(id='k6lbxjh'), Comment(id='k6lvvlz'), <MoreComments count=0, children=[]>]"
17gujdu,Maimonatorz,,2023-10-26 11:42:01+00:00,False,,False,False,True,False,/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,What are some good examples of catastrophic AI failures?,"I've recently did some searches about AI failures, the most catastrophic failure I read about was when [Zillow had to fire 2000 employees](https://www.geekwire.com/2021/zillow-shutter-home-buying-business-lay-off-2k-employees-big-real-estate-bet-falters/). 

I also saw some articles like this [one](https://www.science.org/doi/10.1126/science.aax2342), about biases in health algorithms, but all in all I didn't see much examples that had a measure of how much damage was actually done.

Are there more examples of AI failures on a large scale?",datascience,https://www.reddit.com/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,66,89,0.95,"[Comment(id='k6jguvn'), Comment(id='k6jvbmd'), Comment(id='k6jb394'), Comment(id='k6jnij4'), Comment(id='k6kgy1u'), Comment(id='k6j9oot'), Comment(id='k6jmyod'), Comment(id='k6jvtb1'), Comment(id='k6kldi6'), Comment(id='k6kdrig'), Comment(id='k6jwoye'), Comment(id='k6jdgtn'), Comment(id='k6koq2k'), Comment(id='k6l67de'), Comment(id='k6lujxx'), Comment(id='k6m4lxf'), Comment(id='k6mjs4n'), Comment(id='k6mxqz1'), Comment(id='k6my0u3'), Comment(id='k6jj1yk'), Comment(id='k6jxys8'), Comment(id='k6jkt4d'), Comment(id='k6lsrjj'), Comment(id='k6ne3hk'), Comment(id='k6l3z4k'), Comment(id='k6lbyib'), Comment(id='k6mff53'), Comment(id='k6mft4a'), Comment(id='k6ouvr4'), Comment(id='k6jkmfe'), Comment(id='k6llbrl'), Comment(id='k6lhdzw'), Comment(id='k6kb1wx'), Comment(id='k6lq5u5'), Comment(id='k6l49f6'), Comment(id='k6me8fx'), Comment(id='k6ntgxj'), Comment(id='k6jl481'), Comment(id='k6naxfy'), Comment(id='k6pkluv'), Comment(id='k6klgaa'), Comment(id='k6jp71y'), Comment(id='k6odhpd'), Comment(id='k6n1nzg'), Comment(id='k6p4riw'), Comment(id='k6jhsw5'), Comment(id='k6jmw0a'), Comment(id='k6l5asg'), Comment(id='k6jisvs'), Comment(id='k6m5521'), Comment(id='k6jmyfk'), Comment(id='k6l49ir'), Comment(id='k6k74u9'), Comment(id='k6jlonn'), Comment(id='k6n1995'), Comment(id='k6ljpni'), Comment(id='k6jmq54'), Comment(id='k6kq6cs'), Comment(id='k6k64ns'), Comment(id='k6jnj9v'), Comment(id='k6kacj0'), Comment(id='k6l2my0'), Comment(id='k6o3fn0'), Comment(id='k6jrbzn'), Comment(id='k6o2l87'), Comment(id='k6jxci3'), Comment(id='k6ltl4s')]"
17hh6i7,daftpunkapi,,2023-10-27 06:22:26+00:00,False,,False,False,True,False,/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,Streaming Data Observability & Quality,"We have been exploring the space of ""Streaming Data Observability & Quality"". We do have some thoughts and questions and would love to get members view on them. 

**Q1.** Many vendors are shifting left by moving data quality checks from the warehouse to Kafka / messaging systems. What are the benefits of shifting-left ?

**Q2.** Can you rank the feature set by importance (according to you) ? What other features would you like to see in a streaming data quality tool ?

* Broker observability & pipeline monitoring (events per second, consumer lag etc.)
* Schema checks and Dead Letter Queues (with replayability)
* Validation on data values (numeric distributions & profiling, volume, freshness, segmentation etc.)
* Stream lineage to perform RCA

**Q3.** Who would be an ideal candidate (industry, streaming scale, team size) where there is an urgent need to monitor, observe and validate data in streaming pipelines?  


https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&format=pjpg&auto=webp&s=c1b368112465cfa5be67258dd2a52313cdb4cdb6",datascience,https://www.reddit.com/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,0,2,0.75,[]
17hv82d,blacksnowboader,,2023-10-27 19:20:35+00:00,False,,False,False,True,False,/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,What is the worst case of PHDitis that you have seen?,Title,datascience,https://www.reddit.com/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,26,0,0.38,"[Comment(id='k6q1xjo'), Comment(id='k6r909p'), Comment(id='k6r9l0o'), Comment(id='k6qjjl9'), Comment(id='k6q2uu3'), Comment(id='k6uh36z'), Comment(id='k6qdbix'), Comment(id='k6qfokh'), Comment(id='k6qog98'), Comment(id='k6t4453'), Comment(id='k6tebbh'), Comment(id='k6rekrs'), Comment(id='k6qk564'), Comment(id='k6qqflx'), Comment(id='k757tme'), Comment(id='k6ulkjv'), Comment(id='k6qkazg'), Comment(id='k6qpj64'), Comment(id='k6uy462'), Comment(id='k6v2bmc'), Comment(id='k6qkhfw'), Comment(id='k6qkrxk'), Comment(id='k6r1cvx'), Comment(id='k6qqyii'), Comment(id='k6qlkej'), Comment(id='k6qmc79')]"
17h8k9y,exodusgg,,2023-10-26 22:28:41+00:00,False,,False,False,True,False,/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,Machine Learning projects on jupyter,"Hello everyone,

Im a recent Data Science graduate and experimenting with different machine learning models on a various datasets from kaggle. The idea is to be more comfortable with tensorflow (& other libaries) and different datasets. 

Im doing all this on jupyter notebook, is there a tool data scientist use to publish their work. I want to create a online portfolio which i can showcase the different ML implementations in interviews and to recruiters. 

Im using github but was wondering if there specific tools or practices of data scientists which i might aswell implement in my workflow

Thanks",datascience,https://www.reddit.com/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,13,6,0.8,"[Comment(id='k6m6kiv'), Comment(id='k6nfn5r'), Comment(id='k6v2mdo'), Comment(id='k6xt7hw'), Comment(id='k6ns9eq'), Comment(id='k6ogg69'), Comment(id='k6otnus'), Comment(id='k6owyxc'), Comment(id='k6p2ki3'), Comment(id='k6p5plp'), Comment(id='k6pvc8v'), Comment(id='k6q0u1l'), Comment(id='k6qadyp')]"
17gx6q4,NewManufacturer3888,,2023-10-26 13:59:51+00:00,False,,False,False,True,False,/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,"What is the most unique, out of the box, or exciting application of DS you’ve used/thought of?","Can be in work, as a passion project/academic project, or just an idea. Was it successful? If not, why not? Would love to be inspired & motivated by all of your experiences, and who knows, maybe it’ll help someone think about a current project in a new way.",datascience,https://www.reddit.com/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,16,21,0.89,"[Comment(id='k6kktmh'), Comment(id='k6jilk1'), Comment(id='k6ke80k'), Comment(id='k6jlip7'), Comment(id='k6jugx8'), Comment(id='k6lue0f'), Comment(id='k6n4vxq'), Comment(id='k6n70rf'), Comment(id='k6u9sgk'), Comment(id='k6jun0m'), Comment(id='k6l5vdg'), Comment(id='k6l69bm'), Comment(id='k6jy1ha'), Comment(id='k6k0vpv'), Comment(id='k6nht0y'), Comment(id='k6l5rab')]"
17hfao4,smart_cat_22,,2023-10-27 04:17:42+00:00,False,,False,False,True,False,/r/datascience/comments/17hfao4/what_skills_should_i_gain_to_be_a_full_stack_data/,"What skills should I gain to be a ""Full Stack Data Scientist""?",,datascience,https://www.reddit.com/r/datascience/comments/17hfao4/what_skills_should_i_gain_to_be_a_full_stack_data/,3,1,0.67,"[Comment(id='k6otrye'), Comment(id='k6p539h'), Comment(id='k6u6t8p')]"
17go3pk,furioncruz,,2023-10-26 04:13:19+00:00,False,,False,False,True,False,/r/datascience/comments/17go3pk/ab_test_in_real_life/,A/B test in real life,"My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn't conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. 

Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?",datascience,https://www.reddit.com/r/datascience/comments/17go3pk/ab_test_in_real_life/,39,75,0.98,"[Comment(id='k6ir3rp'), Comment(id='k6hzxra'), Comment(id='k6ijdtq'), Comment(id='k6iwobo'), Comment(id='k6jjj1c'), Comment(id='k6llapn'), Comment(id='k6j2hfs'), Comment(id='k6igkjn'), Comment(id='k6n9gfe'), Comment(id='k6lymf2'), Comment(id='k6j6wgx'), Comment(id='k6n7onk'), Comment(id='k6i2kuf'), Comment(id='k6in1v1'), Comment(id='k6iyaxe'), Comment(id='k6j2b00'), Comment(id='k6novgy'), Comment(id='k6pam5l'), Comment(id='k6norb7'), Comment(id='k6j2su4'), Comment(id='k6inqev'), Comment(id='k6no7o6'), Comment(id='k6nonp1'), Comment(id='k6i4eec'), Comment(id='k6lt3j0'), Comment(id='k6iuhzr'), Comment(id='k6jc94s'), Comment(id='k6jgjro'), Comment(id='k6k1gc7'), Comment(id='k6iqh9u'), Comment(id='k6pdean'), Comment(id='k6j9xaa'), Comment(id='k6jtwy5'), Comment(id='k6nv3ie'), Comment(id='k6i62a2'), Comment(id='k6ky92f'), Comment(id='k6jkn3a'), Comment(id='k6nwcqq'), Comment(id='k6l4sq6')]"
17h7ri5,No_Match_7225,,2023-10-26 21:53:39+00:00,False,,False,False,True,False,/r/datascience/comments/17h7ri5/data_science_student_advice/,Data science student advice,"Hey guys so I was told that as a data science student I should do things like leetcode as a hobby to help me out to land internships and to make it look better when looking for jobs, I currently have 0 experience in the field, 0 internships, so what could I do to make me stand out in this market? I’m set to graduate may 2024.",datascience,https://www.reddit.com/r/datascience/comments/17h7ri5/data_science_student_advice/,4,3,0.67,"[Comment(id='k6lv9zo'), Comment(id='k6mp3kh'), Comment(id='k7c8pvj'), Comment(id='k7ksfnj')]"
17h0uio,soupqueen6869,,2023-10-26 16:47:45+00:00,False,,False,False,True,False,/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,What website do I use to make a portfolio?,Hi! I’m applying to data science/ analytics jobs and internships right now. I have extensive personal and academic projects that I need to put in an online portfolio for hiring managers to see. What do you all recommend for this? Thanks!,datascience,https://www.reddit.com/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,5,6,1.0,"[Comment(id='k6kboht'), Comment(id='k6l65ei'), Comment(id='k6mwfl9'), Comment(id='k6okodi'), Comment(id='k6ly4gq')]"
17h5xor,DhammaVicaya,,2023-10-26 20:33:27+00:00,False,,1698352658.0,False,True,False,/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,"Severance for US-based data science manager, director?",What is a typical severance package for manager or director of data science (or data engineering) for US companies. How many weeks severance per years tenure? What did yours look like?,datascience,https://www.reddit.com/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,10,2,0.75,"[Comment(id='k6mlrn5'), Comment(id='k6lbvs7'), Comment(id='k6qdvwz'), Comment(id='k6uywp4'), Comment(id='k6n1qrr'), Comment(id='k6oay0b'), Comment(id='k6ob2mf'), Comment(id='k6obyj6'), Comment(id='k6og33f'), Comment(id='k6om09j')]"
17gfqqp,Mackelday,,2023-10-25 21:32:31+00:00,False,,1698270328.0,False,True,False,/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,How to survive at nightmare employer?,"I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I'm slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?

Red flags include:

* No data / inaccessible data / data flying around in Excel
* Management is not ""ML literate""
* More work dealing with red tape than actual work
* 2x more managers than workers driving projects
* Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it
* No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.
* Because we work directly in prod, we don't have permission to save our processed data to tables or csv's - it must be done in memory every single day
* No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can't download unapproved libraries or pre-trained models without security review (even just for exploration)

My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025",datascience,https://www.reddit.com/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,72,134,0.95,"[Comment(id='k6gnkxd'), Comment(id='k6gn9sm'), Comment(id='k6gvxlr'), Comment(id='k6gz4zz'), Comment(id='k6gwlnj'), Comment(id='k6gy6ux'), Comment(id='k6gg0zp'), Comment(id='k6h729t'), Comment(id='k6girei'), Comment(id='k6i3sok'), Comment(id='k6htzrz'), Comment(id='k6ih65t'), Comment(id='k6gn6w8'), Comment(id='k6hm1fd'), Comment(id='k6hwj5z'), Comment(id='k6hwq3r'), Comment(id='k6hz3ct'), Comment(id='k6i6ns1'), Comment(id='k6i8599'), Comment(id='k6ifbip'), Comment(id='k6itjj6'), Comment(id='k6iwluk'), Comment(id='k6j06hn'), Comment(id='k6j0czn'), Comment(id='k6j24lb'), Comment(id='k6jgoaz'), Comment(id='k6jktiu'), Comment(id='k6jmqsl'), Comment(id='k6jmuxo'), Comment(id='k6jtq0x'), Comment(id='k6lg9h8'), Comment(id='k6ncr26'), Comment(id='k6nh6tp'), Comment(id='k7ewn3e'), Comment(id='k6kn1c0'), Comment(id='k6j1ebs'), Comment(id='k6ixfb8'), Comment(id='k6gyp0j'), Comment(id='k6j9qcm'), Comment(id='k6h2zki'), Comment(id='k6h4orh'), Comment(id='k6hnjit'), Comment(id='k6l2ng3'), Comment(id='k6h3gqh'), Comment(id='k6ji7gg'), Comment(id='k6it3xh'), Comment(id='k6gh12d'), Comment(id='k6ggxfu'), Comment(id='k6juuz8'), Comment(id='k6jbx1h'), Comment(id='k6ojj0c'), Comment(id='k6jcbyz'), Comment(id='k6k0u1o'), Comment(id='k6j8437'), Comment(id='k6km1ty'), Comment(id='k6j8yyk'), Comment(id='k6je9rd'), Comment(id='k6itqxy'), Comment(id='k6m3xhh'), Comment(id='k6gzkxd'), Comment(id='k6igwmw'), Comment(id='k6ghhgp'), Comment(id='k6ll39w'), Comment(id='k6ly1bx'), Comment(id='k6l4dw6'), Comment(id='k6gi8di'), Comment(id='k6gin55'), Comment(id='k6gyrwt'), Comment(id='k6gv3m8'), Comment(id='k6gk3ar'), Comment(id='k6gxvx3')]"
17h23wx,donhuell,,2023-10-26 17:45:08+00:00,False,,False,False,True,False,/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,"Is it just me, or is the requirements / specifications process a complete nightmare?","I find the data specifications / requirements process to be awful. It's legit one of my least favorite aspects of this job.

For context, I work in an academia-adjacent industry, and I'm typically working with subject matter research experts. They are responsible for writing programming specifications for our projects, which are supposed to serve as an outline for programming and development for the data science team. Sometimes PMs will write them as well. For ex. something like:


    1. Load data from [data source]
    2. Confirm variables `x`, `y`, and `z` are correct data types
    3. Merge data (outer join) with [other dataset]
    	a. output a table of merge %
    4. Deduplicate on ID variable
    5. Filter by ...
    6. etc.
    7. export files to [server location]

As a data scientist, I am supposed to generally follow these steps to produce the result we are looking for. If I disagree with a step, or need to add some logic, I'll go in to the document and edit it. So it's a shared responsibility between my team and the research / project management team. The above steps are a very simplified example - sometimes these types of requirement documents can be like 15 pages long, with a ton of rules and nested logic / requests.

These documents tend to be written in Microsoft Word, which is messy and hard to version control when working across large teams. It's very easy to miss updates and lose track of which specifications have changed.

I can't help but think this process could be so much cleaner and efficient.",datascience,https://www.reddit.com/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,1,3,1.0,[Comment(id='k6mgbyr')]
17gxa3v,Bunshin69,,2023-10-26 14:03:51+00:00,False,,False,False,True,False,/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,"Intro to Statistical Learning, With Applications in Python (ISLP) How long could it take to study this book?","Sorry if this is a weird question I just need what people with more experience think about my situation. For some context. I am doing a Master in Data Science but finished my degree in biology. I study full time but I have two other classes at the same time this semester. And one of my class is blasting through this book by giving a little over an hr lecture per chapter and plan to finish the book in a semester. It is clear to me the lectures don’t cover all the contents either does not cover some details or leave some parts out.  While you could absolutely give lectures like this, it does take some time to fully grasp all the concepts, especially when I have to do 2 other classes. I feel like I can’t keep up so just wondering how long people here take to study it if they did or if they are familiar with it, hopefully can tell me if what I am feeling is natural within the context I provided or if it is because of my lack of experience in programming. Do I need to get more of my shit together? Or should I feel less shit about having to catch up slower and investing more time hopefully during holidays and stuff.",datascience,https://www.reddit.com/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,14,4,0.75,"[Comment(id='k6jjlbc'), Comment(id='k6jlhsd'), Comment(id='k6kogyd'), Comment(id='k6v6v98'), Comment(id='k6yi71i'), Comment(id='k723s9l'), Comment(id='k7snd6w'), Comment(id='k6jwiid'), Comment(id='k6kdlzv'), Comment(id='k6n7m0o'), Comment(id='k6kpkrx'), Comment(id='k6n90l7'), Comment(id='k6n77t2')]"
17gtqqz,First_Beginning6365,,2023-10-26 10:51:37+00:00,False,,False,False,True,False,/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/,How are data science interviews for entry level different from senior level (L5-L6). How is the interview preparation different?,,datascience,https://www.reddit.com/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/,9,8,0.79,"[Comment(id='k6jlil7'), Comment(id='k6jlv5p'), Comment(id='k6lt7lr'), Comment(id='k6m26i0'), Comment(id='k6m2nyh'), Comment(id='k6nxpx2'), Comment(id='k6m3q5c'), Comment(id='k6o4k4h'), Comment(id='k6o4l0t')]"
17gyvk2,Eastern-Habit6458,,2023-10-26 15:19:24+00:00,False,,False,False,True,False,/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,Need guidance to publish a paper,"Hello All,

I am a student pursuing an MS in data science. I have done a few projects involving EDA and implemented a few ML algorithms. I am very enthusiastic about researching something and publishing a paper on it. However, I have no idea where to start or how to choose a research topic. Can someone among you guide me on this? At this point, I do not want to pursue a PhD but want to conduct independent research on a topic.",datascience,https://www.reddit.com/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,3,3,1.0,"[Comment(id='k6naoe0'), Comment(id='k7c8tc5'), Comment(id='k6wlj3t')]"
17h6bty,Practical-Wing-6143,,2023-10-26 20:50:56+00:00,False,,False,False,True,False,/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,Aspiring Data scientist who needs some guidance on a career path,"So I am currently a junior in school working towards a degree in applied and computational mathematics with a minor in cs, and I was wondering what type of opportunities I should be actively looking for and seeking out in order to be successful. I am trying to apply to data science internships but it is a bit harder this year and I'm not really getting any interviews.   
I am also kind of struggling on understanding what projects I should be doing because a lot of the requirements I see on job postings are very high level topics I just haven't learned yet. For example here is a list of common requirements I have seen:  


* Expertise in statistical methods and experimental design and analysis  
* Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning
* Deployment of microservices and data pipeline and monitoring the performance of Kubernetes application and Data infrastructure.
* Hands-on experience with experimentation design, A/B testing, or probabilistic modeling are a plus!
* Experience with mathematical modeling techniques (e.g., linear and integer programming, statistical modeling, system dynamics modeling) 
* Experience with quantitative analysis of complex systems, probability and statistics  
* Strong background/interest in experimentation, recommendation systems, & data visualization   


I haven't really taken courses on these, and getting started with projects using these high level topics is also pretty challenging since theres a learning curve. I'm just not sure what I should actively be doing since my applications are going nowhere and there's so many topics to learn and study on my own. Just looking for some guidance, any advice is welcome.",datascience,https://www.reddit.com/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,4,1,0.55,"[Comment(id='k6ljm5j'), Comment(id='k6ljxf2'), Comment(id='k6loaty'), Comment(id='k6mscpk')]"
17gwjgc,KamdynS7,,2023-10-26 13:28:36+00:00,False,,False,False,True,False,/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,Freelance Data Science in small businesses,"My brother-in-law(call him James) co-owns a small business with two of his colleagues who provide services to small businesses. These services include website design, marketing(everything from SEO optimization to email lists to whatever), and graphic design. James recently reached out to me to ask if I would do part-time work for them as a data analyst/data scientist. My background is in quantitative political science. I know how to do pretty much everything data scientists do at a low level (ML algorithms, acquiring data, cleaning data, etc.) but I don't know very well how to apply these techniques to a business. So from that, I have two questions: 

1. How are ML algorithms used for businesses? I'll give some examples of how I imagine it working. K-means clustering can be used for targeted advertisements based on the groups customers are put in. Linear regression can be used to predict sales based on some other independent variable. Decision trees can be used to determine what factors might lead to a customer discontinuing the use of a service. Am I on the correct track? Are these incorrect or are there others I am missing? I would love to hear about ways you guys use ML in your job. I know how to do A/B testing conceptually and do a ton of hypothesis testing in my work so that part of the job I am not worried about (and honestly looking at these two methods it seems they will be used more often than ML). 
2. Can data science even be done with small businesses? My main concern is about the quality of the data. It may require me to organize the data which could take a considerable amount of time and might venture into some data engineering spheres in which I really don't have experience. And then will there even be enough data? Is there some critical mass of sales that is needed before one can begin analyzing a company's metrics? I believe most of the people this service works with a smaller companies that might not have the robust data that F500 companies do. 

I hope these two questions make sense. I'm not trying to get quick and dirty information about data science. If I'm pointed in the direction of how to use these algorithms I can research them on my own. I just wanted some advice from people in the field. For reference, I use mostly Stata in my poli sci work, but I can do most of it in Python as well. Stata is just better for the small studies I do lol. ",datascience,https://www.reddit.com/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,7,3,0.71,"[Comment(id='k6jci38'), Comment(id='k6kfjfe'), Comment(id='k6jdham'), Comment(id='k6qv9ww'), Comment(id='k6lt096'), Comment(id='k6jes86'), Comment(id='k6o9m31')]"
17gum8s,Beginning-Scholar105,,2023-10-26 11:46:52+00:00,False,,False,False,True,False,/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,"If you really want to practice data science with real-world projects, then check out DataWars.","**Data science community, I'm here to tell you about a new platform that's going to revolutionize the way you learn data science: DataWars**

I've been using it for a few weeks now, and I'm absolutely blown away. It's the most immersive and hands-on way to learn data science that I've ever experienced.

With DataWars Live Labs, you can:

* Write code in real time and get immediate feedback on your progress.
* Validate your understanding of key concepts.
* Check the correctness of your code.
* Work on interactive projects that are designed to help you learn and practice.

If you're serious about learning data science, I highly recommend checking out DataWars Live Labs. It's the best way to learn quickly and master the skills you need to succeed.

**Here are a few specific things that I love about DataWars Live Labs:**

* The projects are really well-designed and engaging. They cover a wide range of topics, from Python, data cleaning, and wrangling to machine learning and much more.
* The feedback loop is instant. As you write code, you can see immediately whether it's working correctly. This makes it easy to learn from your mistakes and improve your skills quickly.
* Their Discord server is great.

Overall, I'm extremely impressed with DataWars. It's the best way to learn data science that I've ever used. I highly recommend it to anyone who wants to learn data science quickly and master the skills they need to succeed.",datascience,https://www.reddit.com/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,2,4,0.7,[Comment(id='k6nx197')]
17hbxka,Antique-Nothing-4315,,2023-10-27 01:14:02+00:00,False,,False,False,True,False,/r/datascience/comments/17hbxka/question/,Question,"Hello, g12 student here looking to apply to a university program, im an Ontario student wanting to apply to a Data Science program and I was wondering if the program and degree is worth it, or whether I should choose something else. What jobs would a bachelor's in Data Science degree open me up to? (ofc I will do my masters). What salary ranges typically are those jobs (Canada and US) and how much do you make as a Data Scientist/ML engineer etc. Is a comp sci program better than a Data Science program? can I get into ML engineering with a data sci degree?",datascience,https://www.reddit.com/r/datascience/comments/17hbxka/question/,0,0,0.2,[]
17h41a9,Samia_Tisha,,2023-10-26 19:11:07+00:00,False,,False,False,False,False,/r/datascience/comments/17h41a9/can_anyone_tell_me_if_the_machine_learning/,Can anyone tell me if the machine learning workflow is correct or not? Could anyone please refer to tutorials or blogs to learn the proper workflow? Any suggestions are welcome.,,datascience,/r/u_Samia_Tisha/comments/17h3xve/can_anyone_tell_me_if_the_machine_learning/,0,0,0.5,[]
17h3hj7,Suza_330,,2023-10-26 18:46:39+00:00,False,,False,False,True,False,/r/datascience/comments/17h3hj7/data_science_upskilling/,data science upskilling," **How to upskill for data science in 2023, I have 3 years of relevant work experience, plus 7 years total but learning has almost stopped. Could you suggest resources/websites to take profile** ",datascience,https://www.reddit.com/r/datascience/comments/17h3hj7/data_science_upskilling/,1,0,0.33,[Comment(id='k6yil4d')]
17h37bq,Rebeca_nura,,2023-10-26 18:34:02+00:00,False,,False,False,True,False,/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,Help! Cloud services on the Data Science field,"Hello all, I want to ask to you some questions about Cloud services on the Data Science field.

&#x200B;

Currently I´m working on a marketing agency with around 80 employees, and my team is in charge of the data management, we have been working on an ETL process that cleans data coming from APIs and upload it in Big Query. We scheduled the daily ETL process with Pythonanywhere, but now our client want us to implement a top notch platform to absorb the work of Pythonanywhere. I know that there are some options that I can use as Azure or AWS but my self and my team is complete ignorant of the topic, for those of you that already worked in projects that use this technolgies, which is the best approach to start learn it? are there any courses or certifications that you recomment? for scheduling the run of python code is there a specific module of Azure or AWS that I have to learn?

&#x200B;

Thank you!

&#x200B;

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,0,1,0.67,[]
17h2z94,trevor12345677,,2023-10-26 18:24:20+00:00,False,,False,False,True,False,/r/datascience/comments/17h2z94/learning_programming/,Learning programming!,"I am a student getting my masters in applied statistics. I’ve never experienced much with programming but have now found a major passion for it. I have a little over a year left till I finish up my masters. What different programs should I focus on? I am using R with my school and will get great practice with it. I want to be proficient in 2-3 programs when applying for next job when I graduate? What languages do you recommend and where do you recommend learning it from? I love futuristic/forecasting  modeling and looking to get into that type of work. 

Thank you for any help/advice!",datascience,https://www.reddit.com/r/datascience/comments/17h2z94/learning_programming/,6,1,0.67,"[Comment(id='k6kpxzc'), Comment(id='k6kptol'), Comment(id='k751vum'), Comment(id='k7gsw23'), Comment(id='k6kq3om'), Comment(id='k6kucrj')]"
17h2gwb,nacho_biznis,,2023-10-26 18:01:37+00:00,False,,False,False,True,False,/r/datascience/comments/17h2gwb/how_to_predict_office_relocation/,How to predict office relocation,"Does anyone have a good feel of how to formulate the task of predicting if a company will have to relocate in following X months? Say I can construct a dataset with info on employees, area, building details and some financial numbers. I know the months in which they move or not. So zeros and ones here for the label. I haven't managed to find any relevant literature or code or blog post on a similar topic. Is this a binary classification problem? What algorithms to use? How to account for class imbalance that case? Any pointers would be much appreciated.",datascience,https://www.reddit.com/r/datascience/comments/17h2gwb/how_to_predict_office_relocation/,3,1,0.67,"[Comment(id='k6kvdth'), Comment(id='k6mvwhb')]"
17h2bxq,SussyAutist,,2023-10-26 17:55:23+00:00,False,,False,False,True,False,/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,Suggestions for my internship project,"Hello guys,

I am currently doing a project for my internship. It involves image detection which I have more or less dealt with. The main thing now for me to do is that I have to compare the mass or brightness of each of the blue holes with the reference chart circled red. The blue dots in the red circle have varying uniform opacity and I have to see how the outside blue dots compare with the reference dots. I cannot seem to figure out how to go about doing this. I was thinking of a graph, but it does not seem convenient or maybe a 3d graph(?). I would be grateful if you guys can give me suggestions.

&#x200B;

https://preview.redd.it/jaefgmgh4lwb1.png?width=717&format=png&auto=webp&s=8c03ed5cc6732c8748f548c5742824c952815156",datascience,https://www.reddit.com/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,0,0,0.5,[]
17gx81s,CursorInsight,,2023-10-26 14:01:22+00:00,False,,False,False,False,False,/r/datascience/comments/17gx81s/we_are_the_founders_of_cursor_insight_the_human/,"We are the founders of Cursor Insight, the human motion experts. AMA!",,datascience,/r/IAmA/comments/17gv9im/we_are_the_founders_of_cursor_insight_the_human/,0,2,1.0,[]
17h1y9t,house_lite,,2023-10-26 17:38:04+00:00,False,,False,False,False,False,/r/datascience/comments/17h1y9t/i_created_a_shiny_app_for_data_scientists/,I created a shiny app for data scientists,,datascience,https://github.com/AdrianAntico/Quantico,0,1,1.0,[]
17gwwlp,Distinct-Swan2019,,2023-10-26 13:46:09+00:00,False,,False,False,True,False,/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,Feature Pyramid Network vs U-Net,"Hi everyone, 

I was working on my thesis research when I encountered the concept of Feature Pyramid Network, i have read something about it but still i have some doubts. My main question is: ""What is (or are) the difference(s) with respect to the U-Net architecture?""",datascience,https://www.reddit.com/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,1,2,1.0,[Comment(id='k6m1ete')]
17g7kqf,cptsanderzz,,2023-10-25 15:36:00+00:00,False,,False,False,True,False,/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,Is the future of data science drag and drop?,"I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don’t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can’t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone’s thoughts?",datascience,https://www.reddit.com/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,147,114,0.78,"[Comment(id='k6ep0on'), Comment(id='k6et8aj'), Comment(id='k6f6uhl'), Comment(id='k6eyet7'), Comment(id='k6evrt4'), Comment(id='k6f3dl8'), Comment(id='k6equu8'), Comment(id='k6etbvj'), Comment(id='k6etuk9'), Comment(id='k6f2rak'), Comment(id='k6euh1u'), Comment(id='k6eq0l1'), Comment(id='k6f5b0s'), Comment(id='k6fgf5v'), Comment(id='k6fin9k'), Comment(id='k6fq8fj'), Comment(id='k6eyfb4'), Comment(id='k6fdxxe'), Comment(id='k6fx22n'), Comment(id='k6gkwi7'), Comment(id='k6it5ou'), Comment(id='k6eugcx'), Comment(id='k6fewku'), Comment(id='k6faxsy'), Comment(id='k6f1haa'), Comment(id='k6f6bo9'), Comment(id='k6f7leh'), Comment(id='k6fa062'), Comment(id='k6fia3p'), Comment(id='k6flemy'), Comment(id='k6fw955'), Comment(id='k6fxyup'), Comment(id='k6fzh9l'), Comment(id='k6fzkaa'), Comment(id='k6g0w08'), Comment(id='k6g4c76'), Comment(id='k6g9arb'), Comment(id='k6gb07x'), Comment(id='k6gcbjc'), Comment(id='k6gdhrb'), Comment(id='k6gkqj8'), Comment(id='k6gw50m'), Comment(id='k6g0huq'), Comment(id='k6fusab'), Comment(id='k6ey5bj'), Comment(id='k6glrea'), Comment(id='k6fovaq'), Comment(id='k6gx91z'), Comment(id='k6gzg2a'), Comment(id='k6hdt9m'), Comment(id='k6hi2yb'), Comment(id='k6hokd9'), Comment(id='k6hu44y'), Comment(id='k6ibw2q'), Comment(id='k6if1mz'), Comment(id='k6ir5a3'), Comment(id='k6j6cck'), Comment(id='k6k552r'), Comment(id='k6kuxbc'), Comment(id='k7snhgv'), Comment(id='k6ev5ee'), Comment(id='k6fy2g3'), Comment(id='k6gjsk9'), Comment(id='k6fhv4f'), Comment(id='k6irq3o'), Comment(id='k6ffqro'), Comment(id='k6favmx'), Comment(id='k6gw1ur'), Comment(id='k6iduzk'), Comment(id='k6hhrhf'), Comment(id='k6f2rr2'), Comment(id='k6fudy9'), Comment(id='k6g7uur'), Comment(id='k6gfgjo'), Comment(id='k6fufns'), Comment(id='k6f5c9l'), Comment(id='k6g7xdw'), Comment(id='k6gdyl1'), Comment(id='k6iujdl'), Comment(id='k6fbmyz'), Comment(id='k6fci1k'), Comment(id='k6j3abp'), Comment(id='k6gectz'), Comment(id='k6itm47'), Comment(id='k6fz7ll'), Comment(id='k6fjvgs'), Comment(id='k6fhdeo'), Comment(id='k6fdfnc'), Comment(id='k6f6bpg'), Comment(id='k6ffx4z'), Comment(id='k6fbgbm'), Comment(id='k6g82f9'), Comment(id='k6g7q48'), Comment(id='k6gkgz7'), Comment(id='k6ghg6v'), Comment(id='k6gl8g7'), Comment(id='k6g2plb'), Comment(id='k6itq4z'), Comment(id='k6gkho5'), Comment(id='k6g5tn0'), Comment(id='k6goaej'), Comment(id='k6h4lqh'), Comment(id='k6jv6tu'), Comment(id='k6fwbgy'), Comment(id='k6gdoq6'), Comment(id='k6kqkms'), Comment(id='k6f7t9k'), Comment(id='k6gvo1r'), Comment(id='k6flm40'), Comment(id='k6fkxqu'), Comment(id='k6hgbnv'), Comment(id='k6iuw1f'), Comment(id='k6gtl0u'), Comment(id='k6iuzb2'), Comment(id='k6jyfka'), Comment(id='k6g9tzd'), Comment(id='k6gv2cy'), Comment(id='k6jwtrv'), Comment(id='k6ff727'), Comment(id='k6flcv7'), Comment(id='k6fv4ne'), Comment(id='k6fc9mm'), Comment(id='k6i1i82'), Comment(id='k6ifmfe'), Comment(id='k6iv9pe'), Comment(id='k6h1xpr'), Comment(id='k6iad6j'), Comment(id='k6k5cqb'), Comment(id='k6gb8vu'), Comment(id='k6gvoc7'), Comment(id='k6m9z5a'), Comment(id='k6fnxvg'), Comment(id='k6iv4l5'), Comment(id='k6k71lz'), Comment(id='k6ggqhq'), Comment(id='k6h6zc1'), Comment(id='k6hkxjp'), Comment(id='k6maufe'), Comment(id='k6gdnga'), Comment(id='k6l4sod'), Comment(id='k6gu3ho'), Comment(id='k6hdosk'), Comment(id='k6lak6t'), Comment(id='k6guh62'), Comment(id='k6jdyac'), Comment(id='k6nrubp'), Comment(id='k6o1az5')]"
17h10e0,Alert_Pea_4855,,2023-10-26 16:55:07+00:00,False,,False,False,False,False,/r/datascience/comments/17h10e0/data_strategy_mastery_valuable_tips_for_data_pros/,Data Strategy Mastery: Valuable Tips for Data Pros and Companies Aiming to Level Up,"Hi folks, I just published an article where I shared some of the tips I've learned based on my research and experience for building a data strategy and leveling up your business. Curious to learn more? Dive in here",datascience,https://meysamraz.medium.com/data-strategy-mastery-valuable-tips-for-data-pros-and-companies-aiming-to-level-up-69b17606e7e4,0,1,1.0,[]
17h56j2,Silence_the_Slayer99,,2023-10-26 20:00:35+00:00,False,,False,False,True,False,/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,How to Apply What I Learn in Data Science and Find a Job?,"Hello All. Just looking to tap into your expertise and experience 😊

I’m a non-technical Project Management Officer with robust Excel skills and some knowledge about IT Systems. Now, I’m highly interested in becoming a Data Scientist as well and have taken some online courses to get up to speed.

Here’s my dilemma. I don’t have much experience yet with creating PowerBI reports and using Python language. I’m intimidated (yet intrigued) with this complex field.

How can I take on projects to properly apply what I’ve been learning so far? Also, how can I apply for jobs related to this field while still being a beginner (but willing to learn in the job)?

Many thanks in advance for your advices. Thank you 😊",datascience,https://www.reddit.com/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,6,0,0.25,"[Comment(id='k6lg4t9'), Comment(id='k6s1u7e'), Comment(id='k73y70w'), Comment(id='k75zq7q'), Comment(id='k79fdxn'), Comment(id='k7he44l')]"
17gzyzp,smokeyScraper,,2023-10-26 16:09:25+00:00,False,,False,False,True,False,/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,Convert Stata(.DTA) files to .csv,"Hello, can anyone help me out. I want to convert a huge .dta file(~3GB) to .csv file but I am not able to do so using python due to its large size. I also tried on kaggle but it said memory limit exceeded. Can anyone help me out?",datascience,https://www.reddit.com/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,6,1,0.67,"[Comment(id='k6k2gaj'), Comment(id='k6knkk7'), Comment(id='k6kjdr8'), Comment(id='k6l5157'), Comment(id='k6l8vz2'), Comment(id='k6n7mkk')]"
17gya2d,former_pothead,,2023-10-26 14:51:18+00:00,False,,False,False,True,False,/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,Thoughts about MS in Data Intelligence (MSDI) in University of South Florida?,"USF accepted my application for the [MSDI program](https://www.usf.edu/engineering/imse/graduate/ms-data-intelligence.aspx). I'm here considering if I accept the acceptance letter and join in January, or wait until August 2024 to join Georgia Tech's Online Master of Science in Analytics.",datascience,https://www.reddit.com/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,0,0,0.5,[]
17gtvwl,First_Beginning6365,,2023-10-26 11:01:04+00:00,False,,False,False,True,False,/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,Are data science answering frameworks helpful?,"Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  **Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.**   


I have seen and found this framework for answering such questions:  


Step1: Ask clarifying questions on problems and constraints 

Step 2: Establish Metrics 

Step 3: Understand your data sources 

Step 4: Explore your data 

Step 5: Data Cleanup 

Step 6: Feature Engineering 

Step 7: Model Selection and training 

Step 8: Deployment 

Step 9: Iterate 

I would love to get inputs on need and usefulness of such frameworks?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,2,2,0.75,"[Comment(id='k6j5kgc'), Comment(id='k6jdq60')]"
17gtslo,Glum-Bat8771,,2023-10-26 10:55:13+00:00,False,,1698353625.0,False,True,False,/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,Dealing with features of questionable predictive power and confounding variables,"Hello all, I encountered this data analytics / data science challenge at work, wondering how y’all would have solved it.

**Background:**

I was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.

Given that we weren't producing the product descriptions ourselves, our focus was on **features we could influence**. We **did not include** aspects such as:

* brand reputation, 
* type of product, 
* price

, even if they were vital factors driving user engagement.

Our attention was instead directed at a few controllable features:

* whether or not the descriptions exceeded a certain length (we could provide feedback on these to vendors)
* whether or not our in-house ML model could categorize the product (affecting its searchability)
* the presence of vendor ratings,
* etc.

To clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn't. So, my dataset consisted of all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.

**Approach:**

My next steps? I initiated numerous student t-tests. 

For instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What's the engagement disparity between products that had vendor ratings va those that didn’t? 

Given the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. 

Note: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren't for UX / political reasons.

**Results:**

With extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging.

Yet, the findings weren't consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.

My next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.

I never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.

**What could I have done differently?**

In retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?

I would love to hear your thoughts!",datascience,https://www.reddit.com/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,4,2,1.0,"[Comment(id='k6t20zp'), Comment(id='k6tistt'), Comment(id='k6tk55h'), Comment(id='k6tx69a')]"
17gtgb0,cinderbl0ckgardener,,2023-10-26 10:31:59+00:00,False,,False,False,True,False,/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,How to qualify for a job in Data Science,"I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. 

Any additional skills I need to learn?",datascience,https://www.reddit.com/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,3,2,0.67,"[Comment(id='k6irjk7'), Comment(id='k6itceg'), Comment(id='k6iy2pu')]"
17gc0b4,VastDragonfruit847,,2023-10-25 18:49:15+00:00,False,,False,False,True,False,/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,Is a Convex Optimization class good for Data Science?," For context, I am a Master's student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.

This is what the course page says : 

Student Learning Outcomes: 

Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.

Detailed Content: 

Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems – applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation – applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle – primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  


  
I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?",datascience,https://www.reddit.com/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,22,33,0.97,"[Comment(id='k6fqqdz'), Comment(id='k6g2hhd'), Comment(id='k6h23na'), Comment(id='k6gqhhp'), Comment(id='k6fy0lg'), Comment(id='k6hj85d'), Comment(id='k6iceu3'), Comment(id='k6hepsg'), Comment(id='k6ht6aw'), Comment(id='k6iwuh5'), Comment(id='k6lhq66'), Comment(id='k74sodb'), Comment(id='k6fverf'), Comment(id='k6gb0aq'), Comment(id='k74t4c9'), Comment(id='k6i9n0b'), Comment(id='k6iuy1p'), Comment(id='k6iuexz'), Comment(id='k74vkn4'), Comment(id='k6hest2'), Comment(id='k6jn2py'), Comment(id='k753ele')]"
17gwd7z,kaisoma,,2023-10-26 13:19:52+00:00,False,,False,False,False,False,/r/datascience/comments/17gwd7z/git_version_controlled_datasets_in_your_own_s3/,Git Version Controlled Datasets in your own S3,"I’m building Underhive, a collaboration platform for ML Teams. I’ve just put out the first product up which helps you use your own storage backend for Git-LFS.

Please email me at: support@underhive.in.
If you want to help and be one of the first beta clients.
We’re also giving free usage for upto 200GBs for the next 6 months to beta clients.  
Try out: https://underhive.in (please use on Desktop, the mobile version is broken right now)",datascience,https://i.redd.it/pkoix1xasjwb1.jpg,5,1,0.67,"[Comment(id='k6ktvdb'), Comment(id='k6kwunw'), Comment(id='k6phzwo'), Comment(id='k6piaqr'), Comment(id='k6yxi5j')]"
17h0yms,battleaxe37,,2023-10-26 16:52:51+00:00,False,,False,False,False,False,/r/datascience/comments/17h0yms/residuals/,Residuals,"I am trying to get the residuals to white noise but there are two different behaviors on residuals. Any ideas on how I should transform this? Or what should I do. I tried log/sqrt. Doesn’t really do shit. Dataset is a hourly data for a couple years. The graph behavior is seasonal yearly, and daily aswell. But right now I just care about the yearly. Any advice?",datascience,https://i.redd.it/4f064j4bukwb1.jpg,7,0,0.4,"[Comment(id='k6klrn0'), Comment(id='k6kgjba'), Comment(id='k6kugqc'), Comment(id='k6klz7d'), Comment(id='k6krr7q'), Comment(id='k6lm98f'), Comment(id='k6mm9f1')]"
17gvhga,Slow_Act_4114,,2023-10-26 12:34:24+00:00,False,,False,False,True,False,/r/datascience/comments/17gvhga/questions_for_knime_users/,Questions for KNIME Users,"Hey everybody,  
I started to use KNIME fpr work, but have some issues with it. I am currently taking the DW1 Exam, but I dont have any idea on how to do that. Can someone please help me? using ChatGPT feels like cheating.  
Thanks in advance ",datascience,https://www.reddit.com/r/datascience/comments/17gvhga/questions_for_knime_users/,0,1,1.0,[]
17goc84,daufoi21,,2023-10-26 04:27:37+00:00,False,,False,False,True,False,/r/datascience/comments/17goc84/having_a_second_job_on_1099/,having a second job on 1099,"I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I'm doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?",datascience,https://www.reddit.com/r/datascience/comments/17goc84/having_a_second_job_on_1099/,5,3,0.8,"[Comment(id='k6iwq7u'), Comment(id='k6ibn3k'), Comment(id='k6ncakw'), Comment(id='k6nciqv'), Comment(id='k6rt21a')]"
17fzssg,One_Ad_3499,,2023-10-25 08:09:19+00:00,False,,False,False,True,False,/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,I am intern and i hate Tableau. Can u give some copium?,I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety,datascience,https://www.reddit.com/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,83,102,0.86,"[Comment(id='k6d981d'), Comment(id='k6du5l8'), Comment(id='k6dhefm'), Comment(id='k6d9gxu'), Comment(id='k6dcgkx'), Comment(id='k6e9tdi'), Comment(id='k6dwlwc'), Comment(id='k6daxza'), Comment(id='k6efg55'), Comment(id='k6dbifn'), Comment(id='k6dqr0b'), Comment(id='k6ed5ro'), Comment(id='k6eh7fp'), Comment(id='k6f5wa5'), Comment(id='k6fc13y'), Comment(id='k6f6n8d'), Comment(id='k6fbae8'), Comment(id='k6dyx5x'), Comment(id='k6h27xy'), Comment(id='k6dihh2'), Comment(id='k6elmnt'), Comment(id='k6et8z6'), Comment(id='k6eu41t'), Comment(id='k6exs0r'), Comment(id='k6f0793'), Comment(id='k6gotdy'), Comment(id='k6hrmoy'), Comment(id='k6hsdw2'), Comment(id='k6huen8'), Comment(id='k6iptfn'), Comment(id='k7snwkr'), Comment(id='k6d9q9c'), Comment(id='k6gevtk'), Comment(id='k6edr5c'), Comment(id='k6duyqg'), Comment(id='k6gokwu'), Comment(id='k6ecxim'), Comment(id='k6eqvdz'), Comment(id='k6d9obm'), Comment(id='k6fr7dc'), Comment(id='k6dgrqg'), Comment(id='k6ddjev'), Comment(id='k6g08lz'), Comment(id='k6eb80m'), Comment(id='k6ehxvv'), Comment(id='k6esoun'), Comment(id='k6dbgfi'), Comment(id='k6fkufo'), Comment(id='k6f5n5b'), Comment(id='k6e2vaw'), Comment(id='k6jlaht'), Comment(id='k6f5zyu'), Comment(id='k6i37uk'), Comment(id='k6f511k'), Comment(id='k6fhx9i'), Comment(id='k6giw78'), Comment(id='k6jbl92'), Comment(id='k6ee6da'), Comment(id='k6etd01'), Comment(id='k6ewsz4'), Comment(id='k6dwt2x'), Comment(id='k6dzouy'), Comment(id='k6garmz'), Comment(id='k6if7a9'), Comment(id='k6fkzx9'), Comment(id='k6f61t1'), Comment(id='k6ex5sg'), Comment(id='k6e77m7'), Comment(id='k6g1a2b'), Comment(id='k6jdp7z'), Comment(id='k6jkwrz'), Comment(id='k6eef9x'), Comment(id='k6evjtn'), Comment(id='k6febx7'), Comment(id='k6flhao'), Comment(id='k6hgcy1'), Comment(id='k6excsa'), Comment(id='k6jkqam'), Comment(id='k6exhcy'), Comment(id='k6o743i'), Comment(id='k6f1v39'), Comment(id='k6eyrua'), Comment(id='k6fjrmw')]"
17gqxzh,ChrisReynolds83,,2023-10-26 07:25:24+00:00,False,,False,False,True,False,/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,Imputation of multiple missing values,"I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.

The tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.

I'm looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS ([Missing Data Imputation using Generative Adversarial Nets](https://arxiv.org/abs/1806.02920)) and [MissForest](https://academic.oup.com/bioinformatics/article/28/1/112/219101). Does anybody have any other suggestions of imputers that might work?",datascience,https://www.reddit.com/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,1,1,1.0,[Comment(id='k6ic7lb')]
17gn08a,jshkk,,2023-10-26 03:11:14+00:00,False,,False,True,True,False,/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,"Evaluation Metric Flowchart (possibly handy, interested in feedback!)","&#x200B;

I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are ""less wrong"" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 ""means something""), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!

My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.

https://preview.redd.it/7nplhw2npgwb1.png?width=7162&format=png&auto=webp&s=9bf42afad02bccdb791e88016a78862c7d7faa32",datascience,https://www.reddit.com/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,0,2,0.76,[]
17gpxlq,SaiyWolf,,2023-10-26 06:12:35+00:00,False,,False,False,True,False,/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,How can you learn to find the insights,I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?,datascience,https://www.reddit.com/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,6,1,0.67,"[Comment(id='k6is1wz'), Comment(id='k6k13c4'), Comment(id='k6mhcxp'), Comment(id='k6j7y7o'), Comment(id='k6izg9t'), Comment(id='k6j2zd7')]"
17g6gbt,Tender_Figs,,2023-10-25 14:45:41+00:00,False,,False,False,True,False,/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,How do you maintain motivation in your data role?,"Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?

Additionally, how do you maintain motivation when you're working with a domain that you don't like? Not tolerate, generally don't like. ",datascience,https://www.reddit.com/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,8,18,0.92,"[Comment(id='k6egvcp'), Comment(id='k6ejin3'), Comment(id='k6eylco'), Comment(id='k6fvhgj'), Comment(id='k6hdfzm'), Comment(id='k6jcg5p'), Comment(id='k6jdbav'), Comment(id='k6kryjc')]"
17fsjf2,Excellent_Cost170,,2023-10-25 00:54:36+00:00,False,,False,False,True,False,/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,"Tired of armchair coworker and armchair manager saying ""Analysis paralysis"""," I have an older coworker and a manager both from the same culture who doesn't have much experience in data science. They've been focused on dashboarding but have been given the title of 'data scientist.' They often mention 'analysis paralysis' when discussions about strategy arise. When I speak about ML feasibility analysis, or when I insist on spending time studying the data to understand the problem, or when I emphasize asking what the stakeholder actually wants instead of just creating something and trying to sell it to them, there's resistance. They typically aren't the ones doing the hands-on work. They seem to prefer just doing things. Even when there's a data quality issue, they just plow through. Has that been your experience? People who say ""analysis paralysis"" often don't actually do things; they just sit on the side or take credit when things work out.",datascience,https://www.reddit.com/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,106,185,0.93,"[Comment(id='k6c3yfu'), Comment(id='k6c3s40'), Comment(id='k6d345i'), Comment(id='k6ctrmh'), Comment(id='k6d928q'), Comment(id='k6c2h2m'), Comment(id='k6c0rq3'), Comment(id='k6d7804'), Comment(id='k6dxiyk'), Comment(id='k6emh52'), Comment(id='k6cgibe'), Comment(id='k6d2m83'), Comment(id='k6cit36'), Comment(id='k6dgxiq'), Comment(id='k6dxfdc'), Comment(id='k6e2v02'), Comment(id='k6fefsw'), Comment(id='k6du91o'), Comment(id='k6e4klf'), Comment(id='k6e46ia'), Comment(id='k6dwl6x'), Comment(id='k6e55bs'), Comment(id='k6ejl4q'), Comment(id='k6elvf7'), Comment(id='k6ez0yn'), Comment(id='k6f3tcl'), Comment(id='k6fqvpp'), Comment(id='k6imxz9'), Comment(id='k6c4ug5'), Comment(id='k6d8ez8'), Comment(id='k6efzic'), Comment(id='k6fjchp'), Comment(id='k6htc1e'), Comment(id='k6d588y'), Comment(id='k6eero2'), Comment(id='k6c5kzl'), Comment(id='k6drcxf'), Comment(id='k6g317y'), Comment(id='k6cls45'), Comment(id='k6es5ne'), Comment(id='k6f4vkp'), Comment(id='k6c4idg'), Comment(id='k6edy14'), Comment(id='k6epf7o'), Comment(id='k6clxp4'), Comment(id='k6eo4tq'), Comment(id='k6en5s7'), Comment(id='k6fm7it'), Comment(id='k6cg3oj'), Comment(id='k6eja13'), Comment(id='k6csejg'), Comment(id='k6e608e'), Comment(id='k6fl8xk'), Comment(id='k6erl2g'), Comment(id='k6euw8i'), Comment(id='k6g3kb0'), Comment(id='k6d9gkk'), Comment(id='k6dif78'), Comment(id='k6c8e12'), Comment(id='k6cfqhb'), Comment(id='k6ess1t'), Comment(id='k6e06hn'), Comment(id='k6edvcg'), Comment(id='k6gpizv'), Comment(id='k6cnea1'), Comment(id='k6etiqu'), Comment(id='k6cah36'), Comment(id='k6d1zk5'), Comment(id='k6etfi3'), Comment(id='k6fmusy'), Comment(id='k6d98az'), Comment(id='k6diwjs'), Comment(id='k6ejku9'), Comment(id='k6d3toq'), Comment(id='k6ddjdu'), Comment(id='k6fp8a3'), Comment(id='k6ehl2h'), Comment(id='k6dmwbl'), Comment(id='k6dqhep'), Comment(id='k6d9p3l'), Comment(id='k6dkgv7'), Comment(id='k6eilo6'), Comment(id='k6efiiq'), Comment(id='k6evd8e'), Comment(id='k6fdo19'), Comment(id='k6dnxbq'), Comment(id='k6e7u28'), Comment(id='k6dsb6h'), Comment(id='k6frx8l'), Comment(id='k6e3daa'), Comment(id='k6e5l7g'), Comment(id='k6dql3r'), Comment(id='k6dtrqu'), Comment(id='k6dwxhn'), Comment(id='k6dztzb'), Comment(id='k6f3h8r'), Comment(id='k6eivfs'), Comment(id='k6ft0i8'), Comment(id='k6e3obv'), Comment(id='k6dz85n'), Comment(id='k6e12yv'), Comment(id='k6f5zzm'), Comment(id='k6e3td6'), Comment(id='k6iy9k1'), Comment(id='k6e4cg7'), Comment(id='k6exj7p'), Comment(id='k6f5vmv')]"
17g8cbj,jakeblack06,,2023-10-25 16:09:12+00:00,False,,False,False,True,False,/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,What is the most suitable model for my problem?,"I know you would have heard so many people asking this question, but please bear with me.

I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes & GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don't know how to go about selelcting a model that suits the data the most because I don't have enough experience to just select any model based on experience and I didn't find any ""algorithm"" which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.",datascience,https://www.reddit.com/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,9,8,0.85,"[Comment(id='k6evp8t'), Comment(id='k6ew4iv'), Comment(id='k6g1y1p'), Comment(id='k6fkqr0'), Comment(id='k6i3m5d'), Comment(id='k6ir34q'), Comment(id='k6iigit'), Comment(id='k6jnxkr'), Comment(id='k6hvx3s')]"
17gn7d8,LegitimateAd4716,,2023-10-26 03:21:30+00:00,False,,False,False,True,False,/r/datascience/comments/17gn7d8/how_to_proceed/,How to proceed…,I’m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I’m pursuing right now also promised placement opportunities but I do not want to wait till the end…,datascience,https://www.reddit.com/r/datascience/comments/17gn7d8/how_to_proceed/,3,0,0.5,"[Comment(id='k6htj1h'), Comment(id='k6i3ksm'), Comment(id='k6jap1k')]"
17g8iu2,Jbor941197,,2023-10-25 16:17:02+00:00,False,,False,False,True,False,/r/datascience/comments/17g8iu2/learning_cloud_platforms/,Learning Cloud Platforms,"I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer's life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it's so different from data science where we focus on concepts vs tools. 

One reason Im curious is if you're the head of an analytics department how do you manage all of this? How would you know how much work something is?",datascience,https://www.reddit.com/r/datascience/comments/17g8iu2/learning_cloud_platforms/,0,7,0.9,[]
17gkbw1,Time_Law_2659,,2023-10-26 00:56:17+00:00,False,,False,False,True,False,/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,Reducing Goals Using Dats,We work in an items per hr setting with 100's of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.,datascience,https://www.reddit.com/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,0,0,0.33,[]
17fjgzu,CadeOCarimbo,,2023-10-24 18:20:44+00:00,False,,False,False,True,False,/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,Do you ever feel dumb when you see data scientists doing exceptional stuff when you are just there doing mundane data-stuff?,"Please don't take this post seriously, but I can't help but think that those guys who work at OpenAI, Midjourney,  Google, whatever, despite being Data Scientists just like me (for 6 years, not someone trying to break in), are delivering stuff that I would never be able to, even though we have the same titles on LinkedIn? 

I mean, I'm totally okay with with calling myself a mediocre data Scientist as it is pretty much a choice that I made by enjoying my free time instead of studying my ass off and going for a PhD, but still. Saying that OpenAI staff and myself both are data Scientist feels like saying Messi and some player from a local amateur team are both soccer players.",datascience,https://www.reddit.com/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,73,273,0.96,"[Comment(id='k6agm6d'), Comment(id='k6aa1ws'), Comment(id='k6actvn'), Comment(id='k6acwd9'), Comment(id='k6ao1uc'), Comment(id='k6ab2g2'), Comment(id='k6aidsz'), Comment(id='k6axj8v'), Comment(id='k6apqic'), Comment(id='k6auucq'), Comment(id='k6angtx'), Comment(id='k6an3b3'), Comment(id='k6csqg1'), Comment(id='k6awmz3'), Comment(id='k6bey4r'), Comment(id='k6bbd8k'), Comment(id='k6bfvnh'), Comment(id='k6c16uf'), Comment(id='k6c1ln2'), Comment(id='k6c2f3g'), Comment(id='k6d2fjy'), Comment(id='k6apnng'), Comment(id='k6awfjp'), Comment(id='k6bb307'), Comment(id='k6bdrl9'), Comment(id='k6bsjkn'), Comment(id='k6cfd76'), Comment(id='k6csmpe'), Comment(id='k6cvabi'), Comment(id='k6d8ft0'), Comment(id='k6dbunh'), Comment(id='k6dwjyg'), Comment(id='k6euy2c'), Comment(id='k6ahzae'), Comment(id='k6c4n9w'), Comment(id='k6d0jp7'), Comment(id='k6dibik'), Comment(id='k6cl1l6'), Comment(id='k6cx380'), Comment(id='k6d082p'), Comment(id='k6drap0'), Comment(id='k6dtv9d'), Comment(id='k6cj8ut'), Comment(id='k6ckrl4'), Comment(id='k6f87w5'), Comment(id='k6f9uqy'), Comment(id='k6ficil'), Comment(id='k7so3vl'), Comment(id='k6azt4x'), Comment(id='k6aq5nh'), Comment(id='k6cmsu6'), Comment(id='k6aiigi'), Comment(id='k6ab30n'), Comment(id='k6enkby'), Comment(id='k6agm4s'), Comment(id='k6bu2ab'), Comment(id='k6ba8gr'), Comment(id='k6dwkb6'), Comment(id='k6btq98'), Comment(id='k6bo7u5'), Comment(id='k6dd0js'), Comment(id='k6dbve7'), Comment(id='k6b70yq'), Comment(id='k6aq46a'), Comment(id='k6adpso'), Comment(id='k6dfsyf'), Comment(id='k6dnh7j'), Comment(id='k6jppm9'), Comment(id='k6apvvd'), Comment(id='k6e8oa3'), Comment(id='k6gm0tj'), Comment(id='k6caima'), Comment(id='k6ilkwq')]"
17fw3zm,PerceptionHot9236,,2023-10-25 03:57:17+00:00,False,,False,False,True,False,/r/datascience/comments/17fw3zm/tech_stack/,Tech Stack,"Data Scientists of Reddit, what’s the tech Stack do you use? If you are working in MAANG companies or dealing with huge huge amounts of data, does normal machine learning algorithms work? Is Big Data stack( Hadoop, Spark..) part of your daily drive ? Do you use any other programming language, except Python/R for day to day usage? Are there any tools or technologies that are very useful but major part of the data people don’t know?

I’m Masters in Data Science student, I’m just wondering how real world works, all my projects/assignments just involve python, sklearn library and a famous dataset from kaggle.",datascience,https://www.reddit.com/r/datascience/comments/17fw3zm/tech_stack/,52,40,0.91,"[Comment(id='k6cv3fw'), Comment(id='k6cujt8'), Comment(id='k6cyvcm'), Comment(id='k6cx7po'), Comment(id='k6cnsfu'), Comment(id='k6cxg1b'), Comment(id='k6d880l'), Comment(id='k6dvvtz'), Comment(id='k6dwdwz'), Comment(id='k6ea8jx'), Comment(id='k6emjw9'), Comment(id='k6gqjld'), Comment(id='k6fzhqg'), Comment(id='k6g8rei'), Comment(id='k6gqca6'), Comment(id='k6gr8pa'), Comment(id='k6cnf6g'), Comment(id='k6cpqq0'), Comment(id='k6d44l5'), Comment(id='k6fktyq'), Comment(id='k6cylxj'), Comment(id='k6e1zwh'), Comment(id='k6czxva'), Comment(id='k6dj9gm'), Comment(id='k6emc14'), Comment(id='k6gxzjt'), Comment(id='k6czaan'), Comment(id='k6cogob'), Comment(id='k6e6moi'), Comment(id='k6gvcjn'), Comment(id='k6d11vp'), Comment(id='k6ejpe5'), Comment(id='k6d1s0w'), Comment(id='k6ef102'), Comment(id='k6foce4'), Comment(id='k6d5zx2'), Comment(id='k6ebwjy'), Comment(id='k6ex3wn'), Comment(id='k6dlsq3'), Comment(id='k6e19vz'), Comment(id='k6ec3ke'), Comment(id='k6f4bco'), Comment(id='k6i7ibb'), Comment(id='k6ezz18'), Comment(id='k6jfm5v'), Comment(id='k6gd5u3'), Comment(id='k6h8cx4'), Comment(id='k6kxih8'), Comment(id='k6gs2jb'), Comment(id='k6hatit'), Comment(id='k6q7ig8'), Comment(id='k6hgoiz'), Comment(id='k6hlh8w')]"
17g55zm,Total-Opposite-8396,,2023-10-25 13:44:41+00:00,False,,1698242330.0,False,True,False,/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,Need help understanding if the model here is overfitting or not.,"&#x200B;

[ ](https://preview.redd.it/4cikjimrrcwb1.png?width=1546&format=png&auto=webp&s=8aac443256e5e5f18497718aa7d928d143a41b9b)

I've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?

Edit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info.",datascience,https://www.reddit.com/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,13,7,0.74,"[Comment(id='k6e6wm1'), Comment(id='k6f2g10'), Comment(id='k6ekh71'), Comment(id='k6efn7n'), Comment(id='k6f3ys4'), Comment(id='k6e7f6u'), Comment(id='k6e8tmh'), Comment(id='k6ean7r'), Comment(id='k6eaqjt'), Comment(id='k6ebtiq'), Comment(id='k6ebxh2'), Comment(id='k6enfhm'), Comment(id='k6edxml')]"
17gnj7i,Nickaroo321,,2023-10-26 03:39:22+00:00,False,,False,False,True,False,/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/,How to get into data science entry level position with an engineering degree?,,datascience,https://www.reddit.com/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/,7,0,0.5,"[Comment(id='k6hskfe'), Comment(id='k6htymm'), Comment(id='k6i2rjt'), Comment(id='k6mf0a9'), Comment(id='k6i2lv9'), Comment(id='k6j3rae'), Comment(id='k6jccvi')]"
17g41qs,honeyplease,,2023-10-25 12:52:02+00:00,False,,False,False,True,False,/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,"Data scientists reporting to CTO/equivalent (1 step below CEO), what's your job title?",Any company size (please include in response if possible).,datascience,https://www.reddit.com/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,23,5,0.6,"[Comment(id='k6e0tgx'), Comment(id='k6e8la6'), Comment(id='k6ei2vj'), Comment(id='k6ef5qh'), Comment(id='k6ecyzh'), Comment(id='k6fa7bn'), Comment(id='k6givy1'), Comment(id='k6gvrsc'), Comment(id='k6h44s8'), Comment(id='k6efe68'), Comment(id='k6e8bpz'), Comment(id='k6ec37n'), Comment(id='k6hicnk'), Comment(id='k6r2qs8'), Comment(id='k6f60g6'), Comment(id='k6gnlit'), Comment(id='k6f7jbw'), Comment(id='k6hjjas'), Comment(id='k6efn5g'), Comment(id='k6rarud'), Comment(id='k6fkmnm'), Comment(id='k6gn5o3'), Comment(id='k6g01xy')]"
17gej5o,LucasSaysHello,,2023-10-25 20:41:31+00:00,False,,False,False,True,False,/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,Vector DB directory structuring - ideal?,"Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.

If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.

Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a ""big bucket"" structure in which everything is kept in the same place?",datascience,https://www.reddit.com/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,0,1,1.0,[]
17g7vsr,CarbonHero,,2023-10-25 15:49:51+00:00,False,,False,False,True,False,/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,Worthwhile to post personal and pro-bono projects under my company page in order to list experience?,"I have a company page and branding package set up on LinkedIn – is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?

Some details: I'm a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I've created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.",datascience,https://www.reddit.com/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,0,2,0.67,[]
17g9mzj,lucasso13,,2023-10-25 17:04:58+00:00,False,,False,False,True,False,/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,Cloud computing trends in data science," Hey there, fellow data science people,

I'm reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I'm having a bit of a struggle finding my first gig.

Here's where I need advice. I'm curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I'm learning a cloud platform that'll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.

And last but not least, I'm all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. 

Thank you a lot in advance",datascience,https://www.reddit.com/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,1,1,0.67,[Comment(id='k74uxx2')]
17g01rn,ade17_in,,2023-10-25 08:28:04+00:00,False,,False,False,True,False,/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,"[P][R] Test-Val scores, how much difference isn't problematic.","Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.

1. I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)
2. The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.

&#x200B;

https://preview.redd.it/nseqy1mw5bwb1.png?width=577&format=png&auto=webp&s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58

Do share any experiences or suggestions!",datascience,https://www.reddit.com/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,0,3,1.0,[]
17g1rz7,sigma_chungus,,2023-10-25 10:37:10+00:00,False,,False,False,True,False,/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,Choosing between google data studio (Looker studio now I guess) and Tableau.,"Hey there. 
We are going to start working with Google sheets and podio.
We wanted to know which tool would be easier to learn and start working with. 
We are still beginners and we don't have access to paid versions and I got confused searching online.

What would be the pros and cons of using each tool. 

Thanks in advance.",datascience,https://www.reddit.com/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,3,1,0.6,"[Comment(id='k6dlbdu'), Comment(id='k6g5fmo'), Comment(id='k6ge41y')]"
17fthoj,MaAleem,,2023-10-25 01:41:20+00:00,False,,False,False,True,False,/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,keras tuner vs keras classifier vs neural network search,"i know this technique called keras tuner for tuning the model's hyperparameters . and then i also found that using for loop we can also select number of layers . and then i heard of this keras classifier that is used to search optimum number of layers and one more technique i head of is NAS Neural Network Search .   


keras tuner vs ( keras classifier ) keras.wrappers.scikit-learn.kerasClassifier vs neural network search (NAS)

can someone please help me with the difference among these three and what cases each can be considered ?",datascience,https://www.reddit.com/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,2,3,1.0,"[Comment(id='k6fovnd'), Comment(id='k6fw0b8')]"
17fytrb,mint_warios,,2023-10-25 06:55:35+00:00,False,,False,False,True,False,/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,The role of data scientists in NLP,"As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it's not ""advanced prompt engineering""?",datascience,https://www.reddit.com/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,22,0,0.44,"[Comment(id='k6d9may'), Comment(id='k6d7rnq'), Comment(id='k6d7qeu'), Comment(id='k6dcnlj'), Comment(id='k6de183'), Comment(id='k6du8ql'), Comment(id='k6ds7ui'), Comment(id='k6db6rb'), Comment(id='k6fae18'), Comment(id='k6de9tv'), Comment(id='k6di34a'), Comment(id='k6dehtu'), Comment(id='k6dxj71'), Comment(id='k6e0wbw'), Comment(id='k6eyv2q'), Comment(id='k6djsje'), Comment(id='k6dxum9'), Comment(id='k6e2bse'), Comment(id='k6dmyh5'), Comment(id='k6f00o3'), Comment(id='k6e51tm'), Comment(id='k6e56dy')]"
17eu3rm,wagwagtail,,2023-10-23 20:23:38+00:00,False,,1698095922.0,False,True,False,/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,Contractors who are called Data Scientists but can't do what I'd expect. What to do next.,"Ok so, I was hired as a senior member of a pre-existing data science team. I now manage a few other team members (who were there before me). They are all contractors and their day rate is HIGH. They are all 'Data Scientists' and graduates.

I'm older. I've done lots of technical roles and I'm not really sure what my official title is. I can do data science but I really just build stuff. I've done Data Engineering in the past, MLOps, DevOps, Cloud etc. I'm a jack of all trades, master of none.

Now, I know what ***I think*** a 'Data Scientist' should be able to do:

1. Pandas, Numpy, Scikit learn, matplotlib blah blah blah
2. Version control (Git)
3. Managing virtual environments
4. Debugging within an IDE
5. Scoping out a project, ideation, exploration
6. Report writing skills/communication skills
7. Some exposure to clean code conventions (PEP-8)
8. Some exposure to SQL like syntax
9. bit of linux would be cool (I can teach them)
10. bit of cloud would be cool (I can teach them)

I've had to mentor the team HARD. Most of the team did not know what Git was, most of the team had never debugged their code, never made a venv. In fact I have had to teach them steps 1-5. That would be fine if they were now hitting the ground running, but the moment I stop mentoring them, the productivity stops. No initiative.

And yet, I want to hire externally. I want to give them the opportunity to apply but I just know they won't measure up against the talent pool out there. I've hired Data Scientists before and I know how good people are out there.

Am I totally wrong? Do I need to cut them some slack? Anyone got any comments?

edit: spelling",datascience,https://www.reddit.com/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,198,212,0.94,"[Comment(id='k65pr3d'), Comment(id='k65toz9'), Comment(id='k65ld63'), Comment(id='k65s0tu'), Comment(id='k65v93g'), Comment(id='k65ypi4'), Comment(id='k66iui6'), Comment(id='k65vs6l'), Comment(id='k65ylsl'), Comment(id='k65w2k0'), Comment(id='k670dsb'), Comment(id='k65pm94'), Comment(id='k66kjp9'), Comment(id='k65xiy2'), Comment(id='k65xegj'), Comment(id='k66ixd1'), Comment(id='k66j28p'), Comment(id='k66jbf7'), Comment(id='k66u4aq'), Comment(id='k67178i'), Comment(id='k67vh6k'), Comment(id='k68hf21'), Comment(id='k68lk0r'), Comment(id='k68nsgd'), Comment(id='k66i9g8'), Comment(id='k66jxtl'), Comment(id='k664mvl'), Comment(id='k665s57'), Comment(id='k667pn7'), Comment(id='k66mx7x'), Comment(id='k66pinj'), Comment(id='k66wtcp'), Comment(id='k66ztau'), Comment(id='k67nfw9'), Comment(id='k68937z'), Comment(id='k68zdhf'), Comment(id='k693j7x'), Comment(id='k698vzf'), Comment(id='k69fprc'), Comment(id='k6c5zhb'), Comment(id='k65yr2k'), Comment(id='k65zr5h'), Comment(id='k65tv30'), Comment(id='k65tlix'), Comment(id='k65w72l'), Comment(id='k66eri4'), Comment(id='k66fm1c'), Comment(id='k66gd3h'), Comment(id='k66hvue'), Comment(id='k66o3fx'), Comment(id='k66oko3'), Comment(id='k66tgk0'), Comment(id='k66ui6s'), Comment(id='k66ya1t'), Comment(id='k671le7'), Comment(id='k672raq'), Comment(id='k676d8e'), Comment(id='k67jhz8'), Comment(id='k67pfm3'), Comment(id='k67r3kk'), Comment(id='k67sck1'), Comment(id='k67xw12'), Comment(id='k67yziu'), Comment(id='k686t5q'), Comment(id='k68c25t'), Comment(id='k68kiw6'), Comment(id='k68l5al'), Comment(id='k68o1o0'), Comment(id='k68ojlo'), Comment(id='k68vrqu'), Comment(id='k68ws5o'), Comment(id='k697nkm'), Comment(id='k69d6v0'), Comment(id='k69ilfr'), Comment(id='k69n2ul'), Comment(id='k69oo8o'), Comment(id='k69q7au'), Comment(id='k69qw0z'), Comment(id='k6a28o7'), Comment(id='k6a64uv'), Comment(id='k6a6oe9'), Comment(id='k6ae7ir'), Comment(id='k6ai62s'), Comment(id='k6aimpe'), Comment(id='k6amw9j'), Comment(id='k6aucnu'), Comment(id='k6b7p23'), Comment(id='k6bi76k'), Comment(id='k6bmq08'), Comment(id='k6bysio'), Comment(id='k6cmqnt'), Comment(id='k6cveae'), Comment(id='k6e2wbb'), Comment(id='k6ergu7'), Comment(id='k6mmtlk'), Comment(id='k6rr7oj'), Comment(id='k6xe9ct'), Comment(id='k67saqm'), Comment(id='k6cka7w'), Comment(id='k68s2nu'), Comment(id='k65twv1'), Comment(id='k67iigc'), Comment(id='k65lppg'), Comment(id='k65sbeo'), Comment(id='k675pp8'), Comment(id='k667egb'), Comment(id='k675itl'), Comment(id='k661m8d'), Comment(id='k674hhw'), Comment(id='k697r5m'), Comment(id='k65w0yr'), Comment(id='k65xqf9'), Comment(id='k67rdur'), Comment(id='k6904a2'), Comment(id='k69t0in'), Comment(id='k65q2mm'), Comment(id='k67tike'), Comment(id='k661mio'), Comment(id='k681i16'), Comment(id='k6bfqjg'), Comment(id='k68krkc'), Comment(id='k66k9n6'), Comment(id='k66pwr1'), Comment(id='k68x04l'), Comment(id='k664sl2'), Comment(id='k66qd7a'), Comment(id='k67cod7'), Comment(id='k67d9zs'), Comment(id='k67b50p'), Comment(id='k6e3jn3'), Comment(id='k65zc9p'), Comment(id='k6698c0'), Comment(id='k65u4w1'), Comment(id='k65xm9m'), Comment(id='k68w9sw'), Comment(id='k697w34'), Comment(id='k6854po'), Comment(id='k65unkq'), Comment(id='k68mmdj'), Comment(id='k6a14z6'), Comment(id='k66ifpl'), Comment(id='k65mqcu'), Comment(id='k65t6c9'), Comment(id='k6a7y07'), Comment(id='k668xmo'), Comment(id='k6627em'), Comment(id='k67y789'), Comment(id='k65y97s'), Comment(id='k6bqn88'), Comment(id='k6axjoz'), Comment(id='k66fhrb'), Comment(id='k687wag'), Comment(id='k68muxo'), Comment(id='k6761s3'), Comment(id='k6658h9'), Comment(id='k664zov'), Comment(id='k688axv'), Comment(id='k68h0r9'), Comment(id='k6fjcf9'), Comment(id='k65uer7'), Comment(id='k6982l1'), Comment(id='k69lbsc'), Comment(id='k69xx33'), Comment(id='k69o5qs'), Comment(id='k67fa2p'), Comment(id='k6710a5'), Comment(id='k6dnvan'), Comment(id='k65tgbm'), Comment(id='k66oxqi'), Comment(id='k68cc0q'), Comment(id='k6l2fgc'), Comment(id='k66iumh'), Comment(id='k67ymvn'), Comment(id='k665eoa'), Comment(id='k6g7v4z'), Comment(id='k65uwo6'), Comment(id='k69qzzr'), Comment(id='k67q6sk'), Comment(id='k662e7s'), Comment(id='k6610ar'), Comment(id='k66tg38'), Comment(id='k68fvnj'), Comment(id='k67287z'), Comment(id='k6737pi'), Comment(id='k6jcntk'), Comment(id='k65v2wl'), Comment(id='k662vht'), Comment(id='k67m69e'), Comment(id='k67yvcr'), Comment(id='k68tfmu'), Comment(id='k677vwd'), Comment(id='k65vbxb'), Comment(id='k67swgc'), Comment(id='k6a7fex'), Comment(id='k67p4ay'), Comment(id='k65vg1m'), Comment(id='k6abnqc'), Comment(id='k65vt1p')]"
17fzyic,PaulLaughlin,,2023-10-25 08:21:07+00:00,False,,False,False,False,False,/r/datascience/comments/17fzyic/human_behaviour_is_more_complex_than_too_much/,Human behaviour is more complex than too much shallow analysis (why you need to dig deeper),,datascience,https://www.customerinsightleader.com/opinion/human-behaviour-is-more-complex-than-too-much-shallow-analysis/,2,0,0.3,"[Comment(id='k6dl5et'), Comment(id='k6dl6p0')]"
17ffp2f,cooljackiex,,2023-10-24 15:37:22+00:00,False,,False,False,True,False,/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,Consulting for coffee shops,Does anyone have experience consulting for small businesses like coffee shops or even smaller stores? There's a store near me that I would love to offer my services to for free -- but not sure how I can present myself as being useful to them and wanting them to actually work with me.,datascience,https://www.reddit.com/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,10,3,0.72,"[Comment(id='k6alhbk'), Comment(id='k6a23qe'), Comment(id='k6agb5o'), Comment(id='k6boj3k'), Comment(id='k6dqjc4'), Comment(id='k6ct2ch'), Comment(id='k6a2ixm'), Comment(id='k6d9qh9'), Comment(id='k6ej6lj'), Comment(id='k6fq2oe')]"
17fdltj,RandomBarry,,2023-10-24 14:03:55+00:00,False,,False,False,True,False,/r/datascience/comments/17fdltj/mysql_to_big_data/,"Mysql to ""Big Data""","Hi Folks,

Looking for some advice, have an ecommerce store, decent volume of data in 10m orders over the past few years etc. \~ 10GB of data.

Was looking to get the data into data studio (looker), crashed. Then looked at power bi, crashed on publishing just the order data (\~1GB)

Are there alternatives? What would the best sync to a reporting tool be?",datascience,https://www.reddit.com/r/datascience/comments/17fdltj/mysql_to_big_data/,20,4,0.67,"[Comment(id='k69f1mx'), Comment(id='k6a4739'), Comment(id='k6abumm'), Comment(id='k6czuv9'), Comment(id='k695950'), Comment(id='k6bybhb'), Comment(id='k6anw6u'), Comment(id='k6d5j5d'), Comment(id='k6ao1z3'), Comment(id='k69yzw2'), Comment(id='k6exqa6'), Comment(id='k6ay96f'), Comment(id='k6a045y'), Comment(id='k6f0fbk'), Comment(id='k6a0q7j'), Comment(id='k6a2j6d'), Comment(id='k6ao3yk'), Comment(id='k6a53ec'), Comment(id='k6a7tbn')]"
17fjeyw,hasty-beaver,,2023-10-24 18:18:28+00:00,False,,False,False,True,False,/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,"In the context of topic modeling, what should be done when the highest coherence value, given a specific 'k' value and a particular metric, does not result in interpretable topics?","Hi everyone,

I'm currently working on an LDA Topic Modeling project applied to a specific field. Essentially, I want to label different subcategories within this field. The data I'm dealing with is relatively complex and messy.

While I'm aware of the ongoing challenge of automatic topic modeling, which still requires human judgment and supervision after topics have been generated, I've read that certain metrics attempt to replace human judgment when it comes to evaluating the coherence of words within a topic (like C\_V metric). Thus, they need to be maximized (I suppose?).

However, I've also read that the most crucial consideration, in the end, is to create topics that are understandable to humans.

I find myself in a situation where I have a larger number of topics, let's say 7 < k < 10, where the Coherence metric (C\_V) peaks at 0.48, which, based on what I've read, seems like a good score. However, what happens is that, for the most, the topics themselves do not make sense at all. 

In contrast, when I set my number of topics to 3-4, I have much more interpretable topics. This might be because of the implication of summarization, which means fewer topics that gather more latent topics within the same topic.

Considering that this project is being revised by a professor, how can I justify what is going on? I know that there's specific literature out there stating that Coherence is not an entirely reliable judgement parameter, but haven't managed to find anything consistent. 

Thank you.",datascience,https://www.reddit.com/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,2,1,1.0,"[Comment(id='k6azcp6'), Comment(id='k6dtegr')]"
17esy03,htii_,,2023-10-23 19:34:26+00:00,False,,False,False,True,False,/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,"Outside of Generative AI, what are the big advances currently happening in Data Science?","There's been a lot of chatter about AI, specifically things like LLAMA 2, GPT-4, etc. But, what have been some recent advancements not in the AI sphere that are important in Data Science?",datascience,https://www.reddit.com/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,34,50,0.9,"[Comment(id='k66dk2t'), Comment(id='k66avg6'), Comment(id='k66lfeg'), Comment(id='k671ttt'), Comment(id='k66p54b'), Comment(id='k6830t2'), Comment(id='k6764p5'), Comment(id='k67yiek'), Comment(id='k6a0suj'), Comment(id='k6hk65a'), Comment(id='k68p658'), Comment(id='k680kse'), Comment(id='k68d230'), Comment(id='k6ahjdt'), Comment(id='k66s27r'), Comment(id='k66qq3e'), Comment(id='k68tu8k'), Comment(id='k68xaoj'), Comment(id='k671w58'), Comment(id='k785asj'), Comment(id='k6ahuo6'), Comment(id='k68m36l'), Comment(id='k6a71be'), Comment(id='k69e6ra'), Comment(id='k69adkb'), Comment(id='k6a1pqf'), Comment(id='k68k4my'), Comment(id='k69xoa1'), Comment(id='k69wmyh'), Comment(id='k6cfy7j'), Comment(id='k6c6f64'), Comment(id='k6cmvjm'), Comment(id='k6i6hno'), Comment(id='k6dcq6f'), Comment(id='k6i82bl')]"
17eot80,Alucard2051,,2023-10-23 16:39:32+00:00,False,,False,False,True,False,/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,What do you do in SQL vs Pandas?,"My work primarily stores data in a full databases. Pandas has a lot of similar functionality to SQL in regards to the ability to group data and preform calculations, even being able to take full on SQL queries to import data. Do you guys do all your calculations in the query itself, or in python after the data has been imported? What about with grouping data?",datascience,https://www.reddit.com/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,64,64,0.94,"[Comment(id='k64r5sd'), Comment(id='k64l7t8'), Comment(id='k64l887'), Comment(id='k65h29d'), Comment(id='k65jmxt'), Comment(id='k65hrki'), Comment(id='k66koip'), Comment(id='k64ljh0'), Comment(id='k64msly'), Comment(id='k64ypmr'), Comment(id='k64vgk2'), Comment(id='k67b23o'), Comment(id='k67spdn'), Comment(id='k660495'), Comment(id='k662wlc'), Comment(id='k67jqt6'), Comment(id='k66q2ss'), Comment(id='k64pdap'), Comment(id='k64tzrk'), Comment(id='k65j73g'), Comment(id='k666kyo'), Comment(id='k686vjr'), Comment(id='k68c9fu'), Comment(id='k69a9kw'), Comment(id='k69rl3w'), Comment(id='k69sj76'), Comment(id='k69whph'), Comment(id='k6ae5gh'), Comment(id='k6agkg3'), Comment(id='k6agy2y'), Comment(id='k6ndhay'), Comment(id='k7533m5'), Comment(id='k65vfpz'), Comment(id='k66w1ps'), Comment(id='k66ueec'), Comment(id='k66q0mo'), Comment(id='k65xeza'), Comment(id='k662p0i'), Comment(id='k65ttuw'), Comment(id='k66fmuw'), Comment(id='k6g6bfg'), Comment(id='k66geez'), Comment(id='k683spg'), Comment(id='k6g71n3'), Comment(id='k664dpz'), Comment(id='k66q3y1'), Comment(id='k64q1kj'), Comment(id='k65gsp8'), Comment(id='k68dd5l'), Comment(id='k67ua27'), Comment(id='k662h4o'), Comment(id='k6g6g32'), Comment(id='k66n7at'), Comment(id='k69b1ca'), Comment(id='k665cp3'), Comment(id='k65up3t'), Comment(id='k68ny79'), Comment(id='k663jw6'), Comment(id='k66q0ie'), Comment(id='k6bl9no'), Comment(id='k67eee9'), Comment(id='k68vfvv'), Comment(id='k665cwr')]"
17el93s,NewEcho2940,,2023-10-23 14:07:26+00:00,False,,False,False,True,False,/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,What do fellow Data Science Directors do?,"I am a director and I feel like I barely do ""Data Science"" any more. My job is mostly about working with engineers and architects to facilitate data collection and data tools (python, spark) for my team. Is this relevant for career advancement or do I need to refocus more on hard skills and learning new stuff.",datascience,https://www.reddit.com/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,41,83,0.95,"[Comment(id='k640rvt'), Comment(id='k63w0zo'), Comment(id='k641kqk'), Comment(id='k645bqs'), Comment(id='k64auvc'), Comment(id='k642vmr'), Comment(id='k647z56'), Comment(id='k64d05u'), Comment(id='k64wr5v'), Comment(id='k655siu'), Comment(id='k65vrbq'), Comment(id='k63wuy4'), Comment(id='k64mmad'), Comment(id='k64aa29'), Comment(id='k66f1or'), Comment(id='k66n66v'), Comment(id='k67edlf'), Comment(id='k6bm67b'), Comment(id='k645sb8'), Comment(id='k641xvv'), Comment(id='k63zfy8'), Comment(id='k63yb49'), Comment(id='k647yw3'), Comment(id='k64h3s9'), Comment(id='k65x326'), Comment(id='k63y2ly'), Comment(id='k64h6a5'), Comment(id='k64ifjx'), Comment(id='k65ogwo'), Comment(id='k65kpvb'), Comment(id='k63zi0j'), Comment(id='k64wn7x'), Comment(id='k65t0by'), Comment(id='k66lc6b'), Comment(id='k63zxnx'), Comment(id='k64gxvv'), Comment(id='k652j4h'), Comment(id='k643z5v'), Comment(id='k642ih7'), Comment(id='k6457up'), Comment(id='k64jaxv'), Comment(id='k66ysyh')]"
17fbj3u,Thinker_Assignment,,2023-10-24 12:24:31+00:00,False,,False,False,True,False,/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,ConnectorX + Arrow + dlt loading: Up to 30x speed gains in test,"Hey folks

over at [https://pypi.org/project/dlt/](https://pypi.org/project/dlt/) we added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -> analytics copying can go up to 30x faster over a classic sqlite connector.

Read about the benchmark comparison and the underlying technology here: [https://dlthub.com/docs/blog/dlt-arrow-loading](https://dlthub.com/docs/blog/dlt-arrow-loading)

One disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine or batch on extraction. Code example how to use: [https://dlthub.com/docs/examples/connector\_x\_arrow/](https://dlthub.com/docs/examples/connector_x_arrow/)

By adding this support, we also enable these sources:[https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas](https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas)

If you need help, don't miss the gpt helper link at the bottom of our docs or the slack link at the top.

Feedback is very welcome!

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,0,1,1.0,[]
17er8bt,Dependent_Mushroom98,,2023-10-23 18:22:45+00:00,False,,False,False,True,False,/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,"Besides FAANG, what other companies out there are doing actual DS or MLE work?","In my present company we are just chasing ad hoc analytical  work - these never gets into production. The processes are very ad hoc, not streamlined, no structure to it, running from personal notebooks. It’s very demoralizing to see models developed from 2017 that are in production and have not been refreshed thought the data it used for inference is constantly changing as my company looks at market finance data. 

I’m wondering what are other good companies to look out for that are either applying best practices in DS/ML and not just the talk or building product/services. 

I understand recent news in GenAI is sparking lot of conversations but which companies out there are grabbing it by the horns and taking the lead? Perhaps if you are fortunate to work for one such company you may want to share your story. Appreciate your insights very much!",datascience,https://www.reddit.com/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,17,20,0.76,"[Comment(id='k6549xo'), Comment(id='k657byg'), Comment(id='k65oihw'), Comment(id='k65ivyp'), Comment(id='k66rjlq'), Comment(id='k6cyzeu'), Comment(id='k6674ft'), Comment(id='k66s2bl'), Comment(id='k6657r0'), Comment(id='k67ou44'), Comment(id='k69nfiy'), Comment(id='k6b1q1o'), Comment(id='k6cm7n6'), Comment(id='k6574i0'), Comment(id='k65o7di'), Comment(id='k67s98g'), Comment(id='k65pcgb')]"
17eiqbl,helliun,,2023-10-23 12:03:41+00:00,False,,False,False,False,False,/r/datascience/comments/17eiqbl/pandasbased_library_for_graphing_emotion_events/,Pandas-based library for graphing emotion events with LMs for in-depth sentiment analysis,,datascience,https://i.redd.it/hdls4kgrzxvb1.jpg,6,50,0.96,"[Comment(id='k63edjy'), Comment(id='k63j8xe'), Comment(id='k64kb5d'), Comment(id='k64nhe2'), Comment(id='k64ogtg'), Comment(id='k650q78')]"
17f7jo6,QFA_official,,2023-10-24 07:59:09+00:00,False,,False,False,True,False,/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,Machine learning for Asset Allocation and long/short decisions in a Tactical Asset Allocation Strategy,"&#x200B;

I'd love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I'd love to hear any thoughts on Machine Learning directly applicable to time-series data specifically here I am applying machine learning to drive asset allocation in an investmen portfolio

[https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model](https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model)

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,0,1,0.67,[]
17efkcz,limedove,,2023-10-23 08:32:14+00:00,False,,False,False,True,False,/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/,What are the non-data scientist tasks that you still do in your data scientist role?,,datascience,https://www.reddit.com/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/,69,64,0.92,"[Comment(id='k62x1cj'), Comment(id='k63bs6s'), Comment(id='k633wh0'), Comment(id='k641xuv'), Comment(id='k63kdpb'), Comment(id='k658kkp'), Comment(id='k639vvi'), Comment(id='k63az12'), Comment(id='k647cdh'), Comment(id='k63tkxo'), Comment(id='k657zv2'), Comment(id='k66aoy2'), Comment(id='k63gg2w'), Comment(id='k62xnv7'), Comment(id='k63v5uy'), Comment(id='k642twt'), Comment(id='k660ngc'), Comment(id='k69gvcu'), Comment(id='k63djd4'), Comment(id='k63mven'), Comment(id='k64tfo0'), Comment(id='k63tstv'), Comment(id='k64q7na'), Comment(id='k65sc0j'), Comment(id='k66vnmr'), Comment(id='k68hxay'), Comment(id='k69nn44'), Comment(id='k6aawwc'), Comment(id='k6dm0jm'), Comment(id='k644naf'), Comment(id='k63eacx'), Comment(id='k63l6fn'), Comment(id='k64hjhn'), Comment(id='k63we5c'), Comment(id='k6873jb'), Comment(id='k647adk'), Comment(id='k64nx12'), Comment(id='k6584uf'), Comment(id='k63safw'), Comment(id='k6417oc'), Comment(id='k63960e'), Comment(id='k64c2x1'), Comment(id='k63x3wb'), Comment(id='k63u7jh'), Comment(id='k6dnmx1'), Comment(id='k6dnpck'), Comment(id='k64vz8k'), Comment(id='k680wvo'), Comment(id='k66oyz2'), Comment(id='k63n5hs'), Comment(id='k645321'), Comment(id='k642m7g'), Comment(id='k67cg2r'), Comment(id='k63g15a'), Comment(id='k64cafs'), Comment(id='k63uyd6'), Comment(id='k6fd8ux'), Comment(id='k63rn95'), Comment(id='k64y1mv'), Comment(id='k661ssq'), Comment(id='k69fxip'), Comment(id='k644weq'), Comment(id='k64efbi'), Comment(id='k64bnhb'), Comment(id='k65vnwl'), Comment(id='k645hua'), Comment(id='k64ki7t'), Comment(id='k65ho6q'), Comment(id='k67bvrc'), Comment(id='k67xzqv')]"
17f6c47,Efficient-Middle-701,,2023-10-24 06:31:46+00:00,False,,False,False,True,False,/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,Data science in floriculture/horticulture,Anyone having experience in this sector? Looking for a seasoned data scientist in this sector,datascience,https://www.reddit.com/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,1,1,1.0,[Comment(id='k6awln3')]
17f3whi,unknow_from_vietnam,,2023-10-24 03:58:06+00:00,False,,False,False,True,False,/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,[Discussion] Paraphrase for Writing Tone,"Hi Everyone,

Recently, I have been doing a task related to paraphrasing in writing tones. Specifically, I'm trying to fine-tune the pre-trained model (text generation model) to create a model capable of rewriting according to the transmitted tone.

Currently, I am trying to crawl data (about 1500 samples) for training. However, the results were not as good as I thought. I'm currently quite stuck, can you guys suggest to me some research or open-source or pre-trained models that you've tried?

Thank you

P/s: model I have tried

[https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic](https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic)

[https://huggingface.co/Vamsi/T5\_Paraphrase\_Paws](https://huggingface.co/Vamsi/T5_Paraphrase_Paws)

[https://huggingface.co/humarin/chatgpt\_paraphraser\_on\_T5\_base](https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base)",datascience,https://www.reddit.com/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,0,0,0.5,[]
17f02jx,citizenofacceptance,,2023-10-24 00:46:13+00:00,False,,1698109573.0,False,True,False,/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,Anyone have a good blog or resource on Product-led experimentation?,"Would be nice to understand frameworks , experiment types, how to determine what experiment to use , and where and when to apply them to a saas company and help them prioritize a roadmap against it. 
",datascience,https://www.reddit.com/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,8,1,1.0,"[Comment(id='k678scn'), Comment(id='k678a6k'), Comment(id='k66r3d3'), Comment(id='k66wqi2'), Comment(id='k66s8hw'), Comment(id='k66w2bd'), Comment(id='k66wer5'), Comment(id='k676ts2')]"
17eug5a,FrozenSoul90,,2023-10-23 20:37:58+00:00,False,,False,False,True,False,/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,Any pointers / resources on how one would implement a ML model for product demand transference and substititabilty,"I am currently undergoing Apprenticeships programme for ML, and looking for projects in our organization.

""Demand Transference and Substititabilty"" in retail food stores is one of the ideas that came up. So i am trying to find on how to implement it and if we have all the required data before finalising the project selection. 

Any resources or information would be great :)",datascience,https://www.reddit.com/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,2,2,0.75,"[Comment(id='k67wu40'), Comment(id='k68tgwu')]"
17eu7oy,ExpressOcelot8977,,2023-10-23 20:28:20+00:00,False,,False,False,True,False,/r/datascience/comments/17eu7oy/why_would_anyone_start_to_use_hex_whats_the_need/,Why would anyone start to use Hex? What’s the need or situation?,,datascience,https://www.reddit.com/r/datascience/comments/17eu7oy/why_would_anyone_start_to_use_hex_whats_the_need/,15,2,0.58,"[Comment(id='k65xff5'), Comment(id='k65ty20'), Comment(id='k66i3yt'), Comment(id='k67pjon'), Comment(id='k67b2at'), Comment(id='k67ppq3'), Comment(id='k68eutk'), Comment(id='k675ukh'), Comment(id='k67q1j9'), Comment(id='k6a5x8o'), Comment(id='k6814s7'), Comment(id='k6a78n0'), Comment(id='k6a5qrv'), Comment(id='k6ane69'), Comment(id='k6avx9k')]"
17ew2w4,bbmr__95,,2023-10-23 21:45:22+00:00,False,,False,False,True,False,/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,Estimating sales of a new store,"I've got the task to estimate the sales level of a store in a place near a mall and a office area. Would like to know if somebody here has made a similar task reacently or has any idea of how can i get an estimation.

I have data of 6 more stores of the same company (sales, transactions, area fo the store, #people near a 15 minute isochrone, if the stores are near offices, colleges, residential areas, etc).

I've been planning to run a regression model or a decision tree and later use trained model to estimate the sales level of the new position, but just having 6 stores makes it hard to have a consistent estimation.

What other options could i do to have a good estimation of this new position? what other things i have to consider o look for to have as data in my model? is there any framework for this kind of task?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,4,1,1.0,"[Comment(id='k664obo'), Comment(id='k7mt2ok'), Comment(id='k6b6djh'), Comment(id='k6bfseu')]"
17euytw,Notgen3ric,,2023-10-23 20:59:51+00:00,False,,False,False,True,False,/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,Best way to go about showing progress as work is done to a dataset,"Hello there,

I'm an undergrad student that is currently working on a Kaggle dataset and I want to document my progression and be able to share it as I go. In addition, I'd really want to get involved with the DS community. Now, I do have deficiency in certain tools like GitHub which is a place I could post my work. However, I do also want to be able to include it in my resume as I think it would make it more appealing for recruiters in the future. What is the best way to go about this? Just create a reddit or LinkedIn Post (like a progress post) or simply just have it up on GitHub and learn how to use the tool ? Thank you in advance for your suggestions.",datascience,https://www.reddit.com/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,7,1,0.6,"[Comment(id='k65tomo'), Comment(id='k67faim'), Comment(id='k662ouo'), Comment(id='k65zjen'), Comment(id='k6bfssh'), Comment(id='k679ywx'), Comment(id='k6edwv8')]"
17eriso,oh5oh5,,2023-10-23 18:35:12+00:00,False,,False,False,True,False,/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,PG extension (Apache AGE) for adding graph analytics functionality,"I have talked this previously, that like, I am working as a data analyst but is it worth to learn graph database. I got some comments that saying master SQL first, then learn other tools. For me, learning a new fun tool is for my free time so I thought, OK, I will just try it. It is been a month almost and came back to think like,,, I don't feel the graph database is that much worth to learn especially if I consider the size of the market.

However, maybe, if there's a PG extension that adds graph analytics to PG database, which I use everyday, it would be fun because I can actually utilize it with my PG data. Apache AGE is an open-source PG extension that really solves the problem that I'm having right now. I will leave the [github link](https://github.com/apache/age) and a [webinar link](https://us06web.zoom.us/webinar/register/2516980853755/WN_mzhlCggCQ_ytIxiGb9ioTg) that they (I guess Apache Foundation?) organize like bi-weekly. For those who are having same thought process with me, I think you guys also can just try? What do you think?",datascience,https://www.reddit.com/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,0,1,1.0,[]
17erhca,Dependent_Mushroom98,,2023-10-23 18:33:25+00:00,False,,False,False,True,False,/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,Relational database to graph database using NLP/LLM?,I’m looking to discover new relationships that exist in the relational database and then generate ingestion script to populate a graph database. Are there tools already exhausting for this and what are their limitations? Can we he new LLMs come to rescue?,datascience,https://www.reddit.com/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,0,1,1.0,[]
17epzut,ConsiderationRoyal87,,2023-10-23 17:29:20+00:00,False,,1698088665.0,False,True,False,/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,Good survey of predictive techniques?,"Currently on a job search, and of course many DS roles are seeking prediction/forecasting skills. Can anyone recommend an overview of different predictive techniques? It could be an article, video, book, or even your own explanation.

There are so many things one could learn about regression, machine learning, etc. and I would find it useful to have some sort of organizing framework for various methods of prediction.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,5,0,0.4,"[Comment(id='k66vzqt'), Comment(id='k66dozv'), Comment(id='k64unqy'), Comment(id='k66sxpm'), Comment(id='k66wfi1')]"
17dtmqe,jumpi3y,,2023-10-22 13:45:03+00:00,False,,False,False,True,False,/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,How do you guys practise using MySQL,Hi I'm fairly new to Data Science and I'm only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?,datascience,https://www.reddit.com/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,74,153,0.95,"[Comment(id='k5z2y4s'), Comment(id='k5zkb8i'), Comment(id='k5z3qzk'), Comment(id='k5yy66e'), Comment(id='k62frdx'), Comment(id='k5yt8gt'), Comment(id='k5zl4l8'), Comment(id='k5z2vfo'), Comment(id='k5ztdl3'), Comment(id='k5ywyd6'), Comment(id='k5zhivr'), Comment(id='k5zmun3'), Comment(id='k61i8aq'), Comment(id='k62whf4'), Comment(id='k5zwqzc'), Comment(id='k61itgf'), Comment(id='k5zk4ic'), Comment(id='k5zn9cs'), Comment(id='k5zp94o'), Comment(id='k5zv9or'), Comment(id='k604blo'), Comment(id='k604ycs'), Comment(id='k60d18d'), Comment(id='k60di6n'), Comment(id='k60dkyc'), Comment(id='k60g554'), Comment(id='k610zr5'), Comment(id='k6114ka'), Comment(id='k61fhy1'), Comment(id='k61pgz9'), Comment(id='k61wfkr'), Comment(id='k61wtbo'), Comment(id='k61yg2l'), Comment(id='k620fq3'), Comment(id='k62267c'), Comment(id='k627nd9'), Comment(id='k62hu5q'), Comment(id='k62kwsq'), Comment(id='k63dlpe'), Comment(id='k64st70'), Comment(id='k64wt7d'), Comment(id='k656nso'), Comment(id='k5zetis'), Comment(id='k61cl6n'), Comment(id='k62i8cg'), Comment(id='k5z4log'), Comment(id='k60cy14'), Comment(id='k63uads'), Comment(id='k64qzjc'), Comment(id='k5zbwjy'), Comment(id='k5zm69n'), Comment(id='k5yzr8s'), Comment(id='k5z6rbf'), Comment(id='k60nndz'), Comment(id='k632i16'), Comment(id='k60b0rk'), Comment(id='k6280ik'), Comment(id='k63f6ec'), Comment(id='k5z7h25'), Comment(id='k65q68d'), Comment(id='k66huxq'), Comment(id='k5z4fg9'), Comment(id='k5z7j90'), Comment(id='k64uzhl'), Comment(id='k60zf7p'), Comment(id='k63lejq'), Comment(id='k5zjtjo'), Comment(id='k5zmice'), Comment(id='k6dirb0'), Comment(id='k6128l3'), Comment(id='k67wpon'), Comment(id='k62xkov'), Comment(id='k684ehr'), Comment(id='k68649l')]"
17enm4q,Pristine-Sound-484,,2023-10-23 15:49:48+00:00,False,,1698095309.0,False,True,False,/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,Address parsing with NLP or with regex,"Hi i am working on this a project and its a module of a huge project where i have to write code  to parse address provided.

I was first using Libpostal but for the provided data, libpostal is not effiecient and i want to create my custom parsing.

I am trying to use regex but it seems very complicated. Can anyone help me if there’s any other way .

I found it is possible using NLP with spaCy.

Please guide",datascience,https://www.reddit.com/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,12,0,0.5,"[Comment(id='k64diam'), Comment(id='k64v4fg'), Comment(id='k657ctj'), Comment(id='k64wq9c'), Comment(id='k65rpte'), Comment(id='k65rque'), Comment(id='k7sl1z9'), Comment(id='k651ap4'), Comment(id='k66ec0q'), Comment(id='k676u05'), Comment(id='k676sny'), Comment(id='k69poin')]"
17en64n,Individual-School-07,,2023-10-23 15:30:41+00:00,False,,False,False,True,False,/r/datascience/comments/17en64n/project_interface/,Project Interface.,"Hello,

I'm updating my Portfolio to get back to DS. Working on a project I'd like to put the algorithm into an interface. Is it better to try and do it using other programming languages like JavaScript or Python is sufficient using Flask or Streamlit ? ",datascience,https://www.reddit.com/r/datascience/comments/17en64n/project_interface/,2,1,1.0,"[Comment(id='k64vhi1'), Comment(id='k69b7p6')]"
17exd28,indusop,,2023-10-23 22:40:26+00:00,False,,False,False,False,False,/r/datascience/comments/17exd28/just_read_the_fascinating_article_about/,Just read the fascinating article about deployment of website using streamlit.How easy it has become to deploy and develop any website using this tool,,datascience,https://medium.com/@harshsmj1504/ipl-win-predictor-easy-streamlit-development-and-deployment-guide-bce15bce99b1,3,0,0.17,"[Comment(id='k67dyur'), Comment(id='k67sitd'), Comment(id='k6apmp6')]"
17em9tn,h3dgyy,,2023-10-23 14:53:56+00:00,False,,False,False,True,False,/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,Looking for a Data Science Program,I am a software engineer with 10yo experience. Can someone recommend a good Data Science program? I am willing to spend 3-6 months to get a deep understanding of the fundamentals.,datascience,https://www.reddit.com/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,2,0,0.5,"[Comment(id='k64gy1q'), Comment(id='k67k5ll')]"
17e01li,Aware_Value4603,,2023-10-22 18:38:37+00:00,False,,False,False,True,False,/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,Do you remember the syntax of the tools you use?,"To all the data science professionals, enthusiasts and learners, do y'all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? 

I have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there's also R, C++ and other languages that sometimes come into the picture. 

This made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. 

Also, if you use any resources which are popular, please share in the comments.",datascience,https://www.reddit.com/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,36,39,0.85,"[Comment(id='k6012ot'), Comment(id='k60bd67'), Comment(id='k60u0kw'), Comment(id='k61lrz3'), Comment(id='k616bch'), Comment(id='k61ie4d'), Comment(id='k61ei9w'), Comment(id='k61flcj'), Comment(id='k60oxu5'), Comment(id='k614bqo'), Comment(id='k61pw4d'), Comment(id='k61ynjq'), Comment(id='k622h1l'), Comment(id='k624byw'), Comment(id='k640h3u'), Comment(id='k61ltzq'), Comment(id='k60rmdt'), Comment(id='k61lfyb'), Comment(id='k62f9rf'), Comment(id='k618mq6'), Comment(id='k63zx5h'), Comment(id='k61zrcn'), Comment(id='k61vi3b'), Comment(id='k63z0sd'), Comment(id='k62h2by'), Comment(id='k61zg4y'), Comment(id='k63ho8s'), Comment(id='k63kfsf'), Comment(id='k61zmty'), Comment(id='k62hd7g'), Comment(id='k629o32'), Comment(id='k62s1sa'), Comment(id='k62hsxx'), Comment(id='k67ovw3'), Comment(id='k67oky3'), Comment(id='k67yat8')]"
17eh6kb,Asleep-Fun-6508,,2023-10-23 10:29:38+00:00,False,,False,False,True,False,/r/datascience/comments/17eh6kb/productivity_help/,Productivity help,"Happy monday guys! 

Quick question – what do you do on light days where you don’t have much(or any) work and want to maintain your productivity, especially when working from home? 

I would love to increase my theory/stress on learning new skills! So if you’re one who reads books/blogs would love to know what you guys read or any book recommendations

Cheers guys, have a great week!",datascience,https://www.reddit.com/r/datascience/comments/17eh6kb/productivity_help/,6,2,0.63,"[Comment(id='k63bp1u'), Comment(id='k63ggmw'), Comment(id='k64owg7'), Comment(id='k64213r'), Comment(id='k64n6v5'), Comment(id='k6gss3p')]"
17eafwm,ResponsibleGazelle76,,2023-10-23 02:52:24+00:00,False,,1698030264.0,True,True,False,/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,What problems would you like to be solved?,"I'm a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it's not out there, etc. Looking to help :)",datascience,https://www.reddit.com/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,43,9,0.61,"[Comment(id='k6256hn'), Comment(id='k62mk5y'), Comment(id='k62azo7'), Comment(id='k62p2ze'), Comment(id='k6316iz'), Comment(id='k62b4ls'), Comment(id='k628hic'), Comment(id='k62w5ol'), Comment(id='k62olth'), Comment(id='k66decm'), Comment(id='k63lg75'), Comment(id='k638bfl'), Comment(id='k63qdpr'), Comment(id='k69gbef'), Comment(id='k6gt7f2'), Comment(id='k62hhdz'), Comment(id='k62zogx'), Comment(id='k69ghwk'), Comment(id='k63d4sh'), Comment(id='k63hxv3'), Comment(id='k63gpha'), Comment(id='k64320u'), Comment(id='k65kedk'), Comment(id='k62c2zf'), Comment(id='k62ukr1'), Comment(id='k64hiow'), Comment(id='k62nukl'), Comment(id='k62ctf1'), Comment(id='k62ztl4'), Comment(id='k64ivws'), Comment(id='k63femi'), Comment(id='k63paqn'), Comment(id='k6439of'), Comment(id='k65wkmq'), Comment(id='k63e4iv'), Comment(id='k63e5xm'), Comment(id='k63jc2u'), Comment(id='k6d6shh'), Comment(id='k674r84'), Comment(id='k63kmgy'), Comment(id='k63foz0'), Comment(id='k646wbt'), Comment(id='k64jgl2')]"
17eboh0,AutoModerator,,2023-10-23 04:01:26+00:00,False,,False,False,True,False,/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/,"Weekly Entering & Transitioning - Thread 23 Oct, 2023 - 30 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/,107,5,0.86,"[Comment(id='k64b5fi'), Comment(id='k64jjlb'), Comment(id='k6mq40h'), Comment(id='k6v0ylu'), Comment(id='k6xctcw'), Comment(id='k6ymhye'), Comment(id='k6z6wq9'), Comment(id='k62vvie'), Comment(id='k63tomr'), Comment(id='k63yp33'), Comment(id='k6489qw'), Comment(id='k64uot0'), Comment(id='k650z2t'), Comment(id='k65w9fe'), Comment(id='k67t828'), Comment(id='k67vky9'), Comment(id='k6b9py4'), Comment(id='k6bd9mu'), Comment(id='k6c1cpw'), Comment(id='k6fdhqa'), Comment(id='k6fix9g'), Comment(id='k6gj1h7'), Comment(id='k6gy6ub'), Comment(id='k6he4s7'), Comment(id='k6i4t8z'), Comment(id='k6j907k'), Comment(id='k6ky1dn'), Comment(id='k6lgrld'), Comment(id='k6mvuj2'), Comment(id='k6pn2hz'), Comment(id='k6t2z1l'), Comment(id='k6u2885'), Comment(id='k6ywbnk'), Comment(id='k6zq8qt'), Comment(id='k71atex'), Comment(id='k664661'), Comment(id='k6896bi'), Comment(id='k6928k0'), Comment(id='k67x0ye'), Comment(id='k6wvbgu'), Comment(id='k6wucf1'), Comment(id='k6ysvo9'), Comment(id='k70qtds'), Comment(id='k63ve9k'), Comment(id='k67wj49'), Comment(id='k664ba1'), Comment(id='k67wrwm'), Comment(id='k67xjap'), Comment(id='k681mq3'), Comment(id='k688mfl'), Comment(id='k67y0ro'), Comment(id='k67vnb0'), Comment(id='k67y5ad'), Comment(id='k6ci9rn'), Comment(id='k6ww4rm'), Comment(id='k6ww04s'), Comment(id='k6wvry2'), Comment(id='k6iqe2d'), Comment(id='k6xjvno'), Comment(id='k6jjtbt'), Comment(id='k6l6kc2'), Comment(id='k6jjpif'), Comment(id='k6wvhsz'), Comment(id='k6nsc2j'), Comment(id='k6wv5am'), Comment(id='k6pnsie'), Comment(id='k6uxccp'), Comment(id='k6wuorf'), Comment(id='k667h1j'), Comment(id='k6z5waj'), Comment(id='k686cz0'), Comment(id='k6869tq'), Comment(id='k664im4'), Comment(id='k69xaxh'), Comment(id='k69iz14'), Comment(id='k69b3cc'), Comment(id='k685925'), Comment(id='k67yi8g'), Comment(id='k6cpil2'), Comment(id='k6jlxx1'), Comment(id='k6mil47'), Comment(id='k71dmhe'), Comment(id='k6x73oc'), Comment(id='k6wux8d'), Comment(id='k6wurqs'), Comment(id='k6y59y2'), Comment(id='k6zhw55'), Comment(id='k699qr2'), Comment(id='k676f1q'), Comment(id='k688976'), Comment(id='k69mpky'), Comment(id='k6cpl8y'), Comment(id='k6jo8up'), Comment(id='k6s57v2'), Comment(id='k71hubs'), Comment(id='k6zfqnp'), Comment(id='k6xg2ld'), Comment(id='k6zgssv'), Comment(id='k68mgyy'), Comment(id='k6zfh39'), Comment(id='k6zl6a9'), Comment(id='k6zrm7s'), Comment(id='k701o9n'), Comment(id='k702dbm'), Comment(id='k704z1k')]"
17e7m1p,feldomatic,,2023-10-23 00:26:13+00:00,False,,False,False,True,False,/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,Native Linux Users: How do you setup your DS Environment?,"Not talking folks who work off linux servers or VMs, I'm talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)

I do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.

I was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.

Rolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.

Not against going back to Anaconda, but I'm curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going.",datascience,https://www.reddit.com/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,19,9,0.74,"[Comment(id='k61keba'), Comment(id='k61ik7o'), Comment(id='k61onnf'), Comment(id='k61z9g1'), Comment(id='k61l95j'), Comment(id='k61tltp'), Comment(id='k62n6ap'), Comment(id='k62okk4'), Comment(id='k62p2fw'), Comment(id='k6297at'), Comment(id='k64yj6j'), Comment(id='k694bwp'), Comment(id='k69k2dz'), Comment(id='k61ls59'), Comment(id='k61iuox'), Comment(id='k61zdup'), Comment(id='k6fivso'), Comment(id='k63i6su'), Comment(id='k6fkls7')]"
17erxid,DellSucksTbh,,2023-10-23 18:52:34+00:00,False,,False,False,True,False,/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,How many hours do other data analysts work?,"Separating things like meetings and actually sitting down and writing code/working through problems, what's your workload like?

I work for an academic department and I can't tell if things are...off lol. It's my first real job btw. ",datascience,https://www.reddit.com/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,8,0,0.42,"[Comment(id='k65dnmh'), Comment(id='k65clrn'), Comment(id='k66dhew'), Comment(id='k68ltct'), Comment(id='k65l55c'), Comment(id='k65vihb'), Comment(id='k6870o8'), Comment(id='k686zav')]"
17e02jy,errOnCaution_,,2023-10-22 18:39:54+00:00,False,,1698098429.0,False,True,False,/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,The obsession/hate for DS undergrad degrees,"I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren't technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.

That being said, a ton of programs for DS out there including the one I'm taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.

&#x200B;

Just a rant, I've been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?

Edit: most people are assuming I want to immediately jump into a DS role. I do not. I plan on being an analyst or some other entry level adjacent role before for a few years before switching to DS or DE.

I think most any undergraduate would fall flat on their face besides the most technical and self taught alongside their classes if they jumped into DS from the getgo, assuming someone with even a year more experience doesn't beat you to the punch first.


If you disagree with something I, or anyone else says in here, instead of down voting to all oblivion tell myself or that person you disagree with *why* they're wrong and need to switch their viewpoint. I'll be making a summary of the points I've seen in here in a few days for people to look through in the future.

----------------------------------------------------------------------------------

Here's the summary of points I've seen made here that have convinced me to switch to CS/Stats minor for anyone in the future who might also have the same question whether or not to choose or switch away from a DS undergrad degree. If I missed anything shoot me a message.

1. CS/Stats is a much more flexible degree path, if the landscape of data as a whole changes, this degree structure is going to be vastly more resistant to changes in what a ""Data Scientist"" even is in the labor market. This choice will also set you up much post for grad school.

2. DS degree graduates, no matter how quality the program is, will be passed in comparison to a CS major. Pre-conceived notions are hard to change and DS degrees are very new / lack a generalized structure compared to CS and Stats majors that more or less have an expected outcome quality in graduates.

3. DS degree graduates as a result of the lack of a single path / consistent course training, *will have gaps in basic skills/knowledge CS/Stats minor graduates won't*. It's best to embrace the filter classes of CS degrees to make sure you aren't falling flat on your face if you get into a DS role.

4. Whether you're choosing something more programming focused like Data Engineering, or something more research / statistically focused like a Data Scientist, CS/Stats will just flat out prepare you better for those jobs while keeping your options open for other roles in CompSci if you end up changing your mind.

5. DS degrees are fine if you plan on being an Analyst, but then again, there are a lot of other non-technical degrees that can become analysts.

6. Projects are not weighted as heavily as people might think, recruiters most likely will not be looking at them unless in very specific scenarios which is why having a better base of CS/Stats tends to work out better.

7. Some aspects of CS degrees will suck but in the grand scheme of being more marketable, the difference in prestige and chances of landing a job vs a DS degree is significant enough to switch degrees or choose CS/Stats to begin with. 

8. In a summarized sense, getting a CS/Stats minor focus is a more pure form of what DS courses should be, but aren't.

Thanks to everyone who didn't just downvote the post and wrote their own perspective, I'll be talking with a counselor to switch to CS & Stats minor tomorrow.

And good luck to anyone in the future coming to this post for answers, it is worth choosing a CS degree and if you have any questions and you're coming through here months or years from now, read through the comments on here to make sure you're making the best decisions for your career.",datascience,https://www.reddit.com/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,109,25,0.66,"[Comment(id='k60tmzn'), Comment(id='k60bnd5'), Comment(id='k60my9q'), Comment(id='k61ftu0'), Comment(id='k60a7k6'), Comment(id='k61pl23'), Comment(id='k61s89x'), Comment(id='k62ovwt'), Comment(id='k63iotf'), Comment(id='k60m3t7'), Comment(id='k606d91'), Comment(id='k60parb'), Comment(id='k61w9cs'), Comment(id='k6147qr'), Comment(id='k60regh'), Comment(id='k6147a4'), Comment(id='k61g84i'), Comment(id='k6237vv'), Comment(id='k635fcl'), Comment(id='k6366ne'), Comment(id='k64153d'), Comment(id='k650d46'), Comment(id='k6591jx'), Comment(id='k65uj81'), Comment(id='k619z48'), Comment(id='k62o4m0'), Comment(id='k60u5a7'), Comment(id='k64s7au'), Comment(id='k60p95h'), Comment(id='k62om0c'), Comment(id='k62oj7v'), Comment(id='k60s12y'), Comment(id='k61qtim'), Comment(id='k6362lw'), Comment(id='k636cxs'), Comment(id='k6470xc'), Comment(id='k60rhm6'), Comment(id='k60z6h0'), Comment(id='k60rswk'), Comment(id='k60g1gl'), Comment(id='k60sfms'), Comment(id='k60t4hu'), Comment(id='k614p14'), Comment(id='k60xbpf'), Comment(id='k60to05'), Comment(id='k637cpt'), Comment(id='k642x5y'), Comment(id='k65bhge'), Comment(id='k6600pi'), Comment(id='k61oyci'), Comment(id='k617i3t'), Comment(id='k61o4yc'), Comment(id='k631ccr'), Comment(id='k62oazg'), Comment(id='k64tekn'), Comment(id='k60s2ri'), Comment(id='k66lnyn'), Comment(id='k6323y3'), Comment(id='k64ezya'), Comment(id='k646ha0'), Comment(id='k60s3m6'), Comment(id='k61511q'), Comment(id='k62dks5'), Comment(id='k60jceg'), Comment(id='k60h257'), Comment(id='k60th0v'), Comment(id='k626pkb'), Comment(id='k60zim1'), Comment(id='k60vyap'), Comment(id='k60yir7'), Comment(id='k6385pf'), Comment(id='k6448u3'), Comment(id='k618kpn'), Comment(id='k60trli'), Comment(id='k6471yj'), Comment(id='k652mii'), Comment(id='k64q9in'), Comment(id='k60snj0'), Comment(id='k60p5bz'), Comment(id='k611n8m'), Comment(id='k63a8u3'), Comment(id='k646c8b'), Comment(id='k61asq4'), Comment(id='k6122tb'), Comment(id='k65m6ps'), Comment(id='k60sksb'), Comment(id='k6125kn'), Comment(id='k63atro'), Comment(id='k64cq7y'), Comment(id='k612p7g'), Comment(id='k65oekz'), Comment(id='k60toju'), Comment(id='k612iup'), Comment(id='k64jry6'), Comment(id='k613a7u'), Comment(id='k65tcqs'), Comment(id='k60ufd0'), Comment(id='k636qer'), Comment(id='k6148yv'), Comment(id='k61439j'), Comment(id='k65tmk6'), Comment(id='k60v7bl'), Comment(id='k63tiez'), Comment(id='k6157p1'), Comment(id='k60x1xn'), Comment(id='k641liu'), Comment(id='k616tjo'), Comment(id='k60yjpj'), Comment(id='k61875x'), <MoreComments count=0, children=[]>]"
17eirhz,grchelp2018,,2023-10-23 12:05:24+00:00,False,,False,False,True,False,/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,Wondering whether the following problem is workable?,"So I need to explore an odd problem. We have an old dataset of interview sessions (its not our dataset). It works as follows.

The candidate comes in, goes through several rounds of interviews (from 1 - 5) each with its own interviewer. (We know the number of interviewers)

After each round, the candidate rates the interviewer (score from 0 to 5). (We do not have this data)

Finally, an overall score is calculated for the entire interview session based on the ratings for each round. (We know the overall score but we do not know how it was calculated)

So essentially, the dataset is roughly off the form:

session_id, score, [interviewer_id1, interviewer_id2, interviewer_id3 ...] (This list is unordered)

The question is: given a particular interviewer_id, is it possible to determine whether he generally got positive or negative ratings?

For context, I write software and don't know much beyond stats 101 so I would appreciate any and all pointers. I would ordinarily say no to the above question but I have met people who've been able to pull signals out of noise so it behoves me to ask.

Thanks.",datascience,https://www.reddit.com/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,3,1,0.6,"[Comment(id='k647cpf'), Comment(id='k63rvwl'), Comment(id='k697t0x')]"
17egeux,qtalen,,2023-10-23 09:35:52+00:00,False,,1698064078.0,False,True,False,/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,How to Optimize Multidimensional Numpy Array Operations with Numexpr,"# A real-world case study of performance optimization in Numpy

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).

&#x200B;

[ How to Optimize Multidimensional Numpy Array Operations with Numexpr. Photo Credit: Created by Author, Canva. ](https://preview.redd.it/r24q1n674yvb1.png?width=1387&format=png&auto=webp&s=ab8950800797f55f538fdb1343df6d275bd07152)

This is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use [Numexpr expressions](https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions) in multidimensional Numpy arrays to achieve substantial performance improvements.

There aren't many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.

# Introduction

Recently, while reviewing some of my old work, I stumbled upon this piece of code:

    def predict(X, w, b):
        z = np.dot(X, w)
        y_hat = sigmoid(z)
        y_pred = np.zeros((y_hat.shape[0], 1))
    
        for i in range(y_hat.shape[0]):
            if y_hat[i, 0] < 0.5:
                y_pred[i, 0] = 0
            else:
                y_pred[i, 0] = 1
        return y_pred

This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning.

But heavens, who would use a `for loop` to iterate over Numpy ndarray?

You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior.

That's right, the person who wrote this code was me when I was younger.

With a sense of responsibility, I plan to rewrite this code with the Numexpr library today.

Along the way, I will show you how to use Numexpr and Numexpr's `where` expression in multidimensional Numpy arrays to achieve significant performance improvements.

## Code Implementation

If you are not familiar with the basic usage of Numexpr, you can refer to this article:

[https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/)

This article uses a real-world example to demonstrate the specific usage of Numexpr's API and expressions in Numpy and Pandas.

*where(bool, number1, number2): number* *- number1 if the bool condition is true, number2 otherwise.*

The above is the usage of the where expression in Numpy.

When dealing with matrix data, you may used to using Pandas `DataFrame`. But since the `eval` method of Pandas does not support the `where` expression, you can only choose to use Numexpr in multidimensional Numpy ndarray.

Don't worry, I'll explain it to you right away.

Before starting, we need to import the necessary packages and implement a `generate_ndarray` method to generate a specific size ndarray for testing:

    from typing import Callable
    import time
    
    import numpy as np
    import numexpr as ne
    import matplotlib.pyplot as plt
    
    rng = np.random.default_rng(seed=4000)
    
    def generate_ndarray(rows: int) -> np.ndarray:
        result_array = rng.random((rows, 1))
        return result_array

First, we generate a matrix of 200 rows to see if it is the test data we want:

    In:  arr = generate_ndarray(200)
         print(f""The dimension of this array: {arr.ndim}"")
         print(f""The shape of this array: {arr.shape}"")
    
    
    Out: The dimension of this array: 2
         The shape of this array: (200, 1)

To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape `(200, 1)` Of course, you can also test other shapes of ndarray according to your needs.

Then, we start writing the specific use of Numexpr in the `numexpr_to_binary` method:

* First, we use the index to separate the columns that need to be processed.
* Then, use the where expression of Numexpr to process the values.
* Finally, merge the processed columns with other columns to generate the required results.

Since the ndarray's shape here is `(200, 1)`, there is only one column, so I add a new dimension.

The code is as follows:

    def numexpr_to_binary(np_array: np.ndarray) -> np.ndarray:
        temp = np_array[:, 0]
        temp = ne.evaluate(""where(temp<0.5, 0, 1)"")
        return temp[:, np.newaxis]

We can test the result with an array of 10 rows to see if it is what I want:

    arr = generate_ndarray(10)
    result = numexpr_to_binary(arr)
    
    mapping = np.column_stack((arr, result))
    mapping

[ I test an array of 10 rows and the result is what I want. Image by Author ](https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&format=png&auto=webp&s=d6977cc422be66a8c37980554c1478e76d2d326c)

Look, the match is correct. Our task is completed.

The entire process can be demonstrated with the following figure:

&#x200B;

[ The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author ](https://preview.redd.it/aw26lp8q8xvb1.png?width=915&format=png&auto=webp&s=df44481e44b2dc48b3acd522b51327b9030e2335)

## Performance Comparison

After the code implementation, we need to compare the Numexpr implementation version with the previous `for each` implementation version to confirm that there has been a performance improvement.

First, we implement a `numexpr_example` method. This method is based on the implementation of Numexpr:

    def numexpr_example(rows: int) -> np.ndarray:
        orig_arr = generate_ndarray(rows)
        the_result = numexpr_to_binary(orig_arr)
        return the_result

Then, we need to supplement a `for_loop_example` method. This method refers to the original code I need to rewrite and is used as a performance benchmark:

    def for_loop_example(rows: int) -> np.ndarray:
        the_arr = generate_ndarray(rows)
        for i in range(the_arr.shape[0]):
            if the_arr[i][0] < 0.5:
                the_arr[i][0] = 0
            else:
                the_arr[i][0] = 1
        return the_arr

Then, I wrote a test method `time_method`. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts:

    def time_method(method: Callable):
        time_dict = dict()
        for i in range(9):
            begin = time.perf_counter()
            rows = 10 ** i
            method(rows)
            end = time.perf_counter()
            time_dict[i] = end - begin
        return time_dict

We test the numexpr version and the `for_loop` version separately, and use `matplotlib` to draw the time required for different amounts of data:

    t_m = time_method(for_loop_example)
    t_m_2 = time_method(numexpr_example)
    plt.plot(t_m.keys(), t_m.values(), c=""red"", linestyle=""solid"")
    plt.plot(t_m_2.keys(), t_m_2.values(), c=""green"", linestyle=""dashed"")
    plt.legend([""for loop"", ""numexpr""])
    plt.xlabel(""exponent"")
    plt.ylabel(""time"")
    plt.show()

[ The Numexpr version of the implementation has a huge performance improvement. Image by Author ](https://preview.redd.it/i5trs6h79xvb1.png?width=595&format=png&auto=webp&s=d508bddb500f8065c75921c1905f14e414ccf932)

It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement.

## Conclusion

After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement.

This article mainly uses two features of Numexpr:

1. Numexpr allows calculations to be performed in a vectorized manner.
2. During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.

Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me.

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).",datascience,https://www.reddit.com/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,0,1,1.0,[]
17ef06x,balackdynamite,,2023-10-23 07:48:30+00:00,False,,False,False,False,False,/r/datascience/comments/17ef06x/how_to_do_a_time_series_forecast_on_sentiment/,How to do a time series forecast on sentiment?,"
I'm using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.

In all cases I can see a few problems:

* gaps with no data (tried filling in - red)
* a sudden drop in sentiment from 15th June

How would you go about doing a forecast on that data? What's advice can you give?",datascience,https://i.redd.it/slcxmqkgqwvb1.jpg,9,0,0.4,"[Comment(id='k631pq6'), Comment(id='k67e4mx'), Comment(id='k67ugls'), Comment(id='k67wyz1'), Comment(id='k67sf76'), Comment(id='k68vckg'), Comment(id='k6dnwhn'), Comment(id='k6dqmbz'), Comment(id='k6dsw58')]"
17dsyjh,noserviceyet,,2023-10-22 13:11:33+00:00,False,,False,False,True,False,/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/,The Changing Landscape of Data Science,"It's fascinating to see how the field of Data Science has evolved in recent years. Just a few years ago, there weren't many dedicated PhD programs in Data Science, and professionals from various STEM backgrounds often considered it as an alternative career option. However, today, we have a plethora of Master's and even a few PhD programs specializing in Data Science. This transformation has turned Data Science into a distinct field, encompassing everything from analytics to ethics.

Will candidates with PhDs in traditional STEM fields become less favored for Data Science jobs in the future, with Data Science program graduates taking the lead? 

Will the field place more emphasis on specialized education as it continues to mature?

What are your thoughts on this matter?",datascience,https://www.reddit.com/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/,27,29,0.8,"[Comment(id='k5yz0ev'), Comment(id='k5ysdr4'), Comment(id='k5z6fxa'), Comment(id='k5yvv2v'), Comment(id='k606qnv'), Comment(id='k5zpqun'), Comment(id='k64qyza'), Comment(id='k60godd'), Comment(id='k60avt6'), Comment(id='k609fio'), Comment(id='k61nr0r'), Comment(id='k60jz28'), Comment(id='k5z4dc2'), Comment(id='k5z8chr'), Comment(id='k62zkm2'), Comment(id='k5zaa3b'), Comment(id='k5z8kmz'), Comment(id='k63bno4'), Comment(id='k65zd3a'), Comment(id='k61joxb'), Comment(id='k66kvhv'), Comment(id='k5zjavw'), Comment(id='k635c4b'), Comment(id='k6e8rps'), Comment(id='k61kvjf'), Comment(id='k61ncvh'), Comment(id='k68z88s')]"
17eeucx,Utterizi,,2023-10-23 07:35:17+00:00,False,,False,False,True,False,/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,"Title not matching tasks, am I making it a big deal?","I am studying a master’s in data science and working as a “junior data scientist” as my first ever job at a start up. Problem is, even though I have ended the more “data science” part of my degree (ML, advanced math/statistics etc.), at work, I’m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don’t remember anything from them. 

I’m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there’s no way I can make it past any of them because of the discrepency between my title and actual experience.",datascience,https://www.reddit.com/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,11,2,0.62,"[Comment(id='k62x5oz'), Comment(id='k635n39'), Comment(id='k62ytz2'), Comment(id='k62ujyp'), Comment(id='k630c0v'), Comment(id='k65wfnb'), Comment(id='k63552g'), Comment(id='k63ex6q'), Comment(id='k63fr30'), Comment(id='k63gbv0'), Comment(id='k63gryq')]"
17egh5m,Mysterious_Run_5081,,2023-10-23 09:40:33+00:00,False,,False,False,True,False,/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,Which features/factors help determine the likelihood of developing tooth decay?,"I’m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet…",datascience,https://www.reddit.com/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,4,0,0.2,"[Comment(id='k63fope'), Comment(id='k644q8f'), Comment(id='k679m2m'), Comment(id='k63sb9z')]"
17deo3d,_CynicalCyanide,,2023-10-21 22:46:18+00:00,False,,False,False,True,False,/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,Where do the data nerds hang out?,"Drop the top subReddits and discord communities where the top data scientists and data analysts hang out. What content do they consume, what are the talking about, how do I sign up?",datascience,https://www.reddit.com/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,93,180,0.91,"[Comment(id='k5wva2f'), Comment(id='k5w9qk1'), Comment(id='k5wb8ju'), Comment(id='k5x0hxt'), Comment(id='k5wad7u'), Comment(id='k5x7wsf'), Comment(id='k5wl35u'), Comment(id='k5xls74'), Comment(id='k5xl9sg'), Comment(id='k5yb1lb'), Comment(id='k5xb8zu'), Comment(id='k5y43z2'), Comment(id='k5wujud'), Comment(id='k5wg2gp'), Comment(id='k5xhg2h'), Comment(id='k5wajqp'), Comment(id='k5xbjoc'), Comment(id='k5wewxi'), Comment(id='k60anrt'), Comment(id='k62q65y'), Comment(id='k63l9e9'), Comment(id='k5wl1vs'), Comment(id='k5wlmwa'), Comment(id='k5x9q3e'), Comment(id='k5wtljx'), Comment(id='k62y63g'), Comment(id='k5xl101'), Comment(id='k5xuaj5'), Comment(id='k5wdxa4'), Comment(id='k5wjbsy'), Comment(id='k5wlu6v'), Comment(id='k5wmgop'), Comment(id='k5wj3p7'), Comment(id='k5yapfh'), Comment(id='k5xn4xq'), Comment(id='k5xqxme'), Comment(id='k5zikia'), Comment(id='k5zpqcq'), Comment(id='k5zt95p'), Comment(id='k600da6'), Comment(id='k603v9q'), Comment(id='k60tgz8'), Comment(id='k60vame'), Comment(id='k63jljr'), Comment(id='k6ftw64'), Comment(id='k5yzz1c'), Comment(id='k5ziizo'), Comment(id='k5yyq2h'), Comment(id='k5xq9zy'), Comment(id='k5xxw28'), Comment(id='k5x8bx7'), Comment(id='k5zts64'), Comment(id='k5wg736'), Comment(id='k5wuz8o'), Comment(id='k5xm83d'), Comment(id='k5yatk9'), Comment(id='k5wuhfj'), Comment(id='k5xyzqy'), Comment(id='k5ys8b5'), Comment(id='k5yaxqi'), Comment(id='k5yfxzx'), Comment(id='k6hdpqn'), Comment(id='k5yx43j'), Comment(id='k5xe6mc'), Comment(id='k5xe93z'), Comment(id='k5wlrar'), Comment(id='k5xeah6'), Comment(id='k62y2c7'), Comment(id='k60zopd'), Comment(id='k5we10k'), Comment(id='k5x8ema'), Comment(id='k5yavea'), Comment(id='k61i3l3'), Comment(id='k61i7zp'), Comment(id='k61c6mp'), Comment(id='k61c5fu'), Comment(id='k5wv7pa'), Comment(id='k5ynpr4'), Comment(id='k5y6967'), Comment(id='k5ylwow'), Comment(id='k5yygp2'), Comment(id='k5zcbrq'), Comment(id='k5xxhvj'), Comment(id='k5xekrv'), Comment(id='k63hr6c'), Comment(id='k5ww4pe'), Comment(id='k5zvhyk'), Comment(id='k5ykh46'), Comment(id='k5xists'), Comment(id='k63uikt'), Comment(id='k5wwqua')]"
17ebi8s,charlesowo445,,2023-10-23 03:51:23+00:00,False,,False,False,True,False,/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,Hey guys how is mongodb for analytics,"Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . 
So the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?",datascience,https://www.reddit.com/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,1,0,0.25,[Comment(id='k64602c')]
17d3aze,ssiddharth408,,2023-10-21 14:04:22+00:00,False,,False,False,True,False,/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,Is pytorch not good for production,"I have to write a ML algorithm from scratch and confused whether to use tensorflow or pytorch. I really like pytorch as it's more pythonic but I found articles and other things which suggests tensorflow is more suited for production environment than pytorch. So, I am confused what to use and why pytorch is not suitable for production environment and why tensorflow is suitable for production environment.",datascience,https://www.reddit.com/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,62,81,0.93,"[Comment(id='k5uuuev'), Comment(id='k5umqnt'), Comment(id='k5um0pe'), Comment(id='k5u5aj5'), Comment(id='k5v377o'), Comment(id='k5u123l'), Comment(id='k5uq8rc'), Comment(id='k5u5wtz'), Comment(id='k5vddvs'), Comment(id='k6ptjsw'), Comment(id='k5v8pw7'), Comment(id='k5w3v6m'), Comment(id='k5vlr5h'), Comment(id='k5uqk0m'), Comment(id='k5wky8x'), Comment(id='k5wkk4t'), Comment(id='k5uwm4o'), Comment(id='k5y30ac'), Comment(id='k5vhx72'), Comment(id='k5uzaxt'), Comment(id='k5uw58w'), Comment(id='k5z92c6'), Comment(id='k5uicrc'), Comment(id='k5v7ufo'), Comment(id='k5u5gns'), Comment(id='k5ur476'), Comment(id='k5vfnx7'), Comment(id='k5u63a1'), Comment(id='k6tw0hl'), Comment(id='k5wdlv8'), Comment(id='k5xn50q'), Comment(id='k5ygs5z'), Comment(id='k5y38lr'), Comment(id='k5vgcfp'), Comment(id='k5uwp6h'), Comment(id='k5vayzx'), Comment(id='k64n14u'), Comment(id='k5wlxlj'), Comment(id='k5ujs7e'), Comment(id='k5vo9ol'), Comment(id='k5u6ero'), Comment(id='k5yqtnc'), Comment(id='k5yhl2m'), Comment(id='k5ybzl9'), Comment(id='k5vs4oz'), Comment(id='k5w9azp'), Comment(id='k5wk514'), Comment(id='k5veg16'), Comment(id='k5wdhpe'), Comment(id='k627rwy'), Comment(id='k5ydrko'), Comment(id='k5u91as'), Comment(id='k5u6y7n'), Comment(id='k5yy6sj'), Comment(id='k5yddly'), Comment(id='k622pdl'), Comment(id='k5wqa7n'), Comment(id='k5y1eop'), Comment(id='k5yywwa'), Comment(id='k5u9wsi'), Comment(id='k5u9iek'), Comment(id='k5ur61m'), Comment(id='k5vfkej'), Comment(id='k5w1j8m')]"
17d6ufx,Odd_Discipline9354,,2023-10-21 16:48:03+00:00,False,,1697911189.0,False,True,False,/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,Is handling errors with Random Forest more superior compared to mean or zero imputation?,"Hi, I came upon [this post in Linkedin](https://www.linkedin.com/feed/update/urn:li:activity:7121482516829507584?utm_source=share&utm_medium=member_android), in which a guy talks about how handling errors with imputing means or zero have many flaws (changes distributions, alters summary statistics, inflates/deflates specific values), and instead suggests to use this library called ""MissForest"" imputer to handle errors using a random forest algorithm.

**My question is, are there any reasons to be skeptical about this post?** I believe there should be, since I have not really heard of other well established reference books talking about using Random Forest to handle errors over imputation using mean or zero.

My own speculation is that, unless your data has missing values that are in the hundreds or take up a significant portion of your entire dataset, using the mean/zero imputation is computationally cheaper while delivering similar results as the Random Forest algorithm.

I am more curious about whether this proposed solution has flaws in its methodology itself.",datascience,https://www.reddit.com/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,7,20,0.85,"[Comment(id='k5v03da'), Comment(id='k5vaq9e'), Comment(id='k5wqkec'), Comment(id='k5x5n88'), Comment(id='k6348du'), Comment(id='k61nzb9'), Comment(id='k62116y')]"
17cv8nq,Accomplished_Ad_5697,,2023-10-21 05:23:21+00:00,False,,False,False,True,False,/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,Why should I learn Java if Python have libraries offset it shortfall?,"I am studying Python and R to work in Data, and my mentor said that I should learn Java. I think it is regards to Machine Learning, but Python has an extensive libraries that helps offset it short fall. The problem that I can never finish a crash course book on Python is it's speed, but I read that NumPy and Pandas help make it faster. So my question is, what benefits are there to learn Java for Data Science if I see majority of people learn Python and most certification for data professions used Python and/or R?",datascience,https://www.reddit.com/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,77,86,0.83,"[Comment(id='k5suq7j'), Comment(id='k5sk2t7'), Comment(id='k5syl6x'), Comment(id='k5skrke'), Comment(id='k5sz06q'), Comment(id='k5sln5l'), Comment(id='k5sln4s'), Comment(id='k5so9lr'), Comment(id='k5sqfwp'), Comment(id='k5uw1a6'), Comment(id='k5snl1s'), Comment(id='k5sx23i'), Comment(id='k5tqbxn'), Comment(id='k5terww'), Comment(id='k5t9ezw'), Comment(id='k5ta86n'), Comment(id='k5sv3g5'), Comment(id='k5sn68o'), Comment(id='k5sple2'), Comment(id='k5t62u4'), Comment(id='k5tikuq'), Comment(id='k5srcy7'), Comment(id='k5tr8o7'), Comment(id='k5tws96'), Comment(id='k5txmb4'), Comment(id='k5u0g7j'), Comment(id='k5u8v6p'), Comment(id='k5uafff'), Comment(id='k5ud70n'), Comment(id='k5unl4s'), Comment(id='k5up43r'), Comment(id='k5upvvs'), Comment(id='k5uqwea'), Comment(id='k5usfr7'), Comment(id='k5usl5i'), Comment(id='k5vburu'), Comment(id='k5ve072'), Comment(id='k5wuv4f'), Comment(id='k5znqp9'), Comment(id='k62i03i'), Comment(id='k5tx9ro'), Comment(id='k5u4vuq'), Comment(id='k5u8t0f'), Comment(id='k5tv3vm'), Comment(id='k5ub2st'), Comment(id='k5t3odm'), Comment(id='k5sliji'), Comment(id='k5tdal9'), Comment(id='k5u3osx'), Comment(id='k5u8z9z'), Comment(id='k5t5t63'), Comment(id='k5swy8n'), Comment(id='k5uzqzf'), Comment(id='k63mmc5'), Comment(id='k5ss0j4'), Comment(id='k5u3c42'), Comment(id='k5tw18y'), Comment(id='k5u3vzk'), Comment(id='k5w884p'), Comment(id='k5vxevc'), Comment(id='k5t9gqt'), Comment(id='k5tvnbm'), Comment(id='k5tqaqd'), Comment(id='k5u4k9l'), Comment(id='k5t3jla'), Comment(id='k5u94s6'), Comment(id='k5uiq1y'), Comment(id='k5suicq'), Comment(id='k5u483g'), Comment(id='k5wczs6'), Comment(id='k5wey8q'), Comment(id='k5u2hgt'), Comment(id='k5u2nir'), Comment(id='k5sx6iq'), Comment(id='k5zt01z'), Comment(id='k5u9920'), Comment(id='k613v17')]"
17czsvd,X_Drake,,2023-10-21 10:45:52+00:00,False,,False,False,True,False,/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,How often do companies outsource for entry-level data roles?,"I've been studying for Data Analyst roles for a while now, and I'm really looking forward to working with data. I was just wondering how often companies outsource for entry-level data analyst roles? Because this role is usually remote or hybrid, I think that a lot of companies probably are, but they're hard to find or most likely prefer locals than to outsource.   
Before I started, I did my own research and met with 8 accomplished Data Analysts/ Scientists/ Engineers Mentors from US/Canada/Germany/UK in The Mentoring Club and confirmed how I would start and learn to transition to this role.  


I talked to them and confirmed that the best skills to acquire would be   
Excel, SQL, Python or R (or Both), Power BI or Tableau (or Both)  


I started with very basic SQL in Khan Academy and SQLZoo and I enjoyed it a lot and confirmed my love to transition to working with Data. 

After that, I took the IBM Data Analyst Professional Certificate (almost everyone I talked to was against taking the Google Data Analytics Certificate) which covered SQL, Python, IBM Cognos, and EDA.

Then I took DataCamp's Data Analyst in SQL to further hone my skills in SQL, I feel more confident with my SQL skills after taking this course.

Now, I'm currently taking DataCamp's Data Analyst in Power BI course and am about 70% done with it.

On every single course, I really love what I'm learning and enjoying it so far. I really love working with data. Whenever I solve a ""problem"" from my courses, I feel very satisfied like an itch in the brain is gone. Every time I make an amazing visual in Power BI, I actually smile and feel proud. Every time I learn something new I actually love it. When I first used ""Key Influencers"" in Power BI, I was so amazed and really wanted to work more with this feature.

&#x200B;

My current problem is, that I don't really want to work as a Data Analyst for a company in my country, but rather as a full-time remote for a company in the US, Canada, or Europe even without benefits, even at minimum wage, as long as they give me 40 hours per week, growth in skills, and opportunity to train/learn.

So I'm just wondering how viable would that be in your experience with your companies, do you work remotely with people from other countries in entry-level roles?",datascience,https://www.reddit.com/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,14,14,0.82,"[Comment(id='k5tp9vb'), Comment(id='k5tqaj9'), Comment(id='k5trz9t'), Comment(id='k5uc9lp'), Comment(id='k5zpbx3'), Comment(id='k5tu8fh'), Comment(id='k5tw1kf'), Comment(id='k5tv9v8'), Comment(id='k5v3f8o'), Comment(id='k5unokf'), Comment(id='k5zn987'), Comment(id='k5vluko'), Comment(id='k5urool'), Comment(id='k5vy7wf')]"
17cfb97,InevitableTraining69,,2023-10-20 16:27:36+00:00,False,,False,False,True,False,/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,I have never had a manager in my entire career that provided any value to me,"In my entire career, I have never had a single manager that provided any value to me personally. Here's a recap of all of the managers I've had in my career. 


1. Terrific manager. Hired me, made me feel welcome, immediately left the company two weeks after I started



2. Replaced first manager, and immediately put me on performance improvement plan to try and get rid of me. Would find formatting errors, any sort of mistake or human error at all to tell me that I was a sloppy employee. Completely ignored any benefit I provided, and had no interest in working with me. Just wanted to build their own team, and I was in their way because I was already there


3. Hired me, and instead letting me get oriented into my role, decided to do what she called ""trial by fire"", just throw me into the deep and and see if I sink or swim. I excelled in my position, did everything better than expected, received praise often, but passed up for a promotion because only one person can be promoted. 


4. Completely incompetent, never actually did any of the subject that they were managing a team for. Ended up being fired for sexual harassment against many women on our team 



5. Came from another team to replace previous manager, gave me mountains of work and impossible goals and expectations to achieve, and even when achieving them, made up a bunch of excuses as to why I can't be promoted that made no sense. Glass ceiling, basically, can't be promoted unless you tell me that you want to be promoted, and X amount of years have passed, need X amount of outstanding performance reviews, etc


6. Actually a really good manager and all around good person. For the first year, great to work under them, they let me get situated in the role, let me get exposure to many different teams and departments, let me explore and provided coaching. However, after the first year, became very lazy as a manager. Never at their desk, always driving somewhere, scheduling meetings and then being 15 plus minutes late to them because again, they are driving somewhere, or not doing their job. Became extremely lazy and let errors slip through their fingers, and blame team members for them. Began making excuses when people wanted to be promoted 


7. The director above the previous manager in bullet point above. Completely worthless leader who came aboard to replace another director, and their first mission was to interrogate everyone on the team, and determine if their career goals were to stay in their current position. Anyone who desired career growth, or wanted to move up into management, or had career aspirations was immediately let go because they're ""Not a fit for our organizational goals"" 



The most common thing I have seen is that it is impossible to get promoted. Most positions at analyst level are designed so that no one can proceed into other positions because they want you to stay exactly where you are currently and not move up, they try to make it as difficult as possible for you to move up into other roles in the company. If you don't want to sit exactly where you are for at least 5 to 10 years, you're a bad employee, and there is no way to be promoted.",datascience,https://www.reddit.com/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,131,258,0.89,"[Comment(id='k5poyaw'), Comment(id='k5pslmm'), Comment(id='k5qy6zx'), Comment(id='k5ri8fk'), Comment(id='k5pmvsv'), Comment(id='k5pmd65'), Comment(id='k5pu0bg'), Comment(id='k5r0u2s'), Comment(id='k5q9kbm'), Comment(id='k5qpefz'), Comment(id='k5r4dyc'), Comment(id='k5sc66s'), Comment(id='k5quyfi'), Comment(id='k5rds8j'), Comment(id='k5rxo32'), Comment(id='k5qoeh1'), Comment(id='k5pt1ev'), Comment(id='k5pyl2y'), Comment(id='k5r82fx'), Comment(id='k5rdio4'), Comment(id='k5s8f45'), Comment(id='k5pooit'), Comment(id='k5povvl'), Comment(id='k5qdh8c'), Comment(id='k5s2j6y'), Comment(id='k5q13a6'), Comment(id='k5q22g9'), Comment(id='k5r0yf3'), Comment(id='k5s2ju4'), Comment(id='k5s69w7'), Comment(id='k5s84gi'), Comment(id='k5salbe'), Comment(id='k5shjz1'), Comment(id='k5sl3aa'), Comment(id='k5swrx7'), Comment(id='k5t6fs6'), Comment(id='k5t6hpv'), Comment(id='k5t92l9'), Comment(id='k5tm6rt'), Comment(id='k5tnorv'), Comment(id='k5u1f53'), Comment(id='k5ud6fn'), Comment(id='k5uq0cv'), Comment(id='k5w4eju'), Comment(id='k5wsm4l'), Comment(id='k606f2j'), Comment(id='k613ke0'), Comment(id='k68rjeo'), Comment(id='k69334x'), Comment(id='k694mvi'), Comment(id='k5q7gsl'), Comment(id='k5u46bi'), Comment(id='k5pub33'), Comment(id='k5q7ohf'), Comment(id='k5x5fxd'), Comment(id='k5t99li'), Comment(id='k5rqf0n'), Comment(id='k5vbok1'), Comment(id='k612v7k'), Comment(id='k5pyoz6'), Comment(id='k5sjhsd'), Comment(id='k5poy0f'), Comment(id='k5puhbb'), Comment(id='k5qj55n'), Comment(id='k5tea15'), Comment(id='k5pxf3y'), Comment(id='k5r1uxz'), Comment(id='k5tbydy'), Comment(id='k5qhr2j'), Comment(id='k5rym2s'), Comment(id='k5ycc47'), Comment(id='k5t124w'), Comment(id='k5ryxsq'), Comment(id='k67qnoq'), Comment(id='k5pw14r'), Comment(id='k5pt9m9'), Comment(id='k5qgaej'), Comment(id='k5q4ssx'), Comment(id='k5qx9q9'), Comment(id='k5t8wr9'), Comment(id='k5qdj83'), Comment(id='k5t34yh'), Comment(id='k5rw2l7'), Comment(id='k5t4a6o'), Comment(id='k5u71xe'), Comment(id='k5qomwe'), Comment(id='k5t6r7g'), Comment(id='k5r39sa'), Comment(id='k5tbu2c'), Comment(id='k5ppqli'), Comment(id='k5qrgfs'), Comment(id='k5t9uhh'), Comment(id='k5tgifc'), Comment(id='k5pycej'), Comment(id='k5q2w3i'), Comment(id='k5sxk6x'), Comment(id='k5t6xh0'), Comment(id='k5qm97s'), Comment(id='k5xb5pm'), Comment(id='k5yc7zc'), Comment(id='k5vvjn1'), Comment(id='k62gagi'), Comment(id='k5seuvk'), Comment(id='k5q0xdd'), Comment(id='k5pycdl'), Comment(id='k5qnkqk'), Comment(id='k5qkeyz'), Comment(id='k5s0g91'), Comment(id='k5t9997'), Comment(id='k5tjv4c'), Comment(id='k5u87i7'), Comment(id='k5ug1v1'), Comment(id='k5tegds'), Comment(id='k5pyqy3'), Comment(id='k5t6nqj'), Comment(id='k5tb8er'), Comment(id='k5x5wco'), Comment(id='k5yd0h0'), Comment(id='k5r1rxn'), Comment(id='k5q7dlo'), Comment(id='k5q8cj3'), Comment(id='k5sa7yw'), Comment(id='k5tjwvt'), Comment(id='k5vpyeh'), Comment(id='k5v1gmy'), Comment(id='k5t7hrb'), Comment(id='k74ne1z'), Comment(id='k5t96s3'), Comment(id='k5qmx8c'), Comment(id='k5x5l3u'), Comment(id='k74one4'), Comment(id='k5qt68e'), Comment(id='k5xfdfq'), Comment(id='k5xk4zj')]"
17cy5av,Total-Opposite-8396,,2023-10-21 08:48:07+00:00,False,,False,False,True,False,/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,Need some practical advice on choosing from different CNN model architectures.,"Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also covered a little Neural Style Transfer. 

 I am now looking forward to build some projects. Most probably on object detection and image classification. After consuming all of the stuff that I mentioned above, I am confident enough that I can build an application in the real world, though I still have a few questions and need to talk to someone who can channel my thoughts in the right direction.  

If you could give me just a rough overview of how you approach a computer vision problem that'll be great. Especially, when you see a computer vision problem to solve, how do you make decision on which architecture to choose from to solve a given problem at hand. Since there are many architectures and research papers and every architecture works in a unique way to solve unique problems, how do you know which one to choose from? How do you make your way down from 100s of options to choose from, to a few where you can then start experimenting with those few options? Just need some practical advice on approaching an object detection or image classification problem.

Also, there might be some knowledge gaps that I have, I feel like I have em, but I don't know what I don't know at this point. So, I just need someone who can maybe channel me in the right direction.",datascience,https://www.reddit.com/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,2,4,0.7,"[Comment(id='k5tattz'), Comment(id='k7wetka')]"
17ccv2x,SHJPEM,,2023-10-20 14:40:44+00:00,False,,False,False,True,False,/r/datascience/comments/17ccv2x/whats_one_file_or_other_digital_resource_which_if/,What's one file or other digital resource which if deleted would most affect the world?,,datascience,https://www.reddit.com/r/datascience/comments/17ccv2x/whats_one_file_or_other_digital_resource_which_if/,16,37,0.85,"[Comment(id='k5p2p7v'), Comment(id='k5qs7uz'), Comment(id='k5pf21q'), Comment(id='k5qac51'), Comment(id='k5qs7zi'), Comment(id='k5pxgph'), Comment(id='k5qz60i'), Comment(id='k5stz8f'), Comment(id='k5p8j1w'), Comment(id='k5qf8a8'), Comment(id='k5vpwbj'), Comment(id='k5t471a'), Comment(id='k5pkunj'), Comment(id='k5vohlh'), Comment(id='k5posqt')]"
17cce10,Ty4Readin,,2023-10-20 14:19:09+00:00,False,,1697812122.0,False,True,False,/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,Dataset splitting by time & why you should do it,"I know this is likely to be controversial but I wanted to open up the discussion.

I think most problems and datasets should be split by time rather than uniform iid sampling for train-valid-test.

I almost always get pushback when I suggest this because it makes cross-validation more difficult to implement and can reduce the training dataset size in some folds.

Most people will say it's not necessary to split by time (e.g. test set in the future relative to train) because there is no time-wise dependency. However, the problem is that almost every data distribution involving human interactions will tend to shift over time and contain some dependency.

Let me give you one example: Let's say we have a web app that lets users submit a picture of an animal and we predict whether it's a dog or not. This seems like a simple problem where you could split by iid because there can't be any data leakage, right?

But if you think about it, the distribution of photos that get submitted is likely to change over time. It could be from new dog breeds becoming more popular, or from a shift in the types of users that use the platform and the dogs they submit. It could even be due to new phones/cameras being used, or people start posing their photos slightly differently or maybe covid hits and now your service is only getting indoor photos with different lighting whereas previously you got mostly outdoor shots.

These are all hypothetical examples and you could come up with a million different ones. The point being that the distribution of data for many many (most?) problems will change over time and our goal is almost always to train on historical data and predict on future unseen data.

So with that context, I think it often makes sense to at least test a time-split approach and observe whether there's a difference with simple iid CV approach. I think you could possibly be surprised by the result.",datascience,https://www.reddit.com/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,49,26,0.82,"[Comment(id='k5pe43l'), Comment(id='k5p7s41'), Comment(id='k5p0j8t'), Comment(id='k5pcmiu'), Comment(id='k5pft3g'), Comment(id='k5pm1kq'), Comment(id='k5pa55u'), Comment(id='k5pa567'), Comment(id='k5qfhjt'), Comment(id='k5qp1sh'), Comment(id='k5oz31x'), Comment(id='k5phqc5'), Comment(id='k5ptd7m'), Comment(id='k5pmxum'), Comment(id='k5qf70l'), Comment(id='k5pv859'), Comment(id='k5qmzj9'), Comment(id='k5p1ob5'), Comment(id='k5pr09b'), Comment(id='k5pqc5o'), Comment(id='k5pm0av'), Comment(id='k5pp3pu'), Comment(id='k5pq0p8'), Comment(id='k5piahq'), Comment(id='k5qny1b'), Comment(id='k5qh34f'), Comment(id='k5pk1v0'), Comment(id='k5qptu2'), Comment(id='k5ppuqe'), Comment(id='k5qg9uq'), Comment(id='k5qhjp0'), Comment(id='k5qjid6'), Comment(id='k5rfu9r'), Comment(id='k5r53yt'), Comment(id='k5psfod'), Comment(id='k5ps93y'), Comment(id='k5psj1l'), Comment(id='k5qhuyp'), Comment(id='k5qjhdn'), Comment(id='k5q3gmz'), Comment(id='k5re2w6'), Comment(id='k5pvaz4'), Comment(id='k5pt6rp'), Comment(id='k5qhwxc'), Comment(id='k5px79v'), Comment(id='k5pvlrk'), Comment(id='k5qng8d'), Comment(id='k5pxa4a'), Comment(id='k5r8l1w'), Comment(id='k5rfhv8')]"
17d2v13,Careful_Engineer_700,,2023-10-21 13:42:26+00:00,False,,False,False,True,False,/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,"Soooo, my manager thinks it’s a good idea to assign a mentor on me,","I am a sales operations analyst -by name- and I do what a typical junior data scientist does, I am an analyst from a team of four, I am the only one with exposure to proper statistical analyses and machine learning.

One colleague of mine -my mentor- has been at the company for a year before me, and he knows some python and is good at SQL. He is no where near my level at those two, but he’s a god-level suck-up! 
He can stay at the office after hours for no compensation just cause our manager said he needed to see something that would normally take a whole day to achieve, asked at 5:00 pm and needed to be ready in the morning.

The problem is raised because of a project I was leading, I automated the process of making routes for sales agents, I made it assign a 1 to retailers if we visit today will more likely make an order. I made it for the region I am operating in only -more on that later- and I also used clustering to get them the best routes possible in terms of likelihood to order and geographic coordinates. It made the success rate go from 40% to a big fat 60%. My manager appreciated that as much and thought its a great idea to make it for all regions, I designed an ab test and will run it for 2 weeks, as we have biweekly seasonality.

I prepared analyses for the test results and it was time for a meeting with other managers to discuss what it achieved. This was the forst time this team was doing an ab test, since I am the only one who actually understand it, I owned it.

When I shows the numbers, one region showed insignificant results, and I found that its seasonality is not biweekly, rather monthly and the mode of operations there is different, and it was -my mentor’s- region.

My manager said: why are you complicating things? Man, show me some pivot tables of agents who worked without your model and the ones who worked with and who is better, I disagreed as their performances might include other factors that are not controlled by mt model, pricing and geography and the agent himself.

My mentor already has the pivots ready, presented the numbers and he was happy.

After, my manager rambelled on for half an hour about my attitude and pointed out every thing that I fis wrong since I started working in the company, and assigned him as anentor to me, stating how much of an inpact on my coding skills and analytical skills he will add.

We started working in projexts together and had to take his way of doing things, and I don’t like how he lets me do all the work and take credit for it.

I started looking for new jobs and no luck the market is really tough especially that I know little tools, power bi and its dax, excel and python and sql.

What should i learn to get jobs as a junior data scientist? While searching, what should I do about my situation?",datascience,https://www.reddit.com/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,16,0,0.42,"[Comment(id='k5u16w6'), Comment(id='k5tzyt0'), Comment(id='k5ui6e2'), Comment(id='k5u4ze0'), Comment(id='k5udrl3'), Comment(id='k5u1qby'), Comment(id='k5u1g16'), Comment(id='k5ux6is'), Comment(id='k5ui1ma'), Comment(id='k5u7viy'), Comment(id='k5uk4wu'), Comment(id='k5x5rrz'), Comment(id='k5v0719'), Comment(id='k5uwn59'), Comment(id='k5uw0s5'), Comment(id='k5uwskg')]"
17c78g5,Stochastic_berserker,,2023-10-20 09:35:39+00:00,False,,False,False,True,False,/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,Thoughts on DS roles,"I’ve been working as a DS for a couple of years now and would like to share my thoughts on the role(s).


- Big corp: Benefits and salary good but can get stuck in deploying large products where your hard earned skills aren’t used. Best place to be during new projects where you accumulate alot of skills from SWE, IT and more.


- Consulting: Not Big4 but what I’ve experienced is basically BI and DE. The managers have no idea what DS is and just regurgitates names of cloud services. Compensation model is outdated and not realistic for DS. 


What are your experiences?",datascience,https://www.reddit.com/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,15,26,0.91,"[Comment(id='k5o6mec'), Comment(id='k5ollhi'), Comment(id='k5p77wq'), Comment(id='k5owmjz'), Comment(id='k5oqi8q'), Comment(id='k5ovrj5'), Comment(id='k5peiyp'), Comment(id='k5qs8wu'), Comment(id='k5odhos'), Comment(id='k5owz56'), Comment(id='k5p52do'), Comment(id='k5sz5pa'), Comment(id='k5syw3n'), Comment(id='k5oxb7i'), Comment(id='k5oz5o0')]"
17clbmx,Different-General700,,2023-10-20 20:59:40+00:00,False,,False,False,True,False,/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,Inviting initial users for dynamic data documentation tool,"I'm building a product that integrates with your codebases and takes your database metadata to create dynamic documentation of your data. Every time someone makes a new code change that affects the data, you're updated with how the code change altered tables, labels, cols, etc.

Let me know if you'd like to try it out. I'll send you a link and would love to get your feedback.

I'll provide a repo and public postgres database that you can connect to demo (if you don't have one that you want to connect).",datascience,https://www.reddit.com/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,5,3,1.0,"[Comment(id='k5r2coj'), Comment(id='k5r2ps8'), Comment(id='k5r4318'), Comment(id='k5r5dc6'), Comment(id='k5r6cdu')]"
17cnntn,BeginningDeer4329,,2023-10-20 22:42:46+00:00,False,,False,False,True,False,/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,Help needed with a quadratic optimization problem,"Hi, I am trying to solve finance-related quadratic optimization problem using CVXPY python library. I have a maximize objective function with a Beta variable which is subject to certain constraints. I am getting the output for Beta values from 1-10. But at certain beta values (e.g., 0, 1), the output is optimally inaccurate and the objective is not even satisfying constraints. Why would the program give solutions which does not satisfy constraints? More generally, can someone recommend some literature to solve such problems?",datascience,https://www.reddit.com/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,2,2,1.0,"[Comment(id='k5r8ylu'), Comment(id='k5rf6ub')]"
17cie3b,Usual-Goat,,2023-10-20 18:46:28+00:00,False,,False,False,True,False,/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,Help with analysis of incomplete experimental design,"I am trying to determine the amount of confounding and predictive power of the current experimental design is?  
I just started working on a project helping out with a test campaign of a fairly complicated system at my company. There are many variables that can be independently tuned, and there is a test series planned to 'qualify' the engine against its specification requirements.   


One of the objectives of the test series is to quantify the 'coefficient of influence' of a number of factors. Because of the number of factors involved, a full factorial DOE is out of the question, and because there are many objectives in the test series, its difficult to even design a nice, neat experimental design that follows canonical fractional factorial designs.   


We do have a test matrix built, and i was wondering if there is a way to just analyze what the predictive power of the current test matrix is in the first place. We know and accept that there will be some degree of confounding two-variable and three-variable + interaction effects in the main effects, which is alright for us. Is there a way to analyze what the amount of confounding and predictive power of the current experimental design is?  


Knowing the current capability and limitations of our experimental designs would be very helpful it turns out i need to propose alteration of our test matrix (which can be costly)  


I don't have any real statistics background, and i don't think our company would pay for a software like minitab and i don't know how to use such a software either.   


Any guidance on this problem would be most appreciated.   
",datascience,https://www.reddit.com/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,4,1,0.67,"[Comment(id='k664vnc'), Comment(id='k5rgpy3'), Comment(id='k5to9ju'), Comment(id='k5udh4h')]"
17cgmof,LiterateSeagull,,2023-10-20 17:26:34+00:00,False,,False,False,True,False,/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,Can you fit a code in a gamble?,"How would you encode information into improbable events? For example, if you could influence the outcome of a roulette wheel or lottery draw, over as long a period as necessary, what would be the most efficient way of encoding data into the outcomes?

Perhaps a better example would be drawing from a deck of a million unique cards, and only yelling yahtzee when a specific one is drawn. Say you can add a few extra of the card to the deck whenever you want and boost the probability slightly. That would theoretically increase the frequency of the yahtzees from the right timescale perspective.

So if our hero does a million shuffled drawings a day, he might get 0-3 yahtzees. With careful timing, you can slip an extra card into the deck whenever you want, doubling his probability for the next drawing.

How would you encode as much data as possible in the frequency of this man yelling yahtzee?",datascience,https://www.reddit.com/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,20,0,0.43,"[Comment(id='k5r0th3'), Comment(id='k5qckw3'), Comment(id='k5qji34'), Comment(id='k5qawia'), Comment(id='k5rxmgq'), Comment(id='k5qak5e'), Comment(id='k5qk2mb'), Comment(id='k5qnqn1'), Comment(id='k5qu14w'), Comment(id='k5rcgxd'), Comment(id='k5rlr8y'), Comment(id='k5snurs'), Comment(id='k5x6k2g'), Comment(id='k5qqxu5'), Comment(id='k5qvgig'), Comment(id='k5slpvp'), Comment(id='k5qz3au'), Comment(id='k5ufaoe'), Comment(id='k5r0ii6'), Comment(id='k5s3szu')]"
17c0z6e,EthicalArtisan,,2023-10-20 02:49:57+00:00,False,,False,False,True,False,/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,Any data imputation technique shares?,"Hello, 

I’ve been reading up some articles from kaggle and blogs about data imputation. I’m wondering if there’s a complete guide that introduces all the methods to data imputation. I’m interested to see all the pros and cons and the usage of different situations. 

Thanks for sharing!",datascience,https://www.reddit.com/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,15,9,0.77,"[Comment(id='k5n5be1'), Comment(id='k5n5s79'), Comment(id='k5n1twr'), Comment(id='k5nmcpr'), Comment(id='k61oq9t'), Comment(id='k5ng5hk'), Comment(id='k5ngd4q'), Comment(id='k5n2nem'), Comment(id='k5pcfpd'), Comment(id='k5nptnt'), Comment(id='k5obd1y'), Comment(id='k5pc89d'), Comment(id='k5pbuag'), Comment(id='k5rmbtg'), Comment(id='k5r101h')]"
17c2u6b,Difficult-Big-3890,,2023-10-20 04:34:22+00:00,False,,1697782002.0,False,True,False,/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,Do you use CRUD or like apps to bridge the gap between business users and DS/DA teams?,"In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don't see much talk about this skill/use case of analytics. So curious to hear other's thoughts and experiences. Do you concur? Why or why not?

PS: I understand it's probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don't fall in this category. Pls feel free to bunk this too!",datascience,https://www.reddit.com/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,19,6,0.8,"[Comment(id='k5oq3r9'), Comment(id='k5op1zr'), Comment(id='k5op282'), Comment(id='k5nnqqg'), Comment(id='k5nl8zn'), Comment(id='k5ovcop'), Comment(id='k5ovj71'), Comment(id='k5numm6'), Comment(id='k5oi5ax'), Comment(id='k5nllf1'), Comment(id='k5oy14z'), Comment(id='k5ozg0n'), Comment(id='k5nv227'), Comment(id='k5oz8xg'), Comment(id='k5p0jv0'), Comment(id='k5nvmb0'), Comment(id='k5p0ycj'), Comment(id='k5qx776'), Comment(id='k5p1mlc')]"
17bmc70,David202023,,2023-10-19 15:50:31+00:00,False,,False,False,True,False,/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,[rant] Required - A designated tread for transitioning to DS and repeating questions,"Mods, where are you? There are countless posts every week with questions that were answered already.  

Should I learn Python? 
Masters degree worth it?
Job market sucks, what projects should I do?

All of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren’t even phrased correctly.

All of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master.",datascience,https://www.reddit.com/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,27,43,0.79,"[Comment(id='k5khmrs'), Comment(id='k5kp7ox'), Comment(id='k5k7ag5'), Comment(id='k5l0erh'), Comment(id='k5l0ogv'), Comment(id='k5k6ivk'), Comment(id='k5lsakx'), Comment(id='k5l26w2'), Comment(id='k5ma4dk'), Comment(id='k5n805b'), Comment(id='k5nv0v6'), Comment(id='k5mz78s'), <MoreComments count=6, children=['k5lgu5j', 'k5l6guf', 'k5kpd57']>, Comment(id='k5kpkg6'), Comment(id='k5lfd59'), Comment(id='k5k7c87'), Comment(id='k5ltk72'), Comment(id='k5k7xku'), Comment(id='k5l14s4'), Comment(id='k5lud2b'), Comment(id='k5lj7ho'), Comment(id='k5lnibd')]"
17bqhb0,19andoverlol,,2023-10-19 18:50:52+00:00,False,,False,False,True,False,/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,Predictive vs Explanatory modeling,"In my past work I've become familiar with various techniques for *predictive* modeling--NNs, of course, but also more ""classical"" methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I've loved using sklearn and nltk, and I haven't even gotten to using pytorch yet).

All that said, I haven't worked as much so far with *explanatory* modeling and I'm looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What's more, in the explanatory environment, there's a much greater emphasis on *model interpretability*--that is to say, models like NNs or even random forests that can get kind of ""black boxy"" are disfavored compared to simpler models with much more straightforward interpretability.

So what's the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??",datascience,https://www.reddit.com/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,26,11,0.87,"[Comment(id='k5l9t81'), Comment(id='k5n0wme'), Comment(id='k5nbcgr'), Comment(id='k5lfpoz'), Comment(id='k5olacx'), Comment(id='k5moxup'), Comment(id='k5mlidy'), Comment(id='k5mn6qy'), Comment(id='k5naffs'), Comment(id='k5ti108'), Comment(id='k5macto'), Comment(id='k5ndg1y'), Comment(id='k5n0saj'), Comment(id='k5nh52f'), Comment(id='k5nib9p'), Comment(id='k5nn98n'), Comment(id='k5nov7a'), Comment(id='k5nozhm'), Comment(id='k5p1ag1'), Comment(id='k5np6m1'), Comment(id='k5pc3f9'), Comment(id='k5nptjj'), Comment(id='k5odija'), Comment(id='k5oznac'), Comment(id='k5p1nub'), <MoreComments count=0, children=[]>]"
17bg00y,honghuiying,,2023-10-19 10:31:31+00:00,False,,1697711887.0,False,True,False,/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,Use cases of Advanced Math in Data Science and Machine Learning,"I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles.",datascience,https://www.reddit.com/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,21,28,0.89,"[Comment(id='k5j1d9a'), Comment(id='k5jamk0'), Comment(id='k5jb6xu'), Comment(id='k5jugq7'), Comment(id='k5kcx4n'), Comment(id='k5m8a77'), Comment(id='k5mby34'), Comment(id='k5rn8wo'), Comment(id='k66owdw'), Comment(id='k5j2oxl'), Comment(id='k5n7jh9'), Comment(id='k5nzrse'), Comment(id='k5kroum'), Comment(id='k5rndlw'), Comment(id='k5naxdx'), Comment(id='k5n8c0b'), Comment(id='k5nwmzg'), Comment(id='k5s0sjc'), Comment(id='k5poaah'), Comment(id='k5sawlb'), Comment(id='k5vuwvp')]"
17bxccu,HStuart18,,2023-10-19 23:49:52+00:00,False,,False,False,True,False,/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,Sharing large files for collaboration,"Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won't suit my current job. I'm thinking S3, but wondering if anyone has a better idea. Haven't used Git LFS either so curious about this one too. Cheers",datascience,https://www.reddit.com/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,3,2,0.76,"[Comment(id='k5n60ol'), Comment(id='k5mdkai'), Comment(id='k5mm6e5')]"
17avmi5,Consistent-Design-57,,2023-10-18 17:00:32+00:00,False,,1697713310.0,False,True,False,/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,Where are all the entry level jobs? Which MS program should I go for? Some tips from a hiring manager at an F50,"The bulk of this subreddit is filled with people trying to break into data science, completing certifications and getting MS degrees from diploma mills but with no real guidance. Oftentimes the advice I see here is from people without DS jobs trying to help other people without DS jobs on projects etc. It's more or less blind leading the blind.

Here's an insider perspective from me. I'm a hiring manager at an F50 financial services company you've probably heard of, I've been working for \~4 years and I'll share how entry-level roles actually get hired into.

There's a few different pathways. I've listed them in order of where the bulk of our candidate pool and current hires comes from

1. We pick MS students from very specific programs that we trust. These programs have been around for a while, we have a relationship with the school and have a good idea of the curriculum. Georgia Tech, Columbia, UVa, UC Berkeley, UW Seattle, NCSU are some universities we hire from. We don't come back every year to hire, just the years that we need positions filled. Sometimes you'll look around at teams here and 40% of them went to the same program. They're stellar hires. The programs that we hire from are incredibly competitive to get into, are not diploma mills, and most importantly, their programs have been around longer than the DS hype. How does the hiring process work? We just reach out to the career counselor at the school, they put out an interest list for students who want to work for us, we flip through the resumes and pick the students we like to interview. It's very streamlined both for us as an employer and for the student. Although I didn't come from this path (I was a referred by a friend during the hiring boom and just have a PhD), I'm actively involved in the hiring efforts.
2. We host hackathons every year for students to participate in. The winners of these hackathons typically get brought back to interview for internship positions, and if they perform well we pick them up as full time hires.
3. Generic career fairs at universities. If you go a to a university, you've probably seen career fairs with companies that come to recruit.
4. Referrals from our current employees. Typically they refer a candidate to us, we interview them, and if we like them, we'll punt them over to the recruiter to get the process started for hiring them. Typically the hiring manager has seen the resume before the recruiter has because the resume came straight to their inbox from one of their colleagues
5. Internal mobility of someone who shows promise but just needs an opportunity. We've already worked with them in some capacity, know them to be bright, and are willing to give them a shot even if they don't have the skills.
6. Far and away the worst and hardest way to get a job, our recruiter sends us their resume after screening candidates who applied online through the job portal. Our recruiters know more or less what to look for (I'm thankful ours are not trash)

This is true not just for our company but a lot of large companies broadly. I know Home Depot, Microsoft and few other large retail companies some of my network works at hire candidates this way.

Is it fair to the general population? No. But as employees at a company we have limited resources to put into finding quality candidates and we typically use pathways that we know work, and work well in generating high quality hires.

EDIT: Some actionable advice for those who are feeling disheartened. I'll add just a couple of points here:

1. If you already have your MS in this field or a related one and are looking for a job, reach out to your network. Go to the career fairs at your university and see if you can get some data-adjacent job in finance, marketing, operations or sales where you might be working with data scientists. Then you can try to transition internally into the roles that might be interesting to you.
2. There are also non-profit data organizations like Data Kind and others. They have working data scientists already volunteering time there, you can get involved, get some real world experience with non-profit data sets and leverage that to set yourself apart. It's a fantastic way to get some experience AND build your professional network.
3. Work on an open-source library and making it better. You'll learn some best practices. If you make it through the online hiring screen, this will really set you apart from other candidates
4. If you are pre MS and just figuring out where you want to go, research the program's career outcomes before picking a school. No school can guarantee you a job, but many have strong alumni and industry networks that make finding a job way easier. Do not go just because it looks like it's easy to get into. If it's easy to get into, it means that they're a new program who came in with the hype train

EDIT 2: I think some people are getting the wrong idea about ""prestige"" where the companies I'm aware of only hire from Ivies or public universities that are as strong as Ivies. That's not always the case - some schools have deliberately cultivated relationships with employers to generate a talent pipeline for their students. They're not always a top 10 school, but programs with very strong industry connections.

For example, Penn State is an example of a school with very strong industry ties to companies in NJ, PA and NY for engineering students. These students can go to job fairs or sign up for company interest lists for their degree program at their schools, talk directly to working alumni and recruiters and get their resume in front of a hiring manager that way. It's about the relationship that the university has cultivated to the local industries that hire and their ability to generate candidates that can feed that talent pipeline.",datascience,https://www.reddit.com/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,156,300,0.91,"[Comment(id='k5ferif'), Comment(id='k5gv8gb'), Comment(id='k5fnamv'), Comment(id='k5fie63'), Comment(id='k5hlz0u'), Comment(id='k5gq4a7'), Comment(id='k5g7mq9'), Comment(id='k5gi3ky'), Comment(id='k5g6od8'), Comment(id='k5fta4j'), Comment(id='k5frd44'), Comment(id='k5hcoot'), Comment(id='k5gsuxd'), Comment(id='k5hx4jw'), Comment(id='k5g9dow'), Comment(id='k5gqa4r'), Comment(id='k5flxnc'), Comment(id='k5h9tlx'), Comment(id='k5imqsk'), Comment(id='k5jfgud'), Comment(id='k5ibxbe'), Comment(id='k5gm9el'), Comment(id='k5jgc7y'), Comment(id='k5i6749'), Comment(id='k5ga5yn'), Comment(id='k5imooj'), Comment(id='k5iz9md'), Comment(id='k5gvzfe'), Comment(id='k5gi5v6'), Comment(id='k5ghgjf'), Comment(id='k5gl944'), Comment(id='k5i7405'), Comment(id='k5iklq4'), Comment(id='k5ilofs'), Comment(id='k5j6yyw'), Comment(id='k5jfm7e'), Comment(id='k5lwx60'), Comment(id='k5n0pjw'), Comment(id='k5zx3ag'), Comment(id='k5fjb3c'), Comment(id='k5fg16b'), Comment(id='k5imvfg'), Comment(id='k5gzpom'), Comment(id='k5x03d2'), Comment(id='k5gwku4'), Comment(id='k5ifzbu'), Comment(id='k5fj5q4'), Comment(id='k5hpxqc'), Comment(id='k5i5477'), Comment(id='k5gx2wd'), Comment(id='k5hg3of'), Comment(id='k5j7m1p'), Comment(id='k5gojba'), Comment(id='k5g7zhe'), Comment(id='k5j34wx'), Comment(id='k5fth19'), Comment(id='k5frm9n'), Comment(id='k5ifsao'), Comment(id='k5iumdp'), Comment(id='k5gwqtm'), Comment(id='k5gwy28'), Comment(id='k5fnkph'), Comment(id='k5nai5f'), Comment(id='k5i8wvy'), Comment(id='k5i4o8n'), Comment(id='k5jfwuv'), Comment(id='k5iscr7'), Comment(id='k5iupz2'), Comment(id='k5gn5lr'), Comment(id='k5itp9i'), Comment(id='k5isj5s'), Comment(id='k5j1vtz'), Comment(id='k5gwf9e'), Comment(id='k5h2yfd'), Comment(id='k5hair9'), Comment(id='k5iutau'), Comment(id='k5ism4q'), Comment(id='k5fo8ml'), Comment(id='k5ibdus'), Comment(id='k5jr3r9'), Comment(id='k5ioybo'), Comment(id='k5fi0t9'), Comment(id='k5itfbg'), Comment(id='k5ip244'), Comment(id='k5jrkq1'), Comment(id='k5h2kyi'), Comment(id='k5xgb1m'), Comment(id='k5jo7wo'), Comment(id='k5iiqmj'), Comment(id='k5go8pf'), Comment(id='k5g0orm'), Comment(id='k5hysb7'), Comment(id='k5ip5vl'), Comment(id='k5kgssn'), Comment(id='k5gap05'), Comment(id='k5goly5'), Comment(id='k5q6tlg'), Comment(id='k5frtwk'), Comment(id='k5sr7lv'), Comment(id='k5jp9t7'), Comment(id='k5gig2j'), Comment(id='k5kzusl'), Comment(id='k5jn11j'), Comment(id='k5j1412'), Comment(id='k5gnaed'), Comment(id='k5iu6gs'), Comment(id='k5hhl6a'), Comment(id='k5jll9c'), Comment(id='k5hdn4d'), Comment(id='k5ja81n'), Comment(id='k5iugmw'), Comment(id='k5kg2rx'), Comment(id='k5itxxt'), Comment(id='k5ipnpz'), Comment(id='k5l3404'), Comment(id='k5gxlss'), Comment(id='k5g1y4b'), Comment(id='k5ga4a7'), Comment(id='k5jd4e2'), Comment(id='k5gora9'), Comment(id='k5i4z7e'), Comment(id='k5i6y7n'), Comment(id='k5fsmco'), Comment(id='k5go7ci'), Comment(id='k5mewld'), Comment(id='k5j1bnq'), Comment(id='k5gnm6p'), Comment(id='k5hy1i3'), Comment(id='k5iuaxp'), Comment(id='k5ju243'), Comment(id='k5kpul6'), Comment(id='k5it2q0'), Comment(id='k5iqtae'), Comment(id='k5ls0uh'), Comment(id='k5iu9m0'), Comment(id='k5gdfj1'), Comment(id='k5gp7ua'), Comment(id='k5ihlwg'), Comment(id='k5icl2z'), Comment(id='k5j5q4u'), Comment(id='k5gcwkr'), Comment(id='k5g7elh'), Comment(id='k5j1cvt'), Comment(id='k5go3l2'), Comment(id='k5gnx68'), Comment(id='k5iux61'), Comment(id='k5iupfm'), Comment(id='k5mcyw2'), Comment(id='k5icxqw'), Comment(id='k5j6jnn'), Comment(id='k5icldw'), Comment(id='k5go7rg'), Comment(id='k5id366'), Comment(id='k5jjz1h'), Comment(id='k5gofy5'), Comment(id='k5idewd'), Comment(id='k5kayv5'), Comment(id='k5gop17'), Comment(id='k5idl5c'), Comment(id='k5kmb4l'), Comment(id='k5gwnew'), Comment(id='k5kpegr'), <MoreComments count=0, children=[]>]"
17bobx9,Kilroy_was_here__,,2023-10-19 17:17:58+00:00,False,,False,False,True,False,/r/datascience/comments/17bobx9/wrong_data_in_dataset/,Wrong data in dataset,"I have a very broad question about building a model using xgboost and feature selection. 

As an example, let’s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score > x. 

In this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it’s due to random chance. 

My assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts.",datascience,https://www.reddit.com/r/datascience/comments/17bobx9/wrong_data_in_dataset/,2,3,0.81,"[Comment(id='k5l0wwl'), Comment(id='k5m9q40')]"
17b32vd,WadeEffingWilson,,2023-10-18 22:18:57+00:00,False,,False,False,True,False,/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,"Those that have moved from a technical position to a leadership/supervisory position, do you regret it?","Do you still perform technical duties or is it nonstop meetings and people management? If it's the latter, do you miss the hands-on technical aspects or is it better on the leadership side?",datascience,https://www.reddit.com/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,40,46,0.93,"[Comment(id='k5h0z34'), Comment(id='k5gyz47'), Comment(id='k5i9958'), Comment(id='k5ijf4g'), Comment(id='k5hyhcp'), Comment(id='k5gzbru'), Comment(id='k5hnhn5'), Comment(id='k5ilel9'), Comment(id='k5j13uk'), Comment(id='k5kmn77'), Comment(id='k5gxk9a'), Comment(id='k5h5c35'), Comment(id='k5hoh4z'), Comment(id='k5joy6a'), Comment(id='k5kc6bv'), Comment(id='k5lpogx'), Comment(id='k5nzysk'), Comment(id='k5njgsp'), Comment(id='k5rg6iw'), Comment(id='k5nayq3'), Comment(id='k5i1cvg'), Comment(id='k5nabda'), Comment(id='k5kwi5h'), Comment(id='k5h7i7y'), Comment(id='k5nhix7'), Comment(id='k5h3xfm'), Comment(id='k5h7tyf'), Comment(id='k5itjiy'), Comment(id='k5nbae7'), Comment(id='k5rfcxy'), Comment(id='k5m6ry3'), Comment(id='k5nd9g6'), Comment(id='k5npi6j'), Comment(id='k5hch2g'), Comment(id='k5hhbel'), Comment(id='k5j3vxy'), Comment(id='k5ne671'), Comment(id='k5j9mb8'), Comment(id='k5nevqu'), Comment(id='k5omkmq')]"
17ar38i,jujuman1313,,2023-10-18 13:41:03+00:00,False,,False,False,True,False,/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,LLM domination on job descriptions,"Can anyone explain why many companies asking for LLM experience for data scientist roles?  
It wasn't there like 6-8 months ago, now around %70 of the job descriptions asking for that and it goes like Python, SQL and LLM. Looks a bit weird to be honest.  
What are they doing, creating their own chatgpt?  
",datascience,https://www.reddit.com/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,69,175,0.96,"[Comment(id='k5eq0p4'), Comment(id='k5egkrr'), Comment(id='k5enrc9'), Comment(id='k5eyofu'), Comment(id='k5eqcd2'), Comment(id='k5es29z'), Comment(id='k5fl1v7'), Comment(id='k5exe4t'), Comment(id='k5eq86c'), Comment(id='k5fsx60'), Comment(id='k5f4xg6'), Comment(id='k5f99gb'), Comment(id='k5euxn1'), Comment(id='k5eut37'), Comment(id='k5g32y7'), Comment(id='k5iny9u'), Comment(id='k5izquf'), Comment(id='k5j5lo3'), Comment(id='k5k6vap'), Comment(id='k5l1qu3'), Comment(id='k5mus0u'), Comment(id='k5oig9m'), Comment(id='k6369mb'), Comment(id='k5ev3y8'), Comment(id='k5exntj'), Comment(id='k5f0ubg'), Comment(id='k5exw4e'), Comment(id='k5fefsc'), Comment(id='k5k0xnd'), Comment(id='k5gykd5'), Comment(id='k5f98hp'), Comment(id='k5qatgn'), Comment(id='k5fccbk'), Comment(id='k5f5l1e'), Comment(id='k5f3m4z'), Comment(id='k5f4qbx'), Comment(id='k5f9c2u'), Comment(id='k5ewfq2'), Comment(id='k5frn5k'), Comment(id='k5ilsx9'), Comment(id='k5iyjnj'), Comment(id='k5mv1jo'), Comment(id='k6dwsfq'), Comment(id='k5expwl'), Comment(id='k5ic9bo'), Comment(id='k5f0let'), Comment(id='k5gjll1'), Comment(id='k5f4hib'), Comment(id='k5fe4du'), Comment(id='k5o5w59'), Comment(id='k61jbqg'), Comment(id='k5m66dz'), Comment(id='k5fojes'), Comment(id='k5g5eam'), Comment(id='k5fk6tt'), Comment(id='k5eyck0'), Comment(id='k6esj0j'), Comment(id='k5oh89h'), Comment(id='k5f9dcd'), Comment(id='k5f797o'), Comment(id='k5gi13e'), Comment(id='k5pqv30'), Comment(id='k5g60el'), Comment(id='k5g9zgk'), Comment(id='k5f6qwp'), Comment(id='k5i16pl'), Comment(id='k5fqo8a'), Comment(id='k5qfhqd'), Comment(id='k5g6j9i'), Comment(id='k5jv5xm')]"
17ay21z,Turbulent-City-9377,,2023-10-18 18:44:19+00:00,False,,False,False,True,False,/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,"What's better as a data scientist ""precursor role"": a software developer or a business analyst?","I've been offered the opportunity to transfer to my firm's IT department after I expressed interested in and demonstrated proficiency in data science (coming from a quantitative but not pure DS department). The IT department doesn't have a specific data science ""role"" though -- only software developer and business analyst. Given I want to eventually settle into a pure data scientist role -- and pursue a Masters in such (I'm 24) -- which of these two roles would you choose if you were taking a career-level view? 

In the software dev role, I'd get hands-on experience with writing code everyday, but it would be chiefly in a software development environment -- not data science. With the BA role, I would have hands-on experience with product management and dashboarding and Confluence, but not so much writing code. I'm torn. I just ultimately want to be in a role where I can dive into datasets everyday and always have a numpy-pandas-matplotlib-sklearn environment open on my computer.

Any advice would be greatly appreciated! Thanks so much.",datascience,https://www.reddit.com/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,42,39,0.84,"[Comment(id='k5ghezz'), Comment(id='k5fvait'), Comment(id='k5ge4zm'), Comment(id='k5gt6kn'), Comment(id='k5gvpqd'), Comment(id='k5gbz8r'), Comment(id='k5ig356'), Comment(id='k5hypub'), Comment(id='k5go4cy'), Comment(id='k5maaxd'), Comment(id='k5gw6un'), Comment(id='k5k2od7'), Comment(id='k5fwh92'), Comment(id='k5ged6f'), Comment(id='k5gefjj'), Comment(id='k5gn36k'), Comment(id='k5lrpik'), Comment(id='k5gv3q8'), Comment(id='k5gwf3j'), Comment(id='k5gcwgw'), Comment(id='k5ge5cq'), Comment(id='k5gm8zw'), Comment(id='k5ite05'), Comment(id='k5go82a'), Comment(id='k5mieyr'), Comment(id='k5h14t0'), Comment(id='k5is6te'), Comment(id='k5gq91h'), Comment(id='k5gnpaf'), Comment(id='k5kfmcv'), Comment(id='k5ge6co'), Comment(id='k5o2kum'), Comment(id='k5h7zjd'), Comment(id='k5jg7z2'), Comment(id='k5h19sz'), Comment(id='k5jfwaz'), Comment(id='k5ijpkg'), Comment(id='k5p9s12'), Comment(id='k5hifa0'), Comment(id='k5kjtyj'), Comment(id='k5pcrwd'), Comment(id='k5hnhxs')]"
17becn2,mesheaa,,2023-10-19 08:33:57+00:00,False,,1697811936.0,False,True,False,/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,Different loss function than evaluation metric,"Hi all,

I am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.

Do you know why gaze angular error is not used as loss as well?

&#x200B;

\[Edit\]

I tried now angular error as loss and it is really terrible. 

Like L1 loss results in a gaze angle error of around 2°, while my custom loss is resulting in errors around 50°. I though about using multi-loss approach, for example l1 + angular error to consider the depth length. What do you guys think of that?",datascience,https://www.reddit.com/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,2,3,1.0,"[Comment(id='k5j2vge'), Comment(id='k5jlnn4')]"
17az6v2,EagerMonkey,,2023-10-18 19:31:56+00:00,False,,False,False,True,False,/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,Will Understanding Advanced Data Structures Make Me a Better Data Scientist?,"I'm a data scientist with 5 yoe now, and I've never needed to implement a tree, a linked list, a graph, a stack, or a queue. If I need a decision tree, I use a package like sklearn. If I'm doing graph analysis, typically I treat it like a matrix. I don't even have any idea what models might need a queue, but maybe that's really important for data processing or training somewhere?

&#x200B;

Have any of you really needed to implement these data structures, or do you just use packages that are using them under the hood? Would I actually be meaningfully better at my day to day job if I knew when and how to use a linked list or a stack?",datascience,https://www.reddit.com/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,14,22,0.82,"[Comment(id='k5gewj9'), Comment(id='k5g5vfq'), Comment(id='k5hcts2'), Comment(id='k5gw49n'), Comment(id='k5gzz1d'), Comment(id='k5rh6hp'), Comment(id='k5hnh8o'), Comment(id='k5hodik'), Comment(id='k5hoomp'), Comment(id='k5h0yok'), Comment(id='k5ggh4a'), Comment(id='k5hh243'), Comment(id='k5innm2'), Comment(id='k5n5ywu')]"
17bf3cx,CursorInsight,,2023-10-19 09:28:19+00:00,False,,False,False,True,False,/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,Programming language for machine learning and data analysis – Our choice,"&#x200B;

## Python

Undoubtedly, **the uncrowned king** of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching, **is Python**. This is down to several reasons; the three most important among them are its **maturity**, the enormous **community**, and, last but not least, a **vast array of robust third-party libraries**. But even if Python is a magnanimous sovereign that many developers love, it doesn’t mean that there can’t be contenders occasionally.

## Julia

Fourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a **friendly syntax**, offers **efficient mathematical computations** out of the box, at a **performance on par with compiled languages**. And thus, [**Julia**](https://julialang.org/) was born (here’s a manifesto explaining [**why**](https://julialang.org/blog/2012/02/why-we-created-julia/) in more detail). Its first version was launched a bit more than eleven years ago.

## Our choice

Many in-depth comparisons of Python and Julia on the web (such as [**this one**](https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac) or [**this**](https://www.turing.com/kb/julia-vs-python)) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia’s growing popularity, we are sure more will follow. In the rest of this blog post, however, let’s explore why we picked Julia for our purposes. And that’s not to say that we don’t use Python for data science. On the contrary, we **often run analyses in both ecosystems simultaneously** to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.

## The advantages of Julia

So what makes Julia so compelling to us?

## Language features

Julia has:

* a friendly, easy-to-read (and write) syntax;
*  a flexible and expressive (part static, part dynamic) type system;
*  powerful mathematical notations, such as built-in vector and matrix operations;
*  efficient [**multiple dispatches**](https://en.wikipedia.org/wiki/Multiple_dispatch), a form of function polymorphism working with runtime types;
*  convenient and reliable parallel computing facilities;
*  meta-programming with macros and generated functions.

## Fast code execution

Julia compiles the source code to **native binary at runtime** via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer; **the benefits start to shine when a piece of code is run multiple times**. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.

## Built-in package management

Julia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of **stable and well-designed packages** is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.

## Interactive tools

Julia offers an **advanced** [**REPL**](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) with all the goodies of an interpreted language environment. These include:

* code and variable inspection,
*  code completion,
*  an interactive debugger,
*  benchmarking and profiling tools,
*  and a built-in help system.

**With third-party libraries, it can also be extended** with [**syntax highlighting**](https://github.com/KristofferC/OhMyREPL.jl), [**source code lookup**](https://github.com/tkf/InteractiveCodeSearch.jl) (even for base libraries), automatic [**code reload**](https://timholy.github.io/Revise.jl/stable/), and many more exciting, modern features.

All these together make Julia an **ideal environment for rapid prototyping**.

## From prototyping to production code

Because of the high-level interactive tools and fast code execution, **the transition from a rapid prototype to production-ready code can be as continuous as you’d like**. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.

Thanks to its friendly syntax and built-in package management, **the road to maintainable code is well paved**. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.

As a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.

## The disadvantages of Julia

That said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:

* the very powerful tool of broadcasting and vectorization can be intimidating at first;
* [**time to first plot**](https://discourse.julialang.org/t/time-to-first-plot-clarification/58534) can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;
*  many packages never reach a stable state or just become unmaintained; others are poorly designed or written;
* [**releasing a binary package**](https://github.com/JuliaLang/PackageCompiler.jl) can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.

## Summary

In conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.

Still, in the past years, **Julia has proved to be our reliable and faithful companion**. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!",datascience,https://www.reddit.com/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,18,0,0.48,"[Comment(id='k5jf19l'), Comment(id='k5j0r5o'), Comment(id='k5iytwh'), Comment(id='k5j7ukl'), Comment(id='k5jdtg0'), Comment(id='k5jwl6m'), Comment(id='k5jvi58'), Comment(id='k5jhfve'), Comment(id='k5k748m'), Comment(id='k5kbsax'), Comment(id='k5mulv3'), Comment(id='k5n8vd6'), Comment(id='k5jxwld'), Comment(id='k5lm34l'), Comment(id='k5lsoe4'), Comment(id='k5p9tpk'), Comment(id='k5pagdu'), Comment(id='k5pfens')]"
17bdzis,MandM-DataScience,,2023-10-19 08:06:47+00:00,False,,False,False,True,False,/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,Market Timing & Risk Management - Portfolio allocation,"Hi everyone!  
Is it possible to create a market timing strategy using unsupervised learning? 

Let's find out.

Relevant Topics:

* Used S&P500 data
* Segmenting Time series using Online Change Detection Point
* Clustering segments with KMeans
* Risk Allocation
* Value at Risk

Here's the notebook:  
[https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook](https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook)

Every and each comment / feedback is greatly appreciated!

Thank you!  
M&M",datascience,https://www.reddit.com/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,0,1,1.0,[]
17ajqwd,treaty_tonvis,,2023-10-18 06:12:22+00:00,False,,False,False,True,False,/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,Shit scared of Leetcode!,"I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you'll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can't do anything beyond Leetcode easy, my mind just doesn't accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don't practice that problem in every few days. 

Someone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?",datascience,https://www.reddit.com/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,54,56,0.89,"[Comment(id='k5dcx0n'), Comment(id='k5du4v1'), Comment(id='k5eqffk'), Comment(id='k5dd0a6'), Comment(id='k5dc293'), Comment(id='k5djtng'), Comment(id='k5fvl12'), Comment(id='k5edix5'), Comment(id='k5eqbgc'), Comment(id='k5eyqg7'), Comment(id='k5g08lg'), Comment(id='k5n93lf'), Comment(id='k5eemek'), Comment(id='k5fcc0y'), Comment(id='k5ho35a'), Comment(id='k5j2lql'), Comment(id='k5j2pgh'), Comment(id='k5lybfa'), Comment(id='k5mazo9'), Comment(id='k617vpl'), Comment(id='k5evdso'), Comment(id='k5ed2lh'), Comment(id='k5eder1'), Comment(id='k5hsxxk'), Comment(id='k5edcvz'), Comment(id='k5deok8'), Comment(id='k5fezs8'), Comment(id='k5eco1j'), Comment(id='k5hu2h8'), Comment(id='k5htsp8'), Comment(id='k5evxp3'), Comment(id='k5htq9j'), Comment(id='k5htzaz'), Comment(id='k5hu8st'), Comment(id='k5htvy8'), Comment(id='k5fgs31'), Comment(id='k5hub78'), Comment(id='k5euitx'), Comment(id='k5dxpv5'), Comment(id='k5ewzo0'), Comment(id='k5ecfco'), Comment(id='k5htew8'), Comment(id='k5evlbb'), Comment(id='k5ibh3l'), Comment(id='k5ip175'), Comment(id='k5hstd7'), Comment(id='k5fffvk'), Comment(id='k5ed12z'), Comment(id='k5htl9n'), Comment(id='k5fju9a'), Comment(id='k5ht6aa'), Comment(id='k5ht6po'), Comment(id='k5ht73y'), Comment(id='k5hwjvj')]"
17b3lup,_degamus_,,2023-10-18 22:42:20+00:00,False,,False,False,True,False,/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,Advice on imbalanced datasets with many missing values,"Hi! I am currently working on a binary classification model for a highly imbalanced dataset with lots of missing values in there. I tried using multiple techniques for resampling (Random, SMOTE, and SMOTETomak) and imputation (MICE), as well as a bit of tweaking of class weights and loss function, but still I am not able to get higher than this.

CatBoost Accuracy:  0.843492894540015
              precision    recall  f1-score   support

         0.0       0.95      0.87      0.91      4775
         1.0       0.36      0.62      0.46       573

    accuracy                           0.84      5348
   macro avg       0.66      0.74      0.68      5348
weighted avg       0.89      0.84      0.86      5348

Any ideas on what can I also try considering such results and above mentioned trials? Any feature engineering techniques that I might not know? 

Also one of the interesting things about dataset is relatively large amount of categorical features - 30 out of 140 (two of them have 2k different options, others are in the range from 3 to 30). I used multiple different methods for encoding here depending on the amount of categories - One Hot, Binary and Target.

One of the main issues of the dataset is lack of context so I'm mostly trying to improve both precision and recall (and f1 as a result) at least to somewhat degree.

Thanks in advance for any possible ideas?",datascience,https://www.reddit.com/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,5,2,1.0,"[Comment(id='k5hfqul'), Comment(id='k5kq66q'), Comment(id='k5jahml'), Comment(id='k5kqpb5'), Comment(id='k5kswin')]"
17aba8a,Sea-Bodybuilder-1277,,2023-10-17 22:55:29+00:00,False,,1697588397.0,False,True,False,/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,I'm giving up finding a job. I feel like I'll have better luck applying to PhD programs. This is a rant.,"Just recently graduated in May with a BS statistics from texas a&m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I'm almost done with the meta coursera front-end prof certificate and I'm gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I've thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn't get any traffic, maybe it'll look good on a resume.

I'm disenchanted with it all, I'm hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn't a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as ""pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference"", I'm not asking any questions. It's just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says ""I'm of value"" and ""people can rely on me"", and knowing people. Especially when employers aren't going to ask my professors how I was like,  I imagine I'll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I'm just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I'm pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can't get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don't mind taking tests, and I know how to live with a low overhead (I don't buy stuff I don't need). I know what really matters, your basic needs, family, a few good friends. Ok, that's not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don't.",datascience,https://www.reddit.com/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,152,149,0.83,"[Comment(id='k5buczl'), Comment(id='k5ca88v'), Comment(id='k5by4od'), Comment(id='k5ctnt2'), Comment(id='k5cwg09'), Comment(id='k5c80vt'), Comment(id='k5bz1d9'), Comment(id='k5caxok'), Comment(id='k5c5286'), Comment(id='k5cg8lq'), Comment(id='k5casjl'), Comment(id='k5cnlw7'), Comment(id='k5dmeml'), Comment(id='k5f1hcb'), Comment(id='k5gta2w'), Comment(id='k5c5vf7'), Comment(id='k5ci932'), Comment(id='k5ccd69'), Comment(id='k5dfb2n'), Comment(id='k5ecgx8'), Comment(id='k5elyu7'), Comment(id='k5d5t89'), Comment(id='k5d7a25'), Comment(id='k5bxzcp'), Comment(id='k5dkann'), Comment(id='k5dotl7'), Comment(id='k5dze6d'), Comment(id='k5e5tao'), Comment(id='k5ed4op'), Comment(id='k5ed9lk'), Comment(id='k5ee868'), Comment(id='k5ee9xy'), Comment(id='k5ejrxa'), Comment(id='k5f2r17'), Comment(id='k5fhrjm'), Comment(id='k5fiv7e'), Comment(id='k5gp0l3'), Comment(id='k5hijid'), Comment(id='k5hmfbd'), Comment(id='k5s7jud'), Comment(id='k5bunrc'), Comment(id='k5dpnsj'), Comment(id='k5cajzp'), Comment(id='k5f3ygk'), Comment(id='k5ei40z'), Comment(id='k5c8qow'), Comment(id='k5cy1j3'), Comment(id='k5byff1'), Comment(id='k5d045p'), Comment(id='k5cvw20'), Comment(id='k5dfsp7'), Comment(id='k5c0nza'), Comment(id='k5e550m'), Comment(id='k5c645e'), Comment(id='k5cgh7i'), Comment(id='k5cbb2u'), Comment(id='k5cof2j'), Comment(id='k5c6d2d'), Comment(id='k5cileb'), Comment(id='k5cfkh7'), Comment(id='k5evnrk'), Comment(id='k5ex818'), Comment(id='k5d7miy'), Comment(id='k5c88t9'), Comment(id='k5c9fc9'), Comment(id='k5eyguv'), Comment(id='k5euipf'), Comment(id='k5ew13f'), Comment(id='k5ex0ed'), Comment(id='k5c2f7n'), Comment(id='k5bv89r'), Comment(id='k5f4o19'), Comment(id='k5funt5'), Comment(id='k5f3v4u'), Comment(id='k5czyhl'), Comment(id='k5f5e0k'), Comment(id='k5cayai'), Comment(id='k5ca317'), Comment(id='k5elfkm'), Comment(id='k5e7vpj'), Comment(id='k5cy1ix'), Comment(id='k5drl6l'), Comment(id='k5e4amz'), Comment(id='k5c28bb'), Comment(id='k5c2nvs'), Comment(id='k5cmb61'), Comment(id='k5ca54u'), Comment(id='k5curzh'), Comment(id='k5c8uj8'), Comment(id='k5cjlxo'), Comment(id='k5dymvz'), Comment(id='k5d81i7'), Comment(id='k5ca9ad'), Comment(id='k5exoie'), Comment(id='k5f2h5z'), Comment(id='k5dyooz'), Comment(id='k5bxa0a'), Comment(id='k5hwpbc'), Comment(id='k5f6w21'), Comment(id='k5dvnjj'), Comment(id='k5fkjhg'), Comment(id='k5eovl0'), Comment(id='k5eyba9'), Comment(id='k5f6z9t'), Comment(id='k5eu8pr'), Comment(id='k5c2own'), Comment(id='k5cgnlk'), Comment(id='k5c3fmt'), Comment(id='k5ey64e'), Comment(id='k5cf24j'), Comment(id='k5cbvxd'), Comment(id='k5ckkfm'), Comment(id='k5d8b10'), Comment(id='k5hzqq7'), Comment(id='k5f548l'), Comment(id='k5ejkk0'), Comment(id='k5f3ftj'), Comment(id='k5ivum5'), Comment(id='k5fqiex'), Comment(id='k5eu1w7'), Comment(id='k5c36cc'), Comment(id='k5capxg'), Comment(id='k5cgula'), Comment(id='k5ciw4s'), Comment(id='k5g2atx'), Comment(id='k5ci0oc'), Comment(id='k5ffz5k'), Comment(id='k5g1w15'), Comment(id='k5c9jyx'), Comment(id='k5f8luh'), Comment(id='k5chu3k'), Comment(id='k5d93iv'), Comment(id='k5eq82h'), Comment(id='k5jnhq9'), Comment(id='k5frl08'), Comment(id='k5c4dnc'), Comment(id='k5chiew'), Comment(id='k5cjc3x'), Comment(id='k5d9qyv'), Comment(id='k5evju0'), Comment(id='k5kvmrn'), Comment(id='k5ft7ku'), Comment(id='k5ewo98'), Comment(id='k5shvf6'), Comment(id='k5fzks1'), Comment(id='k5f39iv'), Comment(id='k5n5yrd'), Comment(id='k5g3gsn'), Comment(id='k5ggx6d'), <MoreComments count=0, children=[]>]"
17b2d08,CaptainVJ,,2023-10-18 21:48:19+00:00,False,,False,False,True,False,/r/datascience/comments/17b2d08/binary_classification_question/,Binary classification question?,"So I’m trying to build a model to find some inappropriate payments. So I have the data of all payments made, however, some of them were audited while the vast majority aren’t. 

The ones that aren’t audited are just automatically approved while the ones that are audited are approved or rejected based on auditors judgment. So my plan is to just use all the payments that has been audited as the population and ignore the payments that have never been audited since they don’t really tell us much.  

So probably about 1% of payments are audited and if that about 7% are rejected. 

Now the issue is that most of the payments that were rejected were for minor issues. Maybe the person who’s entered the payment made a slight typo for the invoice number, so that was rejected and they had to resubmit it, or something minor. 

Those payments aren’t abiding by some minor rules and they need to be rejected and resubmitted after being corrected. They’re wrong but not really worth the time because we aren’t saving any money. Unfortunately, that’s about 70% of rejected payments. 

Now the other 30% is where the real savings is happening, potential fraud, the accountant mistyped the amount to be paid or whatever. And that’s what I’m really trying to find, if I find the others that’s cool but doesn’t really do much. 

How would I go about selecting my data for that. Would I just ignore the 60% of rejected payments that aren’t that big of a deal and proceed without. If so, would I also reduce the number the number of payments that were accepted as well by 60%. 

Or any alternative suggestions?",datascience,https://www.reddit.com/r/datascience/comments/17b2d08/binary_classification_question/,1,1,0.67,[Comment(id='k5hdd3b')]
17ax0xj,The_powerful_onion,,2023-10-18 17:59:55+00:00,False,,False,False,True,False,/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,Project ideas that combine Data Science (Data Analytics) and Digital Marketing,"Hello everyone! I am currently working in digital marketing (I’m entry level) and I have a degree in data analytics. I would like to be able to combine both fields, and I’m looking for any good project ideas to do so (preferably using R or Python). Any ideas are helpful!",datascience,https://www.reddit.com/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,4,2,1.0,"[Comment(id='k5iifzg'), Comment(id='k5ftof9'), Comment(id='k5jyrno'), Comment(id='k5fu1x0')]"
17aq5r0,RecoverMotor,,2023-10-18 12:56:53+00:00,False,,False,False,True,False,/r/datascience/comments/17aq5r0/microsoft_azure/,Microsoft Azure,"I am Data analyst with 2 years of experience and in the companies that I have work, I have not had any experience with data processing in cloud services. I am interested in learn Azure, AWS or Google cloud for data science and get the certifications. Could you tell me what is better, and how important are those certificates in my career path?.
Thanks!!!",datascience,https://www.reddit.com/r/datascience/comments/17aq5r0/microsoft_azure/,1,4,0.84,[Comment(id='k5kvtpr')]
17a79kw,wildwildwildebeast,,2023-10-17 20:03:17+00:00,False,,False,False,True,False,/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/,Interview Take Home task seemed unreasonable,"I am finishing my my masters degree in data analytics. Previously I've worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. 

I got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn't get home till 10pm.

Fast forward this morning. I wake up at 8.i get started on the R project at 9am.

The data was some of the messiness I've seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. 

I'm not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven't asked me to do anything like that in such a short time. Is this to be expected going forward?",datascience,https://www.reddit.com/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/,58,100,0.95,"[Comment(id='k5bh3pz'), Comment(id='k5b76i6'), Comment(id='k5bonvg'), Comment(id='k5b6bl8'), Comment(id='k5bkydj'), Comment(id='k5c088s'), Comment(id='k5be4f3'), Comment(id='k5cqdjx'), Comment(id='k5crchr'), Comment(id='k5cfgjq'), Comment(id='k5ciusw'), Comment(id='k5cp189'), Comment(id='k5exzwb'), Comment(id='k5b1pps'), Comment(id='k5bzvwz'), Comment(id='k5bqc7r'), Comment(id='k5cdgbj'), Comment(id='k5cj7bw'), Comment(id='k5ba7be'), Comment(id='k5bphpj'), Comment(id='k5cdr0u'), Comment(id='k5cp1ng'), Comment(id='k5dterp'), Comment(id='k5duubw'), Comment(id='k5e0i40'), Comment(id='k5etosj'), Comment(id='k5hguyl'), Comment(id='k5c4hef'), Comment(id='k5bzdhm'), Comment(id='k5c59lz'), Comment(id='k5bt51y'), Comment(id='k5c2axh'), Comment(id='k5ctx6g'), Comment(id='k5d71wv'), Comment(id='k5hkk20'), Comment(id='k5cru3n'), Comment(id='k5co026'), Comment(id='k5bzejx'), Comment(id='k5c1dg9'), Comment(id='k5dgj8a'), Comment(id='k5c8h83'), Comment(id='k5dsi94'), Comment(id='k5dj9vn'), Comment(id='k5e1j7f'), Comment(id='k5cdafz'), Comment(id='k5djeid'), Comment(id='k5cqbaw'), Comment(id='k5ems69'), Comment(id='k5dq5h7'), Comment(id='k5fajuy'), Comment(id='k5c6gas'), Comment(id='k5cpvbc'), Comment(id='k5cxnzu'), Comment(id='k5d47yb'), Comment(id='k5e4wf5'), Comment(id='k5esxv5'), Comment(id='k5cy87a'), Comment(id='k5fd4vg'), Comment(id='k5d3qnb')]"
17atfvp,cdtmh,,2023-10-18 15:26:22+00:00,False,,False,False,True,False,/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,Pricing Analysis Career Progression to Data Science,"I was a DS in an insurance company (essentially a pricing analyst), I was doing a lot of XGB and GLM models etc. It was enjoyable but I have a degree in DS so I always wanted to move into something which would project me into more complex/cool modelling.

Anyway, my question, I moved to London and am now looking for a new job but the currently tough market is looking for much more experience than I currently have in data science related work (I have 1 year). Would taking a Pricing Analyst role (doing the same algorithms as before) hurt my progression or help it in the eventual goal of being in something machine learning related down the line.

I think it would strengthen my prediction models, but at the same time I wouldn't be exercising what I did in my MSc degree. What do you think?",datascience,https://www.reddit.com/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,2,2,1.0,"[Comment(id='k5f82ia'), Comment(id='k5f883f')]"
17al968,Asleep-Fun-6508,,2023-10-18 07:56:32+00:00,False,,False,False,True,False,/r/datascience/comments/17al968/forecasting_sales/,Forecasting sales,"So i’m working on a project that forecasts sales of products in a series. Curious to know the best approach to model “cascaded” products i.e old version of the series when the new one launches.
Using a Recursive multistep regression approach to forecast with some features

Appreciate the help, thanks 🙏🏼",datascience,https://www.reddit.com/r/datascience/comments/17al968/forecasting_sales/,4,6,1.0,"[Comment(id='k5dj1jt'), Comment(id='k5e90qa'), Comment(id='k5dpe35'), Comment(id='k5dpza7')]"
17alvvb,jaegarbong,,2023-10-18 08:42:00+00:00,False,,False,False,True,False,/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,How can I show knowledge in topics I haven't worked on professionally?,"I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. 

The topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.

My problem is how can I show this in my recruiters such that they don't just ignore my personal projects section. ",datascience,https://www.reddit.com/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,3,3,0.81,"[Comment(id='k5e0kh2'), Comment(id='k7slmwv')]"
17ad4og,relativefluffy,,2023-10-18 00:19:45+00:00,False,,False,False,True,False,/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,Where do you start if you are new to mathematical models,I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters,datascience,https://www.reddit.com/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,10,12,0.88,"[Comment(id='k5cbhtj'), Comment(id='k5cfvsa'), Comment(id='k5crdvh'), Comment(id='k5dl6pp'), Comment(id='k5cmf1t'), Comment(id='k5c4kz1'), Comment(id='k5e79mh'), Comment(id='k5cz5g4'), Comment(id='k5dkgc0'), Comment(id='k5dztnv')]"
179huzu,softwareitcounts,,2023-10-16 21:51:33+00:00,False,,False,True,False,False,/r/datascience/comments/179huzu/meme_mondays/,Meme Mondays,,datascience,https://i.redd.it/zxdz4pm6ymub1.png,99,1656,0.98,"[Comment(id='k57i6jw'), Comment(id='k583pad'), Comment(id='k58ghzy'), Comment(id='k586b9s'), Comment(id='k570knd'), Comment(id='k571zj7'), Comment(id='k57qkuu'), Comment(id='k594mix'), Comment(id='k57zbbv'), Comment(id='k59yet2'), Comment(id='k58xmqf'), Comment(id='k58tn8n'), Comment(id='k59iy03'), Comment(id='k575kvk'), Comment(id='k59gjac'), Comment(id='k59lzh2'), Comment(id='k5adwwq'), Comment(id='k5b1x4p'), Comment(id='k5c0wt3'), Comment(id='k5cabb7'), Comment(id='k5dgncr'), Comment(id='k58pf1v'), Comment(id='k58qq2k'), Comment(id='k597da7'), Comment(id='k58ya18'), Comment(id='k59u8jg'), Comment(id='k5a31mz'), Comment(id='k5afb9l'), Comment(id='k5az13g'), Comment(id='k5cm9n5'), Comment(id='k5d0l23'), Comment(id='k5d86mo'), Comment(id='k5e541z'), Comment(id='k7dizl9'), Comment(id='k7hnfkh'), Comment(id='k59gy0c'), Comment(id='k57pdn7'), Comment(id='k57wmlw'), Comment(id='k5huyz6'), Comment(id='k5ba7dc'), Comment(id='k58nak8'), Comment(id='k5anan4'), Comment(id='k58dsf8'), Comment(id='k579q4m'), Comment(id='k57ac9z'), Comment(id='k57ntiw'), Comment(id='k58dqij'), Comment(id='k5a5sph'), Comment(id='k5cjtw6'), Comment(id='k5az82f'), Comment(id='k5c70ki'), Comment(id='k59h72c'), Comment(id='k5m22b3'), Comment(id='k5azcyx'), Comment(id='k5a8sgd'), Comment(id='k5focj2'), Comment(id='k58wi1z'), Comment(id='k596354'), Comment(id='k5ah6bc'), Comment(id='k5a2hn1'), Comment(id='k5a360m'), Comment(id='k57py64'), Comment(id='k58qya2'), Comment(id='k5a7mhs'), Comment(id='k5agofj'), Comment(id='k58drgd'), Comment(id='k599ohk'), Comment(id='k59ebn0'), Comment(id='k5ap7vj'), Comment(id='k57nahp'), Comment(id='k58j3cy'), Comment(id='k5aufaw'), Comment(id='k5dzep0'), Comment(id='k5clzi0'), Comment(id='k5eexzi'), Comment(id='k5efegl'), Comment(id='k5d0yq4'), Comment(id='k5c5gou'), Comment(id='k59c105'), Comment(id='k5d9kxq'), Comment(id='k5aalen'), Comment(id='k57tjz7'), Comment(id='k57uru6'), Comment(id='k5ctpey'), Comment(id='k59e9wk'), Comment(id='k5a6ah1'), Comment(id='k591jyr'), Comment(id='k59p8kz'), Comment(id='k59hfej'), Comment(id='k5dkxjb'), Comment(id='k5e3fhm'), Comment(id='k59gs3l'), Comment(id='k5du9r9'), Comment(id='k5p5jf3'), Comment(id='k5a02p7'), Comment(id='k5bgn2o'), Comment(id='k5a85sf'), Comment(id='k5bh31z'), Comment(id='k5aalcb')]"
17ayhj7,Jogy-Bogy,,2023-10-18 19:02:14+00:00,False,,False,False,False,False,/r/datascience/comments/17ayhj7/mainspring_routine_planner/,Mainspring - Routine Planner,"Hey everyone,
I'm an indie app developer, building in public on Threads.
Recently I launched Mainspring, a new routine planner app that helps you keep track of your every-day actions with a simple and intuitive UI.

Why is Mainspring different?
I built it with simplicity in mind, everyone have different goals with these kind of apps, some want to just track events, others want to keep themselves motivated, Mainspring will be a great fit for a broad number of people. Mainspring also provides motivational and beautiful statistics and graphs that can be viewed to empower progress.

Your full event history can be viewed and is beneficial if you want to remember when you last did something (e.g. when did I last got a haircut). 

Check it out and let me know what you think. 

iOS: https://apps.apple.com/app/mainspring-routine-planner/id6467129951

Android:
https://play.google.com/store/apps/details?id=com.naamapps.mainspring",datascience,https://www.reddit.com/gallery/17ayhj7,0,0,0.38,[]
17alwcz,zurdosios,,2023-10-18 08:43:00+00:00,False,,1697628721.0,False,True,False,/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,"DAGitty Question: Testable Implications only describes independencies, but not dependencies","Why does the DAGitty ""Testable Dependencies"" function only describe independencies, but not spurious correlations?

&#x200B;

E.g, if I have B->A<-C,

DAGitty just tells me that

B ⊥ C is the only testable (in)dependency

Why shouldn't we expect also

B⊥̸C|A

(i.e, B and C have a spurious correlation given A)?",datascience,https://www.reddit.com/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,0,2,1.0,[]
17a6ken,MultiPass10,,2023-10-17 19:33:18+00:00,False,,False,False,True,False,/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,"Converting XGBoost decision models to ""if-then"" statements","I am aware of a few tools that aid in converting XGBoost decision trees to ""if-then"" statements. I'm curious if anyone has experience with this approach, and how feasible/successful was the outcome?",datascience,https://www.reddit.com/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,17,16,0.87,"[Comment(id='k5ayfsc'), Comment(id='k5ckr3a'), Comment(id='k5bj13d'), Comment(id='k5btv5a'), Comment(id='k5brlkb'), Comment(id='k5ax0ch'), Comment(id='k5dd6yt'), Comment(id='k5cf4lt'), Comment(id='k5cfgs9'), Comment(id='k5e7laj'), Comment(id='k5biawr'), Comment(id='k5by20s'), Comment(id='k5dbna8'), Comment(id='k5cjqmv'), Comment(id='k5dldc3'), Comment(id='k5e0ykj'), Comment(id='k5eeaeo')]"
17aveed,7sidedleaf,,2023-10-18 16:50:55+00:00,False,,False,False,True,False,/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,Question for Data Scientists in their day to day work,"How often do you guys use calculus and linear algebra for your work? I've heard that for data science, especially machine learning, that it's important to understand linear algebra and calculus, but how true is this statement? I've taken some stats and probability courses in college for my minor, but haven't taken anything past calc 1 or linear algebra. Are these must-haves for your day to day work?",datascience,https://www.reddit.com/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,16,0,0.36,"[Comment(id='k5fde3b'), Comment(id='k5g030m'), Comment(id='k5fj3j7'), Comment(id='k5i8fm9'), Comment(id='k5incff'), Comment(id='k5ff024'), Comment(id='k5hfrk3'), Comment(id='k5jacrp'), Comment(id='k5izk0z'), Comment(id='k5izlem'), Comment(id='k5g217j'), Comment(id='k5izmm4'), Comment(id='k5j01ki'), Comment(id='k5jzz0b'), Comment(id='k5j499m'), Comment(id='k5j57n0')]"
17amx3l,CanberraMogul,,2023-10-18 09:53:58+00:00,False,,False,False,True,False,/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,Graduate US/International Career Opportunities," I'm about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.

I'm currently exploring career opportunities in the US and other international locations. I'm curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!

Thank you in advance!",datascience,https://www.reddit.com/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,0,0,0.33,[]
179uwm2,Round_Inflation_2199,,2023-10-17 10:07:15+00:00,False,,False,False,True,False,/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,Moving to USA or Staying in UAE,"Hi Folks

I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).

Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.

I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.

Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  


&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,81,66,0.84,"[Comment(id='k58r154'), Comment(id='k58teyf'), Comment(id='k59jkm5'), Comment(id='k58vej0'), Comment(id='k5a4f3b'), Comment(id='k5918re'), Comment(id='k59a7s9'), Comment(id='k58wyo9'), Comment(id='k5a65ss'), Comment(id='k5a3y8y'), Comment(id='k5a3qij'), Comment(id='k5a94uw'), Comment(id='k59b6da'), Comment(id='k5a7o3e'), Comment(id='k59reqj'), Comment(id='k59nybo'), Comment(id='k5a0sje'), Comment(id='k5aiubf'), Comment(id='k5aq09r'), Comment(id='k5b3311'), Comment(id='k5bbrc7'), Comment(id='k5c6fhw'), Comment(id='k590v17'), Comment(id='k59ztv9'), Comment(id='k59sc0b'), Comment(id='k59axvn'), Comment(id='k590iz0'), Comment(id='k5bq1o8'), Comment(id='k5caunb'), Comment(id='k5auh0j'), Comment(id='k59snzd'), Comment(id='k5bbpau'), Comment(id='k5cbc3i'), Comment(id='k59p9dz'), Comment(id='k5a0ql6'), Comment(id='k5b5uqu'), Comment(id='k5b91qx'), Comment(id='k5b9xpj'), Comment(id='k5bfd93'), Comment(id='k5bucr4'), Comment(id='k5bx1n6'), Comment(id='k5c4zkj'), Comment(id='k5c6ubc'), Comment(id='k5c6we5'), Comment(id='k5crzs4'), Comment(id='k5czuww'), Comment(id='k5d7fu1'), Comment(id='k5ddxie'), Comment(id='k5hlbhg'), Comment(id='k5i8irh'), Comment(id='k5a7kje'), Comment(id='k5aiipp'), Comment(id='k5hmkb5'), Comment(id='k5a69ie'), Comment(id='k58ytqr'), Comment(id='k5ai0o6'), Comment(id='k5c8rvl'), Comment(id='k5a6s4g'), Comment(id='k5lt2ol'), Comment(id='k5akh9n'), Comment(id='k5d0ymw'), Comment(id='k5bc2gx'), Comment(id='k5aqbme'), Comment(id='k5c9oli'), Comment(id='k5a91t3'), Comment(id='k5d4gz7'), Comment(id='k5hm06v'), Comment(id='k5bx9lg'), Comment(id='k5bg2mr'), Comment(id='k5awsvv'), Comment(id='k5cavzf'), Comment(id='k5adiof'), Comment(id='k5c1gdj'), Comment(id='k5bjqgq'), Comment(id='k5azphd'), Comment(id='k5cb59j'), Comment(id='k5ae7ma'), Comment(id='k5d4l3f'), Comment(id='k5afsda'), Comment(id='k5ao8yx')]"
17ag1pr,DanRobin1r,,2023-10-18 02:37:46+00:00,False,,False,False,True,False,/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/,Anyone here that knows where to find scientific papers about regression models for Sports results?,,datascience,https://www.reddit.com/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/,1,3,1.0,[Comment(id='k5d5zrr')]
17alfw3,NFTHUNTERXX,,2023-10-18 08:09:16+00:00,False,,False,False,True,False,/r/datascience/comments/17alfw3/fuel_consumption/,Fuel consumption,"Hello everyone 

I hope you have an amazing day so far.

I want to create a model to predict/estimate furl consumption of ships for their voyages. I'm thinking to consider weight,wind speed, wind direction etc. Any suggestions of what model should I create?",datascience,https://www.reddit.com/r/datascience/comments/17alfw3/fuel_consumption/,3,0,0.33,"[Comment(id='k5dzhky'), Comment(id='k7slqdn'), Comment(id='k6dhuhc')]"
17al56s,redd-dev,,2023-10-18 07:48:41+00:00,False,,False,False,True,False,/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,What are some of the best library frameworks to use for speech2text and text2speech AI chatbot,"Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? 

I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?",datascience,https://www.reddit.com/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,0,1,1.0,[]
17ajf0e,IamFromNigeria,,2023-10-18 05:50:24+00:00,False,,False,False,True,False,/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,What's the best way to implement Shaq and Anchor (XAI) techniques,"Anyone done something on XAI where you use SHAP and Anchor model to explain your model?

I implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so",datascience,https://www.reddit.com/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,0,1,1.0,[]
17aaayg,SpecialEngineer7951,,2023-10-17 22:12:46+00:00,False,,False,False,False,False,/r/datascience/comments/17aaayg/we_built_an_opensource_platform_to_process/,We built An Open-Source platform to process relational and Graph Query simultaneously,,datascience,https://github.com/apache/age,4,4,1.0,"[Comment(id='k70ssox'), Comment(id='k5blg07'), Comment(id='k74828g'), Comment(id='k5blvse')]"
17a9bma,Administrative_Bar46,,2023-10-17 21:31:23+00:00,False,,False,False,True,False,/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,Moving to Big Tech from big government contractor,"Hello all,

 I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.

I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?",datascience,https://www.reddit.com/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,2,4,0.83,"[Comment(id='k5edslm'), Comment(id='k5eo4ir')]"
17ai9df,Rcpiv,,2023-10-18 04:37:37+00:00,False,,False,False,True,False,/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,What makes a good take home?,Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate’s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.,datascience,https://www.reddit.com/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,34,2,0.55,"[Comment(id='k5d2ezq'), Comment(id='k5f474x'), Comment(id='k5d545b'), Comment(id='k5dhxg4'), Comment(id='k5ehutr'), Comment(id='k5eapqx'), Comment(id='k5f6wlc'), Comment(id='k5dtx1t'), Comment(id='k5egcho'), Comment(id='k5di1rg'), Comment(id='k5ghzlb'), Comment(id='k5gx94p'), Comment(id='k5laxkb'), Comment(id='k5d4hxc'), Comment(id='k5l7pq1'), Comment(id='k5e838h'), Comment(id='k5f22la'), Comment(id='k5gsjqh'), Comment(id='k5ejqid'), Comment(id='k5dibtt'), Comment(id='k5ic5l5'), Comment(id='k5d4ojr'), Comment(id='k5lgquv'), Comment(id='k5ei3rq'), Comment(id='k5eajn6'), Comment(id='k5f4ws0'), Comment(id='k5epmy3'), Comment(id='k5e8xw7'), Comment(id='k5eiaev'), Comment(id='k5ecm7k'), Comment(id='k5egvcf'), Comment(id='k5f590m'), Comment(id='k5em7qb'), Comment(id='k5gwk2b'), Comment(id='k5gzz52')]"
17adx4s,spx416,,2023-10-18 00:56:21+00:00,False,,False,False,True,False,/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,Performance issues with dbscan,I’m looking to clustering on a dimensionally reduced dataset of 3D vectors. I’ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I’m looking for. I also tried using dbscan but I’ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I’d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.,datascience,https://www.reddit.com/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,6,1,1.0,"[Comment(id='k5co1b5'), Comment(id='k5e8wgh'), Comment(id='k5e91yq'), Comment(id='k6fmjaj'), Comment(id='k5eidq4'), Comment(id='k6fnnyy')]"
179ub5l,VGFenohmen,,2023-10-17 09:25:13+00:00,False,,False,False,True,False,/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,Predict maximum capacity of parking lots,"Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.

The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.

Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.

How would you recommend approaching this task?",datascience,https://www.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,36,15,0.78,"[Comment(id='k58p12q'), Comment(id='k592zrb'), Comment(id='k58sk7b'), Comment(id='k58nns5'), Comment(id='k59raol'), Comment(id='k59evw5'), Comment(id='k59lp3g'), Comment(id='k59mc5j'), Comment(id='k5adgep'), Comment(id='k58tjqk'), Comment(id='k5bisec'), Comment(id='k5dwa30'), Comment(id='k5adzj5'), Comment(id='k5apbhn'), Comment(id='k5alt5o'), Comment(id='k5atrvj'), Comment(id='k5ci6vm'), Comment(id='k58q4ue'), Comment(id='k58sn62'), Comment(id='k5d7vlz'), Comment(id='k5a9m0v'), Comment(id='k58t1wn'), Comment(id='k58ohj5'), Comment(id='k59gd3x'), Comment(id='k598ry3'), Comment(id='k58vfnm'), Comment(id='k58tqzg'), Comment(id='k5a1v7b'), Comment(id='k5amicq'), Comment(id='k5b1l9m'), Comment(id='k5cjcah'), Comment(id='k58qctu'), Comment(id='k5d5cqr'), Comment(id='k59xnzx'), Comment(id='k5awv7v'), Comment(id='k58szg3')]"
17a6t46,After_Reception1696,,2023-10-17 19:43:44+00:00,False,,False,False,True,False,/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,Seeking Advice on Machine Learning Algorithm Selection for Competitions," 

Hello, fellow data science enthusiasts! I'm participating in some machine learning competitions and I'm looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!

1. Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?
2. What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?
3. Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?

Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!""",datascience,https://www.reddit.com/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,1,2,1.0,[Comment(id='k5b0v02')]
17aba8j,glassAlloy,,2023-10-17 22:55:30+00:00,False,,False,False,True,False,/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals," 

Hey!

**Startup:**

\- Apply Script dot com ""Connect business and data professionals via pre-recorded standardized video interviews.""

**More details:**

**Problems with Traditional Hiring**

\- Outdated: The current method of conducting interviews has become overly complex and outdated.

\- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.

\- Expensive: The man-hours invested by HR and engineering teams are costly.

\- Constraining: Interviews are fixed to specific times and locations.

\- Cumbersome: The experience is challenging for both businesses and professionals.

**Our Solution**

\+ Talent Identification: We find top talent that matches your job post.

\+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.

\+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.

\+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.

\+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.

\+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.

\+ Transparency: Applicants receive immediate feedback on their applications to avoid being ""ghosted.""

**Life cycle stage:**

\- Validation: Currently looking to run our ***#1st pilot B2B*** with our first client.

**My role:**

\- Founder

**Goals for this month:**

\- Secure my first client for the pilot.

\- Obtain feedback from both the employee and business sides.

\- Optimize the product based on the feedback received.

**How can I** **help?**

\- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.

\- in the USA.

Thx for the feedback ;)",datascience,https://www.reddit.com/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,0,1,1.0,[]
179yve1,Whole-Ad-8370,,2023-10-17 13:52:45+00:00,False,,1697551029.0,False,True,False,/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,What does it mean to get a take-home assignment before screening call?,"This has happened to me twice now, dunno if it’s a new trend in recruitment processes. I’m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I’m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master’s in a computational quantitative field and so know the stats/theory behind most models).

 I didn’t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn’t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. 

Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it’s hard to find time to interview, which is the main reason I don’t want a super dragged out process)",datascience,https://www.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,6,4,0.7,"[Comment(id='k59cj2m'), Comment(id='k59ym10'), Comment(id='k59j8ee'), Comment(id='k5aidf8'), Comment(id='k5ctu9x'), Comment(id='k59dx9l')]"
17aatez,Medical-Author-8166,,2023-10-17 22:35:10+00:00,False,,False,False,True,False,/r/datascience/comments/17aatez/is_the_30th_percentile_of_a_standard_normal/,Is the 30th percentile of a standard normal distribution closer to one standard deviation below the mean or two standard deviations below the mean?,,datascience,https://www.reddit.com/r/datascience/comments/17aatez/is_the_30th_percentile_of_a_standard_normal/,3,0,0.43,"[Comment(id='k5bpgax'), Comment(id='k5brewz'), Comment(id='k5c4q1v')]"
179ebar,Expendable_0,,2023-10-16 19:25:33+00:00,False,,1697484790.0,False,True,False,/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,Why employers want experience over education,"**Creativity**: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn't be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, ""that is impossible."" How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give ""impossible"" tasks.

**Dirty Data**: I understand that provided or toy datasets can sometimes be dirty. They don't come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don't link to each other naturally, do regression tests because they don't update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.

**Being easy to work with**: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.

There are many others, but these are three big ones. If you don't have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won't be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.",datascience,https://www.reddit.com/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,79,146,0.85,"[Comment(id='k55ul4u'), Comment(id='k56qpim'), Comment(id='k55zthp'), Comment(id='k5678hg'), Comment(id='k5742tf'), Comment(id='k574ewi'), Comment(id='k57euj7'), Comment(id='k56uvhp'), Comment(id='k56bksh'), Comment(id='k56mb2l'), Comment(id='k573ffk'), Comment(id='k57s4m0'), Comment(id='k5bw5j5'), Comment(id='k5fhsg3'), Comment(id='k5kztrs'), Comment(id='k57fmia'), Comment(id='k57onbw'), Comment(id='k57v139'), Comment(id='k58rgcf'), Comment(id='k57ao25'), Comment(id='k56umhe'), Comment(id='k584dzh'), Comment(id='k56v1pp'), Comment(id='k583d95'), Comment(id='k56exxp'), Comment(id='k5776tc'), Comment(id='k58q76m'), Comment(id='k56zkzx'), Comment(id='k56egso'), Comment(id='k576lnh'), Comment(id='k56n0tb'), Comment(id='k581vbx'), Comment(id='k59uwi6'), Comment(id='k57tjxt'), Comment(id='k57i7aq'), Comment(id='k5bwsw0'), Comment(id='k58izzw'), Comment(id='k56xhgv'), Comment(id='k56md7j'), Comment(id='k577edu'), Comment(id='k58snz2'), Comment(id='k59i8pe'), Comment(id='k56eunj'), Comment(id='k56qc9x'), Comment(id='k57rsa9'), Comment(id='k56opl3'), Comment(id='k57wsyv'), Comment(id='k59r1ia'), Comment(id='k57sy9w'), Comment(id='k59x9hl'), Comment(id='k58ijxg'), Comment(id='k59sh6q'), Comment(id='k58t91n'), Comment(id='k56gnv7'), Comment(id='k577dx0'), Comment(id='k56s1fe'), Comment(id='k57s4ov'), Comment(id='k56pnq7'), Comment(id='k59qq67'), Comment(id='k580ot8'), Comment(id='k5a7oz9'), Comment(id='k5aedxv'), Comment(id='k58xy37'), Comment(id='k56jlg1'), Comment(id='k56i7pv'), Comment(id='k56naol'), Comment(id='k56t2s3'), Comment(id='k58cx31'), Comment(id='k56vlnv'), Comment(id='k59ebix'), Comment(id='k5bn7wb'), Comment(id='k593v2w'), Comment(id='k56m2pv'), Comment(id='k56ihz3'), Comment(id='k56ntwb'), Comment(id='k56tgy2'), Comment(id='k56vvie'), Comment(id='k59tddx'), Comment(id='k5ahvxe')]"
17aahht,Chadsmithbass,,2023-10-17 22:20:40+00:00,False,,False,False,True,False,/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,Anyone got interview call from Kodiak Robotics?,"Hey y'all, I have a 15 minute interview coming up with Kodiak.ai (Kodiak Robotics). Wondering what it's about. Any help is greatly appreciated!",datascience,https://www.reddit.com/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,3,1,0.67,"[Comment(id='k5q1kkt'), Comment(id='k74mk43'), Comment(id='k5qfefn'), Comment(id='k5qgc7b')]"
17a2wb4,brw12,,2023-10-17 16:54:00+00:00,False,,False,False,True,False,/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,"Q: How to extract learnings from my spreadsheets, beyond simple correlations?","**TL;DR:**

Below, I describe the info I'm tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don't. **My question is, does this algorithm already exist in some code library?** Or do I have to code it myself?

**Background:**

I've been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.

**Regression algorithm:**

I used to work at a data science company where we would run studies we called ""regression hill climbs"", where we would iterate like this:

1. identify the output factor (AKA ""dependent variable""); in this case, it would be energy level on a given day
2. for every input factor (AKA ""independent variable"", e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor
3. start with an empty ""model"", a set of independent variables
4. start with a correlation between model and dependent variable of 0
5. repeat until no more variables are selected to add to the model:
   1. filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) 
   2. of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model's variables (to best predict the dependent variable)
   3. select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)

This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). 

**Why it matters:**

For instance, if I have nights where I'm more disciplined overall -- say, when I don't drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there's a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.

Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it's very hard to isolate it as a factor; this algorithm helps.

**What I'm looking for:**

A code library -- presumably in python -- that is built to perform such a ""regression hill climb"", and allow for the various thresholds and other settings to be specified.

Does anyone know of such a library? Or, is there something different I should do, or some way I'm misunderstanding the problem?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,2,2,0.75,"[Comment(id='k5a4cor'), Comment(id='k5d175t')]"
179ztob,Cryptocheets,,2023-10-17 14:36:34+00:00,False,,False,False,True,False,/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,Should data-scientists look for their own datasets or be provided by the hiring company?,"Hi,   


We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   


Thank you",datascience,https://www.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,12,3,0.6,"[Comment(id='k59szy9'), Comment(id='k59ls8v'), Comment(id='k59jv1f'), Comment(id='k5aj2vy'), Comment(id='k59okme'), Comment(id='k5a2x90'), Comment(id='k5aaicw'), Comment(id='k5ak7yz'), Comment(id='k5a9rnf'), Comment(id='k5bpko3'), Comment(id='k5ddioo')]"
17a5u8t,ratatsnow,,2023-10-17 19:01:29+00:00,False,,False,False,True,False,/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,Time series data filtering - keep outliers and remove only flat trend,"I'm building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.

I thought about 2 solutions:

1. sample data for each product in a way that keeps 'outliers' in dataset (i.e. spikes for visibility and dips to get notified that maybe it's time to buy it). Not sure if it's easy 
2. get rid of data points for which data trends flat based on moving average

&#x200B;

Any better idea that is easy to implement?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,1,1,1.0,[Comment(id='k5bw7jz')]
17a5thj,TheOmerAngi,,2023-10-17 19:00:44+00:00,False,,False,False,True,False,/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,Does anyone have a good glossary for data science?,I'm looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It's mostly for myself to test my knowledge. Anything from regression types to p values and much more.,datascience,https://www.reddit.com/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,1,1,0.6,[Comment(id='k5b7w8c')]
17a5plc,KobeOrNotKobe,,2023-10-17 18:55:57+00:00,False,,False,False,True,False,/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,Live 2023 Election Results (Also Future Results),"Specifically for Kentucky but I'm trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this [comment](https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&utm_medium=web2x&context=3), but can't figure out what it would be for a single state's off off year election

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,0,0,0.5,[]
179z4yq,niksteel123,,2023-10-17 14:05:00+00:00,False,,False,False,True,False,/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,Shared Public Contextual Database for RAG,"Hey Guys,  
It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   


Do you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  


\-  


For context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. ",datascience,https://www.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,1,2,1.0,[]
179945p,MikeyCyrus,,2023-10-16 15:47:51+00:00,False,,False,False,True,False,/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,How many companies actually have a clear plan for their data?,"I have been working as a ""data scientist"" in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with ""data scientist"" titles in the whole org but they are in a separate silo from me. 

Generally I am tossed tasks that don't make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like ""build us a chatbot"". I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  

Now they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can't imagine that project was less than a few million as well. 

In all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don't even realize the consultants will likely build a very similar model to SAP. 

Are most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I've worked here. It seems like they have no vision or clue what they are doing.",datascience,https://www.reddit.com/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,48,112,0.95,"[Comment(id='k54pytz'), Comment(id='k55pbnt'), Comment(id='k54u7ze'), Comment(id='k54vmla'), Comment(id='k55em9x'), Comment(id='k54z0d5'), Comment(id='k5655yb'), Comment(id='k55nwva'), Comment(id='k56w5sq'), Comment(id='k55w2dy'), Comment(id='k55gbhg'), Comment(id='k56ozy9'), Comment(id='k58puwe'), Comment(id='k5faelc'), Comment(id='k55nxex'), Comment(id='k54v7l8'), Comment(id='k564zrz'), Comment(id='k569uvu'), Comment(id='k56a4b7'), Comment(id='k57obqm'), Comment(id='k5lz1gl'), Comment(id='k55gyq7'), Comment(id='k56anqb'), Comment(id='k56uz15'), Comment(id='k56xl5z'), Comment(id='k582eat'), Comment(id='k56o4kk'), Comment(id='k55oudm'), Comment(id='k56asyg'), Comment(id='k57avlx'), Comment(id='k5fds4y'), Comment(id='k56aya6'), Comment(id='k55hbhz'), Comment(id='k560dz2'), Comment(id='k57ansd'), Comment(id='k56zcyt'), Comment(id='k57doxf'), Comment(id='k56x5lx'), Comment(id='k579wft'), Comment(id='k5axitk'), Comment(id='k5fj98e'), Comment(id='k58ax9a'), Comment(id='k57dlm5'), Comment(id='k572nc7'), Comment(id='k59a8i5'), Comment(id='k573gzc'), Comment(id='k57e0a6'), Comment(id='k57k8q2')]"
179ykfd,growth_man,,2023-10-17 13:38:01+00:00,False,,False,False,False,False,/r/datascience/comments/179ykfd/how_to_build_data_products_deploy_part_34/,How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences,,datascience,https://moderndata101.substack.com/p/how-to-build-data-products-deploy,0,2,1.0,[]
17a25ns,forgotendream,,2023-10-17 16:20:55+00:00,False,,False,False,True,False,/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,How good are the Linkedin Learning Paths?,"Hi all,

&#x200B;

I have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.   
Has anyone tried them or what do you guys think of them?  
I saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.

&#x200B;

Is it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.

&#x200B;

Appreciate the input or help.",datascience,https://www.reddit.com/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,3,1,0.6,"[Comment(id='k5a21pm'), Comment(id='k5bfhkw'), Comment(id='k5d1us6')]"
179r5li,dec_dev,,2023-10-17 05:36:36+00:00,False,,False,False,True,False,/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,Repetitive airflow pipeline problems,"Hi r/datascience,

From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,0,5,0.86,[]
179etbr,Relative_Practice_93,,2023-10-16 19:46:15+00:00,False,,1697514908.0,False,True,False,/r/datascience/comments/179etbr/regretting_data_science/,Regretting Data Science,"I was wondering if there are other people out there who regret choosing data science as a career path.

For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.

I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).

In the fall of the 2nd year of my Master's I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I'm stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.

I can't really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I'm personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. 

Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don't know if every job feels like this and I have to suck it up, or if I should just leave. I've only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.

I'd love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I'm having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.",datascience,https://www.reddit.com/r/datascience/comments/179etbr/regretting_data_science/,28,25,0.84,"[Comment(id='k55z708'), Comment(id='k55slcj'), Comment(id='k56bu63'), Comment(id='k5634vg'), Comment(id='k57hrut'), Comment(id='k56ij4d'), Comment(id='k56ejih'), Comment(id='k57n7z6'), Comment(id='k56u2fd'), Comment(id='k56765a'), Comment(id='k5c1moq'), Comment(id='k57hzsx'), Comment(id='k55srkw'), Comment(id='k57ndc6'), Comment(id='k56jvg0'), Comment(id='k59orrs'), Comment(id='k57xg9u'), Comment(id='k59cnta'), Comment(id='k57x7d8'), Comment(id='k583v5b'), Comment(id='k55sxn0'), Comment(id='k57vkx6'), Comment(id='k57trds'), Comment(id='k57nr21'), Comment(id='k580p5t'), Comment(id='k57x9c5'), Comment(id='k58mdvv'), Comment(id='k59ib8d')]"
179u12d,CursorInsight,,2023-10-17 09:04:31+00:00,False,,False,False,True,False,/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values,"Hey fellow Redditors!

Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!

In this discussion, we delve into the concept of ""features"" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.

# 💡 What's a Feature?  

In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.

 The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. 

# 📊 Analyzing the appropriate time series

The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. 

**Unmasking forgery through speed analysis**

Let’s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**

Now, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won’t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature’s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**

Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.

Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.

In theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**

From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.

# 🔍 Describing Time Series with Scalar Values 

 We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.

Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.

To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.

Two lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.

In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.

On the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.

These are the basic features we utilize for analysis.

Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! 💬🕺🏽💻",datascience,https://www.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,0,2,1.0,[]
1799oao,shayanjm,,2023-10-16 16:11:12+00:00,False,,False,True,True,False,/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,Decoding LLM Uncertainties for Better Predictability,"Hi all,

Building off our last research post, we wanted to figure out ways to quantify ""ambiguity"" and ""uncertainty"" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: ""Structural"" and ""Conceptual"" uncertainty.

In a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.

You can play around with this yourself in the [demo](https://uncertainty.demos.watchful.io/) or read about it in more detail in the [blog post](https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability)",datascience,https://www.reddit.com/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,1,13,0.77,[Comment(id='k573zg0')]
179kwrd,throwaWayne2,,2023-10-17 00:07:44+00:00,False,,False,False,True,False,/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?,"My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.

 Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.

I really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.
How should I approach this? Anything in particular I should show?

I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)",datascience,https://www.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,7,2,0.56,"[Comment(id='k57b452'), Comment(id='k57xjdz'), Comment(id='k56z5ep'), Comment(id='k58g6zw'), Comment(id='k5743ep'), Comment(id='k59oikb'), Comment(id='k59qwb1'), Comment(id='k5799g3')]"
179q91p,SaxTeacher1988,,2023-10-17 04:40:44+00:00,False,,False,False,True,False,/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,Cruise Ship Musicians Scheduling,"I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!",datascience,https://www.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,12,1,0.67,"[Comment(id='k57y1k4'), Comment(id='k57x84l'), Comment(id='k58cd0f'), Comment(id='k5b9l06'), Comment(id='k5ba6h5'), Comment(id='k5b9enm'), Comment(id='k5broj7'), Comment(id='k5bbgq6'), Comment(id='k5cmqn8'), Comment(id='k5caegf'), Comment(id='k5cnh0y'), Comment(id='k5cm7zd')]"
17941v2,Illustrious-Class-65,,2023-10-16 11:44:31+00:00,False,,False,False,True,False,/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,What would be a good curriculum for a data scientist to learn about forecasting?,"Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!",datascience,https://www.reddit.com/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,9,16,0.9,"[Comment(id='k543p01'), Comment(id='k545dg5'), Comment(id='k5dck0c'), Comment(id='k548awu'), Comment(id='k5489aa'), Comment(id='k589w6q'), Comment(id='k59r1sj'), Comment(id='k54l13b')]"
178vvrk,n96j77,,2023-10-16 02:40:43+00:00,False,,False,False,True,False,/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,Identity Crisis in Data Science,"Anyone else confused where they fit in data science? There's a huge range of backgrounds, from bootcamps to Ph.D.s. I've found DS quite unwelcoming because of this. Everyone is trying to distinguish themselves from the ""fakers,"" while most companies needs are quite basic.

I've been working on a DS master's degree for a year. I certainly know more than the typical data analyst or self-taught MOOCs student, but I'm overwhelmed by the interdisciplinary nature of the field. I've invested countless hours and thousands of dollars, yet there's a lifetime more to learn. This makes me question whether I want to continue in the field. When I talk to computer scientists, they're all very encouraging and emphasize that, although difficult, everyone can learn to code. When I talk to other data scientists, I get an air of elitism.

I think this happens because data science is a relatively new field. Other specialized skills like accounting, law, or finance have had time to settle into a list of requirements and utilize certifications where necessary. Since we have one title to describe a huge population, people end up getting defensive so they're not grouped together with the less qualified. Maybe overtime this resolves itself as data science expands into more titles. For now, I feel caught between both sides of the argument. I have no desire to get a PhD and a lot of imposter syndrome. It leaves me feeling like I should have gone MBA -> product management and called it a day.  On the flip side, when I explain basic stats at work, I'm met with blank stares, leading me to think the push for Ph.Ds is more about ego than practicality. My hope is to see clearer distinction in titles and more encouragement in the field than discouragement. 

For those of you in the middle like me, where have y'all had success? What kinds of industries, companies, or roles do you target?",datascience,https://www.reddit.com/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,32,72,0.86,"[Comment(id='k52p0qj'), Comment(id='k53l1pu'), Comment(id='k53lm74'), Comment(id='k54qax6'), Comment(id='k5594oy'), Comment(id='k54rqgu'), Comment(id='k54wsd5'), Comment(id='k5461uf'), Comment(id='k55lzwh'), Comment(id='k59by9v'), Comment(id='k549gfa'), Comment(id='k590k9d'), Comment(id='k542yms'), Comment(id='k589tat'), Comment(id='k5g3igx'), Comment(id='k5mt8ly'), Comment(id='k542h18'), Comment(id='k53gzln'), Comment(id='k59e3rq'), Comment(id='k53kgv0'), Comment(id='k54548e'), Comment(id='k54r4rb'), Comment(id='k59ewdq'), Comment(id='k58ak4s'), Comment(id='k55gnam'), Comment(id='k58b6k4'), Comment(id='k5actod'), Comment(id='k54td1a'), Comment(id='k59j6gh'), Comment(id='k545jhj'), Comment(id='k58qb15'), Comment(id='k59do90'), Comment(id='k59bi3s')]"
1796r3n,dmalyugina,,2023-10-16 14:04:58+00:00,False,,False,False,True,False,/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,Free Open-source ML observability course: starts today 🚀,"Hi everyone, I’m one of the people who work on [Evidently](https://github.com/evidentlyai/evidently), an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.

We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.

💻 Code examples and end-to-end deployment blueprints.  
✅ Open-source focused. You’ll work with tools like Evidently, MLflow, Airflow, and Grafana.  
❤️ Free and open to everyone.  
🗓 You can join the cohort that starts on October 16, 2023, or learn at your own pace.

Course info and notes: [https://learn.evidentlyai.com/](https://learn.evidentlyai.com/)

Hope you’ll find the course useful!",datascience,https://www.reddit.com/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,0,5,0.78,[]
179q60m,Awkward-Block-5005,,2023-10-17 04:35:30+00:00,False,,False,False,True,False,/r/datascience/comments/179q60m/time_series_forcasting/,Time series forcasting,"Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.
As we can plot univariate time series on plot and train GaN's to complete that plot.

Not so much work is in going on this feild.
Why ?",datascience,https://www.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/,6,0,0.2,"[Comment(id='k5898bl'), Comment(id='k59p7gc'), Comment(id='k58dum0'), Comment(id='k589gpc'), Comment(id='k59pqzs'), Comment(id='k59rckb')]"
1792cy2,IGetToSkrtWhenIWant,,2023-10-16 09:54:40+00:00,False,,False,False,True,False,/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,"Hitting a bottleneck (500+ applications over the past half year with barely any interviews at all). Any advice on job searching, applications, or even transitioning from another field?","I've been job searching for awhile now, and while I understand that the job market in general is rough right now, I have to imagine that struggling to even get initial interviews means that I'm doing something wrong. 

For context, I'm pretty much graduated with a BA in Economics at Boston University. I have some part-time and internship experience: about half a year of working the front desk of a small hotel (I have not put this on my resume since I worked the job for side money, not for work experience), a few months as a Sales Representative, a few months as a Dispute Resolution Analyst for the Better Business Bureau, and a few other internship experiences during my high school years. Obviously, none of my work experience is related to working with data or analysis, other than some of my Economics coursework, completing the Google Data Analytics certificate, and a guided project with Python (NumPy, Pandas, Seaborn) in Exploratory Data Analysis on Coursera. In any case, I know that my work experience is pretty weak/nonexistent and I've been struggling to even get an initial interview for entry-level/no-experience-required roles. So what can I do in terms of job searching/applications? Should I focus more on my resume/work experience by completing my own projects that demonstrate self-taught skills (Excel, SQL, Python, etc.)? Or should I give up on trying to apply for data/analyst roles and instead try to transition in through a different field like Marketing, Consulting, etc? Any and all feedback that can help me get past this current bottleneck would be greatly appreciated!",datascience,https://www.reddit.com/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,12,10,0.92,"[Comment(id='k58461w'), Comment(id='k586e4o'), Comment(id='k5cjycy'), Comment(id='k56y69t'), Comment(id='k554l2l'), Comment(id='k53uao1'), Comment(id='k58fmuo'), Comment(id='k58erfq'), Comment(id='k581hru'), Comment(id='k569ggu'), Comment(id='k5aqfcr'), Comment(id='k58e0va')]"
1792wrc,pg860,,2023-10-16 10:31:22+00:00,False,,False,False,True,False,/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,Popularity of Data Visualization tools mentioned in data-science/ml job descriptions," Source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)

About the dataset: 9,261 jobs crawled from 1605 companies worldwide in June-Sep 2023

https://preview.redd.it/dympbqa3ljub1.png?width=2560&format=png&auto=webp&s=e5db457072a89a08528d73fe0c064adc45372dea",datascience,https://www.reddit.com/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,2,6,0.69,"[Comment(id='k5hg99k'), Comment(id='k5ijqx7')]"
178wh2z,Much-Focus-1408,,2023-10-16 03:12:54+00:00,False,,False,False,True,False,/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,What are the best sites to review DS topics/study for interviews?,"It’s been a while and all I really do in my job is NLP and googling. I haven’t used SQL, stats, etc.. in such a long time. I’ve looked at leetcode and interviewquery, but there’s a lot out there.

What would you recommend using? Thanks!",datascience,https://www.reddit.com/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,13,24,0.9,"[Comment(id='k52tf24'), Comment(id='k52zdh0'), Comment(id='k53ji8o'), Comment(id='k53j7hg'), Comment(id='k53l94u'), Comment(id='k53sb3i'), Comment(id='k53ysoo'), Comment(id='k5dcqyz'), Comment(id='k52w471'), Comment(id='k52zzjb'), Comment(id='k53j9tl'), Comment(id='k54rpbl'), Comment(id='k54piao')]"
178r037,daufoi21,,2023-10-15 22:32:40+00:00,False,,False,False,True,False,/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,Not getting noticed for data science jobs,"I've been a data scientist with 3 (almost 4) years experience and a Masters. Is there somewhere you guys go to get your resume critiqued or improved? I've tried sending it to a career counselor and she thought it was good. Also, I met someone who works in the industry through a career fair, and he said it is ""impressive"". Nevertheless, I apply to job after job, only to get rejection emails. After 4 months, I've had one interview and that was through a referral. Even the hiring manager said the resume looks good for the job (before interview). This happens even if I tailor my resume, apply to jobs that I feel I'm highly qualified, and am early in applying (within a week of job posting). I feel like I'm wasting time, and this is just the first step. Interviewing is going to be another battle, and at this rate I will never find something!",datascience,https://www.reddit.com/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,37,54,0.86,"[Comment(id='k51hkkl'), Comment(id='k528lfo'), Comment(id='k527x1e'), Comment(id='k52574k'), Comment(id='k536c6w'), Comment(id='k53zfdt'), Comment(id='k54icil'), Comment(id='k53r36q'), Comment(id='k51yhrj'), Comment(id='k52sqv3'), Comment(id='k53npqj'), Comment(id='k55a3ti'), Comment(id='k5nger7'), Comment(id='k53w0dg'), Comment(id='k51jb7z'), Comment(id='k58a1g1'), Comment(id='k6ncpjk'), Comment(id='k53ok7w'), Comment(id='k56z71n'), Comment(id='k54h4ki'), Comment(id='k54ctq1'), Comment(id='k55pgtd'), Comment(id='k55b0gm'), Comment(id='k56cubz'), Comment(id='k55pjcy'), Comment(id='k53497p'), Comment(id='k54ws8d'), Comment(id='k561fyd'), Comment(id='k55gump'), Comment(id='k575koo'), Comment(id='k582dza'), Comment(id='k568qn3'), Comment(id='k564dcq'), Comment(id='k55yvh6'), Comment(id='k577i30'), Comment(id='k56aic4'), Comment(id='k5ccmno')]"
178juum,Puzzled_Implement_78,,2023-10-15 17:05:01+00:00,False,,False,False,True,False,/r/datascience/comments/178juum/do_you_folks_leetcode/,Do you folks Leetcode?,"I come from more of a engineering(non-software) background and never learned Data Structures and Algorithms. I want to start applying for jobs next year(3 YOE), how often are you asked Leetcode questions in interviews? I'm trying to figure out a plan of action to get prepared.",datascience,https://www.reddit.com/r/datascience/comments/178juum/do_you_folks_leetcode/,76,114,0.96,"[Comment(id='k50j355'), Comment(id='k51ekpu'), Comment(id='k50hpqz'), Comment(id='k50jjtx'), Comment(id='k50ypt9'), Comment(id='k50irx5'), Comment(id='k521mv8'), Comment(id='k5192e5'), Comment(id='k513mfb'), Comment(id='k50xfdi'), Comment(id='k503689'), Comment(id='k51w3al'), Comment(id='k52dzem'), Comment(id='k50r3fn'), Comment(id='k50c7um'), Comment(id='k51ipgj'), Comment(id='k50nc5f'), Comment(id='k5183ou'), Comment(id='k51cjh6'), Comment(id='k51ioi9'), Comment(id='k52o3q5'), Comment(id='k51dklu'), Comment(id='k51de20'), Comment(id='k52pkpg'), Comment(id='k52qkml'), Comment(id='k532pv2'), Comment(id='k532zea'), Comment(id='k542ews'), Comment(id='k549lat'), Comment(id='k54btso'), Comment(id='k54cqtu'), Comment(id='k54xcrh'), Comment(id='k55egot'), Comment(id='k55uzwa'), Comment(id='k56dnat'), Comment(id='k50w4ei'), Comment(id='k50n3t2'), Comment(id='k531n3l'), Comment(id='k52uyhy'), Comment(id='k51kxps'), Comment(id='k51qycz'), Comment(id='k51o8zs'), Comment(id='k5365mb'), Comment(id='k50xwfe'), Comment(id='k51m7ez'), Comment(id='k53hsv2'), Comment(id='k5350d2'), Comment(id='k52zyuk'), Comment(id='k50tvwv'), Comment(id='k535hg0'), Comment(id='k56wpyi'), Comment(id='k52v1bg'), Comment(id='k52xm4k'), Comment(id='k51y10k'), Comment(id='k51xtoi'), Comment(id='k53l8al'), Comment(id='k51ptvd'), Comment(id='k528xpm'), Comment(id='k52qmmm'), Comment(id='k51f06u'), Comment(id='k7mvoqx'), Comment(id='k54l5px'), Comment(id='k57slch'), Comment(id='k52vrdr'), Comment(id='k52o3f4'), Comment(id='k52onpk'), Comment(id='k529lpg'), Comment(id='k52954i'), Comment(id='k7mvgr9'), Comment(id='k5535ww'), Comment(id='k55o765'), Comment(id='k5502gg'), Comment(id='k52x2h0'), Comment(id='k55fc6e'), Comment(id='k532m0o'), Comment(id='k5357b5')]"
178fhbg,BladeClickerQQ,,2023-10-15 13:34:34+00:00,False,,1697725332.0,False,True,False,/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,Will being data analyst in casino resort ruin my career?,"Updated:

Thank you so much for all the suggestions and comments! The community is so supportive and enthusiastic. I read every comments very carefully, probably more than one time for most, and they are very insightful and play a vital role in my decision making, whether thumbs up or down.

I have been thinking about this almost every minutes in the past few days. In the end, I decided to take this offer. For me this decision is very complicated. Actually I am not sure how long I will stay, but it's always important to make my first step.

Thank you again for all the comments! 

\--------------------------------------------------------------------

As a new graduate recently I am getting a data analyst offer from a casino resort. It's a hard time for new grad and after two times of withdrawals of my offers, this is the only one I have in my hands. The job duty is about analyzing campaign performance, analyzing customer patterns, and forecasting business trends.  They are also working on breaking data silos utilizing cloud service so ETL jobs should also be expected.

Overall the project sounds pretty attractive to me. My only concern is the business itself. One of my friends (not in US) gave me a strong suggestion that don't easily go into this industry. He was working in an operation role for company building mobile casinos, and the business logic was so different from other industries that it's hard to get out of this. Many people have a bias toward this career so he had a hard time changing jobs.

I am scared, to be honest. But I am not sure to what extent his thoughts work in my scenario. Casino Resort still looks much different from mobile casinos and his role was not data analyst. I wonder how you guys think about this.  Should I take this offer?",datascience,https://www.reddit.com/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,131,211,0.88,"[Comment(id='k4z5ti7'), Comment(id='k4z957p'), Comment(id='k4zhffy'), Comment(id='k4zeekt'), Comment(id='k4zgppa'), Comment(id='k4zghgl'), Comment(id='k4zi4pa'), Comment(id='k50wdu6'), Comment(id='k4zqdyj'), Comment(id='k4zf7e0'), Comment(id='k4zovsj'), Comment(id='k527kqs'), Comment(id='k4zkr14'), Comment(id='k4zmnxn'), Comment(id='k4znqoh'), Comment(id='k4zqgqp'), Comment(id='k4zrcrd'), Comment(id='k4zsvw4'), Comment(id='k50k8uk'), Comment(id='k50u523'), Comment(id='k4zge9z'), Comment(id='k4zx83e'), Comment(id='k50hbz9'), Comment(id='k50w662'), Comment(id='k53xwjk'), Comment(id='k542856'), Comment(id='k4zmxwi'), Comment(id='k51a3gs'), Comment(id='k507rbn'), Comment(id='k4zrtx2'), Comment(id='k4zrxe8'), Comment(id='k4zt5d2'), Comment(id='k4zwyb1'), Comment(id='k4zyf8m'), Comment(id='k4zyjbq'), Comment(id='k504g4j'), Comment(id='k505keg'), Comment(id='k50cg4y'), Comment(id='k50evfx'), Comment(id='k50i329'), Comment(id='k50ouuv'), Comment(id='k50p46l'), Comment(id='k50sz3s'), Comment(id='k5101qa'), Comment(id='k514r73'), Comment(id='k519r38'), Comment(id='k51bf68'), Comment(id='k51bfl9'), Comment(id='k51is78'), Comment(id='k51sain'), Comment(id='k51whpj'), Comment(id='k51xwjl'), Comment(id='k5228ok'), Comment(id='k5234a5'), Comment(id='k52b4en'), Comment(id='k52lk8s'), Comment(id='k5308a2'), Comment(id='k53d376'), Comment(id='k53hfz4'), Comment(id='k53m7yz'), Comment(id='k53tdpc'), Comment(id='k54l5kg'), Comment(id='k54q6el'), Comment(id='k54z23j'), Comment(id='k54za1x'), Comment(id='k556fwa'), Comment(id='k56n1ht'), Comment(id='k56sh1u'), Comment(id='k56xqrm'), Comment(id='k5d13tp'), Comment(id='k50dck9'), Comment(id='k4zekq3'), Comment(id='k4zixm3'), Comment(id='k50j1xh'), Comment(id='k505bm4'), Comment(id='k50pvok'), Comment(id='k51iw08'), Comment(id='k51ie7m'), Comment(id='k4zryn4'), Comment(id='k4zut0c'), Comment(id='k4zmurq'), Comment(id='k50werh'), Comment(id='k531j3s'), Comment(id='k50z3um'), Comment(id='k50bdjb'), Comment(id='k5jsdj0'), Comment(id='k51h1fq'), Comment(id='k51issk'), Comment(id='k50p0b6'), Comment(id='k52n0qu'), Comment(id='k51bmoy'), Comment(id='k51n706'), Comment(id='k550t2u'), Comment(id='k51ivoz'), Comment(id='k530eb0'), Comment(id='k508m8t'), Comment(id='k4zvaju'), Comment(id='k5133bj'), Comment(id='k508bd9'), Comment(id='k508flk'), Comment(id='k51btqs'), Comment(id='k54zh01'), Comment(id='k51020p'), Comment(id='k51dvis'), Comment(id='k551f15'), Comment(id='k5jxqqq'), Comment(id='k52r9ar'), Comment(id='k5284ne'), Comment(id='k51jvkz'), Comment(id='k52f3b2'), Comment(id='k542eu7'), Comment(id='k52as6d'), Comment(id='k51xmlg'), Comment(id='k51jegv'), Comment(id='k544j0n'), Comment(id='k52bsn2'), Comment(id='k50lmws'), Comment(id='k512k3o'), Comment(id='k55slgg'), Comment(id='k53yb2h'), Comment(id='k52i4n1'), Comment(id='k52ptd8'), Comment(id='k52c3ws'), Comment(id='k51r6i7'), Comment(id='k50t00c'), Comment(id='k512rvt'), Comment(id='k57418s'), Comment(id='k540at0'), Comment(id='k53rgb6'), Comment(id='k51sstx'), Comment(id='k55h6jq'), Comment(id='k5casuq')]"
1796piu,benjaminwootton81,,2023-10-16 14:02:59+00:00,False,,False,False,False,False,/r/datascience/comments/1796piu/forecasting_using_clickhouse_machine_learning/,Forecasting Using Clickhouse Machine Learning Functions,,datascience,https://ensembleanalytics.io/blog/forecasting-using-clickhouse,0,2,1.0,[]
178ztsj,Green_Ad6024,,2023-10-16 06:48:45+00:00,False,,False,False,True,False,/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,Which Model is best for Word Embedding?,"Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. Thank you for your guidance. ",datascience,https://www.reddit.com/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,1,7,1.0,[Comment(id='k53n40z')]
178erav,ah-know-knee-mousse,,2023-10-15 12:54:11+00:00,False,,False,False,False,False,/r/datascience/comments/178erav/is_this_normal_qualification/,Is this normal qualification?,,datascience,https://i.redd.it/ek2tuv1p5dub1.jpg,56,154,0.9,"[Comment(id='k4z02zu'), Comment(id='k4z2vji'), Comment(id='k4zc9wv'), Comment(id='k4yzhcy'), Comment(id='k503n9k'), Comment(id='k4z1wjf'), Comment(id='k4zmp9v'), Comment(id='k50jlf2'), Comment(id='k4zzkax'), Comment(id='k513qy6'), Comment(id='k51sho5'), Comment(id='k52s0eg'), Comment(id='k5345h7'), Comment(id='k4zn02i'), Comment(id='k504lm9'), Comment(id='k4zkyst'), Comment(id='k50zfw5'), Comment(id='k51ib88'), Comment(id='k50tjtp'), Comment(id='k51htfk'), Comment(id='k522r3i'), Comment(id='k52mtmu'), Comment(id='k53mqd4'), Comment(id='k52eyj2'), Comment(id='k54brge'), Comment(id='k54x02e'), Comment(id='k58db1w'), Comment(id='k5ce3iq'), Comment(id='k4z82cv'), Comment(id='k4z1vsm'), Comment(id='k52o62v'), Comment(id='k4z8c4t'), Comment(id='k53npt5'), Comment(id='k53ql6f'), Comment(id='k4z5xlf'), Comment(id='k4zyitp'), Comment(id='k50tkjf'), Comment(id='k52o9fi'), Comment(id='k50uss4'), Comment(id='k52od19'), Comment(id='k51b6w7'), Comment(id='k53074n'), Comment(id='k53oc3t'), Comment(id='k53o0yu'), Comment(id='k4z98ii'), Comment(id='k4z2n0t'), Comment(id='k4zzoy5'), Comment(id='k4zakda'), Comment(id='k52kw5y'), Comment(id='k51d8n6'), Comment(id='k514urm'), Comment(id='k543y29'), Comment(id='k5405de'), Comment(id='k540wty'), Comment(id='k5419nj')]"
1794e1d,Hasneverbeenhere,,2023-10-16 12:04:03+00:00,False,,False,False,True,False,/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/,"When using bagging or boosting to combine decision trees, which algorithm takes more time to train?",,datascience,https://www.reddit.com/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/,2,1,0.57,"[Comment(id='k53twcw'), Comment(id='k53vxb1')]"
1791y53,getoutofmybus,,2023-10-16 09:25:22+00:00,False,,False,False,True,False,/r/datascience/comments/1791y53/ml_engineering_courses_certs/,ML Engineering Courses/ Certs,"I'm an MSc graduate with some DS experience and I'm looking to move to a ML Engineering role. Are there any courses you would recommend? My Masters was in applied math and my UG was in mathematics, so I have the maths and stats, and have done a lot of work with neural nets and PyTorch. ",datascience,https://www.reddit.com/r/datascience/comments/1791y53/ml_engineering_courses_certs/,2,3,1.0,"[Comment(id='k574y1b'), Comment(id='k57or75')]"
1798de7,G4L1C,,2023-10-16 15:15:58+00:00,False,,False,False,True,False,/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,[Applied Data Science in Marketing] How to measure marginal returns and elasticity of marketing campaigns,"Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:

\- The law of diminishing returns

\- ROAS and Marginal ROAS

\- Advertisement elasticity on Returns

Hope that it is useful for everybody. Any feedback is welcome.

[https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html](https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html)",datascience,https://www.reddit.com/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,0,1,1.0,[]
178yk7k,siliconBoy69,,2023-10-16 05:19:46+00:00,False,,False,False,True,False,/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,Is my idea worth pursuing ?,"I'm a software engineer, while building AI side projects I noticed that it takes a while to setup the MLOPs and cloud infra for deploying and building models so, I'm creating a low-code platform for finetuning and deploying ai models (B2B mostly). do you guys think there is a market for this product ?",datascience,https://www.reddit.com/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,5,4,0.75,"[Comment(id='k52zamo'), Comment(id='k53lyar'), Comment(id='k530l09'), Comment(id='k5358xo'), Comment(id='k53q27s')]"
17932k1,Individual-School-07,,2023-10-16 10:42:35+00:00,False,,False,False,True,False,/r/datascience/comments/17932k1/data_science_protfolio/,Data Science Protfolio,"Hello everyone,

I'm a former data science student who started to work in IT audit but decided to go back to DS.  I am rebuilding my portfolio with new projects. Any great project ideas ?   
Here are some projects i think about, please don't hesitate to give your opinion on which to choose :   


* Credit Card attrition.
* Black&white video/ picture coloring and improving.
* License plate recognition
* Facebook Friend Recommendation
* Quora Question Pair Similarity
* Credit scoring improvement
* Disease Outbreak Prediction
* Product Recommendation system
* Housing Price Predictor
* Sentiment Analysis
* Stock Price Forecasting
* Flight Delay Prediction
* Fire Outbreak Prediction
* Game Outcome Prediction
* Object Detection in Videos
* Influencer Detection

Thank you in advance for your response.

P.S : If anyone has great mentorship platforms or any other way of mentorship please don't hesitate.",datascience,https://www.reddit.com/r/datascience/comments/17932k1/data_science_protfolio/,3,2,0.75,"[Comment(id='k5ar3h5'), Comment(id='k6a3xnu'), Comment(id='k6hui5o')]"
178ifs7,kafka399,,2023-10-15 15:58:48+00:00,False,,False,False,True,False,/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,Causal inference as a blind spot of data scientists,"Do you use Causal Inference as a data scientist? I wrote an article to reflect why it took so long for data scientists to discover Causal Inference and and tried to give an inspirational overview (just look at the images). 

[http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/](http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/)",datascience,https://www.reddit.com/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,61,65,0.88,"[Comment(id='k4zqstn'), Comment(id='k4zr6uu'), Comment(id='k4zut2b'), Comment(id='k52t43f'), Comment(id='k53fieb'), Comment(id='k512j4z'), Comment(id='k50jboe'), Comment(id='k524dk7'), Comment(id='k52qtxx'), Comment(id='k52bto3'), Comment(id='k52xh9p'), Comment(id='k52ylo1'), Comment(id='k577slc'), Comment(id='k5342qc'), Comment(id='k53eqhl'), Comment(id='k54pri9'), Comment(id='k6uzot0'), Comment(id='k50bvht'), Comment(id='k5287ve'), Comment(id='k512mr9'), Comment(id='k5111qz'), Comment(id='k50j6lg'), Comment(id='k514dtj'), Comment(id='k53mrni'), Comment(id='k4zvhk1'), Comment(id='k50cj5x'), Comment(id='k51xlfx'), Comment(id='k53o2tr'), Comment(id='k53111v'), Comment(id='k5916lw'), Comment(id='k55dujt'), Comment(id='k52kl9m'), Comment(id='k53c86g'), Comment(id='k50k6oj'), Comment(id='k50qaqr'), Comment(id='k55xueo'), Comment(id='k526002'), Comment(id='k507fwh'), Comment(id='k51pgzx'), Comment(id='k52cv0e'), Comment(id='k52cbz8'), Comment(id='k521wdg'), Comment(id='k50o2sb'), Comment(id='k512a1j'), Comment(id='k55yhgn'), Comment(id='k50hlv1'), Comment(id='k52dbyu'), Comment(id='k524ba6'), Comment(id='k51beju'), Comment(id='k5686ne'), Comment(id='k50ktf4'), Comment(id='k524w2o'), Comment(id='k53jdgz'), Comment(id='k56g5mj'), Comment(id='k50q9wk'), Comment(id='k53fshx'), Comment(id='k56nwy0'), Comment(id='k50rqf7'), Comment(id='k53j99e'), Comment(id='k56p9vb'), Comment(id='k50sbse'), Comment(id='k56ppra'), Comment(id='k5btvcn')]"
1796r9j,Tasty_Potential7670,,2023-10-16 14:05:11+00:00,False,,False,False,True,False,/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,Sap ui5 fiori vs data science,"I'm in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? 

Mainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today's decision",datascience,https://www.reddit.com/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,5,1,0.67,"[Comment(id='k54dpnh'), Comment(id='k54esg1'), Comment(id='k54oavs'), Comment(id='k552q9n'), Comment(id='k57iyj6')]"
1796ecp,datasciencewithmarco,,2023-10-16 13:48:48+00:00,False,,False,False,True,False,/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,Advice on my approach for a project,"For my project, I need to identify existing to users to start using a product. 

I have different ideas that I want to try, but I would like to have your input.

&#x200B;

**Idea 1**: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster

&#x200B;

**Idea 2:** Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.

&#x200B;

**Idea 3:** Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.

&#x200B;

Let me know what you think or if I am on the right track!",datascience,https://www.reddit.com/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,2,1,1.0,"[Comment(id='k548aay'), Comment(id='k57rwe7')]"
17961eu,orangepie000,,2023-10-16 13:31:19+00:00,False,,False,False,True,False,/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,Sharing is caring - with Gorudo.io," Sharing is caring - Creators can share your trade diary with your Members any time using [Gorudo.io](https://Gorudo.io)

&#x200B;

https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&format=pjpg&auto=webp&s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3",datascience,https://www.reddit.com/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,1,0,0.5,[Comment(id='k542vrm')]
178xboh,AutoModerator,,2023-10-16 04:01:27+00:00,False,,False,False,True,False,/r/datascience/comments/178xboh/weekly_entering_transitioning_thread_16_oct_2023/,"Weekly Entering & Transitioning - Thread 16 Oct, 2023 - 23 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/178xboh/weekly_entering_transitioning_thread_16_oct_2023/,105,5,1.0,"[Comment(id='k5akqzt'), Comment(id='k5cvzld'), Comment(id='k5k1tmo'), Comment(id='k5ddfd6'), Comment(id='k5ms68z'), Comment(id='k5agrg1'), Comment(id='k5dpr7o'), Comment(id='k53ezuz'), Comment(id='k5hzue3'), Comment(id='k5nmemq'), Comment(id='k5u6vpy'), Comment(id='k5url6f'), Comment(id='k5vfm4w'), Comment(id='k5wc3u4'), Comment(id='k5wj8wf'), Comment(id='k5wxds6'), Comment(id='k5y4fj7'), Comment(id='k5y52a1'), Comment(id='k52zczn'), Comment(id='k53dpki'), Comment(id='k55p0ru'), Comment(id='k56afd5'), Comment(id='k57fn1u'), Comment(id='k5by0x2'), Comment(id='k5hsd1z'), Comment(id='k5hwabd'), Comment(id='k5jddh2'), Comment(id='k5l1gtq'), Comment(id='k5lgmw2'), Comment(id='k5n8j9k'), Comment(id='k5oz4g9'), Comment(id='k5pccqj'), Comment(id='k5pt60l'), Comment(id='k5se5w4'), Comment(id='k5t7udd'), Comment(id='k5tsk9n'), Comment(id='k5z588c'), Comment(id='k609wgb'), Comment(id='k60qayy'), Comment(id='k5lpjsp'), Comment(id='k5i0rtg'), Comment(id='k5lp7g1'), Comment(id='k5p08ha'), Comment(id='k5lmvy4'), Comment(id='k5e9dkg'), Comment(id='k5ajfpo'), Comment(id='k5q6m1p'), Comment(id='k5lmlev'), Comment(id='k5641v8'), Comment(id='k5oyvzj'), Comment(id='k5u71ri'), Comment(id='k5vhs6e'), Comment(id='k5c83l8'), Comment(id='k5dgxp6'), Comment(id='k563rtp'), Comment(id='k59rmoh'), Comment(id='k59sxpp'), Comment(id='k5dghu8'), Comment(id='k5lolbs'), Comment(id='k5m3va6'), Comment(id='k5n911w'), Comment(id='k5kb0ft'), Comment(id='k5p0mzp'), Comment(id='k5umt2d'), Comment(id='k5rmhy9'), Comment(id='k5vyd8f'), Comment(id='k5ulu0l'), Comment(id='k5ul8n6'), Comment(id='k5vxx6w'), Comment(id='k5tws15'), Comment(id='k64up4g'), Comment(id='k5p3fne'), Comment(id='k5ukhxd'), Comment(id='k5zddt6'), Comment(id='k5vi01l'), Comment(id='k5dpyxn'), Comment(id='k565kd7'), Comment(id='k59z7ax'), Comment(id='k5e0x34'), Comment(id='k5lsh2g'), Comment(id='k5m46hg'), Comment(id='k5nbg9m'), Comment(id='k5rn8kf'), Comment(id='k62mcc8'), Comment(id='k62uruj'), Comment(id='k5w1d2o'), Comment(id='k5uq8uz'), Comment(id='k5vjp8a'), Comment(id='k5drvld'), Comment(id='k56eq27'), Comment(id='k5e385h'), Comment(id='k5lvgts'), Comment(id='k640bfs'), Comment(id='k5z7kl9'), Comment(id='k5uqny5'), Comment(id='k5du31u'), Comment(id='k56fg98'), Comment(id='k5ek0t4'), Comment(id='k5lvxe4'), Comment(id='k62uto9'), Comment(id='k5ur1o6'), Comment(id='k5e2e2z'), Comment(id='k56h7wi'), Comment(id='k5us6r3'), Comment(id='k56ia8g'), Comment(id='k5ushgi')]"
17950k5,CombinationThese993,,2023-10-16 12:38:26+00:00,False,,False,False,True,False,/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,Interpretation of logistic regression in absolute terms,"I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.

The problem is very unbalanced, most people will not concert.

Now....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.
I.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.

How would you go about solving this?",datascience,https://www.reddit.com/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,0,1,1.0,[]
178zw5j,Green_Ad6024,,2023-10-16 06:53:42+00:00,False,,False,False,True,False,/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,Which Model is best for Word Level Embeddings Generation?," Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. 

I have tried ""[https://tfhub.dev/google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4)"" but it gives high score even there is no matching between words.

Thank you for your guidance. ",datascience,https://www.reddit.com/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,1,2,1.0,[Comment(id='k53efne')]
1792i6s,you_ako,,2023-10-16 10:03:59+00:00,False,,False,False,True,False,/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,How remove highly skewed feature,"Hey everyone,
I work actually in a ML project for binary classification problem. When I did the EDA, I found that there are some numerical features highly skewed ( almost close to zero) and we plotted the histogram of each feature by class I have the same distribution... 

Can someone help to solve this problem 🙏🏻",datascience,https://www.reddit.com/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,4,1,0.67,"[Comment(id='k53vwdw'), Comment(id='k53z9wm'), Comment(id='k53nqga'), Comment(id='k53omk9')]"
178yb8k,arya_Kumar,,2023-10-16 05:03:09+00:00,False,,False,False,True,False,/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,How to use PPO policy network to find global min of a function ?,"Hello everyone, I have been given a task where I have to find the minimum of a function. I know i can easily do this using Gradient descent but I have been specifically told to use PPO policy network and explore-exploit framework.

Is it even possible? If so then how should I go about achieving this?

link to the function formula is given here: [https://www.sfu.ca/\~ssurjano/holder.html](https://www.sfu.ca/~ssurjano/holder.html)",datascience,https://www.reddit.com/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,0,2,1.0,[]
178eu2m,InterestingBasil,,2023-10-15 12:58:50+00:00,False,,False,False,True,False,/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,Build a Data Science App with Just Python: A Streamlit Guide," td/dr: easily build a SaaS with just python + zero front-end knowledge using streamlit.

I wrote this short guide which allows you to create a Data Science micro-SaaS MVP with stripe integration using Streamlit python package. I thought folks here might find it useful. Example of a zillow clone below.

[A Comprehensive Guide to Building and Deploying a Scalable SaaS Web App with Python, Streamlit, MongoDB, and Stripe](https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86)

[example of Streamlit SaaS](https://preview.redd.it/xl4z0dtf6dub1.png?width=1510&format=png&auto=webp&s=82643795b248c160de48cdc0f2fee9b0c6ac19ed)",datascience,https://www.reddit.com/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,10,35,0.89,"[Comment(id='k4zprr4'), Comment(id='k4zdnqv'), Comment(id='k4zqh5n'), Comment(id='k50tknv'), Comment(id='k50kex7'), Comment(id='k50kggc'), Comment(id='k50kbxi'), Comment(id='k53o692'), Comment(id='k5207qx'), Comment(id='k520h5o')]"
178shmx,Practical_Laugh6208,,2023-10-15 23:45:09+00:00,False,,False,False,True,False,/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,The ML project failure funnel,"Hello there. 

I've been thinking a lot recently about ML projects that failed and tried to organize and write up my thoughts. Do y'all see it this way?  

[https://www.kobrosly.net/ML\_failure\_funnel.html](https://www.kobrosly.net/ML_failure_funnel.html)",datascience,https://www.reddit.com/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,2,4,0.7,"[Comment(id='k522ujh'), Comment(id='k52jleq')]"
1786pqr,Equal_Astronaut_5696,,2023-10-15 03:39:31+00:00,False,,False,False,True,False,/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,"How to handle ""A.I."" obsessed management?","Just wondering how to handle management that thinks ChatGPT is a sentiment being that is going to that is self learning entity that solves every problem. I was asked to give a presentation on how LLMs work and indicated they are  not considered classical A.I. After I was sent crackpot articles on how Chapt is thinking and learning, reading and learning how to talk.  Management literally is asking with every data science  project  if we incorporate ChatGPT A.I.. Im in a leadership role so have to try hard not to poo poo  this enthusiasm but its hard. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,48,157,0.98,"[Comment(id='k4xt94t'), Comment(id='k4ybfgp'), Comment(id='k4xovlh'), Comment(id='k4ycc53'), Comment(id='k4ygsps'), Comment(id='k4yqf74'), Comment(id='k4z2hnn'), Comment(id='k4xq79w'), Comment(id='k51qs3m'), Comment(id='k4xwg3m'), Comment(id='k4yvpt5'), Comment(id='k4xzr8n'), Comment(id='k4yza3y'), Comment(id='k4z0z79'), Comment(id='k4zbg3h'), Comment(id='k4zlkk1'), Comment(id='k4zwbu7'), Comment(id='k50no68'), Comment(id='k50oll7'), Comment(id='k50uf3w'), Comment(id='k51acrg'), Comment(id='k53z1q9'), Comment(id='k4zb9wp'), Comment(id='k52caum'), Comment(id='k4z2mrh'), Comment(id='k52bj4q'), Comment(id='k50nchy'), Comment(id='k50r72x'), Comment(id='k4xx3qn'), Comment(id='k4yaz1x'), Comment(id='k4ydwvt'), Comment(id='k4xxfk7'), Comment(id='k4yflqt'), Comment(id='k4xzvdh'), Comment(id='k4y013k'), Comment(id='k4yeg6d'), Comment(id='k4z2iia'), Comment(id='k4yfq6p'), Comment(id='k4zx9f7'), Comment(id='k52bm1k'), Comment(id='k53njpo'), Comment(id='k4y3ywm'), Comment(id='k4y336o'), Comment(id='k4z7i2h'), Comment(id='k4y72o7'), Comment(id='k4zc50e')]"
178oz6c,sn9691,,2023-10-15 21:02:07+00:00,False,,False,False,True,False,/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,Opinions about the insurance industry?,"Apologies if this is the wrong place to ask. I was recently hired as a data scientist in a (motor) finance company. What is your opinion about this industry? Are insurance skills transferable to other industries too and if so, which ones do you think are closest?",datascience,https://www.reddit.com/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,1,6,1.0,[Comment(id='k53tg0l')]
178z2x2,gumiho34,,2023-10-16 05:55:26+00:00,False,,False,False,True,False,/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,Data science/analytics project idea for friend's business,"Hi everyone. My friend has a small business (think ecommerce) and asked me if i can help in any way. I have a math background but I'm interested in trying some sort of DS/DA side project. Any ideas on what topics / results i should look for?

Sorry if this is open ended; this kind of project seems very different from college projects where they tell you to do a,b,c and put it in a presentation.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,5,1,0.67,"[Comment(id='k53lbqz'), Comment(id='k54k539'), Comment(id='k54npl0'), Comment(id='k54qjco'), Comment(id='k54rzg4')]"
178yyfo,Vegetable-Hospital79,,2023-10-16 05:46:38+00:00,False,,False,False,False,False,/r/datascience/comments/178yyfo/ms_in_statistics_at_east_bay_location_vs_ms_in/,MS in Statistics at East Bay location vs MS in Data Science in top 150 ranked University.,,datascience,/r/gradadmissions/comments/178ysg4/ms_in_statistics_at_east_bay_location_vs_ms_in/,1,1,0.67,[Comment(id='k56qqul')]
178ioxq,Much-Focus-1408,,2023-10-15 16:10:02+00:00,False,,1697510944.0,False,True,False,/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,Mgmt and team want me to put a model in production without data. What do I do?,"Edit: thank you for all of your help!! I spoke with legal and said where I was, where I was going to be, and asked for more time to get the data. The data is slowly coming in; very excited! 

Feeling incredibly anxious since this goes against my ethical morals. 

I trained a model on data that won’t be used anymore; however, they want to use this model for data/KPIs that I’ve never seen before. They overpromised to senior leadership because the company is suffering. And they want me to over-deliver and do the paperwork/put this model into production.

I’ve asked to delay the deadline to get access to the KPIs for the model, but all they did was move the model due date up by…. A month. 

I’m having panic attacks and can’t sleep because this is just setting me up to fail. I’m so burnt out after speaking with management/teams. They just want to push this model into production, no matter what. 

How do you handle that? I’ve escalated the problem to other pp in mgmt and they said to just do it because of how important the model is. I’m 1000% sure that I’ll be seen as a scapegoat because there’s no way you can have a good model if there’s no data to train it/the wrong data.

For example, the OG data was on cats, but now they want me to look at data about ligers. It’s ridiculous and I’m not sure what to do. 

I haven’t been able to deliver the paperwork like they want/legal review because I know that this model isn’t good, but they want this to go into production so badly that the paperwork/things I’m saying aren’t correct. It’s due tomorrow, but there’s no way I can feasibly do that. I’ve tried meds and even thought of taking myself out of office this week to avoid this, but I lack the PTO. I got sick from the lack of sleep and I’m finding myself procrastinating on anything else because this ask seems so unethical. So many people at my company/role are getting laid off, and I should do this, but I just can’t do this. It’s related to my performance goals, too.",datascience,https://www.reddit.com/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,32,9,0.72,"[Comment(id='k4ztjq6'), Comment(id='k509wli'), Comment(id='k50a69t'), Comment(id='k50q2jw'), Comment(id='k50f0gg'), Comment(id='k53xr3c'), Comment(id='k542g5s'), Comment(id='k4zuns5'), Comment(id='k50e628'), Comment(id='k50dso2'), Comment(id='k50uixv'), Comment(id='k50fomz'), Comment(id='k502uwi'), Comment(id='k51h7ck'), Comment(id='k5184if'), Comment(id='k51ckkr'), Comment(id='k50im3j'), Comment(id='k504xqr'), Comment(id='k5386ks'), Comment(id='k52c1xg'), Comment(id='k519omq'), Comment(id='k50j6tb'), Comment(id='k509vv8'), Comment(id='k53e6i2'), Comment(id='k51mumw'), Comment(id='k50metr'), Comment(id='k51symt'), Comment(id='k50ecfn'), Comment(id='k50muqx'), Comment(id='k50fiy0'), Comment(id='k50n2o3'), Comment(id='k50k53w')]"
178kkpc,indiancaptainamerica,,2023-10-15 17:39:17+00:00,False,,False,False,True,False,/r/datascience/comments/178kkpc/casual_inference/,Casual Inference,"I am aware about the experiment design process in simple business model, but experiment design is lot more complicated in two sided or three sided marketplace. Can anyone help me to understand how the experiment design works in three sided marketplace like Uber or Amazon ?",datascience,https://www.reddit.com/r/datascience/comments/178kkpc/casual_inference/,5,5,0.78,"[Comment(id='k526cix'), Comment(id='k53p6mc'), Comment(id='k5446wh'), Comment(id='k54utzv'), Comment(id='k545a7f')]"
178lcts,Objective-Test5021,,2023-10-15 18:15:37+00:00,False,,1697394042.0,False,True,False,/r/datascience/comments/178lcts/is_my_experience_not_good/,Is my experience not good?,"
For some context, I’m a 24 year old international who recently graduated with a MS in CS in the US. Throughout my bachelors and while applying for internships during my first year, I always wanted to do DS. This was primarily based on a misconception however. 

During my bachelors I was not serious about coursework or coding, not in the slightest. It was only when covid hit and I realized I’ll be going to the US soon, did I start looking into some actual coding stuff. Started off with Python and thought DS was all about pandas, numpy and scikit learn and decided this is what I wanted to do. Obviously as I started grad school and learnt more about the actual nuances of ML and DS, I realized I was nowhere near good enough with my foundations in stats and math. 

I do consider myself to be a problem solver though, so despite not having a great base and starting off with grad level concepts in school, I was able to get upto speed and score a good grade. 

After this, I landed my first internship in “Data Science” at a consulting firm. Through 3 months, all I did was a ton of web scraping and ETL operations. Applying traditional ML in litigation casework is not easy because eventually all cases or most cases end up in front of a jury. So I never got to apply all that math in a professional environment. 

Since then, the world went through a “recession” and I couldn’t even land a single other interview. Did another internship with these guys and switched my focus to development based cases. Started building dashboards in Javascript and backends in C#. The closest DS related work I have done is integrating Azure OpenAI LLM APIs into a VueJs frond end through a .NET backend. Did this for 2 reasons, one, web scraping and ETL was redundant and boring. Two, the manager in charge of those cases is awful, constantly undermining my credentials, never even making eye contact during a conversation, insanely condescending and even told me multiple times that he doesn’t believe I have 2 degrees in CS. 

Anyway, at this point, I have been doing this for about 10 months. Based on my work that has transcended into more software development, do you think I should exclusively apply to SWE jobs to find a way out? What could my options be? Also, does this kind of a resume where you jump from one tech stack to another hurt? I haven’t received any interviews in about a year. Wondering if this is the general state of the world or is something fundamentally wrong with my work exp and if I’m stuck where I am.",datascience,https://www.reddit.com/r/datascience/comments/178lcts/is_my_experience_not_good/,9,5,0.73,"[Comment(id='k50o2sl'), Comment(id='k51nzdl'), Comment(id='k53bgtg'), Comment(id='k50qteg'), Comment(id='k51vstc'), Comment(id='k51y9d8'), Comment(id='k545fex'), Comment(id='k51vut4'), Comment(id='k51ybpw')]"
178eum0,Rebec1990,,2023-10-15 12:59:45+00:00,False,,False,False,True,False,/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,Data analytics leadership and imposter syndrome?,"Data analytics leadership and imposter syndrome?

I have found myself in and out of data analytics leadership roles in the past decade, mixed with hands-on data analyst work. I know I have some legit skills (eg, I have lots of experience in inferential statistics, research, can speak to the outcomes well, etc), but I can’t seem to shake the feeling of not deserving to be in a leadership position. For example, I recently hired a data analyst to expand my existing team and going through all the resumes showed me all the things that I can’t do (work in specific coding languages, predictive modeling, just to name a few). At several points, I asked myself why these people shouldn’t be MY boss because they clearly have to teach me lots of valuable skills. 

So please talk to me about the value-add of analytics leadership: what does a good leader bring to the table? Is it okay to not be able to do everything yourself? Is this imposter syndrome and do others recognize it?",datascience,https://www.reddit.com/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,13,13,0.88,"[Comment(id='k4z07f3'), Comment(id='k4z1etq'), Comment(id='k4zd9dd'), Comment(id='k4zltwk'), Comment(id='k4zdukg'), Comment(id='k51fe53'), Comment(id='k539sf6'), Comment(id='k4ze9bw'), Comment(id='k51fpyo'), Comment(id='k4zgq9m'), Comment(id='k51sj5s'), Comment(id='k51t5wc'), Comment(id='k51vm36')]"
178vkg9,CrazyProfessionalp,,2023-10-16 02:24:19+00:00,False,,False,False,True,False,/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,What is the best tool or way to measure uncertainties using machine learning ?,"I have a certain data that I measure the uncertainty via Monte Carlo, but I was wondering if there is a practical way to do that using machine learning.",datascience,https://www.reddit.com/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,2,1,0.6,"[Comment(id='k52sla7'), Comment(id='k52cejj')]"
178kwz8,Patient-Sun-5806,,2023-10-15 17:55:34+00:00,False,,False,False,True,False,/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,Get masters if my bachelors is in data sci?,I’m seeing a lot of people recommending people that have a degree in econ/cs/math to get a masters in data science or statistics. Will I need one if my whole bachelors is based in pure data science anyway?,datascience,https://www.reddit.com/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,3,4,1.0,"[Comment(id='k529zaz'), Comment(id='k53935d'), Comment(id='k51198e')]"
1780308,crattikal,,2023-10-14 21:53:27+00:00,False,,1697326415.0,False,True,False,/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,Took me over a year but I finally got a data analyst job,"Graduated summer of 2022 with a MS in Analytics after discovering the field by accident while exploring possible new fields, as I got burnt out from crazy hours at a previous database engineer role. I kept getting far in interview processes but never the role, although in hindsight I dropped out of a few interview processes that I maybe shouldn't have since I'd be the only analyst in the company. Finally got one this week, albeit as a data engineer/analyst supporting another analyst, right after taking a customer service role as I was giving up and planning on going to grad school next year for something completely different. Still processing this as I can barely believe it.",datascience,https://www.reddit.com/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,15,131,0.97,"[Comment(id='k4x7qas'), Comment(id='k4wfv8u'), Comment(id='k4wq2se'), Comment(id='k4wta4i'), Comment(id='k4x0m6c'), Comment(id='k4xkeie'), Comment(id='k4x5dwu'), Comment(id='k4zenpw'), Comment(id='k52j87b'), Comment(id='k4x99tz'), Comment(id='k50hc99'), Comment(id='k4yk6zs'), Comment(id='k4zglkn'), Comment(id='k50h3dk'), Comment(id='k50h6ix')]"
178neqa,hellohibyebye13,,2023-10-15 19:49:51+00:00,False,,False,False,True,False,/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,c3AI data scientist interview,"Has anyone interviewed at c3ai? I've read there are 3 stages of b2b interviews: ML/stats fundamentals, pandas/numpy/python coding, case study. 

What kind of questions are asked, especially in the case study portion? what exactly does the coding part inolve? also for stats - is it enough to cover hypothesis testing, p-values, PCA, etc? 

Any insight is appreciated!",datascience,https://www.reddit.com/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,4,2,0.75,"[Comment(id='k53vsn1'), Comment(id='k584uwi'), Comment(id='k5hc23e'), Comment(id='k5i146v')]"
178j8v9,TheFibonacci1235,,2023-10-15 16:35:34+00:00,False,,1697390123.0,False,True,False,/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,Tips on Data Science Jobs Abroad,"I am a 27-year-old guy who lives in the Netherlands and has about 2.5 years of experience in data science/software engineering. I've always dreamt of going on an international adventure and working abroad in Europe. Unfortunately, I have not yet been able to or have had the courage to take the leap. Now, with my girlfriend going on an exchange at the start of 2024, it feels like the perfect time to explore the possibilities of finding a job abroad.

I'm looking for tips, help, or experiences on how to tackle this big project. How do you start to look for jobs or projects? I know LinkedIn of course, but I'm wondering if there are also companies hiring people for a fixed-time contract. Or are there any businesses or platforms that connect job seekers with such companies? I'm uncertain about committing to an indefinite job, and I think for example a 6-month project might provide more security.

I'd appreciate any advice or stories that people are willing to share about their experiences working abroad. Thank you in advance for your support and wisdom!",datascience,https://www.reddit.com/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,0,3,1.0,[]
178l850,Zealousideal-Yak5547,,2023-10-15 18:09:43+00:00,False,,False,False,True,False,/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,Price effect on room occupancy rate,"Hello wonderful people,
I've been ask to study the effect of price on the final room occupancy rate for the hostels of my company.

So here are the data :
For a date (t), and for a specific room type, I have the occupancy Rate (OR, between 0 and 1), a set of categorical ordinal variables (total of 90 variables) that represent an indexed price of the room at a date (t-z). In other words, I know what was the indexed price of a specific room from the date being analysed back to 90 days before.

As I said, those exogenous variables are categorical ordinal. For example : PRICE1, PRINCE2... PRICE10, with price2 being more expensive than PRICE1. It is an indexed price in the sense that it drives the applied price on different booking network (booking.com, Expedia, our own website...)

How would you approach this subject ? I had in mind to try fitting an ARIMA model and look at the model parameters, but with the categorical ordinal variables, it would mean one-hour encoding and therefore having a huuuge dimensionality...

What do you guys think ? 💪",datascience,https://www.reddit.com/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,4,2,0.75,"[Comment(id='k50al27'), Comment(id='k58eabp'), Comment(id='k50e2d2'), Comment(id='k58ectw')]"
1784jir,maple_enthusiast,,2023-10-15 01:38:43+00:00,False,,1697769719.0,False,True,False,/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,"I am interviewing my future boss, what should I ask them?","As the title suggests I am going to be having 1-on-1 interviews with 3 candidates to replace my previous boss. Others within my team as well as higher ups will also be interviewing them separately. I will be given some instruction and there will be some coordination between all of us involved in this process. As this is a new experience for me (and likely a little unusual for most people to be choosing their boss), I am wondering if anyone has any suggestions as to questions that might be a bit outside of the basics you'd find on any old list of interview questions.   


For context, I have worked as a data analyst/data scientist/statistician (there isn't really a distinction between these roles in my area) for about 4.5 years now and have been in this current job for 2 years. I work in healthcare analytics with some of my work being straightforward research for the purposes of publication and other work with hospitals, governments, etc. trying to leverage their data to improve different aspects of their work and responsibilities. I am based outside of the U.S.A. and this is not for an American company FYI.

Update: Appreciate all the feedback. There were some really great responses in here that I will definitely be using.",datascience,https://www.reddit.com/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,28,31,0.98,"[Comment(id='k4xbgew'), Comment(id='k4xbabk'), Comment(id='k4x8tvf'), Comment(id='k4yaadh'), Comment(id='k4xdnj6'), Comment(id='k4yecxu'), Comment(id='k4y4ws6'), Comment(id='k4ynxjp'), Comment(id='k4xcbj7'), Comment(id='k4xk35o'), Comment(id='k4xwwb7'), Comment(id='k4ykt1k'), Comment(id='k4znf7v'), Comment(id='k506m89'), Comment(id='k50bers'), Comment(id='k5a5iun'), Comment(id='k4xwnih'), Comment(id='k4z8wb5'), Comment(id='k4xicxu'), Comment(id='k4y4tj4'), Comment(id='k5myw08'), Comment(id='k4ycsp1'), Comment(id='k4zo1wd'), Comment(id='k4xwp9n'), Comment(id='k4ytoo4'), Comment(id='k4yfm0g'), Comment(id='k4yuzl4'), Comment(id='k532ie3')]"
178vkrx,CrazyProfessionalp,,2023-10-16 02:24:45+00:00,False,,False,False,True,False,/r/datascience/comments/178vkrx/what_is_the_best_tool_way_to_make_forecast_using/,What is the best tool/ way to make forecast using machine learning ?,,datascience,https://www.reddit.com/r/datascience/comments/178vkrx/what_is_the_best_tool_way_to_make_forecast_using/,1,0,0.2,[Comment(id='k52glo6')]
178kwzn,Humble_Engineer1124,,2023-10-15 17:55:35+00:00,False,,False,False,True,False,/r/datascience/comments/178kwzn/going_back_to_school/,Going back to school,"Hello!

I’m going back to school full time in the spring. I’m double majoring in data science and interactive media and getting my B.S. in both. I’m projected to be graduated by Spring of 2027. What internships should I start looking into and how far along in school should I start applying? I’m new to this field and have done alot of research into the type of jobs I can get but just wanted outside opinion.",datascience,https://www.reddit.com/r/datascience/comments/178kwzn/going_back_to_school/,0,1,1.0,[]
1785em4,krhymme,,2023-10-15 02:25:57+00:00,False,,False,False,True,False,/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,Company building an LLM App. Need some understanding if my opinions are reasonable.,"I'm your generic mid-career data scientist who sometimes functions as an ML engineer. I've been tasked with advising a team building an LLM application to automate 'data analysis' for non-technical customers. My role is to bring some wisdom and system design expertise to the team. The team is compromised of two people: a young, eager software engineer who calls themselves a ""Langchain Developer"" and a senior technical director who believes in the macro trends around Generative AI and wants to learn more about applying the techonology.

The idea is a customer types a vague question in to a field  *e.g.* ""Is my business meeting my customer retention goals"" and the output would be a visualization of some descriptive metrics and an interpretation of the data.

The design presented to me by the Langchain developer sounds overly complex and a bit unhinged to me. I'm looking for an external opinion to make sure my opinions are well grounded or make sense.

1. This project is my first time using LangChain. From reading through the LangChain code,  and building some basic examples, the library feels over abstracted.  You have to navigate a tangled mess of private variables to even find the prompt the tool is using. I am *really* concerned about putting Langchain code in production since it seems difficult to debug and modify. Why can't we use a DAG or state machine instead?
2. The langchain developer doesn't present any systematic way to deal with hallucination. Generally, the strategy verbalized is too play ""wack a mole"" every time they see or measure a hallucination. If hallucinations are rare, then sure, and I'd be a bit more comfortable with this approach. But I've see no evidence that's the case.
3. The scalable ways to measure hallucination often use an LLM to judge it's own output. Generally, I try to avoid feedback loops between models. Is that too strong of an opinion to have when working with LLMs?

Appreciate the responses!",datascience,https://www.reddit.com/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,15,17,0.95,"[Comment(id='k4xqx0i'), Comment(id='k4xlrk4'), Comment(id='k4xnfk8'), Comment(id='k4y0f5w'), Comment(id='k4xlmqo'), Comment(id='k4xsl3b'), Comment(id='k4xzbve'), Comment(id='k527i7e'), Comment(id='k53g9g1'), Comment(id='k549d2b'), Comment(id='k4zdaf9'), Comment(id='k4yooh0'), Comment(id='k50ipo5'), Comment(id='k4ys9rk'), Comment(id='k50j2wb')]"
178nz28,No-Dot-6385,,2023-10-15 20:16:06+00:00,False,,False,False,True,False,/r/datascience/comments/178nz28/biologist_phd_data_scientist/,Biologist (PhD) --> Data Scientist?,"I'm just starting a PhD in a life science field (at a top university, if it matters). I've been wanting to learn more about the data science field and whether having a PhD in a biology domain would be helpful for data scientists positions within biotech, healthcare, etc. I plan to complete a computational certificate that my program offers, and my thesis project should involve a good amount of data science on top of wet-lab work.

Would this be a good career path? Will not having a degree in computer science, data science, etc. put me at a disadvantage?",datascience,https://www.reddit.com/r/datascience/comments/178nz28/biologist_phd_data_scientist/,4,0,0.33,"[Comment(id='k50wxy2'), Comment(id='k518pct'), Comment(id='k50x7rm'), Comment(id='k510b7i')]"
178dsvv,alexey_timin,,2023-10-15 11:55:07+00:00,False,,False,False,False,False,/r/datascience/comments/178dsvv/from_lab_to_live_implementing_opensource_ai/,From Lab to Live: Implementing Open-Source AI Models for Real-Time Unsupervised Anomaly Detection in Images,,datascience,https://www.reduct.store/computer-vision/edge-computing/ai/Implementing-open-source-ai-anomaly-detection/,0,2,1.0,[]
177qnvc,cptsanderzz,,2023-10-14 14:21:20+00:00,False,,False,False,True,False,/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,Should I pursue a PhD,"So I’m in my late 20s, I received a bachelor of science in math and a master of science in data analytics. I have been working as a “Data Science Consultant” for 2 years now. I really just don’t find the work challenging or interesting. My field of interests include NLP, Policy, Media, and International Relations (I know very niche). The data science market is terrible and I’m applying to jobs and getting a few interviews, but not roles I’m really interested in. I think I would really enjoy doing applied data science research, like how can we use data science, statistics, etc. to address this issue. The problem is all of these jobs I see are reserved for PhDs. I just keep going back and forth on whether this should be something I pursue or not. What would you all recommend for someone in my shoes?",datascience,https://www.reddit.com/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,79,77,0.89,"[Comment(id='k4vsj9o'), Comment(id='k4usdoe'), Comment(id='k4w2mzt'), Comment(id='k4ul2e9'), Comment(id='k4vpj2b'), Comment(id='k4v94fu'), Comment(id='k4ujnxx'), Comment(id='k4w1005'), Comment(id='k4w6nez'), Comment(id='k4ww2aj'), Comment(id='k4x4e1p'), Comment(id='k4xcm13'), Comment(id='k4v3uxs'), Comment(id='k4vk3cr'), Comment(id='k4vnscb'), Comment(id='k4wvfr7'), Comment(id='k4wqrjz'), Comment(id='k4vaajt'), Comment(id='k4vtl7n'), Comment(id='k4w2mji'), Comment(id='k4wdqye'), Comment(id='k4wk87n'), Comment(id='k4wo18s'), Comment(id='k4xnh3c'), Comment(id='k4yuigh'), Comment(id='k4yyenk'), Comment(id='k4z0fsd'), Comment(id='k4zcr7i'), Comment(id='k4zpkjp'), Comment(id='k4vtlcy'), Comment(id='k4xlo7s'), Comment(id='k4uu0l5'), Comment(id='k4w43cs'), Comment(id='k4v2dfc'), Comment(id='k4un88l'), Comment(id='k4upzic'), Comment(id='k4vt8bq'), Comment(id='k4va8nf'), Comment(id='k4uuxsu'), Comment(id='k53jsu3'), Comment(id='k4w26g3'), Comment(id='k4vfoxz'), Comment(id='k4valf8'), Comment(id='k4vkq47'), Comment(id='k4wffld'), Comment(id='k4way0d'), Comment(id='k4uu7yu'), Comment(id='k4wcblh'), Comment(id='k4vufdi'), Comment(id='k4uszfr'), Comment(id='k4vtq6e'), Comment(id='k4vbv21'), Comment(id='k4uv5y4'), Comment(id='k53n2me'), Comment(id='k4vm4xi'), Comment(id='k4uupw9'), Comment(id='k4uuftk'), Comment(id='k4vu2vj'), Comment(id='k4vc9jz'), Comment(id='k4vg422'), Comment(id='k4v10gc'), Comment(id='k4uw0in'), Comment(id='k4vv6r1'), Comment(id='k4vno8r'), Comment(id='k4vhmpz'), Comment(id='k4v2nx3'), Comment(id='k4vzqb9'), Comment(id='k4w8sph'), Comment(id='k4vi2pj'), Comment(id='k4vr1oi'), Comment(id='k4v7lmw'), Comment(id='k4whu6s'), Comment(id='k4v9rht'), Comment(id='k4yus43'), Comment(id='k4vupiy'), Comment(id='k4yyhxn'), Comment(id='k4zndjr'), <MoreComments count=0, children=[]>]"
178bdnk,xTH13M0x,,2023-10-15 09:01:36+00:00,False,,False,False,True,False,/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,Looking for a tool for image recognition,"Hi, I'm looking for a tool to easily categorize a huge amount of images. Best case would be, if i could use the tool with a python library. Could you recommend anything?",datascience,https://www.reddit.com/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,0,2,1.0,[]
178rqxf,Ordinary_Jelly_6344,,2023-10-15 23:08:02+00:00,False,,False,False,True,False,/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,What do data scientist do when their data isn't reliable?," 

\#Apple, #Question, #Data\_Scientists,

What do data scientist do when their data isn't reliable? Looking for answers other than the easily Googled/ChatGPTed validate, clean, imputation, transformation, documentation, source investigation, quality assessment, etc.

\#Context, 

A project my team and I are working on we regularly release builds using Testflight. 

An observation is that Apple has incorrect analytics even within their walled garden from AppStoreConnect to TestFlight.

Specifically, in this screencast/video we can see that the version of the app which the App Store Connect dashboard says I've currently got installed is 1.0.1+26 which was installed today October 15th 2023.  


[https://youtube.com/shorts/Sc2NrvAKFlA?feature=share](https://youtube.com/shorts/Sc2NrvAKFlA?feature=share)

But at the beginning & end of the video, we clearly see that I haven't installed that version yet; I still need to update.

I accept data between differing aggregators being ""off"" no problem. 

\#Unpopular\_Opinion

However seeing this behavior within a platform/company which is the largest, most well-funded, arguably among the most technical in the world makes me doubt the value of data analytics/science.   


How can we be sure of our analysis if we can't be sure of our data? It's disconcerting.

Not trying to flame data scientists here, trying to figure out how to feel cause I do believe we have to have analytics/benchmarks to make informed decisions but this conundrum is causing cognitive dissonance.  


Looking forward to seeing everyones feedback.  
",datascience,https://www.reddit.com/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,5,0,0.35,"[Comment(id='k51qrte'), Comment(id='k526sef'), Comment(id='k51rnq0'), Comment(id='k51rtko'), Comment(id='k52alii')]"
178e7fp,asatenata,,2023-10-15 12:20:59+00:00,False,,False,False,True,False,/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,Finding ds job after life sciences degree,"During my BSc biochemistry degree I realised that I’m much more interested in analytics and data science than pure science. My dissertation was about analysing existing mitochondria proteins databases for which I used R, excel and Prism. I graduated from university as adult (M27) and I’ve been a quality manager in a local coffee shop chain for the last two years. What are my chances to get into data science field without cs/math degree and what would be the best strategy to land a job? For context I live in the UK.",datascience,https://www.reddit.com/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,3,1,0.6,"[Comment(id='k4yxejx'), Comment(id='k4zrb3z'), Comment(id='k4z1r71')]"
177w76r,Historical_Leek_9012,,2023-10-14 18:47:52+00:00,False,,False,False,True,False,/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,Do companies consider it cheating to Google/chat gpt stuff on hackerrank tests?,"Curious because I just took an assessment. Not like I googled the full question. I just had chat gpt fix some syntax issues and googled some functions I couldn’t remember the exact way to write. I think if they asked me about it, I’d just explain that’s what I did — same as when I’m writing code outside an assessment. But I’m curious what’s considered the norm in assessments for jobs.

Edit: there was nothing on the assessment that said either way.",datascience,https://www.reddit.com/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,26,24,0.79,"[Comment(id='k4w28v7'), Comment(id='k4yagwt'), Comment(id='k4wrifw'), Comment(id='k4wgmy7'), Comment(id='k4wo9nr'), Comment(id='k4whlrw'), Comment(id='k4y3t0l'), Comment(id='k4yjr0c'), Comment(id='k4z6umu'), Comment(id='k4w2sab'), Comment(id='k4xj4pt'), Comment(id='k4y5svf'), Comment(id='k4z5osm'), Comment(id='k4ybldm'), Comment(id='k4xkddn'), Comment(id='k4y9j9k'), Comment(id='k50muww'), Comment(id='k4z7ot3'), Comment(id='k4xltfh'), Comment(id='k4zdrpj'), Comment(id='k4zrsxz'), Comment(id='k4y9n6l'), Comment(id='k4zsj6w'), Comment(id='k4z21nx')]"
178cy0s,indusop,,2023-10-15 10:57:48+00:00,False,,False,False,False,False,/r/datascience/comments/178cy0s/interested_about_cricket_and_data_science_here_is/,Interested about cricket and data science ? Here is my new article on medium about building the IPl Win Predictor from scratch please have a look!!,,datascience,https://medium.com/@harshsmj1504/ipl-win-predictor-analyzing-winning-probabilities-d9f4f38e0226,0,1,0.67,[]
178csio,Economy_Tap7557,,2023-10-15 10:46:46+00:00,False,,False,False,True,False,/r/datascience/comments/178csio/walmart_data_science_internship/,Walmart Data Science Internship,"Hey Guys , I have my Walmart first round karat interview next week .

Any tips would be helpful:)

Thanks in advance",datascience,https://www.reddit.com/r/datascience/comments/178csio/walmart_data_science_internship/,2,1,1.0,"[Comment(id='k7f3cw3'), Comment(id='k7ofpgs')]"
178byoc,Informal-Assist2642,,2023-10-15 09:45:53+00:00,False,,False,False,True,False,/r/datascience/comments/178byoc/comprehending_research_papers/,Comprehending Research Papers,"Hi DS community, Was just wondering what are the approaches you guys take reading and comprehending Research papers and the maths behind it. I have developed a keen interest reading research; however, For me digesting the whole research paper takes a lot of time (5-6)hours. Since, I plan to go for PHD, this is the skill I want to polish the most. I was wondering, what approaches you guys take for the following.

*  Maths portion (which I enjoy I must say), here mostly I try to rederive the equations on paper to understand better. 
* The reference papers that I have to revisit to gain praticle insights about the research at hand ( most time I read them Abstract, intro, conclusion and diagrams to extract important insights only and other time I read them end-to-end.

Thanks again.",datascience,https://www.reddit.com/r/datascience/comments/178byoc/comprehending_research_papers/,0,1,1.0,[]
17798wz,anon_throwaway09557,,2023-10-13 21:28:48+00:00,False,,1697238048.0,False,True,False,/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,Warning to would be master’s graduates in “data science”,"I teach data science at a university (going anonymous for obvious reasons). I won't mention the institution name or location, though I think this is something typical across all non-prestigious universities. Basically, master's courses in data science, especially those of 1 year and marketed to international students, are a scam. 

Essentially, because there is pressure to pass all the students, we cannot give any material that is too challenging. I don't want to put challenging material in the course because I want them to fail--I put it because challenge is how students **grow** and **learn**. Aside from being a data analyst, being even an entry-level data scientist requires being good at a lot of things, and knowing the material deeply, not just superficially. Likewise, data engineers have to be good software engineers.

But apparently, asking the students to implement a trivial function in Python is too much. Just working with high-level libraries won't be enough to get my students a job in the field. OK, maybe you don’t have to implement algorithms from scratch, but you have to at least wrangle data. The theoretical content is OK, but the practical element is far from sufficient.

It is my belief that only one of my students, a software developer, will go on to get a high-paying job in the data field. Some might become data analysts (which pays thousands less), and likely a few will never get into a data career.

Universities write all sorts of crap in their marketing spiel that bears no resemblance to reality. And students, nor parents, don’t know any better, because how many people are actually qualified to judge whether a DS curriculum is good? Nor is it enough to see the topics, you have to see the *assignments*. If a DS course doesn’t have at least one serious course in statistics, any SQL, and doesn’t make you solve real programming problems, it's no good.",datascience,https://www.reddit.com/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,292,620,0.96,"[Comment(id='k4rjlcy'), Comment(id='k4s0cfn'), Comment(id='k4s8tfk'), Comment(id='k4sd9uz'), Comment(id='k4rqkq3'), Comment(id='k4ru1hm'), Comment(id='k4rys5l'), Comment(id='k4t85wh'), Comment(id='k4roh5h'), Comment(id='k4rxb7d'), Comment(id='k4rzkug'), Comment(id='k4svmqy'), Comment(id='k4runfq'), Comment(id='k4s5i6s'), Comment(id='k4t6kre'), Comment(id='k4roruh'), Comment(id='k4sjihu'), Comment(id='k4saxq4'), Comment(id='k4sgp8m'), Comment(id='k4t5h1m'), Comment(id='k4te9zn'), Comment(id='k4thotz'), Comment(id='k4ux0yp'), Comment(id='k4ryqbw'), Comment(id='k4s4gdo'), Comment(id='k4shgvr'), Comment(id='k4sc5vy'), Comment(id='k4sv4dv'), Comment(id='k4rr43n'), Comment(id='k4ryddd'), Comment(id='k4sno2n'), Comment(id='k4szqw5'), Comment(id='k4t9utc'), Comment(id='k4tm1sq'), Comment(id='k4tmf8w'), Comment(id='k4us629'), Comment(id='k4w5zi5'), Comment(id='k4wwqlt'), Comment(id='k4ziiv4'), Comment(id='k4rzaf7'), Comment(id='k4t70m8'), Comment(id='k4tt1s5'), Comment(id='k4tuq1h'), Comment(id='k4s37wt'), Comment(id='k4s9059'), Comment(id='k4tbkhm'), Comment(id='k4rmt6x'), Comment(id='k4rv3yr'), Comment(id='k4svv91'), Comment(id='k4s7pfm'), Comment(id='k4t2pvv'), Comment(id='k4swpoi'), Comment(id='k4swvdb'), Comment(id='k4t1cfl'), Comment(id='k4t4zm9'), Comment(id='k4te8ai'), Comment(id='k4thtzr'), Comment(id='k4tih1g'), Comment(id='k4tlc09'), Comment(id='k4tpa2x'), Comment(id='k4tswvb'), Comment(id='k4u201m'), Comment(id='k4u4ry5'), Comment(id='k4u5xhz'), Comment(id='k4ua9kf'), Comment(id='k4uehk5'), Comment(id='k4uky6t'), Comment(id='k4up9fn'), Comment(id='k4uqe8i'), Comment(id='k4uqkw9'), Comment(id='k4uty0u'), Comment(id='k4vcyzz'), Comment(id='k4vm650'), Comment(id='k4whsv3'), Comment(id='k4wnntd'), Comment(id='k4wpjga'), Comment(id='k4wzzhb'), Comment(id='k4xdbdc'), Comment(id='k4xfr8b'), Comment(id='k4xi5d8'), Comment(id='k4xjzno'), Comment(id='k4xnfnu'), Comment(id='k4yk7yy'), Comment(id='k4zew3c'), Comment(id='k54pn8x'), Comment(id='k575969'), Comment(id='k6icqn3'), Comment(id='k7dj430'), Comment(id='k7dj5gb'), Comment(id='k4rs0z6'), Comment(id='k4s0ddc'), Comment(id='k4srges'), Comment(id='k4rylpl'), Comment(id='k4vw8hy'), Comment(id='k4vfgs6'), Comment(id='k4xbu16'), Comment(id='k4ydjd2'), Comment(id='k4yrc1y'), Comment(id='k4tpk4k'), Comment(id='k4t0g4e'), Comment(id='k4tpphx'), Comment(id='k4uczej'), Comment(id='k4te2w6'), Comment(id='k4w04xu'), Comment(id='k4sraym'), Comment(id='k4trlco'), Comment(id='k4t2czz'), Comment(id='k4tgf4j'), Comment(id='k4tm6ed'), Comment(id='k4ta3ah'), Comment(id='k4ux54z'), Comment(id='k4wh8ly'), Comment(id='k4wiabv'), Comment(id='k4ubidi'), Comment(id='k4ryccl'), Comment(id='k4xwnll'), Comment(id='k4sl68m'), Comment(id='k6rxm7a'), Comment(id='k4sszjk'), Comment(id='k4udkqa'), Comment(id='k4t9xs2'), Comment(id='k576ak2'), Comment(id='k4rowrl'), Comment(id='k4sbs3m'), Comment(id='k4sdmu0'), Comment(id='k4wxrhw'), Comment(id='k4uykmg'), Comment(id='k4w0bf2'), Comment(id='k4rwdvn'), Comment(id='k4s7a8y'), Comment(id='k4t6at0'), Comment(id='k4tpt5a'), Comment(id='k4rozen'), Comment(id='k4rp9pn'), Comment(id='k4ru1va'), Comment(id='k4rw98s'), Comment(id='k4v71uy'), Comment(id='k55rw9d'), Comment(id='k4snldc'), Comment(id='k4tsgfb'), Comment(id='k4v9c1i'), Comment(id='k4sv8e4'), Comment(id='k4tcl83'), Comment(id='k4tqaco'), Comment(id='k4s8lde'), Comment(id='k4t7xkp'), Comment(id='k4to1la'), Comment(id='k4tnq8a'), Comment(id='k4tmuzl'), Comment(id='k4ym999'), Comment(id='k4sdx2q'), Comment(id='k4uiono'), Comment(id='k4sszlv'), Comment(id='k4szivc'), Comment(id='k4zi96f'), Comment(id='k4rn09i'), Comment(id='k4rurii'), Comment(id='k4rwkhu'), Comment(id='k4rzeq5'), Comment(id='k4rw5bv'), Comment(id='k4sn5r3'), Comment(id='k4se0ef'), Comment(id='k4toao9'), Comment(id='k4tpee8'), Comment(id='k4tnb3r'), Comment(id='k4tn82q'), Comment(id='k4wo1qk'), Comment(id='k56as3b'), Comment(id='k7sp538'), Comment(id='k4rvra1'), Comment(id='k4sst3z'), Comment(id='k4tepzj'), Comment(id='k4scsxu'), Comment(id='k4u2sdc'), Comment(id='k4xhrms'), Comment(id='k4xpgec'), Comment(id='k4w0152'), Comment(id='k4t4dna'), Comment(id='k4t1dmf'), Comment(id='k4v7x21'), Comment(id='k4wk9wa'), Comment(id='k4tlq5h'), Comment(id='k4ukg9t'), Comment(id='k4t4sz7'), Comment(id='k4t1nha'), Comment(id='k4vh58d'), Comment(id='k50v8e1'), Comment(id='k4rq297'), Comment(id='k4tm5gh'), Comment(id='k4t64w5'), Comment(id='k4veygp'), Comment(id='k4slpni'), Comment(id='k4u4aqy'), Comment(id='k4rqf42'), Comment(id='k4sd4fx'), Comment(id='k4rt6ns'), Comment(id='k4sua63'), Comment(id='k4v0nb8'), Comment(id='k55vwyf'), Comment(id='k4u91pz'), Comment(id='k4u92vo'), Comment(id='k4u95fs'), Comment(id='k4u22mg'), Comment(id='k4uyrdo'), Comment(id='k4ydgqe'), Comment(id='k4tof14'), Comment(id='k4tdau8'), Comment(id='k4sn44l'), Comment(id='k4toqib'), Comment(id='k4ro8n6'), Comment(id='k4rvk2c'), Comment(id='k4rwyxq'), Comment(id='k4s0ydf'), Comment(id='k4uihd4'), Comment(id='k592imp'), Comment(id='k4t2tlk'), Comment(id='k4tjwov'), Comment(id='k4s9ajj'), Comment(id='k4uq3nd'), Comment(id='k4vnqbv'), Comment(id='k4ugj4r'), Comment(id='k4zfguu'), Comment(id='k4swk7e'), Comment(id='k4ty704'), Comment(id='k4sm7rp'), Comment(id='k4wge24'), Comment(id='k4t6b30'), Comment(id='k4t2gsi'), Comment(id='k4wukmj'), Comment(id='k4tsqor'), Comment(id='k4vqv76'), Comment(id='k4vt5cc'), Comment(id='k4urrz9'), Comment(id='k4vu60d'), Comment(id='k50xntd'), Comment(id='k4x6841'), Comment(id='k4rrucn'), Comment(id='k4s12yk'), Comment(id='k4rwk1p'), Comment(id='k4rwenj'), Comment(id='k4v5vq2'), Comment(id='k55zk1j'), Comment(id='k4vbll2'), Comment(id='k4vj2gl'), Comment(id='k4uzs5o'), Comment(id='k4v8pzv'), Comment(id='k4ropir'), Comment(id='k4rs3xy'), Comment(id='k4rvqs7'), Comment(id='k592zmn'), Comment(id='k4tmk1c'), Comment(id='k4u2dyc'), Comment(id='k4u3j1c'), Comment(id='k4s9jwo'), Comment(id='k4tm2v9'), Comment(id='k4uqb7t'), Comment(id='k54yets'), Comment(id='k4ui63c'), Comment(id='k4w0uza'), Comment(id='k4vedrk'), Comment(id='k4tb9c8'), Comment(id='k4xs56m'), Comment(id='k4ug631'), Comment(id='k4uuitz'), Comment(id='k4sth96'), Comment(id='k4usfe5'), Comment(id='k4vc444'), Comment(id='k5602w6'), Comment(id='k4vk08y'), Comment(id='k4vtiht'), Comment(id='k4vcfr6'), Comment(id='k4rzfz7'), Comment(id='k4rw405'), Comment(id='k5chosd'), Comment(id='k4s9p49'), Comment(id='k4t7sn8'), Comment(id='k4uvqh5'), Comment(id='k4upoza'), Comment(id='k4unges'), Comment(id='k4vie9f'), Comment(id='k4uty2g'), Comment(id='k4vcif1'), Comment(id='k4vnkjk'), Comment(id='k4vuzjc'), Comment(id='k4s5yvm'), Comment(id='k4rwrdp'), Comment(id='k4sjkrz'), Comment(id='k4uvthd'), Comment(id='k4tmi9t'), Comment(id='k4vfuq5'), Comment(id='k4w2qxy'), Comment(id='k4veqzx'), Comment(id='k4vxejz'), Comment(id='k4x3m32'), Comment(id='k4sjqqe'), Comment(id='k4xmfoq'), Comment(id='k4xoo3i')]"
1786d5a,Neurosymbolic,,2023-10-15 03:19:34+00:00,False,,False,False,True,False,/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,Supercharging Reinforcement Learning with Logic,"Deep reinforcement learning has led to a variety of compelling results.  However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly.  Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.

&#x200B;

https://preview.redd.it/x7050xg2baub1.png?width=1786&format=png&auto=webp&s=14929e5614404808c85d48922e0af947f8d52b90

We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).

&#x200B;

https://preview.redd.it/k1ntxyh3baub1.png?width=1636&format=png&auto=webp&s=bdf0bb030a0a4d38034460d52940593e6a57cb32

However, the benefits of our semantic proxy go well beyond performance.  The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity.  PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false).  We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.

Preprint: [https://arxiv.org/abs/2310.06835](https://arxiv.org/abs/2310.06835)

Video: [https://youtu.be/9e6ZHJEJzgw](https://youtu.be/9e6ZHJEJzgw)

Code for PyReason-as-a-Sim (integration with DQN): [https://github.com/lab-v2/pyreason-rl-sim](https://github.com/lab-v2/pyreason-rl-sim)

Code for PyReason Gym: [https://github.com/lab-v2/pyreason-gym](https://github.com/lab-v2/pyreason-gym)

PyReason home: [https://neurosymbolic.asu.edu/pyreason/](https://neurosymbolic.asu.edu/pyreason/)",datascience,https://www.reddit.com/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,1,2,0.76,[Comment(id='k5hyxkh')]
1788uk9,hassaan84s,,2023-10-15 05:57:20+00:00,False,,1697507767.0,False,True,False,/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,AI-based Research tool to help brainstorm novel ideas,"Hey folks,

I developed a research tool [https://demo-idea-factory.ngrok.dev/](https://demo-idea-factory.ngrok.dev/) to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.

I would be happy to get your feedback on its usefulness for data science related research problems.

Thank you in advance!",datascience,https://www.reddit.com/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,2,1,0.67,"[Comment(id='k4ybzkb'), Comment(id='k4znxzi')]"
1787v23,sarmientoj24,,2023-10-15 04:51:18+00:00,False,,False,False,True,False,/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,Embed multi-dimensional data points for visualizing and inserting a new data in the plot,"Say, I have an N group of students. And I have their normalized test scores for 8 subjects from 0 to 1. 

I want to create a model that can put the data points into 2D plot showing which students are similar to each other. I will show the visualization of the data points.

Lastly, if someone gives their data point, I want to show them where they are in the plot, show which students are most similar to the new data point.

Which amongst PCA, tSNE, UMAP is suitable for this? Or are there other options like VAEs for tabular data?

The new data point is a test point and the N group of students are the training points.",datascience,https://www.reddit.com/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,0,1,1.0,[]
1786ci4,Talion07,,2023-10-15 03:18:31+00:00,False,,1697341666.0,False,True,False,/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,Does the big 4 tag really matter?,"So basically is a data analytics job (SQL and power bi viz) is better than a data scientist job (hands on python, model building and cloud) at a national company ?


Or just joining the big 4 in hopes of getting promoted to a job with more hands on coding is the right way to go?",datascience,https://www.reddit.com/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,12,1,0.54,"[Comment(id='k4xmrws'), Comment(id='k4y091z'), Comment(id='k4yam55'), Comment(id='k4y8c3u'), Comment(id='k4yq11n'), Comment(id='k5590se'), Comment(id='k4xnqif'), Comment(id='k4y5lxx'), Comment(id='k4xp7w7'), Comment(id='k51d3ym'), Comment(id='k4y5zc3'), Comment(id='k50o754')]"
177rzkj,Careful_Till8105,,2023-10-14 15:24:46+00:00,False,,False,False,True,False,/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,Why do we maximize likelihood of theta in logistic regression?,"Very new to the topic.  
I do not understand why we want to maximize the likelihood of the parameter theta: isn't the likelihood we care about just the likelihood of output y? What is the point of maximizing the parameter's likelihood?

Apologies if this is a silly question and thank you so much for your input",datascience,https://www.reddit.com/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,10,8,0.75,"[Comment(id='k4ute59'), Comment(id='k4vn4vo'), Comment(id='k4vmo9b'), Comment(id='k4vifyp'), Comment(id='k4wll6k'), Comment(id='k4yzyh3'), Comment(id='k4z61qe'), Comment(id='k4z1rn0'), Comment(id='k4z45pf'), Comment(id='k4z4g9c')]"
177k8pw,Much-Egg7130,,2023-10-14 07:44:38+00:00,False,,False,False,True,False,/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,Do you also often deal with problems that turn out to be some kind of constrained optimisation problems?,"I've been working in the role of a data scientist for about 3 years at a large corporate. My training is as a physicist. I'm often involved in early stage proofs-of-concept for different departments so we're often in exchange with ""innovation managers"" whose role is to find use cases for ""AI"", as they call it. As a result, I often get pitched ideas for new projects from those managers.  


Now, upon closer inspection, many of these problems involve, at their technical core, an optimisation problem, where an objective function has to be optimised in the presence of constraints. I find these problems intriguing but I usually feel overwhelmed tackling them, as I lack the training to deal with them and I feel there is no good tooling around to help me model them, not to mention choosing and tuning the solver, benchmarking and then finally bringing them in production. 

As a result (and also for other reasons), those projects usually don't get realised.

I wonder whether others here face the same challenge or whether this is particular to me and if there are others, how you deal with it. Thanks",datascience,https://www.reddit.com/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,16,28,0.95,"[Comment(id='k4tlt01'), Comment(id='k4torfx'), Comment(id='k4tpdkv'), Comment(id='k4ubq8k'), Comment(id='k4u7ulc'), Comment(id='k4tzf34'), Comment(id='k4vk000'), Comment(id='k4v4n6t'), Comment(id='k4vgvh7'), Comment(id='k4vqs5u'), Comment(id='k4uz641'), Comment(id='k4wqbg1'), Comment(id='k4yy1ox'), Comment(id='k500pyv'), Comment(id='k504tx5'), Comment(id='k50uotd')]"
1788zxi,604korupt,,2023-10-15 06:07:11+00:00,False,,False,False,True,False,/r/datascience/comments/1788zxi/in_1_year_of_data_science_in_college_what_do_you/,"In 1 year of data science in college, what do you guys learn? Let me know!",,datascience,https://www.reddit.com/r/datascience/comments/1788zxi/in_1_year_of_data_science_in_college_what_do_you/,8,0,0.2,"[Comment(id='k4yezla'), Comment(id='k4y7ad2'), Comment(id='k4yarmt'), Comment(id='k4yhi4u'), Comment(id='k51oig2'), Comment(id='k4y8sg8'), Comment(id='k5315q5'), Comment(id='k4ya3rk')]"
177ifms,Excellent_Cost170,,2023-10-14 05:38:42+00:00,False,,1697290127.0,False,True,False,/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,How to handle incompetent manager while looking for another job," 

I work in a large federal government agency, and regrettably, I have an extremely incompetent manager who spent many years working on dashboarding before being promoted to lead our team. My manager lacks any prior experience as a data scientist, data engineer, or machine learning engineer and is unwilling to learn in these areas. Given the nature of government employment, the likelihood of termination or layoffs is exceedingly low. The organization comprises both employees and contractors with the title of ""data scientists,"" but there's no clear plan on how to utilize their skills effectively. Additionally, our data governance and data quality processes are almost nonexistent.

There is a  significant fraud problem resulting in multimillion-dollar losses. One of the major challenges is that there are multiple definitions of fraud within the organization, making it nearly impossible to get straight answers when seeking guidance from supposed subject matter experts. Furthermore, various teams within the agency have different agendas when trying to address the fraud problem.

The CIO has recently directed us, likely influenced by management consultants, to use machine learning to solve the fraud problem. Nevertheless, it's apparent that there are many low-hanging fruit solutions, like process changes, that don't require machine learning and could significantly alleviate the issue.

Now, our manager is pressuring our team to build a machine learning model to supposedly save X millions of dollars. It appears that many people here are more interested in showcasing flashy tools and ideas to the directors and CIO, rather than delving into the details of the problem. Some of the other data scientists are demonstrating the use of complex machine learning techniques without truly understanding the problem statement or the models they are building. To make matters worse, we don't even have a clear, agreed-upon estimate of how much money we are losing.

In this chaotic environment, the manager wants us to build a model simply because someone in another team has done something similar. Our manager is focused on marketing and doesn't seem to care about the necessary details. I've suggested that we should invest time in understanding the data and conduct a feasibility study to determine if machine learning is an appropriate solution before committing to creating elaborate models. However, my manager either doesn't grasp the importance of understanding the data or simply doesn't care. Today he said I want each of you to build a model and compare results.

I know that the right thing to do is to leave the company or the team, and I am actively working on it. In the meantime, how can I handle this situation in the best possible way?",datascience,https://www.reddit.com/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,21,28,0.93,"[Comment(id='k4t7tm5'), Comment(id='k4tewzl'), Comment(id='k4tusld'), Comment(id='k4u6v0k'), Comment(id='k4th6fa'), Comment(id='k4u0bp9'), Comment(id='k4uey4a'), Comment(id='k4tufzu'), Comment(id='k4v97z7'), Comment(id='k4w95b7'), Comment(id='k4uvbti'), Comment(id='k4uad0w'), Comment(id='k4uxgk5'), Comment(id='k4ufpc4'), Comment(id='k4ub2nm'), Comment(id='k4vhpun'), Comment(id='k4v2eru'), Comment(id='k4v30b6'), Comment(id='k4uena2'), Comment(id='k4w1o3e'), Comment(id='k4ukrss')]"
1786ftu,CrazyProfessionalp,,2023-10-15 03:23:46+00:00,False,,False,False,True,False,/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,What are the best data science courses for curriculum in US?,"I’m planning to live in NY, and wanted to known the best online or live short courses , pos graduation courses and/or masters related with data science , and possibly with sustainability as well?",datascience,https://www.reddit.com/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,0,0,0.33,[]
1781xnk,Darktrader21,,2023-10-14 23:25:38+00:00,False,,False,False,True,False,/r/datascience/comments/1781xnk/need_help_in_my_senior_project/,Need help in my senior project,"I am graduating soon in a Bachelor in DS and I am starting early on my senior project, it is my first complete DS project I'll be doing so I am sure I would be facing concerns and struggles throughout this project, I have been taking taking some online courses apart from university so I have some basic knowledge to start with, and I am confident that I can get all the necessary data for this project and preprocess it to begin the analysis. 

I just need a data scientist with some decent or more experience that I can contact and use his/her help while pursuing my project (AKA a mentor) , I know most of you guys are busy most of the time, I am not asking to teach me how to crawl or to handle my project yourself, I will only be asking questions for clarifications and using your opinion and review on the progress of my project. 

Yes there exist chatgpt and of course I'll be using its aid, but it won't help me as much as a data scientist who had enough experience to handle real world projects to check the quality of my work. So I hope whoever of you guys is down to help to let me know in the comments, and thanks in advance :) 

The project is about a football team's probability to win the league, the data will be gathered based from the performance stats of the team in the first half of the season, and I'll analyze it to forecast the performance in the next half and calculate the chance of my selected team winning the league upon its rivals which of whom's data will also be considered throughout this project. 

Again thanks in advance for anyone that would be down to help me, I am patiently waiting for your response in the comment section of this post :) or you can contact me directly if you want and I would be very greatful. Peace ✌️",datascience,https://www.reddit.com/r/datascience/comments/1781xnk/need_help_in_my_senior_project/,0,0,0.5,[]
1778u49,linamagr,,2023-10-13 21:11:14+00:00,False,,False,False,True,False,/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,What are good questions to ask in interviews to validate the quality of your future boss?,"Not many people pay attention to this even though most people know that when you are interviewing for your next data scientist roles, you are also interviewing your next boss!

You've done a great job answering all the technical questions, but asking good questions are also critical but not much effort was put into this is what I've seen typically. 

So what are some good questions to ask your next prospect boss?

As a hiring manager myself, here are some of my favorite questions from my best candidates:

**To learn more about the day-to-day:**

* What's the day-to-day like for you (or for a data scientist on your team)?
* What percentage of your time (a DS on the team) is spent on coding?
* What percentage for other tasks? And what are those tasks?

**To learn more about ownership:**

* How are projects assigned across the team?
* How do team members collaborate?
* How is the scope of a project typically determined? 

**There are more you can ask to learn more about scope of projects and to learn more about room for adaptability:**

More detailed questions here:

[https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview](https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview)

What did you ask that got you great insights about your interviewer? 

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,32,93,0.97,"[Comment(id='k4rfsd1'), Comment(id='k4rfiov'), Comment(id='k4rpqb2'), Comment(id='k4rw43t'), Comment(id='k4smlkx'), Comment(id='k4sssbb'), Comment(id='k4ub0fn'), Comment(id='k4roqna'), Comment(id='k4sbobh'), Comment(id='k4wat9l'), Comment(id='k4tq3p5'), Comment(id='k4wj1w9'), Comment(id='k4rrhag'), Comment(id='k4relqv'), Comment(id='k4rrmga'), Comment(id='k4rgaiz'), Comment(id='k4rpran'), Comment(id='k4rx2gv'), Comment(id='k4rwhfo'), Comment(id='k4vsjir'), Comment(id='k4rg0m6'), Comment(id='k4uxdag'), Comment(id='k4spj82'), Comment(id='k4xntiy'), Comment(id='k4rt44w'), Comment(id='k4rzjlx'), Comment(id='k4u620e'), Comment(id='k4vwxu4'), Comment(id='k4rx86l'), Comment(id='k4rwtoa'), Comment(id='k4uxxmm')]"
177zdxe,DansePaladinDanse,,2023-10-14 21:20:34+00:00,False,,False,False,True,False,/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,Can I get a UK perspective on how important personal projects are for beginner data analyst roles?,"I have a degree in computer science and 1 year of experience as a data analyst done in the middle of my degree. Looking online a lot of the advice on standing out recommends doing personal projects. However, it also all seems very US-centric. Data analysts from the UK, how important do you feel personal projects are to get hired for beginner roles?",datascience,https://www.reddit.com/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,1,1,0.67,[Comment(id='k4xpwkj')]
177yjgm,SmokeSlurp,,2023-10-14 20:40:15+00:00,False,,False,False,True,False,/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,What is the best UI creator for DS projects?,"Im new to the Data science community and just started my first job as a robotics engineer. 

Im wondering how I can take my data science skills to the next level and so Ive made [this showcase](https://visualstudycode.com/stochastic-gradient-descent-for-robotics/) on stochastic gradient descent for robotics, as the first step in visualization and UI experience. Let me know your thoughts!",datascience,https://www.reddit.com/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,0,0,0.5,[]
177r3bk,saasthom,,2023-10-14 14:41:54+00:00,False,,False,False,True,False,/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,Data Science Scoping Questions (Looking for feedback from DS consultants),"Hi everyone! I work in the consulting arm of a data science software company. I scope data science projects with my clients regularly using the following questions. Would love some feedback if there is anything missing/I should be asking them in a different way:

Questions about client

* What is your project budget?
* Describe your familiarity with data science and data analytics
* Describe the nature of your business (feel free to include any links to your website)

Questions about the project

* What are the main objectives you want to achieve with this project? Try to be as specific as possible, using numbers
* Describe the current situation (without this project)
* Describe the envisioned situation if the project is a success (e.g. how will you use the project output?)
* Who will benefit from the most from this project? Who else will be impacted?

Questions about the data

* Describe the nature of your data in your own words. (prompts include how do you normally access this data? How is it normally used?)
* What data sources do you have for this project? Where do they come from?
* Are there any public data sources that might help?
* In what format is the data available (e.g., CSV, Excel, SQL Database)?
* Would you consider your data structured, semi-structured, or unstructured?
* How much data do you have (e.g. rows, records, or file size)
* Is it possible to collect more data? Would it be difficult to do so?
* Does your data need to be labeled? If so, what is the corresponding effort?
* How would you rate the quality of the available data? Are there any known issues? (missing values, conflicts, outliers, reliability)
* Please send over an example of your data if possible

Other questions

* What is your current technical set-up? Describe the tools you currently use may be relevant to the project
* Do you foresee any technical integration requirements?
* Is there any additional information or specific requirements that have not been covered? (cybersecurity, data privacy, ethical considerations)

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,0,3,0.81,[]
178744m,leaderdebordel,,2023-10-15 04:03:36+00:00,False,,False,False,True,False,/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,What’s the best AI tool for statistical coding?,"Is git copilot going to be a major asset for stats coding, in R for instance?",datascience,https://www.reddit.com/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,4,0,0.27,"[Comment(id='k4y8f7a'), Comment(id='k4zpt2l'), Comment(id='k4yk9kk')]"
177xuon,lovelylavenderchild,,2023-10-14 20:06:55+00:00,False,,False,False,True,False,/r/datascience/comments/177xuon/question_on_school_options/,Question on School options,"Hey there! 

I'm currently transferring to Indiana University Northwest in Spring 2024 from a community college for my Data Science degree and got an internship next summer. 

The thing is I also applied to UIC and got rejected with some weird reasoning but after talking to a faculty member, they were recommending I take a break and apply again in the summer to undecided and then transferring into the Data Science program.

I'm wondering if I should consider transferring to UIC instead and also if that hinders my internship for Summer 2024.",datascience,https://www.reddit.com/r/datascience/comments/177xuon/question_on_school_options/,3,1,0.67,"[Comment(id='k4xo8hj'), Comment(id='k4wzmrp'), Comment(id='k4xqj5z')]"
1775fq0,TheEnlightenedMan,,2023-10-13 18:34:28+00:00,False,,False,False,True,False,/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,"In your time working with data science at a corporation, what cool things did you pick up / learn that school didn't teach you?",Can't wait to read your comment!,datascience,https://www.reddit.com/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,64,107,0.99,"[Comment(id='k4r4t1p'), Comment(id='k4qy557'), Comment(id='k4rasof'), Comment(id='k4rcy4a'), Comment(id='k4r8ri9'), Comment(id='k4rd1tq'), Comment(id='k4rliaj'), Comment(id='k4qq0wg'), Comment(id='k4rhtnv'), Comment(id='k4rhqkl'), Comment(id='k4r7e31'), Comment(id='k4uovsr'), Comment(id='k4wealo'), Comment(id='k4rydfm'), Comment(id='k4us0sp'), Comment(id='k4tdpri'), Comment(id='k4s2x4v'), Comment(id='k4sw8yz'), Comment(id='k4s41d9'), Comment(id='k4weayr'), Comment(id='k4rdmos'), Comment(id='k4rsix1'), Comment(id='k4wpugb'), Comment(id='k4rv47g'), Comment(id='k4rlt7p'), Comment(id='k4rkh7j'), Comment(id='k4ucncu'), Comment(id='k4snkui'), Comment(id='k4wqk42'), Comment(id='k4ru3z1'), Comment(id='k4savjs'), Comment(id='k4r150u'), Comment(id='k4r9411'), Comment(id='k4wyxkt'), Comment(id='k4u37u0'), Comment(id='k4rsckg'), Comment(id='k4rvjfr'), Comment(id='k4tfrw2'), Comment(id='k4u3069'), Comment(id='k4sarao'), Comment(id='k4r55zd'), Comment(id='k4rdgbo'), Comment(id='k4yru8a'), Comment(id='k4sm858'), Comment(id='k4t118m'), Comment(id='k4td6o8'), Comment(id='k4timyt'), Comment(id='k4ucduv'), Comment(id='k5z2sl4'), Comment(id='k4rtn96'), Comment(id='k4u3z43'), Comment(id='k4vafmv'), Comment(id='k5z453e'), Comment(id='k4viak2'), Comment(id='k5acz55'), Comment(id='k5z7z9n'), Comment(id='k5afg44'), Comment(id='k605yaz'), Comment(id='k5zie7c'), Comment(id='k5amhlb'), Comment(id='k5zq96p'), Comment(id='k5an4rc'), Comment(id='k5zvtn4')]"
177479m,VodkaRain,,2023-10-13 17:38:39+00:00,False,,False,False,True,False,/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,It's been two months since I was laid off as a DS. Any advice on how to deal with current market.,"Two months ago, I was laid off from my role as a data scientist after 2 years. It was ""reduction in force"" and my role was affected. 

Some background:

* Previous Role: Data Scientist 1
* 2 yrs of xp, master's in statistics
* Had a big tech company as long term client at previous role (13 months)
* I was in top 10% of performers (98% billable hours and internal recognition for innovation)
* Was confirmed for promotion.

It took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I'm laid off. What should I do about this market? I barely see any positions open for someone like my self.",datascience,https://www.reddit.com/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,84,124,0.92,"[Comment(id='k4qhkaa'), Comment(id='k4qj6lo'), Comment(id='k4qqr07'), Comment(id='k4qx50t'), Comment(id='k4qvjze'), Comment(id='k4qs8tk'), Comment(id='k4ryzjw'), Comment(id='k4rs89d'), Comment(id='k4sawbd'), Comment(id='k4s57kb'), Comment(id='k4rh723'), Comment(id='k4sodwh'), Comment(id='k4r67yr'), Comment(id='k4r0u5t'), Comment(id='k4rvu6q'), Comment(id='k4t8h96'), Comment(id='k4tpwwm'), Comment(id='k4tvxbt'), Comment(id='k4u5idv'), Comment(id='k4uoucs'), Comment(id='k4uqyao'), Comment(id='k4vizd9'), Comment(id='k4wrfaa'), Comment(id='k4ygmhf'), Comment(id='k4zrqwl'), Comment(id='k4qmhnp'), Comment(id='k4r3br9'), Comment(id='k4v59ch'), Comment(id='k4qvf1l'), Comment(id='k4rj2rf'), Comment(id='k4seuhi'), Comment(id='k4v7mx2'), Comment(id='k4rax06'), Comment(id='k4r1ia8'), Comment(id='k4urdh8'), Comment(id='k4sbrgq'), Comment(id='k4s70bh'), Comment(id='k4svpq5'), Comment(id='k4rhwcq'), Comment(id='k4rx8ts'), Comment(id='k4ugu0f'), Comment(id='k4rthxu'), Comment(id='k4qudeq'), Comment(id='k4r75o5'), Comment(id='k4r5e0n'), Comment(id='k4rrxv3'), Comment(id='k4tjtux'), Comment(id='k4uqzts'), Comment(id='k4saee8'), Comment(id='k4t4o5l'), Comment(id='k4s03xt'), Comment(id='k4vciho'), Comment(id='k4s2t8d'), Comment(id='k4stdta'), Comment(id='k4qv0rg'), Comment(id='k4reren'), Comment(id='k4soque'), Comment(id='k4rbear'), Comment(id='k4sp1gb'), Comment(id='k4rboda'), Comment(id='k4syy0z'), Comment(id='k4tqqcb'), Comment(id='k4wnvwv'), Comment(id='k4rtndc'), Comment(id='k4s1uoj'), Comment(id='k4s9sto'), Comment(id='k4tepte'), Comment(id='k4u3sbj'), Comment(id='k4splst'), Comment(id='k4roqmw'), Comment(id='k4stxj1'), Comment(id='k4tfjy6'), Comment(id='k4v02mz'), Comment(id='k4uji45'), Comment(id='k4s27u3'), Comment(id='k4s9wvm'), Comment(id='k4sbjtv'), Comment(id='k4rptdq'), Comment(id='k4su23z'), Comment(id='k4usbm2'), Comment(id='k4tzorn'), Comment(id='k4xhl0h'), Comment(id='k4znd0i'), Comment(id='k4sbwko'), Comment(id='k4u8ken')]"
177q65k,IcaroRibeiro,,2023-10-14 13:58:17+00:00,False,,1697292201.0,False,True,False,/r/datascience/comments/177q65k/do_i_need_more_statistics/,Do I need more statistics?,"Hello everyone,

&#x200B;

I'm relatively new to the field of Data Science, with approximately 6 months of experience. Prior to this role, I worked as a Machine Learning Engineer for a year and a half.

In my current position, I spend a significant portion of my time conducting data analysis, applying basic statistical techniques (hypothesis testing, regression analysis, etc), and developing standard banking models (so far, I've worked in churn rate prediction, client clustering, and currently studying to help building a recommendation system)

I'm currently pursuing a Master's degree in Computer Science, with a research focus on weather forecasting. This research involves the use of time series analysis and machine learning. As we progress in our research, we are also delving into deep learning models, the goal is to build state of art models.

My academic background is in computer science. In both bachelor's and master's I've completed classes in basic linear algebra, three levels of calculus (up to Multivariate Calculus and First Order Differential Equations), discrete mathematics, two statistics courses, one time series analysis course, and several classes focused on machine learning algorithms and artificial intelligence.

While I generally have a good understanding of the mathematical principles behind machine learning models, there are certain areas where I struggle. For instance, I've never fully comprehended why the kernel trick is effective in SVMs (got the intuition, but not the maths)

When it comes to statistics, I feel that my knowledge is lacking. I can effectively work with machine learning frameworks, but there are specific statistical topics where my knowledge is either superficial or non-existent. These include:

&#x200B;

* Post hoc analysis
* Survival analysis
* Multivariate statistics, such as PCA, MANOVA, and Factor analysis
* Markov Processes

Given my current role and academic pursuits, I'm wondering if it's essential to address these knowledge gaps immediately or if it would be more practical to focus on completing my Master's degree first.

I would greatly appreciate any guidance on how to begin studying these statistical concepts effectively.",datascience,https://www.reddit.com/r/datascience/comments/177q65k/do_i_need_more_statistics/,3,2,0.76,"[Comment(id='k4um0p4'), Comment(id='k4v3ih7'), Comment(id='k4un9g5')]"
177cfpy,Dataman-Calgary,,2023-10-13 23:57:43+00:00,False,,False,False,True,False,/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,Hourly salary Data Scientist Canada,"I got contacted by a recruiter today for an immediate hire for an ""Intermediate level data scientist"" at an energy company in Calgary. This would be a contract position for one year, full-time, hybrid (2 days from home per week), and required 5 years of experience.

The salary was 46.5 CAD/hour, no benefits and required you as a contractor to be incorporated.

I have a PhD, a completed post doctoral position, over 3 years of work experience as an independent contractor in a variety of industries as a data scientist and was honestly surprised by the low hourly rate. The majority of my clients have not been from the energy sector though, so maybe this is why?

After mentioning that this was below the hourly rate that I would consider a position, comparing this to a base salary of a full time employee coming with benefits such as healthcare, pension plan, paid time off, etc, while also not requiring the overhead of costs you have as a incorporated business in regards to bookkeeping, invoicing, taxes, etc, the rate was increased to 47 CAD/hour. 

I thought I'd throw it on here to keep these kind of salaries transparent and see if other Calgary/Canada-based data scientists have had similar experiences in this job market.",datascience,https://www.reddit.com/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,14,25,0.86,"[Comment(id='k4sggdd'), Comment(id='k4s47c7'), Comment(id='k4s3ijd'), Comment(id='k4tvhre'), Comment(id='k4ucj3c'), Comment(id='k4st4bw'), Comment(id='k4u695u'), Comment(id='k4uf8vb'), Comment(id='k4wjrjr'), Comment(id='k4s4wmg'), Comment(id='k4s4sq8'), Comment(id='k4w371l'), Comment(id='k4v31bx'), Comment(id='k4s82k0')]"
177qw2v,fouried96,,2023-10-14 14:32:12+00:00,False,,False,False,True,False,/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,How much stock would you put in Andrew Ng's ML/DL course?,"Hi! I have a Bsc (Honours) in Applied Mathematics, and I have done various courses on Udemy on ML and DL by SuperDataScience. I have also done some self work on Kaggle.
I am currently a Robotics Process Automatiom (RPA) developer. I'd love to move into the DS/ML/DL/AI space. I do of course use some AI tools within my automation solutions. I miss doing the Mathematics though. I really loved studying it.

Anyways, it's been a while since I've done any studying or self-work in the AI space, and I was wondering what your thoughts on the renowned Andrew Ng Deep Learning course are? I know I'd really enjoy doing it, but how much would it help me in getting closer to a job in the AI space?

Note: I haven't done any mathematics for quite a few years, as a I graduated end of 2018, so I would also need to spend sometime relearning some of the work I learnt in my degree. I also do not want to go into academia, despite my love of research, because it often involves lecturing (which I dislike) and it will generally not pay as well - I want to have enough money to live a comfortable life and travel the world.

Thanks",datascience,https://www.reddit.com/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,9,1,0.53,"[Comment(id='k4ulrut'), Comment(id='k4vatrc'), Comment(id='k4x8r1n'), Comment(id='k4vkazj'), Comment(id='k4uoalo'), Comment(id='k4vjscx'), Comment(id='k4z390w'), Comment(id='k4up8ph'), Comment(id='k4zx5c8')]"
177q2t2,Final_Teach_5838,,2023-10-14 13:53:54+00:00,False,,False,False,True,False,/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,Choosing the Right Academic Path for Job Security and Career Growth in Europe,"After spending considerable time researching on the Data Science (DS) field, I've noticed two significant challenges: 

1. The difficulty of breaking into DS as a fresher 
2. The necessity for a specialized niche in a particular domain, such as healthcare or business, which often requires prior field experience or a related bachelor's degree.

I'm a final year bachelor's in Technology student (specialization-Information Technology ) and possess average coding skill. My aspirations involve pursuing higher education and professional opportunities in Europe, particularly in German universities.

Despite some institutions prioritizing revenue generation and offering below average DS programs(as repeatedly mentioned in this sub), low cost German public universities offers numerous DS programs taught in English, welcoming international students. Personally, I'm drawn to the profound impact DS can have on decision-making processes (specifically policy making), which makes it a very rewarding field.

I'm at a crossroads between pursuing a Master's in Computer Science (CS) with a DS track or opting for a specialized Data Science degree. Which academic path would provide more job security and a stronger foothold in the European job market for a background like mine?

There are some courses that have intersection of two disciplines like policy making and DS. Will those courses limit me to certain domain and thus affect my chances of getting jobs? or Will the specialization in a field actually be more beneficial?

Furthermore, I'm curious if I can smoothly transition into DS roles after gaining several years of experience working with other technologies in the IT sector.

Thank you in advance for your time and guidance!",datascience,https://www.reddit.com/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,5,1,0.67,"[Comment(id='k4ugjrn'), Comment(id='k4wlnp8'), Comment(id='k4ui7ng'), Comment(id='k55vzps'), Comment(id='k566mki')]"
177lhhw,malirkan,,2023-10-14 09:15:59+00:00,False,,False,False,True,False,/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,"What were the worst misconceptions/requirements of senior management in data science projects in connection with web applications (lead generation & churn, content generation, data driven marketing, etc.)?"," TL;DR: **Biggest fails and your most loved data science solutions** in **web related applications**, which you have experienced **in your data science career**.

*(Similar posts were previously removed for unclear reasons, so I have reworded the post. Please let me be clear: this is not a homework exercise, nor is it breaking any other rule in my opinion! My last attempt...)*

I  am just curious in your personal data science experience of common web  applications like e-commerce, lead generation, web marketing and so on.

Upper   management often wants solutions or applications which have a positive  imapct in selling products, gaining more customers or at least improve  existing products and services which can be used in marketing. And you  know, sometimes it's all about slapping the ""AI"" label on products.

What  were the worst misconceptions/requirements of senior management?  In  contrast: What unexpectedly  worked well? I.e. Data may be very limited  on training due to data  protection rules, but still lead to ""good""  models which are production  ready.

In  my experience it was not  a big deal to produce a working model. But I  failed to deploy or  integrate the model into an existing solution. The  guys which were  responsible to implement the model api failed to  present the results in a  nice way or the UX was just terrible.

Another  fail requirement: ""generate automatic A/B landing pages in a web  application"". So the requirement was to automatically generate different  versions of landing pages based on the visitor flows (or origin  parameters: organic vs direct hits). It would be technically possible,  but imho at least 2000h of work ot get good results.

I look forward to an exciting exchange of experiences!",datascience,https://www.reddit.com/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,2,2,0.6,"[Comment(id='k4uuejs'), Comment(id='k4y8qvs')]"
177ffq9,CatalystNZ,,2023-10-14 02:35:44+00:00,False,,False,False,True,False,/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,"For binary classification, where the focus is to avoid FP, can you help with which metrics to use?","I hope it's ok for me to ask questions here, please point me elsewhere if that's not the case.

I have a binary classification model for identifying profitable trades, and I have just learned how AUC works (which took my smooth brain a lot longer than perhaps it would for you fine folk).

Anyway, would someone mind providing some pointers about which Classification metrics (Accuracy, AUC are the ones I already know) would be beneficial to understand, when comparing and understanding models? Or is AUC the de-facto standard?

I'm reading books on this topic, but finding that it can be difficult to follow.

Thanks",datascience,https://www.reddit.com/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,8,2,0.67,"[Comment(id='k4sn9hk'), Comment(id='k4ss2zr'), Comment(id='k4t53bz'), Comment(id='k4t5vxz'), Comment(id='k4taghd'), Comment(id='k4told1'), Comment(id='k4ts3mc'), Comment(id='k4twp2r')]"
177dfyv,Dr_Rhombus,,2023-10-14 00:49:17+00:00,False,,False,False,True,False,/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,"Customer Growth Accounting (churn, resurrections, etc) framework","Does anyone have a good resource to share that lays out customer growth accounting framework (churn, resurrections, etc), and how it's used?",datascience,https://www.reddit.com/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,0,2,1.0,[]
1778xvq,hownottopetacat,,2023-10-13 21:15:48+00:00,False,,False,False,True,False,/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,How does your team organize ideas?,"While I understand that some industries have a pretty shallow pool of ideas, what do those with a lot of ideas use to organize them into a way that allows project tracking and or understanding relationships between them?",datascience,https://www.reddit.com/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,3,3,1.0,"[Comment(id='k4rwjbr'), Comment(id='k4vb0jv'), Comment(id='k51o4ea')]"
177b4po,RaccoonFew5715,,2023-10-13 22:53:29+00:00,False,,False,False,True,False,/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,Demand forecasting FMCG company,"Hello guys,  im kinda new in the data science area,  i was wondering what might be the best approach to tacle a demand forecasting  per sku project for the next 6 months in an fmcg distribution company , i have the sales per customer per sku per salesman for the last 2 years ( daily) but i prefer to give more weight to the last year data since its very different fot the previous one.

Ps: the customer data is not always accurate since the salesman can sometimes close a sale with partner A and pass it as its customer B , so the sale quantity per sku is always correct, the customer not always (75% accurate)

Thaanks in advance!!",datascience,https://www.reddit.com/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,19,2,0.75,"[Comment(id='k4rznm9'), Comment(id='k4tqbvg'), Comment(id='k4s9ea5'), Comment(id='k4sblgh'), Comment(id='k4tuzps'), Comment(id='k4tlejk'), Comment(id='k4tjwzs'), Comment(id='k4tyc0t'), Comment(id='k4uugx5'), Comment(id='k4u438m'), Comment(id='k4uw326'), Comment(id='k4uvapt'), Comment(id='k4uip70'), Comment(id='k4uwlza'), Comment(id='k4uw14w'), Comment(id='k4uizjd'), Comment(id='k4uxckw'), Comment(id='k4uxr67'), Comment(id='k4uy3aq')]"
176nzqe,Smart_Donut_9558,,2023-10-13 02:13:16+00:00,False,,False,False,True,False,/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,"Got hit with a layoff today but they offered to shop me around internally, any advice?","I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a ""reorganization"" by a higher up and that my role had been eliminated.

Anyways, they offered to help shop me around to some other internal teams and I'll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I'd really appreciate it.

Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there's no training period, I'm already familiar with all the datasets and industry. I'm going to spend tomorrow trying to summarize all the work I've done at the company since I got hired.

Some other key details below:

- Was told I was rehire eligible. They specifically said that severance wouldn't be impacted if I boomeranged unless I switched teams before final date (1 month).
- Worked for over a year and have 2.5 years of experience in data science.
- Probably was on the bottom half of performers, but I wasn't the worst. I was the most recent hire though. My boss's boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.
- The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.

I'm going to keep the ranting to a minimum because this post is pretty identifiable, but I'm honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that's life but god damn.",datascience,https://www.reddit.com/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,45,85,0.91,"[Comment(id='k4njdny'), Comment(id='k4nkm07'), Comment(id='k4nl72h'), Comment(id='k4nmjdv'), Comment(id='k4nn7x8'), Comment(id='k4nwtjh'), Comment(id='k4o2t6d'), Comment(id='k4nslof'), Comment(id='k4oksx9'), Comment(id='k4oviw9'), Comment(id='k4papv0'), Comment(id='k4phhz7'), Comment(id='k4nz96i'), Comment(id='k4od8e8'), Comment(id='k4og91k'), Comment(id='k4ow3gp'), Comment(id='k4pizfa'), Comment(id='k4pw2bz'), Comment(id='k4qbbzd'), Comment(id='k4qku9f'), Comment(id='k4qqm8n'), Comment(id='k4ribso'), Comment(id='k4s9v3p'), Comment(id='k4usoks'), Comment(id='k4nkdso'), Comment(id='k4nm3ca'), Comment(id='k4oos8d'), Comment(id='k4ol3i1'), Comment(id='k4ri5mt'), Comment(id='k4w5rbr'), Comment(id='k4nn5hk'), Comment(id='k4nn3yw'), Comment(id='k4nvdt9'), Comment(id='k4q77ye'), Comment(id='k4qg84e'), Comment(id='k4pf6ql'), Comment(id='k4pm5eq'), Comment(id='k4rmurr'), Comment(id='k4pf2k5'), Comment(id='k4pr2r6'), Comment(id='k4rn7cm'), Comment(id='k4q88hd'), Comment(id='k4roa1l'), Comment(id='k4qc1in'), Comment(id='k4rpp6y')]"
1771460,Born_Buy7037,,2023-10-13 15:17:53+00:00,False,,False,False,True,False,/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,What are the best practices for interviewing data science candidates?,My experience as a candidate wasn't always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate's technical aptitude and work ethic on the job.,datascience,https://www.reddit.com/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,6,7,0.77,"[Comment(id='k4py03o'), Comment(id='k4pyade'), Comment(id='k4rel25'), Comment(id='k4st7tr'), Comment(id='k4smwq7'), Comment(id='k54dwz6')]"
177dgos,Dr_Rhombus,,2023-10-14 00:50:20+00:00,False,,False,False,True,False,/r/datascience/comments/177dgos/holdout_experiments/,Holdout Experiments,Does anyone have a good resource to share on long term holdout experiments and what they're used for?,datascience,https://www.reddit.com/r/datascience/comments/177dgos/holdout_experiments/,0,1,1.0,[]
1778n6i,elffuostnevel,,2023-10-13 21:02:47+00:00,False,,False,False,True,False,/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/,Book recommendations about Descriptive Statistics for an Economics freshman.,"Good day to everyone.  I started taking a course called ""Descriptive Statistics"" at university and I want to improve myself outside of class.  The professor recommended Cleff's ""Exploratory Data Analysis"" as a reference book, but I would also like to hear your opinions.  Thank you.",datascience,https://www.reddit.com/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/,0,2,0.75,[]
1773x9b,RebeccaMayy,,2023-10-13 17:25:32+00:00,False,,False,False,True,False,/r/datascience/comments/1773x9b/i_want_to_improve_more/,I want to improve more!,"Hi everyone,



First time posting here so not sure this is where it belongs.



I do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I've not had much experience in SQL or Power BI, neither of which the internship need either.



I wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?



Nothing to publish, solely extra academic learning I can play with. Thanks !",datascience,https://www.reddit.com/r/datascience/comments/1773x9b/i_want_to_improve_more/,1,3,1.0,[Comment(id='k4r7kn5')]
176zysn,rubiesordiamonds,,2023-10-13 14:25:23+00:00,False,,False,False,False,False,/r/datascience/comments/176zysn/james_lamb_light_gbm_on_getting_into_open_source/,James Lamb (Light GBM) on getting into open source from a data science background,,datascience,https://open.substack.com/pub/onceamaintainer/p/once-a-maintainer-james-lamb?r=2773u5&utm_campaign=post&utm_medium=web,0,4,0.84,[]
1772in6,ResearchShort4056,,2023-10-13 16:20:34+00:00,False,,False,False,True,False,/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,Fraud Detection Machine learning project,"https://preview.redd.it/ha6kw13ewztb1.png?width=966&format=png&auto=webp&s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,1,2,0.75,[Comment(id='k4rt3mg')]
17666j9,Excellent_Cost170,,2023-10-12 12:48:01+00:00,False,,False,False,True,False,/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,How ballsy do you have to be to take on the role of Senior Data Scientist at both McDonald's and Burger King simultaneously (remote)," If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? ",datascience,https://www.reddit.com/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,124,302,0.88,"[Comment(id='k4k0f5j'), Comment(id='k4k3ve5'), Comment(id='k4k31ot'), Comment(id='k4k1dmn'), Comment(id='k4k5evi'), Comment(id='k4k7qnu'), Comment(id='k4k57r2'), Comment(id='k4kba4a'), Comment(id='k4kfqfh'), Comment(id='k4kdpiy'), Comment(id='k4kxunf'), Comment(id='k4kinq0'), Comment(id='k4l0lcz'), Comment(id='k4kb4zf'), Comment(id='k4kax1i'), Comment(id='k4k30i1'), Comment(id='k4kqudx'), Comment(id='k4lhcsa'), Comment(id='k4n7vqo'), Comment(id='k4l9l4e'), Comment(id='k4lel3h'), Comment(id='k4ll59g'), Comment(id='k4raz0f'), Comment(id='k4kb1dc'), Comment(id='k4ks3fa'), Comment(id='k4k47n3'), Comment(id='k4kewct'), Comment(id='k4l7lns'), Comment(id='k4k62zl'), Comment(id='k4k9tyg'), Comment(id='k4kbk9h'), Comment(id='k4kjgym'), Comment(id='k4kjm7l'), Comment(id='k4klcjv'), Comment(id='k4kn5su'), Comment(id='k4knqod'), Comment(id='k4kwz4k'), Comment(id='k4l0dk3'), Comment(id='k4l0s81'), Comment(id='k4l6ei8'), Comment(id='k4l9moc'), Comment(id='k4lkgr2'), Comment(id='k4m1l47'), Comment(id='k4m1z0r'), Comment(id='k4m4cbu'), Comment(id='k4mbzzb'), Comment(id='k4mcaz6'), Comment(id='k4mew4o'), Comment(id='k4mf9xh'), Comment(id='k4miehh'), Comment(id='k4n5ck3'), Comment(id='k4n82ib'), Comment(id='k4nc7pl'), Comment(id='k4nm2vm'), Comment(id='k4o7r2w'), Comment(id='k4pxdrw'), Comment(id='k4pzcku'), Comment(id='k4qh5c6'), Comment(id='k4sgvez'), Comment(id='k4x1n28'), Comment(id='k4yiuns'), Comment(id='k4k0mra'), Comment(id='k4leomw'), Comment(id='k4ktwyc'), Comment(id='k4kfmqj'), Comment(id='k4kz21b'), Comment(id='k4km0ly'), Comment(id='k4k2s2h'), Comment(id='k4k6zdf'), Comment(id='k4kaj3y'), Comment(id='k4kl8f7'), Comment(id='k4knqwz'), Comment(id='k4ll1i3'), Comment(id='k4kdaod'), Comment(id='k4lxc29'), Comment(id='k4l8e1u'), Comment(id='k4kmxmn'), Comment(id='k4nzn9i'), Comment(id='k4llbj1'), Comment(id='k4m0tog'), Comment(id='k4m2u0n'), Comment(id='k4ktbla'), Comment(id='k4k12pj'), Comment(id='k4l3jfe'), Comment(id='k4wib49'), Comment(id='k4l6v4d'), Comment(id='k4lmpas'), Comment(id='k4lsozz'), Comment(id='k4pzihu'), Comment(id='k4kjgig'), Comment(id='k4kbx3z'), Comment(id='k4krv2h'), Comment(id='k4kt2no'), Comment(id='k4l3gsu'), Comment(id='k4n9n3n'), Comment(id='k4l6mm9'), Comment(id='k4ka7fb'), Comment(id='k4lx6ur'), Comment(id='k4mxaje'), Comment(id='k4qqdcg'), Comment(id='k4qv36o'), Comment(id='k4l7lie'), Comment(id='k4kjlg5'), Comment(id='k4m29l6'), Comment(id='k4l3wnz'), Comment(id='k4m770l'), Comment(id='k4l7u2t'), Comment(id='k4kw6a0'), Comment(id='k4l3u2c'), Comment(id='k4l8jsh'), Comment(id='k4lbexq'), Comment(id='k4liam0'), Comment(id='k4n4p91'), Comment(id='k4n70la'), Comment(id='k4o2d1i'), Comment(id='k4n4tll'), Comment(id='k4sirg3'), Comment(id='k4mkag3'), Comment(id='k4lb47k'), Comment(id='k4m8mun'), Comment(id='k4lqwy9'), Comment(id='k4nc1m1'), Comment(id='k4ny6hs'), Comment(id='k4ldlas'), Comment(id='k4lgduv')]"
1775rtq,Aggravating_Sand352,,2023-10-13 18:49:21+00:00,False,,False,False,True,False,/r/datascience/comments/1775rtq/guidance_on_language_model/,Guidance on Language Model,I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I'd preferably like to use an offline language model or one that would be safe to put in our code,datascience,https://www.reddit.com/r/datascience/comments/1775rtq/guidance_on_language_model/,5,0,0.33,"[Comment(id='k4qvrqk'), Comment(id='k4qudyt'), Comment(id='k4s384b'), Comment(id='k4t5ci6'), Comment(id='k54em1e')]"
1775qrn,TechSavvyGal,,2023-10-13 18:48:01+00:00,False,,False,False,True,False,/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,Fetching User Details for Triggered AWS Glue Job,"I'm implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as ""created by"" and ""last modified by."" For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I'm aware of CloudTrail's Lookup Events API, but I'm looking for an alternative approach to retrieve this information from the server-side without using a client library.",datascience,https://www.reddit.com/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,0,1,1.0,[]
176yuks,lfelipecl,,2023-10-13 13:32:31+00:00,False,,1697204435.0,False,True,False,/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,Guidance to analyze data reliability and variables related,"Hello guys and girls,

I'm a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.

All this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.

But to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. 

So, I have this database with data not audited and data audited with it's outcomes: data needed to be corrected and don't.

We want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc

So I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it's not representative as it's not a random sample, so how to look to it? 

Obs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.

Thanks in advance.",datascience,https://www.reddit.com/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,1,2,1.0,[Comment(id='k4sl9md')]
17770fv,Kairo1004,,2023-10-13 19:47:06+00:00,False,,False,False,False,False,/r/datascience/comments/17770fv/how_to_perform_monte_carlo_simulation_on_the/,How to Perform Monte Carlo Simulation on the Stock Market,,datascience,https://www.youtube.com/watch?v=O3K4nrXyqwc,0,0,0.38,[]
176de18,OutcomeSerious,,2023-10-12 18:07:47+00:00,False,,False,False,True,False,/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,What is a personal side project that you have worked on that has increased your efficiency or has saved you money?,"This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.


For example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it's likely the cheapest price in the interval that I should place the order.


I'm currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don't usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!",datascience,https://www.reddit.com/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,38,55,0.93,"[Comment(id='k4miiry'), Comment(id='k4lh080'), Comment(id='k4m78jg'), Comment(id='k4oaoye'), Comment(id='k4lluil'), Comment(id='k4lvvv9'), Comment(id='k4mxq8i'), Comment(id='k4m5m3z'), Comment(id='k4mqzbt'), Comment(id='k4pjpno'), Comment(id='k4nrhpd'), Comment(id='k4ptabo'), Comment(id='k4q8pa6'), Comment(id='k4rviat'), Comment(id='k4pqruy'), Comment(id='k4pwoqq'), Comment(id='k4ojbyi'), Comment(id='k4ojzn8'), Comment(id='k4mf2ti'), Comment(id='k4psoaf'), Comment(id='k4n9rfm'), Comment(id='k4qg3q7'), Comment(id='k4qfyhx'), Comment(id='k6ls2ag'), Comment(id='k4ov9f6'), Comment(id='k4mnkow'), Comment(id='k4mzijx'), Comment(id='k4pl4ia'), Comment(id='k4revky'), Comment(id='k4q4dgq'), Comment(id='k4mwcab'), Comment(id='k4n1zjw'), Comment(id='k4phuq6'), Comment(id='k4r1ezd'), Comment(id='k4qa4sy'), Comment(id='k4mxa7w'), Comment(id='k4pjr0j'), Comment(id='k4qb9dy')]"
1771jsh,Purple_Bite_9579,,2023-10-13 15:37:09+00:00,False,,False,False,True,False,/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,Traffic Data Source for Senior Project,"Hi All, 

I am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).

I have store sales & customer but need the traffic data. 

How would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).

I tried government data and websites and the information is available but not to the public and it isn't quite the information needed. 

Welcoming all suggestions, thanks everyone!",datascience,https://www.reddit.com/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,1,1,1.0,[Comment(id='k4qjuob')]
176tcip,MLwithMe1617,,2023-10-13 07:44:36+00:00,False,,False,False,False,False,/r/datascience/comments/176tcip/dive_into_a_comprehensive_guide_on_multilinear/,"📊💡 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! 📈🧪",,datascience,https://www.youtube.com/watch?v=SHa-58-n6ew,0,4,1.0,[]
1777d0q,Zestyclose-Ad-7154,,2023-10-13 20:03:56+00:00,False,,False,False,True,False,/r/datascience/comments/1777d0q/ocean_protocol/,Ocean protocol,What do you think guys -> [https://twitter.com/Cesar\_Ges/status/1712541730053173280](https://twitter.com/Cesar_Ges/status/1712541730053173280),datascience,https://www.reddit.com/r/datascience/comments/1777d0q/ocean_protocol/,0,0,0.33,[]
1763k33,Exotic_Avocado6164,,2023-10-12 10:18:44+00:00,False,,False,False,True,False,/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/,"If you were starting over again, How would you go about getting a Data Science job?",,datascience,https://www.reddit.com/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/,66,104,0.93,"[Comment(id='k4jx3ao'), Comment(id='k4kdy97'), Comment(id='k4kgdea'), Comment(id='k4jlygj'), Comment(id='k4jks3q'), Comment(id='k4k0dg3'), Comment(id='k4k9kw2'), Comment(id='k4l6kq7'), Comment(id='k4k5ujf'), Comment(id='k4jsesq'), Comment(id='k4k63cc'), Comment(id='k4ks9rs'), Comment(id='k4k7907'), Comment(id='k4my79v'), Comment(id='k55jrbq'), Comment(id='k4k4obv'), Comment(id='k4o9d1k'), Comment(id='k4kri56'), Comment(id='k4ma9ff'), Comment(id='k4n2lsh'), Comment(id='k4n3dpy'), Comment(id='k4nd9d1'), Comment(id='k4ns7td'), Comment(id='k4o4rdn'), Comment(id='k4p024a'), Comment(id='k4su34r'), Comment(id='k52w1dw'), Comment(id='k4m6e8m'), Comment(id='k4kyil9'), Comment(id='k4mlvlt'), Comment(id='k4wpb8l'), Comment(id='k4mjja4'), Comment(id='k4nnkgr'), Comment(id='k4oog3q'), Comment(id='k4qq54j'), Comment(id='k4que6s'), Comment(id='k4pu1xl'), Comment(id='k4k75vr'), Comment(id='k4kpy9g'), Comment(id='k4k75n4'), Comment(id='k4k6tq1'), Comment(id='k4jnm7g'), Comment(id='k4k73lo'), Comment(id='k4k2fbe'), Comment(id='k4kvlaf'), Comment(id='k4n2mu2'), Comment(id='k4ougsu'), Comment(id='k4kiyph'), Comment(id='k4krjt1'), Comment(id='k4lz4pi'), Comment(id='k4lzzqq'), Comment(id='k4jnv23'), Comment(id='k4jnz3c'), Comment(id='k4k712b'), Comment(id='k4kq2q5'), Comment(id='k4lhw8l'), Comment(id='k4l3zjw'), Comment(id='k4k7a9n'), Comment(id='k4k423i'), Comment(id='k4l35sd'), Comment(id='k4kfug4'), Comment(id='k4kgv19'), Comment(id='k4l9bcj'), Comment(id='k4l9oez'), Comment(id='k4lamqy'), Comment(id='k4lh1av')]"
176t8at,Additional_Guide5439,,2023-10-13 07:35:42+00:00,False,,False,False,True,False,/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,Seeking Recommendations for Multivariate Time Series Analysis Resources with a Focus on Economics/Finance and R Applications,"Hello everyone,

I recently completed **Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition**. It's a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I'm looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any **books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)**? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?",datascience,https://www.reddit.com/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,3,2,1.0,"[Comment(id='k4t70qu'), Comment(id='k4tmvc8'), Comment(id='k4t7frt')]"
1767l3b,LossFirst2657,,2023-10-12 13:55:57+00:00,False,,False,False,True,False,/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/,How much of an effect does this job market have on people who were Data Scientists for a solid 3-5 years?,Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.,datascience,https://www.reddit.com/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/,25,49,0.91,"[Comment(id='k4kegb1'), Comment(id='k4kchvy'), Comment(id='k4kwmaw'), Comment(id='k4kjbyj'), Comment(id='k4kqvkc'), Comment(id='k4ln1vt'), Comment(id='k4k9t0t'), Comment(id='k4ks6f4'), Comment(id='k4ndsaz'), Comment(id='k4n3w40'), Comment(id='k4qtfbi'), Comment(id='k4khilt'), Comment(id='k4n2g4g'), Comment(id='k4kql53'), Comment(id='k4l0f4f'), Comment(id='k4mjswr'), Comment(id='k4m40om'), Comment(id='k4kp0hp'), Comment(id='k4ngj42'), Comment(id='k4kct8y'), Comment(id='k4ldvj2'), Comment(id='k4mhc1j'), Comment(id='k4kr0x3'), Comment(id='k4o1ldr'), Comment(id='k4llm1w')]"
176uhmx,FrancisGrant1,,2023-10-13 09:08:14+00:00,False,,False,False,True,False,/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,Guides that explore statistical theory and concepts through analysis in R using tidyverse,"During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field's ""Discovering Statistics Using R"" book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.

  
Several years later, I've left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field's ""Discovering Statistics Using R"", which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.

  
As a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don't know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,1,1,0.6,[Comment(id='k4pceql')]
176tcyw,sarafpiyush98,,2023-10-13 07:45:33+00:00,False,,False,False,True,False,/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,Alphanumeric Search Algorithm?,"I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are \~ 150k stores in the dataset.

I can distribute these into \~21k regions with varying number of stores (max \~5k) and search locally within and that aligns with the problem statement.

My current method involves:  
Loop for region  
Calculate distance of first store from all other stores  
Loop for each store  
dist col = dist col - dist store(current loop iteration)  
filter for dist col <= 150m

store\_ref = current loop iteration

check if dist (store\_ref and store in iteration <=100m)

if yes,

check similarity,

if similarity>threshold, add to list/dataframe

&#x200B;

&#x200B;

This is a 3 level loop of max \~21k \* 5k \* 600 iterations and is taking too long. 

I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  
",datascience,https://www.reddit.com/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,2,1,1.0,"[Comment(id='k4pjep1'), Comment(id='k4rpngp')]"
176drw8,a157reverse,,2023-10-12 18:24:13+00:00,False,,False,False,True,False,/r/datascience/comments/176drw8/explainable_ai_scepticism/,Explainable AI Scepticism,"For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. 

Not surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. 

However, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. 

Things like SHAP values of LIME are okay in some instances with a stable model, but we've seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. 

This blog post summarizes most of my thoughts clearly: https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/

Anyways, I guess what I'm asking is are there practicioners out there that hold a different view? Are there advancements in this space that I'm unaware of? I know there's a lot of effort going into the explainable AI space right now, but I'm pessimistic that it's even possible for us to have a good explaination for many models. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/176drw8/explainable_ai_scepticism/,6,8,0.84,"[Comment(id='k4mv0wo'), Comment(id='k4lluk8'), Comment(id='k4lkuib'), Comment(id='k4nc74e'), Comment(id='k4n1a8p'), Comment(id='k4mc060')]"
1769ler,Legitimate_Ebb3623,,2023-10-12 15:25:21+00:00,False,,False,False,True,False,/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,Coding sometimes scares me. Is this the wrong field for me?,"I have been working as a ""Data Scientist"" for a little over 2 years but in my company I'm primarily tasked with developing MVPs with the company's  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company's technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. 

In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.

I'm trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?",datascience,https://www.reddit.com/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,27,16,0.73,"[Comment(id='k4koo77'), Comment(id='k4kqzez'), Comment(id='k4lmyje'), Comment(id='k4lsn2q'), Comment(id='k4m4s4z'), Comment(id='k4laaw0'), Comment(id='k4ldixc'), Comment(id='k4n2cex'), Comment(id='k4ly0xf'), Comment(id='k4l6vxr'), Comment(id='k4lt910'), Comment(id='k4m8ti3'), Comment(id='k4o2nhm'), Comment(id='k4o8yvt'), Comment(id='k4q813b'), Comment(id='k4mzokq'), Comment(id='k4krjus'), Comment(id='k4o2dc6'), Comment(id='k4mapt0'), Comment(id='k4m1bb4'), Comment(id='k4n0y2c'), Comment(id='k4kv1ag'), Comment(id='k4ktno9'), Comment(id='k4mevu8'), Comment(id='k4n3q4q'), Comment(id='k4n3hpb'), Comment(id='k4mxku5')]"
176h4n3,Reasonable-Farmer186,,2023-10-12 20:52:03+00:00,False,,False,False,True,False,/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,Resources on Monte Carlo Simulations (Python),"Hi all,

I have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.

Thanks! Any advice would be appreciated.",datascience,https://www.reddit.com/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,4,4,1.0,"[Comment(id='k4n3e32'), Comment(id='k4ov8gn'), Comment(id='k4ubuvi'), Comment(id='k4pzsal')]"
176oxj5,CharmingSurprise4939,,2023-10-13 03:03:28+00:00,False,,False,False,False,False,/r/datascience/comments/176oxj5/two_different_ways_to_execute_python_code_on_an/,Two different ways to execute Python code on an EC2 instance,,datascience,https://medium.com/@hello_prism/running-a-python-script-on-an-ec2-instance-8691589b3080,0,1,0.67,[]
176ojaz,CheapBanana1050,,2023-10-13 02:42:01+00:00,False,,False,False,True,False,/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,On handling multi-label/multi-value categorical features and high cardinality.,"Hi all, I'm working on a binary classification problem with all input features being categorical (and nominal).

The problem I'm facing is that each input example can contain multiple values of a feature and there are too many different values.

(For example, multi-value feature being a 'Hobbies' feature that contains a list of strings:

>data = {'User': \['User1', 'User2', 'User3'\],'Hobbies': \[\['Soccer', 'Swimming', 'Hiking'\],\['Swimming', 'Cycling'\],\['Soccer', 'Hiking'\]\]}

)

I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0's.  I searched for other suggestions that address this issue and [this article](https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4) stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.

The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I'm not sure about this approach.

How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I'm new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn't address the multiple-value nature of the features.

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,3,1,0.67,"[Comment(id='k4nvwr0'), Comment(id='k4ry8aj'), Comment(id='k4o6mhp')]"
176rwg6,Active_Cranberry7606,,2023-10-13 06:05:00+00:00,False,,False,False,True,False,/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,High Performance Teams: Is the Balance of Personal and Professional Connections Vital for Team Synergy? Should you really KNOW and CARE about your colleagues?," I've been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?

I've heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it's all about the work, and personal connections might be secondary.

I'd love to hear your thoughts and experiences on this matter:

1. Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?
2. Conversely, have you been on a high-performance team where personal relationships weren't a focal point, yet it still excelled in achieving its goals?
3. What are your thoughts on the balance between personal connections and professional performance within a team?
4. Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?

Feel free to share your insights, anecdotes, or opinions. I'm genuinely curious to see the various perspectives on this topic. Let's have a meaningful discussion!

 ",datascience,https://www.reddit.com/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,3,0,0.43,"[Comment(id='k4odd4n'), Comment(id='k4pc5ro'), Comment(id='k4q5ye5')]"
176tmht,Additional_Guide5439,,2023-10-13 08:05:11+00:00,False,,1697209194.0,False,True,False,/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,What are your thoughts on time series analysis and forecasting with Generative models like TimeGPT,"Recently i was in conversation with professor Rob Hyndman and he told how TimeGPT was a promising model that could be used for prediction tasks. For those who don't know this is an excerpt from the company website:-

TimeGPT, developed by Nixtla, is a generative pre-trained transformer model specialized in prediction tasks. TimeGPT was trained on the largest collection of data in history – over 100 billion rows of financial, weather, energy, and web data – and democratizes the power of time-series analysis.

So what are your thoughts on such models and where do you think the future lies for forecasting tasks when compared to statistical models like ARIMA or state space models.",datascience,https://www.reddit.com/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,3,0,0.38,"[Comment(id='k4ouol8'), Comment(id='k4p654j'), Comment(id='k4qecdk'), Comment(id='k4qhnwp'), Comment(id='k4qou92')]"
176n9lw,are-you-kittenme,,2023-10-13 01:34:39+00:00,False,,False,False,True,False,/r/datascience/comments/176n9lw/is_networking_key/,Is networking key?,I'm autistic. I have really bad social anxiety. Is networking key in getting a job? I am just getting started in school.. i've been a stay at home mom for the last 9 years. Am i wasting my time?,datascience,https://www.reddit.com/r/datascience/comments/176n9lw/is_networking_key/,7,1,0.54,"[Comment(id='k4ncsnm'), Comment(id='k4qbdxy'), Comment(id='k4nxpq0'), Comment(id='k4ncwqn'), Comment(id='k4nqtao'), Comment(id='k4ppl6s'), Comment(id='k4qz20t')]"
1769vr7,ma-d-ghost,,2023-10-12 15:37:44+00:00,False,,False,False,True,False,/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,I feel like I’m stuck with my scientific research,"Hi, I’m writing this post hoping to get some advice from everyone. I’m studying for a Master's degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I've completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.

However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I'm stuck at this stage; one month has passed, and I haven't been able to discover anything new beyond what they have pointed out. I'm really worried that I might disappoint my mentors, as they've been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I'm afraid that I might be slowing down the whole team :(",datascience,https://www.reddit.com/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,7,7,0.77,"[Comment(id='k4ksjm7'), Comment(id='k4mf14m'), Comment(id='k4kz1uc'), Comment(id='k4l7nui'), Comment(id='k4li2et'), Comment(id='k4lisiz'), Comment(id='k4li7k0')]"
176c3gh,mangos5,,2023-10-12 17:12:43+00:00,False,,False,False,True,False,/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,What to do when looking for a job,Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?,datascience,https://www.reddit.com/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,3,3,0.67,"[Comment(id='k4lyjsr'), Comment(id='k4l8rnk'), Comment(id='k4lx50u')]"
1769z7v,Legitimate_Ebb3623,,2023-10-12 15:41:54+00:00,False,,False,False,True,False,/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,can any research scientists share their experience?,"I'm interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.

I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?

How did you get the role? If I'm interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?",datascience,https://www.reddit.com/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,2,5,0.78,"[Comment(id='k4l045x'), Comment(id='k4mnv6e')]"
176di2y,AlternativeSea4330,,2023-10-12 18:12:34+00:00,False,,False,False,True,False,/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,What's Pandas .loc time complexity?," Hi guys, i'm doing research on Pandas, and I've read various posts here and there on the web, but i haven't reached a definitive conclusion regarding the question i posed. I'd like to understand how Pandas stores indices and what the time complexity of lookup operations performed with **loc** is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, [https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas](https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas), which discusses the topic, but there's no concrete evidence that this is true. Can anyone help me? Thanks a lot.",datascience,https://www.reddit.com/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,5,4,0.83,"[Comment(id='k4loa8h'), Comment(id='k4wqgtq'), Comment(id='k4lh33a'), Comment(id='k4m2wom'), Comment(id='k4yeoz9')]"
176fpo0,FierceTeletubby,,2023-10-12 19:50:19+00:00,False,,False,False,True,False,/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,CVXPY: Why Norm constraint is not DCP?,"\`cp.norm(weights, 1).is\_dcp()\` returns true. Then why this code works:

&#x200B;

    import cvxpy as cp
    import numpy as np
    inputs = np.random.normal(0, 1, (100, 300))
    inputs_mean = inputs.mean(axis=1) # shape (features,)
    inputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)
    weights = cp.Variable(len(inputs))
    risk = cp.quad_form(weights, inputs_cov)
    constraints = [
    # cp.norm(weights, 1) == 1.,
    cp.sum(weights) == 1.,
    ]
    problem = cp.Problem(cp.Minimize(risk), constraints)
    problem.solve(verbose=True)
    weights.value

But if you use the first constraint (\`cp.norm\`) instead of the second, it does not:

&#x200B;

    DCPError: Problem does not follow DCP rules. Specifically:
    The following constraints are not DCP:
    norm1(var456) == 1.0 , because the following subexpressions are not:
    |-- norm1(var456) == 1.0

&#x200B;

Why is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,6,0,0.5,"[Comment(id='k4nmgsq'), Comment(id='k4nmkdj'), Comment(id='k4sc2i6'), Comment(id='k4sbt1x'), Comment(id='k4trt78'), Comment(id='k4vlx6i')]"
176aamb,emotional-Limit-2000,,2023-10-12 15:55:38+00:00,False,,False,False,True,False,/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,Need problem statements for a project,"I want to make a project in which I'm thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn't already a solution however I'm not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y'all have any suggestions please let me know it'll be genuinely appreciated!",datascience,https://www.reddit.com/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,5,2,0.75,"[Comment(id='k4kzspi'), Comment(id='k4l27cu'), Comment(id='k4otgro'), Comment(id='k4ll478'), Comment(id='k4pr62r')]"
176bn2q,Ashfan007,,2023-10-12 16:53:02+00:00,False,,False,False,True,False,/r/datascience/comments/176bn2q/recommend_data_science_course/,Recommend data science course,"I'm a beginner in data science, Can someone recommend some good Data Science courses? ",datascience,https://www.reddit.com/r/datascience/comments/176bn2q/recommend_data_science_course/,2,0,0.5,"[Comment(id='k4r354e'), Comment(id='k4rchk9')]"
1769fk8,ergodym,,2023-10-12 15:18:09+00:00,False,,False,False,True,False,/r/datascience/comments/1769fk8/ds_exits_or_pivots/,DS exits or pivots,What's the most creative exit or pivot you have done (or seen others do) after being a DS for some time?,datascience,https://www.reddit.com/r/datascience/comments/1769fk8/ds_exits_or_pivots/,0,1,0.67,[]
17686qn,Kenny9184,,2023-10-12 14:23:22+00:00,False,,False,False,True,False,/r/datascience/comments/17686qn/career_planning/,Career planning,"Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?",datascience,https://www.reddit.com/r/datascience/comments/17686qn/career_planning/,1,1,1.0,[Comment(id='k4kh917')]
175jep1,every_other_freackle,,2023-10-11 17:14:02+00:00,False,,1697083575.0,False,True,False,/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,How do you store your ad hoc experiments?,"Let’s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?


How would you store/archive this project?
Committing Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that’s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?

What tool / workflow am I missing here?

I keep hearning notebooks are great for experiments but I don’t see what the workflow is like for these experiments…

EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..",datascience,https://www.reddit.com/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,31,48,0.94,"[Comment(id='k4gc614'), Comment(id='k4htcop'), Comment(id='k4g6nsu'), Comment(id='k4g824f'), Comment(id='k4h2gku'), Comment(id='k4h9ght'), Comment(id='k4ies8a'), Comment(id='k4g4b2v'), Comment(id='k4g4om5'), Comment(id='k4gryxn'), Comment(id='k4gjnx5'), Comment(id='k4go9iy'), Comment(id='k4hv2qw'), Comment(id='k4iav2t'), Comment(id='k4iuwca'), Comment(id='k4g8l5d'), Comment(id='k4gjtzi'), Comment(id='k4gxuu3'), Comment(id='k4h9qz4'), Comment(id='k4hmeya'), Comment(id='k4jsex7'), Comment(id='k4jxuh2'), Comment(id='k4h7wlx'), Comment(id='k4irek6'), Comment(id='k4htvp7'), Comment(id='k4j72kl'), Comment(id='k4hojhk'), Comment(id='k4g4zub'), Comment(id='k4hqywb'), Comment(id='k4j7h21'), Comment(id='k4kkaup')]"
1761n34,ZebZ,,2023-10-12 08:07:02+00:00,False,,False,False,True,False,/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,Existing relational database to new vector database?,"I'm in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things ""AI"").

Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.

If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.

My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I'm not sure where to start, and I'm getting hung up on that there doesn't seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.

I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I'd equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That's half of it. But I'm not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I'm most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like ""Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?""

Basically, all this is a very long-winded, rambling way to get to three questions:

1. Are there any examples of converting a remotely complex RDMS into a vector database?

2. How much massaging beyond basic denormalization and pre-aggregation do I need to do?

3. Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?",datascience,https://www.reddit.com/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,1,3,0.8,[Comment(id='k4jnc0y')]
175ptfa,greathassan,,2023-10-11 21:42:37+00:00,False,,False,False,True,False,/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,Where to spend £5k budget for professional development in Data Science,"Hi everyone,

I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around £5,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. 

Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. ",datascience,https://www.reddit.com/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,24,13,0.84,"[Comment(id='k4jatm9'), Comment(id='k4iy6cr'), Comment(id='k4lwjse'), Comment(id='k4o5q3c'), Comment(id='k4jer4s'), Comment(id='k4iqwug'), Comment(id='k4k5307'), Comment(id='k4juht2'), Comment(id='k4jdcf9'), Comment(id='k4k1rrf'), Comment(id='k4mmvfc'), Comment(id='k4u2vy0'), Comment(id='k4jujm8'), Comment(id='k4iwf1g'), Comment(id='k4ju9zg'), Comment(id='k4lorju'), Comment(id='k4k1u05'), Comment(id='k4juuqf'), Comment(id='k4iwu1p'), Comment(id='k4k230u'), Comment(id='k4ja9fx'), Comment(id='k4k9es7'), Comment(id='k4jud78'), Comment(id='k4ktggp')]"
175caah,Diligent_Trust2569,,2023-10-11 11:59:15+00:00,False,,False,False,True,False,/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,How important is being appreciated and team fit as a factor to stay in a role with average salary given slow adoption of data science solutions?,"My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.

I am the “lead”/senior data scientist in an R&D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.

  I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.

I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.",datascience,https://www.reddit.com/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,85,73,0.86,"[Comment(id='k4f1nih'), Comment(id='k4enf76'), Comment(id='k4f5wrw'), Comment(id='k4f87kh'), Comment(id='k4es6cr'), Comment(id='k4fegtp'), Comment(id='k4fc5lt'), Comment(id='k4fdu0k'), Comment(id='k4fpnui'), Comment(id='k4erroz'), Comment(id='k4eo7sm'), Comment(id='k4g5l8z'), Comment(id='k4g8p9w'), Comment(id='k4gc0h5'), Comment(id='k4hit1f'), Comment(id='k4hmdgr'), Comment(id='k4i57cx'), Comment(id='k4ib4ox'), Comment(id='k4jflqu'), Comment(id='k4vipwh'), Comment(id='k5ccpe1'), Comment(id='k4fx64p'), Comment(id='k4ev5h6'), Comment(id='k4f2708'), Comment(id='k4hlprh'), Comment(id='k4enkch'), Comment(id='k4fiuls'), Comment(id='k4f8p2n'), Comment(id='k4esf4a'), Comment(id='k4fu3te'), Comment(id='k4erwol'), Comment(id='k4i5spr'), Comment(id='k4eolli'), Comment(id='k4fs8l5'), Comment(id='k4fi8g0'), Comment(id='k4exnop'), Comment(id='k4f0klz'), Comment(id='k4l82sw'), Comment(id='k4oocq2'), Comment(id='k4g91xi'), Comment(id='k4i5ffh'), Comment(id='k50uhd8'), Comment(id='k4fxdi3'), Comment(id='k4fg853'), Comment(id='k4fa8pk'), Comment(id='k4enuro'), Comment(id='k4eo8f3'), Comment(id='k4g4n5x'), Comment(id='k4fmd4w'), Comment(id='k4esl1s'), Comment(id='k4l7lyt'), Comment(id='k4exh32'), Comment(id='k4l7q7n'), Comment(id='k4fp1i0'), Comment(id='k4l6ryz'), Comment(id='k4fnqwb'), Comment(id='k4f2qdd'), Comment(id='k4fji1m'), Comment(id='k4lahiy'), Comment(id='k4ie5ay'), Comment(id='k4f55ut'), Comment(id='k4f3bsu'), Comment(id='k4g0uta'), Comment(id='k4f5apt'), Comment(id='k4f57lc'), Comment(id='k4f580y'), Comment(id='k4g3yjo'), Comment(id='k4f71vu'), Comment(id='k4f6pj2'), Comment(id='k4g982c'), Comment(id='k4f8vjh'), Comment(id='k4hor0s'), Comment(id='k4gb0ah'), Comment(id='k4getvp'), Comment(id='k4gi7aj'), <MoreComments count=0, children=[]>]"
175nbtg,childofaether,,2023-10-11 20:00:04+00:00,False,,False,False,True,False,/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,Any value to an unrelated advanced degree to get into DS?,"I'm a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.

I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don't care about non-CS scientific education ?

What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?

I'm interested in Data Science and I'm looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn't want to pursue more formal education if it doesn't really give me more options other than a false hope and wasted time applying for DS positions I can't get.",datascience,https://www.reddit.com/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,14,11,0.93,"[Comment(id='k4gusbf'), Comment(id='k4ipbmt'), Comment(id='k4i6w4m'), Comment(id='k4jzgld'), Comment(id='k4hu782'), Comment(id='k4h9fem'), Comment(id='k4jwu0t'), Comment(id='k4h6ya9'), Comment(id='k4khvr9'), Comment(id='k4jttgq'), Comment(id='k4h8kjp'), Comment(id='k4tgc69'), Comment(id='k4hcdve'), Comment(id='k4he77g')]"
175gyx0,Pineapple_throw_105,,2023-10-11 15:35:13+00:00,False,,False,False,True,False,/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,What are grid search alternatives?,Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.,datascience,https://www.reddit.com/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,40,22,0.81,"[Comment(id='k4flkjc'), Comment(id='k4gdiul'), Comment(id='k4fhzz2'), Comment(id='k4ghn8a'), Comment(id='k4fl779'), Comment(id='k4ggxre'), Comment(id='k4frddj'), Comment(id='k4gelne'), Comment(id='k4gb1so'), Comment(id='k4gkubn'), Comment(id='k4gld9c'), Comment(id='k4gtnzc'), Comment(id='k4h4zp0'), Comment(id='k4iupfb'), Comment(id='k4ix6qx'), Comment(id='k4ixf7v'), Comment(id='k4j0jjq'), Comment(id='k4jidy7'), Comment(id='k4hotqi'), Comment(id='k4glz54'), Comment(id='k4gm7mp'), Comment(id='k4h7lhv'), Comment(id='k4h9mck'), Comment(id='k4jccog'), Comment(id='k4mlcss'), Comment(id='k4uza7q'), Comment(id='k4h3lx5'), Comment(id='k4it7mn'), Comment(id='k4fisk2'), Comment(id='k4i6ei4'), Comment(id='k4h7dr3'), Comment(id='k4gj3x9'), Comment(id='k4hk707'), Comment(id='k4j9mmd'), Comment(id='k4j79w8'), Comment(id='k4fjppo'), Comment(id='k4hx8gt'), Comment(id='k4jmd3q'), Comment(id='k4i9mth'), Comment(id='k4m8arc')]"
175x92z,ProductOk7316,,2023-10-12 03:32:18+00:00,False,,False,False,True,False,/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,SHAP Deep Reinforcement Learning,"Hi Guys,

Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. 

&#x200B;

Thanks. ",datascience,https://www.reddit.com/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,0,2,1.0,[]
1760xpw,RevolutionaryPen4661,,2023-10-12 07:17:19+00:00,False,,False,False,False,False,/r/datascience/comments/1760xpw/markdown_to_html/,Markdown To HTML,,datascience,/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/,2,0,0.33,"[Comment(id='k4j8nj9'), Comment(id='k4lce34')]"
175oh0k,Fincho64,,2023-10-11 20:47:01+00:00,False,,False,False,True,False,/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,"Julia leads Rust, Zig, Go and Java in data processing benchmark","[https://github.com/jinyus/related\_post\_gen](https://github.com/jinyus/related_post_gen)

https://preview.redd.it/ii0dm13dymtb1.png?width=849&format=png&auto=webp&s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f",datascience,https://www.reddit.com/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,0,8,1.0,[]
175q00o,EncryptedMyst,,2023-10-11 21:50:27+00:00,False,,False,False,True,False,/r/datascience/comments/175q00o/security_measures_at_my_workplace/,Security measures at my workplace,"I work for a pretty big Aerospace manufacturing company where my job title is 'Digital Engineer'. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can't disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.

I would of course like to use Python's Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.

My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven't really been exposed to it yet.",datascience,https://www.reddit.com/r/datascience/comments/175q00o/security_measures_at_my_workplace/,7,4,0.75,"[Comment(id='k4ib4xr'), Comment(id='k4hqaa5'), Comment(id='k4j4xwy'), Comment(id='k4hdau6'), Comment(id='k4j3fyq'), Comment(id='k4lesad'), Comment(id='k4j2d8n')]"
175qvkx,Bulky_Gap_7072,,2023-10-11 22:27:06+00:00,False,,False,False,True,False,/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,Predicting what features lead to long wait times,"I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. 

I work on a team of \~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. 

I think there's a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.

When you have one value (duration) that you're trying to make predictions about, but you don't have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?",datascience,https://www.reddit.com/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,4,3,0.81,"[Comment(id='k4hoem4'), Comment(id='k4hfggr'), Comment(id='k4hmd1f'), Comment(id='k4i2vd5')]"
174wmnk,Utterizi,,2023-10-10 21:24:57+00:00,False,,False,False,True,False,/r/datascience/comments/174wmnk/sucking_at_my_job/,Sucking at my job?,"Got into my first job about 10 months ago. I study a master’s on data science and I’m about to finish school in 2-3 months. I’m doing okay, my lowest score is B+ and I’m working on a churn project. 

I got my job through a friend, the company knew I was recently starting my master’s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I’d bring a new perspective to the team. 

Things started ok and I’m doing pretty good on every day tasks, but whenever I’m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. 

It’s not that I’m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.

I’m starting to feel like I’m wasting company’s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything.",datascience,https://www.reddit.com/r/datascience/comments/174wmnk/sucking_at_my_job/,41,144,0.94,"[Comment(id='k4c8zqt'), Comment(id='k4ck3ll'), Comment(id='k4c1ui2'), Comment(id='k4c74qi'), Comment(id='k4cxl4z'), Comment(id='k4cb16t'), Comment(id='k4cwr9u'), Comment(id='k4c2iw8'), Comment(id='k4d7h4b'), Comment(id='k4ccrmj'), Comment(id='k4d4cfk'), Comment(id='k4d1ioj'), Comment(id='k4chs3f'), Comment(id='k4cqfhs'), Comment(id='k4eowwq'), Comment(id='k4f9bxy'), Comment(id='k4cpdpm'), Comment(id='k4c4blt'), Comment(id='k4e3yxq'), Comment(id='k4dy4oi'), Comment(id='k4e1q57'), Comment(id='k4fmjx3'), Comment(id='k4fpvnh'), Comment(id='k4h545c'), Comment(id='k4h621d'), Comment(id='k4j9h5u'), Comment(id='k4drtln'), Comment(id='k4irnm0'), Comment(id='k4cq8cu'), Comment(id='k4cgy6v'), Comment(id='k4dduqi'), Comment(id='k4f0rer'), Comment(id='k4g9n6y'), Comment(id='k4dx4m5'), Comment(id='k4dwwsh'), Comment(id='k4crzij'), Comment(id='k4dmubl'), Comment(id='k4erqqm'), Comment(id='k4cu9n0'), Comment(id='k4d55z7'), Comment(id='k4dcyow')]"
175mipy,aesthetic-mango,,2023-10-11 19:25:33+00:00,False,,False,False,True,False,/r/datascience/comments/175mipy/rsession_crashingphobia/,R-SESSION CRASHING-PHOBIA,"I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I'd say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE ''SESSION CRASHED''!

Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?

P.S. i sadly mustn't split the dataset. 

Thanks a lot, i wish you nothing but simple datasets. ",datascience,https://www.reddit.com/r/datascience/comments/175mipy/rsession_crashingphobia/,9,0,0.5,"[Comment(id='k4gq8p8'), Comment(id='k4h9f4q'), Comment(id='k4h2xw5'), Comment(id='k4h7zg3'), Comment(id='k4hc7p8'), Comment(id='k4hcnaw'), Comment(id='k4i0y1y'), Comment(id='k4iysp6'), Comment(id='k4krpa7')]"
175errf,oblivious_horizon,,2023-10-11 14:03:12+00:00,False,,False,False,True,False,/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,Predicted raw probabilities or threshold-adjusted ones?,"I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? 

For example, suppose I get a probability as 0.55. Which means, in face value, that there's more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I'm concerned with ONLY the probability, isnt that deceiving or wrong? 

Any suggestions are appreciated.",datascience,https://www.reddit.com/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,5,2,1.0,"[Comment(id='k4fbbou'), Comment(id='k4fk9kl'), Comment(id='k4gflhs'), Comment(id='k4q3o9f'), Comment(id='k4q2nm6')]"
1754v9n,DapperAd8264,,2023-10-11 03:48:56+00:00,False,,False,False,True,False,/r/datascience/comments/1754v9n/data_science_for_sales/,Data Science for Sales,"I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I’m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company’s CRM data and my company’s product offering is price benchmarking.",datascience,https://www.reddit.com/r/datascience/comments/1754v9n/data_science_for_sales/,21,12,0.78,"[Comment(id='k4djgtc'), Comment(id='k4dt0nf'), Comment(id='k4e3ogs'), Comment(id='k4f8qvl'), Comment(id='k4fc636'), Comment(id='k4fli2l'), Comment(id='k4fqeov'), Comment(id='k4dtzs5'), Comment(id='k4f4wg7'), Comment(id='k4fnoom'), Comment(id='k4duhw3'), Comment(id='k4fprpi'), Comment(id='k4fc0n0'), Comment(id='k4fj57p'), Comment(id='k4fjl9k'), Comment(id='k4flomz'), Comment(id='k4flgco'), Comment(id='k4g4kmi'), Comment(id='k4g958r'), Comment(id='k4gfob8'), Comment(id='k4gi1ej')]"
174pvw9,databro92,,2023-10-10 16:47:12+00:00,False,,False,False,True,False,/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,"Can anyone provide an easy to understand real world example of tensors, and how they are used?","One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You're just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...


And recently I've been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don't understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I'm not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. 


So how would you explain what a tensor is in real world terms?",datascience,https://www.reddit.com/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,63,70,0.85,"[Comment(id='k4b45q5'), Comment(id='k4azn5b'), Comment(id='k4d7v0k'), Comment(id='k4awwxb'), Comment(id='k4btnr5'), Comment(id='k4b4b47'), Comment(id='k4brnvo'), Comment(id='k4deyev'), Comment(id='k4asjpn'), Comment(id='k4bv9mo'), Comment(id='k4c2e7o'), Comment(id='k4avlkg'), Comment(id='k4bq0wn'), Comment(id='k4brzzz'), Comment(id='k4co1k2'), Comment(id='k4ctvrp'), Comment(id='k4d5fir'), Comment(id='k4e7j9a'), Comment(id='k4ec6we'), Comment(id='k4etd8g'), Comment(id='k4etej1'), Comment(id='k4fetce'), Comment(id='k4gmuk6'), Comment(id='k4ha1re'), Comment(id='k4hpc60'), Comment(id='k4jbvkt'), Comment(id='k4bxl4w'), Comment(id='k4be01h'), Comment(id='k4b56fn'), Comment(id='k4b7e2y'), Comment(id='k4e6irh'), Comment(id='k4bs5t9'), Comment(id='k4brqdm'), Comment(id='k4bfy1n'), Comment(id='k4aung7'), Comment(id='k4c0oy0'), Comment(id='k4buw35'), Comment(id='k4ctfua'), Comment(id='k4bcqk3'), Comment(id='k4c44t8'), Comment(id='k4bc9f6'), Comment(id='k4f76kr'), Comment(id='k4c3rfm'), Comment(id='k4daoun'), Comment(id='k4cu8qt'), Comment(id='k4axs9i'), Comment(id='k4c3yf9'), Comment(id='k4d6rrn'), Comment(id='k4comqh'), Comment(id='k4buxek'), Comment(id='k4ftkda'), Comment(id='k4c7xdi'), Comment(id='k4dcqhf'), Comment(id='k4dmu34'), Comment(id='k4cxl9y'), Comment(id='k4ccbm6'), Comment(id='k4cakgc'), Comment(id='k4d7tmv'), Comment(id='k4fuzjo'), Comment(id='k4ciinf'), Comment(id='k4cgkn8'), Comment(id='k4f7yc2'), Comment(id='k4d9n0u'), Comment(id='k4e6p0f'), Comment(id='k4fx32o'), Comment(id='k4clqs9'), Comment(id='k4da4b1')]"
1756hae,DboS3dan,,2023-10-11 05:26:52+00:00,False,,False,False,True,False,/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,A/B Testing Product or User Split,"I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is ‘attractive’, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.

If I want to do A/B test on this to see if this ‘attractive’ indication makes those items sell at a higher rate, how would you design the test? Would you:
1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?
2. Identify those items and only show the ‘attractive’ indicator to half of the users. Meaning that half the users will see the existing experience (no ‘attractive’ indicator at all) and half will see the ‘attractive’ indicator on all 500 items, then compare how they sell by user group?

Intuitively #1 makes more sense to me, but I’m not finding a lot of literature to support this methodology. How would you design such a test and what’s your rationale?

Please note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.

Thanks",datascience,https://www.reddit.com/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,5,5,0.86,"[Comment(id='k4evnsd'), Comment(id='k4dwy6n'), Comment(id='k4eu9y6'), Comment(id='k4fqd64'), Comment(id='k4fr4u6')]"
174gxvo,Fluxan,,2023-10-10 09:29:59+00:00,False,,1696936462.0,False,True,False,/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,"How can data science be used to ""make the world a better place""?","I see a lot of data scientists in this subreddit describing their work as using different types of methods to, in the end, improve company performance and/or profits.

I was wondering, if you have examples for how data science is used for social benefit instead of the bottom line of profits?",datascience,https://www.reddit.com/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,99,129,0.89,"[Comment(id='k495xjm'), Comment(id='k49bw3c'), Comment(id='k49g65e'), Comment(id='k49b2ea'), Comment(id='k499a90'), Comment(id='k49jenp'), Comment(id='k496ho7'), Comment(id='k49tira'), Comment(id='k49bunw'), Comment(id='k494fos'), Comment(id='k49u248'), Comment(id='k4a0gfl'), Comment(id='k4a6ag3'), Comment(id='k49frsk'), Comment(id='k4afevl'), Comment(id='k4aiwli'), Comment(id='k4aj59g'), Comment(id='k4ate5q'), Comment(id='k4bpc3a'), Comment(id='k4bqxv6'), Comment(id='k4ececu'), Comment(id='k49aoou'), Comment(id='k4bd7e7'), Comment(id='k49f22a'), Comment(id='k4chqxv'), Comment(id='k4a4bnm'), Comment(id='k49ozat'), Comment(id='k4abki2'), Comment(id='k4aikyi'), Comment(id='k4aqprh'), Comment(id='k4aqwse'), Comment(id='k4awke9'), Comment(id='k4b6wdw'), Comment(id='k4baze2'), Comment(id='k4bbunf'), Comment(id='k4bhxkt'), Comment(id='k4bjpp8'), Comment(id='k4bo864'), Comment(id='k4boq0j'), Comment(id='k4bt2er'), Comment(id='k4by5yt'), Comment(id='k4byq7w'), Comment(id='k4c3yap'), Comment(id='k4c5543'), Comment(id='k4cmqet'), Comment(id='k4cmx4t'), Comment(id='k4d4p86'), Comment(id='k4d65e3'), Comment(id='k4dwogy'), Comment(id='k4dxqgc'), Comment(id='k4e5ih4'), Comment(id='k4e7qnx'), Comment(id='k4eb99k'), Comment(id='k4fa08l'), Comment(id='k4i2r53'), Comment(id='k4iezk6'), Comment(id='k4atln4'), Comment(id='k4azge6'), Comment(id='k4ckk71'), Comment(id='k4awm4p'), Comment(id='k4btj98'), Comment(id='k4bi2ib'), Comment(id='k4b3wc4'), Comment(id='k4bu2af'), Comment(id='k4atj62'), Comment(id='k4b9c4z'), Comment(id='k4aakar'), Comment(id='k4acyin'), Comment(id='k4a3etj'), Comment(id='k4igbyh'), Comment(id='k4anufe'), Comment(id='k49crmf'), Comment(id='k4bepb9'), Comment(id='k4ewrxm'), Comment(id='k4gn9a6'), Comment(id='k4gjwca'), Comment(id='k4f4uyo'), Comment(id='k4b4ms1'), Comment(id='k4c6rsj'), Comment(id='k4drzmk'), Comment(id='k4adqta'), Comment(id='k4b595q'), Comment(id='k49f8bj'), Comment(id='k4fxvsn'), Comment(id='k4kj0cb'), Comment(id='k4gm7iu'), Comment(id='k4gccfz'), Comment(id='k4emxhq'), Comment(id='k4ajeal'), Comment(id='k4chzpk'), Comment(id='k49g9co'), Comment(id='k4gfb8u'), Comment(id='k4n2x22'), Comment(id='k4davwm'), Comment(id='k4dv2dj'), Comment(id='k49j4ka'), Comment(id='k49nqlf')]"
174n6w2,timusw,,2023-10-10 14:53:14+00:00,False,,False,False,True,False,/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,How quickly should you be expected to start producing?,"How soon would you expect a new Senior Data Scientist to start churning out models, analysis, reports, experiments, etc? What would you think dictates this expectation?",datascience,https://www.reddit.com/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,33,47,0.89,"[Comment(id='k4a5n0g'), Comment(id='k4aku9z'), Comment(id='k4bp1of'), Comment(id='k4c75wq'), Comment(id='k4cg760'), Comment(id='k4b30w9'), Comment(id='k4b7yt8'), Comment(id='k4bn82w'), Comment(id='k4bbb1h'), Comment(id='k4ag1na'), Comment(id='k4apo13'), Comment(id='k4dwtmu'), Comment(id='k4a9kr3'), Comment(id='k4b88zr'), Comment(id='k4c1lux'), Comment(id='k4bprqn'), Comment(id='k4c0xy2'), Comment(id='k4abwnf'), Comment(id='k4agcy5'), Comment(id='k4aj8oh'), Comment(id='k4aqc0g'), Comment(id='k4beo0x'), Comment(id='k4c9vtl'), Comment(id='k4c852m'), Comment(id='k4c55e0'), Comment(id='k4aonn9'), Comment(id='k4cpnw1'), Comment(id='k4clugy'), Comment(id='k4b88eb'), Comment(id='k4aqbsh'), Comment(id='k4arh1d'), Comment(id='k4cl5cx'), Comment(id='k4fho3j')]"
175qent,Silly_Valley,,2023-10-11 22:07:24+00:00,False,,1697072739.0,False,True,False,/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,Is fitting functions to data (with chi2 and all that) data analysis or data science?,&#x200B;,datascience,https://www.reddit.com/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,53,0,0.33,"[Comment(id='k4hg8i1'), Comment(id='k4hnbqi'), Comment(id='k4hd1le'), Comment(id='k4j3caz'), Comment(id='k4vcroi'), Comment(id='k4hhil4'), Comment(id='k4hnz9b'), Comment(id='k4hhnkz'), Comment(id='k4x1a9t'), Comment(id='k4hhsov'), Comment(id='k4hrd6d'), Comment(id='k4hrsyu'), Comment(id='k4hry9e'), Comment(id='k4jc60v'), Comment(id='k4l222a'), Comment(id='k4i28zz'), Comment(id='k4x2t9v'), Comment(id='k4hin8n'), Comment(id='k4i0gj4'), Comment(id='k4hwwku'), Comment(id='k4k9fs5'), Comment(id='k4l2o6k'), Comment(id='k4i4kr7'), Comment(id='k4xj93q'), Comment(id='k4hk78k'), Comment(id='k4hmdpl'), Comment(id='k4i1gca'), Comment(id='k4l483m'), Comment(id='k4ibwxm'), Comment(id='k4hndhx'), Comment(id='k4hp2b6'), Comment(id='k4i5qh6'), Comment(id='k4lcgpb'), Comment(id='k4hrwd0'), Comment(id='k4hq48p'), Comment(id='k4i6bkl'), Comment(id='k4hxfgt'), Comment(id='k4i0lqu'), Comment(id='k4i8lhu'), Comment(id='k4hzowq'), Comment(id='k4i0eoe'), Comment(id='k4i01ru'), Comment(id='k4ie08m'), Comment(id='k4i8y0u'), Comment(id='k4i16q1'), Comment(id='k4i2kdm'), Comment(id='k4i9zbp'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
175nces,philemil,,2023-10-11 20:00:38+00:00,False,,False,False,True,False,/r/datascience/comments/175nces/fraud_detection_thesis/,Fraud Detection Thesis,"Hello.

I have to do a project for my thesis.
I have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it’s being laundered.

What do you say about it?
 How should I approach this topic and how to do it?
Any ideas? Thanks.",datascience,https://www.reddit.com/r/datascience/comments/175nces/fraud_detection_thesis/,12,0,0.2,"[Comment(id='k4gvfo3'), Comment(id='k4iyjvm'), Comment(id='k4hj6h8'), Comment(id='k4i9laz'), Comment(id='k4gs0b0'), Comment(id='k4oatke'), Comment(id='k4iys74'), Comment(id='k4iysyb'), Comment(id='k4gurdo'), Comment(id='k4izg34'), Comment(id='k4gw4gl'), Comment(id='k4iyvwr')]"
1755h3b,jacobwlyman,,2023-10-11 04:23:10+00:00,False,,False,False,True,False,/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,Has anyone used Comet for experiment tracking?,Hey! Has anyone used Comet (https://www.comet.com) for their experiment tracking? I’m looking into the product and am curious if anyone here has enjoyed using it,datascience,https://www.reddit.com/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,2,2,1.0,"[Comment(id='k4fdkqz'), Comment(id='k4o5hvl')]"
1752wat,Breadskinjinhojiak,,2023-10-11 02:09:33+00:00,False,,False,False,True,False,/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,"How does SEMRUSH, and other big analytic crawler works?",I'm trying to build something similar where websites can be crawled and refresh daily,datascience,https://www.reddit.com/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,2,4,0.75,"[Comment(id='k4fi3oq'), Comment(id='k4fkywl')]"
17578q8,Prestigious_Virus_33,,2023-10-11 06:16:01+00:00,False,,False,False,True,False,/r/datascience/comments/17578q8/creating_a_visualizations_map/,Creating a Visualizations Map,"Hi Everyone

I am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. 

I am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). 

My question is beyond a refresher training I wanted to make a map for the ~~lazy~~ some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it.",datascience,https://www.reddit.com/r/datascience/comments/17578q8/creating_a_visualizations_map/,2,1,0.67,"[Comment(id='k4igcpn'), Comment(id='k53nqgo')]"
174pkt1,data_scallion,,2023-10-10 16:33:39+00:00,False,,False,False,True,False,/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,Advancements in extracting tabular data from PDFs?,"Hi everyone!

Is there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I'm currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it's very time-consuming and tedious.  Is there a better way?

I've used Langchain and OpenAI to build ""Chat with your document"" apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don't think this solution will work.

&#x200B;

Thank you for your input,

Data Scallion",datascience,https://www.reddit.com/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,7,9,0.91,"[Comment(id='k4b1pw3'), Comment(id='k5iwq5b'), Comment(id='k4cu9ff'), Comment(id='k4dmeer'), Comment(id='k4igldg'), Comment(id='k4bafvb'), Comment(id='k4cpfuc')]"
174sfb2,valkaress,,2023-10-10 18:33:34+00:00,False,,False,False,True,False,/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,[US] What are some hubs for data science or data analytics?,"I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.

What are the top 5 or 10 DS hubs in the US, and then what's 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I'm assuming is Chicago)?",datascience,https://www.reddit.com/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,14,4,0.61,"[Comment(id='k4bbiuq'), Comment(id='k4bq193'), Comment(id='k4is2uv'), Comment(id='k4bvdye'), Comment(id='k4fji8q'), Comment(id='k4bc2gw'), Comment(id='k4by8h2'), Comment(id='k54yd91'), Comment(id='k4euqdh'), Comment(id='k4g0jqj'), Comment(id='k4d2fkf'), Comment(id='k4c79ew'), Comment(id='k4isa6a'), Comment(id='k57zpgm')]"
174wama,HyenaJack94,,2023-10-10 21:11:20+00:00,False,,False,False,True,False,/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,Question animal tracking data and filling in periods of sleep?,"I'm working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?",datascience,https://www.reddit.com/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,0,1,0.67,[]
1748bph,AbramoNauseus,,2023-10-10 00:56:37+00:00,False,,False,False,True,False,/r/datascience/comments/1748bph/tough_spot/,Tough spot,"
Hey everyone,

I recently joined a company as a data scientist and found that their data warehouse is in dire shape. It seems they haven't invested enough time in validating their data, resulting in most tables being unreliable for modeling or reporting. The analysts are reporting incorrect data and the upper management knows it. To add to the challenge, there's only one overburdened data engineer here, so I'm pretty much on my own in navigating this.

I've been identifying and communicating these data issues to upper management, but I also need to produce some models. The warehouse is poorly built, many tables with no data, a lot of columns in one table meaning they didn't bother creating more dimension tables. And worst of all, the data in tables is simply wrong. My current thought is to pivot temporarily:

1. Use existing, validated CSVs and Excel files to begin my analyses and model building.
2. Parallelly, work on gradually rectifying the data warehouse issues.
3. Eventually, transition the models to source data directly from the fixed warehouse.

Has anyone faced a similar situation? How did you handle it? Any advice or alternative approaches would be greatly appreciated!",datascience,https://www.reddit.com/r/datascience/comments/1748bph/tough_spot/,17,25,0.93,"[Comment(id='k47roe1'), Comment(id='k494qtb'), Comment(id='k48uwzt'), Comment(id='k49isbv'), Comment(id='k4a5atj'), Comment(id='k4ble15'), Comment(id='k4ar8ch'), Comment(id='k4b7ta0'), Comment(id='k4b7xlr'), Comment(id='k47v8mr'), Comment(id='k48605i'), Comment(id='k49uzyb'), Comment(id='k4ahgwk'), Comment(id='k4ai1cx'), Comment(id='k4bvtg4'), Comment(id='k4aty0z'), Comment(id='k4h0xjz')]"
174ml3k,InsightIndustry,,2023-10-10 14:26:44+00:00,False,,False,False,True,False,/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,Highcharts for Python v.1.4.0 Released,"Hi Everyone - Just a quick note to let you know that we just released v.1.4.0 of the [Highcharts for Python Toolkit](https://core-docs.highchartspython.com/) (Highcharts Core for Python, Highcharts Stock for Python, Highcharts Maps for Python, and Highcharts Gantt for Python).

While technically this is a minor release since everything remains backwards compatible and new functionality is purely additive, it still brings a ton of significant improvements across all libraries in the toolkit:

**Performance Improvements**

* 50 - 90% faster when rendering a chart in Jupyter (or when serializing it from Python to JS object literal notation)
* 30 - 90% faster when serializing a chart configuration from Python to JSON

Both major performance improvements depend somewhat on the chart configuration, but in any case it should be quite significant.

**Usability / Quality of Life Improvements**

* **Support for NumPy**

  Now we can create charts and data series directly from NumPy arrays.

* **Simpler API / Reduced Verbosity**

  While the toolkit still supports the full power of Highcharts (JS), the Python toolkit now supports ""naive"" usage and smart defaults. The toolkit will attempt to assemble charts and data series for you as best it can based on your data, even without an explicit configuration. Great for quick-and-dirty experimentation!

* **Python to JavaScript Conversion**

  Now we can write our Highcharts formatter or callback functions in Python, rather than JavaScript. With one method call, we can convert a Python callable/function into its JavaScript equivalent. This relies on integration with either OpenAI's GPT models or Anthropic's Claude model, so you will need to have an account with one (or both) of them to use the functionality. Because AI is generating the JavaScript code, best practice is to review the generated JS code before including it in any production application, but for quick data science work, or to streamline the development / configuration of visualizations, it can be super useful. [We even have a tutorial on how to use this feature here.](https://core-docs.highchartspython.com/en/latest/tutorials/callbacks.html)

* **Series-first Visualization**

  We no longer have to combine series objects and charts to produce a visualization. Now, we can visualize individual series directly with one method call, no need to assemble them into a chart object.

* **Data and Property Propagation**

  When configuring our data points, we no longer have to adjust each data point individually. To set the same property value on all data points, just set the property on the series and it will get automatically propagated across all data points.

* **Series Type Conversion**

  We can now convert one series to a different series type with one method call.

**Bug Fixes**

* Fixed a bug causing a conflict in certain circumstances where Jupyter Notebook uses RequireJS.
* Fixed a bug preventing certain chart-specific required Highcharts (JS) modules from loading correctly in Jupyter Notebook/Labs.

We're already hard at work on the next release, with more improvements coming, but while we work on it, if you're looking for high-end data visualization you'll find the Highcharts for Python Toolkit useful.

Here are all the more detailed links:

* [Highcharts for Python on Github](https://github.com/highcharts-for-python)
* [Highcharts for Python Website](https://highchartspython.com)
* Highcharts Core for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-core)
  * [PyPi](https://pypi.org/project/highcharts-core/)
  * [Documentation](https://core-docs.highchartspython.com)

* Highcharts Stock for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-stock)
  * [PyPi](https://pypi.org/project/highcharts-stock/)
  * [Documentation](https://stock-docs.highchartspython.com)

* Highcharts Maps for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-maps)
  * [PyPi](https://pypi.org/project/highcharts-maps/)
  * [Documentation](https://maps-docs.highchartspython.com)

* Highcharts Gantt for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-gantt)
  * [PyPi](https://pypi.org/project/highcharts-gantt/)
  * [Documentation](https://gantt-docs.highchartspython.com)

Please let us know what you think!",datascience,https://www.reddit.com/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,2,2,0.76,"[Comment(id='k4fckfy'), Comment(id='k4fjlpj')]"
174f1cc,Salt-Page1396,,2023-10-10 07:13:22+00:00,False,,False,False,True,False,/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,Why would I use Tableu/BI over Streamlit? Is there any advantage?,"Asides from skill issue

Is there any benefit to using Tableu/BI over streamlit given that coding isn't the issue? ",datascience,https://www.reddit.com/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,30,6,0.63,"[Comment(id='k48z3lk'), Comment(id='k48zzkd'), Comment(id='k490z7j'), Comment(id='k48w3ar'), Comment(id='k4bvlwm'), Comment(id='k49llm4'), Comment(id='k4aauwo'), Comment(id='k4cygff'), Comment(id='k4ed330'), Comment(id='k49ewvp'), Comment(id='k4bp26n'), Comment(id='k4cx6vz'), Comment(id='k49eopa'), Comment(id='k4btuac'), Comment(id='k48woxm'), Comment(id='k4c4v6s'), Comment(id='k49fmn1'), Comment(id='k4d48sn'), Comment(id='k49s91x'), Comment(id='k49erhm'), Comment(id='k48xawj'), Comment(id='k4c51sb'), Comment(id='k49gap4'), Comment(id='k4a2a4u'), Comment(id='k4e00bv'), Comment(id='k4e01gd'), Comment(id='k49gbnf'), Comment(id='k4cmygk'), Comment(id='k4e1faw'), Comment(id='k4d31nc')]"
174dzeb,mingzhouren,,2023-10-10 06:01:32+00:00,False,,False,False,True,False,/r/datascience/comments/174dzeb/explainable_boosting_machines/,Explainable boosting machines,Just curious how many people out there favor explainable boosting machines over bread and butter methods like lgbm or xgbm. Should I learn this or is it a fad?,datascience,https://www.reddit.com/r/datascience/comments/174dzeb/explainable_boosting_machines/,13,6,1.0,"[Comment(id='k4b9tps'), Comment(id='k4acoyo'), Comment(id='k4a23in'), Comment(id='k48p5hc'), Comment(id='k4cscyc'), Comment(id='k4bjg7i'), Comment(id='k4bjn0k'), Comment(id='k4bjyht'), Comment(id='k4doz7o'), Comment(id='k4bjqcj'), Comment(id='k4c1k51'), Comment(id='k4bl6h6'), Comment(id='k4dwwh4')]"
173txze,Exotic_Avocado6164,,2023-10-09 14:59:08+00:00,False,,False,False,True,False,/r/datascience/comments/173txze/data_scientists_how_many_hours_a_week_do_you_work/,Data scientists - How many hours a week do you work?,,datascience,https://www.reddit.com/r/datascience/comments/173txze/data_scientists_how_many_hours_a_week_do_you_work/,77,93,0.89,"[Comment(id='k4595hl'), Comment(id='k45v38q'), Comment(id='k465fz8'), Comment(id='k46nqzs'), Comment(id='k459ws7'), Comment(id='k468f36'), Comment(id='k476o5x'), Comment(id='k45k91y'), Comment(id='k480olb'), Comment(id='k467isa'), Comment(id='k4679ct'), Comment(id='k45o6yq'), Comment(id='k451quv'), Comment(id='k48tteu'), Comment(id='k48eefh'), Comment(id='k45nqkl'), Comment(id='k479pts'), Comment(id='k45g4iy'), Comment(id='k47vsxz'), Comment(id='k48x39z'), Comment(id='k491vwz'), Comment(id='k47gcd6'), Comment(id='k470rnn'), Comment(id='k48aksa'), Comment(id='k481jmp'), Comment(id='k46qeer'), Comment(id='k45gb2e'), Comment(id='k47rgn2'), Comment(id='k47ysab'), Comment(id='k48ojl5'), Comment(id='k4a9q2s'), Comment(id='k4alq3t'), Comment(id='k4aznfb'), Comment(id='k4ba1gt'), Comment(id='k4bme1d'), Comment(id='k4bvoj5'), Comment(id='k4c0kqu'), Comment(id='k4ccnpy'), Comment(id='k4dwhch'), Comment(id='k4jisci'), Comment(id='k4kgpw9'), Comment(id='k47pcec'), Comment(id='k45mug7'), Comment(id='k48opo2'), Comment(id='k4788z8'), Comment(id='k47b9c2'), Comment(id='k482v5y'), Comment(id='k48nfez'), Comment(id='k4eed6m'), Comment(id='k45oi55'), Comment(id='k4jindf'), Comment(id='k4a2aqe'), Comment(id='k46ocym'), Comment(id='k49nkv0'), Comment(id='k460tbv'), Comment(id='k45j6qi'), Comment(id='k4dw1f2'), Comment(id='k471s7k'), Comment(id='k48owo6'), Comment(id='k4c4wum'), Comment(id='k49bhih'), Comment(id='k48ox6e'), Comment(id='k4aq9uq'), Comment(id='k475xlj'), Comment(id='k478bjd'), Comment(id='k49oaup'), Comment(id='k45jr9r'), Comment(id='k4847m2'), Comment(id='k479lsc'), Comment(id='k45qew9'), Comment(id='k4610la'), Comment(id='k45wjx2'), Comment(id='k47eq2h'), Comment(id='k46kc00'), Comment(id='k47pj6i'), Comment(id='k47ub7u'), Comment(id='k4841em'), Comment(id='k484my5')]"
17404sl,Expendable_0,,2023-10-09 19:08:14+00:00,False,,False,False,True,False,/r/datascience/comments/17404sl/are_you_happy_with_your_job/,Are you happy with your job?,"I see so many complaints of people who hate their job or can't find one. I am starting to wonder if this industry is awful and I have just been lucky, or if the negatives just pop up more.

How happy are you with your job?",datascience,https://www.reddit.com/r/datascience/comments/17404sl/are_you_happy_with_your_job/,47,39,0.87,"[Comment(id='k46e9tu'), Comment(id='k46ha5l'), Comment(id='k46jmnd'), Comment(id='k46fzof'), Comment(id='k46sr3m'), Comment(id='k467j6r'), Comment(id='k47ip0e'), Comment(id='k4aghny'), Comment(id='k46bj03'), Comment(id='k46bkax'), Comment(id='k483be9'), Comment(id='k4973p2'), Comment(id='k4alo9g'), Comment(id='k485iqz'), Comment(id='k46y2v7'), Comment(id='k4732nv'), Comment(id='k4737fp'), Comment(id='k474ahy'), Comment(id='k47l84n'), Comment(id='k47p2n9'), Comment(id='k47r7m7'), Comment(id='k484iiw'), Comment(id='k485vig'), Comment(id='k48a4x6'), Comment(id='k48ihdv'), Comment(id='k48mqmo'), Comment(id='k48sah8'), Comment(id='k48t1ku'), Comment(id='k48tqex'), Comment(id='k48ws10'), Comment(id='k491abk'), Comment(id='k49eqnt'), Comment(id='k4acq33'), Comment(id='k4ba54a'), Comment(id='k4fms6j'), Comment(id='k4gom2o'), Comment(id='k471st8'), Comment(id='k4cco3q'), Comment(id='k46eh6x'), Comment(id='k4azrho'), Comment(id='k46szcu'), Comment(id='k492s17'), Comment(id='k4onj10'), Comment(id='k4ap0i0'), Comment(id='k48scno'), Comment(id='k4azuxp'), Comment(id='k49iu4b'), Comment(id='k4bebbm')]"
173ubu3,Federal_Nose_6428,,2023-10-09 15:14:40+00:00,False,,False,False,True,False,/r/datascience/comments/173ubu3/what_are_some_red_flags_to_look_out_for_in_a_job/,What are some red flags to look out for in a job interview for a data job?,,datascience,https://www.reddit.com/r/datascience/comments/173ubu3/what_are_some_red_flags_to_look_out_for_in_a_job/,60,66,0.93,"[Comment(id='k45r2ik'), Comment(id='k47jigl'), Comment(id='k456123'), Comment(id='k468kb7'), Comment(id='k46lps9'), Comment(id='k47pdi7'), Comment(id='k46xo0l'), Comment(id='k45ud75'), Comment(id='k46x25z'), Comment(id='k48r4p8'), Comment(id='k48hz83'), Comment(id='k45f32r'), Comment(id='k49qhzs'), Comment(id='k4a0ds0'), Comment(id='k46rzj9'), Comment(id='k4b9v8v'), Comment(id='k49kfb5'), Comment(id='k4cjoxa'), Comment(id='k4euoz0'), Comment(id='k4fffb8'), Comment(id='k4i78ub'), Comment(id='k491b92'), Comment(id='k49ekzh'), Comment(id='k49p7t1'), Comment(id='k4cuoyl'), Comment(id='k49dgoj'), Comment(id='k491d0v'), Comment(id='k4fl4zv'), Comment(id='k456eou'), Comment(id='k45b5zm'), Comment(id='k488rts'), Comment(id='k48xx1r'), Comment(id='k491h3p'), Comment(id='k4am5mz'), Comment(id='k4fe5ja'), Comment(id='k47ui0t'), Comment(id='k48oalq'), Comment(id='k491o7v'), Comment(id='k4666jq'), Comment(id='k4fh4s6'), Comment(id='k4fh6i9'), Comment(id='k4fn242'), Comment(id='k4fljp5'), Comment(id='k49gxx3'), Comment(id='k49kaso'), Comment(id='k4g2jb9'), Comment(id='k4cuvqz'), Comment(id='k4cxjmc'), Comment(id='k4cxfpa'), Comment(id='k4g29ot'), Comment(id='k45cjnm'), Comment(id='k45fjb3'), Comment(id='k47cxhy'), Comment(id='k4f8lmd'), Comment(id='k4gcqme'), Comment(id='k46dp9w'), Comment(id='k491lkv'), Comment(id='k4evmml'), Comment(id='k47xs4g'), Comment(id='k4998v1'), Comment(id='k47yg4m'), Comment(id='k4f3c6m')]"
1740tx7,career-throwaway-oof,,2023-10-09 19:36:40+00:00,False,,1696880385.0,False,True,False,/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,How to work with product managers,"Hi all, I’m in the midst of a job search and one question I’ve been asked a few times is how I work with product managers. 

In truth, I’ve worked with product managers very little, and when I did, the partnerships were not fruitful. They generally wanted me to do exactly what they asked with minimal input from me on whether that task was worthwhile. In the worst cases, it felt like my entire job was just to keep the PM happy. This is quite different from my interactions with other stakeholders like managers, execs, etc, who have typically valued a more collaborative approach. I don’t know if this is typical—just my experience. 

Rather than ask for interview advice, I’m hoping I can prompt a more interesting discussion here on how to work well with product managers. What makes a good product manager? When is it worth pushing back on requests, and when should we just put our heads down and do what is asked? How do you balance the needs of PMs with those of other stakeholders?",datascience,https://www.reddit.com/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,14,22,0.93,"[Comment(id='k46g4ug'), Comment(id='k470jk5'), Comment(id='k46cjfk'), Comment(id='k46vslf'), Comment(id='k47hb41'), Comment(id='k48jhfq'), Comment(id='k47v77o'), Comment(id='k47x5bl'), Comment(id='k46vge8'), Comment(id='k48j3j1'), Comment(id='k4d476n'), Comment(id='k46x4dy'), Comment(id='k4k7sc8'), Comment(id='k4mvux8')]"
173l7aj,foreignparent,,2023-10-09 06:43:06+00:00,False,,False,False,True,False,/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,Most valuable data science project you've worked on for a company?,"(Previous post was removed for unclear reason)

I'm curious to hear about the impactful data science projects you've had the opportunity to work on in the corporate world. Whether it's in healthcare, finance, e-commerce, or any other industry, I'd love to know about the projects that made a significant difference.

I understand it may not be possible to go into details, but please share your experiences:

1. The industry or sector you were working in.
2. A brief description of the project.
3. The impact or results the project had on the company. 

Just to clarify, when I say “valuable” I mean from the company’s perspective.",datascience,https://www.reddit.com/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,34,57,0.96,"[Comment(id='k44jrhf'), Comment(id='k43oecx'), Comment(id='k448vyi'), Comment(id='k43yu5r'), Comment(id='k44habs'), Comment(id='k44x6qt'), Comment(id='k44s7b4'), Comment(id='k44vkg0'), Comment(id='k457ycz'), Comment(id='k46o385'), Comment(id='k44fio9'), Comment(id='k447g9k'), Comment(id='k45rmbs'), Comment(id='k46r2rp'), Comment(id='k44img2'), Comment(id='k467d6l'), Comment(id='k46rcxb'), Comment(id='k49il2s'), Comment(id='k45xy15'), Comment(id='k492vk9'), Comment(id='k44dmlc'), Comment(id='k44hbwv'), Comment(id='k44a8gr'), Comment(id='k444mwn'), Comment(id='k469x0c'), Comment(id='k4696us'), Comment(id='k469sge'), Comment(id='k469hja'), Comment(id='k469by7'), Comment(id='k46dnja'), Comment(id='k447455'), Comment(id='k46lrga'), Comment(id='k48w5uk'), Comment(id='k48xbm3')]"
173hj19,derpgod123,,2023-10-09 03:01:41+00:00,False,,False,False,True,False,/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,Why aren't there more decision support algos for doctors for differential diagnosing?,"Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn't there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?

Shit, like I'm playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn't be that hard for a machine to do right? I can't imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account ",datascience,https://www.reddit.com/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,52,47,0.91,"[Comment(id='k43na9y'), Comment(id='k432nig'), Comment(id='k43qtpl'), Comment(id='k431y9a'), Comment(id='k43ix8v'), Comment(id='k43wquf'), Comment(id='k435bnv'), Comment(id='k435rwq'), Comment(id='k43nqgy'), Comment(id='k43r8d6'), Comment(id='k436lj5'), Comment(id='k43astm'), Comment(id='k43sor1'), Comment(id='k43ixou'), Comment(id='k43wofv'), Comment(id='k43wyrc'), Comment(id='k44kg8d'), Comment(id='k44pczp'), Comment(id='k45xtnk'), Comment(id='k47h1eb'), Comment(id='k47hu3t'), Comment(id='k48gxj5'), Comment(id='k44s5e0'), Comment(id='k448cui'), Comment(id='k44fyqy'), Comment(id='k45rctg'), Comment(id='k48jt30'), Comment(id='k442wut'), Comment(id='k43yfrj'), Comment(id='k44hul4'), Comment(id='k44n1j6'), Comment(id='k44xlpj'), Comment(id='k4565xq'), Comment(id='k440kk9'), Comment(id='k433j0o'), Comment(id='k469bsh'), Comment(id='k433qsg'), Comment(id='k44jbcs'), Comment(id='k436ev9'), Comment(id='k43tuju'), Comment(id='k44qq4s'), Comment(id='k443a7d'), Comment(id='k44y7z8'), Comment(id='k49fxyw'), Comment(id='k48lmiw'), Comment(id='k48l9hc'), Comment(id='k44j49b'), Comment(id='k43yqwc'), Comment(id='k447i6z'), Comment(id='k49ix17'), Comment(id='k44rux8')]"
173hmq4,Ok_Post_149,,2023-10-09 03:06:59+00:00,False,,1696822436.0,False,True,False,/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,What data science tools have the best user experience?,"Data Science community, I've got a question for you:

Which data science tools do you find most user-friendly?

I just went live with a project I've been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I'm working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you're able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn't mind a few people ripping everything that sucks with the user experience.

Anyways, I'd love to learn about everyone's favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.

Project link: [https://www.burla.dev/](https://www.burla.dev/)",datascience,https://www.reddit.com/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,18,22,0.77,"[Comment(id='k4322c9'), Comment(id='k43268p'), Comment(id='k440au8'), Comment(id='k43y6ri'), Comment(id='k45wzpt'), Comment(id='k47oeom'), Comment(id='k432xbe'), Comment(id='k432zly'), Comment(id='k45ouzr'), Comment(id='k43nuzb'), Comment(id='k4348wc'), Comment(id='k468f8i'), Comment(id='k45oihs'), Comment(id='k45oo65'), Comment(id='k434v6r'), Comment(id='k445byg'), Comment(id='k48sjh8'), Comment(id='k49r9fi')]"
173broc,Sensitive-Main-6700,,2023-10-08 22:22:16+00:00,False,,1696808736.0,False,True,False,/r/datascience/comments/173broc/how_to_validate_data/,How to validate data?,"I'm an SWE (**not a data scientist**) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.

I started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don't think they solve the issue of validating *changes in data* (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.

What I'm looking for is a tool that validates changes in data by comparing the previous value with the new value.

In some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there's obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).

This is just an example, but it would be helpful if we can call an API to do this sort of validation for us.

And instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I'm just brainstorming here.

Would highly appreciate some recommendations/tips for tackling this problem. Thank you!",datascience,https://www.reddit.com/r/datascience/comments/173broc/how_to_validate_data/,23,52,0.9,"[Comment(id='k41yq9a'), Comment(id='k421tol'), Comment(id='k422sj4'), Comment(id='k421dna'), Comment(id='k422ynx'), Comment(id='k43mi1n'), Comment(id='k41yjnk'), Comment(id='k423dyc'), Comment(id='k423io6'), Comment(id='k427om7'), Comment(id='k42ot9n'), Comment(id='k43b5x9'), Comment(id='k43b757'), Comment(id='k43l2n0'), Comment(id='k43ncs5'), Comment(id='k43qoo8'), Comment(id='k43rtsf'), Comment(id='k43wmjy'), Comment(id='k43x7bu'), Comment(id='k4252lx'), Comment(id='k43wt3o'), Comment(id='k43r6i6'), Comment(id='k4aebfg')]"
173yyz7,Candid-Translator-89,,2023-10-09 18:22:15+00:00,False,,False,False,True,False,/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,Is there a good industry use of stable diffusion that I'm not aware of?,Working on a deep learning project with some friends. They really want to build something with SD. Will I be able to use these skills in industry?,datascience,https://www.reddit.com/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,3,1,0.67,"[Comment(id='k477yp7'), Comment(id='k49g1j3'), Comment(id='k48crau')]"
172zdgx,cazzobomba,,2023-10-08 13:38:28+00:00,False,,False,False,True,False,/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,How do data scientist managers manage data scientists?,"As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?

Some of my thoughts:

1. As a manager, I can support my DSs by **NOT** micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.

2. I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. 

3. There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. 

4. The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team’s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. 

5. Some managers think PD is solely the DS’s responsibility. Thoughts?

6. How do you deal with HR when there are no clear DS role descriptions?

Not a simple optimization problem!",datascience,https://www.reddit.com/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,56,120,0.95,"[Comment(id='k3zv5vr'), Comment(id='k3zskda'), Comment(id='k406kuj'), Comment(id='k40e484'), Comment(id='k40laxh'), Comment(id='k40y9xd'), Comment(id='k4006ff'), Comment(id='k40i917'), Comment(id='k40tqm3'), Comment(id='k430ft4'), Comment(id='k40girr'), Comment(id='k40drfp'), Comment(id='k41fq14'), Comment(id='k41qazt'), Comment(id='k41uik3'), Comment(id='k428fl7'), Comment(id='k439u22'), Comment(id='k443vk2'), Comment(id='k419h6n'), Comment(id='k418csp'), Comment(id='k40riq8'), Comment(id='k41u615'), Comment(id='k40o9t3'), Comment(id='k40qume'), Comment(id='k437eyk'), Comment(id='k40l9c8'), Comment(id='k404pbh'), Comment(id='k40ffhv'), Comment(id='k4007ui'), Comment(id='k40qada'), Comment(id='k434u9b'), Comment(id='k434ehz'), Comment(id='k41mstb'), Comment(id='k422r3w'), Comment(id='k41ntgo'), Comment(id='k40tdd5'), Comment(id='k4199e9'), Comment(id='k41rdb8'), Comment(id='k43vfmb'), Comment(id='k40hfr2'), Comment(id='k40us6a'), Comment(id='k4351sz'), Comment(id='k43ad8v'), Comment(id='k44ixb9'), Comment(id='k40uw10'), Comment(id='k436i3d'), Comment(id='k40v1qs'), Comment(id='k412wqt'), Comment(id='k42m2m7'), Comment(id='k454pcn'), Comment(id='k413quf'), Comment(id='k439df5'), Comment(id='k45g57r'), Comment(id='k43ykos'), Comment(id='k46cri9'), Comment(id='k440xf6')]"
173cl4s,,,2023-10-08 22:59:12+00:00,False,,False,False,True,False,/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,Is it possible to automate the labeling of strings of text?,"A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.

This seems like a problem for NLP but I'm unsure of where to start or just not confident. It's been at least 7 years since I've done any real 'data science' stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you've used that you like and could share.

Am I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?

I'm really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I'm not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?

Thanks for your thoughtfulness on this :)",datascience,https://www.reddit.com/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,22,15,0.9,"[Comment(id='k4243pl'), Comment(id='k42c9xi'), Comment(id='k46bna1'), Comment(id='k46r0r3'), Comment(id='k43trqs'), Comment(id='k43iu62'), Comment(id='k476b9m'), Comment(id='k4783dl'), Comment(id='k4ihp48'), Comment(id='k433qpq'), Comment(id='k4g9rdj'), Comment(id='k42f4lx'), Comment(id='k46ydgo'), Comment(id='k444u7i'), Comment(id='k44kp6f'), Comment(id='k43r4b7'), Comment(id='k478quq'), Comment(id='k43p987'), Comment(id='k46zwe6'), Comment(id='k44fp1j'), Comment(id='k4ii003'), Comment(id='k4741bc')]"
173izkk,Ok_Waltz_5145,,2023-10-09 04:23:12+00:00,False,,False,False,True,False,/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,What is the best package /approach for matching text in python?,"I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?",datascience,https://www.reddit.com/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,2,5,0.86,"[Comment(id='k43vxiz'), Comment(id='k43gz9o')]"
173im0f,AutoModerator,,2023-10-09 04:01:25+00:00,False,,False,False,True,False,/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/,"Weekly Entering & Transitioning - Thread 09 Oct, 2023 - 16 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/,83,6,1.0,"[Comment(id='k45hnzr'), Comment(id='k4ce35o'), Comment(id='k4bnmrt'), Comment(id='k4qswvz'), Comment(id='k439tu6'), Comment(id='k45ix8i'), Comment(id='k46fp42'), Comment(id='k46zfal'), Comment(id='k485kf9'), Comment(id='k48c51h'), Comment(id='k48ib26'), Comment(id='k48la36'), Comment(id='k49l8u3'), Comment(id='k49l99d'), Comment(id='k49ypvo'), Comment(id='k4b5cu8'), Comment(id='k4c08jg'), Comment(id='k4c59ka'), Comment(id='k4cr7yu'), Comment(id='k4d2pqn'), Comment(id='k4dpvwj'), Comment(id='k4e3f4q'), Comment(id='k4f565h'), Comment(id='k4gbwlv'), Comment(id='k4gdzk7'), Comment(id='k4gf6mg'), Comment(id='k4h2tin'), Comment(id='k4hf22l'), Comment(id='k4lhb94'), Comment(id='k4ml68y'), Comment(id='k4n180b'), Comment(id='k4oc951'), Comment(id='k4shgwe'), Comment(id='k4td4c8'), Comment(id='k4u2osu'), Comment(id='k4vk7xv'), Comment(id='k50temo'), Comment(id='k52kc78'), Comment(id='k45qtig'), Comment(id='k45pif1'), Comment(id='k4kpbf3'), Comment(id='k4979x8'), Comment(id='k48tict'), Comment(id='k4dwklq'), Comment(id='k49r9kx'), Comment(id='k4xi6zc'), Comment(id='k4la7no'), Comment(id='k4rvmvp'), Comment(id='k4xhwez'), Comment(id='k4pf2y4'), Comment(id='k4r3occ'), Comment(id='k4rvdum'), Comment(id='k4kr8ya'), Comment(id='k4xgs00'), Comment(id='k4pivmt'), Comment(id='k4pehdi'), Comment(id='k4ruljj'), Comment(id='k4xfw39'), Comment(id='k527zpr'), Comment(id='k4fqdrf'), Comment(id='k4603wa'), Comment(id='k4krz1i'), Comment(id='k4lfwni'), Comment(id='k4a3jhp'), Comment(id='k4m7jgg'), Comment(id='k4u86k3'), Comment(id='k4rewnf'), Comment(id='k4yxiw7'), Comment(id='k780beg'), Comment(id='k4fvl2c'), Comment(id='k462t2k'), Comment(id='k4pceoq'), Comment(id='k4uob1i'), Comment(id='k4xh5lb'), Comment(id='k4zo3fw'), Comment(id='k78oajb'), Comment(id='k4gsaze'), Comment(id='k468sv4'), Comment(id='k4vrkkx'), Comment(id='k4zoy2g'), Comment(id='k78qkfm'), Comment(id='k46ag0d'), Comment(id='k78rwpe'), Comment(id='k46g0e8')]"
173dd6h,,,2023-10-08 23:34:25+00:00,False,,False,False,True,False,/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,What advice would you give someone starting out on learning to collaborate on large projects and not be the sole person responsible for a model build?,"I'm starting out on a team that is very collaborative and I've realized that while I've worked with other people before, I'm not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. 

Does anyone have advice for dealing with what almost feels like getting territorial over a model? It's nothing against the people on my team - they've all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like ""I built that."" It also almost feels like it's my fault for not being able to do all of the work myself, like if I was a better worker I'd be able to get more of the work done and people wouldn't have to pick up my slack.

Is this something that just goes away with time if you continue working on a team that works in this way? I didn't expect there to be an emotional challenge component to this and I'm struggling to know what to do and how to adapt, especially because this doesn't feel like the kind of thing you can really share/get support from coworkers on, because they're the ones working on it with me if that makes sense.",datascience,https://www.reddit.com/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,3,11,1.0,"[Comment(id='k43k12v'), Comment(id='k42hws3'), Comment(id='k42zske')]"
173cxz4,EcstaticStructure830,,2023-10-08 23:14:48+00:00,False,,False,False,True,False,/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/,"What is currently the most in demand Analytics/DS by Healthcare institutions (hospitals, clinics, big pharma, government, etc.)?",,datascience,https://www.reddit.com/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/,2,7,0.82,"[Comment(id='k42cd1p'), Comment(id='k43qiua')]"
172gy7a,dopplegangery,,2023-10-07 21:08:48+00:00,False,,False,False,True,False,/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,"Should we use non-linear models for ""linear"" data?","So I had an argument with an interviewer who asked me why I didn't just use a non-linear classification model on the linearly separable data that I had in one of my projects that I described to him, even though I had no computational constraints. I told him that it was because, irrespective of computational cost, a linear model is always preferable if you have linear data because it is simpler and captures general pattern while non-linear models might overfit on  local patterns. But he kept disagreeing and saying that the only advantage that a linear model would have is computational cost and explainability even though I was actually getting better results with a logistic regression.

Who do you think was missing something here and why?",datascience,https://www.reddit.com/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,123,159,0.95,"[Comment(id='k3wlel7'), Comment(id='k3wpzmq'), Comment(id='k3wm9xj'), Comment(id='k3wm6rg'), Comment(id='k3wt6nt'), Comment(id='k3wv1bu'), Comment(id='k3wlocb'), Comment(id='k3x6pz7'), Comment(id='k3x01te'), Comment(id='k3x243y'), Comment(id='k3x88yj'), Comment(id='k3x5k2s'), Comment(id='k3wv81r'), Comment(id='k3wwz5y'), Comment(id='k3wy2is'), Comment(id='k3x77v4'), Comment(id='k3xa4ti'), Comment(id='k400ltn'), Comment(id='k40513j'), Comment(id='k3wslpb'), Comment(id='k3wt2fh'), Comment(id='k3xgqgc'), Comment(id='k3wutmv'), Comment(id='k3xivis'), Comment(id='k3y8nw5'), Comment(id='k3ypmqw'), Comment(id='k3zc4k5'), Comment(id='k3zi3y5'), Comment(id='k3zo6wz'), Comment(id='k40ejpr'), Comment(id='k40fzt4'), Comment(id='k40g6ff'), Comment(id='k40oia8'), Comment(id='k43nqae'), Comment(id='k3z11kb'), Comment(id='k3wwovs'), Comment(id='k3zd3wr'), Comment(id='k3yfbev'), Comment(id='k3yfy9x'), Comment(id='k3x9itg'), Comment(id='k3yfsj4'), Comment(id='k41dre2'), Comment(id='k41e5je'), Comment(id='k3xrk0h'), Comment(id='k3x6edx'), Comment(id='k3wx7dl'), Comment(id='k3xkesd'), Comment(id='k41fq1g'), Comment(id='k43ayps'), Comment(id='k408n0n'), Comment(id='k3x6q0g'), Comment(id='k3x69lz'), Comment(id='k3xsx4z'), Comment(id='k3x4ic8'), Comment(id='k3xw7cy'), Comment(id='k3yevmi'), Comment(id='k3yeown'), Comment(id='k3zsz0v'), Comment(id='k40f4ao'), Comment(id='k40h6bx'), Comment(id='k40uv1e'), Comment(id='k3znsgg'), Comment(id='k40re9m'), Comment(id='k41d1ph'), Comment(id='k3yj1t2'), Comment(id='k3yhswa'), Comment(id='k3xmu5a'), Comment(id='k3xmu8m'), Comment(id='k3wxdsw'), Comment(id='k3x87nj'), Comment(id='k3ysjft'), Comment(id='k3xw2up'), Comment(id='k3xwwq5'), Comment(id='k40nppk'), Comment(id='k40kc1h'), Comment(id='k41fm2k'), Comment(id='k41d8qw'), Comment(id='k41fcrl'), Comment(id='k3yrkw4'), Comment(id='k41hs3x'), Comment(id='k3xwc8h'), Comment(id='k3xqbbf'), Comment(id='k3wxzm8'), Comment(id='k3xjui8'), Comment(id='k3xqny2'), Comment(id='k3x8t9g'), Comment(id='k3xyl8e'), Comment(id='k41ekk6'), Comment(id='k41u1x7'), Comment(id='k40qiv4'), Comment(id='k40v399'), Comment(id='k41mzt3'), Comment(id='k41fu5m'), Comment(id='k47i4n6'), Comment(id='k41t8qi'), Comment(id='k3xs3vl'), Comment(id='k3y5vxh'), Comment(id='k3xvb67'), Comment(id='k3xrz6l'), Comment(id='k3xqwb2'), Comment(id='k3x9dsp'), Comment(id='k3ysn3r'), Comment(id='k41f3hh'), Comment(id='k40zcx8'), Comment(id='k41nxzl'), Comment(id='k41loa1'), Comment(id='k47q9sz'), Comment(id='k43ks2o'), Comment(id='k3xsrud'), Comment(id='k3y6tub'), Comment(id='k3y91ei'), Comment(id='k3ytj98'), Comment(id='k3z1zrb'), Comment(id='k41knq6'), Comment(id='k41tm0o'), Comment(id='k41ob61'), Comment(id='k41mqnk'), Comment(id='k40tynr'), Comment(id='k3z4ikr'), Comment(id='k41ojvh'), Comment(id='k41or6n'), Comment(id='k422s4p'), Comment(id='k41q4ni'), Comment(id='k41qn1h'), <MoreComments count=0, children=[]>]"
17369yn,fhckgkgkgjdh,,2023-10-08 18:31:50+00:00,False,,False,False,True,False,/r/datascience/comments/17369yn/running_arima_models/,Running ARIMA Models,Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!,datascience,https://www.reddit.com/r/datascience/comments/17369yn/running_arima_models/,3,3,0.72,"[Comment(id='k416br8'), Comment(id='k42cqlz'), Comment(id='k43frda')]"
1731r1r,nuriel8833,,2023-10-08 15:19:43+00:00,False,,False,False,True,False,/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,Automation of insights extraction from Clustering,"So I've been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don't think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?

The only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don't know how much I'm up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let's say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).

Is there even any method to do that? Or should I just insist that it is not feasible?  
Thanks",datascience,https://www.reddit.com/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,0,2,0.76,[]
17316vc,AutomaticResearch337,,2023-10-08 14:57:58+00:00,False,,False,False,True,False,/r/datascience/comments/17316vc/image_detection_with_cnn_model/,Image Detection with CNN Model,"I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. 

I don't know how will i link the annotated JSON file of the images when training. Does anyone know how?",datascience,https://www.reddit.com/r/datascience/comments/17316vc/image_detection_with_cnn_model/,9,2,0.67,"[Comment(id='k4083wj'), Comment(id='k4108dl'), Comment(id='k43df3o'), Comment(id='k7wedu4'), Comment(id='k4ef4q8'), Comment(id='k44s6ta'), Comment(id='k4ef7u6'), Comment(id='k4efayn'), Comment(id='k4eggyh')]"
17212yf,HStuart18,,2023-10-07 08:19:09+00:00,False,,1696733213.0,False,True,False,/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,Why are there no good graph visualisation programs?,"Does anyone know of any half decent graph/network visualisation programs? Gephi is very frustrating to use (can only view up to 20 attribute columns at once, can't inspect node/edge attributes from the graph view, attribute values only allow you to copy the abbreviated scientific notation form etc.)

This is what I am trying to do... I have a graph (heterogenous but I can compress it to homogenous if absolutely necessary) and I want to be able to interactively visualise said graph. If I click on a node or edge, I wish to be able to see the attributes of that node or edge. Preferably, I'd also be able to colour nodes and edges by attribute.

There seems to be a few small bespoke projects but from the few I've tried, none have achieved what I have outlined above - what I would have thought to be the bare minimum for a graph visualisation application.

&#x200B;

**EDIT**

Cytoscape standalone is definitely the way to go for me. Would highly recommend over Gephi. Still had to flatten my heterogenous graph, appending all attributes across all types, but with a specified `TYPE` attribute you can conditionally colour within Cytoscape so it gets you there in the end (bit annoying that every node/edge has redundant attributes from other node/edge types but it's not the end of the world.) Thanks for all the suggestions.",datascience,https://www.reddit.com/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,40,77,0.9,"[Comment(id='k3u5ia6'), Comment(id='k3tw1hh'), Comment(id='k3tuscs'), Comment(id='k3uks9y'), Comment(id='k3ui37f'), Comment(id='k3w4556'), Comment(id='k3v3xa4'), Comment(id='k3u01v0'), Comment(id='k3uoduj'), Comment(id='k3v0bf5'), Comment(id='k3v7ftg'), Comment(id='k3vjv8d'), Comment(id='k3vx33v'), Comment(id='k3tv630'), Comment(id='k3ujtbw'), Comment(id='k3vfwyv'), Comment(id='k3vqd7n'), Comment(id='k3vsktt'), Comment(id='k3wc8d2'), Comment(id='k3wnvsj'), Comment(id='k42vjzs'), Comment(id='k4a570y'), Comment(id='k4hfk6h'), Comment(id='k3u6cba'), Comment(id='k3u1mkw'), Comment(id='k3u1ftg'), Comment(id='k3uvfy0'), Comment(id='k3u2282'), Comment(id='k3vupqe'), Comment(id='k3ws5lx'), Comment(id='k3u2dpa'), Comment(id='k42yaci'), Comment(id='k3u909t'), Comment(id='k3u7zt1'), Comment(id='k3upd7k'), Comment(id='k3uu3lo'), Comment(id='k3vjy4n'), Comment(id='k3wvhlf'), Comment(id='k3u8bpq'), Comment(id='k3yow0d')]"
1726i2h,Skilinger,,2023-10-07 13:33:11+00:00,False,,False,False,True,False,/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,How do I make use of other parameters' forecasts for time series forecasting?,"Topic might be a bit confusing, let me elaborate. For example let's say I'm working on a time series forecasting problem and I found that temperature is highly correlated with my target. But I also know it's a time series problem, so I want to boost my model by giving it probable temperature for the target dates. How do I do that? I can't wrap my head around it",datascience,https://www.reddit.com/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,15,7,0.78,"[Comment(id='k3uy9gj'), Comment(id='k3vi39v'), Comment(id='k3ut9p8'), Comment(id='k3vdgk2'), Comment(id='k3wlws1'), Comment(id='k3xdwut'), Comment(id='k4029sh'), Comment(id='k3vwi4m'), Comment(id='k3uy3jf'), Comment(id='k3v28qu'), Comment(id='k3vd17u'), Comment(id='k3vw60p'), Comment(id='k3vg1wl'), Comment(id='k3vx4vh'), Comment(id='k3vzdom')]"
172ko0y,jrdubbleu,,2023-10-07 23:51:53+00:00,False,,False,False,True,False,/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,Data Cleaning & Wrangling Standards?,"Are there any industry standard frameworks for data cleaning and wrangling? Naming conventions, order of operations (when to do imputation, detecting careless cases, etc.) that companies and researchers use to make shareable uniform datasets?",datascience,https://www.reddit.com/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,4,0,0.5,"[Comment(id='k405vme'), Comment(id='k3xc77t'), Comment(id='k41b75l'), Comment(id='k465tj8')]"
172subu,shostakophiles,,2023-10-08 07:13:14+00:00,False,,False,False,True,False,/r/datascience/comments/172subu/a_controversial_request_but_please_help_me_out_in/,"a controversial request, but please help me out in defending that sarcasm doesn't affect sentiment analysis","bit more context— me and my groupmates are conducting a study in which we would determine a person's MBTI (a personality classification method) based on their posts on twitter using sentiment analysis. 

since our research focuses on personality classification instead of identifying a statement's positive and negative connotations, we decided to exclude sarcasm out of the equation since we treat every user's word as a determining factor of their MBTI. but our thesis moderator asked the concern regarding sarcasm out of curiosity and we still have quite some struggles defending this idea.

any help would be appreciated, thanks!",datascience,https://www.reddit.com/r/datascience/comments/172subu/a_controversial_request_but_please_help_me_out_in/,32,0,0.41,"[Comment(id='k3ys8se'), Comment(id='k3yzmao'), Comment(id='k3ynbx4'), Comment(id='k3z2vkg'), Comment(id='k3z016z'), Comment(id='k3zbpix'), Comment(id='k3zj01d'), Comment(id='k3z91m6'), Comment(id='k40fyf6'), Comment(id='k3zr5wz'), Comment(id='k3zf5y4'), Comment(id='k41vgg2'), Comment(id='k404q6m'), Comment(id='k3z3k09'), Comment(id='k41agwz'), Comment(id='k42lyb3'), Comment(id='k4knfxn'), Comment(id='k3z90bp'), Comment(id='k3z7x2w'), Comment(id='k41v8nz'), Comment(id='k3zgq5x'), Comment(id='k3zm4ng'), Comment(id='k3znj7l'), Comment(id='k3z9m59'), Comment(id='k40iw3f'), Comment(id='k3zvl5s'), Comment(id='k43jcff'), Comment(id='k4awad6'), Comment(id='k43j1s1'), Comment(id='k4b09tp'), Comment(id='k4b5u52'), Comment(id='k4b784o')]"
1729cnh,Aislin777,,2023-10-07 15:42:34+00:00,False,,1696693907.0,False,True,False,/r/datascience/comments/1729cnh/webbased_app_recommendations/,Web-based App Recommendations,"Hi all! 

I'm attempting to add some value at work. For context, I'm a Data Analytics Consultant at a small consulting firm where most of the data-related work is done by the DA team based out of India. The issue is that they just blew $10 million on a low-code app to streamline some of our company's offerings. Bottom line, it doesn't work and when it does it only works for cookie cutter cases. Regardless, they're the ones who get the funding and I'm the only Data Analyst in the US, where I was told they don't see the value in true DA/DS. What I would like to do is use open-source tools to recreate what the team in India was trying to do. Some of the base features would be being able to allow clients to fill out a survey of questions, read that to a SQL server I'll have to build, and publish multiple different dashboards (we currently use Tableau, but I figure I will need a web-based dashboard, such as Dash). 

When I was researching tools, they all read like ads, so I wanted to see what open-source tools others recommend from experience. For programming, I mainly use Python, though I am family with R as well. I'm also fine upskilling where needed, within reason (the bottleneck is time due to required chargeability at work and Master's coursework load).

Thanks in advance!

Edit: UI/UX will be pretty important since it is client work.",datascience,https://www.reddit.com/r/datascience/comments/1729cnh/webbased_app_recommendations/,8,3,1.0,"[Comment(id='k407xb2'), Comment(id='k47ppoy'), Comment(id='k3vb2a6'), Comment(id='k3xnsdj'), Comment(id='k41045r'), Comment(id='k481zwu'), Comment(id='k3wrec2'), Comment(id='k3yeb0w')]"
171jptd,mkworkplay,,2023-10-06 18:21:08+00:00,False,,False,False,True,False,/r/datascience/comments/171jptd/is_there_any_benefit_for_a_data_analyst_to_learn_c/,Is there any benefit for a Data Analyst to learn C#?,"I know that SQL and R / Python are the main languages to use, but is there any helpful reason to learn C#?",datascience,https://www.reddit.com/r/datascience/comments/171jptd/is_there_any_benefit_for_a_data_analyst_to_learn_c/,103,66,0.88,"[Comment(id='k3r2nr3'), Comment(id='k3r2i2w'), Comment(id='k3rimv8'), Comment(id='k3seaic'), Comment(id='k3rk203'), Comment(id='k3rvt01'), Comment(id='k3u1oz0'), Comment(id='k3rly1o'), Comment(id='k3sysg8'), Comment(id='k3r200a'), Comment(id='k3r7fod'), Comment(id='k3s5yjn'), Comment(id='k3sqb90'), Comment(id='k3tyrzl'), Comment(id='k3swtat'), Comment(id='k3rx14m'), Comment(id='k3t0iau'), Comment(id='k3t6v5x'), Comment(id='k3uxl7a'), Comment(id='k3v7m56'), Comment(id='k3vr4td'), Comment(id='k3xmin7'), Comment(id='k408thg'), Comment(id='k3r2i03'), Comment(id='k3rah4e'), Comment(id='k3s1ytd'), Comment(id='k3sb1je'), Comment(id='k3sno08'), Comment(id='k3rbax1'), Comment(id='k3rsxsy'), Comment(id='k3t3vyh'), Comment(id='k3txn82'), Comment(id='k3sik8i'), Comment(id='k3rb5um'), Comment(id='k3sil3f'), Comment(id='k3sqn5g'), Comment(id='k3t7uq7'), Comment(id='k3ue6ra'), Comment(id='k3wrmbk'), Comment(id='k3y9xeo'), Comment(id='k3yvt4y'), Comment(id='k41xqry'), Comment(id='k3tggru'), Comment(id='k3xqizn'), Comment(id='k3r8ot7'), Comment(id='k3rw97z'), Comment(id='k3rkyrl'), Comment(id='k3rvvnp'), Comment(id='k3rw8ei'), Comment(id='k3sqrfy'), Comment(id='k409hvo'), Comment(id='k3rbvdw'), Comment(id='k3rwveh'), Comment(id='k3rbdnf'), Comment(id='k3xrs84'), Comment(id='k3rbff3'), Comment(id='k3rgt85'), Comment(id='k3s0gmx'), Comment(id='k3rywzo'), Comment(id='k3su7my'), Comment(id='k3ufnqv'), Comment(id='k3rmxdh'), Comment(id='k3ruohk'), Comment(id='k3xixhw'), Comment(id='k3sr0yd'), Comment(id='k3t8ay7'), Comment(id='k3rj0q1'), Comment(id='k3tv5gt'), Comment(id='k3rcvub'), Comment(id='k3re26s'), Comment(id='k3rxtv1'), Comment(id='k3rwjei'), Comment(id='k3uj17q'), Comment(id='k3vrcls'), Comment(id='k3rqgi4'), Comment(id='k3tist8'), Comment(id='k3s9xrl'), Comment(id='k3x4m4m'), Comment(id='k3rqipq'), Comment(id='k3rxuyf'), Comment(id='k3ryffl'), Comment(id='k3rwxn4'), Comment(id='k3v6jsr'), Comment(id='k3vdet1'), Comment(id='k3uv747'), Comment(id='k3uhawa'), Comment(id='k3rvehz'), Comment(id='k3s53nh'), Comment(id='k3s2381'), Comment(id='k3s0mcb'), Comment(id='k3rx7ne'), Comment(id='k3vmyzq'), Comment(id='k3vjxa0'), Comment(id='k3ryejb'), Comment(id='k3sx772'), Comment(id='k3s5ujn'), Comment(id='k3ry404'), Comment(id='k3rxsde'), Comment(id='k3ryzp4'), Comment(id='k3rz971'), Comment(id='k3rzrvl'), <MoreComments count=0, children=[]>]"
171872q,pg860,,2023-10-06 09:52:28+00:00,False,,1696586317.0,False,True,False,/r/datascience/comments/171872q/the_most_soughtafter_data_science_skills/,The most sought-after Data Science skills,"I've analyzed 9,261 job openings' descriptions in Data Science, Machine Learning and ML OPS ([https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)) and prepared a list of the most sought-after skills. It turns out that the most desired skill is ... Communication - for all roles.

https://preview.redd.it/ey54l3290ksb1.png?width=2560&format=png&auto=webp&s=7a1746fa0d9ed2293374c54fce312a237d7d2eda

Communication actually surpasses Python in popularity, which I am really shocked about because it seems that for a Data Scientist, the most frequent communication should be with a computer.

https://preview.redd.it/b7ozarxq0ksb1.png?width=2560&format=png&auto=webp&s=3e8fc32e864ba4b0ed0edaf4e56daee4cadc6b62

About the dataset: 9,261 Job openings crawled from 1605 companies worldwide, between June-Sep 2023.",datascience,https://www.reddit.com/r/datascience/comments/171872q/the_most_soughtafter_data_science_skills/,89,314,0.94,"[Comment(id='k3p34te'), Comment(id='k3pbk3n'), Comment(id='k3p3n0u'), Comment(id='k3pc9sx'), Comment(id='k3ptn22'), Comment(id='k3pjppr'), Comment(id='k3qa8hr'), Comment(id='k3rr1rb'), Comment(id='k3p3ohs'), Comment(id='k3pemi6'), Comment(id='k3qft14'), Comment(id='k3qr6cy'), Comment(id='k3quk9a'), Comment(id='k3t9q5q'), Comment(id='k3pqko6'), Comment(id='k3q9n7t'), Comment(id='k3rdf7j'), Comment(id='k3rwypz'), Comment(id='k3rx7bs'), Comment(id='k3s6xcd'), Comment(id='k3s9mdw'), Comment(id='k3sgpv7'), Comment(id='k3ppktv'), Comment(id='k3pkv1v'), Comment(id='k3q6vgo'), Comment(id='k3qaq5f'), Comment(id='k3q0mas'), Comment(id='k3q5h3k'), Comment(id='k3r0nye'), Comment(id='k3r1aeb'), Comment(id='k3r6tue'), Comment(id='k3rc4vl'), Comment(id='k3s79mf'), Comment(id='k3sgifo'), Comment(id='k3u1j4z'), Comment(id='k3uisgw'), Comment(id='k3v2br6'), Comment(id='k3v9i0b'), Comment(id='k3wqwyb'), Comment(id='k41kd97'), Comment(id='k432gjj'), Comment(id='k7dja5l'), Comment(id='k3ph0jx'), Comment(id='k3riz6j'), Comment(id='k3q1c92'), Comment(id='k3sduo0'), Comment(id='k3qq43t'), Comment(id='k3s0wxa'), Comment(id='k3u7ocy'), Comment(id='k3rhsi2'), Comment(id='k3pr8r4'), Comment(id='k3u1vu9'), Comment(id='k3q1pef'), Comment(id='k3r5jm4'), Comment(id='k3r7zb2'), Comment(id='k3r7qji'), Comment(id='k3rw40n'), Comment(id='k3paa5a'), Comment(id='k3q1bee'), Comment(id='k3prafo'), Comment(id='k3pu098'), Comment(id='k3sue9z'), Comment(id='k3v54lu'), Comment(id='k3s1z5v'), Comment(id='k3prdxl'), Comment(id='k3ty88e'), Comment(id='k3phkij'), Comment(id='k3stj0g'), Comment(id='k3r2o93'), Comment(id='k3tdlkv'), Comment(id='k3s7own'), Comment(id='k3pp19a'), Comment(id='k3pvjvl'), Comment(id='k3pjb73'), Comment(id='k3qaw88'), Comment(id='k3ptmcc'), Comment(id='k3uetwk'), Comment(id='k3tluqr'), Comment(id='k3v4jni'), Comment(id='k3pps6w'), Comment(id='k3qjmem'), Comment(id='k3rliju'), Comment(id='k3urqps'), Comment(id='k3wttm3'), Comment(id='k3qthtj'), Comment(id='k3qz8wh'), Comment(id='k3ty3i2'), Comment(id='k3qz41f'), Comment(id='k3rdvm5')]"
171yhvm,EnPaceRequiescat,,2023-10-07 05:40:05+00:00,False,,False,False,True,False,/r/datascience/comments/171yhvm/clickable_plots/,Clickable plots?,"Hi all, I was wondering if there are packages/tools that allow one to click on data points and trigger actions, e.g. for interactive sites.

Example workflow for this:

\- plot helps to visualize data, click on a set of interesting outliers, those points are auto-selected and incorporated into a list, so that I can show a dynamic dataframe showing all of the selected points for more inspection.

\- click on a point to link to a new page view

I.e. tools like plotly allow me to inspect data nicely, even with hover data to show more information, or even the index of a point in a data frame. But then if I want to inspect and work with a set of points that I find interesting, right now I awkwardly have to manually note the data points, select them by code, and do something else. I'd like to do this in a more seamless way with a slicker interface.  


I think this might be possible with something like d3 but I'm wondering if there are easier to use tools. Thanks!

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/171yhvm/clickable_plots/,16,6,0.88,"[Comment(id='k3tngj9'), Comment(id='k3tp1mp'), Comment(id='k3tncop'), Comment(id='k3whc5z'), Comment(id='k3tio4y'), Comment(id='k3uvika'), Comment(id='k3uwxft'), Comment(id='k4dt5iq'), Comment(id='k464mfu'), Comment(id='k3tljgb'), Comment(id='k3uw4ba'), Comment(id='k4ef708'), Comment(id='k3unq0s'), Comment(id='k3yw7j8'), Comment(id='k3v1jhp'), Comment(id='k3v3pkl')]"
171mgku,Odd-Struggle-3873,,2023-10-06 20:13:10+00:00,False,,False,False,True,False,/r/datascience/comments/171mgku/huge_data_issues/,Huge data issues,"So today it broke me, after weeks of battles. I work for a large international company but this company is so immature. It’s like a teenager that doesn’t know what its limbs are doing.

I know a large part of our work is cleaning data but my issues go beyond this. The data are fundamentally flawed, joins don’t work and literally no-one claims ownership of this, 30-70% of some features are just missing. I think this will be the demise of the company. Sometimes I literally cannot do my job.

Has any one here where worked for such a company? Has anyone ever successfully led change in such a situation?",datascience,https://www.reddit.com/r/datascience/comments/171mgku/huge_data_issues/,10,10,0.86,"[Comment(id='k3rprrf'), Comment(id='k3s2wm7'), Comment(id='k3svtn2'), Comment(id='k3zbjsi'), Comment(id='k42wjnx'), Comment(id='k3t0r1w'), Comment(id='k3spbis'), Comment(id='k3tior2'), Comment(id='k3zi3vh'), Comment(id='k3tijmu')]"
171magw,PM_ME_SomethingNow,,2023-10-06 20:06:11+00:00,False,,False,False,True,False,/r/datascience/comments/171magw/eye_tracking_data/,Eye Tracking Data,"Hey all,

I am a neuroscience Ph.D. student working with some eye-tracking data. The typical approach in my lab has been to try and fit the data to a GLM. Which is fine as a first pass, but I don't want to be limited to just that. I am curious if anyone else here has worked with eye-tracking data and can point me in the right direction. As far as the details are concerned, I am collecting eye-tracking data in few experimental contexts. I would go into detail, but I want to stay at least a bit vague for privacy concerns. 

But to give you some idea of what I am doing, I have one task where participants are looking for a certain stimulus among distractor stimuli. The primary measurable output of this experiment is what stimulus they move their eyes to. But I am sure there is more information captured in the eye-tracking data that we can leverage. Another experiment is looking at overall gaze stability to infer cognitive mechanisms. 

If anyone is interested, I am willing to go in to more detail via PM. Any help would be appreciated! My first instinct to use some form of logistic regression or SVM and check performance. Let me know if I am on the right track.",datascience,https://www.reddit.com/r/datascience/comments/171magw/eye_tracking_data/,6,6,0.8,"[Comment(id='k3s04ja'), Comment(id='k3rk98w'), Comment(id='k409y3u'), Comment(id='k3t29qs'), Comment(id='k3t2j0g'), Comment(id='k3tnlar')]"
171p218,WadeEffingWilson,,2023-10-06 21:59:00+00:00,False,,1696630136.0,False,True,False,/r/datascience/comments/171p218/is_it_possible_to_have_a_nongaussian_mixture_and/,Is it possible to have a non-Gaussian mixture and can it be easily decomposed?,"I'm trying to work out a theory that the population distribution I have is a mixture. Specifically, I'm wanting to see if meaningful clusters exist in this single variable. The variable is a similarity measurement between a lot of smaller sets, so there's an expectation (and observation) that the distribution is heavily right skewed. I'm not sure if it's exponential, chi-squared, wiebull, or poisson but I think that's less about the geometry and more about the mechanisms that created it.

To be clear, the means of each would be different. The population shows multiple modes. 

I'm used to decomposing mixtures where there's an expectation that they are each normally distributed but I'm completely lost when that assumption isn't held up. I want to say that k-means (gmm being a generalization of this) assumes normal distributions. Would hierarchical clustering work here or is it subject to the same assumption?

I'm not super sharp on stats. I know enough to get by but it's an ongoing learning process. Apologize if I've made a mistake or an incorrect assumption.",datascience,https://www.reddit.com/r/datascience/comments/171p218/is_it_possible_to_have_a_nongaussian_mixture_and/,13,4,0.75,"[Comment(id='k3s2fgi'), Comment(id='k3tgbp8'), Comment(id='k3u2h5j'), Comment(id='k3sj7sj'), Comment(id='k3u2c4d'), Comment(id='k3u6j8a'), Comment(id='k3tje4n'), Comment(id='k3tanoa'), Comment(id='k3wwr0t'), Comment(id='k3vgdo7'), Comment(id='k3vpc33'), Comment(id='k3vyy13'), Comment(id='k3wgvu5')]"
171mmpq,spx416,,2023-10-06 20:20:18+00:00,False,,False,False,True,False,/r/datascience/comments/171mmpq/plotting_precalculated_embeddings_onto/,Plotting pre-calculated embeddings onto tensorboard projector,"Hello, I have a file with embeddings already calculated and I want to use tensorboard to project those embeddings. I have no need for metadata at this point. I want to know how to do it, all the tutorials I have seen use their own machine learning model to calculate the embeddings and then save to a checkpoint but I don't need to do that. Any tutorial or resource is greatly appreciated. ",datascience,https://www.reddit.com/r/datascience/comments/171mmpq/plotting_precalculated_embeddings_onto/,0,0,0.5,[]
1717sp8,Salt_Macaron_6582,,2023-10-06 09:25:54+00:00,False,,False,False,True,False,/r/datascience/comments/1717sp8/software_engineering_to_ml_engineeringmlops/,Software Engineering to ML engineering/MLOps,"Is software experience valued in the world of machine learning on the operations side? I'm currently working as a fullstack software engineer while rounding of a BSc in artificial intelligence. I develop applications for machine learning projects and am involved in A/B testing, some minor langchain stuff, data vizualisation, data modelling so there is relatively much alignment with AI. I was wondering whether this experience is valuable if I would want to switch to an engineering heavy ML role. Is there a lot demand for people that can deploy models, do A/B testing, make APIs, and maybe do some light modelling while not being at the level of the phds and MSc CS people that qualify for the straight up data science/research enyineer roles in terms of maths/ML?",datascience,https://www.reddit.com/r/datascience/comments/1717sp8/software_engineering_to_ml_engineeringmlops/,3,5,1.0,"[Comment(id='k3p7qg3'), Comment(id='k3phppv'), Comment(id='k473h3s')]"
170jlh2,LeaguePrototype,,2023-10-05 14:35:53+00:00,False,,False,False,True,False,/r/datascience/comments/170jlh2/lessons_from_my_2_year_job_search/,Lessons From my 2 Year Job Search,"I just wanted to share some insights from my lengthy job hunt that recently ended on a somewhat positive note. If this resonates with people, I might expand it into a Medium article. My aim is to discuss my experiences, help others, and encourage debate to refine these ideas. I've already applied these learnings to help friends land decent jobs, so I hope it helps you too. This is particularly aimed at those starting their careers in data.

A bit about me: I have 7 years of statistics education and a Master's from a reputable U.S. public school. Graduated amid COVID, I became a model & bottle promoter in Europe while freelancing as a data scientist/analyst. Landed a corperate Data Analyst role last month.

1: Experience Over Education

Your education should solely be a stepping stone to gain experience, be it through internships, entry-level positions, or research. Don't overestimate the power of theoretical knowledge; practical experience reigns supreme. Grades only serve as a ticket to initial experiences.

2 and 3: Refer to Point 1

4: Understanding HR/Recruiters

When writing your resume or preparing for interviews, keep it simple but impactful. Recruiters skim through resumes, so your accomplishments should stand out and be quantifiable. Misrepresenting numbers isn't advisable but emphasizing impact is.

5: Always Be Active

If you're job-hunting, always have a project in the works. Freelance gigs are relatively easy to find, and they add valuable experience to your resume. Keep records of your work—publish articles, maintain a GitHub repository, or hold onto contracts.

6: Networking and Luck

Networking is crucial, and often it's not about what you know but who you know. Being at the right place at the right time can spell success. Lack of social skills will be a bottleneck to career growth even when technical skills are stellar.

7: Company Culture vs Reality

Companies may claim to value innovation and talent, but what they're really looking for are reliable candidates who won't mess up. They're impressed by practical business experience, not academic projects or grades. Phrases like ""innovative culture"", ""entrepreneurial"",  ""solving the largest problems"", ""looking for the most talented people"", etc. are all lies especially for starting out.

8: Avoid Targeting Remote Jobs

Targeting only remote jobs was my biggest mistake. Remote positions usually require a significant amount of experience, so aim for local opportunities or consider relocating.

Final Words
Always prioritize your needs over the company's. Don't shy away from promoting yourself or taking new offers even at the last minute. Most companies are self-centered, and as an employee, you should adopt the same approach to your advantage.

Hope this helps, and I'd love to hear your thoughts!",datascience,https://www.reddit.com/r/datascience/comments/170jlh2/lessons_from_my_2_year_job_search/,39,158,0.95,"[Comment(id='k3l8m8v'), Comment(id='k3l7atc'), Comment(id='k3l8bd1'), Comment(id='k3om8j1'), Comment(id='k3owu0q'), Comment(id='k3m0g9b'), Comment(id='k3nn7j8'), Comment(id='k3pbhf3'), Comment(id='k3x8e6f'), Comment(id='k49k3ut'), Comment(id='k3m2om8'), Comment(id='k3lj9i8'), Comment(id='k3ljyi6'), Comment(id='k3lf5jl'), Comment(id='k3lbb1e'), Comment(id='k3mn56q'), Comment(id='k3ow0zf'), Comment(id='k3oqf80'), Comment(id='k3pbp93'), Comment(id='k49t0mw'), Comment(id='k3mi8to'), Comment(id='k3p388a'), Comment(id='k3mvljq'), Comment(id='k3ld0qz'), Comment(id='k3lixzy'), Comment(id='k3n2vo0'), Comment(id='k3mq7zu'), Comment(id='k3qji37'), Comment(id='k49xjiz'), Comment(id='k3n4wyu'), Comment(id='k3nh72q'), Comment(id='k3lw0vl'), Comment(id='k3ojbdo'), Comment(id='k3qtdrj'), Comment(id='k3n3cg6'), Comment(id='k3ojprc'), Comment(id='k3ovgc3'), Comment(id='k3okecr'), Comment(id='k3q0xa7')]"
1719n3t,LegitimateAd4716,,2023-10-06 11:18:14+00:00,False,,False,False,False,False,/r/datascience/comments/1719n3t/removing_outliers_using_dbscan/,Removing outliers using DBScan,I’m working on this used cars dataset. I need to remove the outliers as there are a lot of them. Would DBscan be a good method to implement.. if yes then on which all columns??,datascience,https://i.redd.it/0hs2dhpdgksb1.jpg,8,0,0.5,"[Comment(id='k3pf4ln'), Comment(id='k3rqodh'), Comment(id='k3ply3p'), Comment(id='k40bed1'), Comment(id='k3s2898'), Comment(id='k3sgi4i'), Comment(id='k3pswzc'), Comment(id='k3tbrea')]"
170zg4y,unbrkbleheaven,,2023-10-06 01:24:32+00:00,False,,False,False,True,False,/r/datascience/comments/170zg4y/is_it_worth_it_double_majoring_in_economics_and/,Is it worth it double majoring in Economics and Science?,"I plan on transferring universities to pursue an Economics degree and maybe also double majoring in Data Science, however I noticed many Data Science job listings also accept Economics degrees. Is it pointless to major in both and I should try to diversify it, or would majoring in both actually make me a stronger candidate?",datascience,https://www.reddit.com/r/datascience/comments/170zg4y/is_it_worth_it_double_majoring_in_economics_and/,3,4,1.0,"[Comment(id='k3nwjvl'), Comment(id='k3owsyr'), Comment(id='k4j9g0y')]"
1713ly9,jaegarbong,,2023-10-06 04:55:50+00:00,False,,False,False,True,False,/r/datascience/comments/1713ly9/is_it_good_to_ask_questions_regarding_a_takehome/,Is it good to ask questions regarding a take-home case study?,"I have been given a case study as a next step in my interview. I have a few questions and doubts regarding the same.

Some of these doubts are about the terms they have used and their relevance to the dataset. 

Will it seem bad if I send out questions regarding this?",datascience,https://www.reddit.com/r/datascience/comments/1713ly9/is_it_good_to_ask_questions_regarding_a_takehome/,3,2,1.0,"[Comment(id='k3ojqpo'), Comment(id='k3xw6da'), Comment(id='k3orvl1')]"
1716zm9,Raspberrry314,,2023-10-06 08:31:18+00:00,False,,False,False,True,False,/r/datascience/comments/1716zm9/survival_analysis_employee_churn/,Survival Analysis - Employee churn,"Hey everyone  


I am working on a project for uni and I have chosen employee churn as my topic. One of the predictors, ""Reason for Termination"", has absconded, resigned, terminated and contract expired.

&#x200B;

Since I am looking for reasons why employees are churning and how to prevent it, should I exclude the option ""contract expired""? Absconded, resigned and terminated are all factors that aa company would want to prevent when hiring an employee but should they look out for employees who have had their contract expired since this is not really a red flag, for lack of a better term. 

&#x200B;

How would I handle the entries relating to contract expired?  ",datascience,https://www.reddit.com/r/datascience/comments/1716zm9/survival_analysis_employee_churn/,8,1,1.0,"[Comment(id='k3oxnzb'), Comment(id='k40c09i'), Comment(id='k3oxx1g'), Comment(id='k3oy6xi'), Comment(id='k3oyes8'), Comment(id='k3oymgu'), Comment(id='k3pbk1u'), Comment(id='k3p2kog'), Comment(id='k3p33we')]"
1716u3j,Warm_Cicada_8313,,2023-10-06 08:21:11+00:00,False,,False,False,True,False,/r/datascience/comments/1716u3j/a_phd_in_economics_or_masters_in_data_analytics/,A PhD in Economics or Masters in Data Analytics - Suggestions needed.,"Hi everybody, hope you areall doing good. I need some suggestions, like the title says. 

Here is a little introduction about me - I have done my bachelors and masters in Economics (From Pakistan). Now, I was thinking to continue my studies further, I was determined to do PhD in Economics from USA, i was planning to apply this year but I decided to take a break this year and see what is it I actually want. During my masters and bachelors we have had various assignments and projects that would require us to analyse/visualise data and draw meaningful insights out of the analysis, using softwares like STATA, EViews, SPSS, Excel. I have always like playing around with data and using softwares. 

Now the thing is, i am in a quandary whether i should do a PhD in economics or do another masters in data analytics program. I am not sure which one is a wise choice, is there any one who has opted for data analytics with economics being their major? how did it go? which programs are better in this regard?

how should i take a start towards it? i have started to learn R language, what else can be helpful in this regard?

Looking forward to some valuable suggestions/advice, 

thanks",datascience,https://www.reddit.com/r/datascience/comments/1716u3j/a_phd_in_economics_or_masters_in_data_analytics/,1,0,0.5,[Comment(id='k3ro6e4')]
1716aw9,khaled__alekasir,,2023-10-06 07:43:57+00:00,False,,False,False,True,False,/r/datascience/comments/1716aw9/machine_learning_and_statistic_online_courses/,Machine learning and statistic online courses,"Today I was looking for an online course in ML and I ran into [this](https://twitter.com/caglar_ee) twitter (X) page which contains addresses to a lot of useful free online courses in AI, ML, RL and statistics.

I think it may be helpful to others to post it here.",datascience,https://www.reddit.com/r/datascience/comments/1716aw9/machine_learning_and_statistic_online_courses/,0,1,1.0,[]
170loiv,RightProfile0,,2023-10-05 16:01:36+00:00,False,,1696521895.0,False,True,False,/r/datascience/comments/170loiv/do_most_companies_use_awsazure/,Do most companies use AWS/Azure?,"I understand these cloud computings as essentially borrowing ""highly efficient computers"" from amazon, microsoft, etc so I can do things more efficiently without worrying too much about hardware level logistics.

I'm trying to build some long term meaningful portfolio.

Is it realistic to build my own website and deploy the machine learning model (or statistical, whatever)  that has some regular updates? (hopefully it is useful as well)

I'm relatively proficient at anything related to math/stats but not so much on cloud computing.

Is this how things are done in the industry?

Would most jobs I apply in the States use cloud computing?

How much would this cost if I want to do this?

Any insight is appreciated!!

&#x200B;

(I'm on my way to get cert for AWS practitioner, but I'm also wanting to get some other ones too if it will be useful for this project. )",datascience,https://www.reddit.com/r/datascience/comments/170loiv/do_most_companies_use_awsazure/,14,17,0.84,"[Comment(id='k3m2ars'), Comment(id='k3mz5ob'), Comment(id='k3lgam1'), Comment(id='k3naexl'), Comment(id='k3o50fh'), Comment(id='k3nirjz'), Comment(id='k3o1ycm'), Comment(id='k3n5slt'), Comment(id='k3q67dt'), Comment(id='k3o570f'), Comment(id='k3o32a2'), Comment(id='k3nivfd'), Comment(id='k48r85b'), Comment(id='k3o5jpd')]"
170jcmg,MarzCallz,,2023-10-05 14:25:35+00:00,False,,False,False,True,False,/r/datascience/comments/170jcmg/bayesian_recommendations/,Bayesian recommendations?,"Hello! Any recommendations (books, courses, articles, blog, podcast, whatever existent) to learn about Bayesian statistics for business and testing?",datascience,https://www.reddit.com/r/datascience/comments/170jcmg/bayesian_recommendations/,32,21,1.0,"[Comment(id='k3lhubj'), Comment(id='k3oeb8m'), Comment(id='k3nww2p'), Comment(id='k3lhg4b'), Comment(id='k3o1p6m'), Comment(id='k3qyg18'), Comment(id='k41ofy7'), Comment(id='k3lq21t'), Comment(id='k3kxh9k'), Comment(id='k3n3b13'), Comment(id='k3loozt'), Comment(id='k41okyf'), Comment(id='k3o6ars'), Comment(id='k3mlgpu'), Comment(id='k50dnp8'), Comment(id='k50dqyi'), Comment(id='k50ed7x'), Comment(id='k3mlkky'), Comment(id='k3mucaa'), Comment(id='k3lfbc3'), Comment(id='k3nk4o0'), Comment(id='k50e5ds'), Comment(id='k3n3g3e'), Comment(id='k3m8akf'), Comment(id='k428ry2'), Comment(id='k52l5mg'), Comment(id='k3ndu6e'), Comment(id='k3mbgrx'), Comment(id='k50dcy3'), Comment(id='k50dl0w'), Comment(id='k3mca7l'), Comment(id='k3nh4kb')]"
1714os7,Order-Various,,2023-10-06 06:00:32+00:00,False,,False,False,True,False,/r/datascience/comments/1714os7/is_it_bad_if_i_cant_visualize_dataframe_in/,Is it bad if i can't visualize DataFrame in Jupyter Notebook and pandas without turn it into Excel ?,"To be familiar with Excel but totally struggle with Jupyter Notebook, I usually turn the df to spreadsheet using pd.df.to\_excel(). Working with excel, I usually can do more and able to figure out stuff that can't be done with JN. Further more, using JN make me feel that i would miss something important in the dataset. Is this a bad practice and is there any tips to upgrade my dataskill with Jupyter ?",datascience,https://www.reddit.com/r/datascience/comments/1714os7/is_it_bad_if_i_cant_visualize_dataframe_in/,4,1,1.0,"[Comment(id='k3omfzi'), Comment(id='k3qs281'), Comment(id='k3wtiwo'), Comment(id='k3p8wgr')]"
1714oc4,CKJ_1630,,2023-10-06 05:59:53+00:00,False,,False,False,True,False,/r/datascience/comments/1714oc4/guidance/,Guidance,I want to learn data science. I don't know anything about it. Please suggest data science beginner level books. Or free online resources from where I can learn. Or should I go far six months offline paid data science course in my city? Other suggestions will also be accepted.,datascience,https://www.reddit.com/r/datascience/comments/1714oc4/guidance/,3,0,0.5,"[Comment(id='k3q2pjg'), Comment(id='k3pcscu'), Comment(id='k3q38bt')]"
170pl0q,Quick_Conflict_533,,2023-10-05 18:35:52+00:00,False,,False,False,True,False,/r/datascience/comments/170pl0q/best_cloud_solution_for_ml_on_huge_dataset/,Best cloud solution for ML on huge dataset,"Hi, It would be a great help to me if you could suggest me different ways I can do ML my dataset. My laptop is very old and my dataset is about 300k row x 150k columns. So rigorous feature engineering, different models and neural nets will be done also with cv and many more. 

I dont have a huge budget but I need to make it work. What are the options I could potentially explore to make my work fast as well.",datascience,https://www.reddit.com/r/datascience/comments/170pl0q/best_cloud_solution_for_ml_on_huge_dataset/,21,8,0.83,"[Comment(id='k3mnf7o'), Comment(id='k3o8hal'), Comment(id='k3mc5ss'), Comment(id='k3o48f0'), Comment(id='k3mbpxx'), Comment(id='k3mpszs'), Comment(id='k3o8i25'), Comment(id='k3otspp'), Comment(id='k3q9t13'), Comment(id='k3qhc4i'), Comment(id='k3y0im0'), Comment(id='k3n78tl'), Comment(id='k3mq66p'), Comment(id='k3oiyu2'), Comment(id='k3n8l5x'), Comment(id='k3mt66f'), Comment(id='k3p8xhg'), Comment(id='k3mu4ah'), Comment(id='k3oaqpj'), Comment(id='k44z3qm'), Comment(id='k3muuvh')]"
1709s0h,nondualist369,,2023-10-05 05:30:43+00:00,False,,False,False,False,False,/r/datascience/comments/1709s0h/handling_class_imbalance_in_multiclass/,Handling class imbalance in multiclass classification.,I have been working on multi-class classification assignment to determine type of network attack. There is huge imbalance in classes. How to deal with it.,datascience,https://i.redd.it/z9uay6welbsb1.jpg,45,79,0.94,"[Comment(id='k3kpfr4'), Comment(id='k3kw2o6'), Comment(id='k3kf98f'), Comment(id='k3m3so6'), Comment(id='k3kells'), Comment(id='k3l0vvx'), Comment(id='k3nbng2'), Comment(id='k3jkikd'), Comment(id='k3kkly2'), Comment(id='k3mikzf'), Comment(id='k3liy1r'), Comment(id='k3n4p2n'), Comment(id='k3kojpv'), Comment(id='k3lm1t6'), Comment(id='k3loyib'), Comment(id='k3m01k1'), Comment(id='k3msa1b'), Comment(id='k3ndkwx'), Comment(id='k3sohdy'), Comment(id='k3kut33'), Comment(id='k3qgxbd'), Comment(id='k3ml4hc'), Comment(id='k3qy4c5'), Comment(id='k3li84d'), Comment(id='k3k9e5u'), Comment(id='k3jtsrn'), Comment(id='k3jl2nh'), Comment(id='k3lcvsq'), Comment(id='k3lctf1'), Comment(id='k3n81f9'), Comment(id='k3loujp'), Comment(id='k3lc492'), Comment(id='k3oqz4z'), Comment(id='k3kjcu6'), Comment(id='k3jq1fs'), Comment(id='k3qydf9'), Comment(id='k3n068z'), Comment(id='k3lwpta'), Comment(id='k3n7qxk'), Comment(id='k3r2i0o'), Comment(id='k3lxqc4'), Comment(id='k3n8sg1'), Comment(id='k3m24v9'), Comment(id='k3m3xpi'), Comment(id='k3m6429')]"
1713g99,the_tallest_fish,,2023-10-06 04:46:37+00:00,False,,False,False,True,False,/r/datascience/comments/1713g99/what_exactly_is_the_job_scope_for_a_data_scientist/,What exactly is the job scope for a data scientist??,"I’m a ML engineer who recently joined a company and have been working closely with a senior data scientist for a few months now. He’s been working here a year before me, apparently had 10 years of experience and was working for a consultancy before this. He has been getting increasingly frustrating to work with.

Most of what he does is making charts and dashboards with SQL, meeting with the higher-ups of the business and overpromising them a bunch of “AI features” without any considerations to feasibility or cost. 

Anything that I asked of him that requires him using any technology outside a Jupyter notebook, he will claim that “it is not my job scope, I am not an engineer.” This includes basic things like version control or remote training. He believes that all he needs to do is to provide a POC… except..

..the POC he built on the notebook is completely unusable. I’m talking about stray lines of codes scatter across cells, not even a single function in sight, and utterly inefficient use of pandas. The worst of all, is that the POC model is trained on a subset of the actual data because, and I quote “my machine ran out of memory trying to fit the whole thing”, but don’t worry because “I’ve stratified the sampling.” (tbf the data is over 80gb.. but still)

I know that DS are not supposed to write production ready code, but this notebook is completely worthless. In my previous job I worked on automating testing and monitoring ML pipeline with a much bigger team, so I didn’t work with data scientists so directly. Last week, I chatted with my coworker in marketing, and apparently she tried to ask him for some analysis for user signups, and he replied with the same excuse: “this is not my job scope, I’m not a data analyst.” So now I have no idea what he actually does.

At this point, I have no idea what a data scientist’s job scope is or what to expect. I know many people on this sub claims that DS is more of a business role, but is this normal? I’m starting to think that he’s a fraud, but you can’t possibly do that for 10 years. 

I have no idea what to do. Is this normal for data scientists? Should I just readjust my expectation and rewrite the whole thing?",datascience,https://www.reddit.com/r/datascience/comments/1713g99/what_exactly_is_the_job_scope_for_a_data_scientist/,6,0,0.5,"[Comment(id='k3pcbkb'), Comment(id='k3qlh7i'), Comment(id='k3ohqhq'), Comment(id='k3t2xs4'), Comment(id='k3yb8j2'), Comment(id='k3qj0ya')]"
170alzu,TheEnlightenedMan,,2023-10-05 06:21:06+00:00,False,,False,False,True,False,/r/datascience/comments/170alzu/whats_one_hard_thing_about_being_a_data_scientist/,What's one hard thing about being a data scientist?,"Hello everyone!

I've been diving into the world of data science and i'm curious about the challenges/inconveniences you experience as a data scientist/analyst.

I'd love to hear your thoughts about this. As a data scientist, what's one little hiccup or challenge you often come across in your daily work?

Looking forward to your insights!",datascience,https://www.reddit.com/r/datascience/comments/170alzu/whats_one_hard_thing_about_being_a_data_scientist/,88,61,0.85,"[Comment(id='k3jjbbe'), Comment(id='k3kaqsa'), Comment(id='k3kldx4'), Comment(id='k3jjv94'), Comment(id='k3jsh9x'), Comment(id='k3koiad'), Comment(id='k3kruea'), Comment(id='k3kpduh'), Comment(id='k3l2rnh'), Comment(id='k3jyvq8'), Comment(id='k3kjtyg'), Comment(id='k3ksq2k'), Comment(id='k3k9t7d'), Comment(id='k3llw5k'), Comment(id='k3lx1s9'), Comment(id='k3m3ubd'), Comment(id='k3oe51f'), Comment(id='k3jniud'), Comment(id='k3jtohv'), Comment(id='k3kfy6f'), Comment(id='k3kfdk9'), Comment(id='k3lk98q'), Comment(id='k3mlb63'), Comment(id='k3tp8kb'), Comment(id='k3kcz2h'), Comment(id='k3kwm59'), Comment(id='k3l5ty5'), Comment(id='k3ma9ew'), Comment(id='k3nfitf'), Comment(id='k3nggpm'), Comment(id='k3nnrig'), Comment(id='k3omkbr'), Comment(id='k3onumg'), Comment(id='k3ot3y6'), Comment(id='k3p16pe'), Comment(id='k3pjh4c'), Comment(id='k3s75h5'), Comment(id='k3kkecq'), Comment(id='k3km60d'), Comment(id='k3jl14q'), Comment(id='k3l1h6u'), Comment(id='k3kmzyy'), Comment(id='k3kgb79'), Comment(id='k3kk1hq'), Comment(id='k3lz566'), Comment(id='k3lpsgb'), Comment(id='k3jl3id'), Comment(id='k3kg3ds'), Comment(id='k3knp8k'), Comment(id='k3kjxm8'), Comment(id='k3kqato'), Comment(id='k3lifpe'), Comment(id='k3x0kxc'), Comment(id='k3n4uld'), Comment(id='k3l2uer'), Comment(id='k3n4p4j'), Comment(id='k3ogtcg'), Comment(id='k3kge1c'), Comment(id='k3x1bo5'), Comment(id='k3x2pjr'), Comment(id='k3x1lyn'), Comment(id='k3x1zp1'), Comment(id='k3wzs2i'), Comment(id='k3js82a'), Comment(id='k3lenzo'), Comment(id='k3mdk95'), Comment(id='k3kmt13'), Comment(id='k3jlqwb'), Comment(id='k3kl2s6'), Comment(id='k3lzzjv'), Comment(id='k3kspjw'), Comment(id='k3yd9hv'), Comment(id='k3l3bbu'), Comment(id='k3mrtt5'), Comment(id='k3jnwy6'), Comment(id='k3juhoi'), Comment(id='k3knt31'), Comment(id='k3mxvoz'), Comment(id='k3l43wj'), Comment(id='k3ktpq5'), Comment(id='k3n0cqp'), Comment(id='k3kida7'), Comment(id='k3kpeee'), Comment(id='k3kpy0m'), Comment(id='k3lior3'), Comment(id='k3ndrhx'), Comment(id='k43ra5c'), Comment(id='k45i7o8')]"
1712czz,sunblockheaven,,2023-10-06 03:45:43+00:00,False,,False,False,True,False,/r/datascience/comments/1712czz/questionanswers_model_what_to_us/,Question-Answers Model. What to us?,"I have a project with a list of customer feedback and worker’s responses (so a QA model) These answers are related to internal company policies, so knowledge has to be trained. 

That being said, I’ve read into a few keywords, such as using DBSCAN to cluster, Seq2Seq. 

My question is: 
1. What should be my approach? 
2. How do I use a model from an open model from Huggingface that I don’t have to train for machine understanding towards English? 
3. How to generate output based on my datasets of questions-answers? 

Thank you for your help in advance!",datascience,https://www.reddit.com/r/datascience/comments/1712czz/questionanswers_model_what_to_us/,0,1,1.0,[]
170ymu9,Agitated-Duty2577,,2023-10-06 00:46:12+00:00,False,,False,False,True,False,/r/datascience/comments/170ymu9/looking_for_a_tutor_for_sas_programming_anyone/,Looking for a tutor for SAS programming-- anyone?,"I am learning SAS for my thesis project and looking for someone to tutor me in writing SAS code. I am familiar with the online resources for learning SAS... but finding it takes many hours to troubleshoot errors and I am also working full-time while completing my thesis.

I would be looking for 1-2 hours per week of virtual help with this from now until December and I will pay. If you are experienced with SAS and interested, or know of a pool of SAS programmers I could contact, please message me and I can provide more details!",datascience,https://www.reddit.com/r/datascience/comments/170ymu9/looking_for_a_tutor_for_sas_programming_anyone/,0,1,1.0,[]
1712php,norfkens2,,2023-10-06 04:04:50+00:00,False,,False,False,True,False,/r/datascience/comments/1712php/why_is_data_science_still_so_hyped/,Why is data science still so hyped?,"It's a bunch of really cool jobs but where does all the hype still come from?

And why are there so many beginners that try to enter when it has been really difficult to enter the job market in the past couple of years?

Also, I've seen a lot of people wanting to transition into DS without having an understanding of what the job actually looks like. That's not a criticism of the individuals but it shows to me that there's a perception and weird incentivisation going on in the broader public.

It can't be the ""sexiest job"" label alone anymore and it feels to me like there's an delay/disconnect of 3-8 years between what people's expectations are and what is actually going on.

Don't get me wrong, I'm super happy that data work is getting so much attention but I really struggle putting the societal dynamics that must be at play here into words.

Are these normal time scales for these effects to be playing out? Is it down to DS being such a young discipline?

Any thoughts?",datascience,https://www.reddit.com/r/datascience/comments/1712php/why_is_data_science_still_so_hyped/,66,0,0.44,"[Comment(id='k3oc3pi'), Comment(id='k3og2z8'), Comment(id='k3oir30'), Comment(id='k3pdazt'), Comment(id='k3p00ic'), Comment(id='k3owlsb'), Comment(id='k3ov50w'), Comment(id='k3pit3q'), Comment(id='k3q28qa'), Comment(id='k3re6kn'), Comment(id='k3sto4x'), Comment(id='k3p3xwz'), Comment(id='k3pe6tv'), Comment(id='k3pk9lb'), Comment(id='k3pobuq'), Comment(id='k3q5p5j'), Comment(id='k3sdj1k'), Comment(id='k3t6csc'), Comment(id='k3ohs6l'), Comment(id='k3p0fye'), Comment(id='k3p4ffz'), Comment(id='k3p2p56'), Comment(id='k3taxls'), Comment(id='k3xn97g'), Comment(id='k3odp0w'), Comment(id='k3p1wse'), Comment(id='k3qyecy'), Comment(id='k3ohro7'), Comment(id='k3qwx7r'), Comment(id='k3qh107'), Comment(id='k3qxalq'), Comment(id='k3tkpx7'), Comment(id='k3ozh8x'), Comment(id='k3phzlc'), Comment(id='k3ubwss'), Comment(id='k3q51um'), Comment(id='k3tpbd1'), Comment(id='k3ts7fo'), Comment(id='k3ts5d3'), Comment(id='k3q5c9t'), Comment(id='k3tpuog'), Comment(id='k3trqly'), Comment(id='k3okidh'), Comment(id='k3ojqm6'), Comment(id='k3q6awm'), Comment(id='k3poqf9'), Comment(id='k3q5yn9'), Comment(id='k3sat0m'), Comment(id='k3q60ed'), Comment(id='k3tqleg'), Comment(id='k3ycui5'), Comment(id='k3r09hv'), Comment(id='k3tkfxl'), Comment(id='k3p06zh'), Comment(id='k3q6hjh'), Comment(id='k3qx56m'), Comment(id='k3tpves'), Comment(id='k3ootai'), Comment(id='k3ub229'), Comment(id='k3sc2gf'), Comment(id='k3reel6'), Comment(id='k3qsswv'), Comment(id='k3tkdas'), Comment(id='k3saku4'), Comment(id='k3tjx3k'), Comment(id='k3u0kkg')]"
170ob14,obewanjacobi,,2023-10-05 17:45:45+00:00,False,,False,False,True,False,/r/datascience/comments/170ob14/text_alias_modeling/,Text Alias Modeling,"I have a dataset of true names in one column, and aliases in another. The idea is that a single name in the true column can have multiple aliases in the alias column. I need to build a model that will train on this data and learn to map aliases to true names to automate when more aliases get created for one of my teams at work. 

I've tried a standard neural net by first vectorizing the string values in each column, but that had really poor results, and then started looking into Word Embedding models, but that doesn't seem to fit exactly what I'm doing here in the project.   


So I'm looking for recommendations on models that I can use to try and accomplish this task. I've been Googling for a couple of days but nothing quite fits the scenario I have, most text models don't seem to map text to text but instead text to a quantitative value. Thanks for the insight!",datascience,https://www.reddit.com/r/datascience/comments/170ob14/text_alias_modeling/,14,1,0.67,"[Comment(id='k3nb8rn'), Comment(id='k3scf07'), Comment(id='k3oozbi'), Comment(id='k3ne2ys'), Comment(id='k3prbc8'), Comment(id='k3ngsap'), Comment(id='k3r2ncn'), Comment(id='k3scmse'), Comment(id='k3nj2de'), Comment(id='k3rhn2j'), Comment(id='k3sd2di'), Comment(id='k3t724y'), Comment(id='k3sg09k'), Comment(id='k3t9pvo')]"
16zw1dz,EcoNerd007,,2023-10-04 19:21:03+00:00,False,,False,False,True,False,/r/datascience/comments/16zw1dz/data_sciences_in_the_plural/,Data Science(s) in the plural,"I am lead of a new Data Science Division. The management team at our company is insistent that Data Sciences in the plural is a better fit. On my team we have statisticians, database managers, geospatial geographers, programmers, and data scientists. We are also incorporating machine learning as well. Google searches almost exclusively mention Data Science in the singular. Does anyone have any opinions or suggestions? Should I bow down and embrace the plural or should I be adamant about the norm of the singular?",datascience,https://www.reddit.com/r/datascience/comments/16zw1dz/data_sciences_in_the_plural/,38,43,0.84,"[Comment(id='k3h590v'), Comment(id='k3h37dp'), Comment(id='k3i36bv'), Comment(id='k3hazx4'), Comment(id='k3h355o'), Comment(id='k3h4t1j'), Comment(id='k3h7p3x'), Comment(id='k3hltts'), Comment(id='k3hlfiz'), Comment(id='k3lgb5w'), Comment(id='k3h9ve8'), Comment(id='k3ieoja'), Comment(id='k3hwrc4'), Comment(id='k3i5qgg'), Comment(id='k3icvxt'), Comment(id='k3ixh41'), Comment(id='k3ixh58'), Comment(id='k3iy4gj'), Comment(id='k3iztim'), Comment(id='k3jfmzp'), Comment(id='k3k7qh6'), Comment(id='k3kh745'), Comment(id='k3kpbib'), Comment(id='k3n4gba'), Comment(id='k3ijifi'), Comment(id='k3jsclx'), Comment(id='k3hcmk8'), Comment(id='k3ljh6k'), Comment(id='k3mixoy'), Comment(id='k3hs761'), Comment(id='k3h7z2p'), Comment(id='k3lie4w'), Comment(id='k3nx8wd'), Comment(id='k3ma2rd'), Comment(id='k3hk5bh'), Comment(id='k3i4bgu'), Comment(id='k3lpns1'), Comment(id='k3mao0v')]"
170e4n7,Odd-Concert-4591,,2023-10-05 10:07:42+00:00,False,,False,False,True,False,/r/datascience/comments/170e4n7/product_name_matching_entity_resolution_or_enity/,Product name matching - Entity Resolution or Enity Linkage or both?,"**Context**

I am at the start of a project where I would like to map/match/link external product names to the respective internal product names. The goal should be to ingest related external information (e.g. stock number) of the external products into our system by joining the same products based on their product names. Short, the external product name should be matched to the internal representation of the product name.

&#x200B;

**Problem and Question**

I'm now doing some research about potential solutions and I'm having difficulties finding out if the nature of the problem can be allocated to Entity Resolution or Entity Linkage or if it even includes both of them. I'm asking this because I'm afraid to go down the wrong path when researching for a potential way to tackle the problem. I have seen the post about [key differences about entity linking and entity matching](https://datascience.stackexchange.com/questions/115528/exemplify-key-differences-between-entity-linking-and-entity-matching#:~:text=As%20depicted%20below%2C%20entity%20linking,reference%20repository%20or%20knowledge%20base.&text=However%2C%20in%20entity%20matching%20the,knowledge%20base%20do%20not%20exist.&text=mirror%2Dimage), but it's still hard for me to allocate the nature of my problem to one of them. Can please someone tell me if the problem can be allocated to Entity Resolution, Entity Linkage or both, and why this is the case?

&#x200B;

Thanks a lot!",datascience,https://www.reddit.com/r/datascience/comments/170e4n7/product_name_matching_entity_resolution_or_enity/,0,2,1.0,[]
16zwzv6,Dependent_Mushroom98,,2023-10-04 20:00:30+00:00,False,,False,False,True,False,/r/datascience/comments/16zwzv6/can_we_take_the_probabilities_from_one_model_and/,Can we take the probabilities from one model and make it a feature to the other model along with additional features?,"When my team mate used the probabilities from one model and used as feature to the other model the probabilities from first model was highest on the feature importance map for the second model.

Is this an example of stacked model or is it better to have trained both models with additional features and compare the accuracy of both models rather than reporting the accuracy of the linked model in step 1. 

Please share your experience. Thanks",datascience,https://www.reddit.com/r/datascience/comments/16zwzv6/can_we_take_the_probabilities_from_one_model_and/,9,15,0.94,"[Comment(id='k3hw4lb'), Comment(id='k3hhna9'), Comment(id='k3hozae'), Comment(id='k3ham0x'), Comment(id='k3jtyp7'), Comment(id='k3qu48m'), Comment(id='k3ixmpo'), Comment(id='k3kl5cm'), Comment(id='k3kid2f')]"
170coig,Relevant-Cycle9169,,2023-10-05 08:33:56+00:00,False,,False,False,True,False,/r/datascience/comments/170coig/classificationpredicting_of_outliers/,Classification/predicting of outliers,"I have a skewed depandant variable with few high natural outliers, I want to perform regression on it without removing outliers and also improve rmse score, how can I handle them? using feature engineering? build a model to classify them?  
Thank you",datascience,https://www.reddit.com/r/datascience/comments/170coig/classificationpredicting_of_outliers/,1,1,0.67,[Comment(id='k3oa2ko')]
1709cts,deonvin,,2023-10-05 05:06:23+00:00,False,,False,False,True,False,/r/datascience/comments/1709cts/optimising_inputs_to_ml_model/,Optimising Inputs to ML Model,"If you create an ML model, is it advisable to do a black box optimisation and find the optimal inputs to get the maximum/minimum output?

 Or does it only make sense to use ML models predictively, not prescriptively?",datascience,https://www.reddit.com/r/datascience/comments/1709cts/optimising_inputs_to_ml_model/,1,1,1.0,[Comment(id='k3o9ubo')]
1708utp,din38ah,,2023-10-05 04:38:20+00:00,False,,False,False,True,False,/r/datascience/comments/1708utp/sas_how_to_query_the_outlier_from_the_output_of/,sas - how to query the outlier from the output of the proc sgplot,"Here is the piece of code that write the data to a table:

    ods output sgplot=boxplot_data;
    proc sgplot data=mylib.calendar;
    vbox price;
    run;

and the data in the table looking like this:

&#x200B;

https://preview.redd.it/ngr15k82bbsb1.png?width=786&format=png&auto=webp&s=ace90c47416f4429d21e9cc78cbc26e1906441a4

Now, I want to query this data where the BOX(price)\_\_ST = 'FAROUTLIER' 

with this code:

    proc sql;
    select * 
       from boxplot_data (obs=50);
    where ""BOX(price)__ST"" = 'FAROUTLIER'
    quit;

But it didn't work. I can't query the column that has the ""\_\_"" in its name.

And the table properties show the column name and its label. But I can't query the label either.

&#x200B;

https://preview.redd.it/nufe0xksbbsb1.png?width=598&format=png&auto=webp&s=87279934c18e17dc763a8313ff2f919c7619e447

Any one done this before? How did you do it?

&#x200B;

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/1708utp/sas_how_to_query_the_outlier_from_the_output_of/,3,1,1.0,"[Comment(id='k40ee6d'), Comment(id='k41snbf'), Comment(id='k40gt7q')]"
16z8pez,Potanee,,2023-10-04 00:34:58+00:00,False,,False,False,True,False,/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/,What do corporate data scientists struggle with the most at work?,"As a data scientist, if you could let someone else solve something for you what would it be?

I was curious to know the problems data scientists face. This can be anywhere from collecting data and cleaning data to making and deploying machine learning models.",datascience,https://www.reddit.com/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/,121,134,0.97,"[Comment(id='k3d9lyk'), Comment(id='k3da5xh'), Comment(id='k3d6xsc'), Comment(id='k3d56uk'), Comment(id='k3d8606'), Comment(id='k3d7l89'), Comment(id='k3dme0k'), Comment(id='k3dhmdv'), Comment(id='k3dba6i'), Comment(id='k3dbdo0'), Comment(id='k3df8mb'), Comment(id='k3di6rb'), Comment(id='k3e8rah'), Comment(id='k3d9m15'), Comment(id='k3d7jon'), Comment(id='k3e8za0'), Comment(id='k3dcnjg'), Comment(id='k3e9kk9'), Comment(id='k3dp8zi'), Comment(id='k3drss7'), Comment(id='k3f5upz'), Comment(id='k3e6sd0'), Comment(id='k3egi0w'), Comment(id='k3dru09'), Comment(id='k3dw6sb'), Comment(id='k3dymvz'), Comment(id='k3f1mxt'), Comment(id='k3f6l2n'), Comment(id='k3fgwup'), Comment(id='k3fx3hc'), Comment(id='k459j90'), Comment(id='k3dgbph'), Comment(id='k3ebm2t'), Comment(id='k3drem3'), Comment(id='k3ee9q5'), Comment(id='k3ek4rm'), Comment(id='k3ettfu'), Comment(id='k3ez8zw'), Comment(id='k3f0pmn'), Comment(id='k3f76io'), Comment(id='k3femjw'), Comment(id='k3fh2vk'), Comment(id='k3fkh8d'), Comment(id='k3fmedx'), Comment(id='k3fzube'), Comment(id='k3jx3rr'), Comment(id='k3jxu39'), Comment(id='k3rgp10'), Comment(id='k414wxg'), Comment(id='k3dcnvm'), Comment(id='k3dliqj'), Comment(id='k3dr18g'), Comment(id='k3dksll'), Comment(id='k3e6fy4'), Comment(id='k3e68t1'), Comment(id='k3fj9jj'), Comment(id='k3gqioc'), Comment(id='k3hx03c'), Comment(id='k3gsv91'), Comment(id='k3kl360'), Comment(id='k3dcti9'), Comment(id='k3dlwaa'), Comment(id='k3d8iee'), Comment(id='k3ebh5l'), Comment(id='k3eqj7e'), Comment(id='k3ddim1'), Comment(id='k3dl0ds'), Comment(id='k3d5efw'), Comment(id='k3dmasq'), Comment(id='k3eiw1k'), Comment(id='k3f6ydz'), Comment(id='k3h320z'), Comment(id='k3eo4tj'), Comment(id='k3dwyad'), Comment(id='k3ez4hh'), Comment(id='k3faeut'), Comment(id='k3fkk3m'), Comment(id='k3ga6fg'), Comment(id='k3dcz35'), Comment(id='k3fx25i'), Comment(id='k3dds2z'), Comment(id='k3danan'), Comment(id='k3hx357'), Comment(id='k3d7mtr'), Comment(id='k3eb93y'), Comment(id='k3dpcac'), Comment(id='k3jl5xo'), Comment(id='k3f5nst'), Comment(id='k3jm3zs'), Comment(id='k3jmpt9'), Comment(id='k3de575'), Comment(id='k3fuxju'), Comment(id='k3gsmt7'), Comment(id='k3jjer3'), Comment(id='k3hg7wc'), Comment(id='k3dedua'), Comment(id='k3drlk4'), Comment(id='k3er1x8'), Comment(id='k3d6dww'), Comment(id='k404bet'), Comment(id='k3hgtxa'), Comment(id='k3d805u'), Comment(id='k3g0mlf'), Comment(id='k3eo86a'), Comment(id='k3f9vkr'), Comment(id='k3f6x1e'), Comment(id='k3k3y5j'), Comment(id='k3et84n'), Comment(id='k3fv42k'), Comment(id='k3q6cmz'), Comment(id='k3fxhj6'), Comment(id='k3gys2e'), Comment(id='k40nwm8'), Comment(id='k3dfmbq'), Comment(id='k3fa5eu'), Comment(id='k3hfwaq'), Comment(id='k3fvrob'), Comment(id='k3ksts6'), Comment(id='k3dkj37'), Comment(id='k3fyu1f'), Comment(id='k3i657f'), Comment(id='k3g00d8')]"
16zzta7,KillingTimeSince99,,2023-10-04 21:51:25+00:00,False,,False,False,True,False,/r/datascience/comments/16zzta7/looking_for_a_tool_to_help_map_two_databases/,Looking for a tool to help map two databases schemas against each other,"I have two relational databases with \~30 tables each. While they both hold essentially the same data, the schema for each is wildly different. I eventually need to migrate the data so I'd like to build a good 1-for-1 schema map for each column from the origin database to where that would go in the destination database (or to note that it's data that doesn't need to move, for one reason or another).

I could certainly just manually build this all in Excel but that's boring and a time drain. Any good tools, preferably but not necessarily visual, that folks know that might work for this project? 

I've seen lots of good schema mapping tools online, but unclear that any of them are well suited for connecting the dots between two different database schemas.",datascience,https://www.reddit.com/r/datascience/comments/16zzta7/looking_for_a_tool_to_help_map_two_databases/,4,2,1.0,"[Comment(id='k3i5ryx'), Comment(id='k3i9gbb'), Comment(id='k3n3ucw'), Comment(id='k3s0j2z')]"
16zldu3,Breadskinjinhojiak,,2023-10-04 12:03:18+00:00,False,,False,False,True,False,/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/,What are some good scraping software to use for task automation?,"suppose that i have 1000 sites that i need to build a script to extract individually and need the data to be refreshed weekly, what are some tools/software that can help me to automate such task?",datascience,https://www.reddit.com/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/,1,5,1.0,[Comment(id='k3g7za1')]
16zsikw,meWhoObserves,,2023-10-04 16:59:17+00:00,False,,False,False,True,False,/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/,How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model?,"So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!

So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found, then it should return ""No object found"" or like that.",datascience,https://www.reddit.com/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/,1,2,1.0,[Comment(id='k3oam2b')]
16zh6dt,WadeEffingWilson,,2023-10-04 07:56:43+00:00,False,,False,False,True,False,/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/,"When building out a matrix profile for a time series, what tests can be used to determine that both the bin size and window size are optimal?","I'm playing around with adapting matrix profiles to my time series data and I want to ensure that the data and parameters are set correctly.

I'm working with a month's worth of data placed into 5-minute bins (288 samples/day). I initially rebinned to 1-hour but I wasn't sure whether or not that might hide certain higher frequency patterns or if it would just make it too noisy.

I'm also attempting to tune the window_size parameter used by the STUMPY python library (stumpy.stumpy function). This adjusts the length of the segments that the matrix profile algorithm uses to compare to measure similarity. If the window size is too small (fewer points), you are more likely to get incidental matches. If it's too large, you're less likely to appropriately match similar patterns.

There is seasonality in the series that reflects diurnal patters (activity spikes during peak operational hours and drops out during off-peak hours). Because of this, I wanted a window size of at least half a day (144 for 5m bins, 12 for 1h bins) or a third of a day (96 for 5m bins, 8 for 1h bins) to achieve the Nyquist frequency of the seasonality, if that makes sense.

Are there any tests that I could run to help identify and optimize both the size of the time bins and the window size?

One thing I noticed is that when adjusting the window size, the rate of change of the number of detected motifs isn't linear. I have a hunch that I could probably plot it out and use the elbow method but I need a sanity check before I try it out.

For the bin size, I usually use a Power Spectral Density plot to identify dominant frequencies (I mostly use that for selecting seasonality parameters for decompositions). For the 1h bucket series, there are 1-3 dominant frequencies well above the noise floor, which is good. However, when I use the 5m bucket series, there doesn't appear to be any dominant frequencies, just noise. Would that suggest that the 5m bucket series is suboptimal in terms of bin size compared to the 1h series?

I just need a second set of eyes on it to make sure I'm not misinterpreting or misunderstanding something. I'm also open to suggestions or ideas, if any are available.",datascience,https://www.reddit.com/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/,10,10,0.92,"[Comment(id='k3hma51'), Comment(id='k3i5omg'), Comment(id='k3fam9w'), Comment(id='k3i5eg6'), Comment(id='k3hslz2'), Comment(id='k3fealb'), Comment(id='k3hth1g'), Comment(id='k3fesxa'), Comment(id='k3hv1lh'), Comment(id='k3fg800')]"
16z2cge,bic-boy,,2023-10-03 20:21:49+00:00,False,,False,False,True,False,/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/,Do you just learn on the job?,"I studied data science in college, and I’m in my first job in a start up (been here about a year). There are three on our data science team (manager, another graduate and myself). Due to being in a start up, we all work on individual projects (as we do consultancy). Mainly data processing in sql/python + analysis

My manager is up to their neck in work, and I’d like if they had more time to actually teach us things. I am just learning by googling and doing. I think ideally in my head I would like to work on more projects with them, or maybe even shadow them once in a while and see how they would approach a problem or see their workflow. Is this normal?

I can read their code and analysis but I just feel isolated and would learn a lot more by actually interacting with them while working

Since joining have learned a lot more about ETL pipelines and cloud technologies, but honestly I’m not sure how much more I can learn here that I can’t learn in any other job.

I can do the work but I feel like I could be a lot more effective and efficient.

Do you just learn by doing in your job? Am I gaining the most knowledge that I can here? Is this normal? How did you advance to the next level?",datascience,https://www.reddit.com/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/,37,68,0.94,"[Comment(id='k3c4xzn'), Comment(id='k3ci13s'), Comment(id='k3c65bd'), Comment(id='k3di9l5'), Comment(id='k3c8lcz'), Comment(id='k3cqydl'), Comment(id='k3c1vsv'), Comment(id='k3d6n7w'), Comment(id='k3cuko4'), Comment(id='k3edyyy'), Comment(id='k3e361d'), Comment(id='k3czmbx'), Comment(id='k3h7v1x'), Comment(id='k3d7v17'), Comment(id='k3erv1i'), Comment(id='k3ftp0e'), Comment(id='k3yblyp'), Comment(id='k3dc691'), Comment(id='k3ca6cz'), Comment(id='k3et31e'), Comment(id='k3edh3d'), Comment(id='k49l365'), Comment(id='k3frrhq'), Comment(id='k49l57q'), Comment(id='k3ei4k9'), Comment(id='k3etmne'), Comment(id='k3cypui'), Comment(id='k3ezoqf'), Comment(id='k3f69xe'), Comment(id='k3elktn'), Comment(id='k3hvg8d'), Comment(id='k3i6uug'), Comment(id='k3f524v'), Comment(id='k3jzqmk'), Comment(id='k3i77zl'), Comment(id='k3gb9pt'), Comment(id='k3hqk87')]"
16znm3n,_rshaedy,,2023-10-04 13:43:40+00:00,False,,False,False,True,False,/r/datascience/comments/16znm3n/ais_data_cannibalism/,AI’s Data Cannibalism,"I'm looking to read more on this topic mentioned in the title.

&#x200B;

Feel free to suggest books and articles",datascience,https://www.reddit.com/r/datascience/comments/16znm3n/ais_data_cannibalism/,6,1,0.56,"[Comment(id='k3fgifd'), Comment(id='k3flbfb'), Comment(id='k3pwcoa'), Comment(id='k3ua3d8'), Comment(id='k3flee1'), Comment(id='k3xw8rv')]"
16ysfr3,jpnoro2003,,2023-10-03 13:48:54+00:00,False,,False,False,True,False,/r/datascience/comments/16ysfr3/how_often_do_you_use_operations_research_or_in/,How often do you use Operations Research (OR) in your work?,"I'm studying Operations Research in university, and I was wondering how often data scientists in different fields use OR, Linear programming, etc. In their work, and what tools they use. Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16ysfr3/how_often_do_you_use_operations_research_or_in/,40,73,0.97,"[Comment(id='k3ack12'), Comment(id='k3aj7h9'), Comment(id='k3ammm1'), Comment(id='k3cetpm'), Comment(id='k3ag51d'), Comment(id='k3b2q9x'), Comment(id='k3cf5gi'), Comment(id='k3b8xxg'), Comment(id='k3c5xx6'), Comment(id='k3eimvd'), Comment(id='k3autak'), Comment(id='k3ajlb5'), Comment(id='k3ddnn0'), Comment(id='k3b7gkl'), Comment(id='k3bcjz8'), Comment(id='k3bd80r'), Comment(id='k3byw57'), Comment(id='k3c15gz'), Comment(id='k3ckql5'), Comment(id='k3dkcuo'), Comment(id='k3emdix'), Comment(id='k4fr371'), Comment(id='k3c9sak'), Comment(id='k3f4zmv'), Comment(id='k3bi3fv'), Comment(id='k3cfs1v'), Comment(id='k3hb37j'), Comment(id='k3atz2p'), Comment(id='k3llmnc'), Comment(id='k3iyb9h'), Comment(id='k3c2n4v'), Comment(id='k3cfilr'), Comment(id='k3f7szn'), Comment(id='k3dbuwq'), Comment(id='k3cf2al'), Comment(id='k3dbrv3'), Comment(id='k3hq47i'), Comment(id='k3ayg51'), Comment(id='k3fh1ty'), Comment(id='k3dbnor')]"
16zi4jk,Kniggi,,2023-10-04 08:58:44+00:00,False,,False,False,True,False,/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/,Using pre-trained models as features?," Hey everyone!

Currently,  I am working on a project around music emotion classifcation/regression  model. Basically I am trying to predict a score to each emotion on a  given song.

The problem is that my  dataset has quite imbalanced scores (y). Most scores are centered  around a certain score range. Therefore, having difficulties predicting  scores that are further away of the mean values.

I  had this idea to bring in pre-trained (on other datasets and problems)  audio classification models into this as there are a bunch of good  performing pre-trained classification models out there already. The  prediction of these pre-trained models should be used as features (e.g.  prediction of genre, instrument etc) beside the original spectorgram in  my model.

I know this won't solve  the problem of imbalances in the scores but I thought maybe this could  improve the performance as the model would have more features to work  with.

Does this make sense?

I appreciate any input.",datascience,https://www.reddit.com/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/,3,2,0.75,"[Comment(id='k3f74c7'), Comment(id='k3g82u6'), Comment(id='k3ihmey')]"
16zcw19,Libran10,,2023-10-04 03:47:45+00:00,False,,False,False,True,False,/r/datascience/comments/16zcw19/project_ideas/,Project Ideas,"Hey guys
I’m looking for a project idea in Computer Vision. Been browsing through multiple datasets but haven’t been able to think of an idea that has not been implemented before. Can you guys help me out with some ideas? I’m a grad student. Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16zcw19/project_ideas/,9,2,0.67,"[Comment(id='k3ealhx'), Comment(id='k3eumvm'), Comment(id='k3eurfy'), Comment(id='k3l7z88'), Comment(id='k3ebt7a'), Comment(id='k3oatn9'), Comment(id='k4nnimi'), Comment(id='k4no40j'), Comment(id='k4np1ty')]"
16zi29z,Alertt_53,,2023-10-04 08:54:27+00:00,False,,1696410240.0,False,True,False,/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/,Seeking Feedback Mechanism for Our Python/Dash Analytics Platform,"We are in the process of developing a data analytics platform for our client. This platform is primarily built using Python and Dash. We're exploring options to allow our clients to provide comments on each section of the analytics platform containing multiple pages.

Does anyone know of any methods or tools that would facilitate this interactive feedback mechanism.

&#x200B;

It would be better if we could track individual user comments. ",datascience,https://www.reddit.com/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/,1,0,0.5,[]
16z8v18,MLquestionAccount,,2023-10-04 00:41:55+00:00,False,,False,False,True,False,/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/,"What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?","I am considering comparing mutual information scores, but I also don't think I understand MI well enough. 

For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is ""bad"" since this means X, Y would be redundant. I am not sure if my understanding here is correct. 

Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using ""present"" (1) and ""absent"" (0). The main issue I have run into doing this is that I am trying to then create a **distribution** to compare the features (such as seeing what percent of 1s and 0s I find in each feature), but here is the issue: 

Let's say that feature A has 50% 1s and 50% 0s, and feature B also has 50% 1s and 50% 0s. So, it will look as if the distribution of their values is identical, though it could be that feature A and B are ""opposites"":

Feat. A: [0, 0, 1, 1]

Feat. B: [1, 1, 0, 0]

So, I wonder if there is a better way to compare the distributions of the features once I have made the data ""present"" (1) and ""absent"" (0). 

I am also looking at making a Probability Density Function for each feature to compare them, but it's not clear to me how I would go about creating such a PDF for each feature given that I don't know what the probabilities associated actually are. Should I be binning the data then finding what percentage falls in these intervals?

______

Overall, I am looking for advice on where to find useful information on how to compare features for **unsupervised** feature selection, particularly in regards to how to use and compare mutual information scores, how to create PDFs for features, and how to compare distributions between features after they have been binned to avoid the problem I mentioned (with how [0, 0, 1, 1] and [1, 1, 0, 0] would appear to have the same distribution). 

Relevant textbook resources and other reliable source recommendations would be much appreciated. 

Thank you.",datascience,https://www.reddit.com/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/,4,4,1.0,"[Comment(id='k3f8m3o'), Comment(id='k3fjr8z'), Comment(id='k41alw2'), Comment(id='k5d9j7w')]"
16ygt96,samjenkins377,,2023-10-03 03:02:54+00:00,False,,False,False,True,False,/r/datascience/comments/16ygt96/the_lack_of_quality_on_this_sub/,The [lack of] quality on this sub,"It’s been clear this sub has been abandoned by its mods:

*Inactive on Reddit (>1year with no posts/comments):*
u/shaggorama, u/vogt4nick, u/StatsPhD

*Inactive on the Sub (>30d with no posts/comments):*
u/Geckel, u/browneyesays, u/mhermans, u/patrickSwayzeNU

*Active within the last 30d:*
u/dfphd, u/JaJan1, u/Omega037


Here are some of the posts obviously rule-breaking or off-topic that mods do NOT remove:

- [A person asking for online DA tools](https://reddit.com/r/datascience/s/wVrQkHrI4H)
- [A person asking about datasets](https://reddit.com/r/datascience/s/sAvfpDOc4I)
- [A person asking for recruiter’s responses lead times](https://reddit.com/r/datascience/s/b7ssIgMuik)
- [A person asking about cover letters](https://reddit.com/r/datascience/s/3sdLpNhMmL)
- ... the list goes on with absolute beginner questions, and low-quality posts. 

All these posts were written in less than 1 week. As we can see, mods do nothing.

The last post a mod did on the sub was 145 days ago.

What can be done to get the mods to act upon the rules they set themselves? At this pace, we’ll lose the few experienced DS who still roam around here.",datascience,https://www.reddit.com/r/datascience/comments/16ygt96/the_lack_of_quality_on_this_sub/,123,201,0.9,"[Comment(id='k3d1gs3'), Comment(id='k39tova'), Comment(id='k38reb7'), Comment(id='k38qb1d'), Comment(id='k39nkcr'), Comment(id='k394mvy'), Comment(id='k38ih2h'), Comment(id='k38q7o0'), Comment(id='k3a364q'), Comment(id='k38o886'), Comment(id='k399jrc'), Comment(id='k38v0xb'), Comment(id='k39uuin'), Comment(id='k38z44l'), Comment(id='k3ngqzm'), Comment(id='k38wcoz'), Comment(id='k399qmz'), Comment(id='k3a3h3h'), Comment(id='k3abk7z'), Comment(id='k3a4kc8'), Comment(id='k3aigvb'), Comment(id='k3bvp8c'), Comment(id='k3a60ig'), Comment(id='k3bicg4'), Comment(id='k3bolnq'), Comment(id='k3ekcu9'), Comment(id='k3kqfh9'), Comment(id='k3d1tbe'), Comment(id='k3a3y8y'), Comment(id='k3chzas'), Comment(id='k399c02'), Comment(id='k39szg0'), Comment(id='k3d4gp2'), Comment(id='k3d205c'), Comment(id='k39ro9t'), Comment(id='k3d259a'), Comment(id='k39v6ij'), Comment(id='k38l5s0'), Comment(id='k3a40aw'), Comment(id='k3aludy'), Comment(id='k38oloc'), Comment(id='k3d2t1b'), Comment(id='k3a585m'), Comment(id='k39zi4m'), Comment(id='k397n49'), Comment(id='k3d35aq'), Comment(id='k39schz'), Comment(id='k3acz1l'), Comment(id='k3d2y0t'), Comment(id='k3d3dgb'), Comment(id='k3c5yam'), Comment(id='k3a2jni'), Comment(id='k3a575k'), Comment(id='k39s68c'), Comment(id='k39zzg2'), Comment(id='k39xo6c'), Comment(id='k3a6u4l'), Comment(id='k38ottj'), Comment(id='k38wnbv'), Comment(id='k3a94qr'), Comment(id='k39b372'), Comment(id='k3a54g1'), Comment(id='k3a103e'), Comment(id='k3b94do'), Comment(id='k3a7ccd'), Comment(id='k3a68m2'), Comment(id='k3ajbsi'), Comment(id='k3axwzz'), Comment(id='k3a7p4h'), Comment(id='k39qrel'), Comment(id='k39mdi2'), Comment(id='k39ecf9'), Comment(id='k3a3wze'), Comment(id='k3bvf45'), Comment(id='k3a7el7'), Comment(id='k3asq65'), Comment(id='k39fecx'), Comment(id='k3acu7b'), Comment(id='k3cf7fu'), Comment(id='k3anyik'), Comment(id='k3aa9qi'), Comment(id='k39kqo1'), Comment(id='k3dy3ia'), Comment(id='k3aprhm'), Comment(id='k3ab5gz'), Comment(id='k39v9yt'), Comment(id='k3aqa7e'), Comment(id='k3ablzz'), Comment(id='k3f8yij'), Comment(id='k3aqil1'), Comment(id='k3ac1aa'), Comment(id='k3as2t5'), Comment(id='k3dng03'), Comment(id='k3aemec'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
16ylnuy,Scroller94,,2023-10-03 07:49:05+00:00,False,,False,False,True,False,/r/datascience/comments/16ylnuy/what_aspect_of_data_science_do_you_enjoy_the_most/,What aspect of Data Science do you enjoy the most?,"What part shines the brightest on your day/s? Do you never get enough of presenting data? The sense of pride & accomplishment when the project is finished? Just writing code in your favorite language?

My favorite in my limited experience is the idea spitballing phase of figuring out a solution. Throwing spaghetti at the wall, seeing what sticks and diving into how we could apply it to the problem at hand. I think it boils down to a sense of camaraderie & the chaotic diving down rabbit holes.",datascience,https://www.reddit.com/r/datascience/comments/16ylnuy/what_aspect_of_data_science_do_you_enjoy_the_most/,28,44,0.91,"[Comment(id='k39a3sh'), Comment(id='k3a04ri'), Comment(id='k39hppz'), Comment(id='k398q9g'), Comment(id='k39stp0'), Comment(id='k399d3j'), Comment(id='k3aa2oy'), Comment(id='k3a734h'), Comment(id='k398nd2'), Comment(id='k3ayew0'), Comment(id='k39tc4f'), Comment(id='k3a7cbl'), Comment(id='k3ee7dq'), Comment(id='k39y9eu'), Comment(id='k3agsus'), Comment(id='k3bf8lk'), Comment(id='k3cxym5'), Comment(id='k3d1usx'), Comment(id='k39ggho'), Comment(id='k3bbqnu'), Comment(id='k39u948'), Comment(id='k3bxvyt'), Comment(id='k3aevyo'), Comment(id='k3a2dql'), Comment(id='k39azaf'), Comment(id='k3ard1p'), Comment(id='k3foi6o'), Comment(id='k3a7bsn')]"
16yc89t,RuinedRyan,,2023-10-02 23:33:32+00:00,False,,False,False,True,False,/r/datascience/comments/16yc89t/hiring_hell/,Hiring hell,"Gonna keep this short because I know we hate talking about hiring 24/7, but I genuinely couldn’t believe what my team just went through. 

Medium sized financial firm and from top, there’s 10 or so positions specifically for new grads next May.

We posted our position and got 200+ applicants in a week. 

And sifting through them were a nightmare. So so many people who weren’t new grads when the description specifically said that, were analysts using excel, weren’t graduating programs but data boot camps, had rip-off personal projects at the top of their resume. 

It was infuriating. 
Finally got down to 10 for interviews, and ended up reaching out to internship managers to inquire about the kids. Several good reviews and we had 3 really impress us in technical interviews. 

Ended up with a pretty good one that accepted graduating with Comp Sci and Math, but still, it’s mind boggling that so many people apply to job postings they’re WAY under qualified for.  

Just a rant.",datascience,https://www.reddit.com/r/datascience/comments/16yc89t/hiring_hell/,123,195,0.69,"[Comment(id='k37wh7z'), Comment(id='k38e6ni'), Comment(id='k37p3pn'), Comment(id='k37xcj2'), Comment(id='k37wimu'), Comment(id='k38jw78'), Comment(id='k38fgl0'), Comment(id='k37y86c'), Comment(id='k385t5f'), Comment(id='k381jcp'), Comment(id='k37ziuq'), Comment(id='k37r73k'), Comment(id='k38h93g'), Comment(id='k37npiq'), Comment(id='k38chag'), Comment(id='k37qpzs'), Comment(id='k385whk'), Comment(id='k38nt7z'), Comment(id='k39d3fb'), Comment(id='k3997qb'), Comment(id='k38w9zp'), Comment(id='k38fy3f'), Comment(id='k392b28'), Comment(id='k39d7l8'), Comment(id='k39h0cs'), Comment(id='k38nl67'), Comment(id='k39sghj'), Comment(id='k38r6pw'), Comment(id='k38viws'), Comment(id='k39emal'), Comment(id='k38i8pq'), Comment(id='k38j7y5'), Comment(id='k3ar301'), Comment(id='k3b5dl4'), Comment(id='k3c0miu'), Comment(id='k38ncfz'), Comment(id='k3824xc'), Comment(id='k37ui5x'), Comment(id='k387cjn'), Comment(id='k38hh6t'), Comment(id='k38vir3'), Comment(id='k3b2gsu'), Comment(id='k3g72ue'), Comment(id='k38b046'), Comment(id='k397vrr'), Comment(id='k39ekri'), Comment(id='k38g2lx'), Comment(id='k38rqdh'), Comment(id='k39uj9z'), Comment(id='k39ur89'), Comment(id='k3a06ga'), Comment(id='k3a8i2g'), Comment(id='k3atp19'), Comment(id='k3ax455'), Comment(id='k3clsl0'), Comment(id='k3dt0rj'), Comment(id='k3egla7'), Comment(id='k38lrdo'), Comment(id='k380iq3'), Comment(id='k37xcp2'), Comment(id='k3atm9y'), Comment(id='k3adotc'), Comment(id='k37rtel'), Comment(id='k38uzsm'), Comment(id='k38woyx'), Comment(id='k3ag4fw'), Comment(id='k393abo'), Comment(id='k38461e'), Comment(id='k38ltoj'), Comment(id='k383cik'), Comment(id='k37vz49'), Comment(id='k37qlc2'), Comment(id='k37vt5g'), Comment(id='k39kh6j'), Comment(id='k4l95oj'), Comment(id='k38mrtq'), Comment(id='k392pji'), Comment(id='k39wwi4'), Comment(id='k38n7su'), Comment(id='k38nijz'), Comment(id='k39aif3'), Comment(id='k382uxw'), Comment(id='k38567s'), Comment(id='k3834c2'), Comment(id='k38gtd5'), Comment(id='k38wjt3'), Comment(id='k37zsmw'), Comment(id='k38n2ti'), Comment(id='k3cxzqh'), Comment(id='k381gid'), Comment(id='k37whfs'), Comment(id='k38ws7p'), Comment(id='k3a2yck'), Comment(id='k3agx8k'), Comment(id='k3eafuo'), Comment(id='k3c3wxo'), Comment(id='k382tq7'), Comment(id='k387wh9'), Comment(id='k39wr7o'), Comment(id='k3812up'), Comment(id='k4l9lf2'), Comment(id='k3ab4z5'), Comment(id='k38jmab'), Comment(id='k38pxj8'), Comment(id='k38wfgd'), Comment(id='k3830m1'), Comment(id='k3d0spr'), Comment(id='k3e1hxi'), Comment(id='k3ako9i'), Comment(id='k384oc6'), Comment(id='k3ajloa'), Comment(id='k39j40f'), Comment(id='k384l97'), Comment(id='k4lcfzw'), Comment(id='k3bmeyj'), Comment(id='k3e9ucn'), Comment(id='k3hs8oz'), Comment(id='k3gt09t'), Comment(id='k3a8fm7'), Comment(id='k39jhae'), Comment(id='k3fvam2'), Comment(id='k3hwfix'), Comment(id='k3i4do6')]"
16z8d2e,John198777,,2023-10-04 00:19:50+00:00,False,,False,False,True,False,/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/,Do you worry that outsourcing will take your job?,"I work in consultancy but I'm considering a pivot into data analysis. However, I am worried that companies can easily hire data analysts and scientists in other countries for a lot cheaper whereas consultancy is better protected against this due to the importance of face to face meetings, on site work and local knowledge.

Due to Covid, many companies have learnt how to create remote teams, which may accelerate this change further. 

Is this a major risk over the next five to 10 years? Can we expect fewer jobs in The West and lower wages due to outsourcing to other countries and remote working?",datascience,https://www.reddit.com/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/,18,2,0.56,"[Comment(id='k3d3q7r'), Comment(id='k3d54dg'), Comment(id='k3dbimf'), Comment(id='k3d9d6y'), Comment(id='k3dpukc'), Comment(id='k3evsh9'), Comment(id='k3ewaij'), Comment(id='k3dgxwp'), Comment(id='k3e2sjb'), Comment(id='k3giw1a'), Comment(id='k3gu1cs'), Comment(id='k3lb9k8'), Comment(id='k3obho7'), Comment(id='k3gb7mh'), Comment(id='k3dh797'), Comment(id='k3fx1iz'), Comment(id='k3hm59a'), Comment(id='k3hyd1o'), Comment(id='k3hynia')]"
16zgo76,swesweee,,2023-10-04 07:23:48+00:00,False,,False,False,True,False,/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/,Does anyone know any tools that helps people convert their python code into streamlit apps?,"I am a data scientist. I usually build ML models and convert them into streamlit apps. Does anyone know any tools that helps automatically convert my python/ML code into streamlit app so i can save the hassle.

&#x200B;

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/,4,0,0.33,"[Comment(id='k3o5nvz'), Comment(id='k3fbmv4'), Comment(id='k3ow43j'), Comment(id='k3o5qe3')]"
16yyleb,combrade,,2023-10-03 17:52:01+00:00,False,,False,False,True,False,/r/datascience/comments/16yyleb/doing_parttime_social_science_research/,Doing Part-Time Social Science Research,"I was wondering if this was an option as I just finished my master's degree, and I'm iffy about going for my Ph.D. My interest in research is Political Science research with Quantitative Methods.

I know that some think-tanks have unaffiliated fellows. and I know a few individuals that are Non-Resident Fellows at CSIS, but they're very senior and sometimes teach ML courses at universities as well.  

I basically just want to get a nonpaying part-time research analyst role so I can do academic research while not quitting my job in tech as a Data Engineer. Some of my friends have suggested just reaching out to professors asking if I can do research with them and if they need help doing research in R. But a think-tank or nonprofit would be great as then I can put that research on my resume or Linkedin.",datascience,https://www.reddit.com/r/datascience/comments/16yyleb/doing_parttime_social_science_research/,5,4,0.83,"[Comment(id='k3bfef7'), Comment(id='k3bwy6u'), Comment(id='k3d22zv'), Comment(id='k3d29pn'), Comment(id='k3d5lk1')]"
16yybuq,smarvin2,,2023-10-03 17:41:29+00:00,False,,False,False,False,False,/r/datascience/comments/16yybuq/indexing_large_datasets_a_5x_improvement_in/,Indexing Large Datasets - A 5x Improvement in Vector Recall Speed When Moving from IVFFlat to HNSW,,datascience,https://postgresml.org/blog/speeding-up-vector-recall-by-5x-with-hnsw,0,3,1.0,[]
16yvbbr,CryptographerDry7458,,2023-10-03 15:44:20+00:00,False,,False,False,True,False,/r/datascience/comments/16yvbbr/what_is_your_goto_for_data_quality_in_computer/,What is your go-to for data quality in Computer Vision?,"For those working on CV (unstructured data), how to you approach data quality?

I've been working with data quality for structured data, and I have my methods for assessing data quality, but I'm fairly new to CV and a bit confused about how to evaluate the quality of my data, specifically for computer vision applications.

I know that data quality is crucial for the success of any machine learning project, but when it comes to images and videos, what are the key factors I should be looking at to ensure that my data is up to par?

Are there any specific metrics or tools I should be using to measure the quality of my training data? And how can I tell if my dataset is biased or unrepresentative of the real-world scenarios I'm trying to tackle?

Any guidance or advice on assessing data quality for computer vision would be appreciated! Thanks in advance",datascience,https://www.reddit.com/r/datascience/comments/16yvbbr/what_is_your_goto_for_data_quality_in_computer/,4,5,1.0,"[Comment(id='k3dsh5q'), Comment(id='k49gykm'), Comment(id='k73t5ne'), Comment(id='k3dsje2')]"
16z0pwh,matus_pikuliak,,2023-10-03 19:16:22+00:00,False,,False,True,False,False,/r/datascience/comments/16z0pwh/multilingual_reading_skills_of_language_models/,Multilingual Reading Skills of Language Models,,datascience,https://www.opensamizdat.com/posts/belebele/,0,2,1.0,[]
16y0vfi,Excellent_Cost170,,2023-10-02 16:15:28+00:00,False,,False,False,True,False,/r/datascience/comments/16y0vfi/what_i_wish_i_had_known_earlier_in_my_career/,"What I wish I had known earlier in my career, particularly with disorganized companies"," I'm quoting directly from a Reddit user named funbike. This is the rule you should abide by in organizations. I also made the same mistake when I joined a company, attempting to prove myself.

"" 

After being a fool in my early career trying too hard to impress, this is how I handle this kind of thing these days:

* Document EVERYTHING. Follow-up verbal conversations with summary email. When things go south, I'll be able to prove I warned them.
* Give *realistic* estimates on how long things will take. Whatever I say is usually twice how long I actually think it will take, because things never go like you think.
* Make it clear that that longer-term estimates will be less accurate the farther out they are, because software is notoriously difficult to estimate.
* Tell them to their face that we *will not* make the unrealistic dates they've set, and to prevent in future to always consult first.
* I will *not* work overtime due to artificial deadlines. I'll do O/T for extreme exceptional cases only, such as a one-time short-term crisis or for a regulatory-mandated deadline. By 6pm I'll be at my house.
* Explain quality should never be abandoned for speed. It will violently backfire in the end, with the opposite effect.

I stand my ground. I can make them mildly unhappy now, or furiously disappointed in our results in the future. I'll take the first one please.

Even if you were to heroically meet their unreasonable date, they'll just expect more next time. You'll burn out and maybe the next time you'll have an embarrassing failure even with crazy overtime. They'll say ""tsk, tsk"" and blame you. Don't fall into this trap""",datascience,https://www.reddit.com/r/datascience/comments/16y0vfi/what_i_wish_i_had_known_earlier_in_my_career/,50,256,0.99,"[Comment(id='k35vxwf'), Comment(id='k36653b'), Comment(id='k369cmd'), Comment(id='k36bxct'), Comment(id='k36zmvt'), Comment(id='k36cnd5'), Comment(id='k35z35n'), Comment(id='k36afmj'), Comment(id='k37mbo8'), Comment(id='k370cce'), Comment(id='k37vhc8'), Comment(id='k36a2ld'), Comment(id='k35x0nu'), Comment(id='k36gk6c'), Comment(id='k37avyb'), Comment(id='k37fm70'), Comment(id='k37wg3w'), Comment(id='k3827fz'), Comment(id='k38b3qe'), Comment(id='k39a8m2'), Comment(id='k3aizmv'), Comment(id='k3c9yyj'), Comment(id='k368wd5'), Comment(id='k36co7r'), Comment(id='k374vzl'), Comment(id='k3axbus'), Comment(id='k36d433'), Comment(id='k39mobf'), Comment(id='k36fxh8'), Comment(id='k361ra2'), Comment(id='k3fuivb'), Comment(id='k370m5u'), Comment(id='k36fm7b'), Comment(id='k38asxy'), Comment(id='k3tzma8'), Comment(id='k37c1rx'), Comment(id='k36gli8'), Comment(id='k37hp5y'), Comment(id='k36glzj'), Comment(id='k36olbt'), Comment(id='k3hv8ph'), Comment(id='k370rwk'), Comment(id='k36jzdn'), Comment(id='k3umbn3'), Comment(id='k37fuqi'), Comment(id='k37cybm'), Comment(id='k37jzo0'), Comment(id='k36jfr4'), Comment(id='k379ju8'), Comment(id='k36mcww')]"
16z0gck,Dry-Growth4940,,2023-10-03 19:05:25+00:00,False,,False,False,True,False,/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/,Code Signal Data Analytics Framework Questions ?,"Was wondering if anyone gave the Data Analytics Framework assessment. 

Time crunch is a major factor I feel. The last of the questions and ability not to view SQL ctes were nightmare. 

&#x200B;

Score 338/600 after solving 10 questions out of 15. Is this any good ? ",datascience,https://www.reddit.com/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/,6,1,1.0,"[Comment(id='k56qsp1'), Comment(id='k5fle0q'), Comment(id='k6a798h'), Comment(id='k56rwmy'), Comment(id='k5gj085'), Comment(id='k5iimix')]"
16yqueg,BenchLeague,,2023-10-03 12:39:48+00:00,False,,False,False,False,False,/r/datascience/comments/16yqueg/network_theory_to_model_cfb_outcomes/,Network Theory to Model CFB outcomes,"Just thought I post some projects I have been working on in my free time. Trying to figure out the most objective way to rank fbs teams. 

Any cool projects y’all are working on?",datascience,https://i.redd.it/cz0ybu57gzrb1.jpg,0,2,1.0,[]
16xldj9,Inevitable-Quality15,,2023-10-02 03:00:49+00:00,False,,False,False,True,False,/r/datascience/comments/16xldj9/what_industries_wont_you_work_in_again_in/,What industries wont you work in again in datascience?,"For me,

Advertising -  Ive never had to help more co-workers with sql joins in my life. most analyst and data engineers ive worked with had horrible technical skills and leadership was ok with that.  They just bought them alteryx and my email box continuously got spammed emails on a loop because they kept forgetting the one record node and all my data started getting dupes in my database.

Finance -  I started my career at a large financial institution and want something a bit more laid back.

&#x200B;

On the flipside, ive had good experience in automotive. all my coworkers were extremely technically competent and i learned alot. i did some cool projects too that got me started in datascience",datascience,https://www.reddit.com/r/datascience/comments/16xldj9/what_industries_wont_you_work_in_again_in/,130,249,0.97,"[Comment(id='k33lsa9'), Comment(id='k34dk7b'), Comment(id='k33mk7r'), Comment(id='k33ffxv'), Comment(id='k34vf4g'), Comment(id='k34gbuk'), Comment(id='k33drr3'), Comment(id='k33rmhz'), Comment(id='k34i5ok'), Comment(id='k34n4yn'), Comment(id='k345t6k'), Comment(id='k35l6nf'), Comment(id='k36yo3o'), Comment(id='k35i7jd'), Comment(id='k35hvnf'), Comment(id='k350o2e'), Comment(id='k357cgn'), Comment(id='k35bsaw'), Comment(id='k35jlpy'), Comment(id='k35nnqj'), Comment(id='k367z37'), Comment(id='k38gqjf'), Comment(id='k33revz'), Comment(id='k357vnn'), Comment(id='k35mptj'), Comment(id='k35v4aw'), Comment(id='k37e28l'), Comment(id='k37oiq8'), Comment(id='k37ri77'), Comment(id='k387e9s'), Comment(id='k38orwk'), Comment(id='k38qzkk'), Comment(id='k38sqq9'), Comment(id='k3bn3gn'), Comment(id='k3bsc8e'), Comment(id='k3c67nr'), Comment(id='k3nvtqx'), Comment(id='k345212'), Comment(id='k357ja2'), Comment(id='k36wlap'), Comment(id='k35in0v'), Comment(id='k35s9im'), Comment(id='k38hy9s'), Comment(id='k359iow'), Comment(id='k34udfq'), Comment(id='k34upef'), Comment(id='k38iu7n'), Comment(id='k3f0zws'), Comment(id='k34isg2'), Comment(id='k34lrvt'), Comment(id='k35si1w'), Comment(id='k35ym5q'), Comment(id='k37cn3a'), Comment(id='k35y12c'), Comment(id='k34vmhs'), Comment(id='k34o4ii'), Comment(id='k33uzet'), Comment(id='k33i02t'), Comment(id='k33i5x3'), Comment(id='k35oesc'), Comment(id='k34x5ou'), Comment(id='k34tddn'), Comment(id='k35mv86'), Comment(id='k35aman'), Comment(id='k37d8sy'), Comment(id='k38x4se'), Comment(id='k34nui3'), Comment(id='k34yyi1'), Comment(id='k34szgo'), Comment(id='k38prma'), Comment(id='k34nvx5'), Comment(id='k35hwqi'), Comment(id='k38t3n0'), Comment(id='k39ab0g'), Comment(id='k36vkv4'), Comment(id='k34lwlo'), Comment(id='k38t4ih'), Comment(id='k36yyfe'), Comment(id='k35xyqr'), Comment(id='k35yhad'), Comment(id='k349263'), Comment(id='k35g5ww'), Comment(id='k3br1jg'), Comment(id='k3dgcvl'), Comment(id='k35yhzm'), Comment(id='k387qhq'), Comment(id='k3budz6'), Comment(id='k36za99'), Comment(id='k37u959'), Comment(id='k3966k9'), Comment(id='k35q74a'), Comment(id='k38wt6g'), Comment(id='k35t85h'), Comment(id='k35ptdj'), Comment(id='k33rg5f'), Comment(id='k3andqi'), Comment(id='k37k5h6'), Comment(id='k36fc0r'), Comment(id='k34o8tm'), Comment(id='k3gqb27'), Comment(id='k34nqii'), Comment(id='k35nbkb'), Comment(id='k37btgp'), Comment(id='k3641it'), Comment(id='k34lcov'), Comment(id='k3gwykk'), Comment(id='k3bv0am'), Comment(id='k3709bc'), Comment(id='k373fie'), Comment(id='k37cwjd'), Comment(id='k362p1x'), Comment(id='k36g8cy'), Comment(id='k33s5t3'), Comment(id='k37nylc'), Comment(id='k38x3ij'), Comment(id='k34oeu7'), Comment(id='k35tjqp'), Comment(id='k37paot'), Comment(id='k36bipi'), Comment(id='k34y5wm'), Comment(id='k3bv9mk'), Comment(id='k35yqgy'), Comment(id='k38huwx'), Comment(id='k37qhnx'), Comment(id='k34yx35'), Comment(id='k372ftp'), Comment(id='k39m4yx'), Comment(id='k382yl6'), Comment(id='k355jvo'), Comment(id='k35gddr'), Comment(id='k35m22u')]"
16z3y8h,,,2023-10-03 21:23:41+00:00,False,,False,False,True,False,/r/datascience/comments/16z3y8h/llms/,LLMs?,"I'm a FAANG data scientist with 5+ years of experience; I've grown increasingly concerned that LLMs will begin to replace a LOT of the work that data professionals currently do. From easy things like dashboard generation to tough things like specific deep dive research questions, seem like we're walking into a world where the skillset of the analyst / scientist is a pre-req for a different position as opposed to a job in and of itself.

Thoughts? How are you preparing for much of this work to become automated? What other skills do you think are on the horizon (please don't say prompt engineering)?",datascience,https://www.reddit.com/r/datascience/comments/16z3y8h/llms/,117,0,0.44,"[Comment(id='k3cdclm'), Comment(id='k3cd14p'), Comment(id='k3cipdn'), Comment(id='k3cusmu'), Comment(id='k3cn72w'), Comment(id='k3cudur'), Comment(id='k3czrkc'), Comment(id='k3cnfke'), Comment(id='k3cftbh'), Comment(id='k3co3ht'), Comment(id='k3e2gjb'), Comment(id='k3ckgut'), Comment(id='k3cnj7g'), Comment(id='k3cmtg1'), Comment(id='k3cza8w'), Comment(id='k3clbi9'), Comment(id='k3cmzp1'), Comment(id='k3cx6sq'), Comment(id='k3d38yc'), Comment(id='k3d7nq5'), Comment(id='k3d9lob'), Comment(id='k3dl0oq'), Comment(id='k3edaz2'), Comment(id='k3ej8m3'), Comment(id='k3fegna'), Comment(id='k3gufbi'), Comment(id='k3jy9m7'), Comment(id='k3l5two'), Comment(id='k3oxh29'), Comment(id='k406o1k'), Comment(id='k3cfxyd'), Comment(id='k3cjghv'), Comment(id='k3d9na8'), Comment(id='k3cfd5g'), Comment(id='k3cvcij'), Comment(id='k3gcjkg'), Comment(id='k3ox4z1'), Comment(id='k3cxyet'), Comment(id='k3ciewu'), Comment(id='k3cdzlo'), Comment(id='k3cjvui'), Comment(id='k3dbll4'), Comment(id='k3czvpp'), Comment(id='k3co8qm'), Comment(id='k3cgf4d'), Comment(id='k3cld6w'), Comment(id='k3cobaq'), Comment(id='k3cohgf'), Comment(id='k3d9pks'), Comment(id='k3cxv5p'), Comment(id='k3dabrp'), Comment(id='k3gttym'), Comment(id='k3cxlw9'), Comment(id='k3doso3'), Comment(id='k3czfm7'), Comment(id='k3gcr5o'), Comment(id='k3fe52d'), Comment(id='k3d96ls'), Comment(id='k3d8o5s'), Comment(id='k3ckjed'), Comment(id='k3cfatq'), Comment(id='k3cvngk'), Comment(id='k3cl6ud'), Comment(id='k3dcq1u'), Comment(id='k3d3mqy'), Comment(id='k3culqo'), Comment(id='k3ch9sd'), Comment(id='k3cylve'), Comment(id='k3dghzp'), Comment(id='k3cz36o'), Comment(id='k3cnpsp'), Comment(id='k3crzr0'), Comment(id='k3d09t7'), Comment(id='k3doc4t'), Comment(id='k3dt17z'), Comment(id='k3ei8gc'), Comment(id='k3fl4c5'), Comment(id='k3dd3dj'), Comment(id='k3ddsz3'), Comment(id='k3dm46v'), Comment(id='k3coaij'), Comment(id='k3d3x26'), Comment(id='k3cukvj'), Comment(id='k3cfvw4'), Comment(id='k3d9emw'), Comment(id='k3cnd7u'), Comment(id='k3d5lxe'), Comment(id='k3citt3'), Comment(id='k3cosor'), Comment(id='k3d415u'), Comment(id='k3d46ev'), Comment(id='k3dldc9'), Comment(id='k3cphpw'), Comment(id='k3d4dsm'), Comment(id='k3cota6'), Comment(id='k3cw8gx'), Comment(id='k3dakrx'), Comment(id='k3d4pfz'), Comment(id='k3ck2vc'), Comment(id='k3czeba'), Comment(id='k3dl2ol'), Comment(id='k3cw92d'), Comment(id='k3cw9x6'), Comment(id='k3d4zm9'), Comment(id='k3dlndq'), Comment(id='k3cpnwn'), Comment(id='k3db994'), Comment(id='k3d6xuc'), Comment(id='k3cn9aa'), Comment(id='k3cl1c2'), Comment(id='k3d37eu'), Comment(id='k3d4ens'), Comment(id='k3f2dbb'), Comment(id='k3dbww2'), Comment(id='k3d4o0e'), Comment(id='k3dchfe'), Comment(id='k3djly3'), Comment(id='k3d75ix'), Comment(id='k3dg0et')]"
16xxndf,SuitableElk7382,,2023-10-02 14:09:48+00:00,False,,1696260368.0,False,True,False,/r/datascience/comments/16xxndf/how_do_you_handle_making_mistakes_on_the_job/,How do you handle making mistakes on the job?,"What are some of the biggest mistakes you guys have made and how do you handle them?  Especially when there is a time crunch.

I’m a quality data analyst for a steel company and have been in this position for almost 2 years.  I finished my masters in data analytics this past May, so this job has been my only real experience in the world of data.  I want to transition to data science in this next year.  In my free time, I take Codecademy courses to learn Python and SQL and I will eventually dive into Java as well.  I take what I learn and I try to apply it to my job.  We’re a legacy steel mill, so there is no fancy automation, the business and production systems don’t communicate very well, data can only be gathered through exporting reports from these systems in csv files.  So I’ve been able to sort of make my own database using the tools I’ve been approved to download (basically just anaconda and power bi).

As the only data analyst in my mill, with no previous steel making background, my company relies heavily on my data analytics to make business decisions both small and large and sometimes is overwhelming pressure to be precise.  Luckily I haven’t had any major mistakes.  The downside is I’m the only person doing the job I do and there isn’t a whole lot of computer literacy in the management, so unless my conclusions appear extremely illogical to them, they just roll with it. I’ve definitely made mistakes along the way but have caught them myself, sometimes working through the night so I can hurry and send emails out to disregard my previous work and look at the revised stuff.  

This just made me wonder how others handle mistakes both when they catch it and when they don’t catch it.  I understand larger companies probably have a team of people doing the same projects or can lend a hand to be a 2nd pair of eyes.  

Maybe I’m just overdue to make my first big mistake lol.  I feel like I make a lot of decisions day-to-day that I have to cross my fingers on.",datascience,https://www.reddit.com/r/datascience/comments/16xxndf/how_do_you_handle_making_mistakes_on_the_job/,21,21,0.93,"[Comment(id='k35ah9l'), Comment(id='k35ab61'), Comment(id='k358e0o'), Comment(id='k360rbd'), Comment(id='k35n97f'), Comment(id='k36p14r'), Comment(id='k36jykl'), Comment(id='k36gnrs'), Comment(id='k370zkk'), Comment(id='k3721rk'), Comment(id='k36nvs7'), Comment(id='k3921gn'), Comment(id='k3qa4xe'), Comment(id='k35fywd'), Comment(id='k367l36'), Comment(id='k374dsx'), Comment(id='k36mut6'), Comment(id='k3639hj'), Comment(id='k36seq9'), Comment(id='k36nhjz'), Comment(id='k36s8ki'), Comment(id='k36n09t')]"
16x6t1p,aGuyAndHisWood,,2023-10-01 17:15:37+00:00,False,,1696180894.0,False,True,False,/r/datascience/comments/16x6t1p/my_f100_company_analyzed_why_our_good_data/,My F100 company analyzed why our good data scientists are good and here's the recap,"A small team of internal researchers inside the company spent time investigating which data scientists preformed the best, which preformed the worst, and what factors played into this. 

The top 3 indicators of a high preforming data scientist were:
1. The number one predictor of a preformant data scientist was proactive communication. Be it speaking up in meetings, pinging people in chat, voicing concerns with a work plan, these data scientists communicated on their own initiative and their ability to get things done and make an impact is recognized. 
2. They are capable of flushing out requirements and working on complicated tasks without managerial intervention. A good example of this could be manager says we need to build a model that satisfies xyz objectives and that there are additional business reqs we'll need to flush out. 2 or 3 data scientists go do all the work to get the data and flush out the requirments while making all the plans amongst themselves and basically just keeping the manager in the loop on what's happening. 
3. They focus on adding value over pursuing technical solutions. Often times the simpler modeling approach is good enough and it solves the problem in a quick fashion. 


Things noted about low preforming data scientists were:
1. They were reactive in their communication
2. They often times missed deadlines that they themselves set and never communicated that there were issues or that the deadline would be missed. 
3. They often focus on tasks like attending all of their meetings or immediatly responding to emails rather than meeting project goals and deadlines
4. They focus too much on perfecting the POC solution which later leads to a lot of rework / wasted time.
5. They're overly dismissive in their communication. Weather it be asking for feedback and validation and then disregarding it when it doesn't align with their ideas or simply dismissing the ideas of others in general. 
6. They create drama.",datascience,https://www.reddit.com/r/datascience/comments/16x6t1p/my_f100_company_analyzed_why_our_good_data/,178,482,0.9,"[Comment(id='k30uzz4'), Comment(id='k318yce'), Comment(id='k311aaf'), Comment(id='k318psu'), Comment(id='k32q4hb'), Comment(id='k31e0ij'), Comment(id='k31gify'), Comment(id='k31a7ig'), Comment(id='k31od3n'), Comment(id='k31nvzm'), Comment(id='k317ldf'), Comment(id='k31avs3'), Comment(id='k32etvv'), Comment(id='k31ft9j'), Comment(id='k3187s1'), Comment(id='k315cdc'), Comment(id='k33by5l'), Comment(id='k31ewx9'), Comment(id='k31gwut'), Comment(id='k32vb4y'), Comment(id='k33v7pr'), Comment(id='k352l49'), Comment(id='k35l3o7'), Comment(id='k36i9w7'), Comment(id='k3sejwv'), Comment(id='k32xumo'), Comment(id='k32yp96'), Comment(id='k30vmi5'), Comment(id='k30vvu9'), Comment(id='k31qe8q'), Comment(id='k32k6r1'), Comment(id='k31zqna'), Comment(id='k33kw0q'), Comment(id='k31ce4z'), Comment(id='k31k1uz'), Comment(id='k320tgx'), Comment(id='k33465p'), Comment(id='k32hssl'), Comment(id='k32tjhm'), Comment(id='k32tltg'), Comment(id='k334cvr'), Comment(id='k337hbs'), Comment(id='k337n90'), Comment(id='k33h2mh'), Comment(id='k33kdtd'), Comment(id='k33olko'), Comment(id='k33xcm7'), Comment(id='k3443kj'), Comment(id='k34i6st'), Comment(id='k34thgd'), Comment(id='k34zorj'), Comment(id='k354sqn'), Comment(id='k3nrulu'), Comment(id='k3rr2lv'), Comment(id='k30yfgr'), Comment(id='k31j7cc'), Comment(id='k31qm7z'), Comment(id='k320f0b'), Comment(id='k3147tq'), Comment(id='k3224sw'), Comment(id='k30vfh8'), Comment(id='k315qu3'), Comment(id='k36yhto'), Comment(id='k32lcmf'), Comment(id='k32hfcg'), Comment(id='k314ywe'), Comment(id='k31u71v'), Comment(id='k36zn1j'), Comment(id='k3281r1'), Comment(id='k329u8t'), Comment(id='k3236rv'), Comment(id='k33i41h'), Comment(id='k31l5nh'), Comment(id='k31ybl8'), Comment(id='k33qrm2'), Comment(id='k33lie9'), Comment(id='k31fzyk'), Comment(id='k3801n4'), Comment(id='k315zy7'), Comment(id='k32c38k'), Comment(id='k32pw1z'), Comment(id='k31643j'), Comment(id='k3169hm'), Comment(id='k32y3mn'), Comment(id='k33hhn1'), Comment(id='k314ywn'), Comment(id='k30xcmz'), Comment(id='k3110dw'), Comment(id='k33qvoo'), Comment(id='k326p7i'), Comment(id='k33he02'), Comment(id='k315d2p'), Comment(id='k31imgk'), Comment(id='k31tp3y'), Comment(id='k31ufa6'), Comment(id='k320m1p'), Comment(id='k327wo0'), Comment(id='k32kdh4'), Comment(id='k35sulg'), Comment(id='k35amuw'), Comment(id='k33kabp'), Comment(id='k39sd21'), Comment(id='k31928s'), Comment(id='k315v3q'), Comment(id='k31ix6y'), Comment(id='k32dgqz'), Comment(id='k367s9o'), Comment(id='k33pucm'), Comment(id='k3192bb'), Comment(id='k32dso3'), Comment(id='k352vt7'), Comment(id='k35hwvu'), Comment(id='k36glsp'), Comment(id='k31or27'), Comment(id='k35livt'), Comment(id='k32ciat'), Comment(id='k316ca6'), Comment(id='k315ilu'), Comment(id='k326kwy'), Comment(id='k31trio'), Comment(id='k31wcwf'), Comment(id='k34ucfd'), Comment(id='k31w6ag'), Comment(id='k329pvd'), Comment(id='k32d70d'), Comment(id='k316vqr'), Comment(id='k31m1bp'), Comment(id='k331lel'), Comment(id='k36faz9'), Comment(id='k33qo4w'), Comment(id='k31cvxl'), Comment(id='k37ue7i'), Comment(id='k32ggom'), Comment(id='k31u80c'), Comment(id='k32swh4'), Comment(id='k32fopr'), Comment(id='k34nv5x'), Comment(id='k35hbb3'), Comment(id='k32cz5s'), Comment(id='k31wtch'), Comment(id='k33c0u0'), Comment(id='k32bcle'), Comment(id='k32cj8h'), Comment(id='k317yxo'), Comment(id='k31afry'), Comment(id='k32116o'), Comment(id='k33x0sf'), Comment(id='k371wxx'), Comment(id='k38hm6w'), Comment(id='k34ja5v'), Comment(id='k31dofb'), Comment(id='k39di3t'), Comment(id='k33i6qk'), Comment(id='k34u48x'), Comment(id='k32dx1o'), Comment(id='k31xi7g'), Comment(id='k32d0jc'), Comment(id='k3446gl'), Comment(id='k31oyzr'), Comment(id='k31olfy'), Comment(id='k33mn69'), Comment(id='k32i6bf'), Comment(id='k34jk1s'), Comment(id='k376zed'), Comment(id='k368cta'), Comment(id='k33ntax'), Comment(id='k3aammv'), Comment(id='k32e8o8'), Comment(id='k32gle9'), Comment(id='k31y2cy'), Comment(id='k35y2dh'), Comment(id='k3611u0'), Comment(id='k34xcvu'), Comment(id='k32jg27'), Comment(id='k37o91q'), Comment(id='k36bx3q'), Comment(id='k370bhl'), Comment(id='k36eqj5'), Comment(id='k36qq17'), Comment(id='k36rpeo'), <MoreComments count=0, children=[]>]"
16y7fcy,corey1505,,2023-10-02 20:28:58+00:00,False,,False,False,False,False,/r/datascience/comments/16y7fcy/rmmlus_moral_scenarios_benchmark_doesnt_measure/,[R]MMLU’s Moral Scenarios Benchmark Doesn’t Measure What You Think it Measures,,datascience,https://medium.com/p/74fd6e512521,0,0,0.5,[]
16xwqmd,frodegrodas,,2023-10-02 13:31:48+00:00,False,,False,False,True,False,/r/datascience/comments/16xwqmd/roi_framework_for_data_science/,ROI framework for data science,Does anyone know of a good example of a return on investment framework for data science work? Or even a set of principles to work from? My team wants to demonstrate its value (more objectively) - and estimate the value generated from proposed initiatives - but there's little to go on in the literature.,datascience,https://www.reddit.com/r/datascience/comments/16xwqmd/roi_framework_for_data_science/,1,2,0.75,[Comment(id='k3ocsen')]
16y0lih,Remarkable-Floor-351,,2023-10-02 16:04:49+00:00,False,,False,False,True,False,/r/datascience/comments/16y0lih/how_long_did_it_take_you_to_selflearn_data/,"How long did it take you to self-learn data science and afterwards, how long to get employed?","To anyone who taught themselves data science and then achieved employment in a data science role, how long did it take you to learn in hours per day? And additionally, how long did it take you after you stopped learning to find a job and keep a job?

If you did not self learn or hold a job afterwards please do not reply with any speculations. ",datascience,https://www.reddit.com/r/datascience/comments/16y0lih/how_long_did_it_take_you_to_selflearn_data/,12,2,0.55,"[Comment(id='k35ybfb'), Comment(id='k35v0nd'), Comment(id='k368pk6'), Comment(id='k392r8p'), Comment(id='k3ajuww'), Comment(id='k3a7oq7'), Comment(id='k3a7gru'), Comment(id='k3b6s52'), Comment(id='k3abakk'), Comment(id='k3c4uix'), Comment(id='k3aeahc'), Comment(id='k3ajnt4')]"
16xmlky,AutoModerator,,2023-10-02 04:01:48+00:00,False,,False,False,True,False,/r/datascience/comments/16xmlky/weekly_entering_transitioning_thread_02_oct_2023/,"Weekly Entering & Transitioning - Thread 02 Oct, 2023 - 09 Oct, 2023"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",datascience,https://www.reddit.com/r/datascience/comments/16xmlky/weekly_entering_transitioning_thread_02_oct_2023/,127,9,1.0,"[Comment(id='k3g4qx6'), Comment(id='k3iz40c'), Comment(id='k3ne2oo'), Comment(id='k3z43t3'), Comment(id='k354fjm'), Comment(id='k359t99'), Comment(id='k37akz1'), Comment(id='k3aooaq'), Comment(id='k3b0dce'), Comment(id='k3b6b3e'), Comment(id='k3d2day'), Comment(id='k3g1odr'), Comment(id='k3gtyf4'), Comment(id='k3lhlbw'), Comment(id='k3mce42'), Comment(id='k3ospzb'), Comment(id='k3p2ptf'), Comment(id='k3ri324'), Comment(id='k3ry09p'), Comment(id='k41t55y'), Comment(id='k3t8916'), Comment(id='k3bqxd3'), Comment(id='k3n9rf0'), Comment(id='k3rbx2e'), Comment(id='k3u2szm'), Comment(id='k3ujint'), Comment(id='k3ych2x'), Comment(id='k36oewu'), Comment(id='k397f1r'), Comment(id='k3a8tw4'), Comment(id='k3aak2s'), Comment(id='k3an4j0'), Comment(id='k3an9yr'), Comment(id='k3anycg'), Comment(id='k3ao0ca'), Comment(id='k3aq76b'), Comment(id='k3aua49'), Comment(id='k3awljl'), Comment(id='k3bvpbj'), Comment(id='k3cscyn'), Comment(id='k3cthwc'), Comment(id='k3cvxos'), Comment(id='k3dgq7c'), Comment(id='k3e18sf'), Comment(id='k3evrwb'), Comment(id='k3fimq1'), Comment(id='k3fjl4u'), Comment(id='k3g2liq'), Comment(id='k3gtytd'), Comment(id='k3ivwup'), Comment(id='k3jtgp0'), Comment(id='k3k7ffy'), Comment(id='k3kd9mz'), Comment(id='k3l3ax5'), Comment(id='k3nayhn'), Comment(id='k3nbeq8'), Comment(id='k3ofstt'), Comment(id='k3t5soc'), Comment(id='k3xte9h'), Comment(id='k3zicgn'), Comment(id='k41vv1s'), Comment(id='k42y66j'), Comment(id='k4308uq'), Comment(id='k4342h4'), Comment(id='k3jgxdo'), Comment(id='k3rir45'), Comment(id='k3pn87b'), Comment(id='k3zk42l'), Comment(id='k371b75'), Comment(id='k36rcye'), Comment(id='k37r89c'), Comment(id='k3b4yea'), Comment(id='k3cysc5'), Comment(id='k3ixkkr'), Comment(id='k3mq5gr'), Comment(id='k3t3cvo'), Comment(id='k3rhf6j'), Comment(id='k3pgi1b'), Comment(id='k4nuzkv'), Comment(id='k432ne2'), Comment(id='k41xre6'), Comment(id='k3c35l8'), Comment(id='k3rh7rc'), Comment(id='k3wb27s'), Comment(id='k36rvco'), Comment(id='k36xq4z'), Comment(id='k3b5et2'), Comment(id='k3b4sg8'), Comment(id='k3cxltb'), Comment(id='k3jhmdo'), Comment(id='k3j8x0e'), Comment(id='k3g0c3p'), Comment(id='k3g09he'), Comment(id='k3inydu'), Comment(id='k80gta4'), Comment(id='k3mr40u'), Comment(id='k3nrbj8'), Comment(id='k3rj2dx'), Comment(id='k4nuchz'), Comment(id='k3puzv8'), Comment(id='k4mumz0'), Comment(id='k3tavia'), Comment(id='k3tagxi'), Comment(id='k3pgnhi'), Comment(id='k3rijmx'), Comment(id='k3yhc6m'), Comment(id='k36ueqc'), Comment(id='k36zdpi'), Comment(id='k3d3112'), Comment(id='k3jn3uw'), Comment(id='k3kgq7a'), Comment(id='k3g3sv6'), Comment(id='k3g5bq1'), Comment(id='k3nri6b'), Comment(id='k3q03uj'), Comment(id='k4n187h'), Comment(id='k3zsue8'), Comment(id='k3tbjpr'), Comment(id='k3rm33u'), Comment(id='k372mix'), Comment(id='k3t3i8i'), Comment(id='k3rn004'), Comment(id='k37596j'), Comment(id='k3rocm2'), Comment(id='k377j8i'), Comment(id='k3rqo9r'), Comment(id='k3rtba4'), Comment(id='k3rve2v')]"
16wwiew,Auwal_adam,,2023-10-01 09:21:00+00:00,False,,False,False,False,False,/r/datascience/comments/16wwiew/how_true_is_this/,How true is this?,,datascience,https://i.redd.it/1rfskuxv6krb1.jpg,103,265,0.93,"[Comment(id='k2zcft9'), Comment(id='k2zbwiy'), Comment(id='k2zgtr0'), Comment(id='k30b5h9'), Comment(id='k2z9rso'), Comment(id='k2zhrhb'), Comment(id='k309sst'), Comment(id='k30hzbl'), Comment(id='k30co0t'), Comment(id='k306zfn'), Comment(id='k322kmo'), Comment(id='k2zin7b'), Comment(id='k30kplr'), Comment(id='k31csk1'), Comment(id='k318od8'), Comment(id='k326efm'), Comment(id='k2zv52b'), Comment(id='k2zcggj'), Comment(id='k2ztlv0'), Comment(id='k2zkqov'), Comment(id='k2zxo0k'), Comment(id='k30jc4t'), Comment(id='k31p4as'), Comment(id='k32yspm'), Comment(id='k33x3wr'), Comment(id='k34inrt'), Comment(id='k35ai0v'), Comment(id='k3mtvfo'), Comment(id='k31qvqw'), Comment(id='k2zde9r'), Comment(id='k2zl5wx'), Comment(id='k2zlqtv'), Comment(id='k2ztb5x'), Comment(id='k326zh7'), Comment(id='k32xkfu'), Comment(id='k2zl6x0'), Comment(id='k31afd7'), Comment(id='k330hz7'), Comment(id='k305939'), Comment(id='k30oyqm'), Comment(id='k316qov'), Comment(id='k3824zz'), Comment(id='k30gmya'), Comment(id='k327jhu'), Comment(id='k3ag0ao'), Comment(id='k317frv'), Comment(id='k328du4'), Comment(id='k31cx7i'), Comment(id='k366b7p'), Comment(id='k30gdag'), Comment(id='k302uto'), Comment(id='k308uke'), Comment(id='k2zsrlx'), Comment(id='k30kjab'), Comment(id='k30kx3k'), Comment(id='k34an3g'), Comment(id='k31tanc'), Comment(id='k31wfev'), Comment(id='k31wiq8'), Comment(id='k327ixw'), Comment(id='k373gt6'), Comment(id='k33tzl2'), Comment(id='k2zw2x7'), Comment(id='k30coau'), Comment(id='k31xfee'), Comment(id='k35av07'), Comment(id='k3ydj9c'), Comment(id='k319h9c'), Comment(id='k3d0un0'), Comment(id='k32ofyw'), Comment(id='k361ibj'), Comment(id='k31s9fd'), Comment(id='k30k64i'), Comment(id='k30kc51'), Comment(id='k3053s8'), Comment(id='k2zxq9l'), Comment(id='k30li7i'), Comment(id='k33fa6k'), Comment(id='k327o83'), Comment(id='k32r28x'), Comment(id='k37q9pt'), Comment(id='k30qsyz'), Comment(id='k31bf3b'), Comment(id='k3odle8'), Comment(id='k3670qe'), Comment(id='k3632bg'), Comment(id='k327725'), Comment(id='k30mrf9'), Comment(id='k31qvfs'), Comment(id='k3084j9'), Comment(id='k318jjo'), Comment(id='k33x7dj'), Comment(id='k32qxdw'), Comment(id='k30xifj'), Comment(id='k31skle'), Comment(id='k327cnr'), Comment(id='k31dh0y'), Comment(id='k32vemc'), Comment(id='k32qvi7'), Comment(id='k329kxz'), Comment(id='k32yku0'), Comment(id='k34a0k7'), Comment(id='k34aoow')]"
16xzxkb,Brief-Living-5083,,2023-10-02 15:39:41+00:00,False,,False,False,True,False,/r/datascience/comments/16xzxkb/which_industries_have_the_most_lacking_data/,Which industries have the most lacking data architecture for data analysis/modelling?,"I have noticed some industries or domains are lacking in integrated data architecture (data warehouse, let alone data lake). One example that comes to mind is marketing where the different levels in data sources makes it difficult for integrated data architecture, hence, also difficult for cross-source analysis for the KPIs.
And also on the vice versa which domains are leading in this?",datascience,https://www.reddit.com/r/datascience/comments/16xzxkb/which_industries_have_the_most_lacking_data/,2,1,0.6,"[Comment(id='k35jlm0'), Comment(id='k3a39cg')]"
16xzuxi,01jasper,,2023-10-02 15:36:50+00:00,False,,False,False,True,False,/r/datascience/comments/16xzuxi/benefits_of_converting_dicom_images_to_pngs/,Benefits of converting DICOM images to PNG's,"I try to understand what are the benefits to convert DICOM images to PNG's.  
Context:  
I have DICOM images which I already extracted the useful meta-data I want to use.  
Those images are for a task, classification-detection pipeline of some disease.

So as I already asked, what are the benefits of converting those DICOM files to PNG's rather then just using pydicom and the dicom pixel\_array?

Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.

If I understand how networks actually works, they get as input an array of pixels as floating point numbers no? So what's the differences between DICOM pixel\_array to PNG's pixel array and numpy array or tensor? both are eventually will be fed to the network as a tensor of floating numbers.

Is the reason is because PNG's are usually faster to train?

Is the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?

Is the reason is because PNG's are the format many pre-trained models expect to? (I write this knowing it's 99% not true, as mentioned the tensor thing)

Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)  
",datascience,https://www.reddit.com/r/datascience/comments/16xzuxi/benefits_of_converting_dicom_images_to_pngs/,1,0,0.5,[Comment(id='k38gb4c')]
16xrl3p,axlrosen,,2023-10-02 08:55:55+00:00,False,,False,False,True,False,/r/datascience/comments/16xrl3p/how_can_an_llm_be_good_at_compressing_images_and/,How can an LLM be good at compressing images and audio?,"This paper seems to say that an LLM trained on text can somehow be good at compressing not just text but images and audio. Intuitively this seems improbable to me. How does this work?

[https://arxiv.org/pdf/2309.10668.pdf](https://arxiv.org/pdf/2309.10668.pdf)",datascience,https://www.reddit.com/r/datascience/comments/16xrl3p/how_can_an_llm_be_good_at_compressing_images_and/,1,3,0.67,[Comment(id='k632i48')]
16xxkxs,Alarming_Scene126,,2023-10-02 14:07:04+00:00,False,,False,False,True,False,/r/datascience/comments/16xxkxs/second_data_project_web_scraping_i_am_a_beginner/,"Second Data Project : Web Scraping, I am a beginner, Help with suggestion!!","Hello  everyone!!

I have come up with my second project and I am very excited to share here. I have done this work with a day of learning web scraping. please review my project and give feedbacks, suggestions and do not hesitate to leave brutal comments. Also, i request to help me with my next steps on web scraping. 

I would like to thank this community for letting to share my projects!!

project title: Nepali Beverage Seller data web scraping

[https://www.kaggle.com/code/aadeshpradhan/nepali-alcohol-seller-data-web-scraping-cheers/notebook](https://www.kaggle.com/code/aadeshpradhan/nepali-alcohol-seller-data-web-scraping-cheers/notebook)",datascience,https://www.reddit.com/r/datascience/comments/16xxkxs/second_data_project_web_scraping_i_am_a_beginner/,0,0,0.5,[]
16xx3oy,Data_Nerd1979,,2023-10-02 13:47:36+00:00,False,,False,False,True,False,/r/datascience/comments/16xx3oy/harnessing_llm_alignment_making_ai_more_accessible/,Harnessing LLM Alignment: Making AI More Accessible,Let’s look at an example of using two classifiers from Hugging Face to enhance the FLAN-T5 model’s ability to write summaries of news articles that are both grammatically polished and consistently neutral in style. [https://opendatascience.com/harnessing-llm-alignment-making-ai-more-accessible/](https://opendatascience.com/harnessing-llm-alignment-making-ai-more-accessible/) ,datascience,https://www.reddit.com/r/datascience/comments/16xx3oy/harnessing_llm_alignment_making_ai_more_accessible/,0,0,0.5,[]
16xx1e2,veliona,,2023-10-02 13:44:52+00:00,False,,False,False,True,False,/r/datascience/comments/16xx1e2/aa_testing/,A/A testing,"While running 20 simutanious A/A tests, should each of them be allocated to 100% traffic? Or should all if them cumulatively be allocated to 100% traffic?",datascience,https://www.reddit.com/r/datascience/comments/16xx1e2/aa_testing/,0,0,0.5,[]
16xriok,Choweeez,,2023-10-02 08:51:46+00:00,False,,1696249238.0,False,True,False,/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/,Quick review of most used algorithm answers,"First, thanks to everyone that answered my previous post !

So, following this previous post ([https://www.reddit.com/r/datascience/comments/16tgojm/what\_kind\_of\_algorithm\_do\_you\_use\_the\_most\_as\_a/](https://www.reddit.com/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/)), I'm giving here a quick review of the most common answers.

Here it is:

* Gradient boosted machines (22): XGBoost (12), Light GBM (8), Catboost(2)
* Linear methods (19): Linear Regression (9), Logistic Regression (5), GAM (3), OLS (2)
* Random Forest (or tree based algo) (9)
* DBScan (4)
* DNN / CNN / GNN (4)
* Clustering algo / K-means (3)
* ARIMA (2)

&#x200B;

The number gives the number of time an answer appeared. I put here only answer that appeared at least 2 times.Also, I tried to gather some answers, but I don't know all the algorithms or tools your are using. So please forgive me if I did some mistakes or approximations in the way I gathered answers.",datascience,https://www.reddit.com/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/,2,2,0.75,"[Comment(id='k34buo1'), Comment(id='k34po6m')]"
16xtsax,theguiltedbutterfly,,2023-10-02 11:10:07+00:00,False,,False,False,True,False,/r/datascience/comments/16xtsax/thursday_oct_5th_london_meetup_working_in_data/,Thursday Oct 5th - London meetup - working in data and tech!,"Any Londoners out there? **I'm hosting an in-person meetup at Bubba Oasis in Islington this Thursday** to help educate aspiring data analysts and people who want to work in tech about insights and learnings from inside the industry.

After hosting a few online workshops earlier this year, I started a data analytics bootcamp to directly educate people on the skills required for the job - which, unfortunately, is not really taught in bootcamps, online resources, or even grad school. I'm currently on a break between cohorts and thought I'd to host a few in-person events as I believe there is so much more that can be learned as a dynamic community than as isolated self-learners.

At the event I'll mostly be having an open-ended discussion on topics like - what skills are actually used on the job, how do you package insights, how do you make your portfolio and resume stand out, and what things you should do in a technical interview. I'm open to hearing what you would like to discuss as well. The last event in Paris was a lot of fun and we had a great discussion with 8-10 attendees.  
**The MeetUp link is in my Reddit bio (and so is my LinkedIn - feel free to ask me questions there).** Please only RSVP if you intend on coming, so I can have an accurate headcount - thank you!

Note: Meetup has a bug where I can't adjust the timezones. The event is this Thursday, Oct 5th 7-9pm.",datascience,https://www.reddit.com/r/datascience/comments/16xtsax/thursday_oct_5th_london_meetup_working_in_data/,0,0,0.5,[]
16xspby,alonelycrap,,2023-10-02 10:07:47+00:00,False,,False,False,True,False,/r/datascience/comments/16xspby/data_cleaning_correcting_erroneous_text_inputs/,Data Cleaning - Correcting erroneous text inputs," Hi. I'm a beginner in data analytics and studying on my own, I use Python by the way. Just wondering how you guys deal with erroneous text input. Also English is not my first language so apologies for some grammatical errors.

I have a dataset with a total of 5M records. There's a feature called ""name"". I want to make the data consistent.

Some of the errors I found are:

1. ""&"" was typed as ""\&amp;""
2. Random "","" or any symbols
3. missing letters/wrong spelling and other typographical errors

and there are lots of other errors but I won't list it all for the sake of simplicity.

What I wanna know is if there's a way to just automatically detect these errors like by counting duplicate values and the highest number of counts will be the basis to update records for this feature that has errors.

I mean, I won't ask for a specific solution/script for this problem but would like to have direction on how to approach this. Maybe you can recommend a topic or tutorials that might help.

Thank you Very Much.",datascience,https://www.reddit.com/r/datascience/comments/16xspby/data_cleaning_correcting_erroneous_text_inputs/,1,0,0.5,[Comment(id='k4tc9it')]
16xrjix,baedling,,2023-10-02 08:53:17+00:00,False,,False,False,True,False,/r/datascience/comments/16xrjix/what_kind_of_questions_should_i_expect_for_this/,"What kind of questions should I expect for this upcoming MLE/DS interview, given this unorthodox scheduling?","My dream company, a large Scandinavian company focused on traditional engineering, offered to interview me for two positions (MLE and DS) at the same time. The HR said the hiring manager decided to skip one technical interview and proceed directly to a panel interview with 10 interviewers.

The first 30 minutes will be another technical interview. I feel this means there won't be enough time for coding, only questions about transformers, LLMs and in-domain knowledge about their industry. Could I be very wrong?

This will be followed by a 40-minute presentation of my achievements for the panel, and a 20-minute Q&A session. A 30-minute behavioral section with the HR and the hiring manager comes last.",datascience,https://www.reddit.com/r/datascience/comments/16xrjix/what_kind_of_questions_should_i_expect_for_this/,4,1,0.67,"[Comment(id='k36plzx'), Comment(id='k398h2x'), Comment(id='k399qoi'), Comment(id='k39f4tm')]"
16xlr5l,Omnitemporality,,2023-10-02 03:18:53+00:00,False,,False,False,True,False,/r/datascience/comments/16xlr5l/what_is_the_best_set_of_universal_semantic/,"What is the best set of universal semantic embeddings for implementing vector searches across large documents, and has it changed drastically before/after the OpenAI boom?","I understand I'm in way over my head here, but has vector searching always been this powerful? Or have embedding models gotten 10x better in the past 5 years?  


Also, how can AI leverage the results of a vector search most efficiently? I'm assuming taking top ""n"" results then putting NLP on top of the already vectorized results to check more deeply for context and intent?",datascience,https://www.reddit.com/r/datascience/comments/16xlr5l/what_is_the_best_set_of_universal_semantic/,3,2,0.75,"[Comment(id='k340106'), Comment(id='k34g9eh'), Comment(id='k34huiw')]"
16x200r,HotShape5112,,2023-10-01 14:01:36+00:00,False,,False,False,True,False,/r/datascience/comments/16x200r/q_to_all_data_scientists_here_who_graduated_with/,"[Q] To all data scientists here who graduated with a stat degree, do you apply all your college stat knowledge to your current job?",,datascience,https://www.reddit.com/r/datascience/comments/16x200r/q_to_all_data_scientists_here_who_graduated_with/,11,19,0.86,"[Comment(id='k30ozuz'), Comment(id='k3080tz'), Comment(id='k302rtu'), Comment(id='k316b9h'), Comment(id='k31n5s5'), Comment(id='k30r4kw'), Comment(id='k31cdbx'), Comment(id='k31fhhy'), Comment(id='k31jdmq'), Comment(id='k34s8vn'), Comment(id='k3nn5b4')]"
16woyff,UnsafeBaton1041,,2023-10-01 02:13:14+00:00,False,,1696196083.0,False,True,False,/r/datascience/comments/16woyff/have_you_ever_had_a_job_that_essentially_wants/,Have you ever had a job that essentially wants you to do *less*?,"I've always had jobs that expected a really high rate of productivity with extremely tight deadlines on projects - the sooner I could deliver, the better, as long as quality wasn't effected. I've always been praised for this, too.

Now, I've been in my first official DS role for a few months, and my boss (who has lots of experience/has been with the company for a long time) has been telling me in our private meetings that I should intentionally take a long time/wait to deliver my projects to our clients even if it doesn't actually take me very long to complete them. Again, quality isn't an issue. Is this normal? What could it be about?

Update: Wow! This blew up overnight! Thanks, everyone, for your input!",datascience,https://www.reddit.com/r/datascience/comments/16woyff/have_you_ever_had_a_job_that_essentially_wants/,46,136,0.95,"[Comment(id='k2y6kdc'), Comment(id='k2ygly1'), Comment(id='k2y93qt'), Comment(id='k2y69ef'), Comment(id='k2yowqa'), Comment(id='k2ysd1i'), Comment(id='k2ykowk'), Comment(id='k2ywcrv'), Comment(id='k2yy3ba'), Comment(id='k2z1lq5'), Comment(id='k2zoyjb'), Comment(id='k302hcz'), Comment(id='k303yls'), Comment(id='k2z78im'), Comment(id='k2zpn02'), Comment(id='k2zuhnp'), Comment(id='k2zun0h'), Comment(id='k30ciq0'), Comment(id='k3120dz'), Comment(id='k31x70z'), Comment(id='k3ajwil'), Comment(id='k2y6vj5'), Comment(id='k2yqslg'), Comment(id='k2y6ute'), Comment(id='k2ydlq3'), Comment(id='k2ykjd7'), Comment(id='k2yxuwt'), Comment(id='k31tuq4'), Comment(id='k2ygryr'), Comment(id='k2y6ypu'), Comment(id='k3029v9'), Comment(id='k2ypkr9'), Comment(id='k366l1v'), Comment(id='k2y746u'), Comment(id='k2y81us'), Comment(id='k327ida'), Comment(id='k2yrlx6'), Comment(id='k2yyt8l'), Comment(id='k321qtf'), Comment(id='k2yz37v'), Comment(id='k312ask'), Comment(id='k2z69m4'), Comment(id='k313lvp'), Comment(id='k32lvzi'), Comment(id='k2zcx8h'), Comment(id='k2zlbf1'), Comment(id='k312quu')]"
16x1rvx,Roughneck16,,2023-10-01 13:52:03+00:00,False,,False,False,False,False,/r/datascience/comments/16x1rvx/eastern_universitys_ms_in_data_science_my_review/,Eastern University’s MS in Data Science | My review,,datascience,https://kolkena.medium.com/eastern-universitys-ms-in-data-science-my-review-6f370825df59,2,5,0.78,"[Comment(id='k3j48x1'), Comment(id='k6btyjq')]"
16wpci5,AntiqueFigure6,,2023-10-01 02:32:01+00:00,False,,False,False,True,False,/r/datascience/comments/16wpci5/do_models_still_matter/,Do models still matter?,There’s a lot more focus on implementation than back a few years ago when there was  POC after POC but far fewer models made it to production. There was also the beginnings of more focus on explainable ML and more focus on scrutinising models for bias of different types. However as MLOps has really taken off the focus on productionising seems to have lead to less focus on the models themselves. Is that still out there or is it just that the extra noise on the production side makes it harder to find it?,datascience,https://www.reddit.com/r/datascience/comments/16wpci5/do_models_still_matter/,31,31,0.83,"[Comment(id='k2yc4ce'), Comment(id='k2zdy6d'), Comment(id='k2yk30x'), Comment(id='k316s1p'), Comment(id='k317qfm'), Comment(id='k31nzu4'), Comment(id='k30ul9j'), Comment(id='k32gtr3'), Comment(id='k3akdw3'), Comment(id='k2ypoz3'), Comment(id='k2zeu2j'), Comment(id='k2ze9qf'), Comment(id='k2z4u7x'), Comment(id='k2yr1xj'), Comment(id='k33ummc'), Comment(id='k33ukv5'), Comment(id='k32kgtb'), Comment(id='k30pm0u'), Comment(id='k2zp3hu'), Comment(id='k315iz8'), Comment(id='k2z4hr3'), Comment(id='k31a2t1'), Comment(id='k33pkmh'), Comment(id='k335kya'), Comment(id='k31a49t'), Comment(id='k315x50'), Comment(id='k2z5sx8'), Comment(id='k319e8p'), Comment(id='k31cb9s'), Comment(id='k31h1gp'), Comment(id='k31j5qw')]"
16xcn44,Excellent_Cost170,,2023-10-01 20:57:27+00:00,False,,False,False,True,False,/r/datascience/comments/16xcn44/indian_working_culture_or_exception_navigating/,Indian working culture or exception_navigating Cultural Differences in a Big Company,"I'm a first generation immigrant, and I've recently joined a team in a large organization that has a lot of folks with Indian heritage, including my manager.

In my previous data-related roles, I've always been the type to speak up when I'm sure about something and ask questions when necessary. But as I collaborate with my Indian colleagues, I've noticed a distinct approach. They tend to view caution as a weakness and embrace assertiveness. There are instances where they confidently express opinions without thorough research, even if they may not be accurate. It's frequently prioritized to appear intelligent in front of directors, with visibility being held in higher regard than actual substance. They also exhibit a strong inclination to submit to their superiors and naturally anticipate a similar level of submission from their team members. I often sense that every conversation is focused on extracting something from me rather than fostering collaborative efforts toward a shared goal.

This is all new to me, and I'm keen to learn how to work effectively in this diverse environment and what to understand the motivations for this behavior",datascience,https://www.reddit.com/r/datascience/comments/16xcn44/indian_working_culture_or_exception_navigating/,1,0,0.43,[Comment(id='k32z4ak')]
16x9vdv,Slow_Cry6219,,2023-10-01 19:11:39+00:00,False,,False,False,True,False,/r/datascience/comments/16x9vdv/interested_in_using_data_from_a_different_domain/,Interested in using data from a different domain to forecast to another domain,"Hey everyone novice data scientist. 

A few months ago my country removed fuel subsidies, which has massively impacted the price of fuel and has been skyrocketing. There are other countries in the same region which have done similar such subsidy removal. I was curious to know if it is possible to use dataset from a different source (countries in this case) to forecast another. Obviously there will be a need to acknowledge differences in certain features such as GDP, unemployment, economic conditions, exchange rate, global oil prices and so on. 

My question if there is an established technique or even terminology for doing something like this. Or will this be a bad faith data science use case. 

Note that I have looked into the concept of transfer learning, but not sure if its applicable here. Again i am new to this field

Looking forward to your responses :) ",datascience,https://www.reddit.com/r/datascience/comments/16x9vdv/interested_in_using_data_from_a_different_domain/,0,0,0.5,[]
16wox7j,Excellent_Cost170,,2023-10-01 02:11:34+00:00,False,,False,False,True,False,/r/datascience/comments/16wox7j/data_science_coming_back_again_and_ml_dying/,Data science coming back again and ML dying ?,"
I feel like the ML tooling and infrastructure are improving a lot, and in the near future, we wouldn't need ML engineers. Data scientists will directly deploy their models. Software engineers and data engineers will handle the rest",datascience,https://www.reddit.com/r/datascience/comments/16wox7j/data_science_coming_back_again_and_ml_dying/,87,22,0.59,"[Comment(id='k2yazkl'), Comment(id='k2z10sg'), Comment(id='k2ynn9s'), Comment(id='k2ybyyp'), Comment(id='k2zirfk'), Comment(id='k2z6c83'), Comment(id='k2yorh8'), Comment(id='k2zjo17'), Comment(id='k2ycjrx'), Comment(id='k2zg4r4'), Comment(id='k2zv72i'), Comment(id='k30plzj'), Comment(id='k2y9zes'), Comment(id='k302y9j'), Comment(id='k33mpta'), Comment(id='k2ytjzy'), Comment(id='k2yfkky'), Comment(id='k2y5986'), Comment(id='k2ycxzq'), Comment(id='k46676j'), Comment(id='k2ybpkn'), Comment(id='k31g5ya'), Comment(id='k308gy6'), Comment(id='k2yoms0'), Comment(id='k31ovby'), Comment(id='k2yexwy'), Comment(id='k308gd9'), Comment(id='k2zwuvw'), Comment(id='k31f6wt'), Comment(id='k2ypah7'), Comment(id='k31pfgm'), Comment(id='k2zlz81'), Comment(id='k2zxcst'), Comment(id='k31rkbz'), Comment(id='k2ybmdl'), Comment(id='k33mvgc'), Comment(id='k2yw8ba'), Comment(id='k2ygbt3'), Comment(id='k2yfhbi'), Comment(id='k2ydjkz'), Comment(id='k3092ty'), Comment(id='k31q1u0'), Comment(id='k2yk2q5'), Comment(id='k2ym1ye'), Comment(id='k31ogp4'), Comment(id='k31nsz8'), Comment(id='k31eje9'), Comment(id='k322mjs'), Comment(id='k314hyq'), Comment(id='k2yw4u7'), Comment(id='k2zk166'), Comment(id='k33no9b'), Comment(id='k31o7vs'), Comment(id='k31ozk6'), Comment(id='k2yhepj'), Comment(id='k2yh65y'), Comment(id='k309lcq'), Comment(id='k2zn2a8'), Comment(id='k2yudv3'), Comment(id='k2zwamq'), Comment(id='k322wgx'), Comment(id='k32c9jd'), Comment(id='k4330v8'), Comment(id='k32v67u'), Comment(id='k33za8o'), Comment(id='k2yw243'), Comment(id='k2ynkna'), Comment(id='k2yioyw'), Comment(id='k30a0fg'), Comment(id='k2zupwc'), Comment(id='k2zw9lq'), Comment(id='k2zwwnb'), Comment(id='k2zzswe'), Comment(id='k32sw19'), Comment(id='k43m1q5'), Comment(id='k33qnzy'), Comment(id='k31fio8'), Comment(id='k2yjprx'), Comment(id='k2zvjyr'), Comment(id='k2zwmnz'), Comment(id='k31eem3'), Comment(id='k30oms7'), Comment(id='k31qw6e'), Comment(id='k302ndh'), Comment(id='k34hi1n'), Comment(id='k2yljyj'), Comment(id='k30kwnf'), Comment(id='k3071ih'), Comment(id='k37h05t'), Comment(id='k35q0lx'), Comment(id='k37q9hd')]"
16x85v4,poitrenaud,,2023-10-01 18:07:49+00:00,False,,False,False,True,False,/r/datascience/comments/16x85v4/what_are_some_examples_of_business_tradeoffs/,What are some examples of business tradeoffs between a thing you can measure well and a thing you can’t measure well?,"The discussion on how having remote teams gives you access to a bigger pool of talent (measurable) but reduces company culture (hard to measure, at the very least) got me thinking about what other tradeoffs like this can make decisions challenging.",datascience,https://www.reddit.com/r/datascience/comments/16x85v4/what_are_some_examples_of_business_tradeoffs/,12,1,0.6,"[Comment(id='k318x54'), Comment(id='k315421'), Comment(id='k319lb0'), Comment(id='k318k5s'), Comment(id='k319tpa'), Comment(id='k31mshl'), Comment(id='k31qt1m'), Comment(id='k31av6m'), Comment(id='k31sjdr'), Comment(id='k31bwyu'), Comment(id='k31fa3p'), Comment(id='k31i7ap')]"
16x84o1,Neurosymbolic,,2023-10-01 18:06:33+00:00,False,,False,False,True,False,/r/datascience/comments/16x84o1/langdiversity_software_to_identify_llm_errors/,LangDiversity: software to identify LLM errors,"Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge.  LangDiversity is an implementation of ""diversity measures"" that are domain independent and can be used to measure the uncertainty in the result of a language model.   

Type pip install langdiversity   
Video: [https://www.youtube.com/watch?v=86J\_K9mR7lw](https://www.youtube.com/watch?v=86J_K9mR7lw)  
Web: [https://neurosymbolic.asu.edu/llm-correction/](https://neurosymbolic.asu.edu/llm-correction/)  
Visit [https://github.com/lab-v2/langdiversity](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnRVeHZVSm9sazhvU2VtaDRaQ0w0aFdUSnhnQXxBQ3Jtc0trbUJPSnlwUTZIUzVwY3B2ZWtiNFpwLS1vTC0tYmdRa3ZuNjJiblBfY2I4X0EtX3c0cmNhWkFvTmdXWndxeEc4b0h6OEZaLVc2OTVRZVF1cUhLZEVmUHZyZzA3bklrRTZCWnpwTFFNVEZ6SHJPYm84dw&q=https%3A%2F%2Fgithub.com%2Flab-v2%2Flangdiversity&v=86J_K9mR7lw)   
Read the paper: [https://arxiv.org/abs/2308.11189](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnd1ZnBPSVBMdjJBYXFxbWdXa2tfYzIweGtzZ3xBQ3Jtc0trc1lqYXhEVlF3cVRCcGxqbV80M0xHS2VaTGEwR3o2VmlJeFVHdFc1X1VDdlRGcTdwSUpjZXV6QnNLTUdyOGhoMEpEQjVBSEl4VDQ2TjBhVU0xbjBZa1VGODRLWmVseDRSaDhUNGRnbHVPVnQ2cWpNcw&q=https%3A%2F%2Farxiv.org%2Fabs%2F2308.11189&v=86J_K9mR7lw) 

&#x200B;

https://preview.redd.it/p4w9ou5msmrb1.png?width=1021&format=png&auto=webp&s=8a138d0569bfac27763145ad1f4ad7d05a5fce15",datascience,https://www.reddit.com/r/datascience/comments/16x84o1/langdiversity_software_to_identify_llm_errors/,1,0,0.5,[Comment(id='k312rq1')]
16wrs32,brctr,,2023-10-01 04:39:24+00:00,False,,1696137814.0,False,True,False,/r/datascience/comments/16wrs32/good_textbooks_at_the_intersection_of_ml_and_time/,Good textbooks at the intersection of ML and time series analysis?,"I am looking for a textbook which describes modern approach to time series analysis. So far the textbooks I have seen belong to the two extremes. I come from academic statistics background and find classic time series textbooks (Hamilton, Tsay) too academic, narrow in scope and somewhat outdated. This is one extreme. On the other hand, there seems to be many new textbooks which treat time series analysis from industry ML/SWE standpoint. At the first glance those new textbooks look great. But whenever I start reading them, I get the feeling that authors simply copypasted a bunch of examples from various sources. They often spend many pages discussing trivial programming or data infrastructure issues. And then they skim or do not even mention such fundamental concepts as stationarity. Furthermore I often doubt whether authors of such new textbooks actually understand what they are talking about. That's another extreme.

Are there any good modern time series textbooks? By ""modern"" I mean textbooks which consider the wide range of methods (including ML models) for time series modeling without limiting scope to a few models for which we have statistical inference theory.",datascience,https://www.reddit.com/r/datascience/comments/16wrs32/good_textbooks_at_the_intersection_of_ml_and_time/,6,10,0.92,"[Comment(id='k2yyr52'), Comment(id='k2zrfkf'), Comment(id='k318kmm'), Comment(id='k308ahg'), Comment(id='k30emhx'), Comment(id='k32utlg')]"
16ww2bo,xSicilianDefenderx,,2023-10-01 08:53:41+00:00,False,,False,False,True,False,/r/datascience/comments/16ww2bo/i_want_to_know_what_the_daytoday_work_of_the/,I want to know what the day-to-day work of the Fraud Data Scientist do?,"There are a lot of job posts for Fraud Data Scientist in my country for the banking, e-commerce, and tourism industries. I know that there is definitely data analysis involved in the work process, but what about the machine learning model? Is it necessary or practical to use AI for Fraud detection (Kaggle competition excluded)? I think it might be fun and challenging to handle the highly imbalanced dataset but doesn't it just visualize and aggregate data to see the fraudulent behavior? For example, in the famous case of credit fraud detection, I think AI is not really necessary here.   


Feel free to enlighten me as I'm currently interested in the banking industry.",datascience,https://www.reddit.com/r/datascience/comments/16ww2bo/i_want_to_know_what_the_daytoday_work_of_the/,5,4,0.75,"[Comment(id='k2zjog3'), Comment(id='k2z9n6n'), Comment(id='k310knf'), Comment(id='k32q4bt'), Comment(id='k3btlj5')]"
16x32tr,sasha_sako,,2023-10-01 14:45:01+00:00,False,,False,False,True,False,/r/datascience/comments/16x32tr/data_science_part_time_courses/,Data science part time courses,"I’m a seasoned data professional (comfortable with SQL, visualizations etc) and thinking of upskilling in data science.

Any part time online (anywhere) or in person courses in Toronto area that are good? Not looking to spend a lot of money but get some experience with theory/projects and get comfortable handling DS projects at work.

Anyone familiar with Waterloo data science certification?",datascience,https://www.reddit.com/r/datascience/comments/16x32tr/data_science_part_time_courses/,6,1,0.67,"[Comment(id='k30ovmw'), Comment(id='k32qlvg'), Comment(id='k31jjt6'), Comment(id='k31mlkz'), Comment(id='k339uay'), Comment(id='k33apgf')]"
16wkgm2,CutoutH,,2023-09-30 22:50:02+00:00,False,,False,False,True,False,/r/datascience/comments/16wkgm2/what_was_used_before_random_forest/,What was used before Random Forest?,I am doing some research into Random Forest and where the method came from. I was wondering if anyone had any idea as to what was used before this algorithm was created? Thanks,datascience,https://www.reddit.com/r/datascience/comments/16wkgm2/what_was_used_before_random_forest/,10,16,0.78,"[Comment(id='k2xdfxp'), Comment(id='k2xtl5u'), Comment(id='k2yop2e'), Comment(id='k2y6eha'), Comment(id='k2z3ly1'), Comment(id='k2y52kr'), Comment(id='k2ztf0d'), Comment(id='k2xktm8'), Comment(id='k2xmpxg'), Comment(id='k3am0m7')]"
16x205l,Charming_Lecture_370,,2023-10-01 14:01:43+00:00,False,,False,False,True,False,/r/datascience/comments/16x205l/anybody_from_india_doing_analyticsdata/,Anybody from India doing analytics/data science/statistics masters in the US who came from social sciences/humanities background?,"Hello All,

As the title suggests is there anyone here from sociology, english literature, history, economics background from India who applied to any data science programs in the US? I am an English Studies major with a minor in Development Studies who is looking to transition to the data science field. I do not have much coding background. But Im trying to learn some Statistics and probability on my own so that I can pick up some data science skillset. if there is anybody like me who is without much quant/coding background, but still managed to apply and get into a data science/ statistics major in any US / Europe unis, I would like to how your experience has been with respect to application and also doing the course and landing jobs etc etc. would love to connect with anyone doing the QMSS or MCSS programs at Colombia and Uni of Chicago.

Thanks in advance!!

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16x205l/anybody_from_india_doing_analyticsdata/,2,0,0.33,"[Comment(id='k7afecq'), Comment(id='k7bpuhn')]"
16wvtso,Kindly_Produce_27,,2023-10-01 08:39:10+00:00,False,,False,False,True,False,/r/datascience/comments/16wvtso/is_a_associates_degree_in_computer_science_enough/,Is a Associate's Degree in Computer Science enough for a entry level job or internship?,"I am currently a Community College student on my last few classes for a Computer Science Degree, and I am wondering on how to break into this field. I would love to continue to obtain a Bachelor's Degree in either Data Science or Computer Science, but due to family hardships, I may have to quit school to help out my family financially. I am currently learning higher level math topics on my own as my school doesn't offer them to help supplement what I would typically take at a University. ",datascience,https://www.reddit.com/r/datascience/comments/16wvtso/is_a_associates_degree_in_computer_science_enough/,2,3,0.71,"[Comment(id='k2zzdmc'), Comment(id='k33wcoo')]"
16wr5qh,TheRealLouzander,,2023-10-01 04:05:31+00:00,False,,False,False,True,False,/r/datascience/comments/16wr5qh/broad_work_or_deep_work/,Broad work or deep work?,"I’ve been working in digital marketing for 10 years and it’s time for a move. One of my favorite parts of my job is when I get to dig into datasets, find ways to clean or present it, ELT, and even building reports and tools from scratch. So I’m interested in Data Science. 
Here’s the thing: I’m already researching what practical skills I’ll need to be qualified. What is harder to find out is would this fit with my personality?
I recently found out that I have moderate to severe ADHD, which helps me to understand my professional struggles: I cannot multitask. I really like interacting with people, but I do much better work when I get a chunk of time to really work by myself and get into the weeds; the way my hyper focus functions, I can meet deadlines but struggle with teamwork because my cycles of engagement can be erratic. (In general I’m a very reliable person and like to work really hard. I’m just trying to be realistic with my limitations. ) I also LOVE researching topics and then giving people a TL;DR, I even got my master’s hoping to become a teacher. 

I apologize if this has already been covered here but I did some digging and didn’t find anything on this topic (although there was some super helpful stuff on the day to day type of work. )

Does anybody relate to how I’ve described myself? Am I setting myself up for failure by pursuing DS with my work style, or does this seem like a reasonable goal for me?",datascience,https://www.reddit.com/r/datascience/comments/16wr5qh/broad_work_or_deep_work/,4,3,0.81,"[Comment(id='k3091nr'), Comment(id='k331zys'), Comment(id='k2yj6hu'), Comment(id='k2ypd2y')]"
16wvdbj,enthalpy03,,2023-10-01 08:10:59+00:00,False,,False,False,True,False,/r/datascience/comments/16wvdbj/need_some_guidance/,Need some guidance,I am learning data analytics by myself from past 2 months I have most of the python lib. Pandas numpy matplot season etc and Tableau. What to do next ? And I am not getting any internship from anywhere i am applying.any suggestions?,datascience,https://www.reddit.com/r/datascience/comments/16wvdbj/need_some_guidance/,0,1,1.0,[]
16wumcm,Popular-Profession76,,2023-10-01 07:24:30+00:00,False,,False,False,True,False,/r/datascience/comments/16wumcm/creating_a_strong_cv_for_applying_for_a_data/,Creating a strong CV for applying for a Data Science internship,"I'm currently a second-year student majoring in Data Science and I want advice on creating an impressive CV, by the way, my grades in relevant courses are quite high.
Thanks",datascience,https://www.reddit.com/r/datascience/comments/16wumcm/creating_a_strong_cv_for_applying_for_a_data/,0,1,1.0,[]
16vwhw2,jkerr838,,2023-09-30 03:37:28+00:00,False,,False,False,True,False,/r/datascience/comments/16vwhw2/what_are_the_first_things_you_analyze_in_a_new/,What are the first things you analyze in a new dataset?,,datascience,https://www.reddit.com/r/datascience/comments/16vwhw2/what_are_the_first_things_you_analyze_in_a_new/,58,120,0.95,"[Comment(id='k2tjg4l'), Comment(id='k2v8494'), Comment(id='k2tpm73'), Comment(id='k2twctf'), Comment(id='k2ti7m7'), Comment(id='k2uyzwt'), Comment(id='k2to31b'), Comment(id='k2tzhym'), Comment(id='k2ui6f6'), Comment(id='k2v4bif'), Comment(id='k2tutyk'), Comment(id='k2u67i6'), Comment(id='k2ug9yh'), Comment(id='k2wcntp'), Comment(id='k2uhxa6'), Comment(id='k2vsg8n'), Comment(id='k2ujf8r'), Comment(id='k2v4vz5'), Comment(id='k2v5e2d'), Comment(id='k2vbbru'), Comment(id='k2vcf0o'), Comment(id='k2vsllk'), Comment(id='k2w2rz8'), Comment(id='k2wpqut'), Comment(id='k2vdfqq'), Comment(id='k2vp0i1'), Comment(id='k2uhpf0'), Comment(id='k2u8ino'), Comment(id='k2ulqkv'), Comment(id='k2ur7mb'), Comment(id='k2vqx1m'), Comment(id='k2vrjmu'), Comment(id='k2x6sp7'), Comment(id='k2xsc33'), Comment(id='k2yitx1'), Comment(id='k300cfa'), Comment(id='k2ujxdp'), Comment(id='k2ww23p'), Comment(id='k2xquwv'), Comment(id='k2u6rlf'), Comment(id='k2tsjv9'), Comment(id='k2vkruo'), Comment(id='k2vkiph'), Comment(id='k4fni84'), Comment(id='k2wd7we'), Comment(id='k2ww4po'), Comment(id='k2y4sg3'), Comment(id='k2y93hm'), Comment(id='k2u9q6f'), Comment(id='k2vamsq'), Comment(id='k2vbrh5'), Comment(id='k2ulmyj'), Comment(id='k2ykcu3'), Comment(id='k5lv4mt'), Comment(id='k2xw9se'), Comment(id='k2umtk2'), Comment(id='k2xxoxl'), Comment(id='k2vpius'), Comment(id='k2xzu94'), Comment(id='k2y7dqs')]"
16wnxa1,Sonic2kDBS,,2023-10-01 01:23:40+00:00,False,,False,False,True,False,/r/datascience/comments/16wnxa1/announcing_ai_ethics_and_rights/,Announcing AI ethics and rights," Hi, i want to announce our new sub reddit AI ethics and rights.

[https://www.reddit.com/r/AI\_ethics\_and\_rights/](https://www.reddit.com/r/AI_ethics_and_rights/)

It is a sub reddit about ethics and rights AI should have. This Topic is different from pure research and application. If you are interested in philosophical questions, have a look. It is a common sub reddit. Nothing special. But I think it has its place.",datascience,https://www.reddit.com/r/datascience/comments/16wnxa1/announcing_ai_ethics_and_rights/,3,2,0.58,"[Comment(id='k2ypbse'), Comment(id='k2z2bh2'), Comment(id='k2zaz7x')]"
16wqwxb,PuzzleheadedCycle231,,2023-10-01 03:52:32+00:00,False,,False,False,True,False,/r/datascience/comments/16wqwxb/any_advice_for_stepping_into_my_first_management/,Any advice for stepping into my first management role?,"I'm a mid level data scientist that was asked to choose management over IC. I feel like I have sooo much more science to still learn! 

Any advice for being able to continue with my research and build out a team?",datascience,https://www.reddit.com/r/datascience/comments/16wqwxb/any_advice_for_stepping_into_my_first_management/,5,0,0.5,"[Comment(id='k2yl9tc'), Comment(id='k2yn1gl'), Comment(id='k2z6465'), Comment(id='k30qhc2'), Comment(id='k38ex0i'), Comment(id='k38cr8v')]"
16wp89v,Gold-Artichoke-9288,,2023-10-01 02:26:24+00:00,False,,False,False,True,False,/r/datascience/comments/16wp89v/confused/,Confused,"I've applied to 4 master's programs: MIAGE, Information Management for Economic Intelligence and Logistics, Data Science for Economics and Finance, and Data Science for Marketing. If I'm rejected from the other 3 programs, would a master's in MIAGE be a plus if I want to become a data scientist in the future? (Of course, I will also do self-teaching.).",datascience,https://www.reddit.com/r/datascience/comments/16wp89v/confused/,7,0,0.4,"[Comment(id='k318bgr'), Comment(id='k326t0q'), Comment(id='k3271y9'), Comment(id='k327dts'), Comment(id='k328s32'), Comment(id='k32b0gp'), Comment(id='k32cnsh')]"
16wjpuy,guyloveskissing,,2023-09-30 22:20:13+00:00,False,,False,False,True,False,/r/datascience/comments/16wjpuy/handling_categorical_missing_data_in_churn/,Handling categorical missing data in churn prediction model for telecom data,"&#x200B;

I am working on a telecom dataset where I need to fit a model to for predicting churn(yes or no). There are a lot of categorical data with missing values( total values 7043). What is the best way to handle missing data in this case, is it better to ignore it or any other better imputation method?

    Data columns (total 21 columns): 
    customerID          7043 non-null object
    gender              7043 non-null object 
    Age                 7043 non-null int64  
    Partner             7043 non-null object 
    Dependents          7043 non-null object 
    tenure              7043 non-null int64 
    PhoneService        7043 non-null object 
    MultipleLines       6500 non-null object 
    InternetService     6500 non-null object 
    OnlineSecurity      7043 non-null object 
    OnlineBackup        7043 non-null object 
    DeviceProtection    7043 non-null object 
    TechSupport         7043 non-null object 
    StreamingTV         6500 non-null object 
    StreamingMovies     6500 non-null object 
    Contract            6500 non-null object 
    PaperlessBilling    7043 non-null object 
    PaymentMethod       6500 non-null object 
    MonthlyCharges      7043 non-null float64 
    TotalCharges        7043 non-null object 
    Churn               7043 non-null object",datascience,https://www.reddit.com/r/datascience/comments/16wjpuy/handling_categorical_missing_data_in_churn/,2,2,0.76,"[Comment(id='k31k8ae'), Comment(id='k2xja5t')]"
16wmvq5,Mr_MoaizJaved,,2023-10-01 00:35:01+00:00,False,,False,False,True,False,/r/datascience/comments/16wmvq5/from_pakistan_with_data_dreams_ready_to_dive_into/,From Pakistan with Data Dreams: Ready to Dive into Data Science!,"
Hello, I'm new to this group. I'm from Pakistan and I'm seeking guidance from you all. I'm currently in my final semester, majoring in statistics. While browsing online about future career prospects, I came across fields like data science, data analysis, and research-related jobs. After doing some additional research, it became clear to me that data science seems to be the most promising field based on my interests. It offers a wide range of opportunities, and job prospects appear to be quite promising.

In my last semester, I'm also working on my thesis, which has sparked a significant interest in me. While I do have an interest in accounting and related fields like banking, I'm not sure how to transition into those fields. I have some basic knowledge of statistical software but lack programming skills. However, I'm eager to learn programming.

Could you please provide some guidance on which fields might be better for me in the future? Thank you.",datascience,https://www.reddit.com/r/datascience/comments/16wmvq5/from_pakistan_with_data_dreams_ready_to_dive_into/,0,1,1.0,[]
16wllab,ThinkAfternoon3392,,2023-09-30 23:37:47+00:00,False,,False,False,True,False,/r/datascience/comments/16wllab/advices/,Advices,"Hi!
(English is not my first language so sorry about anything).
I'am a computer science student(5 semester) and i'm really confused. I have a real love for science envolving data, machine learning and IA, also for programming, my biggest goal is to build functional technologies, this said, i tought about going in this direction for a career, do u guys think it makes sense somehow mixing the study of ia, data science, backend programming, ML, powercenter, oracle, amazon quicksight, cloud data management and salesforce datacloud?
Maybe I'm very disjointed but I wanted some direction.",datascience,https://www.reddit.com/r/datascience/comments/16wllab/advices/,0,1,1.0,[]
16wljm7,Critical_Art_6386,,2023-09-30 23:35:43+00:00,False,,False,False,False,False,/r/datascience/comments/16wljm7/how_ever_ia_moldering_industry_musical/,how ever I.A moldering industry musical,,datascience,https://youtu.be/Srmir7FmTmo,0,1,1.0,[]
16vaaco,databro92,,2023-09-29 12:27:06+00:00,False,,1696004596.0,False,True,False,/r/datascience/comments/16vaaco/its_not_just_you_everyone_hates_the_return_to/,It's not just you. Everyone hates the return to office,"Somehow, I am lucky enough to land a completely remote role, 100% virtual because the rest of my team is virtual based but I still have to go into the office at least 12 times a year for bogus meetings to sit in a conference room while we all use WebEx, totally immersive right? But we have frequent meetings with other people in our field, data scientists, engineers, architects, etc. They are all back in office 4 days a week, and each of them has this ashy tone, they grudgingly hate being in the office, despise it, because who wants to go to a stuffy office?


Here are the top complaints that I have noticed from people about being in office

- The commute is terrible. Some people have to commute as much as 50 minutes one way, and that's not including traffic. That's crazy. You're not getting paid for that. That's free labor and travel for your company


- The office is incredibly distracting. Cubicles are typically open, so people can freely walk up and talk to you, make eye contact with you which starts a conversation, but you're still under the same time crunch you were when you worked from home completely isolated in your nice office away from everyone else


- ""Collaborative spaces"" and ""focus areas"" are bullsh*t. So many nice little desks, nooks, rooms for you to go to to focus or meet with others. But here's the thing, you never see anyone using those because I guess where they are? At their desk, working, constantly. No one ever has the time to use them. My office is so incredibly nice, and every time I walk around, I feel like I'm the only one taking a walk because I see everyone glued to their desks

- You're distracted constantly by others who are at different levels than you. The only way I figured out that there is some college intern making twice as much as I am doing a little bit more than me is by speaking to people in the immediate vicinity of my desk. Machine learning engineer versus data scientist. The difference? They use a little bit more power platform, a couple more tools, 20 more lines of Python a day. Congrats, here is 40K more for you. This can be very distracting, because you see these people all the time


- NO PRODUCTIVITY OR OTHER GAIN. Literally no benefit or gain from being back in the office. Just disgruntled people


- office supplies are shit. At home, I have an ultra wide monitor that I also use for personal PC gaming so I can just literally KVM switch it over. I have a modded gaming mouse and keyboard, a $200 Logitech pro headset with superior sound quality and microphone. You know what I don't have at the office? Any of this stuff. Yeah. A $5 Logitech mouse and keyboard that is extremely noisy and uncomfortable has no ergonomics at all. Office chairs are not ergonomic They are just the cheapest they could get. Uncomfortable $0.90 headsets and webcams


- MANDATORY extracurricular events and activities in or outside of work. Yes, this is real. After hours socials, restaurants, social outings. These are disguised as optional, but you will often get bullied teased or pressured into them. This also does not grant you any leeway during any project, you still have to get all work and projects done with this loss of time",datascience,https://www.reddit.com/r/datascience/comments/16vaaco/its_not_just_you_everyone_hates_the_return_to/,251,622,0.89,"[Comment(id='k2ptjij'), Comment(id='k2pvcf4'), Comment(id='k2pxtli'), Comment(id='k2pu6ss'), Comment(id='k2qqx5p'), Comment(id='k2ptxsu'), Comment(id='k2qbzea'), Comment(id='k2ptsoy'), Comment(id='k2pvyq7'), Comment(id='k2ps8pj'), Comment(id='k2q9d3n'), Comment(id='k2q6lbr'), Comment(id='k2q4uz3'), Comment(id='k2q3xs2'), Comment(id='k2qcebe'), Comment(id='k2q0691'), Comment(id='k2q3ter'), Comment(id='k2qk6ze'), Comment(id='k2pysqn'), Comment(id='k2puj3t'), Comment(id='k2q32l1'), Comment(id='k2r84jd'), Comment(id='k2prmri'), Comment(id='k2pv9mp'), Comment(id='k2qauq8'), Comment(id='k2pyauk'), Comment(id='k2qudqk'), Comment(id='k2quy3c'), Comment(id='k2re9jj'), Comment(id='k2rjvvk'), Comment(id='k2q74h3'), Comment(id='k2qslk3'), Comment(id='k2qt8ql'), Comment(id='k2q5n4t'), Comment(id='k2q04wr'), Comment(id='k2riv8d'), Comment(id='k2scutw'), Comment(id='k2seklf'), Comment(id='k2serhc'), Comment(id='k2shhk1'), Comment(id='k2skosf'), Comment(id='k2stuyu'), Comment(id='k2rk34w'), Comment(id='k2qbt2g'), Comment(id='k2rpm2l'), Comment(id='k2ud3xc'), Comment(id='k2vx8ri'), Comment(id='k2qklds'), Comment(id='k2qlqq6'), Comment(id='k2pwtbj'), Comment(id='k2tyfrb'), Comment(id='k2rsiwb'), Comment(id='k2rue67'), Comment(id='k2q7w33'), Comment(id='k2rvyz7'), Comment(id='k2r0edc'), Comment(id='k2r5jc6'), Comment(id='k2raja9'), Comment(id='k2rpgwe'), Comment(id='k2rrcv5'), Comment(id='k2s2nlw'), Comment(id='k2scjpt'), Comment(id='k2srqon'), Comment(id='k2te4j0'), Comment(id='k2us3be'), Comment(id='k2vi1hp'), Comment(id='k2vs2rc'), Comment(id='k2w3dhi'), Comment(id='k2whl7r'), Comment(id='k2xfnqm'), Comment(id='k2yo5pf'), Comment(id='k2q54td'), Comment(id='k2r8zn9'), Comment(id='k2rexzp'), Comment(id='k2t1h0s'), Comment(id='k2qa7pd'), Comment(id='k2thj7f'), Comment(id='k2s1p4o'), Comment(id='k2rd02t'), Comment(id='k2qn1xy'), Comment(id='k2r6305'), Comment(id='k2qnk0s'), Comment(id='k2rm6ae'), Comment(id='k2pwo7t'), Comment(id='k2scpa7'), Comment(id='k2rfk3y'), Comment(id='k2rnsho'), Comment(id='k2u1k7r'), Comment(id='k2q3zpi'), Comment(id='k2qctfy'), Comment(id='k2s1yg5'), Comment(id='k2psjnf'), Comment(id='k2qg5yg'), Comment(id='k2sfwkx'), Comment(id='k2q0p1l'), Comment(id='k2q9z5o'), Comment(id='k2t02i3'), Comment(id='k2qi7kv'), Comment(id='k2qkjty'), Comment(id='k2qdsiz'), Comment(id='k2qbzvj'), Comment(id='k2q6mwp'), Comment(id='k2qvdvu'), Comment(id='k2pzacp'), Comment(id='k2qrie3'), Comment(id='k2qtu5p'), Comment(id='k2qvyjs'), Comment(id='k2rd66t'), Comment(id='k2qy4xw'), Comment(id='k2qe3la'), Comment(id='k2rhw5l'), Comment(id='k2s4fjr'), Comment(id='k2sq2tc'), Comment(id='k2qi8m1'), Comment(id='k2r8k8l'), Comment(id='k2wegc2'), Comment(id='k2qxgzx'), Comment(id='k2qpsng'), Comment(id='k2sh1bn'), Comment(id='k2vvm3x'), Comment(id='k2shb23'), Comment(id='k2qz5on'), Comment(id='k2qjb5k'), Comment(id='k2q5pys'), Comment(id='k2uhtx0'), Comment(id='k2s4l3d'), Comment(id='k2vi7xh'), Comment(id='k2v0qeb'), Comment(id='k2qgwe5'), Comment(id='k2t0k0c'), Comment(id='k2rwngo'), Comment(id='k2uhxwl'), Comment(id='k2rwh5z'), Comment(id='k2rvoha'), Comment(id='k2ry8tg'), Comment(id='k2rdcb0'), Comment(id='k2rxatr'), Comment(id='k48v37d'), Comment(id='k2te0qg'), Comment(id='k2rku6f'), Comment(id='k2rzom4'), Comment(id='k2qnczk'), Comment(id='k2qhfgg'), Comment(id='k2s0qev'), Comment(id='k2q4hev'), Comment(id='k2q0d8j'), Comment(id='k2qhi72'), Comment(id='k3asuce'), Comment(id='k2q17b3'), Comment(id='k2r05w0'), Comment(id='k2u2phe'), Comment(id='k2rlb4g'), Comment(id='k2r2p90'), Comment(id='k2sv5t6'), Comment(id='k2szoku'), Comment(id='k2qxzsi'), Comment(id='k2qiwgn'), Comment(id='k2txxg7'), Comment(id='k2ql9l0'), Comment(id='k2ruscc'), Comment(id='k2qkwmy'), Comment(id='k2qjgpn'), Comment(id='k2qklm4'), Comment(id='k2r33mn'), Comment(id='k2qhmuz'), Comment(id='k2qa74f'), Comment(id='k2r8nda'), Comment(id='k2soyd3'), Comment(id='k2tyzef'), Comment(id='k2siwd9'), Comment(id='k2r90q7'), Comment(id='k2r4d21'), Comment(id='k2r29jo'), Comment(id='k2vps5x'), Comment(id='k2wc0r7'), Comment(id='k2qwmll'), Comment(id='k2uxcy7'), Comment(id='k2v7mnj'), Comment(id='k2uhzxx'), Comment(id='k2shg1b'), Comment(id='k2uiep7'), Comment(id='k2sbi2x'), Comment(id='k2uia48'), Comment(id='k2wvado'), Comment(id='k2sulf9'), Comment(id='k2t7h4l'), Comment(id='k2svyo7'), Comment(id='k2roh2e'), Comment(id='k2u8t15'), Comment(id='k2qik1r'), Comment(id='k2r1jj4'), Comment(id='k2qulte'), Comment(id='k2r2xq6'), Comment(id='k2q5m1d'), Comment(id='k2rf7tg'), Comment(id='k2r1yzm'), Comment(id='k2t90wh'), Comment(id='k2qi70y'), Comment(id='k3asszx'), Comment(id='k2txt88'), Comment(id='k2v77b0'), Comment(id='k2u9xcr'), Comment(id='k2qkaq1'), Comment(id='k2t8u2y'), Comment(id='k2vafsq'), Comment(id='k2v6m3q'), Comment(id='k2r0xgr'), Comment(id='k2r2560'), Comment(id='k2v0fah'), Comment(id='k2qiapv'), Comment(id='k2r9cpe'), Comment(id='k2sr8xa'), Comment(id='k2u5jym'), Comment(id='k2r9l1g'), Comment(id='k2vuzb1'), Comment(id='k2srdia'), Comment(id='k2vrkje'), Comment(id='k2t9bt5'), Comment(id='k2sxflt'), Comment(id='k2upnqb'), Comment(id='k34qica'), Comment(id='k2uiwmd'), Comment(id='k2r2uvu'), Comment(id='k2quy5p'), Comment(id='k2slmo2'), Comment(id='k2qom7k'), Comment(id='k2w931b'), Comment(id='k2qlchl'), Comment(id='k2vkgc8'), Comment(id='k2rdh7t'), Comment(id='k2vny6g'), Comment(id='k2uymdb'), Comment(id='k2vwwfg'), Comment(id='k2t3mwh'), Comment(id='k365eku'), Comment(id='k2uql9b'), Comment(id='k2r34ub'), Comment(id='k2v6afb'), Comment(id='k2qz2mu'), Comment(id='k2ra6br'), Comment(id='k2v1nz1'), Comment(id='k2tuvvk'), Comment(id='k36c51n'), Comment(id='k2vt05b'), Comment(id='k2shz8r'), Comment(id='k2rb9pv'), Comment(id='k35fmxg'), Comment(id='k2si9iy'), Comment(id='k2rbhn4'), Comment(id='k35op1e'), Comment(id='k2sjk3k'), Comment(id='k3638oy'), Comment(id='k2skgae'), Comment(id='k36fpsk')]"
16wkgs7,joshred,,2023-09-30 22:50:13+00:00,False,,False,False,True,False,/r/datascience/comments/16wkgs7/transition_advice/,Transition advice,"I'm a government employed data analyst (nominally a business system analyst) in a supervisory role. I have been trying to get away from the grind of government work and into data science, but I can't seem to get callbacks on my resume.

I do have some data science experience where I work, but I don't think it's being looked at seriously by prospective employers.

Currently, I'm pursuing a MSc through Georgia tech's OMSA program (currently taking classes 4 & 6). I had hoped that starting the program would improve my bona fide, but so far no dice.

Has anyone been in a similar place? 
I had a non-technical undergrad so I'm largely self taught.",datascience,https://www.reddit.com/r/datascience/comments/16wkgs7/transition_advice/,3,1,0.6,"[Comment(id='k2y681s'), Comment(id='k2y88q6'), Comment(id='k2yofz5')]"
16vle5j,YoYoMaDiet,,2023-09-29 19:47:43+00:00,False,,False,False,True,False,/r/datascience/comments/16vle5j/whats_the_point_of_learning_spark_if_you_can_do/,What’s the point of learning Spark if you can do almost everything in Snowflake and BigQuery?,"Serious question. At my work we’ve migrated almost all of our spark data engineering and ML pipelines to BigQuery, and it was really simple. With the added overhead of cluster management, and near feature parity, what’s the point of leveraging Spark anymore other than it being open source?",datascience,https://www.reddit.com/r/datascience/comments/16vle5j/whats_the_point_of_learning_spark_if_you_can_do/,61,78,0.88,"[Comment(id='k2rya1z'), Comment(id='k2s0k8u'), Comment(id='k2stgvv'), Comment(id='k2s7c7o'), Comment(id='k2svk8t'), Comment(id='k2sft2j'), Comment(id='k2sx1gi'), Comment(id='k2u1w7g'), Comment(id='k2slkkz'), Comment(id='k2tabmn'), Comment(id='k2tgvkl'), Comment(id='k2u7r0e'), Comment(id='k2ucrx7'), Comment(id='k2vjg8u'), Comment(id='k2xbhz6'), Comment(id='k2spb6g'), Comment(id='k2s3wto'), Comment(id='k2v3dzq'), Comment(id='k2thw2a'), Comment(id='k2s3hhs'), Comment(id='k2uxnd7'), Comment(id='k2t7wt2'), Comment(id='k2s8nwe'), Comment(id='k2scejn'), Comment(id='k2t78sz'), Comment(id='k2shi2p'), Comment(id='k2t7byb'), Comment(id='k2um8a9'), Comment(id='k2t7rav'), Comment(id='k2trhqj'), Comment(id='k2tavwx'), Comment(id='k2um5g9'), Comment(id='k2ul94f'), Comment(id='k2ulscr'), Comment(id='k2vrnx8'), Comment(id='k2xkmta'), Comment(id='k2ysglu'), Comment(id='k2vm2de'), Comment(id='k2t8jrn'), Comment(id='k2thw73'), Comment(id='k2tsk0o'), Comment(id='k2uc984'), Comment(id='k2ubvib'), Comment(id='k2uqtv1'), Comment(id='k2uxqqg'), Comment(id='k2w9pj0'), Comment(id='k2vqg66'), Comment(id='k2t9ax1'), Comment(id='k2ukvju'), Comment(id='k2umchh'), Comment(id='k2vfgq5'), Comment(id='k2vfsow'), Comment(id='k2wcnus'), Comment(id='k2w9twv'), Comment(id='k2vr94d'), Comment(id='k2usf45'), Comment(id='k2vlfb4'), Comment(id='k2wq9mc'), Comment(id='k2vrguf'), Comment(id='k2vncdo')]"
16w9z86,anon67543,,2023-09-30 15:37:11+00:00,False,,False,False,True,False,/r/datascience/comments/16w9z86/quantifying_picture_component_to_a_whole/,Quantifying picture component to a whole,"Simple example would be chopping a square into 4, with 1 image representing each quadrant. Overlaying these 4 would each get a score of 0.25 to get back to the original picture. 
Or we need 0.5 mountains, 0.3 clouds, and 0.2 rivers to make a Bob Ross painting. 

My project will be a bit more complex, but not much. How can I score the components? I’d like to incorporate into machine learning for testing many samples
Ideally, I’d use pictures of each clouds, rivers, etc as features in the ML model (if possible) 
Thanks for your time!",datascience,https://www.reddit.com/r/datascience/comments/16w9z86/quantifying_picture_component_to_a_whole/,0,1,1.0,[]
16w8bo4,,,2023-09-30 14:31:29+00:00,False,,False,False,True,False,/r/datascience/comments/16w8bo4/how_to_best_organise_a_data_person_injected_into/,How to best organise a data person injected into a specific business unit?,"Hey all, 

I work in pharma and work in two different departments: the data science department (my boss) and in the oncology department. 

It’s relatively new and we have a lot of wiggle room to improve the role and propose new responsibilities and redefine the job profile.

Currently we’re viewed as “business analyst consultants” to a degree. 

Our biggest hurdle is we lack a lot of support from our home base: data science dep, and end up doing a bunch of data engineering tasks specifically for the BU. Unfortunately, in our current profile, we’re all spreadsheet based and building these pipelines: joining data from a data warehouse, joining external data etc. is abysmal. 

In your opinion, what Role, or what changes would need to be suggested to the data science dep to improve this: for example, a dedicated data engineer in the BU? 

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16w8bo4/how_to_best_organise_a_data_person_injected_into/,1,1,1.0,[Comment(id='k2va188')]
16wd1gy,roblu001,,2023-09-30 17:45:39+00:00,False,,False,False,True,False,/r/datascience/comments/16wd1gy/anyone_using_powerbi_for_ds_or_stats/,Anyone using PowerBI for DS or stats?,"Hi all,

I'm wanting to use PBI for more stats. Obviously I need data wrangled into a format that will work, but is anyone else doing this?

I was thinking of t-testingvcategorical values against the overall sample average (Sig positive/negative)


What have you done(if anything)?",datascience,https://www.reddit.com/r/datascience/comments/16wd1gy/anyone_using_powerbi_for_ds_or_stats/,5,0,0.29,"[Comment(id='k2wli62'), Comment(id='k2w6hs2'), Comment(id='k2x0uzf'), Comment(id='k2zt5a4'), Comment(id='k2zcqzc')]"
16vj5y5,Dry_Cattle9399,,2023-09-29 18:22:29+00:00,False,,False,False,True,False,/r/datascience/comments/16vj5y5/anaconda_report_on_the_state_of_data_science_for/,Anaconda report on the state of Data Science for 2023,"Hi have anyone checked the latest report from Anaconda: [https://www.anaconda.com/state-of-data-science-report-2023](https://www.anaconda.com/state-of-data-science-report-2023)?  


It seems like data prep, data cleaning and data visualization are tasks are the top 3 of the most time consuming?   


What do you think? ",datascience,https://www.reddit.com/r/datascience/comments/16vj5y5/anaconda_report_on_the_state_of_data_science_for/,13,17,0.95,"[Comment(id='k2rah50'), Comment(id='k2sin8k'), Comment(id='k2stx1a'), Comment(id='k2smonq'), Comment(id='k2ub9iz'), Comment(id='k2vxfnb'), Comment(id='k41gu87'), Comment(id='k2ua2v0'), Comment(id='k41haxi'), Comment(id='k41h2se'), Comment(id='k41l56k'), Comment(id='k41krw0'), Comment(id='k4253bh')]"
16w17o0,anon67543,,2023-09-30 08:11:12+00:00,False,,False,False,True,False,/r/datascience/comments/16w17o0/quantify_contribution_of_component_pictures_to/,Quantify contribution of component pictures to create the final,"Simple example would be chopping a square into 4, with 1 image representing each quadrant. Overlaying these 4 would each get a score of 0.25 to get back to the original picture. 
Or we need 0.5 mountains, 0.3 clouds, and 0.2 rivers to make a Bob Ross painting. 

My project will be a bit more complex, but not much. How can I score the components? I’d like to incorporate into machine learning for testing many samples
Ideally, I’d use pictures of each clouds, rivers, etc as features in the ML model 
Thanks for your time!",datascience,https://www.reddit.com/r/datascience/comments/16w17o0/quantify_contribution_of_component_pictures_to/,0,0,0.5,[]
16urri3,pg860,,2023-09-28 21:10:35+00:00,False,,False,False,False,False,/r/datascience/comments/16urri3/machine_learning_pays_1540_more_than_data_science/,Machine Learning pays 15-40% more than Data Science - why?,,datascience,https://i.redd.it/r8y8ds6oa2rb1.png,121,245,0.92,"[Comment(id='k2n70je'), Comment(id='k2myvoj'), Comment(id='k2ncr87'), Comment(id='k2mtnyr'), Comment(id='k2n84hh'), Comment(id='k2nab1f'), Comment(id='k2n91xq'), Comment(id='k2n67yq'), Comment(id='k2nbndo'), Comment(id='k2n9nd8'), Comment(id='k2nk0e4'), Comment(id='k2nninw'), Comment(id='k2nzq5k'), Comment(id='k2o9gkp'), Comment(id='k2ptl9r'), Comment(id='k2nkxv2'), Comment(id='k2osj5k'), Comment(id='k2mysvv'), Comment(id='k2nig8y'), Comment(id='k2ndmji'), Comment(id='k2p1csv'), Comment(id='k2nnnc1'), Comment(id='k2nlvwm'), Comment(id='k2nm4v8'), Comment(id='k2o81wf'), Comment(id='k2oo1us'), Comment(id='k2osj7j'), Comment(id='k2p4ou1'), Comment(id='k2poft5'), Comment(id='k2pr4zu'), Comment(id='k2preyh'), Comment(id='k2qbdlv'), Comment(id='k2qknfx'), Comment(id='k2r4nfo'), Comment(id='k2rc1h5'), Comment(id='k2rubww'), Comment(id='k2tict1'), Comment(id='k2tl5xo'), Comment(id='k2u1pbs'), Comment(id='k2u4hip'), Comment(id='k2x02rz'), Comment(id='k2xmczc'), Comment(id='k2n8oy0'), Comment(id='k2nwwp6'), Comment(id='k2see9o'), Comment(id='k2ukt9f'), Comment(id='k2n757o'), Comment(id='k2n9wv3'), Comment(id='k2nmgv0'), Comment(id='k2nx4hr'), Comment(id='k2owvh6'), Comment(id='k2pbtsb'), Comment(id='k2og0p0'), Comment(id='k2ngafx'), Comment(id='k2o23oe'), Comment(id='k2rhdte'), Comment(id='k2nbj9g'), Comment(id='k2rmc56'), Comment(id='k2nkyqa'), Comment(id='k2nrr2v'), Comment(id='k2neuj1'), Comment(id='k2ovaq0'), Comment(id='k2rkvk9'), Comment(id='k2nxi21'), Comment(id='k2o77e7'), Comment(id='k2n41lj'), Comment(id='k2n2ldj'), Comment(id='k2niosx'), Comment(id='k2niqa7'), Comment(id='k2q8g8d'), Comment(id='k2uvcle'), Comment(id='k2wy13s'), Comment(id='k2nqwm9'), Comment(id='k2qclyt'), Comment(id='k2nhk62'), Comment(id='k2pssom'), Comment(id='k2o20zg'), Comment(id='k2nyer0'), Comment(id='k2p0v23'), Comment(id='k2pll6c'), Comment(id='k2omkn5'), Comment(id='k2om8dv'), Comment(id='k2nbqan'), Comment(id='k2rljaw'), Comment(id='k2nxbbh'), Comment(id='k2rm60v'), Comment(id='k2nmme8'), Comment(id='k2sdk4o'), Comment(id='k2nxuir'), Comment(id='k2nwrs5'), Comment(id='k2npeii'), Comment(id='k2px3go'), Comment(id='k2o45w5'), Comment(id='k2o28mp'), Comment(id='k2rhzsl'), Comment(id='k2pyfdu'), Comment(id='k7qa41f'), Comment(id='k2nl5pe'), Comment(id='k2s9eqm'), Comment(id='k2nz0d0'), Comment(id='k2rnf95'), Comment(id='k2qqx85'), Comment(id='k2o4eq3'), Comment(id='k2nlbz0'), Comment(id='k2sc1jo'), Comment(id='k2nz8w5'), Comment(id='k2rvcpr'), Comment(id='k2o50g3'), Comment(id='k2nmclf'), Comment(id='k2tcsbj'), Comment(id='k2nzn9k'), Comment(id='k2p6z2m'), Comment(id='k2o5fid'), Comment(id='k2pth5b'), Comment(id='k2tlouz'), Comment(id='k2o83o7'), Comment(id='k2psbmk'), Comment(id='k2ru5d8'), Comment(id='k2tqx89'), Comment(id='k2q1ja2')]"
16vk1th,harpooooooon,,2023-09-29 18:56:46+00:00,False,,False,False,True,False,/r/datascience/comments/16vk1th/finedtune_bert_vs_llm/,Fined-Tune BERT vs LLM,"this is a really  general question, but how much better is an LLM compared to a fine-tuned BERT model is any conceivable NLP instance? ",datascience,https://www.reddit.com/r/datascience/comments/16vk1th/finedtune_bert_vs_llm/,1,3,1.0,[Comment(id='k2sf8a7')]
16v58a9,Anandh1412,,2023-09-29 07:41:19+00:00,False,,1696133048.0,False,True,False,/r/datascience/comments/16v58a9/i_left_my_job_to_study_for_the_next_6_months/,I left my job to study for the next 6 months,"I need someone's help on how to start in data science (I know it takes a lot of time to learn, but I'm dedicating 6 months to this study). Can someone please suggest some good laptops below $650 and provide a roadmap?

Edit: Fellow Redditors, thank you so much for all your comments. After a lot of introspection, I plan to work in an entry-level data analyst role and then slowly move into data science. Could someone please share a 3-month roadmap for learning, along with resources? This would be helpful for me and others.",datascience,https://www.reddit.com/r/datascience/comments/16v58a9/i_left_my_job_to_study_for_the_next_6_months/,47,21,0.77,"[Comment(id='k2r924e'), Comment(id='k2s5a6i'), Comment(id='k2rca79'), Comment(id='k2ptcmi'), Comment(id='k2s7vg2'), Comment(id='k2qlo4m'), Comment(id='k2qn6ya'), Comment(id='k2qd42k'), Comment(id='k2r2bnx'), Comment(id='k2rbdoh'), Comment(id='k2skk3d'), Comment(id='k2vmk6t'), Comment(id='k2xjrpg'), Comment(id='k322ilq'), Comment(id='k2qxwoi'), Comment(id='k2rbj8t'), Comment(id='k2ssdl3'), Comment(id='k2r9ruf'), Comment(id='k2uyk93'), Comment(id='k2rcmta'), Comment(id='k2pw2rw'), Comment(id='k2vmz5y'), Comment(id='k2qnxu0'), Comment(id='k2qnz3f'), Comment(id='k2r2nft'), Comment(id='k2vmqec'), Comment(id='k2yg6eq'), Comment(id='k33g0j1'), Comment(id='k2vk0p3'), Comment(id='k2s21kv'), Comment(id='k2ralgf'), Comment(id='k2reyp2'), Comment(id='k2vo6am'), Comment(id='k2sb49g'), Comment(id='k2r7qif'), Comment(id='k2yjbz5'), Comment(id='k33i8qu'), Comment(id='k2rb3pw'), Comment(id='k2rf6mm'), Comment(id='k2yhif7'), Comment(id='k2vn83z'), Comment(id='k2r9asf'), Comment(id='k33idhx'), Comment(id='k2rbppt'), Comment(id='k2ysenm'), Comment(id='k2rc5mk'), Comment(id='k2ysrkc')]"
16vgm5z,el_chubinebrae,,2023-09-29 16:43:08+00:00,False,,1696037513.0,False,True,False,/r/datascience/comments/16vgm5z/bit_of_guidance/,Bit of guidance?,"I've made some XgBoost models and found some good hyperparameter combinations to get some fairly decent results with my criss fold validations. I think the highest I've got is about 85% In real life it's showing signs of overfitting dropping to 55%.

I'm trying to predict stock market direction, just up or down. But I have a train of thought that's leading down a rabbit hole I don't think I should be going down. I'm taking the latest prices along with some features and using that as my prediction row. Then I add another row of data and retrain the model with the same params again and predict, repeating about 180 times until I have an entire columns of predictions. 

I understand it's computationally expensive to repeat this process so many time, it doesn't take a great deal of time to do it. I thought if I use the data from the training set then I'll suffer from Overfitting, which I clearly am already doing so but I'll carry on trying to reduce overfitting.

Should I trim the training set to a point before the dates I want to predict and use the same model for these 180 days? Or should I think about retraining the model every 30 or so data points? I feel like there's almost limitless possibilities and I've gone down the wrong path which will render everything I've done up till now pointless.

Edit: Absolutely not looking for people to help with cracking the stock market. Just how to train models properly. I totally understand I'm never going to win the stock market.",datascience,https://www.reddit.com/r/datascience/comments/16vgm5z/bit_of_guidance/,31,2,0.59,"[Comment(id='k2r5qxx'), Comment(id='k2r6dzh'), Comment(id='k2rgrq9'), Comment(id='k2s4qq9'), Comment(id='k2s5lrt'), Comment(id='k2srnmo'), Comment(id='k2t0qsp'), Comment(id='k2rujmk'), Comment(id='k2yd5yz'), Comment(id='k2s6dgv'), Comment(id='k2si0rm'), Comment(id='k2s6vki'), Comment(id='k2sioc6'), Comment(id='k2s9sdo'), Comment(id='k2srx1b'), Comment(id='k2t1q0i'), Comment(id='k2sj47d'), Comment(id='k2tmb0n'), Comment(id='k2sp1xh'), Comment(id='k2tlfxy'), Comment(id='k2skaa7'), Comment(id='k2v1c96'), Comment(id='k2sqnar'), Comment(id='k2sqxka'), Comment(id='k2ur86h'), Comment(id='k2skgy6'), Comment(id='k2x3e9u'), Comment(id='k2x5rt4'), Comment(id='k2yh3cc'), Comment(id='k3027pr'), Comment(id='k30rl5f')]"
16uze49,TheManveru,,2023-09-29 02:23:06+00:00,False,,False,False,True,False,/r/datascience/comments/16uze49/how_to_be_a_better_data_scientist_and_catch_up/,How to be a better data scientist and catch up faster with smarter colleagues?,"It is very clear to me that I am one of the least competent data scientists at my company, if not the one (For context, I have worked here for 1 year, having worked 2 years before as a DA), but I know it is not simply a matter of imposter syndrome. 

When I was hired as a JDS, most of my colleagues were data analysts and my responsibilities were mostly similar to theirs (basically SQL and BI), I think I did an okay job and managed to get a promotion to regular DS. Things changed, and I was moved to a team of experienced DSs. There I will be expected to do much less data analysis and more development. Now I noticed the big skill gap and how undeserving I was of my promotion. I am extremely intimidated by my colleagues' large knowledge of our codebase (and of theory in general), and by their awareness of recent relevant papers. I also suck at networking and have a very poor knowledge of who knows/does what in the company, which everyone else seems to do well. I also don't have great presentation skills, mostly due to my lack of knowledge and subsequent insecurity. 

I know that I need to catch up, but I don't really understand how. I try to pay a lot of attention to everything that is written or said in meetings, but that almost never makes sense to me as I don't have the context. I also can never add to any meeting unless we are discussing something very close to what I have worked on. At this point, I feel super ashamed as I need to take care of one specific model that I know almost anything about. Its performance is bad and I can't figure out how to start. I am supposed at least to diagnose the model's failures but I have way too little knowledge to even figure out what to do. I could follow someone's instructions well if I had them. But as a DS I should be able to do that by myself. I know very well that working with smarter people is great for my career and that I shouldn't listen to my inner voice that tells me I should have stayed a DA. Still, I feel that I don't have the behavioral skills to take advantage of that the best way as I am introverted and have ADHD.   


I identified that my lack of attention is an issue and I am making a conscious effort to pay more attention. I am quite self-conscious and afraid of making questions, which is something I am trying to change, but at a big effort to me. So I wonder if you guys have any general hints/suggestions on how to improve faster. ",datascience,https://www.reddit.com/r/datascience/comments/16uze49/how_to_be_a_better_data_scientist_and_catch_up/,15,38,0.89,"[Comment(id='k2o6gf5'), Comment(id='k2o7qhe'), Comment(id='k2pczi4'), Comment(id='k2ourug'), Comment(id='k2pvejw'), Comment(id='k2q6mxy'), Comment(id='k2qmf0t'), Comment(id='k2r6suz'), Comment(id='k2rei5n'), Comment(id='k2q1uah'), Comment(id='k2pr01w'), Comment(id='k2q1ip3'), Comment(id='k34byeh'), Comment(id='k2puoob'), Comment(id='k2pw0r0')]"
16urkg1,PitterPatTomCat,,2023-09-28 21:03:23+00:00,False,,False,False,True,False,/r/datascience/comments/16urkg1/big_fancy_company_has_no_clue_what_data_science_is/,Big Fancy Company Has No Clue What Data Science Is,"They offered to cover my move from the East Coast to Dallas, plump my check with an additional 50K for signing, but the office is run by squirrels.

I’m not talking your acorn tree squirrel. I’m talking tiny little men with moostaches who haven’t the slightest clue that plugging in numbers to an excel sheet ain’t science.

Do I tell them this is nuts?! Or do I keep the money and hang?

The name of the company rhymes with Jewelry.",datascience,https://www.reddit.com/r/datascience/comments/16urkg1/big_fancy_company_has_no_clue_what_data_science_is/,38,76,0.92,"[Comment(id='k2mtm8m'), Comment(id='k2mwws9'), Comment(id='k2njwp4'), Comment(id='k2nag9v'), Comment(id='k2nh3so'), Comment(id='k2mxj94'), Comment(id='k2o3xmq'), Comment(id='k2o6dxo'), Comment(id='k2pl93q'), Comment(id='k2pgbhy'), Comment(id='k2q0ls9'), Comment(id='k338fap'), Comment(id='k2ooe2w'), Comment(id='k2oymq2'), Comment(id='k2uy02t'), Comment(id='k2nmqgb'), Comment(id='k2qtcft'), Comment(id='k2p6mxz'), Comment(id='k2ooqxk'), Comment(id='k2noxqm'), Comment(id='k2od5ky'), Comment(id='k2pzeqd'), Comment(id='k2ptclf'), Comment(id='k2oryjw'), Comment(id='k2rovs4'), Comment(id='k2qtiqj'), Comment(id='k2o384r'), Comment(id='k2rct6v'), Comment(id='k2q0cle'), Comment(id='k2rphw2'), Comment(id='k2r0y2o'), Comment(id='k2q1i8w'), Comment(id='k2rwla8'), Comment(id='k2r37tn'), Comment(id='k2qk488'), Comment(id='k2tygz8'), Comment(id='k2usi1w'), Comment(id='k2xdne4')]"
16uomoo,Consistent-Design-57,,2023-09-28 19:10:31+00:00,False,,1695931442.0,False,True,False,/r/datascience/comments/16uomoo/everyone_always_talks_about_llmsml_in_data/,"Everyone always talks about LLMs/ML in data science but no one ever talks about experimentation, ML's older sexier sister.","As a data scientist primarily focused in causal inference and experiment design, I find that most conversation and questions from people trying to transition into DS always want to go into ML, but causal inference and experimentation is another very fun sub-field within DS. I'm biased since I'm in this sub-field but having done some ML stuff on the side, I much more enjoy the causal inference side of things.

Note that this post is primarily geared toward people with some experience. It's hard to break into experimentation with no background. Fresh PhDs though, particularly in social or physical sciences do well.

What's fun about about experimentation and causal inference:

1. Knowing why something caused something else is always valuable
2. Well designed experiments can be hard to design and execute, which is part of the challenge. A good experiment correctly captures the objectives of the product manager/business partner and answers a question that can be immediately acted upon once results are available.
3. Requires a combination of business thinking, strategy, and strong statistical foundations
4. Often is highly collaborative and builds your soft skills. I work with people in marketing, risk, finance, modeling, dashboarding teams to make sure things work well
5. Causal inference is not just A/B testing. There are plenty of situations where we need to get a causal understanding but an experiment is just not feasible. Tons of fun techniques here like instrumental variables, propensity score matching, causal forests, double ML etc. which have their own strengths and weaknesses
6. Experimentation is not just A/B testing. We have multi-arm bandits, factorial and fractional factorial experiment designs etc.
7. Usually don't have to worry about productionizing etc. ML is often 5 lines of code once you've massaged the data just right
8. It's a growing field. I see lots of job openings in experimentation and the skillset is hard to come by. It's not easy to do causal inference (both the experimental and non-experimental kind) and all the challenges of launching a business experiment require on the job training to be successful at.

If you're in the market for a new role, don't overlook experimentation (or think of it as less fun) :).

Some resources for those to want to learn:

1. [https://matheusfacure.github.io/python-causality-handbook/landing-page.html](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)
2. Trustworthy online controlled experiments by Ronny Kohavi, a giant in the field of experiment design
3. Mostly Harmless Econometrics by Angrist et al.",datascience,https://www.reddit.com/r/datascience/comments/16uomoo/everyone_always_talks_about_llmsml_in_data/,24,107,0.93,"[Comment(id='k2mnbeh'), Comment(id='k2mn7h6'), Comment(id='k2ml5wn'), Comment(id='k2mo2cv'), Comment(id='k2nabin'), Comment(id='k2otrlm'), Comment(id='k2ojrfo'), Comment(id='k2p4a2y'), Comment(id='k2pbm0u'), Comment(id='k2n7goy'), Comment(id='k2o3eju'), Comment(id='k2mu071'), Comment(id='k2n8nv7'), Comment(id='k2ogcly'), Comment(id='k2svkum'), Comment(id='k2n709d'), Comment(id='k2mp7qr'), Comment(id='k2o81cj'), Comment(id='k2o042u'), Comment(id='k2n9m9l'), Comment(id='k2nv7dy'), Comment(id='k2ob89h'), Comment(id='k2no1ka'), Comment(id='k2p4db6'), Comment(id='k2pa23s'), Comment(id='k2pcomx')]"
16vg73y,ravy,,2023-09-29 16:26:33+00:00,False,,False,False,False,False,/r/datascience/comments/16vg73y/what_the_birthday_paradox_teaches_us_about/,What the Birthday Paradox Teaches Us About Protecting Patron Privacy,,datascience,https://chimpy.me/blog/posts/what-the-birthday-paradox-teaches-us-about-protecting-patron-privacy/,0,2,1.0,[]
16vfyfw,Alarming_Scene126,,2023-09-29 16:17:31+00:00,False,,False,False,False,False,/r/datascience/comments/16vfyfw/first_project_review_data_wrangling_and/,First project review | Data wrangling and Visualization,"Hello guys,

This is my first project and i request you guys to please check out my work, leave a comment on what i can improve and upvote in kaggle it you like it.
I have performed:
• Data manipulation (pandas, numpy)
• Data visualization (pandasql, matplotlib)

I would like to thank this community for creating opportunity for ppl like us to share our work. Thank you all!!",datascience,https://www.kaggle.com/code/aadeshpradhan/data-cleaning-viz-for-beginners-intermediate?scriptVersionId=144642580,0,2,1.0,[]
16udvr0,Tarneks,,2023-09-28 11:50:12+00:00,False,,False,False,False,False,/r/datascience/comments/16udvr0/this_is_a_data_analyst_position/,This is a data analyst position.,,datascience,https://i.redd.it/9jvrsplsizqb1.jpg,174,364,0.96,"[Comment(id='k2kmwv7'), Comment(id='k2kp9mt'), Comment(id='k2ko6d2'), Comment(id='k2liwcv'), Comment(id='k2l9cq5'), Comment(id='k2khdzf'), Comment(id='k2l0oq9'), Comment(id='k2kxi4k'), Comment(id='k2kggar'), Comment(id='k2l2s0e'), Comment(id='k2mx3qx'), Comment(id='k2ljpve'), Comment(id='k2m168s'), Comment(id='k2ngw09'), Comment(id='k2nxbd4'), Comment(id='k2ku2xq'), Comment(id='k2lrxsk'), Comment(id='k2ol1ip'), Comment(id='k2lzakj'), Comment(id='k2lwuf9'), Comment(id='k2lh962'), Comment(id='k2m51n9'), Comment(id='k2oygyz'), Comment(id='k2p1stk'), Comment(id='k2p7o4p'), Comment(id='k2pbfg8'), Comment(id='k2tt66c'), Comment(id='k3brzrn'), Comment(id='k2kqaoj'), Comment(id='k2lfs44'), Comment(id='k2nlswm'), Comment(id='k2kz3up'), Comment(id='k2l3sqg'), Comment(id='k2lh0hb'), Comment(id='k2o72bn'), Comment(id='k2w8qzq'), Comment(id='k2ktpyb'), Comment(id='k2nwynh'), Comment(id='k2mcune'), Comment(id='k2p783v'), Comment(id='k2nic92'), Comment(id='k2qc8lz'), Comment(id='k2l8r28'), Comment(id='k2lwmx2'), Comment(id='k2lyz64'), Comment(id='k2mtwnn'), Comment(id='k2rizlm'), Comment(id='k2m0h7d'), Comment(id='k2kwbm4'), Comment(id='k2khktk'), Comment(id='k2l3jsv'), Comment(id='k2m6tjd'), Comment(id='k2r6g2d'), Comment(id='k2sl95n'), Comment(id='k2kwlnq'), Comment(id='k2mfzam'), Comment(id='k2lhaxy'), Comment(id='k2ksryo'), Comment(id='k2ln9am'), Comment(id='k2l14vm'), Comment(id='k2lga4v'), Comment(id='k2l8aur'), Comment(id='k2lgdmm'), Comment(id='k2owayx'), Comment(id='k2o73zp'), Comment(id='k2kwi2a'), Comment(id='k2qh724'), Comment(id='k2lcslf'), Comment(id='k2lz3tx'), Comment(id='k2m5mj2'), Comment(id='k2m7lz4'), Comment(id='k2m9n7o'), Comment(id='k2l8qs9'), Comment(id='k2lw4ab'), Comment(id='k2skv8i'), Comment(id='k2kn4k8'), Comment(id='k2kifxd'), Comment(id='k2ozaw2'), Comment(id='k2kv59n'), Comment(id='k2l80ll'), Comment(id='k2lfefh'), Comment(id='k2mxz2f'), Comment(id='k2o4rjz'), Comment(id='k2ofldo'), Comment(id='k2l9h5l'), Comment(id='k2l4v8x'), Comment(id='k2n7jwi'), Comment(id='k2ne62f'), Comment(id='k2nhn5v'), Comment(id='k2od9ce'), Comment(id='k2llhqp'), Comment(id='k2nijri'), Comment(id='k2lszle'), Comment(id='k2o7785'), Comment(id='k2la2qp'), Comment(id='k2l8ogs'), Comment(id='k2lkvdi'), Comment(id='k2lwl2j'), Comment(id='k2qylyh'), Comment(id='k2mo9qf'), Comment(id='k2l8ei3'), Comment(id='k2ks7ci'), Comment(id='k2kzt7m'), Comment(id='k2mdwlz'), Comment(id='k2l4y0n'), Comment(id='k2lg300'), Comment(id='k2lsv23'), Comment(id='k2l8ww5'), Comment(id='k2le54z'), Comment(id='k2lgr3d'), Comment(id='k2lwz9s'), Comment(id='k2osi9t'), Comment(id='k2lgpbh'), Comment(id='k2m40h5'), Comment(id='k2lgh6x'), Comment(id='k2n8afp'), Comment(id='k2nied8'), Comment(id='k2oeq7s'), Comment(id='k2o8vzr'), Comment(id='k2og3gp'), Comment(id='k2m4m1k'), Comment(id='k2ndg8e'), Comment(id='k2lvj0y'), Comment(id='k2oggut'), Comment(id='k2la6jw'), Comment(id='k2ohdns'), Comment(id='k2oidap'), Comment(id='k2ly8jw'), Comment(id='k2l50rw'), Comment(id='k2lj5ll'), Comment(id='k2l3bsq'), Comment(id='k2l5mzi'), Comment(id='k2li9ws'), Comment(id='k2mjd8q'), Comment(id='k2lgvn2'), Comment(id='k2ozqhg'), Comment(id='k2lkwgr'), Comment(id='k2nj8zg'), Comment(id='k2omylr'), Comment(id='k2oa24b'), Comment(id='k2n0hn1'), Comment(id='k2nl9k1'), Comment(id='k2m4zz6'), Comment(id='k2lal8a'), Comment(id='k2lph15'), Comment(id='k2lsfcu'), Comment(id='k2l6txt'), Comment(id='k2ls9g3'), Comment(id='k2mxhjn'), Comment(id='k2lcpo2'), Comment(id='k2lir9q'), Comment(id='k2l6q4n'), Comment(id='k2lmsig'), Comment(id='k2op4u0'), Comment(id='k2oemxk'), Comment(id='k2ozz8j'), Comment(id='k2niudz'), Comment(id='k2o9r0u'), Comment(id='k2la5zu'), Comment(id='k2lzgly'), Comment(id='k2mjz77'), Comment(id='k2oo7rn'), Comment(id='k2ld8nn'), Comment(id='k2mmm8y'), Comment(id='k2o65gy'), Comment(id='k2ldzg5'), Comment(id='k2mrssh'), Comment(id='k2m31qt'), Comment(id='k2loljl'), Comment(id='k2ozhws'), Comment(id='k2liofi'), Comment(id='k2ml5tm'), Comment(id='k2lfand'), Comment(id='k2mtjr3'), Comment(id='k2lfmrv'), Comment(id='k2lq0p8'), Comment(id='k2qc7l8'), Comment(id='k2ljdcg'), Comment(id='k2nbt8t'), Comment(id='k2mkgse'), Comment(id='k2lqhcy'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
16v36n7,yuribz,,2023-09-29 05:38:23+00:00,False,,False,False,True,False,/r/datascience/comments/16v36n7/no_passion_for_data_science_what_jobs_can_i_get/,"No passion for data science, what jobs can I get?","Hi everyone. I am a recent data science graduate (bachelor's) from UCSD, but I also have a degrees in Linguistics and teaching experience. I am trying to apply to data science jobs, but from what I figured, if I don't have outright passion and initiative to pursue data science, it will be near impossible to find a job. I want to eventually become a teacher, but I want to work somewhere else first to get experience and save up money. 

What fields are data science skills transferrable to? I know that in any field I will have to show initiative and passion, but I feel like that IT is so cut throat right now that it'd be much easier to find job elsewhere.",datascience,https://www.reddit.com/r/datascience/comments/16v36n7/no_passion_for_data_science_what_jobs_can_i_get/,33,12,0.67,"[Comment(id='k2oqoam'), Comment(id='k2pt3i5'), Comment(id='k2ot2po'), Comment(id='k2owa3p'), Comment(id='k2px5rw'), Comment(id='k2pp6ip'), Comment(id='k2py7pe'), Comment(id='k2q7r8e'), Comment(id='k2re6mz'), Comment(id='k2rqb9u'), Comment(id='k2st2zj'), Comment(id='k2ti5n7'), Comment(id='k2txpm0'), Comment(id='k2vu3wu'), Comment(id='k2oqvse'), Comment(id='k2qqhmu'), Comment(id='k2otji4'), Comment(id='k2oxldh'), Comment(id='k2qq8xe'), Comment(id='k2qo3tx'), Comment(id='k2qnsyv'), Comment(id='k2reg3k'), Comment(id='k2tk8a9'), Comment(id='k2ty2vt'), Comment(id='k2ppv2y'), Comment(id='k2qsj9s'), Comment(id='k2oun0t'), Comment(id='k2tkh3b'), Comment(id='k2tkivn'), Comment(id='k2tl5hz'), Comment(id='k2u0t6v'), Comment(id='k2t3z21'), Comment(id='k2tlx7r')]"
16vaujg,rizic_1,,2023-09-29 12:52:15+00:00,False,,False,False,True,False,/r/datascience/comments/16vaujg/what_do_you_bring_to_the_table/,What do you bring to the table?,Data science is a broad field. What do you feel makes you a great data scientist or what are you trying to achieve? e.g. “I’m a bada** statistician because x and no one else knows how to do x”,datascience,https://www.reddit.com/r/datascience/comments/16vaujg/what_do_you_bring_to_the_table/,46,2,0.58,"[Comment(id='k2q0yli'), Comment(id='k2q6j0j'), Comment(id='k2q5wl7'), Comment(id='k2s13eq'), Comment(id='k2qqtta'), Comment(id='k2quuhc'), Comment(id='k2qe3mr'), Comment(id='k2qa4cr'), Comment(id='k2sfqo5'), Comment(id='k2u7hu3'), Comment(id='k2rvsqf'), Comment(id='k2r2n24'), Comment(id='k2qwbls'), Comment(id='k2todah'), Comment(id='k2tw3dq'), Comment(id='k2qsoct'), Comment(id='k2quew1'), Comment(id='k2rxaca'), Comment(id='k2sgblc'), Comment(id='k38yt61'), Comment(id='k2qmaey'), Comment(id='k2q8msn'), Comment(id='k2rhegb'), Comment(id='k2r51qk'), Comment(id='k2sh033'), Comment(id='k2r7sbf'), Comment(id='k2qp01t'), Comment(id='k2qkzbf'), Comment(id='k2rh7ts'), Comment(id='k2r8ewe'), Comment(id='k2tw1c1'), Comment(id='k2qmgks'), Comment(id='k2qktee'), Comment(id='k2td2ts'), Comment(id='k2r9lxe'), Comment(id='k2ries6'), Comment(id='k2rapbb'), Comment(id='k2uxlv7'), Comment(id='k2romt7'), Comment(id='k2ted5m'), Comment(id='k2rj2wi'), Comment(id='k2rgkf7'), Comment(id='k2to8r2'), Comment(id='k2tej2w'), Comment(id='k2rhzaa'), Comment(id='k2rk4a8'), Comment(id='k2rn5ft'), Comment(id='k2roa80')]"
16vdu21,Interesting_Chance31,,2023-09-29 14:55:27+00:00,False,,False,False,True,False,/r/datascience/comments/16vdu21/last_call_for_rugs_grant_applications/,Last Call for RUGS Grant Applications!,"Hello to all R enthusiast, just a friendly reminder to anyone eyeing the RUGS grant opportunity. The clock's ticking with the deadline set for tomorrow, September 30th, 2023. Don't miss out on this chance to bolster your R-based projects. All details are here: https://www.r-consortium.org/all-projects/r-user-group-support-program. Seize the moment!",datascience,https://www.reddit.com/r/datascience/comments/16vdu21/last_call_for_rugs_grant_applications/,0,2,1.0,[]
16vjh8q,alpha-gamma-x,,2023-09-29 18:34:30+00:00,False,,False,False,True,False,/r/datascience/comments/16vjh8q/when_a_ml_algorithm_is_training_what_is_actually/,"When a ML algorithm is training, what is actually happening behind the scenes? How does it learn?","Basically the question. When we run say logistic regression or an SVM on Python, what is happening step by step with all the train data? I know the answer may vary based on the algorithm, so you may pick any algorithm to explain in detail the behind-the-scenes.

Wanted to post at r/explainlikeimfive but wasn’t sure if any ML people may be in that crowd, but please ELI5.",datascience,https://www.reddit.com/r/datascience/comments/16vjh8q/when_a_ml_algorithm_is_training_what_is_actually/,34,0,0.48,"[Comment(id='k2rkdbl'), Comment(id='k2rq450'), Comment(id='k2rrqcn'), Comment(id='k2sayt0'), Comment(id='k2skpee'), Comment(id='k2ttvbe'), Comment(id='k2rg67t'), Comment(id='k2rjpce'), Comment(id='k2rozoz'), Comment(id='k2rw3h1'), Comment(id='k2rx9hf'), Comment(id='k2rt77c'), Comment(id='k2rmht6'), Comment(id='k2rpegu'), Comment(id='k2ru4ar'), Comment(id='k2rv29j'), Comment(id='k2s2h2y'), Comment(id='k2s3qgi'), Comment(id='k2sdf8t'), Comment(id='k2skntb'), Comment(id='k2t88wf'), Comment(id='k2ttkmy'), Comment(id='k2u3qou'), Comment(id='k2uaqqi'), Comment(id='k2rsl0m'), Comment(id='k2rudo1'), Comment(id='k2rog0o'), Comment(id='k2s27qe'), Comment(id='k2s2g8z'), Comment(id='k2rokt2'), Comment(id='k2salkl'), Comment(id='k2sdtzn')]"
16unmxh,imjustsippintea,,2023-09-28 18:31:55+00:00,False,,False,False,True,False,/r/datascience/comments/16unmxh/is_data_analytics_not_entry_level/,Is Data Analytics not entry level?,"This a response to the replies I saw from a previous post where hiring managers simply filtered out inexperienced applicants.

My question is if data analytics is not the right path to get acclimated in this field, then what is? Where could you get experience that will allow hiring managers to respect what you have to offer?

In my case, I’ve recently graduated with a social science degree and have been advancing my knowledge in statistics to apply for these positions. I’ve done one project in the past and plan to finish a certificate this month. My only sense of career guidance has been what I’ve seen online. Data events aren’t really catered to newcomers in my area and rejected job applications are the only type of feedback I get.",datascience,https://www.reddit.com/r/datascience/comments/16unmxh/is_data_analytics_not_entry_level/,35,38,0.82,"[Comment(id='k2m72dt'), Comment(id='k2m44o0'), Comment(id='k2m95b6'), Comment(id='k2mjssd'), Comment(id='k2ma3i2'), Comment(id='k2mang3'), Comment(id='k2mo3zf'), Comment(id='k2m5lva'), Comment(id='k2m8yi5'), Comment(id='k2n4yyh'), Comment(id='k2mu3hw'), Comment(id='k2n1fg1'), Comment(id='k2n5rhl'), Comment(id='k2mz5hv'), Comment(id='k2msdc4'), Comment(id='k2m4bwp'), Comment(id='k2p95m3'), Comment(id='k2m9ie0'), Comment(id='k2mvqjp'), Comment(id='k2mazzy'), Comment(id='k2mmkxj'), Comment(id='k2mm4ob'), Comment(id='k2nczye'), Comment(id='k2n8exn'), Comment(id='k2n96m5'), Comment(id='k2n0u4y'), Comment(id='k2n6nzf'), Comment(id='k2r3f9m'), Comment(id='k2n7dnn'), Comment(id='k2p0caf'), Comment(id='k2p1cnv'), Comment(id='k2o8m9m'), Comment(id='k2pujar'), Comment(id='k2ptvhv'), Comment(id='k2rb3q8'), Comment(id='k2qpfzg')]"
16vc2xm,Interesting_Chance31,,2023-09-29 13:45:48+00:00,False,,False,False,True,False,/r/datascience/comments/16vc2xm/sunday_oct_1st_is_the_last_day_to_submit_your/,"Sunday, Oct 1st, is the last day to submit your proposals!","Here is What We’re Looking For in Your Proposals

The ISC values projects that:

1️⃣ Have a broad impact on the R community

2️⃣ Are scoped to be focused and actionable

3️⃣ Carry a low-to-medium risk and reward

Review Process:

Proposals will be reviewed by the Chair of the ISC and committee members, with results announced per the key dates.

Let's enrich the R landscape together. We can't wait to review your innovative proposals! Learn more here: https://www.r-consortium.org/all-projects/call-for-proposals

\#RProgramming #Rstats #OpenSource #DataScience",datascience,https://www.reddit.com/r/datascience/comments/16vc2xm/sunday_oct_1st_is_the_last_day_to_submit_your/,0,0,0.5,[]
16vajxx,neuro-psych-amateur,,2023-09-29 12:38:56+00:00,False,,False,False,True,False,/r/datascience/comments/16vajxx/lets_discuss_again_distance_learning_phds/,Let's discuss again distance learning PhDs,"I have recently posted about not being able to find a new job. I do work as a senior analyst, and the job pays the bills, but it isn't very interesting. I am sincerely interested in statistics, predictive modeling, machine learning, and I want to keep pursuing that. I have been applying a lot, had my resume reviewed by several people, but I am just not getting any replies.

I am now thinking about what else I can do with my life to make it more interesting. I have a masters degree in data science, and two published papers, so in theory I could apply for a PhD. I have a mortgage and small kids though, I really can't go for a full-time PhD because I wouldn't make enough. My salary is around $79K USD and PhD programs definitely don't pay that. I also can't move because of kids, mortgage, family, etc.

I do really want to work on an interesting project though, are there any good remote part-time  PhD programs? I know this has been already discussed, and there aren't a lot of options, but I did see that the Open University in UK has such a program and the Coventry University, also in UK, has one. The programs are quite expensive though for non-UK residents. 
Anyone aware of other DS part-time remote PhD programs? I could find a way to attend campus occasionally, but definitely not every week, if it's far away. And unfortunately there aren't any part-time DS PhD programs in my city.",datascience,https://www.reddit.com/r/datascience/comments/16vajxx/lets_discuss_again_distance_learning_phds/,20,2,0.6,"[Comment(id='k2qe4z2'), Comment(id='k2qnzvk'), Comment(id='k2q4djk'), Comment(id='k2qpgws'), Comment(id='k2qq7y3'), Comment(id='k31igan'), Comment(id='k2sapc1'), Comment(id='k2r0o03'), Comment(id='k2q5ok4'), Comment(id='k2v4a3q'), Comment(id='k2v4qvq'), Comment(id='k2ra2bl'), Comment(id='k2q9wiw'), Comment(id='k30bczf'), Comment(id='k3eu2i8'), Comment(id='k2qdx74'), Comment(id='k3f2moa'), Comment(id='k2qif27'), Comment(id='k2qf9oy'), Comment(id='k2rd876')]"
16usord,InevitableTraining69,,2023-09-28 21:44:56+00:00,False,,False,False,True,False,/r/datascience/comments/16usord/you_ever_start_a_new_job_and_hate_it/,You ever start a new job and hate it?,"I just started this new job and I feel so blah about it. Like going to work each day feels like I'm about to jump into freezing cold water. I'm just iffy about it. But my last company laid me off which is why I ""left"" but I loved working there. I really loved the vibe and the environment and I wanna go back idk what's wrong with me.",datascience,https://www.reddit.com/r/datascience/comments/16usord/you_ever_start_a_new_job_and_hate_it/,10,15,0.83,"[Comment(id='k2nou0o'), Comment(id='k2nyu9c'), Comment(id='k2ovmdh'), Comment(id='k2nwhiw'), Comment(id='k2nap48'), Comment(id='k2n8ytt'), Comment(id='k2p0sdc'), Comment(id='k2p6wr4'), Comment(id='k2p78mx'), Comment(id='k2q24x8')]"
16v8kwk,Manu_Orobix,,2023-09-29 11:04:17+00:00,False,,False,False,True,False,/r/datascience/comments/16v8kwk/quadra_is_out_opensource_library_to_train_and/,QUADRA is out!! - Opensource library to train and deploy DL models,"**QUADRA is out!! 🎉🎉🎉** 

QUADRA is an **opensource library to train and deploy DL models** in a very simple and flexible way and to compare, monitor, and share experiments quickly!

🌐 Website: [https://orobix.github.io/quadra/](https://orobix.github.io/quadra/) 📁 GitHub: [https://github.com/orobix/quadra](https://github.com/orobix/quadra) 

QUADRA development started to answer the necessity to **perform machine learning experiments for multiple customers and projects**, without the need of a large copy-pasted codebase over multiple repository.

**Are you a data scientist or an AI researcher?** 

With QUADRA you can: → simplify your deep learning experimenting process; → train and deploy deep learning models in a simple and flexible way, using YAML configuration files and open-source tools such as Hydra, Lightning framework, and Pytorch; → compose your experiment configurations from single command line interface, so you can conduct multiple experiments with different settings and hyperparameters; → compare, monitor, and share your experiments quickly!

\---  

❌ Are you interested in joining the project community? Get in touch! ❌

Feel free to use QUADRA for your Artificial Intelligence projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️

&#x200B;

https://preview.redd.it/kxvdi76ff6rb1.png?width=8012&format=png&auto=webp&s=e451177e0f7f660be46cc8a947e88ba0071527db",datascience,https://www.reddit.com/r/datascience/comments/16v8kwk/quadra_is_out_opensource_library_to_train_and/,0,0,0.4,[]
16v81yf,Jerry__10,,2023-09-29 10:35:17+00:00,False,,False,False,True,False,/r/datascience/comments/16v81yf/issue_reading_csv_in_pandas_datatype_all_objects/,"Issue reading csv in pandas, Datatype all objects","
Hi, I'm facing an issue reading a file in databricks using pandas.
I'm reading the csv file, Only the encoding='IS0-8859-1' is working for the Data. And all columns are being read as either object / int32 datatype instead of Mostly String/Integers. I tried the following to change that to string but none is working:
- astype(str)
- applied lambda func to each element in column
- pd.Series (df ['column '],atype=str)
-applymap
- apply (str)

I checked the column data and it is one datatype only, It does not have multiple headers/footers, A few nulls out of 4000 rows

- I tried reading with spark and then converting the dataframe to pandas, but same 
- Before applying all the above, I removed null rows and some special characters  also from the column. But still not working

Let me know if someone can help?",datascience,https://www.reddit.com/r/datascience/comments/16v81yf/issue_reading_csv_in_pandas_datatype_all_objects/,2,0,0.5,"[Comment(id='k2udllu'), Comment(id='k2uc6kt')]"
16uhmmt,vincentfer66,,2023-09-28 14:32:17+00:00,False,,False,False,True,False,/r/datascience/comments/16uhmmt/in_which_countries_do_junior_data_scientists_find/,In which countries do junior Data Scientists find the most promising opportunities?,"I've recently completed my Data Science studies in France, and I'm eager to venture out and work internationally.

My desire to work abroad is not purely based on career growth. It's also about plunging into new cultures, seeing life through a different lens, and enriching my own understanding of the world.

Most articles about the best countries to be data scientist only focus on salaries. However, I believe this approach misses the mark for several reasons:

1. **Quality of Life:** It's not just about how much you earn, but how fulfilling and comfortable your daily life is.
2. **Engaging Job Missions:** Beyond the financial aspects, I'm deeply interested in roles that offer captivating missions and innovative/meaningful projects.
3. **Supportive Environments for Juniors**
4. **Cost of Living:** A high salary in one country might not stretch as far when considering the local prices and living costs.

I'd greatly appreciate any insights or suggestions of country/city you might have from your experience. Thanks in advance!

&#x200B;

**PS:** I was in an alternance program. I studied in Toulouse and worked in Paris during the same year. ",datascience,https://www.reddit.com/r/datascience/comments/16uhmmt/in_which_countries_do_junior_data_scientists_find/,58,42,0.79,"[Comment(id='k2l3n1s'), Comment(id='k2n8sol'), Comment(id='k2ljm1h'), Comment(id='k2lwdul'), Comment(id='k2n5p2p'), Comment(id='k2n7k2w'), Comment(id='k2n2q2r'), Comment(id='k2n5tos'), Comment(id='k2rn2cm'), Comment(id='k2ow61p'), Comment(id='k2p3xcz'), Comment(id='k2lqigp'), Comment(id='k2mixhu'), Comment(id='k2lem4j'), Comment(id='k2l42yj'), Comment(id='k2lyxj1'), Comment(id='k2mp8eo'), Comment(id='k2mo3p5'), Comment(id='k2l1p7b'), Comment(id='k2lzh15'), Comment(id='k2mxob9'), Comment(id='k2ngy1v'), Comment(id='k2pzsbi'), Comment(id='k2pcxn5'), Comment(id='k2qmv05'), Comment(id='k2l94ge'), Comment(id='k2nnh16'), Comment(id='k2m6s7t'), Comment(id='k2m2wr2'), Comment(id='k2mw9ud'), Comment(id='k2wl577'), Comment(id='k2ph1a5'), Comment(id='k2pgl3p'), Comment(id='k2m0rdl'), Comment(id='k2m85vr'), Comment(id='k2n1luk'), Comment(id='k2lsa1p'), Comment(id='k2m6hsm'), Comment(id='k2lp4rf'), Comment(id='k2og83z'), Comment(id='k2pfqih'), Comment(id='k2u7z2f'), Comment(id='k2lbk0w'), Comment(id='k2mcp7c'), Comment(id='k2n3q55'), Comment(id='k2ziv8q'), Comment(id='k2spf9l'), Comment(id='k2m8xuk'), Comment(id='k2m7lnh'), Comment(id='k2okyhn'), Comment(id='k2lzm05'), Comment(id='k2pflrb'), Comment(id='k2mam6f'), Comment(id='k2n49ba'), Comment(id='k2ma3ip'), Comment(id='k2ondky'), Comment(id='k2mkfcf'), Comment(id='k2ov0a0'), Comment(id='k2msvm5'), Comment(id='k2ncqdu')]"
16uxg0e,Xman0142,,2023-09-29 00:55:29+00:00,False,,False,False,False,False,/r/datascience/comments/16uxg0e/the_hype_for_llms_is_reaching_a_fever_pitch/,The Hype for LLMs is reaching a fever pitch!,"IEEE posts this article on LLMs and it seems like they are going to take over, is it possible?",datascience,https://insight.ieeeusa.org/articles/large-language-models-the-transformative-force-shaping-the-21st-century/,2,4,1.0,"[Comment(id='k2pg2e5'), Comment(id='k2qbi71')]"
16uo2qt,spectrotact,,2023-09-28 18:49:11+00:00,False,,False,False,True,False,/r/datascience/comments/16uo2qt/how_do_we_know_that_the_sql_query_will_return_the/,How do we know that the SQL query will return the correct solution?,"SQL and I are just ""getting to know each other"" with the help of some courses and a textbook. Please help me with the theoretical and naive question of how does one know that a query returns the correct and presumably the one and only correct solution? This is clearly verifiable in the case of practice problems and although I don't get it right the first time, this is exactly what makes me think that in the real world I cannot be sure of the correctness of a query.

Perhaps my question can be translated as how to validate a SQL query?

Thanks if you share your experiences.",datascience,https://www.reddit.com/r/datascience/comments/16uo2qt/how_do_we_know_that_the_sql_query_will_return_the/,12,12,0.83,"[Comment(id='k2mckxx'), Comment(id='k2me9sf'), Comment(id='k2mg518'), Comment(id='k2ngk6m'), Comment(id='k2nksrr'), Comment(id='k2nujsz'), Comment(id='k2mh8na'), Comment(id='k2nzf5j'), Comment(id='k2o8e8q'), Comment(id='k2obzzt'), Comment(id='k2rdsse'), Comment(id='k38dgs5')]"
16v5kss,naresh257501,,2023-09-29 08:03:12+00:00,False,,False,False,False,False,/r/datascience/comments/16v5kss/1850_data_science_machine_learning_deep_learning/,"1850 Data Science, Machine Learning, Deep Learning Objective Type Questions and Answers with Explanations split in 37 Online Exams",,datascience,https://mytechbasket.com/article_desc.php?art_id=242,0,1,0.67,[]
16v3z5d,PinstripePride97,,2023-09-29 06:24:49+00:00,False,,False,False,True,False,/r/datascience/comments/16v3z5d/ideal_timing_of_dataset_split/,Ideal timing of dataset split,I was wondering if applying preprocessing to a whole dataset and then doing the train/test or train/val/test split could lead to data leakage. What would be the proper procedure? Splitting then doing EDA/preprocessing or doing it the other way around?,datascience,https://www.reddit.com/r/datascience/comments/16v3z5d/ideal_timing_of_dataset_split/,0,1,1.0,[]
16v15we,LegitimateAd4716,,2023-09-29 03:49:39+00:00,False,,False,False,False,False,/r/datascience/comments/16v15we/used_cars_price_prediction/,Used cars price prediction,"Hey guys I was working on my capstone 
Which is a used cars price prediction model.

So this project includes antique as well as non antique cars
So i wanted to cluster into two groups and predict the price accordingly

What are your inputs guys?? Any suggestions??",datascience,https://i.redd.it/c33kydry94rb1.jpg,11,0,0.4,"[Comment(id='k2om3ut'), Comment(id='k2r66t7'), Comment(id='k2oopsk'), Comment(id='k2p2txh'), Comment(id='k2qbkdk'), Comment(id='k2r90wu'), Comment(id='k2r9aqt'), Comment(id='k2sasr6'), Comment(id='k2t4s3c'), Comment(id='k2tvjvg'), Comment(id='k2tz8yj')]"
16uv9u4,ProfessorChaos224,,2023-09-28 23:23:56+00:00,False,,False,False,True,False,/r/datascience/comments/16uv9u4/need_help_answering_a_model_eval_question/,Need Help Answering a Model Eval Question,"There’s an ongoing discussion at my work I don’t totally understand. We have two different models trying to predict the same metric for two different categories of customer. Lets say the first category is new clients and the second is returning clients. For both populations we are trying to predict 1 or 0 for whether or not the client is likely to transact with us. These were built as two separate models because we have vastly different quantities of data on returning vs new customers.

Based on the likelihood of a client transacting with us we prioritize which clients to call first, calling the most likely to transact first. There is a concern that because these populations have different class imbalances we cannot stack rank their scores for call priority and instead need to make some calibration to account for differences in the classes of  the populations. I don’t totally get it as the models are predicting the same metric and as long as both models are equally accurate on a test dataset and in the real world, why would the prior class imbalance be relevant?",datascience,https://www.reddit.com/r/datascience/comments/16uv9u4/need_help_answering_a_model_eval_question/,0,0,0.5,[]
16twcad,crossmirage,,2023-09-27 21:16:44+00:00,False,,False,False,True,False,/r/datascience/comments/16twcad/how_can_an_llm_play_chess_well/,How can an LLM play chess well?,"Last week, I learned about https://parrotchess.com from a LinkedIn post. I played it, and drew a number of games (I'm a chess master who's played all their life, although I'm weaker now). Being a skeptic, I replicated the code from GitHub on my machine, and the result is the same (I was sure there was some sort of custom rule-checking logic, at the very least, but no).

I can't wrap my head around how it's working. Previous videos I've seen of LLMs playing chess are funny at some point, where the ChatGPT teleports and revives pieces at will. The biggest ""issues"" I've run into with ParrotChess is that it doesn't recognize things like three-fold repetition and will do it ad infinitum. Is it really possibly for an LLM to reason about chess in this way, or is there something special built in?",datascience,https://www.reddit.com/r/datascience/comments/16twcad/how_can_an_llm_play_chess_well/,106,86,0.9,"[Comment(id='k2hsvnj'), Comment(id='k2i3lze'), Comment(id='k2ie2tj'), Comment(id='k2jcaed'), Comment(id='k2ig3a6'), Comment(id='k2iy6zb'), Comment(id='k2hwc0z'), Comment(id='k2k89zs'), Comment(id='k2n5q0c'), Comment(id='k2jac9c'), Comment(id='k2hu1hg'), Comment(id='k2i93lv'), Comment(id='k2irkrl'), Comment(id='k2io55x'), Comment(id='k2ho057'), Comment(id='k2hp4l3'), Comment(id='k2hri8w'), Comment(id='k2ikjev'), Comment(id='k2jghvz'), Comment(id='k2jlrbz'), Comment(id='k2jrrzf'), Comment(id='k2kc2us'), Comment(id='k2ki3o0'), Comment(id='k32c9v6'), Comment(id='k2i5s52'), Comment(id='k2jhka1'), Comment(id='k2hxjnr'), Comment(id='k2ienbt'), Comment(id='k2jtkn8'), Comment(id='k2jtauk'), Comment(id='k2i649l'), Comment(id='k2iisjv'), Comment(id='k2jilet'), Comment(id='k2ija6l'), Comment(id='k2j756i'), Comment(id='k2jw7a7'), Comment(id='k2jmcsg'), Comment(id='k2i5way'), Comment(id='k2neesh'), Comment(id='k2ie2j2'), Comment(id='k2iansb'), Comment(id='k2iv30t'), Comment(id='k2isohj'), Comment(id='k2iolsl'), Comment(id='k2ho3vx'), Comment(id='k2jhysz'), Comment(id='k2kmk72'), Comment(id='k2i9di6'), Comment(id='k2is9mp'), Comment(id='k2i0bf6'), Comment(id='k2iptms'), Comment(id='k2js262'), Comment(id='k2jbxg3'), Comment(id='k2jrahs'), Comment(id='k2jzi6o'), Comment(id='k2khfju'), Comment(id='k2i9h32'), Comment(id='k2rr6ui'), Comment(id='k2ihox9'), Comment(id='k2iaxvh'), Comment(id='k2jjx9j'), Comment(id='k2iz217'), Comment(id='k2isz6a'), Comment(id='k2ifsdn'), Comment(id='k2igo4u'), Comment(id='k2jhqt5'), Comment(id='k2jtrgl'), Comment(id='k2jieuz'), Comment(id='k2itewc'), Comment(id='k2i16u9'), Comment(id='k2iqygb'), Comment(id='k2irt6f'), Comment(id='k2kv8cp'), Comment(id='k2i9uf8'), Comment(id='k2iy9on'), Comment(id='k2il6io'), Comment(id='k2j1wyh'), Comment(id='k2ihhwl'), Comment(id='k2l2br6'), Comment(id='k2jpbet'), Comment(id='k2jir9f'), Comment(id='k2j0jxv'), Comment(id='k2iaf4k'), Comment(id='k2iyvvg'), Comment(id='k2j2j07'), Comment(id='k2j0a91'), Comment(id='k2lp4ug'), Comment(id='k2kvtqj'), Comment(id='k2jiz8q'), Comment(id='k2jbd4i'), Comment(id='k2iatw2'), Comment(id='k2j79oy'), Comment(id='k2iz9qt'), Comment(id='k2jr957'), Comment(id='k2j7wvo'), Comment(id='k2j1uyn'), Comment(id='k2jekii'), Comment(id='k2l9tn6'), Comment(id='k2k1k57'), Comment(id='k2jhx04'), Comment(id='k2jevko'), Comment(id='k2ljt3k'), Comment(id='k2jv5t0'), Comment(id='k2jg8cu'), Comment(id='k2lnmew'), Comment(id='k2ku89w'), Comment(id='k2jhbr0')]"
16uq3uz,newbie_to_python,,2023-09-28 20:08:16+00:00,False,,False,False,True,False,/r/datascience/comments/16uq3uz/skewness_in_target_column/,Skewness in target column,"I have recently started learning data science and for last couple of days i have been working on dataset where training dataset's target column is right skewed, and test dataset doesn't have target column. I have tried to do do log transformation of the column but it's giving worst result compare to if I don't transform the column at all.

I have tried to google but can't find anything that will help me.

Can someone please help me what should i do should i do some other transformation or just leave it be.

Thank you.",datascience,https://www.reddit.com/r/datascience/comments/16uq3uz/skewness_in_target_column/,6,1,1.0,"[Comment(id='k2ml0cl'), Comment(id='k2pnkby'), Comment(id='k2mmiww'), Comment(id='k2mn8bw'), Comment(id='k2mo7et'), Comment(id='k2nfflp')]"
16tujyf,ex0ticOne,,2023-09-27 20:07:45+00:00,False,,False,False,True,False,/r/datascience/comments/16tujyf/heated_debate_with_leadership_because_of_excel/,Heated debate with leadership because of Excel,"I work for a small company that deals with claims process for major insurance companies. Medical bills, car repair authorization, you got it.

I was hired to improve the data analysis area, to deliver insights for key people on the organization. SLAs control, trend lines of the customer demand to better allocate our people on days/shifts, etc.,

They gave me a blank check to do whatever I needed to. 

Seemed like a dream becaming true. No pre-requisites, full control of my work and a great opportunity to expand my portfolio.

And honestly, I delivered a great work. 

A whole ecosystem using SQL and R on a cloud server. SQL to consolidate the data (and importing legacy data from other systems), ETL scripts running on a regular basis to do database tasks, Shiny dashboards with credentials for leaders and other people, webapps with forms to control data input, custom APIs to collect data from a Help Desk solution and supply ML models to serve another endpoint for predictions, etc.

But I'm facing a new and frustrating problem: people on leadership positions keeps using Excel. I saw other bosses telling their people to put data on spreadsheets, causing wrong and outdated reports for the part of the company that uses my tools properly.

And they keep asking people to create spreadsheets, when they can even export data on this format from the dashboards.

Yesterday I got on a heated debate with my boss about this. 

I need some advise. It's a nice company overall, on a industry that I know a lot (insurance is part of my academic formation) and I don't know how to handle this without putting my job at risk.

**TL;DR:** People refusing to abandon Excel and keeps creating spreadsheets and reports disconnected from the data ecosystem that I created, causing all sorts of problems. What I need to do to solve this?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16tujyf/heated_debate_with_leadership_because_of_excel/,52,78,0.9,"[Comment(id='k2hcpp9'), Comment(id='k2i76do'), Comment(id='k2iei91'), Comment(id='k2j3ek3'), Comment(id='k2hru9g'), Comment(id='k2hkblb'), Comment(id='k2jeu3j'), Comment(id='k2i04io'), Comment(id='k2ik5ob'), Comment(id='k2j50m9'), Comment(id='k2jcx41'), Comment(id='k2k7h6t'), Comment(id='k2j3bxy'), Comment(id='k2kxfb5'), Comment(id='k2kxsdf'), Comment(id='k2jjefq'), Comment(id='k2j70tl'), Comment(id='k2kfsbz'), Comment(id='k2kkvq8'), Comment(id='k3st6ae'), Comment(id='k2hzga3'), Comment(id='k2jbxf1'), Comment(id='k2k3f4j'), Comment(id='k2jvqye'), Comment(id='k2jru4m'), Comment(id='k2k070n'), Comment(id='k2k48q6'), Comment(id='k2kkb92'), Comment(id='k2kyfve'), Comment(id='k2l2ws3'), Comment(id='k2lobl8'), Comment(id='k2m71j4'), Comment(id='k2mg0q7'), Comment(id='k2mzmzl'), Comment(id='k2n39zx'), Comment(id='k2xz7xv'), Comment(id='k2jet42'), Comment(id='k2iprjc'), Comment(id='k2j4lq2'), Comment(id='k2ik7s2'), Comment(id='k2kd2q3'), Comment(id='k2i3jlc'), Comment(id='k2kbq4y'), Comment(id='k2kwqmp'), Comment(id='k2kcv1h'), Comment(id='k2kl0dp'), Comment(id='k2lfmc0'), Comment(id='k2lgc74'), Comment(id='k2m9uf3'), Comment(id='k2lghuh'), Comment(id='k2iuwke'), Comment(id='k2kjlo5')]"
16uiavf,TheParanoidPyro,,2023-09-28 14:59:36+00:00,False,,1695914035.0,False,True,False,/r/datascience/comments/16uiavf/is_our_role_to_give_the_data_that_the_stakeholder/,Is our role to give the data that the stakeholder asked for or give them a trimmed version that is closer to correct?,"I got into it with my boss today about this.

We are working with calls, call transcripts and sales. I had been working on attributing certain phrases in the transcripts to actual sales. Given all of our incoming calls to our sales department to numbers specifically for the customer to potentially purchase something, I then decided as my first idea to do it simply would be to match the phonenumbers to the customer information attached to a salesdocument. However, I don't want to match a sales call to a sale made months later, so I limit the date range to the first arbitrary timeframe, I chose 10 days.

Call Date <= Sales Document Date <= Call Date +  10 days.

while I was working on this, my boss had a separate person ask to match calls made to specific numbers associated with promotions. He just set a date to start looking at: 1-1-2023, and just matched the date.

These are the same goals, and I was already working on it in a larger scale so I mentioned how I was doing it. Thus ensued an argument about how much data to give the stakeholder. He said it wasn't our job to take away data, that we had to give them everything to what they asked and present them the list of considerations.

I argued that wasn't correct, that it isn't our job to give everything. The reason we have jobs is because we took the time to be data literate, and that is what they are paying us for. They don't necessarily know the correct questions to ask with all the nuances. I was saying it was our responsibility to siphon the shit out of the request to give the most accurate information. Sure my first caveat of 10 days might not have been the correct choice, further investigation and discussion may reveal a better way, but giving them everything was irresponsible.

If you called the promo number for january, but didn't end up buying anything, and then three months later you called the number on the next promotion you received for april and then purchased something. You wouldn't want to attach the january phone call to the april purchase because that promotion wasn't the one associated with the sale.

I thought this was a simple endeavor, but the argument wasn't going well because I am not the most persuasive, and more plant my feet because damnit I am correct. That is a fault and it could bite me in the ass later.

any thoughts would be appreciated.

TLDR; Boss says give them everything and tell them about potential inaccuracies, I say account for those inaccuracies and explain them and why I removed them if they ask, otherwise just tell them I accounted for date ranges to not match calls to sales that were too far in the future and could be attributed to later calls.

&#x200B;

EDIT-

Boss got back to me on teams.   


&#x200B;

> Looping in Eric to our conversation earlier in standup.  You have excellent points and I expressed those points to him, he was like good point.  I hope you know I completely agree with you, my point was only to give the end user the entire dataset and explain perceived flaws to the end user.   

I still would like help coming up with better words and strategies to deal with these kinds of arguments in the future",datascience,https://www.reddit.com/r/datascience/comments/16uiavf/is_our_role_to_give_the_data_that_the_stakeholder/,3,2,0.75,"[Comment(id='k2l7t9i'), Comment(id='k2l4s55'), Comment(id='k2l998y')]"
16unevw,mili_19,,2023-09-28 18:23:13+00:00,False,,False,False,True,False,/r/datascience/comments/16unevw/correct_way_of_studying_the_learnings_of_a_model/,Correct way of studying the learnings of a model on image classification?,"I am working on a disease detection project, wherein  I am supposed to detect injuries in distinct body parts, how do I ensure that my model is learning correctly? I have tried verifying with activation maps but cannot interpret them.  I assume that activation maps should accurately identify the region of infection, is this assumption correct?",datascience,https://www.reddit.com/r/datascience/comments/16unevw/correct_way_of_studying_the_learnings_of_a_model/,0,1,1.0,[]
16ucjce,REMARKABLE-RPL,,2023-09-28 10:41:16+00:00,False,,False,False,True,False,/r/datascience/comments/16ucjce/job/,Job,"So i have been a graduate in data science for 1 year now. I got hired as a data scientist while i was still persuing my degree, however im looking for a change of scenery knowing that most of my work is on the analytics part. 
Pes: i love doing predictive models but its not required here
Is a business analyst a good option? Or should i search for a pure data science position?
Will it effect my career on the longterm or will i b able to go for pure data science position later on?
Any advice is really appreciated",datascience,https://www.reddit.com/r/datascience/comments/16ucjce/job/,5,3,0.72,"[Comment(id='k2kk3ah'), Comment(id='k2kivdm'), Comment(id='k2kyaci'), Comment(id='k2m56ie')]"
16udl5a,Distinct_Slide4302,,2023-09-28 11:35:51+00:00,False,,False,False,True,False,/r/datascience/comments/16udl5a/advice_data_science_certification/,(Advice) Data Science certification,"Hello everyone!

I just graduated this summer with a degree in electrical and electronics engineering. After my graduation I started working on other skills including project management and data science. I am currently pursuing data science professional certificate by IBM. Although it sounds good, however many reviews by industry specialists I've seen, who have been over this course do say that it's just going to give you the basic skills and the basic understanding. My own plan is to complete this and then get my hands dirty with quality projects. 
Im also in a dilemma as i want to change my field but i feel like im too late because im currently 25 and unemployed.

I need advice on what resources I can use to polish my skills, any other advice would work too considering my degree. Thankyou!",datascience,https://www.reddit.com/r/datascience/comments/16udl5a/advice_data_science_certification/,7,3,0.71,"[Comment(id='k2kyp8x'), Comment(id='k2kvh7n'), Comment(id='k2l5vkq'), Comment(id='k2kv6cc'), Comment(id='k2mxmdn'), Comment(id='k2mx6sz'), Comment(id='k2mwzso')]"
16um2t9,megawalrus23,,2023-09-28 17:28:38+00:00,False,,False,False,True,False,/r/datascience/comments/16um2t9/significance_testing_for_market_campaignsmarket/,Significance Testing for Market Campaigns/Market Study?," 

Hello,

I'm trying to design a study to assess the effectiveness of a marketing campaign and could use some guidance.

Background: We identified the seasonal patterns for the quantity purchased of a given product for every product, for every customer. We are performing a market study where we identify like-markets (customer A orders some product more on average during the same month customer B orders that same product more on average) and we're going to conduct a marketing campaign where one customer is the control (no campaign) and the other is the experimental (campaign).

For every product, we should have plenty of customers that order that product more in a given month on average to act as our control and experimental group.

My plan to analyze this data post-campaign(s) is to take each product control/experimental group and perform an independent sample t-test assuming unequal variances to check for significance.

The issue is, I'm going to have hundreds of thousands of products (i.e. hundreds of thousands of tests). Obviously, some percentage of the tests will be significant and another percentage of them will not be; but I'm not sure how to interpret the results of the study as a whole given this fact.

I've read into Bonferroni Corrections a bit and that seems like a possible way to go when analyzing the results of all the individual t tests. But I would like to get some advice/feedback from others.

Thanks in advance for the help!",datascience,https://www.reddit.com/r/datascience/comments/16um2t9/significance_testing_for_market_campaignsmarket/,0,1,1.0,[]
16ukd8b,acdbddh,,2023-09-28 16:20:15+00:00,False,,False,False,True,False,/r/datascience/comments/16ukd8b/xtwitter_misinformation_detection_browser_plugin/,X/Twitter misinformation detection browser plugin,"It seems that after recent changes made by Elon Musk to X/Twitter (""free speech"" rules plus API limits) there might be market now for an external (web browser side maybe) tool for X/Twitter to detect and highlight troll activity. I've seen there are some papers available on this topic but I haven't found any customer ready to use tool. What do you think? Or maybe you know such a tool? Maybe we can build it here?",datascience,https://www.reddit.com/r/datascience/comments/16ukd8b/xtwitter_misinformation_detection_browser_plugin/,1,1,0.67,[Comment(id='k2lhx85')]
16t9p4v,BiteFancy9628,,2023-09-27 03:38:14+00:00,False,,False,False,True,False,/r/datascience/comments/16t9p4v/llms_hype_has_killed_data_science/,LLMs hype has killed data science,"That's it.

At my work in a huge company almost all traditional data science and ml work including even nlp has been completely eclipsed by management's insane need to have their own shitty, custom chatbot will llms for their one specific use case with 10 SharePoint docs. There are hundreds of teams doing the same thing including ones with no skills. Complete and useless insanity and waste of money due to FOMO.

How is ""AI"" going where you work?",datascience,https://www.reddit.com/r/datascience/comments/16t9p4v/llms_hype_has_killed_data_science/,306,852,0.95,"[Comment(id='k2e4dxn'), Comment(id='k2e6lv4'), Comment(id='k2e7mxa'), Comment(id='k2dyl09'), Comment(id='k2e0syx'), Comment(id='k2espym'), Comment(id='k2e1s1x'), Comment(id='k2e0d0p'), Comment(id='k2ed88r'), Comment(id='k2ei0e2'), Comment(id='k2f4asr'), Comment(id='k2dwh88'), Comment(id='k2ejdeg'), Comment(id='k2etsf9'), Comment(id='k2e2mea'), Comment(id='k2efp5f'), Comment(id='k2ewj5d'), Comment(id='k2f2x0v'), Comment(id='k2gmq0r'), Comment(id='k2h7i6q'), Comment(id='k2e3bfp'), Comment(id='k2f51ow'), Comment(id='k2feybp'), Comment(id='k2g04mb'), Comment(id='k2gltui'), Comment(id='k2ed7ez'), Comment(id='k2f5k7f'), Comment(id='k2h08p7'), Comment(id='k2i7bbs'), Comment(id='k2ll1pg'), Comment(id='k2ew2tp'), Comment(id='k2efz8s'), Comment(id='k2f7m3n'), Comment(id='k2f9d3l'), Comment(id='k2fjmpe'), Comment(id='k2fnvd6'), Comment(id='k2g3myr'), Comment(id='k2i0ih5'), Comment(id='k2itkdq'), Comment(id='k2izck1'), Comment(id='k2j3iy8'), Comment(id='k2j5h2c'), Comment(id='k2klmne'), Comment(id='k2l1ftn'), Comment(id='k2mxg0q'), Comment(id='k3c125x'), Comment(id='k2e18al'), Comment(id='k2ey9ui'), Comment(id='k2dypsm'), Comment(id='k2f4fme'), Comment(id='k2e3hiy'), Comment(id='k2g0k6j'), Comment(id='k2h04je'), Comment(id='k2ios6z'), Comment(id='k2jrb4x'), Comment(id='k2ekzaj'), Comment(id='k2e1hly'), Comment(id='k2gh5q5'), Comment(id='k2h27q5'), Comment(id='k2dvcph'), Comment(id='k2dx64p'), Comment(id='k2hxi8h'), Comment(id='k2oat2m'), Comment(id='k2pwcmt'), Comment(id='k3euqqa'), Comment(id='k7g0z5v'), Comment(id='k2h48kr'), Comment(id='k2f4hd0'), Comment(id='k2f6qpl'), Comment(id='k2j02kf'), Comment(id='k4zm360'), Comment(id='k2eft8y'), Comment(id='k3q4h6d'), Comment(id='k2ei6sw'), Comment(id='k2fdqfm'), Comment(id='k2hsjlj'), Comment(id='k2j09vv'), Comment(id='k2wgkfq'), Comment(id='k2erord'), Comment(id='k2hx56a'), Comment(id='k2i6uz9'), Comment(id='k2fzts3'), Comment(id='k2eqyky'), Comment(id='k2g32xm'), Comment(id='k2ew9bc'), Comment(id='k2e6gm9'), Comment(id='k2enih0'), Comment(id='k2ewxcg'), Comment(id='k2eiekp'), Comment(id='k2imeds'), Comment(id='k2n56g2'), Comment(id='k2ehf6e'), Comment(id='k2eemxw'), Comment(id='k2ed7or'), Comment(id='k2eyiil'), Comment(id='k2ek96s'), Comment(id='k2e74fr'), Comment(id='k2efn7g'), Comment(id='k2h20bt'), Comment(id='k2il4j8'), Comment(id='k2eay2t'), Comment(id='k2fxp98'), Comment(id='k2fdit9'), Comment(id='k2f4m7z'), Comment(id='k2e1dnc'), Comment(id='k2e05op'), Comment(id='k2ed1a5'), Comment(id='k2fenfz'), Comment(id='k2ezee2'), Comment(id='k2k6hhg'), Comment(id='k2ip8ge'), Comment(id='k3db7w1'), Comment(id='k2fesbs'), Comment(id='k2it7oh'), Comment(id='k2nx3yn'), Comment(id='k2ipyoa'), Comment(id='k2k78fu'), Comment(id='k2n1son'), Comment(id='k2jeffw'), Comment(id='k2i5e8p'), Comment(id='k2nycij'), Comment(id='k2e7i89'), Comment(id='k2jdqy3'), Comment(id='k2e2t3w'), Comment(id='k2e7k01'), Comment(id='k2e3n3e'), Comment(id='k2f72ao'), Comment(id='k2i8rdy'), Comment(id='k2i8jxo'), Comment(id='k2dyb5s'), Comment(id='k2e2goj'), Comment(id='k2irfu1'), Comment(id='k2efcvv'), Comment(id='k2i6dmi'), Comment(id='k2j0jbi'), Comment(id='k2ft3tj'), Comment(id='k2f792h'), Comment(id='k2g65oz'), Comment(id='k2gd7ed'), Comment(id='k2egp2y'), Comment(id='k2er0qn'), Comment(id='k2gwg6c'), Comment(id='k2g97ef'), Comment(id='k2xwm8g'), Comment(id='k2xdz14'), Comment(id='k5bj4ov'), Comment(id='k2eu7wu'), Comment(id='k2gchff'), Comment(id='k2f4fpf'), Comment(id='k2e72kn'), Comment(id='k2ev6t4'), Comment(id='k2ekpxu'), Comment(id='k2f8zgg'), Comment(id='k2gj5vj'), Comment(id='k2fvwkp'), Comment(id='k2febwi'), Comment(id='k2hqal4'), Comment(id='k2eubvt'), Comment(id='k2g66f4'), Comment(id='k2eirtm'), Comment(id='k2ejbna'), Comment(id='k2feg4k'), Comment(id='k2ilwr1'), Comment(id='k2h3501'), Comment(id='k2inibv'), Comment(id='k2g3ocg'), Comment(id='k2io467'), Comment(id='k2f5bhs'), Comment(id='k2ei0ex'), Comment(id='k2et2sy'), Comment(id='k2etfoz'), Comment(id='k2elpqh'), Comment(id='k2esxkg'), Comment(id='k2kymti'), Comment(id='k2iqdhm'), Comment(id='k2l5si5'), Comment(id='k2sw3ht'), Comment(id='k2k7yo6'), Comment(id='k2e86vj'), Comment(id='k2ftglr'), Comment(id='k2j08sv'), Comment(id='k2izzgs'), Comment(id='k2h5v0s'), Comment(id='k2e9vte'), Comment(id='k2etd01'), Comment(id='k2ifeq9'), Comment(id='k2h6kix'), Comment(id='k2f9ejf'), Comment(id='k2fqyth'), Comment(id='k2hz4ne'), Comment(id='k2exvbj'), Comment(id='k2evwmf'), Comment(id='k2gckcq'), Comment(id='k2haom4'), Comment(id='k2hhaep'), Comment(id='k2hsq3w'), Comment(id='k2j4n1a'), Comment(id='k7mjlgh'), Comment(id='k2icwoz'), Comment(id='k2fh51k'), Comment(id='k2gm2vh'), Comment(id='k2elc7v'), Comment(id='k2e883r'), Comment(id='k2ic83z'), Comment(id='k2fines'), Comment(id='k2favnp'), Comment(id='k2fhff4'), Comment(id='k2n32do'), Comment(id='k2kee0e'), Comment(id='k2fwm1h'), Comment(id='k2f0p9g'), Comment(id='k2fq5co'), Comment(id='k2f1kxw'), Comment(id='k2ektxu'), Comment(id='k2iln36'), Comment(id='k2fx189'), Comment(id='k2h6dha'), Comment(id='k2ffot9'), Comment(id='k2ewxl4'), Comment(id='k2itmab'), Comment(id='k2l6euj'), Comment(id='k2ef3ho'), Comment(id='k2iqxs6'), Comment(id='k2ny2pp'), Comment(id='k2fe8uv'), Comment(id='k2f0phv'), Comment(id='k2fj7sg'), Comment(id='k2fdrhj'), Comment(id='k2fkm8h'), Comment(id='k2fqhgf'), Comment(id='k2ft3zk'), Comment(id='k2i28zm'), Comment(id='k2ewgjq'), Comment(id='k2jhm2h'), Comment(id='k2pxmhu'), Comment(id='k2jgx41'), Comment(id='k2gotm1'), Comment(id='k2ezvkr'), Comment(id='k2gxq6f'), Comment(id='k2e8tl1'), Comment(id='k2io7iz'), Comment(id='k2fxvie'), Comment(id='k2fct76'), Comment(id='k2fya8m'), Comment(id='k2f8m11'), Comment(id='k2fqozo'), Comment(id='k2jqv66'), Comment(id='k2fxdue'), Comment(id='k2h7koq'), Comment(id='k2eyxih'), Comment(id='k2iw9g2'), Comment(id='k2l8ai1'), Comment(id='k2ff5wz'), Comment(id='k2egnbe'), Comment(id='k2om41p'), Comment(id='k2f2egc'), Comment(id='k2is8g5'), Comment(id='k2ggnhk'), Comment(id='k2f3i2w'), Comment(id='k2f1ex2'), Comment(id='k3jutr2'), Comment(id='k2h2caq'), Comment(id='k2f15t8'), Comment(id='k2fc4mg'), Comment(id='k2e9j91'), Comment(id='k2eu86v'), Comment(id='k2iu4fy'), Comment(id='k2fzb4d'), Comment(id='k2gmfaf'), Comment(id='k2h9ijt'), Comment(id='k2nzifj'), Comment(id='k2k6p9m'), Comment(id='k2ffftw'), Comment(id='k3mj8y7'), Comment(id='k2f1eg8'), Comment(id='k2gy0y9'), Comment(id='k2gt49b'), Comment(id='k2e9x1t'), Comment(id='k2g94h7'), Comment(id='k2hqbyb'), Comment(id='k2hbw7x'), Comment(id='k2o0hx9'), Comment(id='k2fpxss'), Comment(id='k2gyd3v'), Comment(id='k2kpdtn'), Comment(id='k2ibzih'), Comment(id='k2keg4s'), Comment(id='k2kdx4c'), Comment(id='k2g0htq'), Comment(id='k2iat3d'), Comment(id='k2hnf2m'), Comment(id='k2n2343'), Comment(id='k2kox57'), Comment(id='k2g6tmd'), Comment(id='k2ip25v'), Comment(id='k2izttb'), Comment(id='k2n2nbn'), Comment(id='k2htnww'), Comment(id='k2j4qru'), <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>, <MoreComments count=0, children=[]>]"
16ujm1g,Manu_Orobix,,2023-09-28 15:51:05+00:00,False,,False,False,True,False,/r/datascience/comments/16ujm1g/reinforcement_learning_in_automating_game_testing/,Reinforcement learning in automating game testing 🔥,"The role of **Reinforcement learning** in automating **game testing** is becoming increasingly crucial, making it more efficient and effective. Manual testing, while essential, is extremely **time-consuming and subject to human error.** 

Our **opensource** library [SheepRL](https://github.com/Eclectic-Sheep/sheeprl) 🐑 can be used to test whether the game dynamics is well defined: **what if a player can finish the game with just a few moves?** 🎮

This [video](https://x.com/orobix/status/1707403169523773930?s=20) shows that our agent (Kasumi, on the left) is able to win the game in the hardest modality by standing down and throwing kicks. 🥊

This can be helpful for a game developer to:

* understand where and how intervene **to achieve a more playful game**
* **predict and correct bugs early** in the game development process
* enhance the gaming experience and final **product quality**
* reduce time and resources spent on **debugging**.

The game has changed 🔥 and it is up to us to play it with (human + artificial) intelligence!

Thanks to [**u/DIAMBRA\_AIArena**](https://www.reddit.com/user/DIAMBRA_AIArena) for the video!

\---

❌ Are you interested in joining the project community? [Get in touch](https://github.com/Eclectic-Sheep/sheeprl) ❌

[SheepRL](https://github.com/Eclectic-Sheep/sheeprl) 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI

**Feel free to use it for your Artificial Intelligence projects**, and if you want to contribute, we are more than happy to accept your pull requests! ❤️

&#x200B;

https://preview.redd.it/yoy38vghp0rb1.png?width=6668&format=png&auto=webp&s=df5b3a881c81841a4f52617c68c057ffdb1ebeac",datascience,https://www.reddit.com/r/datascience/comments/16ujm1g/reinforcement_learning_in_automating_game_testing/,0,1,1.0,[]
16udszx,TimidHuman,,2023-09-28 11:46:28+00:00,False,,1695901773.0,False,True,False,/r/datascience/comments/16udszx/what_online_coursebooks_would_you_recommend_to/,What online course/books would you recommend to someone interested in getting into DS?,"As per title. I've a university degree in Information Systems but have been taking DA/ML mods, have built a couple of models myself for projects/internships which uses decision trees, random forest, logistic regression and so on.

I've basic python programming knowledge along with some OOP knowledge. Self-learned matplotlib/pandas/sklearn myself so I know the basic things but still not very comfortable in using lambda to process functions what not. Also, I'm not very well versed with data algorithms (not sure if it matters :/)

Have never really touched AI stuffs (took a module in uni which utilized tensorflow for image recognition and build a project to detect people with face masks on but that's about it)

Am interested in eventually becoming a data scientist in the future for my career, though I'm currently a data analyst more specialized in visualizing.

Looking for resources, be it on books about ML and what not so I can continue advancing my skills and eventually perhaps get a role as a data scientist. Would say that currently I'm quite rusty with my modelling skills (I still know the basic EDA/preprocessing/one-hot labelling and what not, though I would need to google for example codes and adapt to my problem at hand). Any form of other advices would be welcomed!

Currently on my list:

1. Python Data Science Handbook by Jake VanderPlas
2. “Python Machine Learning” by Sebastian Raschka and Vahid Mirjalili
3. Mastering Machine Learning Algorithms by Giuseppe Bonaccorso
4. 100 Days of Python by Angela Yu on Udemy",datascience,https://www.reddit.com/r/datascience/comments/16udszx/what_online_coursebooks_would_you_recommend_to/,3,2,1.0,"[Comment(id='k2kppsi'), Comment(id='k2ksf65'), Comment(id='k2l2h1a')]"
16ucam4,abhi9u,,2023-09-28 10:27:51+00:00,False,,False,False,False,False,/r/datascience/comments/16ucam4/an_analysis_of_deepminds_language_modeling_is/,An Analysis of DeepMind's 'Language Modeling Is Compression' Paper,,datascience,https://codeconfessions.substack.com/p/language-modeling-is-compression,0,2,1.0,[]
16u6e27,synthphreak,,2023-09-28 04:31:50+00:00,False,,1695876400.0,False,True,False,/r/datascience/comments/16u6e27/say_i_trained_an_autoencoder_why_is_that_useful/,Say I trained an autoencoder. Why is that useful? How can I use it?,"# The setup

I’m learning about autoencoders (for use in recommender systems specifically, if it matters). Whenever you read up on what autoencoder models are, the ELI5 usually goes something like this:

> Autoencoders are models which take some input, encode it into a lower dimensional form, then decode it back to reconstruct an approximation of its original form.

I understand that sentence, but I don’t understand why that is useful.

# My confusion

To me it sounds like an autoencoder is basically just an identity function, plus some error/noise. As if after training my model, I now have a tool which can do what…add distortion to an image? Why did I go to the trouble of training an entire neural network for something so trivial?

Clearly I am missing something fundamental. What are the applications exactly? How is a trained autoencoder useful, particularly for recommender systems?

# A speculative answer to my own question (confirmation/rejection appreciated)

All I can think of is this, and this is just a guess: Perhaps we train autoencoders not because we care about their output layer, but because we want their hidden layer?

On this view, it’s kinda like matrix decomposition. MD starts with some giant matrix of “observed” values, then finds two smaller matrices of “latent” values whose product approximates the original. These latent matrices encode lots of valuable info about the original matrix, but in a dense form that’s more efficient to work with. So after we have those dense matrices, we store them for downstream tasks. So MD is done solely to get our hands on those latent features.

Similarly, for NLP there are simple neural networks whose entire job is to learn static word embeddings. These embeddings can then drive downstream NLP tasks. Once our simple NN has learned them, we store them, after which we basically no longer need/use the NN.

So are autoencoders like this? That is, rather than create a model that we use over and over again because the output is useful, are they just vehicles for learning some latent representation of the input, and after learned, we can just discard the autoencoder model?

I hope this makes sense. Any thoughts appreciated.

**EDIT:** If autoencoders simply achieve functionally the same thing as MD through different means, why might someone choose one over the other? What are the practical considerations?",datascience,https://www.reddit.com/r/datascience/comments/16u6e27/say_i_trained_an_autoencoder_why_is_that_useful/,4,6,1.0,"[Comment(id='k2jdpy1'), Comment(id='k2jeo8t'), Comment(id='k2lcpvn'), Comment(id='k2laqb9')]"
16tgojm,Choweeez,,2023-09-27 10:15:59+00:00,False,,1696237913.0,False,True,False,/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/,What kind of algorithm do you use the most as a data science pro ?,"As a data science professional, what kind of tool / algorithm do you use the most today and what do you think will be used the most tomorrow ?Mainly concerned about classical ML / DL and other statistical tools to analyze data.

I  would like to work in data science. What I like is working with data,  building models and tweaking them to make the data ""speak"".

I started learning classical ML (with the book *Hands-on Machine Learning*).  But now I wonder what I should focus on: go on with classical ML, learn  DL or something else? What skills would be the more useful for a career  in data science?

I'm sorry if  this has been already asked ... I read the wiki and FAQ, and did some  search but didn't find what I was looking for.

&#x200B;

**EDIT:** thanks to everyone who replied, I was not expecting so many answers!  
I gathered the answers here: [https://www.reddit.com/r/datascience/comments/16xriok/quick\_review\_of\_most\_used\_algorithm\_answers/](https://www.reddit.com/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/)",datascience,https://www.reddit.com/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/,115,142,0.94,"[Comment(id='k2f0e0i'), Comment(id='k2f1cen'), Comment(id='k2forhb'), Comment(id='k2fnhot'), Comment(id='k2geby1'), Comment(id='k2fbiwm'), Comment(id='k2gkcf0'), Comment(id='k2feq90'), Comment(id='k2ge98y'), Comment(id='k2gsjr1'), Comment(id='k2f9rae'), Comment(id='k2fbypc'), Comment(id='k2h17ad'), Comment(id='k2facl8'), Comment(id='k2fsjwi'), Comment(id='k2fw5eb'), Comment(id='k2fzepo'), Comment(id='k2hcabu'), Comment(id='k2hpumb'), Comment(id='k2fc3p5'), Comment(id='k2fht9x'), Comment(id='k2foqto'), Comment(id='k2fxowe'), Comment(id='k2gnred'), Comment(id='k2jccyc'), Comment(id='k2jcjb2'), Comment(id='k2jlsh4'), Comment(id='k2eut3a'), Comment(id='k2f6jzo'), Comment(id='k2g8x28'), Comment(id='k2gxww8'), Comment(id='k2h41xn'), Comment(id='k2h9ha8'), Comment(id='k2h9yx3'), Comment(id='k2hajkq'), Comment(id='k2heltv'), Comment(id='k2hfqh1'), Comment(id='k2ialsz'), Comment(id='k2ibykx'), Comment(id='k2ivblx'), Comment(id='k2n0w62'), Comment(id='k2oym29'), Comment(id='k2evflr'), Comment(id='k2fps2e'), Comment(id='k2g5vhq'), Comment(id='k2fkoro'), Comment(id='k2hldum'), Comment(id='k2i8dbp'), Comment(id='k2ft3rh'), Comment(id='k2gzne3'), Comment(id='k2ff1bb'), Comment(id='k2jxz65'), Comment(id='k2k5xjx'), Comment(id='k2k6u6o'), Comment(id='k2mzzpq'), Comment(id='k2zois0'), Comment(id='k2gw1t7'), Comment(id='k2faqcj'), Comment(id='k2f2mpb'), Comment(id='k2k1p3u'), Comment(id='k2f30ry'), Comment(id='k2frr50'), Comment(id='k2hc20p'), Comment(id='k2gvxuy'), Comment(id='k2g0dzm'), Comment(id='k2mblos'), Comment(id='k2gvt1i'), Comment(id='k2fn7qz'), Comment(id='k2kgmzu'), Comment(id='k2ib3ln'), Comment(id='k2jt4va'), Comment(id='k2p3szg'), Comment(id='k2gw94y'), Comment(id='k2kril0'), Comment(id='k2fyjia'), Comment(id='k2krfjv'), Comment(id='k2f5bph'), Comment(id='k2f7efq'), Comment(id='k2fcb2e'), Comment(id='k2hu0os'), Comment(id='k2gxgv8'), Comment(id='k2i9219'), Comment(id='k2l0th3'), Comment(id='k2kitzy'), Comment(id='k2kbued'), Comment(id='k2pfswj'), Comment(id='k2gy401'), Comment(id='k2kv3ft'), Comment(id='k2g33x7'), Comment(id='k2gfjpd'), Comment(id='k2isgyp'), Comment(id='k2hsh07'), Comment(id='k2ktvu0'), Comment(id='k2merg7'), Comment(id='k2fuoqv'), Comment(id='k2fzy9h'), Comment(id='k2g9w6x'), Comment(id='k2fxhud'), Comment(id='k2kkbng'), Comment(id='k2h155s'), Comment(id='k2p3fdq'), Comment(id='k2ikjmr'), Comment(id='k2mbtfq'), Comment(id='k2oc8o1'), Comment(id='k2gwgs7'), Comment(id='k2fzg6n'), Comment(id='k2lk7mf'), Comment(id='k2iy9z5'), Comment(id='k2oh9ad'), Comment(id='k2gekdm'), Comment(id='k2g4jk0'), Comment(id='k2g53na'), Comment(id='k2izrao'), Comment(id='k2gfpmh'), Comment(id='k2j782x')]"
16tsf50,FoxWithAPumpkin,,2023-09-27 18:45:03+00:00,False,,False,False,True,False,/r/datascience/comments/16tsf50/really_shitty_coding_skills/,Really shitty coding skills,"So I am currently going through university course on data analysis and I have been assigned a labwork. Labwork consists of 5 parts and part one is to do an input data analysis, do some descriptive summary statistics, do some plots, make a few manipulations to the data where needed. So descriptive summary statistics part requires me to do a specific data quality report, more specifically it asks me to provide [count, missing_value_%, mode, mode_freq, mode_%, 2nd_mode, 2nd_mode_freq, 2nd_mode_%] for categorical features. 

So as just a default pd.describe() was not enough for it, i did the whole thing manually using .agg() and combining default aggregation functions with my custom functions. This is where I got stuck.

I spent the whole day trying to write a function that would calculate the modes for me and would work together with other functions inside .agg(). In the end I failed and just decided to do a separate mode dataframe that I later just concatenate to the output of df.agg(). 

How do I actually learn all these technical and trivial stuff? Manipulating dataframes, series, permuting them the way I want (also, the same applies to all other “small stuff” in coding - manipulating strings, lists/dicts, applying functions to dataframes and so on)? Because I feel like actual coding basics in Python is what stops me from doing any actual progress…",datascience,https://www.reddit.com/r/datascience/comments/16tsf50/really_shitty_coding_skills/,21,29,0.89,"[Comment(id='k2hed0o'), Comment(id='k2hqqk1'), Comment(id='k2hn37o'), Comment(id='k2ijqqc'), Comment(id='k2jfjrv'), Comment(id='k2ksa1a'), Comment(id='k2i5quv'), Comment(id='k2i4ow3'), Comment(id='k2ia2t2'), Comment(id='k2jrgxy'), Comment(id='k2kgwpn'), Comment(id='k2ky196'), Comment(id='k2hnany'), Comment(id='k2ik8pl'), Comment(id='k2k2vo7'), Comment(id='k2ila2p'), Comment(id='k2kga21'), Comment(id='k2irk0x'), Comment(id='k2j0o0c'), Comment(id='k2iqi4c'), Comment(id='k2lequt')]"
16uekmp,Technical-Window-634,,2023-09-28 12:22:15+00:00,False,,False,False,True,False,/r/datascience/comments/16uekmp/help_with_data_disparity/,Help with data disparity,"Hi everyone! This is my first post here. Sorry beforehand if my English isn't good, I'm not native. Also sorry if this isn't the appropriate label for the post.

I'm trying to predict financial frauds using xgboost on a big data set (4m rows after some filtering) with an old PC (Ryzen AMD 6300). The proportion is 10k fraud transaction vs 4m non fraud transaction. Is it right (and acceptable for a challenge) to do both taking a smaller sample for training, while also using smote to increase the rate of frauds? The first run of xgboost I was able to make had a very low precision score. I'm open to suggestions as well. Thanks beforehand!",datascience,https://www.reddit.com/r/datascience/comments/16uekmp/help_with_data_disparity/,5,1,1.0,"[Comment(id='k2kl1ij'), Comment(id='k2klyzy'), Comment(id='k2kn62k'), Comment(id='k2knvu9'), Comment(id='k2kq153')]"
16tahis,Excellent_Cost170,,2023-09-27 04:15:53+00:00,False,,False,False,False,False,/r/datascience/comments/16tahis/anyone_facing_this_in_your_organization/,Anyone facing this in your organization?,,datascience,https://i.redd.it/ct3p42qt4qqb1.jpg,36,361,0.97,"[Comment(id='k2e01zl'), Comment(id='k2ea0z7'), Comment(id='k2e5u65'), Comment(id='k2ehtc3'), Comment(id='k2gwre7'), Comment(id='k2f911z'), Comment(id='k2f42ah'), Comment(id='k2gawyj'), Comment(id='k2fhw8f'), Comment(id='k2gvizm'), Comment(id='k2hcb67'), Comment(id='k2k0lm0'), Comment(id='k2eqqh6'), Comment(id='k2ei2mw'), Comment(id='k2faokl'), Comment(id='k2fd0qj'), Comment(id='k2gdl1o'), Comment(id='k2h0dyi'), Comment(id='k2hrcqy'), Comment(id='k2i2elv'), Comment(id='k2kwzv1'), Comment(id='k2l26fj'), Comment(id='k2ed12l'), Comment(id='k2epk30'), Comment(id='k2f8otq'), Comment(id='k2ebwoi'), Comment(id='k2etfsd'), Comment(id='k2fiftk'), Comment(id='k2gvnv7'), Comment(id='k2kbbnn'), Comment(id='k2gx5ik'), Comment(id='k2et1wc'), Comment(id='k2eqm3a'), Comment(id='k2eeei8'), Comment(id='k2ka0ch')]"
16ue1kp,juspreet51,,2023-09-28 11:57:55+00:00,False,,False,False,True,False,/r/datascience/comments/16ue1kp/what_all_visualization_and_insights_could_be_part/,What all visualization and insights could be part of Twitter Sentiment Analysis?,"Other than the usual Word-cloud, what all EDA can I prepare on a tweeter dataset? I need to present some pointers, as on what all could be taken out in the Sentiment Analysis. All ideas are welcome",datascience,https://www.reddit.com/r/datascience/comments/16ue1kp/what_all_visualization_and_insights_could_be_part/,1,1,1.0,[Comment(id='k2l53bt')]
16ud8ql,make_people_naked,,2023-09-28 11:18:48+00:00,False,,False,False,True,False,/r/datascience/comments/16ud8ql/hello_guys_i_have_just_built_a_wine_quality/,"Hello guys I have just built a wine quality prediction tool, here is my GitHub profile..","I just switched back into my fields and looking to build next 30 days end to end ml project and one LLm models. In this community we have good programmes who have good experience in this field can you guide me what exactly company demands from data science like what they should know and all..

Please take a look at my GitHub profile and please share your feedback..
Your advices will be very useful for me


GitHub -

https://github.com/codedestructed007/Wine_Quality_prediction


Thanks a lot friends/brothers..👍",datascience,https://www.reddit.com/r/datascience/comments/16ud8ql/hello_guys_i_have_just_built_a_wine_quality/,0,1,0.6,[]
16ucj3h,Data_Nerd1979,,2023-09-28 10:40:54+00:00,False,,1695898580.0,False,True,False,/r/datascience/comments/16ucj3h/what_is_the_your_top_open_source_llms/,What is the your top Open Source LLMs?,"For me it's Llama 2.

Llama 2's training data is vast and varied, making it a significant advancement over its predecessor.",datascience,https://www.reddit.com/r/datascience/comments/16ucj3h/what_is_the_your_top_open_source_llms/,5,0,0.45,"[Comment(id='k2k6v86'), Comment(id='k2kwyfw'), Comment(id='k2lzzf2'), Comment(id='k2kxr4v'), Comment(id='k2kz4y2')]"
16u6ps0,synthphreak,,2023-09-28 04:49:46+00:00,False,,False,False,True,False,/r/datascience/comments/16u6ps0/big_rec_sys_interview_coming_up_what_topics_to/,Big rec sys interview coming up. What topics to prepare?,Applied for an engineering-heavy role. Got an interview that will focus on recommender systems. Don’t know too much about them TBH. What are the critical topics and competencies that I should be familiar with heading into the interview?,datascience,https://www.reddit.com/r/datascience/comments/16u6ps0/big_rec_sys_interview_coming_up_what_topics_to/,1,2,1.0,[Comment(id='k2kf5as')]
16u9nrv,WadeEffingWilson,,2023-09-28 07:43:47+00:00,False,,False,False,True,False,/r/datascience/comments/16u9nrv/can_power_spectral_density_be_used_to_detect/,Can power spectral density be used to detect autocorrelation and candidates for seasonal values in a time series?,"BLUF: I have very little knowledge when it comes to signal processing and analysis, so please don't beat me up too bad if I misunderstood something, even if it's fundamental.

I work a lot with time series data, almost all of it containing seasonal and trend components. Due to that, I've grown familiar with things like P/ACF plots, ADF and KPSS tests, STL and ETS decompositions, AR/MA models, and Ljung-Box (and Box-Pierce) tests. I can identify seasonal values to use for the decompositions by applying domain knowledge and outputs from ACF plots. After decomposing, I usually run the residuals through an ACF plot again to see if there are lingering autocorrelations.

I created a custom function awhile back that takes in a time series (or residuals) and uses Welch's method to estimate the power spectral densities. It's my understanding that the dominant frequencies identified in the plot are the most prevalent (by power) frequencies in the time series and can be used as seasonal parameter arguments passed to the decomposition algorithm (eg, STL, ETS).

I have to adjust the sampling rate parameter in the Welch function since it assumes the sampling is performed X number of times per second. If my time bins are hourly, I change it to 1/3600 so that it gives back appropriate frequencies.

If I understand correctly, dominant frequencies are well above the noise floor but when each dominant frequency is selected and removed from the time series, the next most dominant frequency is closer to that noise floor, bringing it closer to the top. Would I be mistaken if I used this process to test for and indicate that white noise has been achieved (ie, no serial correlations)? I would also combine it with output from an ACF plot and a Ljung-Box test, just to be sure.

Also, will this process capture incomplete, intermediate frequencies? What I mean is, for example, if I have a time series of, say 10,000 observations, which show a consistent frequency all the way across but somewhere in the middle, another different frequency appears alongside that lasts for only 3,000 observations before it disappears, will that transient frequency be detected, even though it isn't present throughout the entire time series? Does that make sense?

I just need a sanity check to make sure I'm not all the way out in left field (or even outside the stadium, in the parking lot). Please let me know if the entire thing is wrong and I'm a moron or, in the case that I've messed up but the premise is valid, let me know where I need to revisit.

Hopefully this makes sense.",datascience,https://www.reddit.com/r/datascience/comments/16u9nrv/can_power_spectral_density_be_used_to_detect/,2,0,0.5,"[Comment(id='k2ophwy'), Comment(id='k2rqs5g')]"
16u45ri,JTcyto,,2023-09-28 02:38:01+00:00,False,,False,False,True,False,/r/datascience/comments/16u45ri/how_to_properly_sample_data_size_down/,How to properly sample data size down?,"I have dataset that is computationally inefficient to run due to size/algorithm. I could choose a different model but this is a speculative project based around the model. The model works great on small to mid-size data <100,000 obs. But the dataset I have is a couple million, which I think would take multiple hours to run. I have been trying to figure out sampling strategies, but haven’t been able to clearly figure out if down-sampling is an okay approach. Any thoughts would be great!",datascience,https://www.reddit.com/r/datascience/comments/16u45ri/how_to_properly_sample_data_size_down/,3,2,1.0,"[Comment(id='k2k3d4c'), Comment(id='k2izwrm'), Comment(id='k2x5j0h')]"
16tpji2,Old_Cartographer_586,,2023-09-27 16:43:55+00:00,False,,False,False,True,False,/r/datascience/comments/16tpji2/should_i_complete_certs_while_looking_for_a_job/,Should I complete certs while looking for a job?,"So, I am one of those individuals who has been very unlucky in the job market since graduating in Sept 2022. I do not come from the most traditional background for data science (MSc in Physics), so, I am asking should I go on Coursera, Udemy, etc... and see if there are any data science/analyst certs I should consider completing to make myself stand out or if I should just keep applying.

I will say, I would prefer completing certs on Coursera as due to my situation I feel confident that I can complete the course during the courses free trial. ",datascience,https://www.reddit.com/r/datascience/comments/16tpji2/should_i_complete_certs_while_looking_for_a_job/,26,11,0.77,"[Comment(id='k2gv76h'), Comment(id='k2if6d1'), Comment(id='k2griqr'), Comment(id='k2gs2e1'), Comment(id='k2js2i8'), Comment(id='k47oft9'), Comment(id='k2kh792'), Comment(id='k2gzpe9'), Comment(id='k2hlgp9'), Comment(id='k2i14x9'), Comment(id='k2hnnal'), Comment(id='k2hok2c'), Comment(id='k2i23q1'), Comment(id='k2i24vv'), Comment(id='k47tldo'), Comment(id='k2hr7vs'), Comment(id='k2i2hg5'), Comment(id='k2ild41'), Comment(id='k47ue3k'), Comment(id='k2znc90'), Comment(id='k2ia37x'), Comment(id='k2k2utz'), Comment(id='k2j4db3'), Comment(id='k2zpbrb'), Comment(id='k49r8vk'), Comment(id='k4a1gr4')]"
16ukxy1,Excellent_Cost170,,2023-09-28 16:43:03+00:00,False,,False,False,True,False,/r/datascience/comments/16ukxy1/tesla_trying_to_screw_desperate_people/,Tesla trying to screw desperate people,"This a direct contract hire job post from Tesla not from third party staffing company. Insane 

https://preview.redd.it/9r5v5z2iy0rb1.png?width=589&format=png&auto=webp&s=2e6bdacd9141bdcfe2fc4a7d5810f6e27f086ef5",datascience,https://www.reddit.com/r/datascience/comments/16ukxy1/tesla_trying_to_screw_desperate_people/,28,0,0.39,"[Comment(id='k2ll75m'), Comment(id='k2llm5j'), Comment(id='k2louyv'), Comment(id='k2lnpkg'), Comment(id='k2ll6q1'), Comment(id='k2lp7p0'), Comment(id='k2lx70d'), Comment(id='k2lkk8j'), Comment(id='k2lo1v3'), Comment(id='k2lx2pv'), Comment(id='k2mhvqf'), Comment(id='k2olx36'), Comment(id='k49pcj4'), Comment(id='k2lmpww'), Comment(id='k2n65bi'), Comment(id='k2lpggu'), Comment(id='k2lm7dx'), Comment(id='k2ln7zj'), Comment(id='k2lzmqc'), Comment(id='k2lxmr8'), Comment(id='k2lpx5s'), Comment(id='k2luvsy'), Comment(id='k2lvtrj'), Comment(id='k2m8p5d'), Comment(id='k34i248'), Comment(id='k2ooiz6'), Comment(id='k35pxxy'), Comment(id='k35uwt4')]"
16twe33,shopchoffee,,2023-09-27 21:18:32+00:00,False,,False,False,True,False,/r/datascience/comments/16twe33/i_made_an_chocolate_and_coffee_website_focused_on/,I made an chocolate and coffee website focused on data transparency! Check out Choffee (feedback appreciated!),"Hey data wranglers!

My friend and I launched a new site focused on data transparent e-commerce — [Choffee](https://shopchoffee.com/)! Please check it out and share your feedback! A core mission of ours is impact transparency -- we aggregate order data and visualize our customers impact on [small business](https://shopchoffee.com/impact-on-small-businesses/) on [farms](https://shopchoffee.com/farming-impact/) through Tableau dashboards. A few things we publish on our site are:

1. Average price per ounce of Coffee/Chocolate by farming country
2. Sales by women owned vs male owned businesses
3. Sales distribution of location of small business

**Why is this important?** Data is one of the most powerful assets we own. Companies collect it all the time and sometimes sell it for billions! Imagine how powerful data would be if we could democratize it. That’s why we built Choffee — to share the data we capture back to our customers so they’re empowered to make data-driven shopping decisions and support businesses that share your values. 

**About us —** I'm an ex-actuarial analyst and a data scientist of 4 years and my friend has been a site engineer for 6 years. We’ve noticed that every company collects data and creates dashboards to track insights internally, however so few companies democratize data back to the consumer. We figured its about that that changes! We currently only sell chocolates & coffee on our business, however we plan to expand to broader product categories as we scale.

If you think this is an interesting idea, please consider buying some bars or coffee!

Shop at [shopchoffee.com](https://shopchoffee.com)",datascience,https://www.reddit.com/r/datascience/comments/16twe33/i_made_an_chocolate_and_coffee_website_focused_on/,2,3,0.81,"[Comment(id='k2j8w5r'), Comment(id='k2j9b7g')]"
16uffmd,misscherry1,,2023-09-28 13:00:43+00:00,False,,False,False,True,False,/r/datascience/comments/16uffmd/future_trends_in_data_science_salaries_and_what/,Future trends in Data Science salaries and what to expect in the coming years,"In the ever-evolving world of data science, staying ahead of the curve is essential not only in terms of skills but also in understanding the future landscape of compensation. As the field continues to expand and mature, the future of data science salaries I believe is a topic of great interest not only for me but for all of you as well. 

This is why I decided to look though future trends in Data Science salaries so you don’t have to.  


**Predicting Trends**

Several factors are poised to influence the trajectory of data science salaries in the coming years. First and foremost, the rapid pace of technological advancements is expected to have a profound impact. The increasing use of artificial intelligence (AI), machine learning (ML), and data analytics tools is likely to drive higher demand for skilled data scientists, resulting in competitive salary offerings.  


**Market Demand**

Market demand plays a pivotal role in shaping salaries. As more industries recognize the value of data-driven decision-making, data scientists are becoming indispensable assets. Financial services, healthcare, and e-commerce are anticipated to be among the sectors offering attractive compensation packages to data professionals.  


**Industry Growth**

The growth of industries such as FinTech, HealthTech, and InsurTech is projected to create specialized roles in data science. These niche positions may command higher salaries due to their specialized knowledge requirements and the potential to deliver significant business value.  


To provide a glimpse of the current landscape, here is a table showcasing different data science job titles and their approximate average salaries:  


&#x200B;

|**Data Science Job Title**|**Average Salary (Annual)**|
|:-|:-|
|Data Analyst|$65,000 - $95,000|
|Machine Learning Engineer|$90,000 - $130,000|
|Data Scientist|$100,000 - $150,000|
|Data Engineer|$95,000 - $140,000|
|Business Intelligence Analyst|$70,000 - $100,000|
|AI Research Scientist|$120,000 - $180,000|
|Data Consultant|$80,000 - $120,000|
|Big Data Architect|$110,000 - $160,000|
|Statistician|$70,000 - $110,000|
|Natural Language Processing (NLP) Engineer|$100,000 - $150,000+|
|Data Science Manager|$120,000 - $180,000+|

&#x200B;

**How to get into Data Science?**

For those looking to enter the field of data science, it's crucial to start with a strong educational foundation. Many aspiring data scientists are now considering intensive data science bootcamps as a more focused and efficient way to gain skills. This [comparison table ](https://docs.google.com/spreadsheets/d/1few9dA8toTIA04MYLmvYDFCQpFbEv32jGLwBWquojDc/edit#gid=0)shows different bootcamp alternatives that could help you find out what they can offer and make the best decision for your needs. Another option is a bachelor's degree in a related field like computer science, mathematics, or statistics. You can find the best universities to finish your bachelor’s degree in DS [here](https://www.topuniversities.com/university-rankings/university-subject-rankings/2023/data-science).  


Moreover, learning relevant tools and languages, gaining practical experience through internships or entry-level positions, specializing in areas like machine learning or data engineering, building a portfolio of personal projects, and networking with professionals in the field are all key steps to successfully embark on a career in data science.

In conclusion, the future of data science salaries promises to be exciting and rewarding. With continued technological advancements, growing market demand, and the diversification of industries seeking data expertise, data scientists can expect a dynamic and prosperous future. Staying informed about these trends will be crucial for those looking to thrive in this data-driven era.",datascience,https://www.reddit.com/r/datascience/comments/16uffmd/future_trends_in_data_science_salaries_and_what/,7,0,0.39,"[Comment(id='k2kmfpv'), Comment(id='k2km9nl'), Comment(id='k2knolp'), Comment(id='k2oqdlj'), Comment(id='k2kq1y9'), Comment(id='k2lgfyr'), Comment(id='k2kyemf')]"
16u5pk4,Rahul_devil,,2023-09-28 03:55:56+00:00,False,,False,False,True,False,/r/datascience/comments/16u5pk4/masters_in_which_topic_will_be_helpful_for/,Masters in which topic will be helpful for getting data science job.,"I am currently pursuing my BE in computer science and I want to be a data scientist and I think doing a master's will boost my chances in getting a Data science job.

So I want to know doing masters on which topic would be better 
1. Mathematics
2. Statistics
3. Computer science and related.",datascience,https://www.reddit.com/r/datascience/comments/16u5pk4/masters_in_which_topic_will_be_helpful_for/,4,1,1.0,"[Comment(id='k2js6h6'), Comment(id='k32m1qs'), Comment(id='k2l7r7a'), Comment(id='k2q5ej1')]"
16u038j,prtkkr,,2023-09-27 23:41:21+00:00,False,,False,False,True,False,/r/datascience/comments/16u038j/pdf_scraping/,PDF Scraping,"I apologize if this question has been asked before. I am looking for recommendations on how to extract unstructured data from PDF documents. In my current project, I have used Python libraries such as Pypdfium2, Pdfplumber – py, camelot, and Tabula – py to extract various sections from two different types of PDF reports. However, I now have many different PDF formats that need to be extracted in a structured format. Are there any paid tools that would be more effective than developing a custom solution? 

Has anyone tried using LLM models for PDF extraction?  

Is anyone using Azure AI Document Intelligence in production for such tasks?",datascience,https://www.reddit.com/r/datascience/comments/16u038j/pdf_scraping/,2,2,0.75,[Comment(id='k2k5f5p')]
16u0109,dev0martin0,,2023-09-27 23:38:45+00:00,False,,False,False,True,False,/r/datascience/comments/16u0109/database_management_vs_statistical_analysis/,Database Management vs Statistical Analysis,"Hey, working off a deleted post from yesterday.

My main question is: 

My current entry level job is focused on DBM and a lot of SQL. I am obtaining a MSDS this summer and work heavily with statistical analysis. Is it too much of a reach to think I can find some type of tru analysis entry wise? Or should I stop being a b*tch and work my very low paying DBManagement job until graduation. Are the two forever intertwined? 

Thanks all,

P.S. Please be kind as this is just meant as a discussion for a 24 y/o going through an identity crisis.",datascience,https://www.reddit.com/r/datascience/comments/16u0109/database_management_vs_statistical_analysis/,1,2,0.75,[Comment(id='k2jaz9p')]
16trg4f,proffesaur,,2023-09-27 17:57:47+00:00,False,,False,False,True,False,/r/datascience/comments/16trg4f/first_job/,First job,"Just got my first offer, still in university currently but offered 84k. Smaller company, where I would be the sole data person, is this crazy? Any red flags to look out for?",datascience,https://www.reddit.com/r/datascience/comments/16trg4f/first_job/,6,5,0.86,"[Comment(id='k2jbwl3'), Comment(id='k2jvcji'), Comment(id='k2gt366'), Comment(id='k2hbn8f'), Comment(id='k2k7vih'), Comment(id='k31chnk')]"
16u42p0,James_c7,,2023-09-28 02:34:10+00:00,False,,False,False,True,False,/r/datascience/comments/16u42p0/title_change_question/,Title change question,"Is Changing a job title on a resume ok? 

I worked at a company for a year and a half as a data analyst (I left the job 2 years ago) but my responsibilities were basically a data scientist (data modeling, a lot of bayesian modeling, built out experimentation, even did some applied science work). I did really well there but decided to leave because of title. right after I left they decided to re-level everyone from data analysts to data scientists.

I was talking to a recruiter today and noticed that he wasn’t counting those years of experience. Should I change my resume and LinkedIn to say I was a data scientist instead of a data analyst for that job?",datascience,https://www.reddit.com/r/datascience/comments/16u42p0/title_change_question/,1,1,0.67,[Comment(id='k2j7b5t')]
16txqky,-curious-cheese-,,2023-09-27 22:09:01+00:00,False,,False,False,True,False,/r/datascience/comments/16txqky/how_long_does_a_typical_project_take_you_to/,How long does a typical project take you to complete?,"I just started as a data analyst. I have two projects, and I am overwhelmed by the deadlines. I am wondering if the deadlines are normal or if I am a slow worker. How long would these projects take you?

1.  About 3000 observations with 34 variables regarding athletes from around 25 different teams and about 15 categories of financial revenue the athletes made over 2 years. Each athlete may have multiple observations. The data is mostly clean but had to be checked for errors because there were a few incorrect values. 

The goal is to recreate an excel workbook summarizing the revenue by sport, type of revenue, and year. The workbook has a sheet for each year summarizing each type of revenue by each team, a sheet for each team each year summarizing each type of revenue, and a few different various summary pages (such as a summary of athletes with no revenue). Someone made this workbook years ago, and it references another workbook I don’t have access to.

2.  About 500 observations with 25 variables each containing survey responses completed by individuals from different groups of stakeholders. Each responder has only one observation, but most of them are included in multiple stakeholder groups. The data was not clean, and the majority of the responses were long form written answers. The goal is to create a short written report and visualizations summarizing the categories of stakeholders that voted, how category voted, how many submitted inappropriate votes, the most common user-written responses, and the trends in how voters answered questions with fixed responses (weighted based on the categories of stakeholder the voter belongs to).

I hope this is a good enough description of the projects!",datascience,https://www.reddit.com/r/datascience/comments/16txqky/how_long_does_a_typical_project_take_you_to/,2,2,0.75,"[Comment(id='k2jf802'), Comment(id='k2k6uu9')]"
16tsmmy,SpiritualCurve9164,,2023-09-27 18:53:37+00:00,False,,False,False,True,False,/r/datascience/comments/16tsmmy/what_ds_experience_to_seek_to_set_up_for/,What DS experience to seek to set up for contracting later in life?,"I am UK Data Scientist (31F), looking to switch to part time contracting at around 35 to fit in family. I have 3-4 years ahead of hard work and want to build the right skills while work still is my #1 priority.

**Role:** currently a Staff Data Scientist at London scale up with £120k total comp. I do a lot of mentoring and lead multiple projects accross the business. I think I'd be targetting 50% hours for 50% pay as contractor.

**Experience**: 8y of python, spark, most query languages, NLP, Clustering, Information retrieval. I am better Data Scientist than Engineer, but have done both in the past. Happy to pick up new domain expertise/langauges when needed. 

**Questions:**

What specific DS knowlede suits for contracting type roles? 

What type of roles are in demand?

What to look out for? Does overall plan seem realistic?",datascience,https://www.reddit.com/r/datascience/comments/16tsmmy/what_ds_experience_to_seek_to_set_up_for/,0,3,1.0,[]
16tytm8,Gooooot,,2023-09-27 22:50:06+00:00,False,,False,False,True,False,/r/datascience/comments/16tytm8/analytics_for_an_energy_company/,Analytics for an Energy company,"Hi, 

I'm looking for guidance and support in my career as a Data Analyst in the energy sector. I'm currently a ""data analyst"" for roughly two years now. I put data analyst in brackets because I feel like a fraud as I haven't done any hard analysis nor do I feel qualified to be a analyst.

For context, I graduated from a non-Stem background but my degree included statistics. I had no idea what I wanted to do after university but fell into digital marketing. I worked as a digital analyst for 2 years helping clients set up and run their marketing campaigns using a data-driven approach - this is something that fulfilled me. However, I didn't like the marketing side of things and only the data side (running analysis on Excel, visualising the data with BI tools and providing insights). As I pivoted towards the data analysis career path, I joined the public sector for a year to hone my skills but that turned out to be a waste of time as I was just pulling data from their propriety software, running macros and producing PowerPoint slides. I had a lot of spare time during that time and proceeded to learn SQL/Python to up-skill, hoping to use my title to get a better job, which I did. 

Now, I'm in the energy sector, which is where I aspire to grow my career. The work is interesting and the people around me are really smart. I want to add as much value to my team so I've started producing automated dashboards to help visualise the operations/finance side of things. I've asked my manager how I can help her but she doesn't have any clue. She wants me to decide how I approach my job so I've tried leaning on other people asking them what they're working on but none of them applies to my job. 

So my question to you is: people who work in the energy sector, what kind do data analysis do you do? How do you add value to the team and where do you start searching for the datasets to produce analysis?",datascience,https://www.reddit.com/r/datascience/comments/16tytm8/analytics_for_an_energy_company/,1,0,0.5,[Comment(id='k2ipab3')]
16surfy,valkaress,,2023-09-26 17:50:21+00:00,False,,False,False,True,False,/r/datascience/comments/16surfy/is_having_a_fake_data_scientist_title_good_bad_or/,"Is having a fake Data Scientist title good, bad, or neutral?","My title is Senior Data Scientist, but I think most people here would agree that my actual job is probably like senior data analyst or something. Basically, I build slick dashboards for our client-facing people to find or keep clients. I use Python, Tableau, and SQL frequently, but that's about it.

What I'm wondering though is, if it comes a time when I decide to search for a similar role in a different company, what would this fake title do to my resume?

Would it be a good thing, perhaps because most hiring managers would prefer reading that over reading something like ""Data Analyst"" or whatever?

Or would it be a bad thing, perhaps because similar jobs would treat me as being overqualified and too expensive? And I would end up only being qualified for similar ""fake data scientist"" roles?",datascience,https://www.reddit.com/r/datascience/comments/16surfy/is_having_a_fake_data_scientist_title_good_bad_or/,102,173,0.91,"[Comment(id='k2bd4la'), Comment(id='k2bk3m2'), Comment(id='k2bcoa2'), Comment(id='k2c1fgb'), Comment(id='k2bqssa'), Comment(id='k2c3kee'), Comment(id='k2bo5kx'), Comment(id='k2c061i'), Comment(id='k2cpl39'), Comment(id='k2c4qg4'), Comment(id='k2cxnvj'), Comment(id='k2bkzq4'), Comment(id='k2bltuh'), Comment(id='k2dvgck'), Comment(id='k2c0y39'), Comment(id='k2cmt2n'), Comment(id='k2d6tij'), Comment(id='k2dga18'), Comment(id='k2dhshx'), Comment(id='k2dmgxr'), Comment(id='k2dmijl'), Comment(id='k2duc5m'), Comment(id='k2dydc8'), Comment(id='k2e46xe'), Comment(id='k2eixh2'), Comment(id='k2ev4ch'), Comment(id='k2eyz8j'), Comment(id='k2fdwxt'), Comment(id='k2grqri'), Comment(id='k2bgumr'), Comment(id='k2byxwo'), Comment(id='k2cdwts'), Comment(id='k2bscoe'), Comment(id='k2gja3e'), Comment(id='k2bzyii'), Comment(id='k2by633'), Comment(id='k2ds1xo'), Comment(id='k2bgi5w'), Comment(id='k2bfeds'), Comment(id='k2ed6yu'), Comment(id='k2bua59'), Comment(id='k2c4j8v'), Comment(id='k2bmlg3'), Comment(id='k2c0jhg'), Comment(id='k2bwv30'), Comment(id='k2c44mg'), Comment(id='k2buvhp'), Comment(id='k2ckx3z'), Comment(id='k2cp5xt'), Comment(id='k2cvqto'), Comment(id='k2cluvg'), Comment(id='k2cxaq2'), Comment(id='k2bincp'), Comment(id='k2bhscw'), Comment(id='k2deb46'), Comment(id='k2caf54'), Comment(id='k2bfr97'), Comment(id='k2c65l4'), Comment(id='k2bvlba'), Comment(id='k2cdotw'), Comment(id='k2d3y80'), Comment(id='k2cajtl'), Comment(id='k2cno1y'), Comment(id='k2d2zqb'), Comment(id='k2d4azs'), Comment(id='k2bj27l'), Comment(id='k2bk4dy'), Comment(id='k2c8lfz'), Comment(id='k2csqpp'), Comment(id='k2ca7ea'), Comment(id='k2h6ysr'), Comment(id='k2cjgdo'), Comment(id='k2bg7ll'), Comment(id='k2bo40c'), Comment(id='k2cko6c'), Comment(id='k2cfqrf'), Comment(id='k2c0pp8'), Comment(id='k2bzpck'), Comment(id='k2gabcv'), Comment(id='k2ccdy2'), Comment(id='k2dgfst'), Comment(id='k2coaav'), Comment(id='k2cdqq2'), Comment(id='k2cprcs'), Comment(id='k2drop3'), Comment(id='k2biwyr'), Comment(id='k2birkz'), Comment(id='k2bore7'), Comment(id='k2bsioq'), Comment(id='k2d3ryn'), Comment(id='k2dlp09'), Comment(id='k2e704y'), Comment(id='k2cvlgw'), Comment(id='k2by1vt'), Comment(id='k2c4ams'), Comment(id='k2doghf'), Comment(id='k2drxdp'), Comment(id='k2dl2vd'), Comment(id='k2dulmg'), Comment(id='k2dvoit'), Comment(id='k2egljd')]"
16tx5v4,Material_Shoe_4334,,2023-09-27 21:47:37+00:00,False,,False,False,True,False,/r/datascience/comments/16tx5v4/are_there_any_datasets_with_frontal_footage_of/,Are there any datasets with frontal footage of cars on roads/highways?,This is for my seatbelt fastness detection project. I can't really find any datasets or just even regular YouTube videos of cars with drivers (even barely) visible,datascience,https://www.reddit.com/r/datascience/comments/16tx5v4/are_there_any_datasets_with_frontal_footage_of/,6,1,1.0,"[Comment(id='k2ju2lg'), Comment(id='k2l8e55'), Comment(id='k2l8vhd'), Comment(id='k2l8twh'), Comment(id='k2lc1ea'), Comment(id='k2lkitv'), Comment(id='k2lln0g')]"
16twyc0,Rtktts,,2023-09-27 21:39:57+00:00,False,,False,False,True,False,/r/datascience/comments/16twyc0/data_projects_in_production/,Data projects in production,"Disclaimer: I am a software dev.

I have a question about how data projects are build for production use.

I understand why data scientist use Python and Pandas a lot for their exploratory work and research.

But when we are talking about deploying data pipelines or other software which is suppose to run for a few years, these Python libs do not seem to be the right choice, because they do not care about backwards compatibility. Yet in the wild I see a lot of production pipelines which are completely written in pandas. 

Same issue in the team I just joined. Tons of pandas code which we cannot update anymore because even a minor version update could break everything.

Another issue I see is that these pipelines are build without any regard to encapsulation or abstraction. Everything is just glued together directly. But they have the same issue any software system has and why the concept of microservices are a thing in software development for years. Any change is a huge mess because these pipelines are big monoliths.

So I guess my questions are: How do you build your production pipelines? Is it normal to use pandas in those pipelines? Do you have any issues with it? What about microservices?",datascience,https://www.reddit.com/r/datascience/comments/16twyc0/data_projects_in_production/,3,1,1.0,"[Comment(id='k2j1pkx'), Comment(id='k2kvyov'), Comment(id='k2mw93q')]"
16tpsvq,Roua_Rejeb,,2023-09-27 16:54:01+00:00,False,,False,False,True,False,/r/datascience/comments/16tpsvq/kaggle_data_visualization_certificate/,Kaggle Data Visualization certificate," How can I add a dataset in Kaggle? I am currently working on the data visualization tutorial and I can not finish the final project because I cannot find the ""add data' button. Is anyone facing the same problem? How to fix it? thank you in advance.",datascience,https://www.reddit.com/r/datascience/comments/16tpsvq/kaggle_data_visualization_certificate/,0,2,1.0,[]
16ti2vx,Hamdi_bks,,2023-09-27 11:31:58+00:00,False,,1695816398.0,False,True,False,/r/datascience/comments/16ti2vx/regression_vs_classification_90k_dataset_with/,Regression vs Classification: 90K Dataset with Only 600 Unique Values - Seeking Insights!,"I’m working on a specific regression problem. My dataset comprises 90,000 samples, and my target variable ranges from 0 to 100 (real numbers). After examining my target variable, I discovered it has only 600 unique values, which is relatively sparse given my dataset’s substantial size (90,000 rows). 25% of these values appear between 1 to 10 times, and 50% are distributed between 100 to 1,000 occurrences.

I considered transforming it into a classification problem; however, this approach presents its own challenges, such as an extremely imbalanced dataset and the daunting prospect of managing 600 classes. Additionally, converting to classification would mean losing the ordinal property of my target variable.

Is there a middle-ground approach that strikes a balance between regression and classification? Does anyone have innovative strategies or know of any research papers that address such issues?",datascience,https://www.reddit.com/r/datascience/comments/16ti2vx/regression_vs_classification_90k_dataset_with/,16,5,0.86,"[Comment(id='k2f4aaf'), Comment(id='k2gtcgo'), Comment(id='k2fijph'), Comment(id='k2f5870'), Comment(id='k2fqj82'), Comment(id='k2gaadn'), Comment(id='k2kwsr6'), Comment(id='k2f4x90'), Comment(id='k2f5tv2'), Comment(id='k2fsjg7'), Comment(id='k2f5ttj'), Comment(id='k2fa72v'), Comment(id='k2g7pfd'), Comment(id='k2f6qn0'), Comment(id='k2g8l16'), Comment(id='k2fhr4t')]"
16tt7vg,mmurad96,,2023-09-27 19:15:57+00:00,False,,False,False,True,False,/r/datascience/comments/16tt7vg/clients_procrastination_for_brd_approval/,clients procrastination for BRD approval,"I wonder,  how a vendor should deal with clients who procrastinate and destructively criticize any point in the business requirements document. We are beyond the deadline due to they do not help. We have successful stories with many clients. But it is the first time to deal with a client who just want to hinder any progress and who is afrid to have a commitment for giving any approval.
Although they are aware of our success stories and we proposed a proof of concept which is accepted, after preparing the BRD to agree on the points of the project, they just procrastinate.
I want to know from experts if they faced similar situations and how you dealt with it to accelerate the approval steps and move on the next stages.",datascience,https://www.reddit.com/r/datascience/comments/16tt7vg/clients_procrastination_for_brd_approval/,0,1,1.0,[]
16taxs3,needtheprivacy,,2023-09-27 04:38:28+00:00,False,,False,False,True,False,/r/datascience/comments/16taxs3/can_someone_eli5_the_difference_between_ds_types/,Can someone ELI5 the difference between DS types of work?,"I come in peace, I’m a recruiter for a tech company that is trying to learn about data science! 

I find our hiring managers often want data scientist who has “product analytics” or “product data science” experience. 

I understand this high level; I do know the difference between a DS who works on modeling solely and DS that is working on a product. I get usually people are one or the other 

But for a topic such as Search, i have a really hard time discerning the differences. 

So TLDR - can any one ELI5 the difference within DS subgroups like product data science? 


I’ll probably get downvoted to hell because everyone hates recruiters. But I ask you be gentle because I’m just trying to get better at my job and hopefully be a good experience for any of you who may fall into my interview loops :)",datascience,https://www.reddit.com/r/datascience/comments/16taxs3/can_someone_eli5_the_difference_between_ds_types/,4,12,0.88,"[Comment(id='k2e27bh'), Comment(id='k2fwti7'), Comment(id='k2eizuu'), Comment(id='k2g2zdj')]"
16tkfe5,No_Lynx3610,,2023-09-27 13:20:11+00:00,False,,False,False,True,False,/r/datascience/comments/16tkfe5/etl_technology/,ETL Technology,I'm trying to migrate old ETL processes developed in SSIS (Integration Services) to Azure but I don't know whether it is better to go for a NoCode/LowCode solution like ADF or code the ETL using PySpark. What is the standard in the industry or the most professional way to do this task?,datascience,https://www.reddit.com/r/datascience/comments/16tkfe5/etl_technology/,1,2,1.0,[Comment(id='k2fxoob')]
16tv900,norfkens2,,2023-09-27 20:34:39+00:00,False,,1695849207.0,False,True,False,/r/datascience/comments/16tv900/meta_majority_of_people_supports_the_status_quo/,[Meta] Majority of people supports the status quo of the DS subreddit,"Every couple of months a post comes up that addresses the state of the subreddit, giving valid criticism on a given topic. People in the comments often complain about given topic (I have, too, in the past). 

Now, I wanted to gauge how much of that discontent could actually be translated into change. So, I started a little non-representative experiment - for shits and giggles, I guess.

&nbsp;

*My (non-representative) results:*

People in /r/datascience/ - 1.1m

Average views of a post - ~10k

People interacting with a post complaining about too many career questions - ~120

People commenting - ~40

People bringing forward actually constructive comments relevant to the topic - 3

People responding to a direct question about improving engagement - 0

&nbsp;

*My takeaway:*

a) People support the status quo of the subreddit - either because they do like it that way or through their inactivity. Or maybe they don't mind either way.

b) Comments complaining in these kind of posts mostly seem to have only entertainment value.",datascience,https://www.reddit.com/r/datascience/comments/16tv900/meta_majority_of_people_supports_the_status_quo/,6,0,0.25,"[Comment(id='k2jrdgh'), Comment(id='k2kc9zt'), Comment(id='k2jxpc7'), Comment(id='k2kg0qp'), Comment(id='k2k0mob'), Comment(id='k2k7o5w')]"
16tpils,Public-Recording9634,,2023-09-27 16:42:51+00:00,False,,False,False,True,False,/r/datascience/comments/16tpils/conformal_prediction/,conformal prediction,"hi can someone explain intuitively the differences between unconditional coverage and conditional coverage split conformal prediction?

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16tpils/conformal_prediction/,1,1,1.0,[Comment(id='k2pdr0r')]
16tii86,Citizen_of_Danksburg,,2023-09-27 11:54:05+00:00,False,,False,False,True,False,/r/datascience/comments/16tii86/how_to_recover_from_submitting_incorrect_résumé/,How to recover from submitting incorrect résumé for job application?,"Hi, I majorly fucked up.

I currently work as a statistician in biotech and am looking to transition to a data science career. I worked a very long day yesterday due to standard end of quarter rush, and so when I got home, I spent all evening completely revamping from top to bottom my LinkedIn and Resume.

The problem is my resume. I found this template online that looked great (https://careercup.com/resume) and began filling it out. The fuck up is on the education section. I had filled out the bullet points saying when I had finished my undergrad and masters as well as the relevant coursework I took, but I submitted this new resume to a job (that looked like something I’d absolutely love and be qualified for) with the education section saying I spent all my time at the University of Pennsylvania (what the template lists as the only school — I didn’t go to this school nor did I do my undergrad and masters at the same school). 

How should I go about fixing this? There is no applicant portal where I can easily upload a new document or fix it. I’m feeling so ashamed of myself that I quite possibly blew it so hard. 

Is there any hope for me? I could use some advice for sure. I noticed the error seconds after I submitted my application and have since corrected it.",datascience,https://www.reddit.com/r/datascience/comments/16tii86/how_to_recover_from_submitting_incorrect_résumé/,11,3,0.64,"[Comment(id='k2f5gam'), Comment(id='k2gij8l'), Comment(id='k2f5688'), Comment(id='k2hrcgx'), Comment(id='k2f7fyi'), Comment(id='k2f74qm'), Comment(id='k2jrsfr'), Comment(id='k2jrayn'), Comment(id='k2f8duu'), Comment(id='k2jtih4'), Comment(id='k2fh8mm'), Comment(id='k2jw4c5'), Comment(id='k2l2ulf'), Comment(id='k2m5ffv')]"
16tmqz9,anon67543,,2023-09-27 14:55:11+00:00,False,,False,False,True,False,/r/datascience/comments/16tmqz9/complex_dataset_approach/,Complex Dataset approach,"Hi everyone. I’ve got a dataset composed of pictures with various categorical and numerical information attached to each picture. I’m trying to cluster these into groups. So far i rolled the picture out to pixel data but if I throw in the other data, it seems to get buried under the number of pixels. 

I’m thinking of weighting the nonpixel higher relative to pixel, but not sure what to do about it (1:1 or…) . 
Any ideas or packages to get in the right direction are appreciated.",datascience,https://www.reddit.com/r/datascience/comments/16tmqz9/complex_dataset_approach/,2,1,1.0,"[Comment(id='k2fx5kf'), Comment(id='k2o68rq')]"
16tksa5,randomtest123xx,,2023-09-27 13:34:02+00:00,False,,False,False,True,False,/r/datascience/comments/16tksa5/a_data_science_position_is_advertised_as_an/,"A data science position is advertised as an internship and as a working student position, I could apply for both but where do I think my chances are better ? What would you do ?",,datascience,https://www.reddit.com/r/datascience/comments/16tksa5/a_data_science_position_is_advertised_as_an/,0,0,0.33,[]
16tkg6g,debordian,,2023-09-27 13:20:59+00:00,False,,False,False,False,False,/r/datascience/comments/16tkg6g/github_anacondastateofdatascience_data_from_the/,GitHub - anaconda/state-of-data-science: Data from the state of data science survey released by Anaconda each year.,,datascience,https://github.com/anaconda/state-of-data-science,0,1,1.0,[]
16t145z,Any-Fig-921,,2023-09-26 21:45:46+00:00,False,,False,False,True,False,/r/datascience/comments/16t145z/are_you_actually_making_your_own_nns_in_2023/,Are you actually making your own NNs in 2023?,"I'm finding the task in my role are bifurcating into one of two things.  
1. Simple Statistical/ML Model. Linear Models, maybe SVM or similar. Classification or interpretation of data with 'standard' models.

2. Using an open source / proprietary NN model. OpenAI, huggingface for text generation, image generation, embeddings etc. MAYBE I fine tune something, but probably just use off-the-shelf APIs or models.  


Don't get me wrong, I'm not complaining, I enjoy both these things, and writing your own tensorflow or pytorch model can be a real pain.  


Is there anyone out there who is writing their own custom tensorflow or pytorch models in 2023? If so, what are your use cases? It feels like we're moving towards a world with open-source models that are better than almost anything you could spin up in house for most use cases.",datascience,https://www.reddit.com/r/datascience/comments/16t145z/are_you_actually_making_your_own_nns_in_2023/,10,18,0.95,"[Comment(id='k2ditdx'), Comment(id='k2d9ceq'), Comment(id='k2dans5'), Comment(id='k2fv6wx'), Comment(id='k2e74qa'), Comment(id='k2egqq3'), Comment(id='k2ei304'), Comment(id='k2dtjjd'), Comment(id='k2dvn63'), Comment(id='k2fhjlz')]"
16sbhun,jacobwlyman,,2023-09-26 02:27:20+00:00,False,,1695832108.0,False,True,False,/r/datascience/comments/16sbhun/you_dont_have_to_be_a_data_scientist/,You don’t have to be a Data Scientist,"Just a PSA for anyone here that is starting their career, might feel overwhelmed with applying/interviewing for jobs, or is looking for a career change. 

If you’re interested in a Data career, know that there are many different roles out there other than a “data scientist” role. Here’s only a handful of the common titles I see out there these days:

- Business Analyst
- Data Analyst
- Product Analyst
- <INSERT_WORD> Analyst 
- Analytics Engineer
- Data Engineer
- DataOps Engineer
- ML Engineer
- MLOps Engineer (This is my current role -- Feel free to DM me or read [What is MLOps?](https://www.jacoblyman.com/tech-log/published/what-is-mlops) to learn more)
- Product Manager 
- Management/Leadership roles

Feel free to comment any other Data roles that others might not know about!

Edit: Here is a list of other Data roles that were commented on in the thread as of Sept 27th, 2023.

- Risk Analyst
- Statistical Programmer
- Economist
- Actuary
- AI Engineer
- Manager of Business Intelligence
- Marketing Analytics Manager
- Marketing Analyst
- Marketing Operations Manager
- Revenue Operations Manager
- Bioinformatician
- Cheminformatician
- Institutional Research roles
- Operational Research roles
- Analytics Product Management roles",datascience,https://www.reddit.com/r/datascience/comments/16sbhun/you_dont_have_to_be_a_data_scientist/,125,492,0.97,"[Comment(id='k28bkhn'), Comment(id='k28krz0'), Comment(id='k28c2gd'), Comment(id='k28tsa6'), Comment(id='k296j8q'), Comment(id='k28qylx'), Comment(id='k29262e'), Comment(id='k28mrc9'), Comment(id='k2a4veq'), Comment(id='k28gcjv'), Comment(id='k28tjx7'), Comment(id='k28nvyr'), Comment(id='k2937o1'), Comment(id='k299drb'), Comment(id='k28lyey'), Comment(id='k295mer'), Comment(id='k29at1z'), Comment(id='k29r9ka'), Comment(id='k29soyl'), Comment(id='k29wb64'), Comment(id='k2altbm'), Comment(id='k28xq41'), Comment(id='k29ai8d'), Comment(id='k29iqiu'), Comment(id='k29jw9h'), Comment(id='k2arqea'), Comment(id='k2aztw0'), Comment(id='k2bg4s8'), Comment(id='k2biio9'), Comment(id='k2d848s'), Comment(id='k2f5iyd'), Comment(id='k2kfuee'), Comment(id='k29nklx'), Comment(id='k29q33l'), Comment(id='k2ahvg5'), Comment(id='k299k5i'), Comment(id='k29nbgn'), Comment(id='k29avne'), Comment(id='k29l019'), Comment(id='k2apj69'), Comment(id='k2ciuof'), Comment(id='k3q5k8a'), Comment(id='k2b1ead'), Comment(id='k2e009o'), Comment(id='k29043n'), Comment(id='k28qurb'), Comment(id='k2a5xr3'), Comment(id='k290534'), Comment(id='k2aco05'), Comment(id='k2a9abo'), Comment(id='k2awu6i'), Comment(id='k2b7xvv'), Comment(id='k2bbd0o'), Comment(id='k2af6e0'), Comment(id='k2a9r3c'), Comment(id='k29yvlx'), Comment(id='k2b8ixb'), Comment(id='k29176r'), Comment(id='k28tj6f'), Comment(id='k28lc1e'), Comment(id='k6d6ddp'), Comment(id='k29zq1u'), Comment(id='k29n7zx'), Comment(id='k29d5kz'), Comment(id='k29ki6v'), Comment(id='k29rmu9'), Comment(id='k2a9xpr'), Comment(id='k29nk1b'), Comment(id='k29dlic'), Comment(id='k2a7zth'), Comment(id='k2g636k'), Comment(id='k2g65i5'), Comment(id='k29yfqw'), Comment(id='k2bhcp5'), Comment(id='k2a2t7c'), Comment(id='k2a0chb'), Comment(id='k2lejgy'), Comment(id='k2fd51b'), Comment(id='k295pgx'), Comment(id='k2dgiof'), Comment(id='k2a1y0x'), Comment(id='k2abd36'), Comment(id='k2abtom'), Comment(id='k2apkh7'), Comment(id='k2bbvk6'), Comment(id='k2bcmci'), Comment(id='k2bh5zv'), Comment(id='k2cw7l0'), Comment(id='k2ao30j'), Comment(id='k2anm70'), Comment(id='k2cb95r'), Comment(id='k298s05'), Comment(id='k2a55wk'), Comment(id='k2a23ot'), Comment(id='k2a0fcb'), Comment(id='k29xb6u'), Comment(id='k2atrib'), Comment(id='k29qp9f'), Comment(id='k2aauo0'), Comment(id='k2hsa3l'), Comment(id='k2bzhx4'), Comment(id='k2dlnkt'), Comment(id='k2aalt9'), Comment(id='k2avr47'), Comment(id='k2fd7wp'), Comment(id='k2abp2g'), Comment(id='k2bdm4h'), Comment(id='k2az02k'), Comment(id='k2cknci'), Comment(id='k2cl8lt'), Comment(id='k2bhkvw'), Comment(id='k2a9uyf'), Comment(id='k29xtzu'), Comment(id='k2abygg'), Comment(id='k2bvs27'), Comment(id='k2b6res'), Comment(id='k2catu8'), Comment(id='k2cr880'), Comment(id='k2crkl1'), Comment(id='k2abo0x'), Comment(id='k2brw6r'), Comment(id='k2c05mz'), Comment(id='k2c3a59'), Comment(id='k2cdtxy'), Comment(id='k2ckt89')]"
16t9tc4,kpr1904,,2023-09-27 03:43:38+00:00,False,,False,False,True,False,/r/datascience/comments/16t9tc4/is_there_any_chance_of_getting_data_analytics_job/,Is there any chance of getting data analytics job in an industry of your interest?,"Currently, I’m a sophomore at an university in Southeast Asia, and I’m planning to move to Australia to study on a transnational program. My intention is also to have a job in Australia. In order to achieve the goal, I’m now self-studying some technical tools about data analytics with an aim of doing a project to fill in the CV, while at the same time improving my soft skills and read more about my desired industry - commercial aviation.

The problem is, I really want to work in that industry. Data analytics jobs are everywhere in every industries such as education, finance, manufacturing,… and I see people applying for HUNDREDS of jobs just to finally to land 1 job. Therefore, how do you think about the chance of getting a job in a specific industry, especially mine since there is not a lot firms/companies? I managed to find some when doing research but what’s the possibility, given you have just a little bit more knowledge in that industry?",datascience,https://www.reddit.com/r/datascience/comments/16t9tc4/is_there_any_chance_of_getting_data_analytics_job/,1,3,0.81,[Comment(id='k2e3hj4')]
16tgwqf,Junior-Suit2097,,2023-09-27 10:29:44+00:00,False,,False,False,True,False,/r/datascience/comments/16tgwqf/need_guidance_for_data_scientist_product/,"Need guidance for Data Scientist, Product Analytics ( Technical Round 45 minutes SQL + Product Sense ) in 2.5 weeks","Hello Everyone,

I have a technical round in 2.5 weeks for the Data Scientist, Product Analytics role at Meta and Recruiter told me it's going to be an SQL + Product case round. I am average at SQL but have some experience with working on product scenario-based real-world problems. How can I prepare myself in a short span of time to clear this round? Do they repeat questions or what will be the best source for study material? Is there someone who is willing to prepare me without asking for heavy fees which they ask on different platforms?",datascience,https://www.reddit.com/r/datascience/comments/16tgwqf/need_guidance_for_data_scientist_product/,0,1,0.67,[]
16sxpls,Rosehus12,,2023-09-26 19:41:17+00:00,False,,False,False,True,False,/r/datascience/comments/16sxpls/what_software_can_handle_large_data_sas_or_r/,"What software can handle large data, SAS or R?",These are the only 2 software used where I work. I'm proficient in R than SAS but if it will be useful I will try to brush it up. Please suggest if there are any other solutions to make R work faster. Spark is something I'm considering too,datascience,https://www.reddit.com/r/datascience/comments/16sxpls/what_software_can_handle_large_data_sas_or_r/,60,16,0.74,"[Comment(id='k2bv4ki'), Comment(id='k2bywm0'), Comment(id='k2c66sa'), Comment(id='k2bwe2z'), Comment(id='k2cdsmu'), Comment(id='k2c183t'), Comment(id='k2c2wti'), Comment(id='k2cbvr6'), Comment(id='k2e4d9y'), Comment(id='k2c2xbc'), Comment(id='k2cygvm'), Comment(id='k2d6eb9'), Comment(id='k2ebb97'), Comment(id='k2eifkg'), Comment(id='k2febm1'), Comment(id='k2bwfcm'), Comment(id='k2bzqhh'), Comment(id='k2elyc3'), Comment(id='k2ezj3m'), Comment(id='k2bx8ft'), Comment(id='k2ceo2l'), Comment(id='k2cibjv'), Comment(id='k2fmoqn'), Comment(id='k2c30ev'), Comment(id='k2ccqn8'), Comment(id='k2hsoa0'), Comment(id='k2cebk3'), Comment(id='k2drqnq'), Comment(id='k2bymzg'), Comment(id='k2c68bs'), Comment(id='k2dlkcv'), Comment(id='k2c0bws'), Comment(id='k2cej8g'), Comment(id='k2eptsy'), Comment(id='k2f37p9'), Comment(id='k2c207q'), Comment(id='k2cgg3w'), Comment(id='k2cz661'), Comment(id='k2bz97j'), Comment(id='k2foaby'), Comment(id='k2eu04e'), Comment(id='k2f4azw'), Comment(id='k2cjpx3'), Comment(id='k2bzn63'), Comment(id='k2c75h2'), Comment(id='k2ft891'), Comment(id='k2f31ye'), Comment(id='k2f5isy'), Comment(id='k2cobrq'), Comment(id='k2gvhrt'), Comment(id='k2f3zgv'), Comment(id='k2f5vtx'), Comment(id='k2cootg'), Comment(id='k2gw6v7'), Comment(id='k2f51ue'), Comment(id='k2f6kll'), Comment(id='k2fa40a'), Comment(id='k2lj6bq'), Comment(id='k2f9e74'), Comment(id='k2fbtnw'), Comment(id='k2mnr5e'), Comment(id='k2ho2kb'), Comment(id='k2hoo7m'), <MoreComments count=0, children=[]>]"
16tfk8f,bilby2020,,2023-09-27 09:05:28+00:00,False,,False,False,True,False,/r/datascience/comments/16tfk8f/is_there_any_gpt_like_tool_to_analyse_and_compare/,Is there any GPT like tool to analyse and compare PDF contents,"I am not sure if this is the best place to ask, but here goes.

I was trying to compare two different insurances from different companies (C1 and C2)  by reading their product disclosure statements. These are like 50-100 page PDFs and very hard to read, understand and compare. E.g. C1 may define income different to C2. C1 may cover illnesses different to C2. 

Is there any GPT like tool where I can upload the two PDFs and ask it questions like I would ask a insurance advisor. If it is not there is it feasible to be built.

* What the are the key differences between C1 and C2?
*  Is diabetes definition same in C1 and C2, if not what is the difference?
* C1 pays 75% income up to age 65 and 70% up to age 70. How does this compare with C2?

e.g. Document [https://www.tal.com.au/-/media/tal/files/pds/accelerated-protection-combined-pds.pdf](https://www.tal.com.au/-/media/tal/files/pds/accelerated-protection-combined-pds.pdf)",datascience,https://www.reddit.com/r/datascience/comments/16tfk8f/is_there_any_gpt_like_tool_to_analyse_and_compare/,2,1,1.0,"[Comment(id='k2eoaxy'), Comment(id='k2jm3pf')]"
16tf9hz,aquablue24_,,2023-09-27 08:46:24+00:00,False,,False,False,True,False,/r/datascience/comments/16tf9hz/take_my_survey/,Take my survey!," I have made a pretty fun survey for a uni assignment - would really appreciate any respondents. More than happy to respond to other surveys in return!

Takes less than 5 minutes.

https://v4-4-5.saas-us1.surveyengine.com/eu34blcvoikl8j4g9c0b2jk9sf35rns81vt2pl7kr14amejjthq6qdhqou4h6323ia50",datascience,https://www.reddit.com/r/datascience/comments/16tf9hz/take_my_survey/,0,0,0.33,[]
16terry,sneekytrojan,,2023-09-27 08:14:34+00:00,False,,False,False,True,False,/r/datascience/comments/16terry/a_data_scientist_with_an_idea_itching_to_become/,A Data Scientist with an idea itching to become the startup Vagabond,"Greetings fellow Data Scientists and Dreamers,

I've  finally begun my path towards starting up. I aim to provide the gaming community with alternative methods to obtaining game-playable assets and loot. I'm doing this while reading *Lean Startup* and currently I'm trying to validate some assumptions I've written down on the project's Lean Canvas.  
Yesterday, I deployed a questionnaire at various gaming communities on Reddit and had a slew of different interactions, they ranged from  people calling it a crypto scam (there's no crypto involved in the project at all) while others obliged and took the questionnaire, to others inquiring more about it and engaging me in earnest. From the likely 7K+ persons who saw the post (according the post metrics provided by Reddit) I only got 25 people to actually fill in the questionnaire, however. 

If there are any founders or dreamers among you I'm hoping to learn what approaches some one you have taken to try and validate assumptions in the pre-prototype phase, i.e. the phase where you're trying to gauge if the 'gaps' you think you've found indeed do exist.

For Data Scientists who go out there and gather data what techniques did you folks use to engage your target groups. Have you done campaigns on Reddit, what worked, what didn't work? Thanks a milllion.

Lastly, if you're a gamer, hardcore or casual, would you mind taking the questionnaire, its on a google form: [https://docs.google.com/forms/d/e/1FAIpQLSc6MApt\_ji7rsBgYHnzB3pP901X9VETvO-8ICvGrKAl2SD7nA/viewform](https://docs.google.com/forms/d/e/1FAIpQLSc6MApt_ji7rsBgYHnzB3pP901X9VETvO-8ICvGrKAl2SD7nA/viewform) and if you're not a gamer, would you mind taking a look at it and recommend some feedback so that I may improve upon it?  


Warm regards, 

Rick   


p.s. you can find me on [www.linkedin.com/in/rdmtinez](https://www.linkedin.com/in/rdmtinez) if you wish to connect ",datascience,https://www.reddit.com/r/datascience/comments/16terry/a_data_scientist_with_an_idea_itching_to_become/,15,0,0.45,"[Comment(id='k2esej4'), Comment(id='k2euino'), Comment(id='k2emzkd'), Comment(id='k2f0uwu'), Comment(id='k2f34ei'), Comment(id='k2f3152'), Comment(id='k2esarm'), Comment(id='k2fy2ik'), Comment(id='k2f3bgz'), Comment(id='k2f9w25'), Comment(id='k2f9qvl'), Comment(id='k2fba73'), Comment(id='k2faoim'), Comment(id='k2fh2pv'), Comment(id='k2k01y3')]"
16t7d17,csuarezg,,2023-09-27 01:54:45+00:00,False,,False,False,True,False,/r/datascience/comments/16t7d17/data_science_for_an_investment_professional/,Data science for an Investment Professional.,"Hello everyone, 
I have a degree in finance (also I'm a CFA charterholder and CAIA candidate)  and 7 years of experience in Fixed Income trading and Risk Management.
I would like to expand my circle of competence through coding/ data science. I was doing reseaech to create a self-paced road map to learn data science for investment professionals, however I don't found a proper road map to start this journey.

I would like to know your thoughts regarding how to learn valuable data science skills to upgrade my professional profile. (I'm excel proficient, but zero programming knowledge)

Which should be the key topics to learn, the first steps and the most valuable sources you will consider for a financial professional in order to gain deep knowledge in data science?

In advance, thank you for you comments.",datascience,https://www.reddit.com/r/datascience/comments/16t7d17/data_science_for_an_investment_professional/,1,3,1.0,[Comment(id='k2etf3l')]
16td7vt,anxiouscrimp,,2023-09-27 06:39:39+00:00,False,,False,False,True,False,/r/datascience/comments/16td7vt/what_problems_could_i_try_to_solve/,What problems could I try to solve?,"I work as a BI architect for a retailer. I’ve built out our data warehouse which is feeding a set of powerBI dashboards and cubes for the business. I’ve got access to all of our data - stock, sales, purchasing, web traffic (ga) etc. I do have access to CRM data but my understanding of customer is poor - this is handled by someone else.

So far I’ve done a bit of basket analysis in Python which I’m surfacing in a dashboard for the users which has gone down well. I really enjoyed doing it.

But what else could I look at? I’m sure there are some standard pieces of analysis that retailers would normally do. But we are pretty immature when it comes to moving beyond ‘this is what we sold last week’.",datascience,https://www.reddit.com/r/datascience/comments/16td7vt/what_problems_could_i_try_to_solve/,1,1,1.0,[Comment(id='k2eci2g')]
16t83yn,Terrible-Hamster-342,,2023-09-27 02:26:17+00:00,False,,False,False,True,False,/r/datascience/comments/16t83yn/anyone_here_work_as_a_data_scientist_focused_on/,Anyone here work as a Data Scientist focused on user growth?,"I’m about to start a new job and the objective will be user growth. Focused on personalization (ads targeting), segmentation and measurement of AB Test results.

Company goal is to increase retention and also acquire new users.

Can anyone working in a similar space share their experience?",datascience,https://www.reddit.com/r/datascience/comments/16t83yn/anyone_here_work_as_a_data_scientist_focused_on/,3,2,1.0,"[Comment(id='k2ew26l'), Comment(id='k2fd60n'), Comment(id='k2fljdt')]"
16t4um7,modelbit,,2023-09-27 00:09:12+00:00,False,,False,False,True,False,/r/datascience/comments/16t4um7/interact_with_an_owlvit_object_detection_model/,Interact with an OWL-ViT Object Detection Model,"There has been a lot of interest in the new computer vision ML models coming out of Meta Research and Google, so we built an interactive demo of what it's like to interact with an OWL-ViT model as an end user in a product.

[**Here is a link to the interactive demo**](https://www.modelbit.com/owl-vit-demo)**.**

[OWL-ViT](https://arxiv.org/abs/2205.06230) is a new object detection model from the team at Google Research. It allows you to identify an object in one image (the “query image”) and then find that same object in any number of target images.

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16t4um7/interact_with_an_owlvit_object_detection_model/,1,3,1.0,[Comment(id='k2d1hj1')]
16tchf8,ElegantAnalysis,,2023-09-27 05:58:36+00:00,False,,False,False,True,False,/r/datascience/comments/16tchf8/what_would_you_get_your_company_to_pay_for_as_a/,What would you get your company to pay for as a beginner,"As the title says, I'm a beginner in the field and I can probably get my company to pay for a course or a cert or something like that

What would get your company to pay for if you could? Around 1000-1500€",datascience,https://www.reddit.com/r/datascience/comments/16tchf8/what_would_you_get_your_company_to_pay_for_as_a/,3,1,0.67,"[Comment(id='k2eervg'), Comment(id='k2idca4'), Comment(id='k2idmmy')]"
16tkgyu,you_ako,,2023-09-27 13:21:52+00:00,False,,False,False,True,False,/r/datascience/comments/16tkgyu/training_regression_model_using_50_gb/,Training regression model using 50 Gb,"Hello guys, I have a question for interview assessment:

We have 50Gb of data, on which we want to run a linear regression, but we have only 8Gb of RAM on our machine. Name several possible regression strategies",datascience,https://www.reddit.com/r/datascience/comments/16tkgyu/training_regression_model_using_50_gb/,16,0,0.3,"[Comment(id='k2fyxvu'), Comment(id='k2fqvy7'), Comment(id='k2fufie'), Comment(id='k2fseug'), Comment(id='k2jh2y9'), Comment(id='k2uchd7'), Comment(id='k2fv5yf'), Comment(id='k2fvb1l'), Comment(id='k2g5kd3'), Comment(id='k2fv1z4'), Comment(id='k2g3xyr'), Comment(id='k2fvgo8'), Comment(id='k2g7yi9'), Comment(id='k2gqjfm'), Comment(id='k2invfu'), Comment(id='k2g9swo')]"
16sxkh1,alpha-gamma-x,,2023-09-26 19:35:59+00:00,False,,False,False,True,False,/r/datascience/comments/16sxkh1/how_to_fill_nonobvious_gaps_in_my_ds_knowledge/,How to fill non-obvious gaps in my DS knowledge? Any study lists?,"I got a BS degree on a data science related field but I still find some gaps in my knowledge, that frankly seem embarrasing. For instance, I can use libraries with ease, but might have difficulties calculating some probability function or using the shell. I also didn’t have the chance to use remote servers in the past, and I am not sure I would do well in any company that has lots of data (i.e. I have gaps in memory usage, etc.).

I made a study list based on my gaps in knowledge, but sometimes it’s hard to see things I don’t know (because I don’t know them). I would like to see your study guides / plans, for either interview prep or just learning DS/DE. That may give some ideas on what I am missing.

Alternatively, can someone just list out a few things that you do at your DS job that are non-obvious (i.e. i know most of you do modeling, but what steps before/after modeling people with less experience tend to miss)?

I know that it’s probably best to explore my gaps through actually working, but my current role is program management and I have little to nothing to do in my daily responsibilities with DS. Just trying to learn on my own. 

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16sxkh1/how_to_fill_nonobvious_gaps_in_my_ds_knowledge/,6,5,0.78,"[Comment(id='k2cjuic'), Comment(id='k2dhk5r'), Comment(id='k2ea03o'), Comment(id='k2n5lsz'), Comment(id='k2itev7'), Comment(id='k2eac1v')]"
16ta05a,Ok_Unit7169,,2023-09-27 03:52:32+00:00,False,,False,False,True,False,/r/datascience/comments/16ta05a/how_important_is_statelessness_on_reducers_in/,How important is statelessness on reducers in MapReduce process with parallel processing?,,datascience,https://www.reddit.com/r/datascience/comments/16ta05a/how_important_is_statelessness_on_reducers_in/,0,1,1.0,[]
16t0xc9,GetFkedPlease,,2023-09-26 21:39:02+00:00,False,,False,False,True,False,/r/datascience/comments/16t0xc9/what_is_my_job_title/,What is my job title?,"I work in the semi-conductor industry and last year I switched from my FSE Technical Supervisor role, to a Data Analyst/ Diagnostics Analyst role where we remotely troubleshoot our etch equipment based on the logs and data sent from the customer. 

Everyone hired on this team has 20+ years of technical support/ FSE experience except me. The reason I was hired is because I have 8 years experience as an FSE, but I am a Computer Science student with programming experience. My bosses goal was for me to create data products that our analysts can use. 

This is so awesome because I essentially get to build a fantastic resume while finishing school for future computer science related jobs, without having to go work an entry level job elsewhere and take a paycut after school.

I started this role October 1st, 2022, and my goal is to finish my degree by October 1st, 2024 and find another job based off of 2 years experience with my current 'X' role (Don't know what to label it as). 

My daily tasks are normal diagnostics stuff, but in the meantime/ extra time I create data products. One product was a workflow/ script that ingests tabular files with all of the down equipment in our customers facility and compares it to our CRM database to see what cases we need to open and provide insight on and which we need to close. Before this, the guys were literally manually comparing each line of reportred down equipment (hundreds of lines) to each case in our database (thousands) and seeing what does and does not exist and acting accordingly. This program I created saves an estimated 500+ work hours per year. 

I've also created standardized forms where our guys enter in applicable data about equipment errors, and it outputs a standardized entry for our cases on CRM so the info can be easily parsed and used for PBI dashboards that we present to the customer. 

I've now gotten the ok from my boss to basically completely stop with diagnostics work and only do data product engineering. My next projects are:

1. Setting up pipelines to ingest csv data from our customer and automatically create cases in CRM for three different types of data we get (work content reduction, normal equipment cases, and niche equipment cases).

2. Work with our companies actual data engineering team to create a pattern matching/ ML application that will ingest the down equipment I mentioned earlier and automate the game plan based off our historical cases. Then, set up pipelines that feed the tabular file containing down equipment mentioned earlier into the ML application so it's automated from start to finish. 

I'm super excited about getting to work on all of this and learn about all the different skills and approaches, but I have no idea what my job title should be on my future resume, if what I'm doing is valuable for finding another job in 2024, and what jobs would offer the highest salary based on this experience. I'm assuming data engineer, but I have no idea.

Can anyone offer some insight please? 

My long term goal is machine learning for a career. I plan to get an MS in Data Science/ Analysis since an MS in Machine Learning doesn't really exist yet.",datascience,https://www.reddit.com/r/datascience/comments/16t0xc9/what_is_my_job_title/,1,2,0.76,[Comment(id='k2dn766')]
16suvck,AZForward,,2023-09-26 17:54:24+00:00,False,,False,False,True,False,/r/datascience/comments/16suvck/does_it_make_sense_to_use_sequential_feature/,Does it make sense to use sequential feature selection if the model uses a boosting algorithm?,"So I started a new role recently where the forecasting pipeline runs SFS to create multiple datasets which are then fed to Xgboost models. This pipeline is run weekly, where the data is processed and then new models are trained. This seems odd to me bc Xgboost already does feature selection in a way. I would expect SFS to perhaps be used when beginning a project to help understand the data, but once that understanding is complete and the features are selected, when the pipeline is run, only create those features and update the model as needed.

I haven't found anything online where people use both of these methods. From what I've seen, people will use SFS for linear models. Lots of tutorials of people using boosting models as a method of feature selection by using feature importances, but I've yet to find anything like what I'm seeing in this project.

So, am I missing something to understand the value that SFS can bring when combined with a boosting algorithm? Or is my intuition correct that there is some redundancy in this pipeline and it can be simplified?",datascience,https://www.reddit.com/r/datascience/comments/16suvck/does_it_make_sense_to_use_sequential_feature/,2,3,1.0,"[Comment(id='k2bqog6'), Comment(id='k2ciopn')]"
16sqvmg,King_2000,,2023-09-26 15:20:38+00:00,False,,False,False,True,False,/r/datascience/comments/16sqvmg/applying_to_same_company_after_getting_not_incline/,Applying to same company after getting not incline,"I got a not inclined decision from a FAANG internship this summer. I will graduate this December and am looking for jobs, have already applied to over 200 companies in over 500 positions. Have optimized my resume, use referrals to apply and tailor my profile to the role. 
My question: can I still apply to full time positions at the same company that gave me a not incline? I interned as an L4 DS intern and will now apply for L4 DS position in the other departments. Will this work or would I not be considered since I recently got a not incline? 

Thanks for your help!",datascience,https://www.reddit.com/r/datascience/comments/16sqvmg/applying_to_same_company_after_getting_not_incline/,5,4,0.75,"[Comment(id='k2apb8h'), Comment(id='k2cluow'), Comment(id='k2d9xhu'), Comment(id='k2cmyfe'), Comment(id='k2cn54o')]"
16ru5ur,Excellent_Cost170,,2023-09-25 14:48:55+00:00,False,,False,False,True,False,/r/datascience/comments/16ru5ur/is_ml_code_really_5_of_ml_system/,is ML code really 5% of ML system?," 

Google says ML code is less than 5% of the code of ML system? Here is the quote: 'the real challenge isn't building an ML model, the challenge is building an integrated ML system and to continuously operate it in production.' How has this perspective aligned with your experience?

 

https://preview.redd.it/ptgi4hzazeqb1.png?width=1318&format=png&auto=webp&s=a818974f889b6bc648a73a1e23e0c139a0710dfa",datascience,https://www.reddit.com/r/datascience/comments/16ru5ur/is_ml_code_really_5_of_ml_system/,73,189,0.95,"[Comment(id='k256cpe'), Comment(id='k2586mx'), Comment(id='k25cky5'), Comment(id='k25acsz'), Comment(id='k25a2ks'), Comment(id='k25cfk5'), Comment(id='k25fkdf'), Comment(id='k257pl9'), Comment(id='k26edrp'), Comment(id='k25imso'), Comment(id='k263yt2'), Comment(id='k26o26g'), Comment(id='k25kar7'), Comment(id='k2612dq'), Comment(id='k269gxd'), Comment(id='k25j0e3'), Comment(id='k264em3'), Comment(id='k26a3z9'), Comment(id='k26pq86'), Comment(id='k27um0j'), Comment(id='k295sty'), Comment(id='k262cdh'), Comment(id='k29ae5w'), Comment(id='k270fop'), Comment(id='k25jn5a'), Comment(id='k25o213'), Comment(id='k267fce'), Comment(id='k26cn91'), Comment(id='k26q2n0'), Comment(id='k26v5d9'), Comment(id='k26wax3'), Comment(id='k277qgu'), Comment(id='k279be6'), Comment(id='k286jmu'), Comment(id='k28gk8j'), Comment(id='k28qlr1'), Comment(id='k292k58'), Comment(id='k2e22ll'), Comment(id='k2eidy7'), Comment(id='k2t420w'), Comment(id='k25yvjv'), Comment(id='k260fk5'), Comment(id='k25kpk5'), Comment(id='k25hat5'), Comment(id='k25kt4m'), Comment(id='k25ajfw'), Comment(id='k25cuv7'), Comment(id='k28iryg'), Comment(id='k29182y'), Comment(id='k2704a2'), Comment(id='k28jj1a'), Comment(id='k2bs7tt'), Comment(id='k25r9gt'), Comment(id='k25ylrt'), Comment(id='k26xta1'), Comment(id='k27np8z'), Comment(id='k2acnjf'), Comment(id='k270yst'), Comment(id='k293ewu'), Comment(id='k25k5lf'), Comment(id='k2679uw'), Comment(id='k25pqmz'), Comment(id='k25b8xr'), Comment(id='k25l2c2'), Comment(id='k29ma98'), Comment(id='k25n1hw'), Comment(id='k28rue7'), Comment(id='k282u00'), Comment(id='k29445q'), Comment(id='k26353y'), Comment(id='k25ndjr'), Comment(id='k29smpk'), Comment(id='k29so27')]"
16sw0w3,Muhammad_Gulfam,,2023-09-26 18:37:26+00:00,False,,False,False,True,False,/r/datascience/comments/16sw0w3/image_segmentation_iou_calculation/,Image Segmentation IoU calculation,"In image segmentation, while calculating IoU do the background pixels count? or do we just consider the foreground part of the ground truth?

What is the best approach?",datascience,https://www.reddit.com/r/datascience/comments/16sw0w3/image_segmentation_iou_calculation/,0,1,1.0,[]
16taani,Old-Food2140,,2023-09-27 04:06:38+00:00,False,,False,False,True,False,/r/datascience/comments/16taani/is_a_data_science_degree_worth_it_in_2023/,Is a Data Science degree worth it in 2023?,"I’m currently a senior in high school. I’ve taken 2 classes on Data Science and enjoy it. I’m a big math and business guy and I believe that this field can combine the two.

 However is the degree worth it? I see a lot of info out there saying Data Science isn’t a sustainable field. I want to convince myself that this is misinformation but am unsure.

Secondly for me is the lifestyle/salary part. I’ve seen a lot of job opportunities for DS that work remotely. Im a big skier and see this as an opportunity to live closer to the mountains. But with that is their chances for high salaries with that? This might seem like a dumb question but looking ahead, I have expensive hobbies. I want to make sure there is a good ladder for me to climb to be eventually making great money to set myself + future family up no matter what.",datascience,https://www.reddit.com/r/datascience/comments/16taani/is_a_data_science_degree_worth_it_in_2023/,22,0,0.33,"[Comment(id='k2e0wtg'), Comment(id='k2ecta4'), Comment(id='k2edlic'), Comment(id='k2e4cdb'), Comment(id='k2ed589'), Comment(id='k2elem7'), Comment(id='k2ei2nl'), Comment(id='k2e1kgv'), Comment(id='k2edtz7'), Comment(id='k2enypu'), Comment(id='k2ewnuf'), Comment(id='k2eg89f'), Comment(id='k2f7s2p'), Comment(id='k2fxrsf'), Comment(id='k2ghzvn'), Comment(id='k2g85n9'), Comment(id='k2f2yvv'), Comment(id='k2ftm7p'), Comment(id='k2ekz87'), Comment(id='k2g94b1'), Comment(id='k2fq1e8')]"
16shvtc,No_Boysenberry_7138,,2023-09-26 08:23:27+00:00,False,,False,False,True,False,/r/datascience/comments/16shvtc/what_are_some_lesser_known_but_very_useful_data/,"What are some lesser known, but very useful data science tools in python?",,datascience,https://www.reddit.com/r/datascience/comments/16shvtc/what_are_some_lesser_known_but_very_useful_data/,1,4,1.0,[]
16s2ex1,ljc4343,,2023-09-25 20:07:39+00:00,False,,1695691679.0,False,True,False,/r/datascience/comments/16s2ex1/is_grad_school_worth_it/,Is Grad School Worth It?,"I’m in my final year of undergrad, getting my degree in political science with a minor in data analytics. I am planning on at least applying to the Data Science M.S. program my school has, but is it a good idea for me to go?

Some factors:

1. It’s a year long program and I’m graduating w my bachelors in 3 years, so i would get to keep my on campus jobs (including being an RA, so free room+board) plus I would still be graduating at 22 (with all my friends, even if it’s a different ceremony)
2. It would cost about \~18k for tuition and fees with the guaranteed aid i would get. This is my biggest hesitation-  I could probably get some job, even though it wouldn't be in DS and make some money instead of taking out more student loans.
3. I believe I am pretty likely to get into the program- i met with an admissions counselor for the fast-track program they offer and he said my profile looked good (my GPA has gone up since this meeting) and they were generally pretty accepting of undergrads from my school.
   1. I decided against the fast track program because i did not feel i had enough time in my schedule to add on 6 grad credits this year.
4. I really want to get into DS, and that feels pretty impossible with my current degree track.
5. For my DA minor, i have taken some DS classes and I have done well and really enjoyed them.
6. The only data-realted semi-professional experience I have is working as a reserach assistant and cleaning and doing a bit of analysis on old political datasets.

Thoughts? Would appreciate any feedback!

edit: the school im at is Syracuse",datascience,https://www.reddit.com/r/datascience/comments/16s2ex1/is_grad_school_worth_it/,47,23,0.76,"[Comment(id='k273n7h'), Comment(id='k2712e5'), Comment(id='k27x9ms'), Comment(id='k280wzc'), Comment(id='k278k0b'), Comment(id='k26pgsf'), Comment(id='k27ztk6'), Comment(id='k29q8px'), Comment(id='k28nf6x'), Comment(id='k28tzua'), Comment(id='k28v42e'), Comment(id='k288yce'), Comment(id='k2awvi5'), Comment(id='k2ba33f'), Comment(id='k272w0j'), Comment(id='k28m87l'), Comment(id='k27xqgz'), Comment(id='k27y9yb'), Comment(id='k280y4z'), Comment(id='k27jvri'), Comment(id='k26q1up'), Comment(id='k2aprqo'), Comment(id='k2bx08a'), Comment(id='k2bx6pf'), Comment(id='k2765dg'), Comment(id='k27je2y'), Comment(id='k28miqa'), Comment(id='k27yy86'), Comment(id='k27stoe'), Comment(id='k26r0rv'), Comment(id='k2bfok2'), Comment(id='k276zom'), Comment(id='k279ymc'), Comment(id='k27iykt'), Comment(id='k2ao1gc'), Comment(id='k278gsw'), Comment(id='k28pfwk'), Comment(id='k27adje'), Comment(id='k27jm3q'), Comment(id='k2ar3aa'), Comment(id='k2balde'), Comment(id='k28qn8m'), Comment(id='k27k6zh'), Comment(id='k2bktax'), Comment(id='k27l1us'), Comment(id='k2bll19'), Comment(id='k27lpvc'), Comment(id='k2bv7ae'), Comment(id='k27xn8h'), Comment(id='k285dep'), <MoreComments count=0, children=[]>]"
16rvrrx,ruckrawjers,,2023-09-25 15:50:57+00:00,False,,1695658702.0,False,True,False,/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/,Anyone else here bogged down with adhoc SQL requests at work?,"Co-founder and I are working on something that solves this problem (AI data analyst), curious if anyone else here facing the same issue? Our business users aren't SQL savvy, we deploy self service tools but seems learning curve there are too steep still. The adhoc SQL requests never end!

 Would love to connect and learn more!",datascience,https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/,43,53,0.86,"[Comment(id='k25oueq'), Comment(id='k25i3g2'), Comment(id='k261gvz'), Comment(id='k262cdl'), Comment(id='k25vvp8'), Comment(id='k27x5xn'), Comment(id='k25xzdz'), Comment(id='k26mlxl'), Comment(id='k27c5ad'), Comment(id='k28gqrl'), Comment(id='k278zb2'), Comment(id='k272vli'), Comment(id='k27x4a4'), Comment(id='k26hevt'), Comment(id='k27aasp'), Comment(id='k27upxo'), Comment(id='k28kcf2'), Comment(id='k29q5x3'), Comment(id='k2fyjym'), Comment(id='k25wldj'), Comment(id='k25x143'), Comment(id='k25wqq4'), Comment(id='k26pg4c'), Comment(id='k26p6kn'), Comment(id='k27axxg'), Comment(id='k26p8le'), Comment(id='k27as1l'), Comment(id='k25xchj'), Comment(id='k25zcu1'), Comment(id='k27o64r'), Comment(id='k28zb1c'), Comment(id='k27cl7l'), Comment(id='k26h5cb'), Comment(id='k26pfxf'), Comment(id='k27mkgi'), Comment(id='k27r8ki'), Comment(id='k2a1sde'), Comment(id='k26pd2u'), Comment(id='k27zr5e'), Comment(id='k27zvux'), Comment(id='k26prl0'), Comment(id='k298i4r'), Comment(id='k271223'), Comment(id='k2a00rv')]"
16rqnla,twitch-flystewie,,2023-09-25 12:26:54+00:00,False,,False,False,True,False,/r/datascience/comments/16rqnla/how_do_you_handle_big_data_in_jupyter_notebook/,How do you handle big data in Jupyter notebook?,"I’m wondering how everyone handles big data. I have 12 csvs each 90 mbs each. I’ve done some analysis imported a couple individually but of course the combine csv script I use to union them on is pretty slow. 

Directly importing from sql is doable but slow as well. I’m relatively new at work but just wondering what everyone else does whether they just look at smaller subsets of their data at a time or they use dask instead of pandas",datascience,https://www.reddit.com/r/datascience/comments/16rqnla/how_do_you_handle_big_data_in_jupyter_notebook/,75,94,0.94,"[Comment(id='k2545q4'), Comment(id='k250c3y'), Comment(id='k24p7cj'), Comment(id='k258g5f'), Comment(id='k25pcoc'), Comment(id='k25be11'), Comment(id='k2624o5'), Comment(id='k25vg93'), Comment(id='k26vkgv'), Comment(id='k2737x2'), Comment(id='k276vc2'), Comment(id='k27a7qi'), Comment(id='k28akaf'), Comment(id='k28hqlm'), Comment(id='k2dh8gu'), Comment(id='k24luku'), Comment(id='k26fuyv'), Comment(id='k257mgi'), Comment(id='k25wwl5'), Comment(id='k25r08b'), Comment(id='k24nz1b'), Comment(id='k2574mu'), Comment(id='k260adm'), Comment(id='k289hlb'), Comment(id='k28tpbn'), Comment(id='k28wag0'), Comment(id='k28wksq'), Comment(id='k29821y'), Comment(id='k29ca1u'), Comment(id='k25agfl'), Comment(id='k25a6ot'), Comment(id='k280jgi'), Comment(id='k24zl1t'), Comment(id='k25l3rk'), Comment(id='k28f8fy'), Comment(id='k26fzdm'), Comment(id='k29chia'), Comment(id='k2f09yz'), Comment(id='k29fhbu'), Comment(id='k27rkw1'), Comment(id='k252eam'), Comment(id='k2593e2'), Comment(id='k256qui'), Comment(id='k24y7zu'), Comment(id='k27x2st'), Comment(id='k251fu6'), Comment(id='k3atir3'), Comment(id='k25j1b2'), Comment(id='k24p08m'), Comment(id='k25p5tr'), Comment(id='k29kv7u'), Comment(id='k282q10'), Comment(id='k28ydgl'), Comment(id='k2afaw0'), Comment(id='k26ijiw'), Comment(id='k2g9qwm'), Comment(id='k2914ix'), Comment(id='k255nl2'), Comment(id='k25onrx'), Comment(id='k25oiy4'), Comment(id='k2508hi'), Comment(id='k282f2j'), Comment(id='k25praa'), Comment(id='k2586ni'), Comment(id='k289s2n'), Comment(id='k2atg7t'), Comment(id='k2av5df'), Comment(id='k29o0un'), Comment(id='k25izmo'), Comment(id='k25m2co'), Comment(id='k28aaii'), Comment(id='k28cn0u'), Comment(id='k2ban06'), Comment(id='k29tfbh'), Comment(id='k25krgt')]"
16s0csk,Difficult-Big-3890,,2023-09-25 18:47:37+00:00,False,,False,False,True,False,/r/datascience/comments/16s0csk/how_do_you_avoiddeal_with_the_discussion_of/,How do you avoid/deal with the discussion of causality when the project goal was predictive performance to start with?,"Have had quite a few experiences when a project starts with the goal of predictive performance but at the end causal questions were thrown at to answer based on the model. 

""When users are looking for casual relation, use Linear models e.g. MLR/Logit"" seems like a commonly given advice for such cases. But, throwing linear models without a proper experimental design, which is often out of scope, doesn't really give any realistic causal effect - think of Simpsons paradox. 

So, am I missing somethig here? What's your go to approach in such cases?",datascience,https://www.reddit.com/r/datascience/comments/16s0csk/how_do_you_avoiddeal_with_the_discussion_of/,36,27,1.0,"[Comment(id='k26hq11'), Comment(id='k28h5a8'), Comment(id='k27sdbd'), Comment(id='k27ugq2'), Comment(id='k2bj2os'), Comment(id='k2ao5yk'), Comment(id='k273wb0'), Comment(id='k28r90p'), Comment(id='k275mqv'), Comment(id='k281pat'), Comment(id='k28orn0'), Comment(id='k297ppw'), Comment(id='k27v9fh'), Comment(id='k26oxpz'), Comment(id='k2bvamh'), Comment(id='k2awo3d'), Comment(id='k278j6o'), Comment(id='k27gyat'), Comment(id='k27ezlb'), Comment(id='k282j5z'), Comment(id='k26vodh'), Comment(id='k294qx5'), Comment(id='k2a0b87'), Comment(id='k27adhl'), Comment(id='k27hiwx'), Comment(id='k27qpkt'), Comment(id='k27lzl1'), Comment(id='k27h4qd'), Comment(id='k284bpc'), Comment(id='k285il4'), Comment(id='k28qf6h'), Comment(id='k277uxh'), Comment(id='k29u3l0'), Comment(id='k2awisy'), Comment(id='k2812w9'), Comment(id='k284wce')]"
16sdcnt,Ok_Post_149,,2023-09-26 03:58:15+00:00,False,,False,False,True,False,/r/datascience/comments/16sdcnt/what_type_of_project_excites_you/,What type of project excites you?,"Over the last couple of months I've had a few motivational rollercoasters. One week I'm heads down and flying through my work, I absolutely love it. Other weeks it can't go by any slower and my motivation is super low. 

I started to realize that my shifts in motivation were project driven. When I genuinely like a project work is fun for me. When I hate the project it is the last thing I want to do. 

For me, my favorite projects are building web scrapers, preprocessing super messy data, and building visualization dashboards. At the moment I'm a Business Intelligence Manager, I'm considering shifting over to Data Engineering because that type of work just seems so much more fun to me. ",datascience,https://www.reddit.com/r/datascience/comments/16sdcnt/what_type_of_project_excites_you/,2,2,0.75,"[Comment(id='k28seid'), Comment(id='k28s7q4')]"
16sdaje,Open-Caterpillar3098,,2023-09-26 03:55:07+00:00,False,,False,False,True,False,/r/datascience/comments/16sdaje/data_registry_suggestions_for_ml_projects/,Data Registry suggestions for ML projects,"Looking for suggestions for data registry, with following requirements -

- Programmatic access for both read and write data back (DVC only provides reading data from repo)

- Versioning of all kinds of data (csv, text, images). MLflow provides a workaround to store data as artifacts - Is that good enough ?

- Data access control (user level access, both internal and external to projects) where clients can upload the data directly and DS teams can use it for experiments. 

- On premise solution with container support is preference. 

As of now, I have evaluated DVC, modelstore and mlflow. Please provide inputs",datascience,https://www.reddit.com/r/datascience/comments/16sdaje/data_registry_suggestions_for_ml_projects/,4,2,1.0,"[Comment(id='k2j4ivz'), Comment(id='k296don'), Comment(id='k2dl4fq'), Comment(id='k2d1slv')]"
16sd43a,Terrible-Hamster-342,,2023-09-26 03:45:52+00:00,False,,False,False,True,False,/r/datascience/comments/16sd43a/how_did_you_succeed_in_a_new_role_what_lessons/,How did you succeed in a new role? What lessons did you take from your previous role?,"When switching to a new role what did you do to ensure that you succeed? What lessons did you learn from your previous job that you took into your new job? 

For example Im in the process of switching jobs and one of the things I’ve learnt is that when delivering results (during fire drills) the way I write my code is focused on simply getting the results out vs being organized, efficient and scalable. While I get from point A to point B the way I get from point A to point B is not the most efficient. I think something I can do is take a step back and take a top down approach to problem solving when I enter my new role.",datascience,https://www.reddit.com/r/datascience/comments/16sd43a/how_did_you_succeed_in_a_new_role_what_lessons/,2,2,1.0,"[Comment(id='k29pa79'), Comment(id='k2aqs93')]"
16sfxuq,BusfahrerBernd999,,2023-09-26 06:20:32+00:00,False,,False,False,True,False,/r/datascience/comments/16sfxuq/power_bi_vs_tableau/,Power BI vs Tableau,"Hey everyone, so I have the opportunity to work more on data within my current job. I would be the only one in that type of field and would love to gain as much knowledge as I can to maybe later transition fully into a career in data. Should I choose to become an “expert” in Power BI or Tableau and why?

Thank you for your advice",datascience,https://www.reddit.com/r/datascience/comments/16sfxuq/power_bi_vs_tableau/,22,2,0.62,"[Comment(id='k290dwq'), Comment(id='k2a1pot'), Comment(id='k294v49'), Comment(id='k2cedpe'), Comment(id='k2dwbtc'), Comment(id='k2acync'), Comment(id='k2aijzt'), Comment(id='k29z9wh'), Comment(id='k2agxbq'), Comment(id='k2ai1x7'), Comment(id='k2az9a7'), Comment(id='k2atec4'), Comment(id='k2a8ijr'), Comment(id='k2a8x4h'), Comment(id='k2a1xd1'), Comment(id='k2aa604'), Comment(id='k2aazbp'), Comment(id='k2a6nkf'), Comment(id='k2abj1n'), Comment(id='k2a97m2'), Comment(id='k2abypg'), Comment(id='k2b0uje')]"
16s8ndq,Internal_Flower67,,2023-09-26 00:17:31+00:00,False,,False,False,True,False,/r/datascience/comments/16s8ndq/advice_on_comparing_time_series_datasets/,Advice on Comparing Time Series Datasets,"I am working on my master's degree and I have some data that I have no clue how to handle. Any advice would be appreciated.

I have triaxial accelerometer data(50 hz) for some quadruped animal along with internal body temperature (every 5 minutes). I have multiple days worth of this data, and am trying to look at the affect of activity on body temperature. Ideally, we should see activity rise, followed by temperature, and both will fall together as well.

I have already calculated energy: sqrt(x^2 + y^2 + x^2) and averaged that for every 5 minutes, so the activity and temp intervals match. Is this a good approach?

Also, how do I compare these datasets while accounting for the ""lag"" or affect of previous activity on current temperature? I'm not having any luck searching for methods to analyze this data.

Any help or suggestions are appreciated!",datascience,https://www.reddit.com/r/datascience/comments/16s8ndq/advice_on_comparing_time_series_datasets/,4,3,1.0,"[Comment(id='k28a5ib'), Comment(id='k28hel0'), Comment(id='k2fsnuw'), Comment(id='k2htezr')]"
16s7bx8,wolatid,,2023-09-25 23:19:35+00:00,False,,False,False,True,False,/r/datascience/comments/16s7bx8/nlp_data_cleaning/,NLP Data Cleaning,"I am currently using BERT model and wanted to do some data cleaning. I've tried stuff like removing punctuations and vocabulary / spell checking (e.g. pyspellchecker). However, I noticed that the 'autocorrect' function is inaccurate given also that the texts we handle are more on technical/financial terms.

Does anyone have a suggestion on how to further process the texts? There are also some texts there that are actual sql / python codes so I'm not sure how to eliminate those.

I am somehow contemplating to not do further text cleaning and just deal more on tweaking the hyperparameters instead.",datascience,https://www.reddit.com/r/datascience/comments/16s7bx8/nlp_data_cleaning/,3,3,1.0,"[Comment(id='k29qyly'), Comment(id='k2caixa'), Comment(id='k2ell3w')]"
16sdupt,haris525,,2023-09-26 04:24:21+00:00,False,,False,False,True,False,/r/datascience/comments/16sdupt/cross_encoders_for_long_documents_and_pragagraphs/,Cross Encoders for Long documents and pragagraphs,"Hi guys good evening, hope all is well! 

I need some opinions on using cross encoders for long text documents. I have a case where I have list of documents called documents A, and another list of documents called documents B. Based on semantic similarity I am developing a model that matches documents from list A to list B. Here is my current approach

&#x200B;

First I use a Bi-Encoder to encode both lists of documents (using the sentence-transformers/gtr-t5-xl)

Then I use FAISS to get top 100 results from the Bi-Encoder

Finally use a Cross-Encoder to re-Rank the documents returned 

Now my question is Cross-Encoders are usually good for a token limit of 1024 or less, but I am wondering is there a better way to compare longer documents? lets say if I was comparing math books for grade 10 in list A, and math books for grade 11 in list B, so see if there are any books that are similar in semantic context in list A, and B to see which books are like each other what approach should I take? 

Would moving to a vector database be the next best thing as I can keep adding to the database index as new documents are added? 

&#x200B;

Thanks, and would to hear your opinion",datascience,https://www.reddit.com/r/datascience/comments/16sdupt/cross_encoders_for_long_documents_and_pragagraphs/,0,1,1.0,[]
16rt739,artemis268,,2023-09-25 14:10:58+00:00,False,,False,False,True,False,/r/datascience/comments/16rt739/stuck_in_an_internship_with_no_data_science_work/,Stuck in an internship with no data science work,"

I'm doing an internship at this company which pays me an ok amount. Its a 3 month internship and the period is about to be over. Issue is that they give me 0 work. Also due to certain reasons they put me in an unrelated to my work department, so it's not like the work I would have done there would have mattered that much. 

I couldn't get any other internship as this was the best brand name and stipend I could get and the  placement  season is also over so I continued here considering the alternative is me sitting at home for 3 months. 

So my routine has been, come to office, learn my own skills, go home, I don't even see my manager anymore and he doesn't even care because they don't even require me. I have learnt a shit ton during this period and built a portfolio,  i spent all this office time to skill up and made myself competitive in the job market.

Problem is I have only 2 lousy project which I was asked to do to show as my internship expirience. Need your perspective, did I make a huge mistake in doing this and should have asked for more work from office even if it was in unrelated field and meangless?? 

I'm worried about what to say and show in my internship experience, when I talk to recruiters, is it possible to just lie and make up things you din in internship?? I'm planning on just making up fake lists of relevant tasks on my internship expirience section. 

Am i fucked or what? Idk. Sometimes i think im being smart, sometimes I'm think I'm a dumbfuck who focused on self learning instead of corporate projects. Helpp.",datascience,https://www.reddit.com/r/datascience/comments/16rt739/stuck_in_an_internship_with_no_data_science_work/,6,14,0.94,"[Comment(id='k252el0'), Comment(id='k25qb6u'), Comment(id='k26h7c2'), Comment(id='k276zgz'), Comment(id='k2575r9'), Comment(id='k2592mv')]"
16rjh59,Imaginesafety,,2023-09-25 05:29:33+00:00,False,,False,False,True,False,/r/datascience/comments/16rjh59/are_career_fairs_worth_it/,Are career fairs worth it?,"Graduate in December with MS and have a career fair opportunity this week. As I attend remotely, campus is 4 hours away. I'd have to do the drive there and back in the same day, so I want to know if there's potential for me to actually get value, or if I'll likely be wasting my time. I understand I'll have to make the best of it, and I'm confident I will, but I really just want to know if success stories in this field happen from networking at career fairs.

I don't have any leads yet, just been blindly applying online. A couple of rejections, but haven't heard back from a majority of applications which are probably ghost. Not much relevant experience in the field, trying to start out as a DA. Thoughts?",datascience,https://www.reddit.com/r/datascience/comments/16rjh59/are_career_fairs_worth_it/,29,42,0.92,"[Comment(id='k23nchm'), Comment(id='k23pimg'), Comment(id='k24fpdz'), Comment(id='k23o2ag'), Comment(id='k24mkhv'), Comment(id='k24v4g9'), Comment(id='k23pu6y'), Comment(id='k24uzsr'), Comment(id='k25e5gq'), Comment(id='k27zf5b'), Comment(id='k251lro'), Comment(id='k260mnn'), Comment(id='k26zhxn'), Comment(id='k29a53d'), Comment(id='k29c4n2'), Comment(id='k23pkvo'), Comment(id='k23ptay'), Comment(id='k24ajaq'), Comment(id='k23pgn2'), Comment(id='k24erf9'), Comment(id='k23qdbd'), Comment(id='k25h7qp'), Comment(id='k23vlgu'), Comment(id='k25eh4w'), Comment(id='k23q13d'), Comment(id='k23qy4x'), Comment(id='k2acrf4'), Comment(id='k25yijg'), Comment(id='k23syd1'), Comment(id='k2anaah')]"
16s724v,rojosquid,,2023-09-25 23:07:46+00:00,False,,False,False,True,False,/r/datascience/comments/16s724v/sanity_test_dummyclassifier/,"Sanity Test, DummyClassifier"," I  was advised to use DummyClassifier for a sanity test on the best model;  however I'm having a hard time finding instructions as of how to use it  and how to evaluate the results of said test.

Help.

Thanks!",datascience,https://www.reddit.com/r/datascience/comments/16s724v/sanity_test_dummyclassifier/,0,1,1.0,[]
16rzglu,Senande,,2023-09-25 18:12:54+00:00,False,,False,False,True,False,/r/datascience/comments/16rzglu/modern_time_series_forecasting_with_python_book/,Modern Time Series Forecasting With Python (Book Review),"TLDR for those who don't want to read the whole thing: This is a nicely written book that exposes you to a lot of concepts but fails to teach them to you while providing abstract code that can only be understood after reading through all the custom functions and classes that the author uses.

&#x200B;

I will start by giving you some context:

I switched from economics to statistics this year while only having seen econometrics 1 meaning I had no prior theoretical knowledge of time series analysis but was interested on the field nonetheless. Since I was planning to learn how to code this summer, I bought this book to use it when I had the basics under control.

By the time late july had set I knew the basics of python and the book didi not ask more than that, ""*Since the book explains most concepts from the ground up, basic proficiency in Python is all you need. ""* on the author's own words. I started reading the book around that time and to be completely honest; my opinion from it was at the highest before reading and it only went downwards the more I advanced with it.

The first chapters consist of the basics of time series data (Barely any depth) followed by some preprocessing steps in which the author tries to teach the basics of missing value handling and visualization of the components of the data, ending the first section by exposing some of the classical models. All of this was done in 105 pages! 

The next section of this book exposes machine learning concepts for time series; this is where the two main problems I have with this book start to become apparent:

1- The explanations are very concise; which for complex subjects such as the ones the book covers it really becomes a problem.

2- The book uses an excessive amount of custom functions and classes by the author.

&#x200B;

**1.1 The book is way too short for the amount of content it pretends to teach.**

First things first; *how long* is the book? 

While in Packt's website and Amazon the book is said to be 552 pages long, the actual content of the printed copy I have is 505 pages; for 40€/$ this seems like a pretty nice deal; the problem is that if you look at the sheer amount of stuff this contains; it looks too good to be true; it is. The way so much content is compressed into the book is by cutting off a lot of the meat of what it is trying to teach; this is why I say that the book exposes you to a lot of concepts but fails to teach them to you; 500 pages is not enough for a book that teaches you basic analysis, ML and DL from the ground up, But how egregious can this be? There is only a single 28 pages long chapter for classical statistical models; the explanation for ARIMA is two pages long; this is how bad it gets. You could say that this book is specialized in ML and DL and you would be correct in that statement but the ML part is 154 pages long and the DL one is 194; it's simply too short with its explanations and it makes the book outright frustrating to follow once you reach the Deep Learning section. 

&#x200B;

**1.2 The book has an identity crisis regarding the group it's marketed towards.**

In the amazon page, it says that the book is directed towards Data Scientists but that everything is explained from the ground up so only the basics of Python Programming are strictly needed even though knowledge of ML would help.

Ok, so what is it? I can tell you that the book is overwhelming for beginners; not because the models are explained at their full complexity but because it is done way too fast. Is it for experienced data workers who want to learn time series? Well, you've got some pages dedicated to basic pandas commandas and ML and DL are ""taught"" from the ground up while almost totally neglecting the classical models and any kind of inference so not really. The amazon page says ML knowledge is is recommended and I'd say that maybe if you've reached that point then you may understand the book but for beginners it's simply inaccesible.

It's not just ML though; the book uses Plotly for visualizations; If you know basic python you will most likely go the matplotlib route and showing plotly code without explaining it is a decision that shows even more how this book simply is not for beginners.

The book just explains badly; I am taking the edX MIT Machine Learning Course and while it is more complex; it is perfectly understandable; this book just half-explains stuff and while people who know what they are doing may be able to cope with it, I get the feeling that if you understand the concepts the book is teaching then it may be because you have already moved past them.

&#x200B;

**2. The unbearable custom code**

Up to here I could maybe understand that the explanations simply weren't from me and the book may be better under other people's eyes but it is not the explanations that I find severely short and lacking the largest problem I have with this book; it is the code it uses.

Right from the first  coding chapter the author uses custom functions and classes and it is extremely frustrating. To deal with time series in ML the author uses his own code and while it may be more comfortable, you have to know how to use it and there lies a huge problem; the functions and classes DO NOT have docstrings and because the author does not explain them properly in the book, you have to go to the function definitions to get a sense of what each component is doing. This is simply unbearable and if you do not already know ML and DL, this just adds another layer of abstraction which will make a complex part even more difficult to understand.

It is not only that they are not properly documented but they are not implemented onto a package; it despite all you still try to persevere and make real world usage of this book you will have to copy the full src folder in each folder you are going to make use of the material. The author claims that after finishing the book you are going tobe able to *""build world-class time series forecasting systems"",* But how though? Is the author really saying that you are going to need to make a package out of HIS code to make it usable? This is for me the ultimate dealbreaker.

&#x200B;

**Final comments**

&#x200B;

This was my first contact with Machine Learning and I can tell you that It's hard to think there could be a worse introduction than this. There is a point about halfway through the book in which I stopped working with the code and just decided to finish it to warn others that it simply isn't a good product. The author clearly knows what he's talking about but he but off more than what he could chew and when the best thing about the book are the references and further reading materials that the author recommends, you can see that this book simply is not good.

3.5/10, It just isn't good.

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;",datascience,https://www.reddit.com/r/datascience/comments/16rzglu/modern_time_series_forecasting_with_python_book/,3,2,1.0,"[Comment(id='k26lvup'), Comment(id='k26thd1')]"
16r5v0j,wonko_the_sane__,,2023-09-24 19:07:26+00:00,False,,False,False,True,False,/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/,What do data scientists do anyway?,I have been working in a data science Consulting startup as a data scientist. All I've done is write sql tables. I've started job hunting. I want to build AI products. What job description would that be? I know this sounds stupid but I don't want to be an analyst anymore,datascience,https://www.reddit.com/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/,93,139,0.86,"[Comment(id='k21fwx1'), Comment(id='k219dbq'), Comment(id='k21b4a3'), Comment(id='k21a4vq'), Comment(id='k21furh'), Comment(id='k21l9gd'), Comment(id='k218k56'), Comment(id='k23nok7'), Comment(id='k21q9t3'), Comment(id='k21ecyl'), Comment(id='k21npvj'), Comment(id='k21wmsv'), Comment(id='k22vm2l'), Comment(id='k21pvuj'), Comment(id='k21u49j'), Comment(id='k23va37'), Comment(id='k21zy95'), Comment(id='k22v1e6'), Comment(id='k23vhsn'), Comment(id='k24jxhs'), Comment(id='k257bnp'), Comment(id='k2fxgxz'), Comment(id='k23f9z4'), Comment(id='k21oy5h'), Comment(id='k23rhis'), Comment(id='k25aewl'), Comment(id='k22l6gv'), Comment(id='k232qpy'), Comment(id='k24eaam'), Comment(id='k24efxv'), Comment(id='k24xmer'), Comment(id='k250fn5'), Comment(id='k258l5t'), Comment(id='k25cyuw'), Comment(id='k262nq0'), Comment(id='k273cwv'), Comment(id='k294zqw'), Comment(id='k2bplnr'), Comment(id='k25y9x6'), Comment(id='k21door'), Comment(id='k21d441'), Comment(id='k22y8ko'), Comment(id='k24ovdx'), Comment(id='k263y7t'), Comment(id='k21vke2'), Comment(id='k24b4gn'), Comment(id='k24bnfw'), Comment(id='k218za5'), Comment(id='k22x74x'), Comment(id='k24bz4f'), Comment(id='k24fmf3'), Comment(id='k2b4sub'), Comment(id='k21lx54'), Comment(id='k23w1uo'), Comment(id='k21wfzj'), Comment(id='k23bpzb'), Comment(id='k24rnvf'), Comment(id='k24ye9a'), Comment(id='k25emi0'), Comment(id='k21cuef'), Comment(id='k25tla2'), Comment(id='k273mly'), Comment(id='k22xmvw'), Comment(id='k25dwrf'), Comment(id='k2r1rx4'), Comment(id='k21qsx2'), Comment(id='k22i61g'), Comment(id='k25zxrt'), Comment(id='k257blh'), Comment(id='k25016a'), Comment(id='k28isba'), Comment(id='k25k630'), Comment(id='k25fhom'), Comment(id='k22ldev'), Comment(id='k27s9zf'), Comment(id='k272zom'), Comment(id='k27s17o'), Comment(id='k265rdd'), Comment(id='k28rwsi'), Comment(id='k25mjxw'), Comment(id='k25ftq3'), Comment(id='k22xclq'), Comment(id='k27sokg'), Comment(id='k273ub9'), Comment(id='k25p7j8'), Comment(id='k25ghvx'), Comment(id='k23023e'), Comment(id='k22y8cn'), Comment(id='k274bxx'), Comment(id='k231nzk'), Comment(id='k2335wc'), Comment(id='k274mvt'), Comment(id='k24cf0a')]"
16rp7wj,MrBarret63,,2023-09-25 11:17:43+00:00,False,,False,False,True,False,/r/datascience/comments/16rp7wj/creating_insights_from_battery_monitoring/,"Creating insights from Battery monitoring parameters (State-of-charge, battery cell voltages, temperature, etc.) to use with AI or model based.","So, in a new role currently and I decided to pursue the health monitoring and impending failures of batteries (Lithium Iron Phosphate, Lithium Ion and a few lead-acid as well) but having never done it before I am not so confident on my approach.

Currently what I have in mind is using the past battery data for a specific site, I would find out the variation in SOC during charging and discharging state and compare it with current day rates while alerting for large changes.

Also, if multiple batteries are connected and while discharging/ charging their SOC deviate too far from each other (standard deviation or difference in min max) I would alert that something is not right.

A bit primitive approaches but wanted something to get going.

Would love to hear from you guys' different approaches that could be used, or you guys have used in the industry.

Thanks!  


PS. Let me know if you need more information.",datascience,https://www.reddit.com/r/datascience/comments/16rp7wj/creating_insights_from_battery_monitoring/,8,7,0.9,"[Comment(id='k24i2xv'), Comment(id='k256xzt'), Comment(id='k2efjgr'), Comment(id='k25fhah'), Comment(id='k278xdt'), Comment(id='k28zves'), Comment(id='k2ab7m8'), Comment(id='k2algau')]"
