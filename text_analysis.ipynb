{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf9daeb-3570-432f-b19b-9c1c54b50cef",
   "metadata": {},
   "source": [
    "# Introduction to Text Analysis for Python Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab56e6-b339-4000-8fd3-865061d64395",
   "metadata": {},
   "source": [
    "## What is text analysis and why do we use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d860f6-7498-4cea-a0fc-63fa64da3796",
   "metadata": {},
   "source": [
    "It is easy for machines to read data that has a simple, preconceived structure. For example, below is a table of five famous statues around the world. Each row in the table represents a different statue, and each column consistently represents a piece of information (or variable) related to the statue.\n",
    "\n",
    "We could easily use a piece of software like Microsoft Excel to answer questions about this data, such as \"Which statue was built first?\" and \"Which of the countries in this table have more statues?\"\n",
    "\n",
    "Compare it to the descriptive paragraph of text below. \n",
    "\n",
    "\"The largest statue in the world is India's Statue of Unity. It is 182 meters tall and was completed in 2018. The second largest statue comes in at 128 meters and is called the Spring Temple Buddha. It was built in China in 2008. Next is Laykun Sekkya, a statue in Myanmar that is 115.8 meters. It was also built in 2008. Built in 2020, the Statue of Belief stands in India at 106 meters tall. The fifth largest is Ushiku Daibutsu, a Japanese statue built in 1993. It is 100 meters tall.\"\n",
    "\n",
    "Although the text maintains structures inherint in language (grammar, punctuation, parts of speech, etc.) those structures are complex and inconsistent - so much so that we often refer to text as unstructured. Through text analysis, we can extract machine-readable information from unstructured text.\n",
    "\n",
    "To extract meaningful pieces of information from the paragraph in the example above, we would use a method within text analysis known as Named Entity Recognition. There are many other types of text analysis that solve various other problems. Below are the methods we will discuss in this workshop.\n",
    "\n",
    "Named Entity Recognition\n",
    "Classifies named entities found in unstructured text into pre-defined categories.\n",
    "\n",
    "Supervised Classification\n",
    "Unsupervised Classification\n",
    "Frequencies\n",
    "Collocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b80d81-71f2-49d8-b826-4c9309cc4d3f",
   "metadata": {},
   "source": [
    "## Setting up your environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367788e-dbc9-449a-b595-a4b6de0b1012",
   "metadata": {},
   "source": [
    "Before beginning this workshop, you should have experience using Python in a IDE you are comfortable with. We will be downloading and using files, so be sure you are familiar with your working directory and are downloading your files to the correct location. You should also have the following libraries installed:\n",
    "\n",
    "NLTK\n",
    "SpaCy\n",
    "\n",
    "You should also run the following lines in your terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43164f1-6808-44d8-9211-dc5bc61f1ac7",
   "metadata": {},
   "source": [
    "python -m nltk.downloader punkt\n",
    "python -m nltk.downloader maxent_ne_chunker\n",
    "python -m nltk.downloader words\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141a95-93d7-464e-bf7f-2c5b14f5acfa",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01026f-f320-4e35-9776-fc1fcd70796b",
   "metadata": {},
   "source": [
    "Let's start with the example at the beginning of this workshop. To extract meaningful information from the paragraph of text about statues, we'll use both the NLTK and SpaCy libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d59f9f7-928b-45e8-9e58-287cfef77cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "statues = \"The largest statue in the world is India's Statue of Unity. It is 182 meters tall and was completed in 2018. The second largest statue comes in at 128 meters and is called the Spring Temple Buddha. It was built in China in 2008. Next is Laykun Sekkya, a statue in Myanmar that is 115.8 meters. It was also built in 2008. Built in 2020, the Statue of Belief stands in India at 106 meters tall. The fifth largest is Ushiku Daibutsu, a Japanese statue built in 1993. It is 100 meters tall.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94722e6-3b8a-43c1-868a-2bc963f0cc00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cffbf-cab0-4792-b9b3-12b30c924e69",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tokenization is the first step in most text analysis methods. It involves breaking down our text into smaller pieces such as sentences, multi-word groups, or individual words. For this example, we'll first tokenize our text by sentences, then by individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e1bdbee-85bb-4ea9-a256-ae924ca09102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The largest statue in the world is India's Statue of Unity.\",\n",
       " 'It is 182 meters tall and was completed in 2018.',\n",
       " 'The second largest statue comes in at 128 meters and is called the Spring Temple Buddha.',\n",
       " 'It was built in China in 2008.',\n",
       " 'Next is Laykun Sekkya, a statue in Myanmar that is 115.8 meters.',\n",
       " 'It was also built in 2008.',\n",
       " 'Built in 2020, the Statue of Belief stands in India at 106 meters tall.',\n",
       " 'The fifth largest is Ushiku Daibutsu, a Japanese statue built in 1993.',\n",
       " 'It is 100 meters tall.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize by sentence\n",
    "statues_sent = nltk.sent_tokenize(statues)\n",
    "\n",
    "statues_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9b23a-5f75-4f0e-b40c-06c20a08894c",
   "metadata": {},
   "source": [
    "As you can see above, NLTK's tokenizer takes a single string of text and creates a list of separate strings for each sentence. Now let's break each sentence down into separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d4166e6-e3f6-4c15-8dba-24be009e6913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'largest',\n",
       " 'statue',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'is',\n",
       " 'India',\n",
       " \"'s\",\n",
       " 'Statue',\n",
       " 'of',\n",
       " 'Unity',\n",
       " '.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list to hold our tokenized sentences\n",
    "statues_tk = []\n",
    "\n",
    "# tokenize each sentence and append it to the list\n",
    "for sent in statues_sent:\n",
    "    toks = nltk.word_tokenize(sent)\n",
    "    statues_tk.append(toks)\n",
    "\n",
    "statues_tk[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ccfd9-a616-43ae-b673-ab62e4c300f3",
   "metadata": {},
   "source": [
    "Each sentence has been broken down into a list of separate strings for each word. Note what happens with posessive nouns and punctuation. This is not a problem for our current task, but we will be exploring ways to handle such issues later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3adde1-7e60-4392-94fe-2638b2aa8b86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parts of speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedc0d9-0dea-428f-8db0-20a78228ae5c",
   "metadata": {},
   "source": [
    "Parts of speech tagging allows us to label individual tokens with their lexical categories such as nouns, adjectives, verbs etc. The NLTK library includes a function called `pos_tag()` that will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42f3662e-023d-4a19-90bd-59c80b8d9f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('largest', 'JJS'),\n",
       " ('statue', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('India', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Statue', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Unity', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list to hold our tagged sentences\n",
    "statues_pos = []\n",
    "\n",
    "# tag each sentence with parts of speech and append it to the list\n",
    "for sent in statues_tk:\n",
    "    tags = nltk.pos_tag(sent)\n",
    "    statues_pos.append(tags)\n",
    "\n",
    "statues_pos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8828916-ae30-419c-a386-403c99afc7d9",
   "metadata": {},
   "source": [
    "NLTK'S POS tagging tool is based on the [Penn Treebank Project](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1246&context=cis_reports), so to understand the label each token has been assigned, we'll need to check the [Penn Treebank Project list of tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). As we can see, \"The\" is labeled as a determiner, \"largest\" as a superlative adjective, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e69e8e-3581-4989-9baf-9a457d673c5a",
   "metadata": {},
   "source": [
    "### Named Entity Recognition with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29c819-41f7-4eac-b735-49019ef67b37",
   "metadata": {},
   "source": [
    "Tagging parts of speech begins to provide structure to our text, but it doesn't tell us which words and phrases represent important entities, such as countries, names, etc. In order to find those, we'll need to use another function provided by NLTK called `ne_chunk()`. Let's test that function on just one of our tagged sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e0080069-1db2-40b5-8e66-21406a177ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  second/JJ\n",
      "  largest/JJS\n",
      "  statue/NN\n",
      "  comes/VBZ\n",
      "  in/IN\n",
      "  at/IN\n",
      "  128/CD\n",
      "  meters/NNS\n",
      "  and/CC\n",
      "  is/VBZ\n",
      "  called/VBN\n",
      "  the/DT\n",
      "  (ORGANIZATION Spring/NN Temple/NNP Buddha/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "test = nltk.ne_chunk(statues_pos[2])\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81323cc-9fde-4663-8906-06db319b25e1",
   "metadata": {},
   "source": [
    "We can see that NLTK has chunked the \"Spring\", \"Temple\" and \"Buddha\" tokens into a single entity. That chunk belongs to the object class `nltk.tree.Tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5ae98812-1769-42ea-a5bf-94340459c612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tree.Tree"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4899d-7c5c-4682-94ca-187e5bae5db3",
   "metadata": {},
   "source": [
    "To see all of our named entities in the text, let's print out just the chunks that belong to the `nltk.tree.Tree` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "839d84d5-ab5e-4266-8dc2-c76f5e11885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPE India/NNP)\n",
      "(GPE Unity/NNP)\n",
      "(ORGANIZATION Spring/NN Temple/NNP Buddha/NNP)\n",
      "(GPE China/NNP)\n",
      "(PERSON Laykun/NNP Sekkya/NNP)\n",
      "(GPE Myanmar/NNP)\n",
      "(GPE Belief/NNP)\n",
      "(GPE India/NNP)\n",
      "(PERSON Ushiku/JJ Daibutsu/NNP)\n",
      "(GPE Japanese/JJ)\n"
     ]
    }
   ],
   "source": [
    "for sent in statues_pos:\n",
    "    chunks = nltk.ne_chunk(sent)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if type(chunk) == nltk.tree.Tree:\n",
    "            print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5ea82-63f5-4748-86b4-181536047b06",
   "metadata": {},
   "source": [
    "This is a rather dissappointing list. Although country names have been reliably labelled as Geopolitical Entities (GPE), the full names of some of our statues have been lost, and neither the quantities nor years in the text have been tagged at all.\n",
    "\n",
    "Let's try using a different library to find named entities. This time, we'll use SpaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886d51a-4428-4edc-b8ac-0297292ef433",
   "metadata": {},
   "source": [
    "### Named Entity Recognition with SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46f7b3-bbf8-44b4-a12e-eaa4eb185e7c",
   "metadata": {},
   "source": [
    "SpaCy has a more streamlined approach to tagging. We can simply load a \"pipeline\" that does all of the tokenizing, parts of speech tagging, and named entity recognition for us in one go. We'll use the `en_core_web_sm` pipeline and apply it to our text. This will create a special class of object called `spacy.tokens.doc.Doc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29d9eb03-54c6-48e0-9f24-eacd12be0a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "statues_nlp = nlp(statues)\n",
    "\n",
    "type(statues_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba316-5d54-455c-a83d-b5f91e7a92e7",
   "metadata": {},
   "source": [
    "Our spacy.tokens object has many useful attributes. Named entities are in an attribute called `ents`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb978841-07f1-4681-b7ba-e49a20e4c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(India,\n",
       " Statue of Unity,\n",
       " 182 meters,\n",
       " 2018,\n",
       " second,\n",
       " 128 meters,\n",
       " the Spring Temple Buddha,\n",
       " China,\n",
       " 2008,\n",
       " Laykun Sekkya,\n",
       " Myanmar,\n",
       " 115.8 meters,\n",
       " 2008,\n",
       " 2020,\n",
       " the Statue of Belief,\n",
       " India,\n",
       " 106 meters,\n",
       " fifth,\n",
       " Ushiku Daibutsu,\n",
       " Japanese,\n",
       " 1993,\n",
       " 100 meters)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statues_nlp.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bdf9d5-cbac-4d26-8aa7-0092f8213801",
   "metadata": {},
   "source": [
    "Each `ent` has text and label elements. Printing those elements provides a nice list of all the named entities in our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fadaccda-e884-46fe-b7b9-ede8310b3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India GPE\n",
      "Statue of Unity FAC\n",
      "182 meters QUANTITY\n",
      "2018 DATE\n",
      "second ORDINAL\n",
      "128 meters QUANTITY\n",
      "the Spring Temple Buddha FAC\n",
      "China GPE\n",
      "2008 DATE\n",
      "Laykun Sekkya PERSON\n",
      "Myanmar GPE\n",
      "115.8 meters QUANTITY\n",
      "2008 DATE\n",
      "2020 DATE\n",
      "the Statue of Belief FAC\n",
      "India GPE\n",
      "106 meters QUANTITY\n",
      "fifth ORDINAL\n",
      "Ushiku Daibutsu PERSON\n",
      "Japanese NORP\n",
      "1993 DATE\n",
      "100 meters QUANTITY\n"
     ]
    }
   ],
   "source": [
    "for ent in statues_nlp.ents:\n",
    "    print(ent.text,  ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dbcafd-2c60-436f-89c6-a55a1ae262aa",
   "metadata": {},
   "source": [
    "These results are much more accurate. So why does named entity recognition work so much better in SpaCy than it does in NLTK?\n",
    "\n",
    "The answer lies in **classification**. NLTK and SpaCy use different techniques for classifying tokens into different categories. Classification of words, phrases and documents is one of the most common applications of text analysis used today, and there are many classifcation techniques that can be applied to a text analysis problem. In this workshop, we'll explore two types of classification techniques: supervised and unsupervised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66721f2f-f49d-4924-b764-451cc21130ab",
   "metadata": {},
   "source": [
    "## Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c22214-ef43-4e5e-bddc-a55371bcb183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82344c4-01bb-40b4-9b81-a71e1a169b27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c1039-afb0-46b4-9bd0-832dc85f6ff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bag of words techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136511c3-2206-4814-83bb-af519ab30023",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd0b11-b842-4f43-8dce-a694ffbcbab2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### N-grams/co-occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ed96d-f785-41bc-91be-eaceeb27306a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f59cf0-4b4d-4ad8-a06b-77a9ca670cf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200da21-6d19-4b73-8b5f-b7657cb57aab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12b188-ad5a-4aeb-9ce0-e6bd92829873",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Evaluating results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0584f72-af6f-473b-a479-7483eca68885",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Tweaking/comparing models (prob. Naïve Bayes and SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d04d89-033c-46e8-9432-3f96266fdf38",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277c02b-b28d-412d-8693-9b953a9f8b71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Explain and demonstrate various models (WLDA, clustering, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
